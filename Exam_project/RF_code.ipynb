{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "prescription-webcam",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from scipy.sparse import hstack\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import learning_curve\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.utils import resample\n",
    "from sklearn.utils import resample\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from scipy.sparse import hstack\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "lesbian-closure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "requested-separation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import resample\n",
    "\n",
    "def process_column_rf(column_name, data, with_dummies=False):\n",
    "    \"\"\"Function to process data using RandomForest.\"\"\"\n",
    "    # Step 1: Data Preprocessing\n",
    "    data_cleaned = data.dropna(subset=[column_name])\n",
    "    y = data_cleaned['Article_Gender']\n",
    "    \n",
    "    # Create journal dummies if required\n",
    "    if with_dummies:\n",
    "        journal_dummies = pd.get_dummies(data_cleaned['Journal'], prefix='Journal')\n",
    "\n",
    "    results = {}  # Dictionary to store results\n",
    "    \n",
    "    for ngram, label in [((1, 1), \"ug\"), ((1, 2), \"bg\")]:\n",
    "        # Step 2: Vectorization\n",
    "        tfidf_vectorizer = TfidfVectorizer(max_features=5000, ngram_range=ngram)\n",
    "        X = tfidf_vectorizer.fit_transform(data_cleaned[column_name])\n",
    "        \n",
    "        # Add dummies if required\n",
    "        if with_dummies:\n",
    "            X = hstack([X, journal_dummies.values])\n",
    "\n",
    "        # Step 3: Train-Test Split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Step 4: Addressing Class Imbalance\n",
    "        data_female = data_cleaned[data_cleaned['Article_Gender'] == 'Female']\n",
    "        data_male = data_cleaned[data_cleaned['Article_Gender'] == 'Male']\n",
    "        data_female_oversampled = resample(data_female, replace=True, n_samples=len(data_male), random_state=42)\n",
    "        data_oversampled = pd.concat([data_male, data_female_oversampled])\n",
    "        X_oversampled = tfidf_vectorizer.transform(data_oversampled[column_name])\n",
    "        y_oversampled = data_oversampled['Article_Gender']\n",
    "        X_train_os, X_test_os, y_train_os, y_test_os = train_test_split(X_oversampled, y_oversampled, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Step 5: Building Random Forest Model with OOB Score\n",
    "        rf = RandomForestClassifier(class_weight='balanced', n_estimators=100, oob_score=True, random_state=42)\n",
    "        rf.fit(X_train_os, y_train_os)\n",
    "\n",
    "        # Step 6: Predictions\n",
    "        y_pred = rf.predict(X_test_os)\n",
    "        accuracy = accuracy_score(y_test_os, y_pred)\n",
    "\n",
    "        # Step 7: Performance Evaluation\n",
    "        evaluation_metrics_rf = classification_report(y_test_os, y_pred, target_names=[\"Female\", \"Male\"])\n",
    "        confusion_rf = confusion_matrix(y_test_os, y_pred)\n",
    "\n",
    "        # Step 8: Feature Importance\n",
    "        feature_importance = rf.feature_importances_\n",
    "        important_features = sorted(zip(feature_importance, tfidf_vectorizer.get_feature_names_out()), reverse=True)[:20]\n",
    "\n",
    "        # Step 9: Hyperparameter Tuning\n",
    "        rf_params = {\n",
    "            'n_estimators': [50, 100, 150],\n",
    "            'max_depth': [None, 10, 20, 30],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4]\n",
    "        }\n",
    "        grid_search_rf = GridSearchCV(RandomForestClassifier(class_weight='balanced', oob_score=True, random_state=42),\n",
    "                                      rf_params,\n",
    "                                      cv=5,\n",
    "                                      scoring='accuracy',\n",
    "                                      n_jobs=-1)\n",
    "        grid_search_rf.fit(X_train_os, y_train_os)\n",
    "        best_params_rf = grid_search_rf.best_params_\n",
    "        best_score_rf = grid_search_rf.best_score_\n",
    "\n",
    "        # Outputs\n",
    "        results[label + (\"_dummies\" if with_dummies else \"\")] = {\n",
    "            'accuracy': accuracy,\n",
    "            'evaluation_metrics_rf': evaluation_metrics_rf,\n",
    "            'confusion_rf': confusion_rf,\n",
    "            'important_features': important_features,\n",
    "            'best_params_rf': best_params_rf,\n",
    "            'best_score_rf': best_score_rf\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Call the functions for each of the desired columns without dummies\n",
    "results_intro_cleaned = process_column_rf('Intro_Cleaned', data)\n",
    "results_intro_1 = process_column_rf('Intro_1', data)\n",
    "results_intro_2 = process_column_rf('Intro_2', data)\n",
    "results_intro_3 = process_column_rf('Intro_3', data)\n",
    "\n",
    "# Call the functions for each of the desired columns with dummies\n",
    "results_intro_cleaned_dummies = process_column_rf('Intro_Cleaned', data, with_dummies=True)\n",
    "results_intro_1_dummies = process_column_rf('Intro_1', data, with_dummies=True)\n",
    "results_intro_2_dummies = process_column_rf('Intro_2', data, with_dummies=True)\n",
    "results_intro_3_dummies = process_column_rf('Intro_3', data, with_dummies=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "egyptian-statement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_rf_results(column_name, results):\n",
    "    # Header for the column\n",
    "    print(f\"\\nResults for {column_name}:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Iterate through each variant (ug, bg, ug_dummies, bg_dummies)\n",
    "    for variant, metrics in results.items():\n",
    "        if \"_dummies\" in variant:\n",
    "            model_type = \"with Journal Dummies\"\n",
    "        else:\n",
    "            model_type = \"without Journal Dummies\"\n",
    "        \n",
    "        ngram_type = \"Unigram\" if \"ug\" in variant else \"Bigram\"\n",
    "        \n",
    "        # Basic Information\n",
    "        print(f\"\\nModel Performance Summary (Random Forest, {ngram_type}, {model_type}):\")\n",
    "        print(\"-\" * 60)\n",
    "        print(f\"Random Forest Accuracy: {metrics['accuracy'] * 100:.2f}%\")\n",
    "        print(f\"Best Score with Optimal Hyperparameters: {metrics['best_score_rf'] * 100:.2f}%\")\n",
    "        print(f\"Best Hyperparameters: {metrics['best_params_rf']}\")\n",
    "        print(f\"Top 5 Important Features: {metrics['important_features'][:5]}\")\n",
    "        print(f\"\\nClassification Report:\\n{metrics['evaluation_metrics_rf']}\")\n",
    "        print(f\"Confusion Matrix:\\n{metrics['confusion_rf']}\")\n",
    "        \n",
    "    print(\"\\n\")\n",
    "    \n",
    "# Call the print_rf_results function for each set of results\n",
    "print_rf_results('Intro_Cleaned', results_intro_cleaned)\n",
    "print_rf_results('Intro_1', results_intro_1)\n",
    "print_rf_results('Intro_2', results_intro_2)\n",
    "print_rf_results('Intro_3', results_intro_3)\n",
    "print_rf_results('Intro_Cleaned with Dummies', results_intro_cleaned_dummies)\n",
    "print_rf_results('Intro_1 with Dummies', results_intro_1_dummies)\n",
    "print_rf_results('Intro_2 with Dummies', results_intro_2_dummies)\n",
    "print_rf_results('Intro_3 with Dummies', results_intro_3_dummies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
