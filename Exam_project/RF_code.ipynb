{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "gothic-grenada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from scipy.sparse import hstack\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import learning_curve\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.utils import resample\n",
    "from sklearn.utils import resample\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from scipy.sparse import hstack\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, make_scorer, accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.utils import resample\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, make_scorer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offshore-massage",
   "metadata": {},
   "source": [
    "## baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dedicated-county",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 'Intro_Cleaned' without dummies using precision_female:\n",
      "Score: 0.6785714285714286\n",
      "\n",
      "Results for 'Intro_Cleaned' without dummies using recall_female:\n",
      "Score: 0.04068522483940043\n",
      "\n",
      "Results for 'Intro_Cleaned' without dummies using f1_score_female:\n",
      "Score: 0.07676767676767678\n",
      "\n",
      "Results for 'Intro_Cleaned' without dummies using precision_male:\n",
      "Score: 0.8416401555319901\n",
      "\n",
      "Results for 'Intro_Cleaned' without dummies using recall_male:\n",
      "Score: 0.996234309623431\n",
      "\n",
      "Results for 'Intro_Cleaned' without dummies using f1_score_male:\n",
      "Score: 0.9124353324391646\n",
      "\n",
      "Results for 'Intro_Cleaned' without dummies using accuracy_score:\n",
      "Score: 0.840042002100105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('data_cleaned.csv')\n",
    "\n",
    "def process_column_rf(column_name, data):\n",
    "    \"\"\"Function to process data using RandomForest.\"\"\"\n",
    "    data_cleaned = data.dropna(subset=[column_name])\n",
    "    y = data_cleaned['Article_Gender']\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Vectorize using unigrams & bigram\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "    X = tfidf_vectorizer.fit_transform(data_cleaned[column_name])\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train RandomForest without cross-validation\n",
    "    rf = RandomForestClassifier(n_estimators=100, class_weight='balanced', oob_score=True, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "    # Get scores for Female\n",
    "    results['precision_female'] = precision_score(y_test, y_pred, pos_label='Female', zero_division=0)\n",
    "    results['recall_female'] = recall_score(y_test, y_pred, pos_label='Female', zero_division=0)\n",
    "    results['f1_score_female'] = f1_score(y_test, y_pred, pos_label='Female', zero_division=0)\n",
    "    \n",
    "    # Get scores for Male\n",
    "    results['precision_male'] = precision_score(y_test, y_pred, pos_label='Male', zero_division=0)\n",
    "    results['recall_male'] = recall_score(y_test, y_pred, pos_label='Male', zero_division=0)\n",
    "    results['f1_score_male'] = f1_score(y_test, y_pred, pos_label='Male', zero_division=0)\n",
    "\n",
    "    # Accuracy score\n",
    "    results['accuracy_score'] = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return results\n",
    "\n",
    "# Process 'Intro_Cleaned' column without dummies\n",
    "results_intro_cleaned = process_column_rf('Intro_Cleaned', df)\n",
    "\n",
    "for metric, score in results_intro_cleaned.items():\n",
    "    print(f\"Results for 'Intro_Cleaned' without dummies using {metric}:\")\n",
    "    print(f\"Score: {score}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ruled-desire",
   "metadata": {},
   "source": [
    "## with cross validation & weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-destiny",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, make_scorer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('data_cleaned.csv')\n",
    "\n",
    "def process_column_rf(column_name, data, top_n=20):\n",
    "    \"\"\"Function to process data using RandomForest.\"\"\"\n",
    "    data_cleaned = data.dropna(subset=[column_name])\n",
    "    y = data_cleaned['Article_Gender']\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Vectorize using unigrams & bigram\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "    X = tfidf_vectorizer.fit_transform(data_cleaned[column_name])\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    rf_params = {\n",
    "        'n_estimators': [50, 100, 150],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "\n",
    "    # Loop through weights for female from 1 to 11\n",
    "    for weight in range(1, 12):\n",
    "        class_weights = {'Male': 1, 'Female': weight}\n",
    "        \n",
    "        grid_search_rf = GridSearchCV(RandomForestClassifier(class_weight=class_weights, oob_score=True, random_state=42),\n",
    "                                      rf_params,\n",
    "                                      cv=5,\n",
    "                                      scoring='accuracy',\n",
    "                                      n_jobs=-1)\n",
    "        grid_search_rf.fit(X_train, y_train)\n",
    "        best_params_rf = grid_search_rf.best_params_\n",
    "        \n",
    "        # Use the best estimator for predictions\n",
    "        best_rf = grid_search_rf.best_estimator_\n",
    "        y_pred = best_rf.predict(X_test)\n",
    "        \n",
    "        # Calculate scores for female\n",
    "        precision_female = precision_score(y_test, y_pred, pos_label='Female', zero_division=0)\n",
    "        recall_female = recall_score(y_test, y_pred, pos_label='Female', zero_division=0)\n",
    "        f1_female = f1_score(y_test, y_pred, pos_label='Female', zero_division=0)\n",
    "        \n",
    "        # Calculate scores for male\n",
    "        precision_male = precision_score(y_test, y_pred, pos_label='Male', zero_division=0)\n",
    "        recall_male = recall_score(y_test, y_pred, pos_label='Male', zero_division=0)\n",
    "        f1_male = f1_score(y_test, y_pred, pos_label='Male', zero_division=0)\n",
    "\n",
    "        # Accuracy\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        # Store the results for this weight\n",
    "        results[f\"weight_female_{weight}\"] = {\n",
    "            'precision_female': precision_female,\n",
    "            'recall_female': recall_female,\n",
    "            'f1_score_female': f1_female,\n",
    "            'precision_male': precision_male,\n",
    "            'recall_male': recall_male,\n",
    "            'f1_score_male': f1_male,\n",
    "            'accuracy': accuracy\n",
    "        }\n",
    "\n",
    "    return results\n",
    "\n",
    "# Process 'Intro_Cleaned' column without dummies\n",
    "results_intro_cleaned = process_column_rf('Intro_Cleaned', df)\n",
    "\n",
    "for weight, metrics in results_intro_cleaned.items():\n",
    "    print(f\"Results for 'Intro_Cleaned' without dummies using {weight}:\")\n",
    "    for metric, score in metrics.items():\n",
    "        print(f\"{metric}: {score}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smoking-education",
   "metadata": {},
   "source": [
    "## Validation curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "crude-advance",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-9e6f245e48f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_cleaned\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Article_Gender'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mtfidf_vectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngram_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidf_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_cleaned\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Intro_Cleaned'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   2124\u001b[0m             \u001b[0msublinear_tf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msublinear_tf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2125\u001b[0m         )\n\u001b[0;32m-> 2126\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2127\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2128\u001b[0m         \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1149\u001b[0m                 )\n\u001b[1;32m   1150\u001b[0m             ):\n\u001b[0;32m-> 1151\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1393\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"max_df corresponds to < documents than min_df\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmax_features\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1395\u001b[0;31m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sort_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1396\u001b[0m             X, self.stop_words_ = self._limit_features(\n\u001b[1;32m   1397\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_doc_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_doc_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_sort_features\u001b[0;34m(self, X, vocabulary)\u001b[0m\n\u001b[1;32m   1201\u001b[0m         \u001b[0mReturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mreordered\u001b[0m \u001b[0mmatrix\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmodifies\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvocabulary\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mplace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m         \"\"\"\n\u001b[0;32m-> 1203\u001b[0;31m         \u001b[0msorted_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1204\u001b[0m         \u001b[0mmap_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnew_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_val\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, make_scorer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, validation_curve\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('data_cleaned.csv')\n",
    "\n",
    "data_cleaned = df.dropna(subset=['Intro_Cleaned'])\n",
    "y = data_cleaned['Article_Gender']\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "X = tfidf_vectorizer.fit_transform(data_cleaned['Intro_Cleaned'])\n",
    "weights = range(1, 12)\n",
    "\n",
    "# Using F1 score as the scoring metric\n",
    "train_scores, test_scores = validation_curve(\n",
    "    RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    X, y, param_name=\"class_weight\", param_range=[{'Male': 1, 'Female': w} for w in weights],\n",
    "    scoring=make_scorer(f1_score, pos_label='Female', zero_division=0), cv=5)\n",
    "\n",
    "train_scores_mean = train_scores.mean(axis=1)\n",
    "train_scores_std = train_scores.std(axis=1)\n",
    "test_scores_mean = test_scores.mean(axis=1)\n",
    "test_scores_std = test_scores.std(axis=1)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.title(\"Validation Curve with RandomForest for F1 Score\")\n",
    "plt.xlabel(\"Weight for Female\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.ylim(0.5, 1.1)\n",
    "plt.plot(weights, train_scores_mean, label=\"Training score\", color=\"r\")\n",
    "plt.fill_between(weights, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.2, color=\"r\")\n",
    "plt.plot(weights, test_scores_mean, label=\"Cross-validation score\", color=\"g\")\n",
    "plt.fill_between(weights, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.2, color=\"g\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-plaza",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
