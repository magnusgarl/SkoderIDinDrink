Volume,Issue,Journal Name,Published Date,Link,Title,Journal Year,Author 1,Author 2,Author 3,Gender_Author 1,Gender_Author 2,Gender_Author 3,Article_Gender,Intro,Citations
1.0,1.0,Journal of the Economic Science Association,07 July 2015,https://link.springer.com/article/10.1007/s40881-015-0012-4,Editors’ preface: introducing JESA,July 2015,Nikos Nikiforakis,Robert Slonim,,Male,Male,Unknown,Male,"One of the most important advances in economics in the past century was the development of a methodology for conducting controlled experiments. In the space of 50 years, experimental economists have made contributions to our understanding of markets, strategic behavior and individual decision making that transformed economic theory, influenced policy and helped shape public debate. Two milestones during this period were the establishment of the Economic Science Association (ESA) in 1986 to further economics as an observational science through controlled experiments, and the introduction of Experimental Economics in 1998—ESA’s first official journal—to serve the needs of the growing community of experimental economists. Today marks another milestone. It is our great pleasure to introduce the first issue of the Journal of the Economic Science Association. JESA is a ‘companion journal’ to Experimental Economics (EXEC) which raises two questions: (1) Why does the association need a new journal? (2) How are the two journals similar and, most importantly, how will they differ? This preface is dedicated to answering these questions.",10
1.0,1.0,Journal of the Economic Science Association,19 May 2015,https://link.springer.com/article/10.1007/s40881-015-0006-2,Fair weather avoidance: unpacking the costs and benefits of “Avoiding the Ask”,July 2015,Hannah Trachtman,Andrew Steinkruger,Justin M. Rao,Female,Male,Male,Mix,,
1.0,1.0,Journal of the Economic Science Association,24 February 2015,https://link.springer.com/article/10.1007/s40881-015-0001-7,Conformity in the lab,July 2015,Jacob K. Goeree,Leeat Yariv,,Male,Unknown,Unknown,Male,"Understanding the formation of herds is relevant to a variety of economic environments, ranging from voting behavior to fashion fads to financial market investments. The literature on herd formation is split into two strands. The psychology literature [see initial studies of Sherif (1937); Asch (1958)] suggests a preference-based explanation in which agents exhibit conformity, an intrinsic taste to follow others. In contrast, the economics literature [see Banerjee (1992); Bikhchandani et al. (1992)] has proposed an information-based model in which agents opt to ignore private signals and follow their predecessors’ choices when the latter provide a stronger statistical indication as to the best course of action. In such a setting, agents who appear to be blindly following their peers may simply be best responding. The goal of the current paper is twofold. First, to disentangle conformity from information based decision-making and inequality aversion. Specifically, to determine whether conformity plays a significant role in economic environments. Second, to establish the effects of institutions on the prevalence of conformist behavior. In particular, we explore the impacts of payoff externalities and incentive magnitudes on conformist behavior in the lab. Our experimental design allows subjects to choose between observing a statistically informative signal and the history of choices of preceding players who themselves chose to observe the history of choices of predecessors who chose the history of choices, etc. That is, subjects choose between a statistically informative signal and a pure word-of-mouth signal. Within this framework, we study two aspects of subjects’ decisions: whether they choose to observe the social word-of-mouth signal and whether, upon choosing such a signal, they follow the more popular action. In our experiments, a significant percentage of subjects choose to observe the social information. Upon observing the social information, a significant majority of subjects choose the prevalent action observed. Externalities, learning, or increased stakes do not mitigate the results. In particular, the motives to “conform” appear to outweigh both individual and strategic voting motives. There are several experimental contributions to the literature on information cascades that tie directly to the current paper.Footnote 1 Our experimental design is similar in spirit to that used in Anderson and Holt (1997) and Hung and Plott (2001) in order to test experimentally the original informational cascade model of Bikhchandani et al. (1992). Ultimately, both these papers illustrate the prevalence of cascades and their sensitivity to the institution used to aggregate group choices.Footnote 2 However, in these papers both social and statistical information are always provided and are not objects of choice. Our paper also relates to a few recent papers exploring information acquisition in the context of social learning. For instance, in Çelen and Hyndman (2012), subjects often paid a fee to observe another agent’s action that held information that was not useful. This is consistent with our results. In fact, we illustrate that even when predecessors’ actions hold no information at all, agents are willing to forego statistical information in order to observe historical choices. See also Kübler and Weizsäcker (2004) and work that followed.Footnote 3
 Last, our paper contributes to the literature on imitation. Some of that literature assumes agents mimic successful others and analyzes the likely outcomes [see, e.g., Vega-Redondo (1997) and references therein]. Furthermore, several papers have inspected experimentally the tendency of subjects to mimic successful agents, mostly in the context of oligopolistic competition [see, for instance, Offerman et al. (2002); Apesteguia et al. (2007)]. While that literature often uses evolutionary forces as a justification for agents’ following others who have done well, the current paper suggests agents’ taste for following others, even absent any performance information.",53
1.0,1.0,Journal of the Economic Science Association,19 May 2015,https://link.springer.com/article/10.1007/s40881-015-0005-3,Online field experiments: a selective survey of methods,July 2015,Yan Chen,Joseph Konstan,,Male,Male,Unknown,Male,"Field experiments allow researchers to combine the control of laboratory experiments with some of the ecological validity of field studies. Areas such as medicine (Lohr et al. 1986), economics (Harrison and List 2004), and social psychology (Lerner et al. 2003) have all incorporated field experiments in their research. One of the challenges of field experiments, however, is the substantial cost of conducting them, particularly at a sufficient scale for studying high-variance social phenomena. Online communities present a more practical and cost effective venue for conducting field experiments. Given sufficient access to a community of users and the software substrate for their community, researchers can study both short- and long-term effects of a wide range of manipulations. In this paper, we present an analysis of the design choices for online field experiments using representative studies from both Economics and Computer Science. Within Computer Science, we focus on two subfields, i.e., Human–Computer Interactions (HCI), and Computer-Supported Collaborative Work (CSCW). We first summarize current methods for conducting online field experiments, with particular emphasis on the underlying technologies, and then offer some insights and design advice for social scientists interested in conducting such studies. From the extensive catalog of online field experiments, we choose a representative set of academic studies which use a variety of technologies and cover a broad spectrum of online sites, including those focused on social networking (Facebook, LinkedIn), user-generated content (Wikipedia, MovieLens), e-commerce (eBay, Yahoo!), online games (World of Warcraft), crowdfunding (Kiva), and crowdsourcing (Google Answers, TopCoder, oDesk, Taskcn). Note that we do not include experiments conducted on Amazon’s Mechanical Turk, as they have been covered in a separate survey (Horton et al. 2011). Nor do we include experiments conducted on platforms designed for behavioral experimentation, such as LabintheWild (Reinecke and Gajos 2015) and TestMyBrain (Germine et al. 2012). We also note that IT companies, including Amazon, eBay, Facebook, Google, LinkedIn, Microsoft, Netflix, ShopDirect, Yahoo, and Zynga, conduct a large number of commercial online field experiments, sometimes called A/B testing, to evaluate new ideas, guide product development, and improve interface design.Footnote 1 Although the vast majority of these experiments are not intended for publication and are thus not discussed here, the veracity of these studies nonetheless primarily depends on the same methodological issues academic researchers are concerned with that we discuss in this paper.",24
1.0,1.0,Journal of the Economic Science Association,25 April 2015,https://link.springer.com/article/10.1007/s40881-015-0007-1,Stated and revealed inequality aversion in three subject pools,July 2015,Benjamin Beranek,Robin Cubitt,Simon Gächter,Male,,Male,Mix,,
1.0,1.0,Journal of the Economic Science Association,07 May 2015,https://link.springer.com/article/10.1007/s40881-015-0011-5,Communication in legislative bargaining,July 2015,Andrzej Baranski,John H. Kagel,,Male,Male,Unknown,Male,"The Baron-Ferejohn (1989; BF) legislative bargaining model is one of the most popular, if not the most popular, formal model of the legislative bargaining process. It has been explored experimentally under a variety of different specifications including variations in the size of the committee, in voting rules, whether proposals can be amended, and a number of other variations (see Palfrey 2015 in press, for a review). These experiments provide clear qualitative support for the BF model in that minimum winning coalitions (MWC) are quite common, proposals typically pass without delay, and proposers exercise some power achieving higher payoffs than other members of the winning coalition. However, proposer power is substantially weaker than the stationary sub-game perfect equilibrium (SSPE) predicts. One central element of the legislative bargaining process as it occurs outside the lab, but has been largely missing in these experiments, is pre-play communication between proposers and voters. Under the standard bargaining model, there is no need for pre-play communication; it is assumed that risk neutral players can compute the continuation value of the game, and the only thing that matters is own income. However, past experiments have shown considerable heterogeneity in the payoffs individual players require to secure their vote, so proposers cannot identify voters with the lowest reservation values as coalition partners.Footnote 1 As such, at a minimum, what communication can do is to permit potential coalition partners to signal acceptable offers and, in the case of multilateral bargaining, permit proposers to take advantage of competition between potential coalition partners to elicit their lowest acceptable offers. Of course, given that pre-play communication is not binding, it is possible that coalition partners will exaggerate their lowest acceptable shares. Alternatively, if the cost of delay is not too high, voters might state very low reservation values with the idea of voting against the proposed allocation and getting a better deal, or having the chance to become the proposer when the bargaining continues. In addition, there is some evidence from bilateral bargaining games (Rankin 2003) and the dictator games (Andreoni and Rao 2011) that communication results in more equal payoffs between bargainers compared to the no communication case. Our game involves three player groups with $30 to be distributed under majority rule and no discounting of payoffs following a rejected proposal. The first question addressed is whether permitting free form communication increases proposer power relative to the no communication case. The unambiguous answer is that it results in a substantial increase, with proposers’ earnings averaging 63.7 % of the available money in the last five bargaining rounds compared to 66.7 % predicted under the SSPE, and 48.3 % for the no communication control treatment. This significant increase in proposer power is achieved with a slight increase in the frequency with which initial proposals are accepted, consistent with increased voter acceptability of the sharp increase in proposer power with communication. The second question posed is: What is the mechanism underlying this increase in proposer power? For this, we look at the dialogues between proposers and potential coalition partners. Three bargaining styles are identified: (1) Proposers actively solicit voters’ lowest acceptable offers to get them to compete to be included in an MWC (strong proposer bargaining; 29.4 %), (2) Proposers bargain with potential coalition partners within the context of achieving an “equitable” allocation between all three players (weak proposer bargaining; 7.1 %), and (3) Potential coalition partners initiate the bargaining, making offers to proposers while frequently calling for a zero allocation for the redundant voter (voters initiated bargaining; 50.6 %). We also compare potential coalition partners’ reservation shares to what they were allocated and the extent to which they renege on these commitments. Here, it is not unusual for proposers to reject rock bottom shares, with voters offering to accept significantly lower shares, more likely to renege on these low offers, compared to somewhat higher offers. Further, it is not uncommon for proposers to offer shares a little above what was requested, which significantly increases the probability that their proposal will be accepted. The experiment that is closest to ours is Agranov and Tergiman (2014) who also investigate the BF model with nonbinding communication. There are a number of potentially important differences in our experimental design and theirs.Footnote 2 Our main experimental treatment involves “closed door” bargaining with bilateral communication between proposers and their potential coalition partners, with no communication permitted between voters (think of secret legislative negotiations). In contrast, Agranov and Tergiman permit communication between potential coalition partners, as well as public communication between all players, which is more akin to a double auction market, with strong downward pressure on shares toward the equilibrium outcome. Of potentially more importance, in their experiment the money to be allocated shrinks by twenty percent following rejected offers, which puts strong pressure on accepting lower shares, thereby enhancing proposer power, as well as discouraging voters from forming blocking coalitions in an effort to obtain a better outcome. Finally, our experiment involved three bargainers, theirs five, so that it would be somewhat easier to coordinate the formation of a blocking coalition in our design. In spite of these differences in experimental design, both yield the same main result: permitting cheap talk into the Baron-Ferejohn legislative bargaining process substantially increases proposer power. However, there is an even greater increase in proposer power in our experiment than in theirs. Motivated by these minor differences we conducted a second, “open door”, communication treatment, the same in all respects to our closed door treatment, but with their open door communication. This too results in a sharp increase in proposer power compared to the no communication control, albeit with a somewhat weaker increase in proposer power compared to closed door communication. The results of this treatment are briefly discussed in the results section, with details provided online (Online Supplementary Material).",41
1.0,1.0,Journal of the Economic Science Association,27 May 2015,https://link.springer.com/article/10.1007/s40881-015-0008-0,Game form misconceptions are not necessary for a willingness-to-pay vs. willingness-to-accept gap,July 2015,Björn Bartling,Florian Engl,Roberto A. Weber,Male,Male,Male,Male,"A recent article by Cason and Plott (2014) argues for caution in drawing inferences about non-standard preferences from choice data using experimental value elicitation procedures, such as the mechanism introduced by Becker et al. (1964, henceforth, BDM). This argument raises challenges to parts of the behavioral literature, especially the literature on willingness-to-pay (WTP) vs. willingness-to-accept (WTA) gaps—i.e., the tendency for subjects endowed with an object to state higher valuation for the object than subjects not endowed with it—which is one of the most widely studied phenomena in behavioral economics (see, e.g., Kahneman et al. 1991; Ericson et al. 2014). Cason and Plott support their argument with evidence that a systematic bias in subjects’ stated valuations for an item with a known dollar value is reflective of subjects’ misunderstanding of the game form—that is, subjects systematically fail to understand the incentive properties of the BDM mechanism and therefore over-report their WTA. Specifically, Cason and Plott conduct a classroom experiment in which they endow subjects with a card that is redeemable from the experimenter for $2, and allow subjects to state sales price offers through the BDM procedure. A random posted price between $0 and an upper price limit ranging from $4 to $8 is generated, and a subject sells his card to the experimenter only if this posted price exceeds the subjects’ stated offer price. Using this design, Cason and Plott find that a large majority of subjects (83 %) do not select offers within 5 cents of the dominant strategy of $2. This frequency of apparently confused subjects decreases, to 69 %, with feedback and repetition. Moreover, subjects’ offers are biased upward, and are also influenced by the upper range of the distribution from which the posted prices are drawn. From this evidence, Cason and Plott argue that studies in which researchers attempt to make inferences about preferences from experiments using the BDM elicitation procedure should be taken with caution. The possibility that game form misconceptions may account for behavior inconsistent with standard models of choice in some experiments is intriguing—indeed, this seems to be the case in Cason and Plott’s experiment. In this paper, we ask if game form misconceptions are necessary to produce such data, or whether WTP-WTA gaps are observed even among subjects with no apparent misconceptions about the incentive properties of the BDM. To test whether subjects’ misunderstanding of the incentive properties of the BDM mechanism is necessary in order to observe WTP-WTA gaps, we follow the recommendation that “experimental procedures should be designed to avoid ‘subject misconceptions’” (Plott and Zeiler 2005). But, we also go further and focus the analysis on those subjects for whom we have evidence that there is no misconception. If subject misconceptions about the BDM procedure are largely absent, but subjects’ choices nevertheless exhibit significant WTP-WTA gaps, then we can exclude that the observed behavior is entirely driven by mistakes in understanding the incentive properties of the BDM. To address this question, we conduct a valuation experiment in which subjects are randomly assigned to the role of either buyer or seller and where we elicit, respectively, subjects’ WTP or WTA values. Our experiment consists of two parts. First, in Part I, we elicit buying and selling prices for a card worth precisely 8.50 Swiss francs (CHF). We employ a price-list representation of the BDM procedure, in which subjects are presented with a series of prices and asked, for each price, whether they are willing to trade at that price (Kahneman et al. 1990; Murphy et al. 2010). Part II of the study is identical to Part I, except for exactly one difference: in Part II subjects do not trade an object of induced value (a card worth 8.50 CHF) but instead an item with private and heterogeneous valuation—a box of chocolates. Furthermore, after subjects indicate their choices in each part, but before they can finalize their choices, we also require them to identify the actual payoff consequences for each choice and, in case they make a mistake, we provide feedback and ask them to correct their mistake. Hence, all subjects, at the time of implementing a choice, have correctly entered all of the payoff consequences from their choices. Moreover, we can identify those subjects who entered their payoffs correctly on the very first attempt. These procedures allow us to identify a subset of subjects who satisfy three conditions that are likely to mean they understand the BDM mechanism and its payoff consequences. First, we consider only subjects who provide payoff-maximizing valuations in Part I, where values are common and known. Second, we further eliminate any subjects who do not enter their payoffs entirely correctly on their first attempt in Part I. Third, we also eliminate subjects who do not enter their payoffs correctly on their first attempt in Part II, when bidding or offering prices for the box of chocolates. Hence, what remains are subjects who (1) make optimal choices in the BDM with known value, (2) identify all payoff consequences correctly in the BDM with known value on their first attempt, and (3) identify all payoff consequences correctly in the BDM for the box of chocolates on their first attempt. These “sophisticated” subjects are unlikely to have misconceptions about the BDM game form. We test whether a WTP-WTA gap for the object of unknown value—the box of chocolates—still obtains within this subset of our population. Our main result is that, looking only at the subjects with no apparent game form misconception, we nevertheless replicate a strong WTP-WTA gap in Part II. Hence, WTP-WTA gaps obtain even among a population for which misconception of the incentive properties of the BDM mechanism is likely not an issue. However, while we observe that a majority of subjects, 70 %, provide the payoff-maximizing valuation in Part I of the experiment, we also observe that 30 % do not. Hence, we confirm the limitations of the BDM as a valuation mechanism observed by Cason and Plott (2014), providing support for their claim that caution is warranted when relying on valuations elicited with this mechanism due to subject miscomprehension of the incentive properties. Before proceeding to our design and results, we note that we do not attempt to provide evidence supporting any particular explanation for WTP-WTA gaps. Thus, we make no claims that the WTP-WTA gap in our data is driven by loss aversion, or whether it results from other behavioral phenomena, such as misperception of the value of a commodity or alternative sources of utility or disutility (cf. Plott and Zeiler 2005, 2007; Weaver and Frederick 2012). Instead, our simpler goal is to test whether game form misconceptions are a necessary condition to produce WTP-WTA gaps, or whether such gaps obtain even when such misconceptions are absent.",27
1.0,1.0,Journal of the Economic Science Association,25 February 2015,https://link.springer.com/article/10.1007/s40881-015-0002-6,Dishonesty under scrutiny,July 2015,Jeroen van de Ven,Marie Claire Villeval,,Male,Female,Unknown,Mix,,
1.0,1.0,Journal of the Economic Science Association,09 May 2015,https://link.springer.com/article/10.1007/s40881-015-0010-6,An experimental study of leadership institutions in collective action games,July 2015,Selhan Garip Sahin,Catherine Eckel,Mana Komai,Unknown,Female,Female,Female,"Free riding and coordination failures are two common problems in collective action. Economists have emphasized leadership as a viable solution to such collective action problems, and recent experimental research has explored the effectiveness of leadership in improving cooperation and coordination. We construct parallel standard linear and weakest-link public good games, and examine the effectiveness of two common leadership institutions: leading by example, where a leader moves first and is observed by others; and leading by suggestion, where a leader makes a “cheap talk” suggestion of a choice for each member of a group. Much of the extensive research in economics on leadership can be categorized based on four important characteristics. First is the set of actions that the leader may take. Some leaders lead by making a costly commitment such as their own participation as a first mover in the project (Hermalin 1998; Vesterlund 2003; Potters et al. 2005, 2007; Komai et al. 2007; Komai and Stegeman 2010). In most cases, these leaders are simply first movers with observable actions (Moxnes and van der Heijden 2003; Bardsley and Sausgruber 2005; Guth et al. 2007; Levy et al. 2011; Gächter et al. 2012; Jack and Recalde 2015).Footnote 1 Others lead by sending their followers a cheap talk signal such as making a simple suggestion (Wilson and Sell 1997; Levy et al. 2011; Houser et al. 2014). In a typical experiment these messages are sent by a leader, who is also a participant in the game; strategies (such as contribution levels) are chosen both by the followers and the leader herself after the signals are sent. A second characteristic is the type of collective action in question. Most papers focus on leadership in linear public goods games, most using the voluntary contribution mechanism, in which free-riding is the dominant strategy (e.g., Guth et al. 2007). A number of papers, however, address leadership in coordination games (e.g., Brandts et al. 2007). Several have designed games that simultaneously capture both the free-riding problem and coordination failures (e.g., Komai and Stegeman 2010; Komai et al. 2011). Third is the way in which leaders are selected. In most research in experimental economics, leaders are randomly-selected players who occupy the leadership position. However, selecting the leader, whether by a transparent procedure (Kumru and Vesterlund 2010; Eckel et al. 2010), by volunteering (Arbak and Villeval 2013; Rivas and Sutter 2011), or by election (Brandts et al. 2014; Grossman and Baldassarri 2012; Jack and Recalde 2015) substantially improves the leader’s effectiveness. In our study, leaders are selected according to their score on a 10 question trivia quiz, thus enhancing the legitimacy, and perhaps effectiveness, of the leader.Footnote 2
 A fourth characteristic is the information structure in which the leader operates. The leader may have no informational advantage, in which case he serves primarily as a role model or coordination device (as in Moxnes and van der Heijden 2003); or he may have access to information that the followers do not (as in Potters et al. 2005, 2007; see Footnote 1 for additional studies). Our study focuses on the first condition, and does not consider the very important issue of informational advantage. In this paper, we compare, under complete information, the effectiveness of two leadership institutions in two different collective action settings: a linear public good game (Isaac and Walker 1988) in which the dominant strategy of a selfish player is to free ride on others by contributing zero, and a weakest link coordination game (Van Huyck et al. 1990), in which the optimal strategy of any player depends on the actions of others. The games are repeated for 20 periods in stable groups. We consider an “Exemplar” leadership institution in which a first mover makes a commitment in the form of an actual contribution: This institution is known as “leading by example”. A second institution introduces a “Manager” in which a first mover makes cheap talk suggestions to the team members before contributions are selected: This institution could be termed, “leading by suggestion”. The two games are parallel. Free riding in the linear public good game and coordination failures in the weakest link public good game limit efficiency. Ours is the first paper (to our knowledge) that brings together two different leadership styles in directly comparable linear public goods and weakest link games. Results in the weakest link game reveal strong coordination failure in the absence of leadership. Both leadership institutions significantly reduce coordination failure. Leading by suggestion seems more effective than leading by example in the first period but it loses its advantage over time. Results in the linear public good game also show strong evidence of free riding in the absence of leadership. The free riding problem in the linear public good game, however, does not seem as severe as the coordination failures in the weakest link game; in the sense that in the absence of a leader total contributions in the weakest link game are much smaller than those in the linear public good game. According to our results neither of the leadership institutions seem effective in the linear public good game. Subjects who choose to free ride continue to do so with or without leaders and subjects who choose to be cooperative do not get discouraged by others’ lack of cooperation. Section 2 explains our public good games. Section 3 presents our experimental procedure. Sections 4 and 5 present our results. Section 6 concludes the paper and discusses the replication of previous studies.",34
1.0,1.0,Journal of the Economic Science Association,07 May 2015,https://link.springer.com/article/10.1007/s40881-015-0004-4,Subject pool recruitment procedures: organizing experiments with ORSEE,July 2015,Ben Greiner,,,Male,Unknown,Unknown,Male,"The subject pool is the most precious resource of the experimental economist. It is the source of our data and insights, and a necessary condition for our academic work. Dealing with it mindfully and cautiously is not only a requirement of human subject research ethics, but also a precondition of valid data and valid conclusions from an experimental study. There are several reasons why we should care about recruitment procedures (and this list is not exhaustive): To minimize unobserved or unwanted selection effects, and to fully control for selection criteria imposed for the purpose of the research project (for example, based on subject demographics or participation in previous studies); To prevent multiple participations of the same person in an experiment since this may invalidate the data and conclusions; To minimize the direct costs of both recruitment and maintaining a subject pool; and To ensure that we obtain exactly the right number of participants, not too many (which is costly in terms of turn-away fees) and not too few (which is even more costly due to a potentially insufficient number of observations, or required minimum group sizes). In the early days of experimental economics, before the rise of the Internet and database-backed web applications, a wide range of procedures were used to recruit participants for economic experiments. This included having troops of research assistants approaching people individually, and distributing hundreds of leaflets and signup lists across campus. Since the days of e-mail technology, long (and often inaccurate) e-mail lists have been maintained. Participation would be tracked using Excel lists to prevent multiple participations, but with less than perfect results. The Online Recruitment Software for Economic Experiments (ORSEE) was introduced in 2003, one of the first of its kind.Footnote 1 ORSEE is a software tool that allows researchers to schedule experiment sessions and recruit participants. It tracks experiment participation and provides information about the subject pool and recruitment procedures of a study. This software aims to simplify the organization of economic laboratory experiments and to reduce its cost, to allow for the standardization of the procedures of experiment organization, to depersonalize the experimenter–subject interaction, and to provide information and statistics about the subject pool and recruitment procedures. In terms of the critical aspects of recruitment, using ORSEE immediately reduces the costs of subject recruitment (point 3 above) by saving valuable research assistant time, and makes recruitment more efficient. The database-backed system is also able to effectively prevent multiple participations in the same experiment (point 2), conditional on that each subject holds only one account in the system. (This can be enforced, for example, by requiring subjects to use their student ID or university e-mail address when registering for the subject pool.) A set of strict laboratory rules combined with a reputation system that tracks no-shows can effectively reduce the variability in the number of participants who show up for sessions (point 4). The trickiest issue is selection (point 1). In the context of ORSEE, the selection can take place at two different stages: (1) during registration for the subject pool database, and (2) during the enrolment for sessions of a particular experiment. The means of a recruitment software to address the first stage of selection into the recruitment database are limited. Such selection will largely depend on the laboratory’s efforts to attract students and other populations to create profiles in the system.Footnote 2 However, at the second level of selection into experiments, ORSEE can help to reduce selection biases in various ways. Both stages of selection are likely affected by similar factors. While there is a large and growing literature on whether student samples are representative of broader populations, there is surprisingly little research on non-random selection of students into participation in laboratory experiments. Cleave et al. (2013) studied the total selection effect over both stages by first running trust games and lottery choices with the total number of students in an introductory microeconomics course, and then examined whether the 12 % of the initial population who later enrolled in the database and signed up for an experiment differed from the original population. They found no difference in risk or social preferences among those who signed up compared to the population. Similarly, Falk et al. (2013) examined whether students who donated to a charity were more likely to participate in laboratory experiments than students who did not, but also found no effect. Harrison et al. (2009) and Slonim et al. (2013) directly recruited for experiment sessions. Harrison et al. (2009) varied the spread of earnings advertised in the recruitment e-mail sent to potential subjects, and found that participants who signed up in response to a recruitment e-mail advertising a lower variance were less willing to take risks in the laboratory experiment. Slonim et al. (2013) obtained demographics and choices in a variety of games from a full sample of an undergraduate microeconomics class. The students were then invited to take part in economic experiments. The authors found strong demographic effects of selection into experiments: those with less income, more leisure time, more interest in economics, and who were more pro-social were more likely to participate in laboratory experiments.Footnote 3 Based on the literature and their own results, Slonim et al. (2013) made recommendations to reduce selection biases in experiments: high rewards or even compulsory course credits, short laboratory sessions, convenient laboratory locations, and providing as little information as possible about experiments when recruiting. They also discussed possible econometric ways to compensate or correct for selection effects. ORSEE addresses selection to experiments in the following ways: Extensive participant statistics which can be aggregated at various levels of the subject pool allow the researcher to get an in-depth picture of the subject pool she is going to recruit from. The use of an impersonal software for recruitment, generic e-mail templates, an institutional laboratory e-mail address, a public generic name for experiments etc. all aim to reduce experimenter-subject interaction in the recruitment and prevent biases due to too much information in the recruitment process. A sophisticated query tool that allows researchers to counterbalance an existing non-representativeness of the subject pool compared to the university population, as well as demographics-based enrollment biases. The ORSEE recruitment report facilitates ex-post assessment of the extent of selection bias through detailed comparative subject pool statistics at three levels: the complete subject pool, the pool of eligible subjects, and the subset of subjects who eventually enrolled and participated in the study. These data may be of use to control for biases econometrically (Slonim et al. 2013). Using ORSEE provides another advantage in the evaluation process of experimental research: since it standardizes recruitment procedures to a certain extent, there is additional value (other than complying with ORSEE’s license) to mention the use of this software in the recruitment of experiment subjects, as researchers/reviewers familiar with ORSEE will know immediately how subject recruitment was organized. The wealth of information collected in the system and provided by the ORSEE recruitment report also facilitates the replication of experimental studies down to the details of the recruitment procedures. Researchers wishing to replicate a previous study can use the same selection conditions, the same messages, and follow the exact same timing as in the original study, provided both laboratories use ORSEE for recruitment. That said, one guiding principle in the design of ORSEE is to make it as flexible as possible, and accommodate as many research procedures as possible under the general architecture. In the end, the researcher and the laboratory as an institution will be responsible for proper recruitment procedures and efforts to reduce selection biases. ORSEE provides many tools and features, but the maintenance of an active subject pool, the communication with subjects, and the establishment of rules and procedures are all in the hands of the researchers. The remainder of this paper is devoted to a description of the general features of the software, a list of configuration options demonstrating the software’s flexibility, as well as some technical details and license information. A * will indicate features that are introduced or enhanced in Version 3.0 of the software.",1505
1.0,2.0,Journal of the Economic Science Association,07 December 2015,https://link.springer.com/article/10.1007/s40881-015-0018-y,"Editors’ preface: statistics, replications and null results",December 2015,Nikos Nikiforakis,Robert Slonim,,Male,Male,Unknown,Male,This issue marks the first anniversary of the Journal of the Economic Science Association (JESA). It is therefore an appropriate time to share some summary statistics and information about replication studies and submissions with null results.,8
1.0,2.0,Journal of the Economic Science Association,25 April 2015,https://link.springer.com/article/10.1007/s40881-015-0009-z,Hotelling revisits the lab: equilibration in continuous and discrete time,December 2015,Curtis Kephart,Daniel Friedman,,Male,Male,Unknown,Male,"In his seminal model of spatial competition, Hotelling (1929) analyzed the behavior of two sellers of a homogenous product choosing price and location in a bounded, one-dimensional marketplace. The model has since been expanded to allow numerous sellers to interact strategically in more general marketplaces. As the preeminent model of spatial competition, it has been widely applied, e.g., in industrial organization to analyze geographic competition and product differentiation (Netz and Taylor 2002), and in
 political economy as a tool to analyze voting dynamics (Downs 1957). Here we investigate the dynamic foundations of this static model. How does the ability to quickly adjust product characteristics, and quickly respond to competitors’ repositioning, affect firm behavior? The question is theoretical but quite relevant to 21st century applications as firms adopt new technology and new management practices that encourage them to compete on agility and positioning. Product cycles (and rebranding) seem to be accelerating in consumer electronics and lifestyle goods, while in other industries like enterprise software—for example in web-base applications like those for analytics and customer relationship management—permit their makers to continually tweak their product and respond to competitor repositioning. Outside of voter analysis, empirical tests of the Hotelling model have been sparse. For differentiated products, for example, there is often no consensus on how best to define the attribute space, and most firms have been understandably reluctant to allow access to their data. Experimental methods offer an empirical approach that avoids these problems, but the results so far have been mixed at best. Brown-Kruse et al. (1993) and Brown Kruse and Schenk (2000) investigate a duopoly model with varying customer densities over a finite one-dimensional action space. Collins and Sherstyuk (2000) look into a three-agent model with inelastic demand and uniform prices. There exists no pure-strategy equilibrium in this set-up (Eaton and Lipsey 1975). Shaked (1982) finds a unique mixed strategy equilibrium in which players randomize uniformly over the second and third quartiles. Collins and Sherstyuk (2000) find little support for Shaked’s equilibrium hypothesis. In work most closely related to this paper, Huck et al. (2002) investigate the four-player implementation of the location-only model. Eaton and Lipsey show that all Nash equilibria are in pure strategies with two players located back-to-back at the first quartile, and the remaining two players similarly located at the third quartile. Like Collins and Sherstyuk, Huck et al. find that the empirical distribution of locations is quite different than this NE distribution—subjects exhibit a “W-shaped” distribution of locations, with significant clustering near the second quartile (the median) as well as near the first and third quartile. Using novel software for conducting economic experiments, we investigate the four-player location-only model, uniform customer density, inelastic demand and a bounded, finite action space. We compare a discrete time treatment with two continuous time treatments in which subjects are able to adjust their locations either with (or else without) a speed limit. We replicate earlier results that human subjects generally fail to converge to the distinctive equilibrium in discrete time, but establish for the first time that they do converge reliably to the equilibrium in both continuous time treatments.",14
1.0,2.0,Journal of the Economic Science Association,19 May 2015,https://link.springer.com/article/10.1007/s40881-015-0003-5,Naive play and the process of choice in guessing games,December 2015,Marina Agranov,Andrew Caplin,Chloe Tergiman,Female,Male,Female,Mix,,
1.0,2.0,Journal of the Economic Science Association,28 October 2015,https://link.springer.com/article/10.1007/s40881-015-0016-0,How to measure time preferences in children: a comparison of two methods,December 2015,Silvia Angerer,Philipp Lergetporer,Matthias Sutter,Female,Male,Male,Mix,,
1.0,2.0,Journal of the Economic Science Association,02 September 2015,https://link.springer.com/article/10.1007/s40881-015-0013-3,Learning through passive participation in asset market bubbles,December 2015,Timothy N. Cason,Anya Samek,,Male,Female,Unknown,Mix,,
1.0,2.0,Journal of the Economic Science Association,30 November 2015,https://link.springer.com/article/10.1007/s40881-015-0014-2,The veil of experimental currency units in second price auctions,December 2015,Andreas C. Drichoutis,Jayson L. Lusk,Rodolfo M. Nayga Jr.,Male,Male,Male,Male,"Denominating subjects’ payoffs using an experimental currency unit (ECU), which are later converted into cash, is a practice often employed in experimental economics.Footnote 1 Yet, there appears to be scant research focusing on the implications of using ECUs rather than cash in lab experiments. Davis and Holt (1993, pp. 25–26) were perhaps the first to outline some hypotheses about the use of ECUs in their now classic “Experimental Economics” book. Surprisingly, they advise against using ECUs in experiments, unless “the researcher has a specific design motivation for using a laboratory currency”. They reason that ECUs may “mask or even dilute financial incentives” and create an artificial “game-board sense” promoting “speculative competitiveness”. This paper explores the use of ECUs as a design choice. Although the types of experiments in the literature that use ECUs are widely varied, we chose to further explore this issue using a private, induced value 2nd price auction. Theory has a clear prediction about behavior in the second price auction (i.e., theory predicts that subjects will bid their induced value). However, there is an active debate about whether the theory holds in practice [see for example the contrasting evidence in Kagel et al. (1987), Harstad (2000), Parkhurst et al. (2004), Lusk and Shogren (2007)]. The fact that the debate is still active suggests that at the very least, there are a variety of factors or incentives that might explain when and why the theory accurately predicts behavior. Most relevant to our work is the possible money illusion effect from the use of ECUs as suggested by Davis and Holt (1993). There is a growing literature which finds evidence of money illusion, which can be broadly defined as subjects responding differently to conditions framed in nominal vs. real terms.Footnote 2 A money illusion effect might be desirable because it can increase incentives (and reduce experiment costs) if the subject puts effort into the tasks proportional to the nominal value of the currency. For example, increasing the nominal value of the reward may increase the perceived opportunity cost of “misbehavior” (Harrison 1989, 1992). In this respect, Lusk et al. (2007) have shown that incentives for bidding the weakly dominant strategy in several auction mechanisms depend on the expected cost of misbehaving (expected forgone payoff), which tends to be steeper for higher (nominal) values. We conduct an experiment where we vary the experimental currency-Euro exchange rate and the use/non use of ECUs. Our benchmark is a treatment where no ECUs are used (i.e., subjects bid in the euro currency). In the other treatments, the exchange rate varies by treatment as follows: (i) 0.25 ECUs for 1 €, (ii) 1 ECU for 1 €, (iii) 10 ECUs for 1 € and (iv) 25 ECUs for 1 €. The distribution of actual stakes in Euros, is the same across all treatments and only the framing of the stakes in ECUs changes across treatments. In what follows, we briefly discuss the relevant literature, then describe our experimental design, and present some descriptive analysis and econometric results. We conclude in the last section.",17
1.0,2.0,Journal of the Economic Science Association,19 November 2015,https://link.springer.com/article/10.1007/s40881-015-0017-z,Peer punishment across payoff equivalent public good and common pool resource experiments,December 2015,David C. Kingsley,,,Male,Unknown,Unknown,Male,"Much of the research suggesting that groups can self-govern comes from linear, boundary solution, public good experiments (Chaudhuri 2011). Such experiments are useful because they are easily explained to subjects and provide the starkest possible equilibrium predictions. That is, the incentives are all or nothing; self-interest suggests complete free-riding while efficiency requires contributing one’s entire endowment. However, social dilemmas observed in the real world are rarely as stark as those presented in linear public good experiments. It is thus important to understand whether peer to peer punishment is as effective in non-linear, i.e. more complex, environments. 
Cason and Gangadharan (2015) investigated the effectiveness of peer to peer punishment in non-linear public good (PG) and common pool resource (CPR) experiments. In both treatments, the opportunity to punish increased cooperation. However, the positive impact was too weak to increase welfare (group earnings). Cason and Gangadharan suggest that the non-linear environment limits the effectiveness of peer punishment because the social optimum is harder to identify and, therefore, to coalesce around. These results suggest that cooperative behavior is qualitatively similar across public good and common pool resource experiments. However, the treatments investigated by Cason and Gangadharan are not payoff equivalent and thus it is difficult to compare behavior across treatments. This paper replicates the findings of Cason and Gangadharan (2015) across payoff equivalent, strategically symmetric, PG and CPR experiments. The contribution of this replication is that the level of cooperation can be quantified and directly compared across conditions. Results suggest that peer punishment induces the equivalent amount of cooperation in both treatments. Despite the increased cooperation, punishment alone does not improve welfare. However, the equivalence of the cooperation-inducing effect across treatments suggests that the same procedures that increase the effectiveness of peer punishment in linear PG experiments may have a similar impact within more complicated social dilemmas. This suggests that self-governance in complex social dilemmas is possible.",9
2.0,1.0,Journal of the Economic Science Association,14 May 2016,https://link.springer.com/article/10.1007/s40881-016-0025-7,The slider task: an example of restricted inference on incentive effects,May 2016,Felipe A. Araujo,Erin Carbone,Alistair J. Wilson,Male,,Male,Mix,,
2.0,1.0,Journal of the Economic Science Association,15 February 2016,https://link.springer.com/article/10.1007/s40881-015-0019-x,From imitation to collusion: a replication,May 2016,Jörg Oechssler,Alex Roomets,Stefan Roth,Male,Male,Male,Male,"Imitation, in some strategic settings, has been shown to have negative side effects for the players involved. Specifically, in oligopoly, imitating the most successful competitor yields very competitive outcomes and correspondingly low profits. This has been predicted theoretically by Vega-Redondo (1997) and confirmed experimentally by a number of studies (Huck et al. 1999; Offerman et al. 2002; Apesteguia et al. 2007, 2010; Bigoni and Fort 2013). A recent paper by Friedman et al. (2015) qualifies those results in an interesting way: While they replicate the very competitive results for the first 25–50 periods, they show that when using a much longer time horizon of 1200 periods, results slowly turn to more and more collusive outcomes. 
Friedman et al. (2015) show this result for long-horizon duopolies and triopolies. Huck et al. (2004a) review results from a large number of short-horizon experiments and conclude that 4 firms are usually sufficient to prevent tacit collusion. An interesting question, then, is whether collusive outcomes come about in long-horizon markets with more than 3 firms. Furthermore, given the novelty of the long-horizon result, it is important to test its robustness. This paper seeks to address these issues by looking at long-horizon markets with 2 and 4 firms, using linear demand curves. We succeed in replicating Friedman et al. (2015) result that duopolies eventually became fairly collusive. However, while we also replicate a downward trend in quantities for 4 firms, none of our 4 firm oligopolies becomes permanently collusive. The average quantity always stays above the Cournot–Nash equilibrium quantity. Thus, it seems that “four remain many,” even with 1200 periods, in the sense that collusion is very difficult to achieve.",14
2.0,1.0,Journal of the Economic Science Association,20 November 2015,https://link.springer.com/article/10.1007/s40881-015-0015-1,Delegated bargaining in a competitive agent market: an experimental study,May 2016,Amy K. Choy,John R. Hamman,Roberto A. Weber,Female,Male,Male,Mix,,
2.0,1.0,Journal of the Economic Science Association,19 December 2015,https://link.springer.com/article/10.1007/s40881-015-0020-4,Time for helping,May 2016,Anastasia Danilov,Timo Vogelsang,,Female,Male,Unknown,Mix,,
2.0,1.0,Journal of the Economic Science Association,11 January 2016,https://link.springer.com/article/10.1007/s40881-015-0021-3,Eliciting and measuring betrayal aversion using the BDM mechanism,May 2016,Simone Quercia,,,Female,Unknown,Unknown,Female,"Recent experimental evidence shows that people demand a higher risk premium when the source of risk is another person rather than nature (see Bohnet and Zeckhauser 2004; Bohnet et al. 2008). Moreover, they prefer to opt out from a trust game and let their earnings be determined by a payoff—equivalent lottery to avoid learning whether their co-player betrayed them (Aimone and Houser 2011, 2012, 2013). This evidence reveals that people anticipate the psychological cost of betrayal that they suffer on top of monetary costs. This phenomenon, commonly referred to as betrayal aversion, has been first investigated by Bohnet and Zeckhauser (2004) (BZ, henceforth) using an adaptation of the Becker–DeGroot–Marschak mechanism (BDM, see Becker et al. 1964). Their design compares so-called minimum acceptance probabilities (MAPs) between a social risk and a natural risk situation. A MAP is defined as the minimum probability of the good outcome that subjects require to choose a risky bet rather than a certain payoff. The finding that MAPs are on average higher in the social risk compared to the natural risk setting has been interpreted as evidence that subjects are betrayal averse. In this paper, we ask whether different implementations of the BDM mechanism affect the elicitation of values and the measurement betrayal aversion in the BZ design. Our question is particularly important for two main reasons. First, recent evidence shows that the BDM mechanism may be empirically not reliable due to its complexity and to subjects’ misconceptions of the incentive structure (see, e.g., Cason and Plott 2014). Second, the MAP design uses the BDM mechanism in an unusual way compared to the previous literature as it elicits a probability instead of a price. In most applications, the BDM mechanism is used in selling or buying tasks and subjects are asked the minimum price demanded to give up an object or the maximum price they would be willing to pay to buy the object. The MAP design, instead, asks subjects to reveal the minimum value of a probability that they would require to play a lottery. Arguably this may further increase the complexity of the mechanism.Footnote 1
 In our experiment we simplify the original BZ instructions and procedures to minimize the risk of misconceptions and ask whether this has an impact on the elicitation of betrayal aversion. Study 1, reported in Sect. 2, consists of two experimental conditions: the open-ended (OE) condition replicates the design and procedures of BZ, whereas the choice list (CL) condition introduces a novel instrument and procedures intended to facilitate subjects’ comprehension. Our results from Study 1 show that the way the BDM mechanism is presented to subjects has a significant impact on elicited values. The two elicitation methods generate statistically different distributions of data, with the CL distribution of MAPs being more peaked and presenting less variation. However, when we compare the estimated size of betrayal aversion (the average difference of MAPs in the social versus the natural risk situation), we find no differences between OE and CL. We ask next which method is preferable to use in terms of truthful revelation. To answer this question, in Study 2, we conduct a survey with a sample of undergraduate students, where we compare the experimental instructions of OE and CL used in Study 1 on the basis of perceived complexity and number of mistakes made in a set of comprehension questions. We show that our CL instructions are better understood than the OE instructions in terms of both perceived complexity and number of mistakes in the comprehension questions. We discuss the implication of these findings in our concluding section.",10
2.0,1.0,Journal of the Economic Science Association,01 February 2016,https://link.springer.com/article/10.1007/s40881-016-0023-9,The price of luck: paying for the hot hand of others,May 2016,Silvia Bou,Jordi Brandts,Pablo Guillén,Female,Male,Male,Mix,,
2.0,1.0,Journal of the Economic Science Association,09 April 2016,https://link.springer.com/article/10.1007/s40881-016-0024-8,A comment on framing effects in linear public good games,May 2016,Edward Cartwright,,,Male,Unknown,Unknown,Male,"There is extensive evidence of framing effects in linear public good games (e.g. Andreoni 1995; Cookson 2000; Park 2000; Dufwenberg et al. 2011; Khadjavi and Lange 2015; Cox 2015). In short, it appears that payoff irrelevant differences in the way a public good game is presented to experimental subjects can systematically influence the amount contributed towards the public good. This is a fascinating finding that, amongst other things, provides a valuable way to discern the reasons why people contribute (or do not) towards public goods (see e.g. Ellingsen et al. 2012; Fosgaard et al. 2014, 2015; Gächter et al. 2014). To draw correct inferences about framing effects it is, however, clearly crucial to carefully distinguish between the different frames considered. This paper is motivated by a concern that this is not being done. I particularly want to emphasize the difference between a positive–negative framing effect and give-take framing effect. Positive–negative framing (more details will follow) reflects whether the positive externality of contributing to the public good or the negative externality of not contributing are emphasized. Andreoni (1995), along with the follow up studies of Park (2000) and Fujimoto and Park (2010), study a positive–negative framing effect. Give-take framing, by contrast, reflects the choice a person has to make (and their initial allocation). Specifically, whether they are asked to contribute to a public good or take from a public resource. Most recent studies, e.g. Cubitt et al. (2011a), Dufwenberg et al. (2011), Fosgaard et al. (2014), Khadjavi and Lange (2015) and Cox (2015), focus on a give-take framing effect. We shall see that it is possible to have a positive-give, negative-give, positive-take and negative-take frame. The positive–negative framing effect should, therefore, be seen as distinct from the give-take framing effect. This distinction has, though, become blurred within the literature. Indeed, anyone reading the recent literature would surely come away with the impression that Andreoni (1995) considered a give-take framing effect.Footnote 1 He did not. Interestingly, Andreoni (1995, p. 12) anticipated such confusion: ‘other psychological experiments that I am aware of are not strictly comparable to the one reported here. One reason is that they did not present neutral environments. In particular, these experiments instructed subjects to “give some” in positive frames and to “take some” in negative frames, which could influence outcomes’. Somewhere along the line the true insight of Andreoni (1995) seems to have been lost. But, this is about more than historical accuracy. Picking apart the distinction between the positive–negative and give-take framing effects seems necessary to appropriately interpret the findings of recent experimental studies. We shall see that there is clear and unambiguous evidence of a positive–negative framing effect (e.g. Andreoni 1995; Park 2000). At face value, the evidence for a give-take framing effect appears far more mixed, with some studies showing contributions are higher in the give frame and some in the take frame (Gächter et al. 2014; Cox and Stoddard 2015). I want to argue here that these mixed results stem from a failure to control for the positive–negative effect. In particular we need to question whether studies are comparing a positive-give frame with a negative-take frame (where the positive–negative effect will be present) or with a positive-take frame (where it will not). Once we do this the evidence for give-take framing becomes more consistent. Indeed, we shall see that there is little evidence of a give-take framing effect on contributions in linear public good games. Note, however, that there is evidence of a give-take framing effect on beliefs and cooperation attitudes. To make these points clear I will distinguish three dimensions along which the frames used in linear public good game experiments differ. These will be called the (1) externality, (2) choice, and (3) initial allocation dimensions. The easiest way to illustrate the relevant distinctions is through examples, and so that is the approach I will take. I begin, in Sect. 2, by reviewing the positive–negative externality distinction made by Andreoni (1995). With this done we can then, in Sect. 3, better understand the give-take choice distinction commonly studied in the literature. Given that I am being critical of the language used in some of the literature, let me emphasize that my objective here is not to question in any way the importance of this work. Indeed, it is the very importance of the experiments that motivates the need for a careful distinction between framing effects. My goal, therefore, is one of constructive criticism. I return to this point in Sect. 4 with a concluding discussion.",24
2.0,1.0,Journal of the Economic Science Association,30 January 2016,https://link.springer.com/article/10.1007/s40881-016-0022-x,Symmetric experimental designs: conditions for equivalence of panel data estimators,May 2016,Ronald L. Oaxaca,David L. Dickinson,,Male,Male,Unknown,Male,"In both
 experimental and non-experimental settings the advantages of panel data methods are widely recognized. Because of repeated observations in experiments, experimental data often constitute a panel. The presence
 of subject heterogeneity can lead to inefficient estimation by ordinary least squares (OLS).Footnote 1 Under these circumstances either fixed effects (FE) or random effects (RE) would be the estimator of choice. In this paper we demonstrate, both formally and with an empirical example from the literature, that for a panel data set generated by a symmetric design in which every subject faces every treatment exactly the same number of times, OLS, FE, and RE estimators yield identical treatment effect estimates: Result 1. Although the true standard errors would be identical for all three panel data estimators, it is shown below that the estimated standard errors for the treatment effects are identical between FE and RE but differ from those under OLS: Result 2. Typically, the 
experimentalist would want to use the FE estimated standard errors for statistical inference: Result 3. In this paper we show how a common experimental design exactly conforms to the conceptual framework of Mundlak (1968). The importance of our results for researchers, especially experimental economists, is threefold. We show why the choice between the FE and the RE estimators is moot in important applied contexts, because these are one and the same estimator. Moreover, the estimated average treatment effects for FE and RE are identical to those obtained from (pooled) OLS. Lastly, we show that the only remaining choice is to decide whether to use the OLS standard errors or the FE/RE standard errors in finite samples. A standard F test as well as asymptotic reasoning guide the choice of which estimated standard errors are the appropriate ones to use for statistical inference.",3
2.0,2.0,Journal of the Economic Science Association,18 November 2016,https://link.springer.com/article/10.1007/s40881-016-0031-9,Editors’ preface: reviewing statistics and first evidence of impact,November 2016,Nikos Nikiforakis,Robert Slonim,,Male,Male,Unknown,Male,This issue marks 2 years since the Journal of the Economic Science Association (JESA) opened for submissions. We take this opportunity to share some summary statistics related to the reviewing process and some first evidence on the journal’s impact. The latter indicates that JESA is off to a very promising start.,
2.0,2.0,Journal of the Economic Science Association,12 November 2016,https://link.springer.com/article/10.1007/s40881-016-0027-5,Vickrey auction vs BDM: difference in bidding behaviour and the impact of other-regarding motives,November 2016,Niall Flynn,Christopher Kah,Rudolf Kerschbamer,Male,Male,Male,Male,"Deviations of bids from true valuations in second-price private-value or ‘Vickrey’ auctions (VA; Vickrey 1961) have been a recurrent theme, see Kagel et al. (1987) or Kagel and Levin (1993). The more recent literature has attributed this finding, at least partially, to spite. Andreoni et al. (2007) find that bids increase in rivals’ (known) valuations, which is consistent with the spite explanation. With unknown valuations but costly signals about the latter, Cooper and Fang (2008) also report evidence consistent with the spite hypothesis. If spite, or any form of distributional preferences, is causal for non-sincere bidding in the VA, then deviations of bids from true valuations per construction should be absent in the Becker–DeGroot–Marschak mechanism (BDM; Becker et al. 1964)—which, under the standard assumptions, is strategically equivalent to the VA. Intuitively, in the BDM, the decision is made in isolation and the outcome has only consequences for the decision maker, whereas in the VA, the outcome is also affected by the behaviour of a rivalling bidder, and by changing the own bid, a subject influences the monetary outcome for both parties involved. To test the impact of distributional preferences on bidding behaviour in the lab, we first elicit the distributional preferences of subjects and then let them bid for lottery tickets either in a BDM or in a VA. We then compare the bids across the two mechanisms. We observe underbidding in the aggregate in the VA, but the experimental data do not confirm our predictions at the individual level. Our contribution to the existing literature is twofold. First, by keeping all details except for the treatment variation constant across treatments, our experimental design allows for a neat comparison of BDM and VA bids at the aggregate level; and second, by classifying subjects into distributional preference types and comparing their bidding behaviour across mechanisms, our design allows for a clean test of the hypotheses that distributional preferences are causal for a potential treatment difference.Footnote 1 Keeping the number of bidders constant across the two mechanisms seems indispensable, as the probability that a bidder becomes pivotal decreases in the number of rivals and because with a higher probability of pivotality, we expect bidders to perform higher cognitive effort, as their actions are more likely to influence the final monetary payoff distribution.Footnote 2 Keeping instructions comparable across treatments also seems important, because framing effects are known to potentially influence the behaviour in the lab (see Levin et al. 1998).",6
2.0,2.0,Journal of the Economic Science Association,14 September 2016,https://link.springer.com/article/10.1007/s40881-016-0026-6,Response time and click position: cheap indicators of preferences,November 2016,Fadong Chen,Urs Fischbacher,,Unknown,Male,Unknown,Male,"There is an increasing interest in using process data to get a better understanding of economic decision making. Different methods such as response times (Rubinstein 2007), pupil dilations (Wang et al. 2010), eye movements (Reutskaja et al. 2011) and even neural activity (Smith et al. 2014) have been introduced and have shown significant correspondences between this kind of data and people’s decisions. These methods vary significantly in their complexity and some of them are quite costly. We show that simple by-product data in lab or online economic experiments, such as response times and click positions, can provide information about people’s preferences. With a proper design, this data can be collected at almost no cost. While response time analysis has been used frequently (for a review, see Spiliopoulos and Ortmann 2015), click positions have received attention mainly in computer science. There, click positions are analyzed routinely, in particular for the optimization of web pages (Guo et al. 2009; Liu et al. 2010). However, these studies use the click position only to determine the choice. We study what attributes of a choice subjects click on and show that the personally attractive attributes of a choice have a higher probability to be clicked. Specifically, we use a social value orientation (SVO) experiment in which the response times and the click positions are recorded. The SVO task consists of several decision situations, each consisting of a menu of allocations between the deciding subject and an anonymous partner. Thus, the SVO measures how much people care about their own as compared to the other player’s welfare. The SVO task represents a prototypical situation in which people have to assess and trade off different attributes of an option—in the case of the SVO their own vs the other’s payoff. Our results show that more prosocial subjects take longer to make their decisions in the SVO task. Concerning the click position, we find that individualistic subjects click more often on their own payoffs than on the others’ payoffs, and they click more often on their own payoffs than prosocial subjects. Moreover, the response time information and the click position information are complementary in explaining subjects’ SVO. Thus, response time and click position can be used as indicators of people’s preferences. Response time has increasingly been used in economic experiments (Hutcherson et al. 2015; Krajbich et al. 2010, 2014), in particular as an indicator of whether a decision is made intuitively or deliberatively (Achtziger and Alós-Ferrer 2014; Krajbich et al. 2015; Piovesan and Wengström 2009; Rand et al. 2012; Schulz et al. 2014). Most closely related to our study is Fiedler et al. (2013), who use eye-tracking technology to investigate the underlying processes of social decision making. They find that differences in SVO are accompanied by consistent differences in information search and response times. In another study by Liebrand and McClintock (1988) they find that the processing times vary systematically between different types of subjects. Specifically, cooperators and competitors are slower than altruists and individualists. There is a tradition of using the mouse to track the information search process or information processing. The most prominent example is probably MouseLab (Brocas et al. 2014; Payne et al. 1993).Footnote 1 In this environment, subjects access the information hidden behind boxes on the computer screen by moving the cursor over the boxes. Another method that uses the natural interaction is “response dynamics” (Kieslich and Hilbig 2014; Koop and Johnson 2011; Spivey et al. 2005). In this paradigm, the mouse response is tracked as subjects move from a central location to one of two disparately spaced options. The curvature of the mouse movement is taken as an indicator of cognitive conflicts and more curved response trajectories indicate stronger conflicts. We confirm previous evidence that the response time correlates with subjects’ preferences and find that the click position also correlates with subjects’ preferences. The click position provides much less detailed information than MouseLab since it does not record the information search process, but it has the advantage that it records natural behavior while in MouseLab people need to move the mouse explicitly to acquire information. In this sense, the analysis of the click position is similar to the response dynamics paradigm, which also uses the computer interaction as an additional source of information. Our study highlights the potential benefits of recording response times and click positions in economic experiments involving multiple attribute decision making and using this data to infer people’s preferences.",18
2.0,2.0,Journal of the Economic Science Association,08 November 2016,https://link.springer.com/article/10.1007/s40881-016-0030-x,Leveraging social relationships and transparency in the insider game,November 2016,Gary Bolton,Axel Ockenfels,Peter Werner,Male,Male,Male,Male,"This paper investigates the effect of pay transparency in a novel three-person insider game in which reciprocity leads to negative externalities. Two players (the “insiders”) mutually decide on the payments of their counterparts, whereas the third player (the “outsider”) acts as the residual claimant of profits. Hence, social relationships between insiders may be leveraged to enhance their well-being, but only at a cost to the outsider. We examine how the transparency of payments and competition for interaction partners affect rent extraction. First, we find that pay transparency increases rent extraction, because information about payments to other parties enables insiders to coordinate on a jointly accepted payment level as the basis for stable reciprocal relationships. Second, we observe that introducing competition for transaction partners does not diminish rent extraction. Importantly, insiders who are given the possibility of ending the relationship reciprocate higher payments and rarely change transaction partners once a reciprocal relationship is established. Reciprocity is an important prerequisite for the establishment of interactions that benefit some agents, but only at the costs of others, such as the case of corruption (Lambsdorff 2012): Once a corrupt act is initiated by one party, for instance, by providing a payment, a favorable response cannot be enforced, and the initiator has to rely on the other party’s willingness to reward the friendly action. Therefore, such interactions are often restricted to a network of insiders in which stable relationships can be formed (Lambsdorff 2007). Such relationships can be established in governmental institutions through “the misuse of public office for private gain”, including, for example, “the sale of government property by government officials, kickbacks in public procurement, bribery and embezzlement of government funds” (Svensson 2005, p. 20). In the private realm, such interactions may involve cases, where managers or workers in companies act in opposition to their duties to benefit themselves or others (Argandoña 2003). For instance, social relations between executives and board members may contribute to inefficiencies, such as higher CEO compensation and lower reactivity of CEO pay to poor company performance (Bertrand and Mullainathan 2001; Hwang and Kim 2009; Fracassi and Tate 2012; Kramarz and Thesmar 2013). Similarly, owners and management of a firm can sometimes reciprocally exchange favors and payments at a cost to consumers (Anton et al. 2016). The goal of our controlled laboratory setting is to isolate mechanisms through which reciprocity might influence the allocation of resources between rent seeking parties and residual claimants, and the role transparency (that is, observability of reciprocal payments) might play in the effectiveness of these mechanisms when explicit sanctions of resource extraction are absent. In this sense, our experimental setting isolates the direct behavioral responses of insiders to transparency irrespective of the threat of material punishment. There can be different roles for transparency in our setting: for one, the observability of actions might induce less resource extraction by the rent seeking parties, for example, due to concerns for social image (Andreoni and Bernheim 2009). At the same time, transparent information about exploitative acts might help to establish a common behavioral norm, leading to even more resource extraction among the observing parties. In this sense, a social norm for resource extraction from the outsiders may emerge endogenously in the course of our game. Concerning the role of competition, there is the argument that the existence of competing (potentially) corrupt transaction partners may lead to a decline in the level of corruption; yet, as we will see, there are various mechanisms at work that mute any competition effect. Our study is related to a burgeoning literature on the downside of reciprocity. In a seminal study in the context of lobbying and bribing, Abbink et al. (2002) find positive reciprocal patterns between subjects in the roles of “bribers” and “officials” that are unaffected if small negative externalities on other subjects are introduced.Footnote 1 Moreover, the results of the experimental corruption game by Azfar and Nelson (2007) indicate the importance of social relations for monitoring: stronger monitoring can be achieved if the person who monitors an “executive” is elected rather than being directly selected by the executive. Malmendier and Schmidt (2016, forthcoming) conduct an experiment in which decision makers have to choose a product on behalf of their clients. Here, small gifts by experimental producers strongly bias choices in favor of this firm; yet, the disclosure of the gift by the producer and the product choice by the decision maker to the client do not affect reciprocity towards the producer.Footnote 2 Ellman and Pezanis-Christou (2010) focus on decision procedures in firms, where production is associated with negative externalities and find that the organization structure (vertical or horizontal) has a significant impact on the harm caused by the firm.Footnote 3 In a recent study, Serra and Salmon (2015) find evidence for an important impact of norms on corrupt behavior. Here, subjects participate in different games that involve rule breaking and subsequent harm to third parties. Among other things, the authors conduct a bribery game that involves mutual cooperation at the expense of an outsider and find that the effect of social observability depends on the cultural background of the decision maker. A different line of experimental studies finds that bilateral reciprocal exchange can be sustained even in the face of competition for partners in a variety of game settings (e.g., Brandts and Charness 2004; Bolton et al. 2008; Brown et al. 2012; Huck et al. 2012). Other studies find that relative wage comparisons may lead to punitive behaviors (e.g., Gächter and Thöni 2010; Greiner et al. 2011; Cohn et al. 2014). Our game differs from these studies in two central respects: in our game, the decision to reciprocate is not efficiency enhancing, and there is a third party potentially harmed by the exchange. Finally, in the study by Ryvkin and Serra (2015), participants in the role of public officials can request bribes and compete for customers who can switch between public officials. Here, the effect of competition depends on the size of the switching costs and the search behavior of customers. Section 2 presents our game, the experimental design, and hypotheses. Our results are described in Sect. 3. Section 4 discusses the findings and concludes.",2
2.0,2.0,Journal of the Economic Science Association,22 October 2016,https://link.springer.com/article/10.1007/s40881-016-0029-3,Minimax across a population of games,November 2016,Ido Erev,Alvin E. Roth,Robert Slonim,Male,Male,Male,Male,"Economic experiments usually evaluate the predictions of a theory on a game or task carefully chosen to be a good test of some aspect of the theory. This strategy permits researchers to conclude that either the theory correctly predicts the particular behavior tested or that the theory is not true in general. If the theory is false, the experimental results often suggest how the theory can be modified and/or how the theory needs to be qualified. However, this strategy does not provide information on whether the qualifications (i.e., the reasons a theory is rejected) are robust to similar, yet not identical conditions. For instance, if the results of a low-stakes experiment using specific parameters of a game reject a theory using a student subject population, the theory can be rejected as a general theory, yet the results do not indicate whether the theory would describe behavior among other populations such as professional traders, under other conditions such as higher stakes, or with different parameters. Researchers have therefore studied the robustness of theories across stakes and subject populations (e.g., Slonim and Roth 1998; Roth et al. 1991). But there has been little research focused on the variation of results over a sample population of games.Footnote 1
 This paper uses a sample of games to examine the accuracy of the minimax hypothesis. A sample of games permits a test of the robustness of the minimax hypothesis—does it fail rarely or often? More importantly, the sample of games permits testing correlations between the magnitude of deviations from theory and the different parameters of the games. These correlations may help explain why past experiments prompt different conclusions regarding the accuracy of a theory, as is the case with the minimax hypothesis. Past experiments testing the precise predictions of the minimax hypothesis find mixed evidence. Some experiments find that the minimax hypothesis has little descriptive accuracy (Suppes and Atkinson 1960; Malcolm and Lieberman 1965; Erev and Roth 1998), while others find more accuracy (O’Neill 1987; Mookherjee and Sopher 1994; Ochs 1995). While the minimax hypothesis makes many specific predictions (regarding, e.g., serial correlation, joint choice distributions), we focus here on deviations in the observed aggregated proportion of play of each strategy across the population and rounds of play. Figure 1 shows the mean square distance between minimax play and subject behavior for the past studies as a function of the mean square distance between minimax play and the equal choice mixture. The figure shows that as minimax play gets further from the equal choice mixture across games, minimax play also gets further from subject behavior. OLS regressions show a significant positive relationship between (1) the mean square distance between minimax play and subject choices and (2) the mean square distance between minimax play and equal choice; OLS regressions indicate a slope of 0.55 (standard error 0.10) and we can reject at the p < 0.01 level that the slope equals 0 or 1.Footnote 2 However, these results were generated from the play of a small number of games with different procedures used by different researchers. The different procedures make it impossible to address whether the differences between observed and predicted behavior generalize beyond the particular games studied, or whether the deviations observed in each experiment are specific to features of the experimental procedures. Given that the existing evidence suggests that the accuracy of the aggregated proportion of play (across time and player pairs) varies with the distance between the equilibrium and equal choice of actions, we will focus on the aggregated proportion of play across players and repetition of play. Although the literature has explored all levels of aggregation (and disaggregation), we focus on the most aggregated level to test the game level effects. Relationship between equal choice, equilibrium and average choices in the past 2 × 2 experiments To make direct comparisons feasible, this paper documents play over a class of constant sum games that are two-person, two-action and have a unique nontrivial mixed strategy equilibrium, and are identical in every respect other than the payoff parameters. Even in this minimalist class of games, choosing the parameters of each game involves trade-offs. One method is to choose parameters so that on a well-defined metric (such as over the payoffs or over the distance from the equilibrium to equal choice), the games are evenly spread out over the entire range. An advantage of this approach is that it could provide the best chance to detect discontinuities in the relationship between the space chosen and behavior if discontinuities exist and enough games are included to detect the discontinuities. A disadvantage of this approach is that the researchers nonetheless choose the specific games and metrics which could in itself bias the games chosen. Alternatively, to avoid potential experimenter bias in choice, we randomly sample from all the possible games rather than choose specific games.Footnote 3 Even in this class of games, we will see that the deviation between minimax play and equal probability play of each action systematically generates enough variation to observe on which games the minimax prediction is more or less accurate. Consistent with the evidence from different experimenters using different procedures and different parameters, we find that behavior is closer to minimax play in games in which the frequency of play predicted by minimax is closer to the equal probability mixture. Indeed, when we use the identical procedures we find a significantly greater relationship than the extant literature finds using different procedures, indicating that the different methods applied by different researchers introduced noise that results in underestimating the strength of an important relationship explaining the accuracy of the minimax hypothesis.",
2.0,2.0,Journal of the Economic Science Association,13 October 2016,https://link.springer.com/article/10.1007/s40881-016-0028-4,Simulating power of economic experiments: the powerBBK package,November 2016,Charles Bellemare,Luc Bissonnette,Sabine Kröger,Male,Male,Female,Mix,,
3.0,1.0,Journal of the Economic Science Association,16 May 2017,https://link.springer.com/article/10.1007/s40881-017-0035-0,Turking overtime: how participant characteristics and behavior vary over time and day on Amazon Mechanical Turk,July 2017,Antonio A. Arechar,Gordon T. Kraft-Todd,David G. Rand,Male,Male,Male,Male,"Online survey platforms are an increasingly popular tool for studying human behavior in the social sciences. Since the appearance of Amazon Mechanical Turk (MTurk), a plethora of studies have validated their use by successfully replicating classic findings from economics and psychology (Paolacci et al. 2010; Horton et al. 2011; Amir et al. 2012; Berinsky et al. 2012; Rand 2012; Arechar et al. 2016). In comparison to other methods, online surveys permit quick and affordable collection of large volumes of data. Another feature of these online studies is that they make it easy to collect data at any time and, unlike studies conducted in the laboratory or in other face-to-face environments, participation can easily occur late at night or on weekends. This is possible because researchers commonly leave a single study continuously open for a week or longer, allowing participation at whichever time suits participants. A potential issue arising from this practice, however, is heterogeneity in participants’ characteristics based on time of participation. There is evidence in support of such heterogeneity; for example, people who work in traditional white collar jobs may be unavailable to complete studies during regular business hours. As a result, studies run during those hours may be more likely to recruit “professional” participants who use MTurk as a primary source of income—and thus may have more prior experience (Casey et al. 2016), make fewer errors (Chandler et al. 2015), and complete studies more quickly (Deetlefs et al. 2015). Additionally, participants recruited when a study is first posted may differ from those recruited later, as in college samples where there is evidence that students differ depending on whether they sign up to complete studies at the beginning versus the end of the semester (Aviv et al. 2002). Indeed, in an unincentivized survey study, Casey et al. (2016) explore the demographic and personality differences of participants who took part in surveys at different times on MTurk. Notably, they find that experienced participants were more likely to complete tasks earlier in the day, and that participants tend to be older, less neurotic, and more conscientious earlier in the data collection. Still, little is known about how participants’ behavior may vary based on time of participation, and this is crucial knowledge for accurately interpreting the results of online studies. To shed light on this issue, we ran an incentivized study at regular intervals over 2 weeks to explore how participation at day versus night, and on weekdays versus the weekend, affects incentivized behavior in common economic paradigms, as well as the demographics and personality of those who self-select to participate. Participants completed a series of tasks presented in randomized order. They made seven incentivized decisions: a dictator game, a one-shot prisoner’s dilemma game, and a third-party punishment game with prosocial punishment of selfishness and antisocial punishment of fairness, as well as an honesty task, a charitable giving decision, and a time discounting task. In addition to these incentivized measures, they also completed unincentivized measures of reflectiveness (a modified version of the cognitive reflection test, CRT; Frederick 2005), the Big-5 personality traits of openness to experience, conscientiousness, extraversion, agreeableness, and neuroticism (Gosling et al. 2003), and basic demographics. We do not find significant differences in decisions in any of the incentivized behavioral measures. However, we do find that people participating at night are less experienced, take more time to complete tasks, are less conscientious, and more neurotic than their daytime fellows; and that people participating on weekends are less experienced and reflective. We also examine behavioral and demographic differences based on participation order. We find no differences in any of the incentivized measures, with the exception of charitable giving, where people participating earlier on in the study give less. We also find that such participants are more experienced, reflective, and agreeable than later ones. Of course, our results cannot speak to causality. A person’s characteristics could be influencing when they select into participation in studies on MTurk, or there could be a causal effect such that the same person tends to be, for example, less reflective on the weekend compared to weekdays. Although this distinction is important for understanding the psychological basis of our observations, the direction of causality does not have particular bearing on the practical implications for experimenters interested in running experiments at nights and on weekends using MTurk. In sum, our results suggest that incentivized economic behavior on MTurk is robust to the time of day and the day of the week, while there is some variation in participants’ personality and prior experience across these recruitment times.",51
3.0,1.0,Journal of the Economic Science Association,07 June 2017,https://link.springer.com/article/10.1007/s40881-017-0036-z,Experienced vs. inexperienced participants in the lab: do they behave differently?,July 2017,Volker Benndorf,Claudia Moellers,Hans-Theo Normann,Male,Female,Unknown,Mix,,
3.0,1.0,Journal of the Economic Science Association,05 July 2017,https://link.springer.com/article/10.1007/s40881-017-0038-x,The determinants of voting in multilateral bargaining games,July 2017,Guillaume R. Fréchette,Emanuel Vespa,,Male,Male,Unknown,Male,"Many situations require the division of resources among a group. In particular, elected officials have to allocate resources between districts. Models of multilateral bargaining provide theories on how a committee would divide a fixed budget among members. The model of Baron and Ferejohn (1989) (hereafter BF), has become the standard way of modeling such situations. The BF model uses an alternating-offers procedure to determine an allocation. In its most common form, referred to as the closed rule, one member (the proposer) is randomly recognized to make a proposal that is presented to the committee for a vote. Given a decision rule (e.g., a simple majority), the proposal can be accepted if it gathers enough votes—in which case it is implemented or rejected otherwise. If rejected, the procedure is repeated, but with each new bargaining stage a fraction \((1-\delta )\in [0,1]\) of the budget is lost. The closed-rule BF model has been widely used not only to study bargaining per se, but also as a building block in more involved models that, at some stage, require a group to solve a bargaining problem (e.g., Battaglini and Coate 2007). An important feature of the equilibrium prediction is that committee members vote in favor of a proposal, as long as the share they would receive is not lower than the continuation value (CV) of the game. The CV of the game captures the payoff that the players can expect if the game moves forward. The CV depends on the fraction \((1-\delta )\) of the budget that is lost with each bargaining stage: the higher the fraction that is lost, the lower the expected value of the game. This means that members of the group other than the proposer who receive strictly positive shares (non-proposers) should be willing to accept lower shares as the fraction of the budget that is lost increases. Meanwhile, the proposer is predicted to receive a larger share as \((1-\delta\)) increases. Numerous experiments study the BF environment McKelvey (1991), Fréchette et al. (2003), and Diermeier and Morton (2004) are some of the early studies, but many more have followed, and multiple aspects of behavior in this game are now well documented.Footnote 1 For instance, as the model predicts, the vast majority of proposals are immediately accepted; the majority of proposals involve a minimal winning coalition (MWC) (i.e., they do not distribute funds to subjects whose vote is not necessary to obtain a majority of votes) and proposers exhibit proposer power on average (they take more than they give). Those studies have also systematically documented quantitative deviations from theoretical predictions. In particular, that proposers end up receiving a share substantially below equilibrium, which in turn means that a large majority of non-proposers in the winning coalition receive shares substantially above the CV. However, much less is known about the determinants of voting decisions, even though they are crucial to understanding proposer behavior. Understanding the determinants of voting, for example, can help to evaluate whether proposers’ behavior is optimal given responders’ behavior. In addition, it also offers an interesting window into preferences—since unlike in bilateral bargaining—an agent’s payoff is not tied one-for-one to the proposer’s payoff.Footnote 2
 There are two major challenges to studying the determinants of voting using the standard experimental designs of multilateral bargaining. First, equilibrium offers are seldom observed. As the top panel of Fig. 1 shows, the entire dataset in Fréchette et al. (2003) (hereafter FKL) contains no case of MWC proposals in which the share offered corresponds to the equilibrium offer. In fact, there are no strictly positive shares offered below the equilibrium offer when the proposal is for a MWC. Although there are offers at the equilibrium level, not one of them is part of a MWC offer. In other words, to make inferences on whether equilibrium offers would be accepted requires extrapolating from shares offered as part of non-MWC proposals. Since it is not clear, a priori, that MWC offers are treated the same as non-MWC offers, such inference is not straightforward. Second, previous experimental designs typically use parametrizations such that the equilibrium offer (the CV) is relatively close to \(\frac{1}{N}\) (N being the number of players), which can be thought of as an alternative rule to explain voting decisions. The equilibrium offer is close to \(\frac{1}{N}\) when agents are patient, and most studies consider only values of \(\delta\) at or close to one. The top panel of Fig. 1 illustrates such a case. To the extent that \(\frac{1}{N}\) is a compelling candidate to explain voting, having the two close to one another makes it difficult to distinguish the one that explains voting best. While the lack of equilibrium offers and the closeness of the equilibrium offer to \(\frac{1}{N}\) are features of most previous studies, the design introduced in this experiment attempts to remedy both problems. Equilibrium offers are introduced using a computer that submits proposals in such a way that the CV of the game is unaffected. Only in the first stage of bargaining is it possible for the selected proposer to be replaced by a computer and the computer does not intervene in later bargaining stages. This means that the CV of the game at the time that the opening offer is under consideration is unaffected by the presence of the computer, so that the equilibrium solution is still meaningful. Moreover, when the computer makes an offer, the shares it proposes will actually be allocated to the corresponding subjects if it is accepted, which eliminates problems when subjects care about other participants’ outcomes. Subjects know that proposers can be replaced by a computer, and we elicit beliefs about the likelihood that the proposal came from the computer. This allows us to control for (and investigate) the potential effect of intentions. The bottom panel of Fig. 1 shows the offers for one parameter value in the current experiment. As the figure shows, the current design increases the variability of offers among MWC proposals, including some at or below the equilibrium offer. Another design feature allows us to evaluate whether behavioral rules that do not depend on the CV may better rationalize voting decisions. One conjecture, consistent with findings from bilateral bargaining experiments (Roth 1995), is that CVs might predict voting patterns, but only within a certain range. When the equilibrium CV moves too far below what is considered acceptable (determined, perhaps, by some kind of norm), it stops having attraction power. We assess this conjecture by varying the parameter \(\delta\) within each session. The variation in \(\delta\) will allow us to evaluate whether subjects follow a norm that is independent of the CV. To make the hypothesis more precise, consider the possibility that subjects follow a norm that accepts proposals only if the offered share is above some threshold T. Given the variation in \(\delta\), we can evaluate if there is a T-norm that can rationalize voting patterns across those values, and, in particular, whether such a rule performs better than the equilibrium criterion. Clearly, the \(\frac{1}{N}\) rule of thumb mentioned earlier would be a special case of a T-norm, and the bottom panel of Fig. 1 illustrates one particular value of \(\delta\) for which \(\frac{1}{N}\) is not close to the equilibrium offer. This is the first paper to consider as large a range and as many values of \(\delta\) for the BF game. Shares offered In Fréchette et al. (2003) and in one treatment of the current study (excluding offers of zero) Our first main finding is that close to 90% of voting choices are consistent with the equilibrium prediction (voting in favor of a proposal whenever the offered share is at least as high as the CV). In fact, the equilibrium criterion outperforms any T-norm in terms of rationalizing voting patterns. In other words, any rule that fixes a threshold share T for all values of \(\delta\) makes more mistakes in predicting votes than the equilibrium criterion makes. The exercise indicates that many subjects do not follow a voting rule independent of \(\delta\). Our second main finding is that, although the share offered is the most important determinant of votes, there is a secondary concern that is relevant only when subjects believe the proposal came from another participant. That is, they are more likely to reject a given share when the proposer takes more for himself, but only if they believe the proposer to be a participant. This suggests that subjects may be willing not to penalize proposals that are closer to equilibrium, provided that they believe it is highly likely to have come from the computer. This finding is in line with Blount (1995) and Bolton et al. (2005), who document that in the ultimatum game, biased offers that favor the proposer are more likely to be accepted when introduced by a computer rather than a human. In addition, we find that equilibrium proposals introduced by the computer are less likely to receive favorable votes when the value of \(\delta\) is relatively low and the equilibrium predicts a distribution very favorable to the proposer. In particular, this is consistent with Bolton et al. (2005), who report that in ultimatum games, when the bias in favor of the proposer is too large, proposals are rejected regardless of how they were generated. From another perspective, our findings suggest that allowing for pre-play communication is necessary for proposals to move closer to equilibrium. Agranov and Tergiman (2014) and Baranski and Kagel (2015) show that proposals move substantially closer to equilibrium if there is pre-play communication. However, such designs cannot evaluate whether communication per-se is necessary for the finding, or if the same result would have been reached if subjects had had experience with equilibrium proposals absent communication. Our evidence is consistent with communication being necessary per-se, given that we do not see equilibrium proposals spread after the computer introduced such proposals.",11
3.0,1.0,Journal of the Economic Science Association,12 June 2017,https://link.springer.com/article/10.1007/s40881-017-0037-y,Does the absence of human sellers bias bidding behavior in auction experiments?,July 2017,Björn Bartling,Tobias Gesche,Nick Netzer,Male,Male,Male,Male,"Real-world sales auctions are mechanisms used to allocate goods among potential buyers and generate revenue for the seller. Experimental implementations of auctions in the laboratory typically do not have subjects in the role of the seller who receives the auction’s revenue. However, evidence exists that subjects care about the payoffs of other subjects in auction experiments. In particular, the literature has documented spiteful preferences among the bidders. The question then arises whether these interdependent preferences extend to the seller, in which case the absence of human sellers in the laboratory would systematically bias observed bidding behavior in auction experiments. We analyse this question in a second-price sealed-bid auction (SPA), both theoretically and experimentally. It is a well documented fact that subjects overbid in experimental SPAs, and spite among bidders has been proposed as an explanation (e.g. Morgan et al. 2003; Brandt et al. 2007; Andreoni et al. 2007; Cooper and Fang 2008; Nishimura et al. 2011; Kimbrough and Reiss 2012; Bartling and Netzer 2016).Footnote 1 Spiteful bidders may find it attractive to overbid in order to increase the buying price for the winning bidder. However, overbidding not only reduces the winning bidder’s payoff but it also increases the seller’s payoff. If a subject in the role of the seller is present, and if spite extends to the seller, then the incentive to overbid will be reduced or even reversed. The often observed overbidding in experimental SPAs may thus be an artefact of the particular—and arguably unrealistic—way in which auctions are typically implemented in the laboratory: absent a human subject who receives the auction’s revenue. A seminal paper by Kahneman et al. (1986) provides survey evidence that people indeed care about the fairness of prices in buyer–seller relations (see also, e.g., Campbell 1999; Rotemberg 2011; Herz and Taubinsky 2017). Direct evidence that bidders care about the revenue in auction settings is found for charity auctions both in the lab (e.g. Goeree et al. 2005; Schram and Onderstal 2009) and in the field (e.g. Carpenter et al. 2007; Leszczyc and Rothkopf 2010). In charity auctions, bidders have a preference for high revenues, because the revenue is donated for a good cause. In standard auctions, in contrast, the revenue is kept by the seller, and spiteful bidders may have a preference for low revenues. After all, the revenue is generated by extracting rents from the buyers. To examine this motive more rigorously, we first derive the equilibrium bidding function in the SPA for bidders who care about the competing bidders’ payoffs and the seller’s revenue. We allow for spiteful as well as altruistic preferences. Our model unifies previous approaches such as the one by Morgan et al. (2003), who consider interdependent preferences only among the bidders, and the one by Engelbrecht-Wiggans (1994), who considers interdependent preferences only with respect to the seller. Our theoretical results confirm the intuition that preferences towards the seller counteract the effect of preferences towards the other bidders. In particular, spiteful preferences towards both parties may even restore truthful bidding. In the second part of the paper, we implement SPAs experimentally. We conduct a fully factorial design, including a standard SPA as our benchmark condition, where we exogenously vary the presence of human subjects in the roles of the seller and competing bidders. When competing human bidders are absent, we hold strategic incentives constant through the use of computerized bidders.Footnote 2
 We observe overbidding in the presence of competing human bidders, which is reduced when human bidders are replaced by computerized bidders. This observation is consistent with the previous literature arguing that spite causes overbidding. We however do not detect a systematic effect of the presence of human sellers on overbidding. The latter result shows that the standard experimental implementation of auctions without subjects in the role of sellers does not systematically bias bidding behavior. Our paper thus provides support for the external validity of the entire experimental literature on auctions by addressing a potential fundamental confound. The remainder of the paper is organized as follows. Section 2 presents our theoretical model. Section 3 explains our experimental design and procedures. Section 4 summarizes our hypotheses. Section 5 presents the experimental results. Section 6 concludes with a discussion of possible reasons for our findings.",8
3.0,1.0,Journal of the Economic Science Association,10 March 2017,https://link.springer.com/article/10.1007/s40881-017-0034-1,Ceding control: an experimental analysis of participatory management,July 2017,Philip Mellizo,Jeffrey Carpenter,Peter Hans Matthews,Male,Male,Male,Male,"Many “extraordinary claims have been made about [the effects of] employee involvement” (Lawler et al. 1995) on worker satisfaction and overall firm performance. Despite the strong intuition that employee participation in decision making is a “win-win” for employees and firms, the empirical record is mixed (e.g., Cappelli and Neumark 2001). Certainly, some of this owes to the list of well-known difficulties that accompany estimation: the inability to suitably control for unobservable heterogeneity, endogeneity, self-selection, or, more fundamentally, the availability of reliable and appropriate data. It may also be true that differences in sample characteristics, research designs, practices, and/or performance metrics have additionally contributed to mixed reported findings. In this paper, we use an experiment to mitigate some of the hurdles that hinder the identification of any causal effect of participation on performance. In particular, unlike the field where important aspects of production and motivation (like participation) are often determined endogenously, experiments allow one to implement exogenous, ceteris paribus changes. In our case, we compare groups of workers that were exogenously allowed (or not allowed) by a manager to participate in the running of the firm by having their vote to determine the group’s compensation policy. Because we collected compensation preferences before anyone learned the details of the experiment, they too are exogenous and allow us to control for worker selection. In this setting, we find that the average treatment effect of ceding authority to workers on effort in a real effort task is large (between seven and twelve percentage points), statistically significant and robust. We allow managers to choose to either implement a compensation scheme unilaterally or cede the right to choose the workers in an environment in which nothing is known of the worker characteristics and managers (along with their preferences) are randomly assigned to firms. Interestingly,
 in this setting we find that managers are reluctant to cede decision-making authority despite the possibility that it might be beneficial to do so. This finding replicates a result that is now common in the related literature (e.g., Fehr et al. 2013; Bartling et al. 2014). Considering our main contribution, we find a large and significant effect of participation, one that echoes the recent results on institutional choice and democracy found in Dal Bó et al. (2010).
 Like Dal Bó et al., we find that democratic participation affects motivation; however, while our experimental manipulation to account for possible selection effects is similar, it is also a bit simpler. Dal Bó et al. allow participants to vote on whether or not to modify the payoffs of a social dilemma game but a computer then decides whether or not to heed the results of the vote. When the computer ignores the vote, it decides to modify the game randomly. In our simplification, the context is also a bit more natural in that a human manager takes the role of the computer and decides to cede control to the workers before knowing the outcome of the vote. Reflecting on our previous work, the difference in output between workers in participatory firms and those in no-voice, traditional firms is larger, but in the same “ballpark” as a related estimate described in Mellizo et al. (2014). This original study estimated an effect of voting on effort to be between 7 and 9% points, at most while our current upper bound estimate is close to 12% points. However, there are substantial differences between the current experiment and the previous one, including one that might account for the larger effect. In addition to new design elements that allow us to more convincingly estimate a causal relationship, the elicitation of ex ante preferences to control for selection effects, changes in the compensation schemes available (a piece rate instead of revenue sharing) and a larger sample, we added an aspect of relational contracting (Macneil 1985) to the current experiment, which might partially explain why the current effect is more pronounced. In the current experiment, managers could either trust workers to pick a compensation scheme that would benefit everyone or not trust them and pick the scheme themselves. The manager’s confidence in the workers’ vote could very well interact positively with standard intrinsic motivational effects resulting from just allowing the workers more autonomy (Falk and Kosfeld 2006; Charness et al. 2012). In our previous experiment, things were simple but less realistic: there were no bosses and compensation schemes were either imposed randomly or via the worker’s vote—an environment in which only the intrinsic motivation channel was likely to affect effort. A more extensive review of the literature on participatory management and worker voice can be found in the online appendix that accompanies this paper, along with the experimental instructions and various robustness tests. What follows is a description of our experiment and a detailed analysis of our main results.",2
3.0,1.0,Journal of the Economic Science Association,10 April 2017,https://link.springer.com/article/10.1007/s40881-017-0033-2,Investing in institutions for cooperation,July 2017,Alexander Smith,Xi Wen,,Male,,Unknown,Mix,,
3.0,2.0,Journal of the Economic Science Association,28 November 2017,https://link.springer.com/article/10.1007/s40881-017-0040-3,Testing consumer theory: evidence from a natural field experiment,December 2017,Maja Adena,Steffen Huck,Imran Rasul,Female,Male,Male,Mix,,
3.0,2.0,Journal of the Economic Science Association,27 November 2017,https://link.springer.com/article/10.1007/s40881-017-0044-z,"Consumption experience, choice experience and the endowment effect",December 2017,Steven J. Humphrey,Luke Lindsay,Chris Starmer,Male,Male,,Mix,,
3.0,2.0,Journal of the Economic Science Association,30 November 2017,https://link.springer.com/article/10.1007/s40881-017-0045-y,Emirati women do not shy away from competition: evidence from a patriarchal society in transition,December 2017,Aurelie Dariel,Curtis Kephart,Christina Zenker,Female,Male,Female,Mix,,
3.0,2.0,Journal of the Economic Science Association,16 November 2017,https://link.springer.com/article/10.1007/s40881-017-0043-0,The limits of guilt,December 2017,Loukas Balafoutas,Helena Fornwagner,,Male,Female,Unknown,Mix,,
3.0,2.0,Journal of the Economic Science Association,20 November 2017,https://link.springer.com/article/10.1007/s40881-017-0041-2,Is reciprocity really outcome-based? A second look at gift-exchange with random shocks,December 2017,Brent J. Davis,Rudolf Kerschbamer,Regine Oexl,Male,Male,Female,Mix,,
3.0,2.0,Journal of the Economic Science Association,16 November 2017,https://link.springer.com/article/10.1007/s40881-017-0042-1,Random expected utility and certainty equivalents: mimicry of probability weighting functions,December 2017,Nathaniel T. Wilcox,,,Male,Unknown,Unknown,Male,"Elicitation of certainty equivalents has become routine in laboratory measurement of preferences under risk and uncertainty (Tversky and Kahneman 1992; Tversky and Fox 1995; Wu and Gonzalez 1999; Gonzalez and Wu 1999; Abdellaoui 2000; Abdellaoui et al. 2007; Halevy 2007; Bruhin et al. 2010; Vieider et al. 2015). While elicitation methods vary across such studies, formal empirical interpretations of elicited certainty equivalents are invariably the same. The subject is assumed to have a unique and fixed preference order, implying (under unchanged conditions of background wealth, risk and so forth) a unique and fixed certainty equivalent for each prospect. Elicited certainty equivalents are then interpreted as this unique and fixed certainty equivalent plus some error of banal origin with standard properties. Such added error, or something like it, is necessary: In repeated elicitations using exactly the same prospect, elicited certainty equivalents vary within subjects (Tversky and Kahneman 1992, pp. 306–308; Krahnen, Rieck and Theissen 1997, p. 477; von Winterfeldt et al. 1997, p. 422; Gonzalez and Wu 1999, pp. 144–146; Pennings and Smidts 2000, p. 1342) and other evidence also suggests inherent variability of elicited certainty equivalents (e.g., Butler and Loomes 2007). Luce (1997, pp. 81–82) argued that theory and empirical interpretation need to take a position on such response variability. Adding mean zero error to an otherwise deterministic model of certainty equivalents is clearly one option here, and I call this the standard model of an elicited certainty equivalent. Random preference models are a well-known alternative to standard models. These models assume that an individual subject’s preference order is a random variable, and that each certainty equivalent elicited from that subject is fully determined by a single realization of that random variable. Random preference models are both old and contemporary, particularly in the realm of discrete choice (Becker et al. 1963; Eliashberg and Hauser 1985; Hilton 1989; Loomes and Sugden 1995, 1998; Regenwetter and Marley 2001; Gul and Pesendorfer 2006; Regenwetter et al. 2011; Ahn and Sarver 2013; Apesteguia and Ballester 2016; Karni and Safra 2016). I examine implications of random preference models for elicited certainty equivalents and find a significant complication of their empirical interpretation. Random model expected utility preferences (or more simply random EU as named by Gul and Pesendorfer 2006) imply expected certainty equivalents that can mimic those implied by standard model rank-dependent preferences (or more simply standard RDU). That is, a random EU subject can have expected certainty equivalents that appear to reveal rank-dependent probability weighting functions of the inverse-s shape discussed by Quiggin (1982) and advocated by Tversky and Kahneman (1992) and other scholars. Implicitly, the simulation results of Navarro-Martinez et al. (2017) hint at the direction of my inquiry here. Section 2 develops a standard RDU model and a random EU model of observed certainty equivalents in formal econometric terms, separating both into a conditional expectation function and an error term. Section 3 then develops parametric examples of the random EU model that mimic standard RDU models: For example, Prelec (1998) weighting functions will be derived from certainty equivalents governed by a specific random EU model. Section 4 shows that a class of random EU models will display apparent underweighting of high probabilities and apparent overweighting of low probabilities—just that pattern implied by inverse-s probability weighting functions in a standard RDU model; and Sect. 5 provides brief graphical intuition for all the results. Contra widespread suggestions to the contrary, I conclude that elicited certainty equivalents may not nonparametrically identify preferences, since their conditional expectation (and critically, the interpretation of it) depends on the source of their variability.",3
3.0,2.0,Journal of the Economic Science Association,23 September 2017,https://link.springer.com/article/10.1007/s40881-017-0039-9,Bonus versus penalty: How robust are the effects of contract framing?,December 2017,Jonathan de Quidt,Francesco Fallucchi,Simone Quercia,Male,Male,Female,Mix,,
3.0,2.0,Journal of the Economic Science Association,06 January 2017,https://link.springer.com/article/10.1007/s40881-016-0032-8,Payoff and presentation modulation of elicited risk preferences in MPLs,December 2017,Sameh Habib,Daniel Friedman,Duncan James,Female,Male,Male,Mix,,
4.0,1.0,Journal of the Economic Science Association,06 June 2018,https://link.springer.com/article/10.1007/s40881-018-0051-8,Guilt averse or reciprocal? Looking at behavioral motivations in the trust game,July 2018,Yola Engler,Rudolf Kerschbamer,Lionel Page,Unknown,Male,Male,Male,"This paper investigates the ability of the most prominent models of belief-dependent motivations to explain second-mover behavior in the investment (or ‘trust’) game introduced by Berg et al. (1995). In models of belief-dependent motivations, an agent’s utility is defined over outcomes (as in traditional game theory) and hierarchies of beliefs. Such models are, therefore, deeply rooted in psychological game theory (as pioneered by Geanakoplos et al. (1989) and further developed by Battigalli and Dufwenberg (2009). For second-mover behavior in the investment game, the two most prominent models of belief-dependent motivations make opposite predictions regarding the correlation between second-order beliefs and behavior. According to the theory of sequential reciprocity as introduced by Dufwenberg and Kirchsteiger (2004) (and see also Rabin 1993) and extended by Sebald (2010), a generous transfer by the first mover (FM, he) is interpreted by the second mover (SM, she) as less kind if the FM is believed to expect a high back transfer in return. These models, therefore, predict that the pro-sociality of the SM  decreases in her belief about the payoff expectation of the FM. By contrast, the guilt-aversion model introduced by Charness and Dufwenberg (2006) and generalized and extended by Battigalli and Dufwenberg (2007) assumes that people experience a feeling of guilt when they do not live up to others’ (payoff) expectations. This model, therefore, predicts that the pro-sociality of the SM  increases in her second-order belief. Given the conflicting predictions of the two classes of models, it is ultimately an empirical question whether the revealed pro-sociality of an agent increases or decreases in her expectations about the payoff expectation of the other agent. The previous studies investigating this issue—often obtained by employing variants of the trust game as the work-horse—provide mixed results: while some papers (as, for instance, Guerra and Zizzo 2004, Charness and Dufwenberg 2006 and Bacharach et al. 2007) find a positive correlation between second-order beliefs and pro-social behavior, others [as, for instance, Ellingsen et al. (2010), or Al-Ubaydli and Lee (2012)] find no correlation, or even a (slightly) negative one. This paper explores the possibility that the inclusive evidence reported in the previous studies is due to preference heterogeneity in the population of SMs. Some SMs may be mainly motivated by reciprocity, some others by guilt aversion, and a third group of SMs might not react to others’ payoff expectations at all. If the former two groups are similar in size, then in the aggregate the positive correlation between pro-social behavior and second-order beliefs and the negative, one might simply cancel out. This could explain the no-correlation result obtained in several previous studies. To investigate this possibility, we use a triadic (that is, a three games) design implemented within subjects. Our experimental design is intended to exogenously manipulate the second-order beliefs of SMs in the trust game and we use it to classify experimental SMs into behavioral types depending on how they react to the belief manipulation. In line with the previous findings, we find no pronounced effect of the induced shift in second-order beliefs in the aggregate data. More importantly, while we find some evidence that (at least directionally) supports our hypothesis of the coexistence of guilt averse and reciprocal players, we do not find very clear evidence in support of our hypothesis that the no-correlation result in the aggregate data is caused by the heterogeneity in reactions. Overall, it seems that the behavior of SMs in the trust game is either not primarily driven by beliefs on the payoff expectations of the FM or that it is driven by more complex considerations than those reflected in existing theories. Turning to the related literature, the two papers closest to ours are probably Khalmetski et al. (2015) and Attanasi et al. (2017). The former paper formalizes the idea that people might not only feel guilt from not living up to others’ expectations, but may also get pleasure from positive surprises. For the dictator game, their model predicts a positive correlation between transfers and expectations for guilt-averse dictators and a negative correlation for surprise-seeking ones. While the intuition for the positive correlation is the same as in our work, the intuition for the negative correlation is different—in their work, it results from the fact that lower expectations leave more room for positive surprises, while in our work, it results from the fact that FMs with lower expectations are considered as kinder. The work of Attanasi et al. is more similar to ours in that both test the hypothesis that in a trust game, the SM’s choice may be affected by a combination of guilt aversion and reciprocity. However, while they test their home-grown model in experiments which either disclose or not disclose the beliefs elicited form trustees to the paired trustor (under the auxiliary assumption that disclosure induces a psychological game with complete information), we test existing theories by exogenously varying a design parameter (under the auxiliary assumption that our manipulation shifts second-order beliefs).",5
4.0,1.0,Journal of the Economic Science Association,15 March 2018,https://link.springer.com/article/10.1007/s40881-018-0046-5,Experimental guidance for eliciting beliefs with the Stochastic Becker–DeGroot–Marschak mechanism,July 2018,Ingrid Burfurd,Tom Wilkening,,Female,Male,Unknown,Mix,,
4.0,1.0,Journal of the Economic Science Association,18 May 2018,https://link.springer.com/article/10.1007/s40881-018-0047-4,Inside information in Ponzi schemes,July 2018,Klarita Sadiraj,Arthur Schram,,Female,Male,Unknown,Mix,,
4.0,1.0,Journal of the Economic Science Association,25 June 2018,https://link.springer.com/article/10.1007/s40881-018-0048-3,Self-control and demand for commitment in online game playing: evidence from a field experiment,July 2018,Dan Acland,Vinci Chow,,Male,Unknown,Unknown,Male,"In 2015, 155 million Americans played computer games, with 42% playing 3 h a week or more. The average age was 35, with 44% female. Games range from role-playing games such as World of Warcraft to short, repetitive “casual” games such as Candy Crush Saga.Footnote 1 There has been concern among policy makers and the public about pathological gameplay, with cyber-addiction researchers identifying characteristics of addiction in some players (Kuss 2013). One possible contributor to observed patterns of play is that players may experience self-control problems due to temptation, despite potential negative outcomes such as sleep loss, or not completing important tasks. If players lack willpower to overcome such temptation, they may begin playing more frequently, and continue playing for longer, than they would if they did not experience temptation. Among such players, those with sufficient self-awareness might wish to find ways to limit when, and how long, they play, to mitigate harm from excessive play. Two formal theories model these kinds of issues, the present-biased preferences model of Laibson (1997) and O’Donoghue and Rabin (1999), and the Gul and Pesendorfer (2001) model of temptation and self-control. The former assumes that individuals inflate the value of immediate consequences relative to future consequences, resulting in over-consuming goods with immediate benefits and long-term costs. This model would predict that present-biased players would initiate play more frequently, and continue playing longer, than they would if they did not have present-biased preferences. If such players have sufficient self-awareness of their self-control problems (“sophistication”), they might wish to find ways to restrict their gameplay behavior to more effectively implement their non-biased preferences. The Gul and Pesendorfer model assumes individuals experience temptation utility from some goods in the immediate present, in addition to their standard consumption utility, such that they may choose an option that generates less consumption utility than other options. Individuals have preferences over choice sets, and do not experience temptation when considering choices over choice sets. Thus, individuals may choose a restricted choice set to avoid temptation. Both of these models predict that only those with self-control problems will choose to restrict their gameplay behavior, and that any player who does so will play longer than their non-biased or un-tempted preferences would dictate. Both also predict that only those with a degree of self-awareness of their temptation problem will seek to restrict their choices. Thus, if we were to observe players choosing to restrict their gameplay behavior we would have evidence that they have self-control problems, and self-awareness of those problems. To explore the existence of players with self-identified self-control problems, and their demand for ways to control their behavior, we implemented a large-scale online field experiment in which quasi-randomly assigned players of a casual online game were given access to two voluntary commitment devices, designed to allow players to limit the duration of gameplay sessions. The first device (the “ex-ante” device) allowed players to set a limit on the number of games the game server would allow them to play, before being blocked from the game for 1 h. The second device (the “in-game” device) allowed players at any time during a game session to limit themselves to one more game, whereafter they would be blocked for 1 h. Both of the above models predict that players who make use of such devices will play fewer games per session, as they will be able to overcome the temptation to play more games than they would prefer. Thus, if there are players with self-aware self-control problems, we would expect a reduction in length of gameplay sessions among treatment-group players. And we would take such a reduction as prima facie evidence of the existence of players with self-identified self-control problems. Regarding the frequency of gameplay sessions, neither model makes a clear prediction, because our devices do not allow players to block themselves from starting to play. If players do not experience temptation until they have begun playing, both models predict that they will initiate more sessions in the presence of commitment devices as they will be able to mitigate excessive play. If, instead, they experience temptation at the time of deciding to initiate play, the models predict no change in the frequency of sessions, unless being blocked from the game after setting a limit prevents players from playing sessions that they would have otherwise initiated during the period of the block. Each game lasts 3 min, followed by a 45 s break. We observe all players in all games for 30 months before, and 54 months after the beginning of the intervention. We compute the games per session, sessions per week, and total games per week for each player in each week, as well as the total period, in days, during which they play, which we refer to as their “lifespan”. To preview our results, having the commitment devices available resulted in a reduction in session length of 2.8% for the treatment group as a whole, and a reduction of 6.1% in the number of sessions per week, for a total reduction in games per week of 9.4%. Thus, we conclude there are players with self-identified self-control problems, who have preferences for restricting their choices, and that being blocked from the game reduces their ability to play unwanted additional sessions. In addition, there was a substantial treatment effect on lifespan, with treatment-group players averaging 5.5% longer lifespans than control-group players (15 days on a baseline of 275 days). We provisionally interpret this as evidence that being able to better implement non-biased preferences made the game more rewarding to players with self-identified self-control problems, leading them to stay with the game longer before switching to another game or activity. Instrumental variable regression allows us to estimate the treatment effect on device users specifically, revealing reductions of 11.3, 30.7, and 42.4%, respectively, in session length, session frequency, and games per week among device users, and an increase in lifespan of 11.5%. Approximately one-quarter of treatment-group players make use of one or both of the devices at least twice (ruling out those who try them purely out of curiosity), with the median device user making use of one or other device in approximately 60% of sessions at the beginning of their lifespan, and increasing over the course of their lifespan. The 75th percentile device user uses a device approximately 100% of the time. Finally, comparing the pre-treatment gameplay of those who made use of the devices once they became available, with those who did not, we find that device users are players who play more and longer sessions in the absence of the devices, suggesting that in the absence of commitment devices, their self-control problems may be causing them to play the game more than they would ultimately prefer. The remainder of the paper unfolds as follows: Section 2 presents our experimental design and data. Section 3 presents our results. Section 4 provides discussion and conclusion.",5
4.0,1.0,Journal of the Economic Science Association,24 May 2018,https://link.springer.com/article/10.1007/s40881-018-0050-9,A shared identity promotes herding in an information cascade game,July 2018,Sebastian Berger,Christoph Feldhaus,Axel Ockenfels,Male,Male,Male,Male,"Individual decisions rarely take place in a social vacuum; instead, they are often influenced by others’ advice and behavior. In many situations, decision makers, therefore, face a trade-off between sticking to their own assessment of the state of the world and following the advice or behavior of others. A well-known vehicle to study this conflict in the economic laboratory is the information cascade game pioneered by Anderson and Holt (1997). In this game, players must guess the true state of the world based on their private noisy signals and on what they know about others’ prior choices. In the present research, closely adopting the initial experimental design by Anderson and Holt (1997; see Fahr and Irlenbusch 2011 for a similar setting), we consider a situation with two possible states of the world, which are either an RED urn or a BLACK urn, both being drawn with equal probability. Each member of a six-player group sequentially receives a private and stochastic signal about the true state of the world. The signal is either a red ball or a black ball, with the probability of RED (BLACK) conditional on drawing a red (black) ball being equal to 2/3. After receiving her private signal, each player bets on one of the two states of the world, which gives her a fixed payoff if correct. Apart from their private signals, players know the history of choices of all prior decision makers. Standard economic theory assumes that players update their beliefs about the true state of the world according to Bayes’ rule, further assuming common knowledge of rationality. However, empirical research on information cascade decision-making shows that learning from others’ behavior (i.e., acting upon their decisions) and from one’s private signal often deviates from Bayesian predictions.Footnote 1 Studying a meta-data set consisting of the results of 13 experiments on information cascade decision-making, Weizsäcker (2010) finds that subjects do not only fail to do Bayesian updating consistently, but that they are also too reluctant to discard their private signal. That is, they often err in sticking to their private signal when it would have been empirically optimal (in terms of expected utility) to follow their predecessor’s choice (see also Ziegelmeyer et al. 2013). Similarly, Kübler and Weizsäcker (2004) find that many decision makers purchase private signals even when these are uninformative in Bayesian terms. Such findings are in line with Goeree et al.’s (2007) quantal response equilibrium analysis. All these studies imply that people seem to overweight their private signals compared to publicly provided information (see also Nöth and Weber 2003). In the present research, we investigate whether group composition in terms of shared vs. mixed near-minimal group identities (Tajfel and Turner 1979; Akerlof and Kranton 2000; Mussweiler and Ockenfels 2013) affects subjects’ inclination to follow in the information cascade game. Thus far, the economic literature mainly suggests that a common identity affects people’s preferences and in particular promotes altruism towards the ingroup (McLeish and Oxoby 2007; Chen and Li 2009; Chen and Chen 2011; Ockenfels and Werner 2014). In the information cascade game, the only way by which someone can behave altruistically is by revealing her private information. Hence, this channel would suggest that subjects in homogenous groups reveal their private signal more often to altruistically provide a better information to their fellow group members, even when it may be profit-maximizing to do otherwise. Research predominantly stemming from social psychology suggests another channel through which identity may affect behavior in the information cascade game. Specifically, Levine et al. (2014) show that ethnic homogeneity can promote herding and inflate price bubbles in an asset market experiment.Footnote 2 They explain this observation with an increased confidence in similar others’ choices. More basic psychological research addressing similarity-focused information processing backs this reasoning, suggesting that more similarity among subjects may lead to a more ‘trusting mindset’ (Gino et al. 2009; Mussweiler and Posten 2012; Bolton et al. 2016), which in turn could result in a stronger reaction towards others’ choices in homogenous groups.Footnote 3 This literature hence suggests that group homogeneity may promote herding (i.e., following others’ behavior) in the information cascade context. Interestingly, the effects reported in these two streams of the literature in economics and psychology push behavior in opposite directions. Whereas an argument built on ingroup altruism would suggest less following and more information revelation, an argument built on the literature on similarity would suggest more following. Our data show that laboratory subjects are significantly more likely to follow an ingroup rather than an outgroup member’s choice which provides evidence that a common identity not only affects social preferences but also social cognition.",13
4.0,1.0,Journal of the Economic Science Association,06 June 2018,https://link.springer.com/article/10.1007/s40881-018-0052-7,Pushing the bad away: reverse Tullock contests,July 2018,Bettina Rockenbach,Sebastian Schneiders,Marcin Waligora,Female,Male,Male,Mix,,
4.0,1.0,Journal of the Economic Science Association,04 June 2018,https://link.springer.com/article/10.1007/s40881-018-0049-2,Framing effects on bribery behaviour: experimental evidence from China and Uganda,July 2018,Alessio Gaggero,Simon Appleton,Lina Song,Male,Male,Female,Mix,,
4.0,2.0,Journal of the Economic Science Association,22 October 2018,https://link.springer.com/article/10.1007/s40881-018-0057-2,Effects of gain-loss frames on advantageous inequality aversion,December 2018,Kene Boun My,Nicolas Lampach,Jacopo Magnani,Unknown,Male,Male,Male,"There is considerable evidence that individuals exhibit a preference to reduce inequality in outcome distributions (see Fehr and Fischbacher 2006 for a review of this evidence). While most of the literature has studied preferences over the distribution of gains, there are many situations where individuals have to decide how to divide losses. Consider for example citizens of a country deciding how to fund recovery after a natural disaster or roommates deciding how to split a charge for room damages. Although these kinds of situations are frequently encountered, there is little direct evidence on preferences for reducing inequality in the distribution of losses. Moreover, this lack of clear evidence is compounded by the fact that extrapolating results from previous studies to the loss domain is problematic, because individuals typically perceive losses and gains differently (see for example Kahneman and Tversky 1979). In this paper, we report an experiment that elicits the subjects’ preference to reduce advantageous inequality in the distribution of gains and losses. We analyze behavior in two versions of a modified dictator game (Blanco et al. 2011), one where outcomes are framed as gains and one where outcomes are framed as losses. To derive predictions about the effect of framing, we combine the inequality aversion model of Fehr and Schmidt (1999) with loss aversion in the dictator’s own payoff à la Kahneman and Tversky (1979). This model predicts the dictator will choose more unequal distributions in the loss domain than in the gain domain. Intuitively, while the dictator is willing to sacrifice some of his own net payoff to increase the net payoff of the recipient, accepting a loss is more psychologically painful than giving up an equivalent gain. Consistent with this prediction, the experimental results demonstrate that individuals choose on average less equitable payoffs when the game is framed in terms of losses. The estimated parameters of the utility function imply a positive degree of loss aversion. Additionally, the results also suggest that women are more inequality averse than men. Previous studies in social psychology, such as Loewenstein et al. (1989) and De Dreu (1994), have used surveys to measure subjects’ satisfaction with given hypothetical distributions of gains and losses for themselves and another person. Their findings suggest advantageous inequality aversion is weaker in negatively framed problems than in positively framed problems. Poppe and Valkenberg (1993) report an experiment where subjects choose between distributions of gains and losses. They find that a larger fraction of subjects behaved consistently with maximization of their own payoff under the loss frame than under the gain frame. Compared to these works, the use of the modified dictator game allows us to obtain a more reliable and precise measure of advantageous inequality aversion and quantify the framing effect in terms of loss aversion. A number of recent papers have explored how framing outcomes as losses or gains affects negotiations (e.g. De Dreu et al. 1994; Schweitzer and DeChruch 2001; Carnevale 2008) and behavior in ultimatum games (Buchan et al. 2005; Leliveld et al. 2009; Zhou and Wu 2011; Neumann et al. 2017). Studies on ultimatum games typically show that offers and demands are higher when outcomes are framed as losses than in ultimatum games where outcomes are framed as gains. The fact that responders tend to increase their demands when outcomes are framed as losses shows that aversion to disadvantageous inequality increases in this framing. The implications of these ultimatum game experiments for aversion to advantageous inequality are less clear. According to Leliveld et al. (2009), the fact that proposers increase their offers in games where outcomes are framed as losses shows they are reluctant to harm another person to benefit themselves. However, proposer behavior is also affected by strategic considerations: proposers may rationally increase their offers simply because they anticipate that responders demand higher payoffs under a loss frame. Using a dictator game instead of an ultimatum game, we are able to avoid this potential confound. Thus, our experiment complements this strand of the literature because it allows us to provide direct evidence on how framing outcomes as losses affects aversion to advantageous inequality. We find that the amount of payoff that subjects are willing to sacrifice to increase the net payoff of others is smaller under a loss frame than under a gain frame. This is consistent with loss aversion, i.e. the notion that the disutility caused by a loss is larger than the utility of a commensurate gain. Loss aversion can help account for a series of observed behaviors, such as the endowment effect (Kahneman and Thaler 1991), the sunk-cost fallacy (Samuelson and Zeckhauser 1988), the equity premium puzzle (Benartzi and Thaler 1995), risk aversion over small stake gambles (Rabin 2000) and the effect of labor target earnings (Abeler et al. 2011). Our paper contributes to this literature by studying the interaction between loss aversion and advantageous inequality aversion.",11
4.0,2.0,Journal of the Economic Science Association,31 October 2018,https://link.springer.com/article/10.1007/s40881-018-0058-1,Gender differences in giving in the Dictator Game: the role of reluctant altruism,December 2018,David Klinowski,,,Male,Unknown,Unknown,Male,"Understanding whether and under what circumstances men and women differ in their social preferences has important economic implications. Gender differences in social preferences may play a role in producing differences in the labor market (Bertrand 2011). And differences in charitable preferences may call for gender-specific fund-raising strategies (De Wit and Bekkers 2016). One way by which the economists study gender differences in social preferences is by looking at how males and females allocate money in the Dictator Game (Forsythe et al. 1994). The body of evidence from Dictator Games is unclear on whether males or females are more generous, although a robust finding seems to be that males are more efficiency-oriented and females are more focused on equity (Andreoni and Vesterlund 2001 for a first result; Niederle 2016 for a review). While this literature centers its attention on examining gender differences in preferences over payoffs—efficiency, equity, pure and impure altruism—another line of work unrelated to gender has shown that non-payoff-related motivations such as expectations management and image concerns may also influence giving in the Dictator Game (Dana et al. 2006; List 2007; Bardsley 2008; Andreoni and Bernheim 2009). There is growing evidence that such motivations may cause individuals to behave as “reluctant altruists”, sharing money when asked to, but avoiding the situation or reneging on their gifts if they can do so without being detected (Broberg et al. 2007; Lazear et al. 2012; Cain et al. 2014). In this paper, we draw from these literatures to examine whether males and females display different rates of reluctant altruism, and what this may mean for how we interpret gender differences in giving in the Dictator Game. We find consistently across two laboratory studies (total N = 634) that females give more in the Dictator Game, but are also more likely to retract their gifts, to the extent that expected transfers in the end become similar across gender. Our results suggest that females are influenced by non-payoff-related motivations to a larger degree than males, and this may explain at least in part the initial gender differences in giving. Our study is, however, unable to tease out in detail the different mechanisms that may drive the results, although we discuss some possibilities.",5
4.0,2.0,Journal of the Economic Science Association,13 October 2018,https://link.springer.com/article/10.1007/s40881-018-0056-3,On the effectiveness of elected male and female leaders and team coordination,December 2018,Ernesto Reuben,Krisztina Timko,,Male,Female,Unknown,Mix,,
4.0,2.0,Journal of the Economic Science Association,13 October 2018,https://link.springer.com/article/10.1007/s40881-018-0055-4,A method to estimate mean lying rates and their full distribution,December 2018,Ellen Garbarino,Robert Slonim,Marie Claire Villeval,Female,Male,Female,Mix,,
4.0,2.0,Journal of the Economic Science Association,21 August 2018,https://link.springer.com/article/10.1007/s40881-018-0053-6,When is punishment harmful to cooperation? A note on antisocial and perverse punishment,December 2018,Tingting Fu,Louis Putterman,,Unknown,Male,Unknown,Male,"The problem of collective action and free-riding is discussed extensively in economics, political science, psychology, and evolutionary theory, and one aspect receiving considerable attention is the role played by peer punishment of free riders (for a survey, see Chaudhuri 2011). Although well-directed punishment has been found to help to sustain cooperation, some punishment goes to cooperators, discouraging rather than encouraging their cooperation (Ostrom et al. 1992; Bochet et al. 2006; Herrmann et al. 2008). But consensus remains elusive as to which kind of punishment is most likely to be harmful to cooperation. Our paper investigates this question. We focus on the two main proposals for distinguishing cooperation-encouraging from cooperation-discouraging punishment, delving in detail into the ability of each, and of combinations of them, to predict when punishment increases and when it reduces cooperation. These two proposals are the division of punishments into the “perverse” and the “normal” by Bochet et al. (2006) and others, and its division into the “antisocial” and the “prosocial” by Herrmann et al. (2008) and related papers. Although papers including Carpenter and Matthews (2009) and Cheung (2014) investigate what norms best explain the incidence of punishment, the somewhat different focus of the present paper is on the relative advantages of different classification systems for predicting which punishments are usually efficiency-promoting and which efficiency-reducing. We are aware of only two sets of proposals that have been used in a sustained manner to classify punishments with that purpose in mind. First, Bochet et al. (2006) and Cinyabuguma et al. (2006) distinguished between what they called “perverse” and “normal” punishments on grounds that the latter “seems likely to strengthen incentives to increase contributions and aggregate earnings”, whereas the former “seems to work in the opposite direction”. Cinyabuguma et al. (2006) provided evidence in their working paper that punished high contributors tended to lower their contribution in the subsequent period, whereas punished low contributors tended to raise their contribution (see also Önes and Putterman 2007, Table 3). Ertan et al. (2009) demonstrated that choosing by majority vote to prohibit punishment of above-average contributors while permitting low contributors to be punished raised groups’ contributions and earnings significantly. A more refined econometric demonstration that high contributors’ contributions respond negatively to being punished while low contributors’ contributions respond positively is provided by Page et al. (2013, Table 4). The other proposal for partitioning punishment into an efficiency-enhancing and efficiency-reducing categories is that of Herrmann et al. (2008), who found higher shares of punishment directed at cooperators in subject pools in the former USSR, Greece, Turkey, and the Arabian Peninsula than in Western European, US and Australian sites, with a Chinese site resembling the latter group and a Korean one somewhere on the boundary. They found that subjects in the first group of sites achieved higher levels of contributions and earnings than those in the latter, with the proportion of punishment falling into each category being a strong predictor of contributions and earnings. However, rather than focus on the presence of above-average cooperators per se being targeted for punishment, Herrmann et al. (2008) partitioned punishment into “antisocial” and “prosocial,” defining the former as any case in which the punisher contributed less than or the same amount as the individual punished, the latter as any case in which the punisher contributed more than the punished. The same antisocial/prosocial distinction is used in other papers including Gächter et al. (2010), Gächter and Herrmann (2011), and Thöni (2014). As mentioned, other ways of categorizing and explaining the incidence of punishment in contribution games have been proposed, but only the above-mentioned sets of papers focus on the impact that punishments of different kinds have on contributions and efficiency. What accounts for the choice of these approaches? Carpenter and Matthews (2009) suggest that attention to the group average as a benchmark for understanding who is targeted for punishment goes back at least to Fehr and Gächter (2000), who use the average of other group members’ contributions as a reference point for explaining the amount of punishment each individual receives. Cinyabuguma et al. (2006) state that “Fehr and Gächter’s analysis (2000, p. 991) suggested a discontinuity in subjects’ own views of contributions below and those above the group average”. However, they indicate that what makes punishment conceptually “perverse,” for them, is its tendency to induce reductions in contributions and efficiency. They consider the possibility that the effect of punishment might depend on the absolute level of the contribution, and they mention that there is stronger evidence for punishment discouraging contributions when it is directed at a group’s highest contributor than when merely directed at an above-average contributor (p. 269). When offering opportunities to (higher order) punish subjects conditional on their punishing behaviors, they adopt the group’s average contribution as a pragmatic dividing point because presenting information organized by this categorization (also including punishment of those contributing exactly the average as a separate, third category) “seemed neutral and flexible”. The same advantage of adopting the average as a convenient divide, when letting subjects vote on who it is permissible to punish, is expressed by Ertan et al. (2009). It is less clear to us what motivated Herrmann et al.’s (2008) choice of the classification by punisher’s contribution relative to that of punishment target. In their demonstration that some punishments tend to cause recipients to raise their contribution, others to lower it (in Table S.7 of their Supporting Materials), Herrmann et al. (2008) partitioned punishment cases into those aimed at average and above-average contributors and those aimed at below-average contributors, equivalent to using Bochet et al.’s (2006) “perverse”/“normal” dichotomy.Footnote 1 Nevertheless, Herrmann et al. (2008) focus more of their discussion on the impact than on the motivation for punishing, with their most important conclusion being the one demonstrated by their Fig. 2 and Table 1: that amount of antisocial punishment is a significant negative predictor of contributing to the public good, at subject pool level.Footnote 2
 The goal of our paper is modest. We do not attempt to investigate what norms motivate punishment in public goods games, but only to compare the two proposals for studying which punishments promote and which discourage cooperation, seeking evidence as to which best predicts those outcomes. As an aside, we note that the terminologies “prosocial” and “antisocial” have been applied considerably more frequently by contributors to the social dilemma and punishment literature than have the terms “perverse” and “normal” or “non-perverse,” but some of the difference in frequency of use might be due to the intrinsic appeal of the terms rather than to a preference for the operationalization by Herrmann et al. (2008). There are at least a few cases in which the term “antisocial” was used by authors who were in fact applying the Bochet et al. (2006) operationalization (punish a high contributor) rather than the Herrmann et al. (2008) one (punish an individual who contributed more than oneself).Footnote 3 Although it is desirable that authors reach a clearer consensus about how they are using their terms, our discussion focuses on whether one of the two ways of operationally categorizing punishment, or some combination of the two, does a better job of predicting a negative impact on cooperation, rather than on which terms are most appealing. We use the terms “perverse,” “antisocial,” “normal” and “prosocial” as they were used by the groups of authors mentioned, leaving aside that other usages and terms have been applied to these and related categorizations.",5
4.0,2.0,Journal of the Economic Science Association,07 November 2018,https://link.springer.com/article/10.1007/s40881-018-0059-0,Instructions,December 2018,David J. Freeman,Erik O. Kimbrough,Hanh T. Tong,Male,Male,,Mix,,
4.0,2.0,Journal of the Economic Science Association,05 October 2018,https://link.springer.com/article/10.1007/s40881-018-0054-5,Revisiting gender differences in ultimatum bargaining: experimental evidence from the US and China,December 2018,Shuwen Li,Xiangdong Qin,Daniel Houser,Unknown,Unknown,Male,Male,"Gender differences in bargaining are one source of persistent wage gaps in labor markets (Babcock and Laschever 2009; Blau and Kahn 2017). Early lab evidence of differences in bargaining between genders provided by Solnick (2001) may help to explain this. Using the ultimatum game with the strategy method, she finds that female responders receive lower offers than male responders, and female proposers face higher minimum acceptable offers than male proposers. These patterns leave males earning significantly more than females. Despite these intriguing early findings, experimental evidence on gender differences in bargaining is inconclusive (Croson and Gneezy 2009; Güth and Kocher 2014). Other studies conducted around the same time using different variants of the ultimatum game found different results. For example, Eckel and Grossman (2001) find the same pattern as Solnick (2001) in proposers’ behavior, but both male and female responders are more likely to accept offers from female proposers. Additionally, Saad and Gill (2001) report that male proposers make more generous offers to female than male responders, while female proposers make equal offers independent of the gender of the recipient. Various other studies in the lab and field suggest, generally, that females obtain worse bargaining outcomes than males in a variety of contexts (see, e.g., Ayres and Siegelman 1995; Sutter et al. 2009; Dittrich et al. 2014). An exception is Castillo et al. (2013), who find males receive higher prices from taxicab drivers than females in Lima. This paper contributes to the literature on gender differences in bargaining by reporting a replication study of Solnick (2001) using student subjects from both the United States and China. Subjects play a two-person ultimatum game using a strategy method in which the proposer and the responder in a pair specify the offer and the minimum acceptable offer (MAO) simultaneously. In the Name treatment, subjects know their counterpart’s gender from the experimental ID that explicitly signals gender, while in the Number treatment, they are assigned three-digit IDs that contain no information about gender. We collect data from 493 pairs of players from two large universities: George Mason University (US) and Shanghai Jiao Tong University (China). Using two different subject pools sheds light on whether Solnick’s findings on gender differences continue to hold with contemporary students in different cultures. We observe little evidence of gender differences within either the US or Chinese subject pools. Our inability to find gender differences in ultimatum bargaining suggests that gender differences are context-based and do not have a universal or constant pattern over time.",7
5.0,1.0,Journal of the Economic Science Association,10 September 2019,https://link.springer.com/article/10.1007/s40881-019-00075-z,Choice-Process Data in Experimental Economics,August 2019,David J. Cooper,Ian Krajbich,Charles N. Noussair,Male,Male,Male,Male,"Individuals making decisions direct their attention toward sources of information and take time to consider their options. This process can involve physiological arousal, expressions of emotion, and patterns of neural activity. When a group comes to a decision, the members of the group may communicate verbally. They may use each other’s arousal and expressed emotions as information to help make a choice. In other words, individual and group decisions emerge as a result of a complex array of processes. Behavioral data consist of which decisions are made, but process data reflect how the decisions come about. Data from these processes can be collected and studied. This special issue showcases studies that use process data to understand decision-making. In this introduction, we provide a brief overview of the types of choice-process data that are employed in the papers published here, all of which are now well established in experimental economics, and highlight some of the recent advances using these methodologies. We then discuss the papers contained in this special issue.",5
5.0,1.0,Journal of the Economic Science Association,09 May 2019,https://link.springer.com/article/10.1007/s40881-019-00066-0,Does exposure to alternative decision rules change gaze patterns and behavioral strategies in games?,August 2019,Joshua Zonca,Giorgio Coricelli,Luca Polonio,Male,Male,Male,Male,"Nash equilibrium is a prominent concept in game theory. However, extensive empirical evidence has shown systematic departures from standard equilibrium predictions in many different games (Camerer 2003). To account for the observed deviations, several theories tried to model choices by relaxing some of the assumptions of Nash equilibrium. On the one hand, theories such as level-k (Nagel 1995; Stahl and Wilson 1995; Crawford 2003; Crawford et al. 2013) and Cognitive Hierarchy (CH, Camerer et al. 2004; Chong et al. 2016) allowed more flexibility in players’ beliefs, describing behavior in terms of hierarchical levels of strategic sophistication. The levels of strategic thinking are organized hierarchically starting from players who play randomly (level-0). The next level consists of level-1 players, who believe the counterparts to be level-0 and best respond to this belief; the following step involves level-2 players, who best respond to the belief that the counterparts are level-1 (in level-k theory) or a mixture between level-0 and level-1 (in cognitive hierarchy theory), and so on, moving up in the hierarchy. On the other hand, theories of social preferences (Rabin 1993; Fehr and Schmidt 1999; Bolton and Ockenfels 2000; Andreoni and Miller 2002; Fisman et al. 2007) relaxed the assumption of self-interest, assuming that agents have other-regarding preferences that modulate their utility function and, therefore, their choices. In recent years, behavioral research has sought to describe the process underlying these different models of choice in game play. In particular, empirical works involving eye-tracking and mouse-tracking successfully characterized different types of players based on their payoff lookup patterns (Costa-Gomes et al. 2001; Hristova and Grinberg 2005; Brocas et al. 2014, 2018; Polonio et al. 2015; Devetag et al. 2016; Polonio and Coricelli 2019). Taken together, results show that sophisticated models of choice (level-2 or more) are associated with a specific pattern of information acquisition characterized by the exploration and evaluation of both own and others’ incentives. However, less sophisticated players (level-1) disregard relevant pieces of information that are necessary to evaluate the incentives of the counterpart and to predict her move (Costa-Gomes et al. 2001; Polonio et al. 2015). Yet another type of player (cooperative) focuses on intra-cell comparisons between payoffs, framing the problem as a pure coordination game and disregarding dominant choices of the counterpart: this pattern of visual analysis lead to cooperative choices in line with models of social preferences (Devetag et al. 2016). Although these works successfully describe the processes underlying out-of-equilibrium choices, they do not fully clarify the nature of the observed heterogeneity in gaze patterns. Specifically, we do not know whether level-1 players disregard others’ incentives because they do believe that the other players do not have a preferred choice, or if players do not realize that they could play a more sophisticated strategy (Grosskopf and Nagel 2008; Goodie et al. 2012). At the same time, it is unclear if the emergence of strategies based on intra-cell comparisons is driven by the desire to maximize social well-being, or if it reflects a misrepresentation of the game structure and its interactive nature (Devetag and Warglien 2008). To address these open questions, we run an eye-tracking experiment in which participants initially play different classes of one-shot 2 × 2 matrix games with a human counterpart (phase 1). In phase 2, they are asked to apply specific decision rules (level-1, level-2, and cooperative) playing the same games with a computer algorithm whose strategy is known, and are paid based on the actual compliance to the current rule. In phase 3, participants play the same games as in phase 1 with another human counterpart. We classify players as level-1, level-2, and cooperative types based on their lookup patterns in phase 1, and then explored changes in the visual analysis of the game matrix in phase 3, after participants have experienced the three models of choice. We are particularly interested in testing if level-1 and cooperative players change their type of visual analysis of the game matrix and their choices towards the one expected for more sophisticated types (i.e., level-2), after being exposed to the level-2 model of choice. We show that level-1 players shift their visual analysis towards the one characterizing level-2 players, devoting more attention to the counterpart’s incentives. The attentional shift observed in level-1 players predicts an increase in the proportion of equilibrium responses in games in which the opponent has a dominant action. At the same time, cooperative players do not change their patterns of information acquisition, suggesting that their behavior is not driven by a misrepresentation of the game structure, but rather by other-regarding preferences. Taken together, these results offer new insights on theories of bounded rationality and social preferences.",13
5.0,1.0,Journal of the Economic Science Association,07 May 2019,https://link.springer.com/article/10.1007/s40881-019-00063-3,Eye-tracking and economic theories of choice under risk,August 2019,Glenn W. Harrison,J. Todd Swarthout,,Male,Unknown,Unknown,Male,"Standard economic theories of choice under risk are mathematical characterizations of the outcome of some evaluation and decision-making process. Although expository stories about this process are told to rationalize the characterization, from a formal perspective they are irrelevant: it is only “as if” the individual followed this or that process. Since these theories are characterizations of optimization problems, the manner in which we analysts might numerically solve them provides “algorithmic” insight into a possible process that might have been followed, particularly when the algorithm is modeled as a path-following, homotopy algorithm. However, there are literally infinite variations on these and other algorithms that can lead to the same optimization outcome, so at best this approach provides suggestive hypotheses about how decisions are made.Footnote 1 One role for process data is to inform our knowledge of “behaviorally plausible” decision-making algorithms that might be used. A related role might be to suggest descriptive explanations as to why some individuals tend to weight probabilities in the Rank Dependent Utility (RDU) sense. Finally, identification of the subset of information that is not studied, in absolute or relative terms, should provide insights for the normative evaluation of choices under risk. Decision-process data can be collected in many ways, and we consider eye-tracking. Eye-tracking provides a relatively non-intrusive method to collect rich data on areas of a visual display that are gazed upon. Mouse-tracking provides an alternative which involves software to mask the entirety of a visual display except for an unmasked region defined proximately by the instantaneous position of the mouse pointer, and yields sequences of information acquisition roughly analogous with eye-tracking. However, behavior observed with these two tracking methods differs systematically (Lohse and Johnson 1996). Time-tracking is the least intrusive, and easy to program, but only provides one scalar for the entire process, without discriminating between areas of the visual display. In general, we start with conventional models of choice from economics and add processing correlates to see how they inform those models. An alternative path would be to start with process models from psychology or cognitive science, and characterize our data in terms of them. Prominent process models in the non-economics literature are reviewed and developed by Atkinson and Birch (1970), Tversky (1972), Marley (1981, 1989), Grossberg and Gutowski (1987), Busemeyer et al. (1988), and Busemeyer and Townsend (1993). Our approach differs from the previous literature by assessing whether eye-tracking data inform the statistical, structural characterization of choices. The previous research posits certain patterns of visual attention that are loosely derived from alternative structural models of choice under risk, but does not then relate the visual attention data to any structural econometric representation of that model.Footnote 2 We demonstrate this methodological approach by collecting data from subjects facing lottery choices with incentives, while an eye-tracker is recording eye movements. We then estimate a structural model of the decision-making of these subjects in which we allow for a mixture of Expected Utility Theory (EUT) and RDU theory. We demonstrate that information on eye movements significantly informs our characterization of preferences, particularly the RDU fraction of choices. This insight comes in a structural form: we can say more than that “eye movement data matters for choice.” Moreover, we show that the total duration of time spent on the choice cannot substitute for the richer eye movement data.",8
5.0,1.0,Journal of the Economic Science Association,05 June 2019,https://link.springer.com/article/10.1007/s40881-019-00067-z,Skin conductance responses in anticipation of gains and losses,August 2019,Patrick Ring,Ulrich Schmidt,,Male,Male,Unknown,Male,"Loss aversion is a well-studied phenomenon in the behavioral sciences. It refers to the tendency whereby people accord greater weight to losses than to gains of equal size (Kahneman and Tversky 1979). Numerous studies have provided an empirical basis for loss aversion on the behavioral level (Ganzach and Karsahi 1995; Kahneman et al. 1990), the psychophysiological level (Hochman and Yechiam 2011; Sokol-Hessner et al. 2009; Wu et al. 2016), the brain level (De Martino et al. 2010; Tom et al. 2007), and in self-reported feelings (McGraw et al. 2010).Footnote 1 Based on the accumulated evidence, loss aversion has been used as an explanation for a variety of other empirical findings both from the laboratory and the field, such as the endowment effect (Thaler 1980) and status quo bias (Samuelson and Zeckhauser 1988).Footnote 2 Furthermore, it is an integral part of prospect theory, the dominant theory of decision-making under risk (Kahneman and Tversky 1979). Recently, the validity of the loss aversion hypothesis has been challenged from various accounts (Erev et al. 2008; Ert and Erev 2013; Gal 2006; Gal and Rucker 2018; Harinck et al. 2007; Morewedge et al. 2009; Walasek and Stewart 2015; Yechiam et al. 2014). While some authors fail to replicate its predictions (Erev et al. 2008; Harinck et al. 2007), others provide alternative explanations. Gal (2006), for example, describes the rejection of a lottery with equal chances of losing and winning as status quo bias rather than an aversion to losses. Yechiam et al. (2014) explain loss aversion in self-reported feelings by complaint bias, i.e., a tendency to complain more about losses than to praise gains. By incentivizing self-reported feelings, the authors are able to reduce loss aversion. Moreover, methodological concerns have been raised regarding experimental designs. In several studies, the magnitudes of gains and losses were unbalanced (e.g., Sokol-Hessner et al. 2009; Tom et al. 2007). Typically, the range of losses was smaller than the range of gains (max. gain: 30$–max. loss: 24$ in Sokol-Hessner et al. (2009); max. gain: 40$–max. loss: 20$ in Tom et al. (2007)). Therefore, a diminishing sensitivity to increased bet sizes or a sensitivity to ranks within the set of alternatives could also explain the finding of loss aversion (Hochman and Yechiam 2011; Walasek and Stewart 2015). Walasek and Stewart (2015) are able to reverse loss aversion by manipulating the range of gains and losses. In addition, increased physiological (Sokol-Hessner et al. 2009; Wu et al. 2016) or brain responses (Tom et al. 2007) to losses during the realization phase of lotteries have often been interpreted as an indicator of loss aversion. These studies, however, are not able to differentiate an increased sensitivity to negative outcomes from an increased sensitivity to performance failure (Critchley et al. 2005). In contrast to other concepts within the prospect theory framework, such as reference point dependence or diminishing sensitivity, loss aversion seems to lack a clear psychological foundation (Gal 2006). Our aim in the present study was to disentangle the emotional states that participants experience, while they anticipate a potential gain or loss. To do so, participants played a roulette task, while their skin conductance responses (SCRs) were recorded. SCRs are a commonly used psychophysiological indicator for emotional arousal that is sensitive to monetary outcomes, decisions to deviate from monetary reward maximization, and cognitive biases (Bechara et al. 1997; Boucsein 1992; Jaber-López et al. 2014; Perakakis et al. 2019; Ring 2015). In contrast to most previous studies, gains and losses in this study were separated from one another and symmetric in magnitude. Furthermore, we focused on the anticipation phase rather than on the realization phase and, therefore, excluded an increased sensitivity to performance failure as a potential explanation of our findings. It is worth noting that SCRs are not only elicited in response to but also in anticipation of significant stimuli (Dawson et al. 2011). In our design, we did not find evidence for loss aversion in anticipatory SCRs. We highlight a potential confound in the previous studies due to an unbalanced design of gains and losses.",3
5.0,1.0,Journal of the Economic Science Association,03 July 2019,https://link.springer.com/article/10.1007/s40881-019-00070-4,Additional deliberation reduces pessimism: evidence from the double-response method,August 2019,Katarzyna Gawryluk,Michal Krawczyk,,Female,Male,Unknown,Mix,,
5.0,1.0,Journal of the Economic Science Association,24 April 2019,https://link.springer.com/article/10.1007/s40881-019-00064-2,Using response times to measure ability on a cognitive task,August 2019,Aleksandr Alekseev,,,Male,Unknown,Unknown,Male,"Correct measurement of cognitive ability is essential since ability is used as an explanatory variable in a vast array of contexts. Economists have been using cognitive ability to explain differences in earnings (Murnane et al. 1995; Heckman et al. 2006, 2013), risk and time preferences (Dohmen et al. 2010), the quality of decision-making (Agarwal and Mazumder 2013), strategic reasoning (Gill and Prowse 2016), as well as differences in various life outcomes, such as teenage pregnancy, marital status, smoking, and engaging in criminal activities (Duckworth et al. 2011). This literature traditionally uses performance on a cognitive test as a measure of cognitive ability. A fundamental flaw in this approach is that performance never reflects cognitive ability by itself. Performance also reflects character skills, such as motivation (Borghans et al. 2008; Duckworth et al. 2011; Segal 2012).Footnote 1 The traditional approach thus confounds actual ability with the combination of ability and motivation, which may result in wrong conclusions about the effect of ability. Using performance as a proxy for ability could be justified if subjects’ heterogeneity in motivation is small relative to their heterogeneity in ability. However, the existing literature provides no way to empirically evaluate this assumption. I propose a new approach to measure cognitive ability that overcomes the issues with the traditional approach. My method is based on a dynamic stochastic model of optimal effort choice in which ability and motivation are the structural parameters. I show how these parameters can be separately identified from the data on outcomes and response times in a cognitive task. The proposed method is based on explicit modeling of the decision-making process and is inspired by the literature on drift-diffusion models (Ratcliff 1978; Krajbich et al. 2012; Woodford 2014; Clithero 2018; Webb 2019). These models have been shown to perform well in jointly predicting outcomes and response times, as well as to match the actual processes in the brain. I use response times as a proxy for effort, following Wilcox (1993) and Ofek et al. (2007). An agent’s effective effort is modeled as a Brownian motion with drift in which the drift rate represents the agent’s ability. Higher ability leads to faster accumulation of effective effort. The accumulated effective effort at a given time determines the probability to answer a question correctly. Correct answer yields utility that represents an agent’s motivation. Effort is costly, and the more time an agent spends on a task, the higher will be the accumulated cost of effort. The agent’s problem is to choose the optimal moment to stop the effective effort accumulation process. The solution to the agent’s problem takes the form of a threshold rule in terms of the accumulated effective effort. I derive a closed-form solution for the optimal threshold and show how it is related to ability and motivation. The parameters of the model can be estimated using the maximum likelihood method using the data on outcomes and response times from a series of trials of a cognitive task. The proposed estimation strategy can be viewed as a version of a threshold regression model used in survival analysis (Lee and Whitmore 2006). I conduct a laboratory experiment to illustrate the proposed approach and compare it to the traditional approach. In the experiment, subjects take a digit-symbol test (DST) in which they have to match symbols to digits. DST is designed to capture a subject’s processing speed, which underlies more complex cognitive functions. DST is used in the economics literature (Segal 2012; Dohmen et al. 2010) and in intelligence scales such as WAIS (Weiss et al. 2010). Subjects are free to choose how much time to spend on a task and are not extrinsically motivated for good performance. I estimate ability and motivation for each subject individually and use the structural model to perform a counterfactual simulation in which the only source of variation in performance is variation in ability. I find that performance is a noisy and biased measure of ability. Variation in ability can explain only 0.58 of the variation in observed performance. Subjects with relatively low ability have lower performance than they would have if performance were an unbiased measure of ability, while subjects with relatively high ability have even higher performance than they would have. Ranking subjects by performance leads to an incorrect ranking by ability 24% of the time. These results suggest that more care should be given when interpreting performance as cognitive ability since such an interpretation may be misleading. The present paper, however, should be viewed as a first step toward uncoupling ability from motivation on performance. More work is needed to understand how well performance approximates ability in other cognitive and real-effort tasks used in the literature. The main goal of the present paper is to provide the tools for this work and to illustrate the usefulness of choice-process data and process-based modeling in developing such tools.",4
5.0,1.0,Journal of the Economic Science Association,13 June 2019,https://link.springer.com/article/10.1007/s40881-019-00068-y,Do people exploit risk–reward structures to simplify information processing in risky choice?,August 2019,Christina Leuker,Thorsten Pachur,Timothy J. Pleskac,Female,Male,Male,Mix,,
5.0,1.0,Journal of the Economic Science Association,01 August 2019,https://link.springer.com/article/10.1007/s40881-019-00073-1,Correction to: Do people exploit risk–reward structures to simplify information processing in risky choice?,August 2019,Christina Leuker,Thorsten Pachur,Timothy J. Pleskac,Female,Male,Male,Mix,,
5.0,1.0,Journal of the Economic Science Association,28 March 2019,https://link.springer.com/article/10.1007/s40881-019-00062-4,Estimating the dynamic role of attention via random utility,August 2019,Stephanie M. Smith,Ian Krajbich,Ryan Webb,Female,Male,,Mix,,
5.0,1.0,Journal of the Economic Science Association,01 July 2019,https://link.springer.com/article/10.1007/s40881-019-00071-3,When the eyes say buy: visual fixations during hypothetical consumer choice improve prediction of actual purchases,August 2019,Taisuke Imai,Min Jeong Kang,Colin F. Camerer,Male,,Male,Mix,,
5.0,1.0,Journal of the Economic Science Association,26 July 2019,https://link.springer.com/article/10.1007/s40881-019-00074-0,Understanding decision processes in guessing games: a protocol analysis approach,August 2019,C. Mónica Capra,,,Unknown,Unknown,Unknown,Unknown,,
5.0,1.0,Journal of the Economic Science Association,09 May 2019,https://link.springer.com/article/10.1007/s40881-019-00065-1,\(\mu\)Cap: connecting FaceReader™ to z-Tree,August 2019,Leonard Doyle,David Schindler,,Male,Male,Unknown,Male,"In economics, conducting laboratory experiments to determine causal relationships has become increasingly fashionable over the last few decades. A large number of laboratory experiments are nowadays conducted using computers as a result of the spread of computerized laboratories at major universities and research institutions. Urs Fischbacher’s experimental software z-Tree (Fischbacher 2007) is very popular around the globe and is among the most-used experimental softwares, having been cited more than 8000 times as of 2019 according to Google Scholar. z-Tree is versatile and yet easy to learn—starting with version 3.5.0—users can even record the current time on the client machine. Part of z-Tree’s popularity is presumably due to its simplicity and the convenience of creating even complex experiments with only very little programming effort. The analysis of video footage created during these experiments, however, was relatively inconvenient so far, since the capability of z-Tree to interact with other software packages was limited until recently. For example, consider an experimenter interested in facial expressions of subjects after they observe a certain screen, for example a donation decision in a dictator game. To perform their analysis, experimenters so far needed to employ a software to record videos, create and export the time stamps (i.e., the times at which the events of interest occur) into z-Tree (using table dumpers)Footnote 1, and manually match time stamps and video footage in the program of their choice. It is apparent that these and similar methods might be very tedious to the experimenter, since they rely on manually repeating a large number of tasks. This might be especially burdensome if experimenters have to deal with a large number of subjects and sessions. One of these situations for example concerns the analysis of emotions using FaceReader™. FaceReader™ is a software package developed by the Dutch company Noldus (http://www.noldus.com), it analyzes facial expressions from photographs and videos with respect to six basic emotional states. The software lays a grid of more than 500 key points over images of each participant’s face and identifies emotions by distinct muscle movement that is associated with a change in emotions. According to Noldus, the software performs equally well as trained annotators in describing emotional states of subjects. Researchers in economics have recently started to use FaceReader™ to investigate how emotional states correlate with economic decision making. For example, Noussair and Nguyen (2014) investigate the role of emotions in decision-making under risk, and Breaban and Noussair (2017) look at emotions in the context of asset markets. Furthermore, van Leeuwen et al. (2017) investigate the relationship of anger and rejections in ultimatum games, and Breaban et al. (2016) describe a positive correlation between more negative states and greater prudence. \(\mu\)Cap is the first tool to allow experimenters to create a fully automated connection between z-Tree and FaceReader™ in a straightforward way. It is barely noticeable by subjects and imprecisions are kept very limited with only a few milliseconds delay. As we will point out later, \(\mu\)Cap can easily be implemented to improve experimenters’ work flow and has possible applications beyond its original purpose. \(\mu\)Cap has found first applications, such as Kugler et al. (2018), who use the tool to synchronize decisions from a trust game programmed in z-Tree with videos of participants’ facial expressions.",4
5.0,2.0,Journal of the Economic Science Association,12 December 2019,https://link.springer.com/article/10.1007/s40881-019-00082-0,Editors’ Preface: Trends in experimental economics (1975–2018),December 2019,Nikos Nikiforakis,Robert Slonim,,Male,Male,Unknown,Male,"The first issue of the Journal of the Economic Science Association was published in July 2015. Our editorial for that issue started with a “Welcome!” After 5 years as Co-Editors, the time has come to “pass on the torch” to a new set of editors. With this comes the inevitable desire to reflect on what has been achieved in this period, and the challenges that may lie ahead for our Association. In the preface of the first issue, we explained the need that led to the establishment of JESA as follows: “The main reason for establishing JESA is that experimental findings now feature prominently in leading journals, garner hundreds (sometimes thousands) of citations and influence economic theory and public policy. With this comes the need to evaluate the robustness as well as the internal and external validity of conclusions drawn from experimental data more carefully and extensively.” (Nikiforakis and Slonim 2015, p. 4). To back up this claim, among others, we presented data showing the evolution of experimental research published in the “top-5” economics journals (American Economic Review, Econometrica, Journal of Political Economy, Quarterly Journal of Economics, and Review of Economic Studies) between 1975 and 2014. The data illustrated the explosion in the number of experimental papers published during this 40-year period. However, they also captured an unexpected decline after 2010. Although the decline was substantial, it was not the first time a drop in the number of experimental papers published in the top-5 was observed. This led us to make the following comment: “[The evidence] also shows a drop in the number of lab experiments published in the past 4 years. The drop is due to a reduction in papers published in the American Economic Review. There are too few observations to determine whether this is a temporary drop such as that observed during 1991–1996 or a permanent drop.” (Nikiforakis and Slonim 2015, p. 3). Five years have passed since then, during which we oversaw the publication of ten issues for JESA. That may not sound like much, but it surely felt like it was many more. For our farewell editorial, we decided to explore whether the drop in experimental papers published in the top-5 was temporary or an early-warning signal of things to come.",6
5.0,2.0,Journal of the Economic Science Association,11 October 2019,https://link.springer.com/article/10.1007/s40881-019-00076-y,The digit ratio (2D:4D) and economic preferences: no robust associations in a sample of 330 women,December 2019,Elle Parslow,Eva Ranehill,Anna Dreber,Female,Female,Female,Female,"Testosterone has been hypothesised to be associated with a wide range of economic decision making. One aspect of this hypothesis is the theory that prenatal testosterone exposure impacts brain development and therefore can explain some of the heterogeneity in behaviour between individuals. A putative proxy for the level of prenatal testosterone exposure is the ratio of the length of the second digit to the length of the fourth digit (2D:4D) on each hand, as suggested by Manning et al. (1998). Subsequently, many studies have reported associations between 2D:4D and a variety of traits, such as sexual orientation, spatial ability and personality traits, although the results are often conflicting [and with some possibility of publication bias, see, e.g., Puts et al. (2008), Voracek and Loibl (2009), Grimbos et al. (2010), Voracek et al. (2011), but see Hönekopp and Schuster (2010) and Hönekopp and Watson (2011), who do not find evidence for publication bias]. Furthermore, a sizeable literature uses 2D:4D to explore the effect of prenatal testosterone exposure on economic decisions, also with mixed results. This paper aims to test hypotheses in previous papers in relation to the association between 2D:4D and risk taking, dictator game giving, and the willingness to compete. These preferences are relevant for explaining variation in many economic outcomes. We use a sample of 330 women—which is large given most sample sizes that have previously been reported—in an experiment to measure 2D:4D and economic preferences. Whilst the 2D:4D measure has been used in many studies, the link between prenatal testosterone and 2D:4D is not strongly established (McIntyre 2006). The oft-cited study by Lutchmaya et al. (2004), which indirectly investigates the link between 2D:4D and prenatal testosterone exposure, finds a statistically significant negative correlation in a sample of 29 children between the testosterone-to-estradiol ratio in amniotic fluid and right hand 2D:4D only, even after controlling for gender (the left hand is reported insignificant). An additional method of investigation is to compare same sex and opposite sex twins, based on the theory of sex-hormone transfer in utero (Miller 1994). van Anders et al. (2006) find that females with a male rather than female co-twin have lower left hand 2D:4D, which the authors argue is due to hormone transfer from male to female foetuses, however, they find no statistically significant results for the right hand. Whilst Voracek and Dressler (2007) in a similar study report a statistically significant result for mean 2D:4D, among studies with much larger sample sizes there is a failure to find statistically significant differences (Hiraishi et al. 2012; Cohen-Bendahan 2005; Medland et al. 2008).Footnote 1 In a study looking at umbilical cord androgen and estrogen concentrations and 2D:4D measured as young adults, Hollier et al. (2015) find no statistically significant association for either hand, using a mixed gender sample of 341 participants. Lastly, other methods of establishing a link between 2D:4D and androgen exposure both post- and peri-natally include using congenital adrenal hyperplasia (CAH) and the CAG repeat polymorphism (McIntyre 2006; Brown et al. 2002), and here also there is a mix of positive and null results. Even though the link between 2D:4D and prenatal testosterone is not well established, there are many papers investigating the association of 2D:4D with economic decision making. Whilst 2D:4D is an easy-to-measure way to proxy for prenatal testosterone exposure, many of these papers use multiple tests and have relatively small sample sizes. As far as we are aware, none of the previous studies pre-register their analyses. There are often multiple hypotheses involving different ways of measuring the explanatory variable (left hand, right hand, average of both hands or even squared 2D:4D), as well as which controls to include (such as gender, age or sexual orientation) and which subsamples to analyse (such as ethnicity and gender), giving rise to many ‘forking paths’ (Gelman and Loken 2013) and researcher degrees of freedom (Simmons et al. 2011). As discussed in Simmons et al. (2011), researchers have many options available in choosing among outcome variables, controls and subsample selection, creating ambiguity in the research process and potentially generating higher rates of false positives than 5%, even if researchers do not intend to do so. In our review of the literature in the following subsections, we consider statistically significant results to be cases where the p value is less than 0.05 and report anything above that threshold as insignificant, as is typically used. We present tables to summarise the results of studies that use comparable measures of economic preferences to our experiments.Footnote 2 However, in our own results in this paper, we instead consider a p value less than 0.05 to indicate suggestive evidence, whilst statistical significance requires a p value less than 0.005, following Benjamin et al. (2018). 
Benjamin et al. (2018) suggest a change in the p value defining statistically significant new discoveries from 0.05 to 0.005, to improve the reproducibility of scientific studies (in terms of reducing rates of false positives). The authors propose that where p values are below 0.05 but above 0.005, this should be interpreted as suggestive evidence. Whilst our study aims to be a replication of past studies, the results of past studies are mixed and therefore we think it is appropriate to use the more conservative 0.005 threshold for statistical significance. An additional motivation for a more conservative threshold than 0.05 is that we, following the existing literature, run several tests for each outcome measure. Several papers have looked at the relationship between 2D:4D and giving in the dictator game.Footnote 3 The dictator game removes any repercussions of failure to reciprocate (unlike the ultimatum game), and in all the below studies the participants were told that the recipient in the game is another participant whose identity is unknown.Footnote 4 The hypothesised relationship between 2D:4D and dictator game giving is positive, with higher exposure to testosterone (low 2D:4D) being associated with lower levels of dictator game giving. The results from studies using the dictator game are summarised in Table 1, showing that insignificant findings are common. When statistically significant, regressions using squared 2D:4D measures find an inverse U-shaped relationship between 2D:4D and dictator game giving (low dictator game giving is associated with both low and high testosterone). From the five previous papers summarised in Table 1, 2 out of the 43 total tests find statistically significant positive results, 1 out of 43 finds statistically significant negative results, 8 out of 43 find an inverse U-shaped relationship and 32 out of 43 find no statistically significant results (where here significance is \(p<0.05\)). While several review papers find that women are on average more risk averse than men, [see, e.g., Eckel and Grossman (2008), Croson and Gneezy (2009), Charness and Gneezy (2012)], there is also evidence from a meta-analysis by Nelson (2015) suggesting that the difference (in terms of effect size) is not very large. Nevertheless, there is a substantial literature looking into a biological explanation for this gender difference through prenatal testosterone exposure and the 2D:4D ratio. As far as we are aware, only one study finds an association between 2D:4D and risk tasking in men and not in women (Stenstrom et al. 2011). The hypothesis is that risk taking is negatively related to 2D:4D—higher testosterone exposure is associated with higher risk taking (and lower risk aversion). The results from studies using risk taking tasks are summarised in Table 2. We limit our analysis of the previous literature to the areas of financial or general risk taking. There are numerous ways to measure risk-taking in experimental tasks, as well as the digit ratio (such as by scanner, or calliper etc.), which can add measurement error. From the 18 previous papers summarised in Table 2, 1 out of the 109 total tests finds positive statistically significant results, 15 out of 109 find negative statistically significant results, and 93 out of 109 find no statistically significant results (significance here is \(p<0.05\)). Whilst there is evidence for gender differences in self-selection into competition (Niederle and Vesterlund 2007; Dariel et al. 2017),Footnote 5 there exists substantially less literature looking at the relation between prenatal testosterone exposure and willingness to compete, relative to the other economic preferences discussed. Given the gender differences observed in this scenario, the hypothesis tested in the existing literature is that higher testosterone is associated with higher competitiveness, leading to a negative relationship between 2D:4D and the willingness to compete. Table 3 summarises the results from previous studies. Out of the 10 total tests reported across previous studies, 2 find statistically significant negative results and 8 find no statistically significant results (here significance is \(p<0.05\)).",15
5.0,2.0,Journal of the Economic Science Association,05 July 2019,https://link.springer.com/article/10.1007/s40881-019-00072-2,Mental accounts and the marginal propensity to give,December 2019,David Clingingsmith,,,Male,Unknown,Unknown,Male,"We are all asked from time to time whether we would like to give money to others. Solicitations arrive by post and e-mail, friends seek sponsorship for charity runs and rides, and retail stores ask if we will donate to a charity as we check out. We respond to these requests in part by considering the income at our disposal. Our income come to us from a wide variety of sources, such as wages, bonuses, business profits, welfare benefits, tax refunds, rent, investment returns, gifts, gambling winnings, and so forth. Neoclassical theory holds that sources of income are fungible. What matters for choice is only the total amount.Footnote 1 By contrast, mental accounting holds that, because individuals view some kinds of spending as more appropriate for some sources of income than others, the sources of income as well as the total matter for choice (Thaler 1999). These two theories have contrasting predictions for how changes in income at the margin affect behavior. Neoclassical theory holds that while a marginal increase or decrease in income may affect choice, the source of that marginal change will not matter. Mental accounting holds that if the sources concerned are seen as more or less appropriate for the choice under consideration, then how choice changes will depend on the source of the marginal change in income. In short, neoclassical economics thus holds income to be perfectly fungible at the margin across sources, while mental accounting holds it to be infungible. While there are many potential sources of income that might be treated as different mental accounts, Thaler (1999) highlighted earned income and windfall income as sources that tend to be treated differently with respect to consumption. In particular, people tend to splurge on indulgences when they get a marginal increase in windfall income but not earned income. There is suggestive evidence that earnings and windfall might also be infungible where giving to others is concerned: Dictators give less on average if they earn their endowment than if they receive it as a windfall (e.g., Hoffman et al. 1994; Cherry 2001; Cherry et al. 2002; Cherry and Shogren 2008; Spraggon and Oxoby 2009; Cappelen et al. 2013). However, since designs in the dictator game literature measure average giving from one source at a time, they cannot provide the test of fungibility at the margin needed to comprehensively distinguish the mental accounting and neoclassical theories. To do so we need to modify the design so that there is variation in income at the margin from earnings and windfall. This paper experimentally investigates how the marginal changes in earned income and windfall income affects giving decisions. I recruited 1022 participants from an online labor market to take on the role of dictator or receiver. Dictators earned income via a real-effort task and/or were given windfalls. They then made a decision about how much of their income to give to receivers. The experiment answers two primary questions: (1) Do dictators treat earned and windfall income as fungible at the margin, as the neoclassical account would predict, or as infungible, as mental accounting would suggest? (2) Does behavior differ when both income sources are present at the same time than when only one source is present? Dictators were randomized into treatment cells that induced exogenous variation in both (1) whether and (2) how much income was accrued from earned and windfall sources. Treatment cells are partitioned into two groups that differ in the number of income sources. Dictators get either earned or windfall income in single-source treatments but get both in the two-source treatments. The design insures marginal changes in sources are not correlated with total income (see online appendix). Pooling the single and two-source treatments, I find that dictators are more generous with marginal windfall than marginal earnings, which is inconsistent with fungibility and supports the mental accounting view. Dictators gave 13% of a marginal windfall token and 5% of a marginal earned token. An interaction between earned and windfall income is negative and significant, which shows that dictators treat windfall and earned tokens as only partially rather than fully infungible. In other words, the marginal propensity to give from either source falls in the level of the other source, holding total income constant. Looking at marginal giving in the single- and two-source treatments separately complicates the picture. With only one source present, the marginal propensity to give from an additional token is 14% for windfall and 5% for earnings. With both sources present, the margins are 2% for windfall and 1% for earnings and are statistically indistinguishable. The infungibility in the pooled analysis is driven by the extensive margin of number of sources present. A follow-up experiment in which both sources are windfalls does not show this extensive margin effect, suggesting a qualitative difference in sources is necessary for it. Section 2 describes the design of the experiment and methods of analysis. Section 3 presents the results. In Sect. 4, I discuss the implications of my findings for the neoclassical and mental accounting theories with respect to giving.",1
5.0,2.0,Journal of the Economic Science Association,09 December 2019,https://link.springer.com/article/10.1007/s40881-019-00079-9,Expectations do not affect punishment,December 2019,Lucas C. Coffman,,,Male,Unknown,Unknown,Male,"This paper experimentally tests the hypothesis that punishment responds to expectations: The higher our expectations are relative to what someone actually does, we will punish a wrongdoer significantly more. Suggestive evidence for this idea comes from two related literatures: expectations-based reference dependence in economics as well as affective reasoning in moral psychology. Kahneman and Tversky (1979) proposed and showed utility is contingent on a reference point. Köszegi and Rabin (2006, 2007, 2009) have suggested this reference point is defined by “recent probabilistic beliefs about outcomes” that a stochastic outcome is evaluated according to its expected utility. The ensuing experimental literature, though perhaps mixed, suggests that higher expectations lead to an anticipated loss in utility that affects behavior.Footnote 1 We test how expectations affect decision-making in a moral setting. As with the reference-dependence literature, we are interested in the effect of expectations per se on decision-making. That is, moral expectations are partially formed by instrumental information—I think you will do X because X is normatively appropriate—so expectations should predict punishment. To avoid this confound, we create a paradigm that exogenously affects expectations while holding the choice set and intentions of the actors constant. Why might expectations affect moral decision-making? Imagine I am a third-party Punisher observing agent A deciding whether or not to be selfish toward agent B. I form beliefs about what A is going to do. Agent A then takes an action that fails my expectations; she is more selfish than I expected. First, if I believe agent B has similar expectations as myself, this disappointment has decreased her utility. The upshot is that if I punish A based on B’s utility, I will punish A more harshly. Second, if agent B’s welfare enters directly into my utility function, then my utility has decreased as a result of being disappointed. If I punish based on my own affective response to the situation, this disappointment may lead me to punish more harshly. There is support for this channel in moral Psychology, which suggests moral judgments are largely controlled by emotional reactions to situations.Footnote 2 If disappointment produces a negative emotional reaction, it may then be expected to increase punishment. This paper tests whether these ideas, from reference dependence and moral psychology, extend to the third-party punishment. This paper is not meant to be a test of these theories or results, which never explicitly claim to extend to our setting.",
5.0,2.0,Journal of the Economic Science Association,26 March 2019,https://link.springer.com/article/10.1007/s40881-019-00061-5,Design-features of bubble-prone experimental asset markets with a constant FV,December 2019,Christoph Huber,Parampreet C. Bindra,Daniel Kleinlercher,Male,Unknown,Male,Male,"Experimental design-features are important issues concerning methods for laboratory asset markets and are crucial for the interpretation of experimental results. From a methodological standpoint, the seminal design of Smith et al. (1988, \(\mathrm {\textsc {ssw}}\) henceforth) has been thoroughly examined over the last decades with evidence that seemingly small variations in the experimental design can matter a lot.Footnote 1 It has been argued that price bubbles in decreasing fundamental value (\(\mathrm {\textsc {fv}}\)) designs are a result of the mismatch between the asset’s \(\mathrm {\textsc {fv}}\) trajectory and subjects’ expectations of a non-decreasing price development (e.g. Smith 2010; Oechssler 2010). To circumvent this mismatch, experimental asset market designs with constant \(\mathrm {\textsc {fv}}\)s have been implemented more frequently in the last years (see e.g. Kirchler et al. 2015; Razen et al. 2017; Holt et al. 2017; Weitzel et al. 2018). With the increasing popularity of constant \(\mathrm {\textsc {fv}}\) designs, it is also increasingly important to examine the characteristics of such an experimental design. However, a methodological analysis for experimental settings with constant \(\mathrm {\textsc {fv}}\) regimes is missing at the moment. The goal of this paper is to investigate whether certain design-features can influence results in experimental asset markets with a constant \(\mathrm {\textsc {fv}}\) regime. We specifically examine the experimental asset market design put forward by Holt et al. (2017), which has increasingly been applied in the last years and has been shown to produce typical bubble-crash patterns (Giusti et al. 2016; Weitzel et al. 2018). We therefore employ a continuous double auction market for long-lived assets with dividend and interest payments, exogenous cash inflows, and a constant \(\mathrm {\textsc {fv}}\) trajectory.Footnote 2 In this setting we examine whether two seemingly irrelevant, experimental design-features affect experimental results: First, we manipulate the display of trading prices in the price chart during and after trading periods. While, in general, graphical distortions in information processing have been widely discussed (e.g. Tufte 1983; Beattie and Jones 1992), there is also evidence that in market settings already a different presentation of trading prices and the \(\mathrm {\textsc {fv}}\) prior to the experiment can influence experimental results. Cason and Samek (2015) for example find that the visual representation of trading prices—either displayed in a column of text or in a graphical display—leads to significantly different price levels. Huber and Kirchler (2012) demonstrate that bubble formation is significantly reduced when the \(\mathrm {\textsc {fv}}\) process is displayed in a graph instead of a table prior to the experiment. Baghestanian and Walker (2015) show that setting a visual anchor at the \(\mathrm {\textsc {fv}}\) in the price chart at the beginning of the experiment is sufficient to eliminate or to significantly reduce bubbles. These studies, however, are only concerned with decreasing \(\mathrm {\textsc {fv}}\) regimes. Regarding price charts in general, Lawrence and O’Connor (1993) argue that with smaller scales, prediction intervals get wider and the scale might influence subjects’ perception of variability. Huber and Huber (2019) confirm this intuition and report that the vertical axis scale strongly affects people’s risk perception such that price developments are perceived as riskier when the depicted line extends to the upper or lower borders of a chart. In a similar vein, we alter the vertical axes of price charts during trading across treatments. From a baseline treatment with a standard axis around the middle of the scale we derive two treatments by varying the scale to induce either a high or a low anchor. With these treatment variations, we can detect whether results are driven by seemingly irrelevant display choices and, thus, hint at confusion among subjects in this experimental setting. Second, we provide subjects with full information about the \(\mathrm {\textsc {fv}}\) trajectory which includes detailed explanations in the instructions and a training protocol prior to the experiment. We follow Caginalp et al. (2001), Dufwenberg et al. (2005), Ackert et al. (2006), Noussair et al. (2012), and Giusti et al. (2016), among others, in displaying the \(\mathrm {\textsc {fv}}\) development over time in a table. Here, we aim to rule out confusion among subjects as we provide information about the \(\mathrm {\textsc {fv}}\) upfront and for any given point in time during the experiment. This treatment builds on research that shows that unambiguity and common knowledge about the dividend structure and thereby about the \(\mathrm {\textsc {fv}}\) process is able to reduce bubbles (Lei and Vesely 2009; Kirchler et al. 2012; Cheung et al. 2014) in \(\mathrm {\textsc {ssw}}\)-like experimental asset markets. Finally, we want to stress that the treatment manipulations in this study address important experimental design choices every researcher has to make when designing a laboratory asset market experiment. On one side, we test how sensitive subjects react to different visual stimuli and, on the other, how sensitive subjects react to information about the \(\mathrm {\textsc {fv}}\) process. We observe significant overpricing and typical bubble-crash patterns in all treatments, though with differences of overvaluation across treatments. We find that overvaluation and typical bubble-crash patterns are reduced when prices are displayed in the upper third of the price chart and thereby induce a visual ceiling. While such a result hints at confusion about the \(\mathrm {\textsc {fv}}\) among subjects, surprisingly, we do not find subjects’ common knowledge about the \(\mathrm {\textsc {fv}}\) process to reduce overvaluation.",3
5.0,2.0,Journal of the Economic Science Association,09 November 2019,https://link.springer.com/article/10.1007/s40881-019-00077-x,Testing effects of loss framing and checklists: evidence from a field experiment on wellness program participation in Philadelphia,December 2019,Syon P. Bhanot,Christina A. Roberto,Mehra den Braven,Unknown,Female,Unknown,Female,"In the last 50 years, there has been a steady increase in the development and testing of behavioral interventions that use insights from psychology and economics to influence behavior and wellbeing (i.e., Ashraf et al. 2006; Thaler and Benartzi 2004). There are many behavioral insights that seem promising based on lab experiments; however, few of these have been extensively or rigorously evaluated in field settings. In this paper, we describe a field experiment designed to test the ability of two behavioral science tools—loss framing and presenting information in checklist format—to increase participation in the City of Philadelphia’s wellness program for employees and retirees. Workplace wellness programs are increasingly used to boost productivity, reduce absenteeism, and help employees make healthy choices (Baicker et al. 2010). A persistent challenge, however, is motivating employees to take part in these programs (Berry et al. 2010). The underutilization of wellness programs can have important financial and health consequences.Footnote 1 In Philadelphia, for example, the City government spends around $88 million on health insurance for administrative employees. The City of Philadelphia, as a self-insured entity, could decrease costs by increasing participation in the City’s wellness program. As a result, the City of Philadelphia, like many other employers, provides a financial incentive ($500) to encourage employees to complete the wellness program. Despite these incentives, over half of City employees still do not participate (with 56% non-completion in 2016). Our intervention tested the effect of two different behavioral interventions on participation in the City’s wellness program, by randomly varying the content of a postcard sent to City employees and retirees. First, we tested the effect of “gain” versus “loss” framing on participation using a visual message and text. This builds on prior research suggesting that the framing of decisions can influence choices (Tversky and Kahneman 1981), and in particular that individuals may be “loss averse,” meaning they have a greater psychological reaction to losses relative to equivalent gains (Kahneman and Tversky 1979). Though gain and loss framing has been extensively studied, almost all the existing work is in lab settings, with student populations (Lindenmeier 2008; Choi et al. 2012; Block and Keller 1995). Furthermore, successful field studies that use loss framing have involved structural changes to the incentive schemes individuals face. For example, both Hossain and List (2012) and Fryer et al. (2012) successfully leverage loss aversion through a motivational incentive scheme that provides money up front and “takes it away” if a goal is not achieved (instead of a “gain” incentive that provides money when a goal is achieved). We provide some of the first field evidence on a simpler manipulation, in which only the messaging used to motivate behavior change incorporates loss language, while the underlying structure of the incentive scheme remains unchanged. This manipulation is more “passive” than changing the structure of an incentive scheme, making it more practical and scalable if effective, as it is often not practically feasible to provide an upfront incentive that can be “taken away.” Additionally, we tested the efficacy of presenting information about the steps needed to complete the wellness program in a checklist format (with check boxes next to each step) versus listing the same information in bullet point format. Checklist formatting is theorized to encourage action by providing a clear visual display of the steps needed to advance through a multi-stage action (Boorman 2001). However, most existing work on checklists compares checklist formatting to the provision of no information at all (Clark et al. 2007; Haynes et al. 2009), which makes it difficult to determine if the checklist format influences behavior or if the key element is the easily digestible information provided in the checklist itself. By holding information constant, our work is the first to estimate the causal impact of the checklist format specifically. We worked with the City of Philadelphia’s Office of Human Resources to send postcards to 5235 of the City’s active employees and retirees in August 2017, encouraging them to complete the wellness program for the 2017 calendar year. We utilized a 2 × 2 experimental design, varying the framing of the messaging (gain versus loss) and the format of the information provided (checklist versus bullet point). We then used the City’s administrative data on wellness program completion for the remainder of the calendar year to assess the impact of our interventions. Our results provide no evidence that either condition, loss framing or checklist formatting, had a meaningful impact on wellness program participation. There is also very limited evidence of differential impacts for retirees versus employees. Note that because all participants in our study received a postcard, we cannot make causal claims regarding the impact of receiving a postcard (only about the content therein). These findings suggest that more “passive” behavioral interventions that require minimal effort on the part of the implementer, like framing and checklist formatting on a postcard, may not be sufficient to encourage behavior change in the domain of wellness programs. More intensive approaches, like varying the level of the financial incentive or substantially decreasing the hassle costs involved in completing the program steps have been found to be effective (Cuellar et al. 2017), and may offer more promise in such instances.",
5.0,2.0,Journal of the Economic Science Association,03 December 2019,https://link.springer.com/article/10.1007/s40881-019-00078-w,Trust and kinship: experimental evidence from rural India,December 2019,Yashodha,,,Unknown,Unknown,Unknown,Unknown,,
5.0,2.0,Journal of the Economic Science Association,24 November 2018,https://link.springer.com/article/10.1007/s40881-018-0060-7,Identifying discrete behavioural types: a re-analysis of public goods game contributions by hierarchical clustering,December 2019,Francesco Fallucchi,R. Andrew Luccasen III,Theodore L. Turocy,Male,Unknown,Male,Male,"The heterogeneity in decision-making behaviour observed in both field settings and their laboratory counterparts is by turns a great joy and a great frustration to practitioners of behavioural economics. The richness in the variety of individual behaviour is evidence that people are indeed different, and approach the same economic decision-making task in a variety of ways. However, parsimonious, practical, and tractable economic models try to capture the commonalities in behaviour. Extracting those commonalities from the embarrassment of riches offered by the data is an important challenge in the development of behavioural economics and game theory. One approach is to group behaviour into a small number of distinct types, which we refer to as a typology. In this paper, we will focus on the case of public goods voluntary contribution games (VCGs), for which Fischbacher et al. (2001) (FGF) have proposed one such typology, which groups participants into four types. We choose this as an interesting setting, because the P-experiment protocol introduced by FGF, based on the linear VCG (Ledyard 1997), has been employed as a standard methodology by many studies conducted in various languages and locations (Kocher et al. 2008). The analysis we conduct in this paper benefits from being able to re-use data from a number of studies using a sufficiently similar protocol. Although a number of papers have used variants of the FGF typology, the literature in experimental economics has not employed a framework for defining or evaluating candidate typologies. To address this, we introduce techniques from machine learning, in which exactly these types of classification problems have been studied in depth. Ideally, a typology represents the data well when the behaviours of two participants classified as the same type are similar, while the behaviours of two participants classified as different types are dissimilar. Machine learning provides methods for evaluating the trade-offs between within-type similarity and across-type dissimilarity and for constructing classifications which are optimal according to some criterion with respect to these trade-offs. Machine learning is commonly associated with data sets with large numbers of observations, a problem experimental economists rarely face. However, it also studies the organisation of multi-dimensional data. In the data we analyse, a participant’s type is determined based on a 21-dimensional conditional contribution strategy elicited by the P-experiment protocol. We use data from six previous studies using the P-experiment protocol to construct alternative typologies using hierarchical cluster analysis (Kaufman and Rousseeuw 1990). Our typologies differ from FGF in the organisation of conditionally cooperative participants. FGF propose to categorise these participants primarily into conditional cooperators and non-monotonic “hump-shaped” contributors. In contrast, cluster analysis identifies a group of strong conditional cooperators, centred on participants who match group contributions on a one-for-one basis, and a group of weak conditional cooperators, centred on those who match group contributions at approximately a one-for-two rate. Machine learning offers tools for visualising the properties of classifications of high-dimensional data, such as our behavioural typologies. We use silhouette analysis (Rousseeuw 1987) to assess the cohesion of types using both approaches, and illustrate that, in the FGF typology, participants grouped in the same type exhibit behaviours with heterogeneous consequences in the VCG. To be useful in understanding economic and strategic behaviour, the classifications in a typology should correlate with choices made by the same participants which are not used in the classification process. In the P-experiment, participants make two types of choices: conditional contributions, which are used in the classification, and unconditional contributions, which are not. Across our data set, FGF’s conditional cooperators and hump-shaped contributors do not differ in their unconditional contributions. In contrast, participants classified as strong conditional cooperators make generally higher unconditional contributions than those classified as weak conditional cooperators. This supports the strong/weak conditional cooperator distinction as being a more insightful description of the data and that the underpinnings of the behaviour of weak conditional cooperators may be distinct from those of strong conditional cooperators.",21
5.0,2.0,Journal of the Economic Science Association,13 June 2019,https://link.springer.com/article/10.1007/s40881-019-00069-x,True lies,December 2019,David Hugh-Jones,,,Male,Unknown,Unknown,Male,"Why does the GSV method produce narrow confidence intervals? We can get a clue by running the GSV method when there are 10 reports of “heads” out of 10 for a fair coin flip (\(R = N = 10, P = 0.5\)). The resulting point estimate is that 100% of subjects lied. The upper and lower 99% confidence intervals are also 100%. This is calculated as follows. First, given R reports of heads, the probability that a total of \(T\) “true” heads were observed is calculated as: This is the binomial distribution, truncated at R because by assumption, nobody “lies downward” and reports tails when they really saw heads. Next, from T the number of lies told is calculated as \(R - T\); and the proportion of lies told is: because \(N - T\) people saw the low outcome and had the chance to lie. Combining this with the truncated binomial gives a cumulative distribution function of Lies. This is then used to estimate means and confidence intervals. Putting these together, for \(R = N = 10\), the estimated distribution of Lies is calculated as follows: With probability \(\frac{1}{1024}\), there were really 10 heads. Nobody lied in the sample.Footnote 4 Otherwise, 1 or more people saw tails, and they all lied. The proportion of liars is 100%. Hence, the lower and upper confidence intervals are all 100%. There are two problems with this approach: one statistical, and one conceptual. First, if many heads are reported, you should learn two things. On the one hand, there are probably many liars in your sample. On the other hand, probably a lot of coins really landed heads. The probability distribution in Eq. (5) does not take account of this. For example, suppose we are certain that everyone in the sample is a liar who always reports heads. In this case, observing \(R = N = 10\) gives us no information about the true number of heads. The posterior probability that \(T = 10\) is then indeed 1/1024, the same as the prior. Now, suppose we know that nobody in the sample is a liar. Then on observing \(R = 10\), we are sure that there were truly 10 heads: the posterior that \(T = 10\) is 1. If exactly 5 out of 10 subjects are liars, then observing \(R = 10\) means that all 5 truth-tellers really saw heads. The posterior probability that \(T = 10\) is then \(1/32\), the chance that all 5 liars saw heads, and so on. When we are uncertain about the number of liars, our posterior that \(T = 10\) will be some weighted combination of these beliefs. Unless we are certain everyone in the sample is a liar, the probability that \(T = 10\) will be greater than 1 in 1024. Equation (5) is, therefore, not correct. In this case, it is equivalent to assume that everybody in the sample is a liar, whose report is uninformative about the true number of heads. One then uses the prior distribution of heads to estimate the proportion of those who actually saw tails and lied. Indeed, in the simulations with \(P = 0.5\) and across all values of \(\lambda\), the overall probability that there were 10 true heads, conditional on \(R = N = 10\), was about 1 in 161, not 1 in 1024. Fixing \(\lambda = 0.2\), it was about 1 in 4. This problem means that the GSV estimator of Lies is biased. In the “Appendix”, I show that the GSV estimator can have substantial bias, and performs worse than the naïve estimator from Eq. (1), \(\frac{R/N-(1-P)}{P}\). Also, the GSV confidence intervals do not always achieve nominal coverage of Lies. When the number of heads reported is either high or low, the percentage of confidence intervals containing Lies may fall below the nominal value. There is a second, more important problem. The GSV approach attempts to estimate Lies in Eq. (6). This is the proportion of lies actually told, among the subsample of people who saw tails. But we are not usually interested in the proportion of lies actually told. We care about the probability that a subject in the sample would lie if they saw tails—\(\lambda\) in Eq. (2). This \(\lambda\) can be interpreted in different ways. Maybe on seeing a tail, each person in the sample lies with probability \(\lambda\). Or maybe the sample is drawn from a population of whom \(\lambda\) are (always) liars, and \(1 - \lambda\) are truth-tellers. Lies has no interpretation in the population, because the rest of the population has no chance to tell a lie in the experiment. Lies can be treated as an estimate of \(\lambda\). It is unbiased: it estimates \(\lambda\) from the random, and randomly sized, sample of \(N - T\) people who saw tails. But it can be a very noisy estimate. Again, suppose 10 heads out of 10 are reported, and 9 heads were really observed. Lies is 100%. But it is 100% of just one person. This means that even the correct confidence intervals for Lies would not be correct for \(\lambda\). For example, if 3 out of 3 subjects report heads, the GSV software reports a lower bound of 100% for any confidence interval. Indeed, since anyone who had the opportunity to lie clearly did so, this is the correct lower bound (if we arbitrarily define Lies = 1 when \(T = N\)). But it makes no sense as a confidence interval for \(\lambda\): we clearly cannot rule out that one or two subjects truly saw heads, and would have reported tails if they had seen tails. Because of this problem, the GSV confidence interval coverage of \(\lambda\) is much worse than its coverage of Lies.The issue is especially serious when there are many reports of heads. In this case there were probably many true heads, so T is high and the true sample size \(N - T\) is low, making Lies a noisy estimate of \(\lambda\). Table 4 shows this. It splits the simulations by the proportion of reported heads, R/N. GSV coverage levels fall off sharply as R/N increases. Note that for fair coin flips, R/N is usually greater than 0.5, both in the simulations and in reality.",3
6.0,1.0,Journal of the Economic Science Association,14 December 2019,https://link.springer.com/article/10.1007/s40881-019-00081-1,Framing effects in the prisoner’s dilemma but not in the dictator game,June 2020,Sebastian J. Goerg,David Rand,Gari Walkowitz,Male,Male,Male,Male,"Countless papers have demonstrated that framing can affect behavior despite underlying information and options remaining the same (see recent reviews by Gerlach and Jaeger 2016; Cartwright 2016). But when and how precisely do frames change behavior? There is ample evidence in the literature suggesting that frames affect behavior in social dilemmas (e.g., Dufwenberg et al. 2011; Khadjavi and Lange 2015; Gächter et al. 2017b; Fosgaard et al. 2017). However, for dictator games, the evidence is mixed with some studies reporting significant differences (e.g., Korenok et al. 2014; Krupka and Weber 2013), while others do not (e.g., Grossman and Eckel 2015; Gächter et al. 2017a). Hence, based on the literature, it seems that framing effects are more pronounced and robust in public good games than in dictator games. However, most of the aggregated evidence is based on studies that use different designs and, for example, vary subject pools, efficiency gains, number of repetitions, and numbers of players. With this paper, we attempt to compare the impact of framing in social dilemmas and dictator games by making the different classes of games and the conducted experiments as similar as possible. We run experiments with two-person social dilemma gamesFootnote 1 and dictator games in the same subject pool, apply give and take frames without loaded language, and introduce comparable efficiency gains for generosity or cooperation. We observe that give and take frames influence subjects’ behavior and beliefs significantly in our social dilemma games but not in the dictator games. Without additional assumptions, most theories of other-regarding preferences (e.g., Fehr and Schmidt 1999; Bolton and Ockenfels 2000; Charness and Rabin 2002) predict no differences between two frames of the same decision problem. Yet, simply naming a prisoner’s dilemma game “Community Game” or “Wall Street Game” influences cooperation rates significantly, with higher cooperation under the first frame (e.g., Liberman et al. 2004). Engel and Rand (2014) observe significantly more cooperation in prisoner’s dilemma games with a cooperative frame compared to a competitive frame and show that behavior in a neutral frame follows the behavior of the cooperative frame. Ellingsen et al. (2012) argue that social frames, like naming a game, provide a coordination device helping to select between multiple equilibria with social preferences. They support this account by showing framing effects in simultaneous but not sequential prisoner’s dilemmas. Another common form of framing is valance framing which describes the identical strategic decision as a decision to take or give a certain amount. In repeated public good games, higher contributions are usually observed in the give frame (e.g., Andreoni 1995; Sonnemans et al. 1998; Willinger and Ziegelmeyer 1999; Cookson 2000). However, the size of the framing effect might differ between subject pools (Goerg and Walkowitz 2010). Investigating valence and social frames in one-shot public good games, Dufwenberg et al. (2011) demonstrate that frames affect not only subjects’ contributions but also their first- and second-order beliefs. Cox et al. (2013) argue, based on revealed altruism (Cox et al. 2008), that positive and negative frames result in different games with different degrees of expected reciprocity. Similarly, Gächter et al. (2017b) observe that people seem inclined to cooperate more when establishing a common resource compared to maintaining it. They argue that this finding can be explained by the share of conditional cooperators and their beliefs about cooperation which are influenced by the give and take frames. If framing effects are at least partially caused by beliefs about strategic behavior, they should be weaker in games without strategic interaction. However, no clear picture emerges from the literature on framing effects in dictator games.Footnote 2 Dreber et al. (2013) observe no significant effects of social frames on generosity. Investigating give and take frames for donations to charity, Grossman and Eckel (2015) conclude that generosity is not influenced by the frame. Cartwright and Ramalingam (2019) observe no significant differences between average levels of generosity. However, framing affects the distributions and the take frame leads to more extreme contributions with greater free riding. Gächter et al. (2017a) demonstrate that framing influences individuals’ perceptions of norms on fair sharing but not on actual generosity in the presence of peers. Other studies extend the action set of the dictator games into both domains with the choice to give or take being present at the same time (Bardsley 2008; List 2007). Korenok et al. (2014) show for such games that giving is not equivalent to not taking. Krupka and Weber (2013) compared a standard dictator game with a bully version where both options of giving and taking were available. Outcomes that result from giving under the standard frame of the dictator game are considered more socially appropriate than the same outcomes resulting from taking in the bully game. Strong framing effects are reported by Capraro and Vanzo (2019). In their extreme dictator games, the dictator chooses between two options: $0.50 for the dictator and $0 for the recipient or vice versa. The decisions are framed with words having different connotations. Generosity is higher if the decision is framed as one of stealing or taking compared to giving and donating. Similar effects can be observed in the trade-off game (Capraro and Rand 2018; Tappin and Capraro 2018). There, players unilaterally determine the payoffs for themselves and two others by choosing either an equitable or an efficient option. Framing options as, e.g., equalize, fair, or do good, result in significant framing effects. To summarize, across different designs and frames, there is ample evidence that framing affects behavior in social dilemmas. However, in dictator games, the evidence is mixed with some studies reporting framing effects, while others do not. Yet, most of the designs are not directly comparable, especially between the papers investigating social dilemmas and the ones investigating dictator games. In the following, we try to bridge this gap and investigate framing effects in social dilemma games and dictator games within a comparable framework. Our give and take frames are based on a neutral description of the situation and our experiments are all conducted within the same subject pool.",5
6.0,1.0,Journal of the Economic Science Association,22 February 2020,https://link.springer.com/article/10.1007/s40881-020-00083-4,Pronoun drop and prosocial behavior: experimental evidence from Japan,June 2020,Tai-Sen He,Yohanes E. Riyanto,Katsunori Yamada,Unknown,Unknown,Male,Male,"Since Chen’s (2013) seminal study, a growing body of literature in economics has been devoted to exploring the effects of language on economic decision-making. This literature is motivated by the Sapir–Whorf linguistic relativity hypothesis, which posits that the language we speak shapes our thoughts and decisions.Footnote 1 Most of these existing economic studies focus on the link between the use of future tense and speakers’ future-oriented behavior (Chen et al. 2019; Falk et al. 2018; Pérez and Tavits 2017; Sutter et al. 2018). In this study, we turn to another facet of linguistic structure and investigate the effects of “pronoun dropping” (hereafter, “pro-drop”) on one’s pro-sociality, with a focus on the first-person pronoun “I.” Linguists classify a language as pro-drop if speakers can omit pronouns in a sentence. We consider two competing hypotheses regarding how speaking a pro-drop language affects pro-sociality. The first hypothesis is generally accepted in the existing literature, pioneered by Kashima and Kashima (1998). They proposed that the linguistic licensing of pronoun drop, particularly the omission of the first-person pronoun, is linked to the psychological differentiation between the speaker and the context of speech. Explicit use of the pronoun “I” reminds the speaker of his or her independent self, whereas its absence reduces the speaker’s sense of self. They predicted that speakers of pro-drop languages would think less frequently about themselves, exhibiting a lower level of individualism (more pro-social).Footnote 2 Kashima and Kashima (1998) examined this relationship across 39 languages spoken in 71 cultures and found that cultures with pro-drop languages (e.g., Japanese and Chinese) tended to be less individualistic than those with non-pro-drop languages (e.g., English).Footnote 3 Since the publication of this seminal study, the findings have been well received in psychology and economics. Later studies reported consistent findings and extended the pro-drop effect to include other dimensions, such as a country’s economic performance (Kashima and Kashima 2003), human capital accumulation (Feldmann 2019), governance norms (Licht et al. 2007), and overall quality of government institutions (Tabellini 2010). An alternative view is that the first-person pronoun “I” is a double-edged sword, opening the possibility that people tend to become more pro-social when they use first-person pronouns. In other words, the first-person pronoun activates one’s central values and enhances one’s inherent social-value orientation (Utz 2004). This self-activation hypothesis predicts that inherently pro-social individuals primed with the first-person pronoun will exhibit a higher level of pro-sociality than those not primed.Footnote 4 These two strands of psychological literature share a similar design caveat from an economist’s perspective. Their measures of individualism are based on hypothetical survey responses rather than incentivized choices, raising potential external validity issues. Moreover, Kashima and Kashima’s (1998) study and others like it are mainly based on cross-cultural or linguistic comparisons; however, this empirical strategy prevents researchers from distinguishing the influence of the linguistic rule from the role of cultural differences that extend beyond linguistic differences. In the present study, we moved toward establishing a causal relationship between the two variables using an incentivized experiment. Different from psychological studies on pro-social behaviors, we followed the standard experimental economics procedure to properly incentivize subjects’ decisions using monetary incentives when eliciting their social preferences. In principle, a monetary incentive may reduce one’s degree of pro-sociality by making self-interest more salient. From a methodological viewpoint, it is also important to note that, as in Utz (2004), our study was conducted entirely in the monolingual and monocultural context of Japan, and we investigated within-country differences of pro-sociality caused by dropping the first-person pronoun. The literature stemming from Kashima and Kashima (1998) focused predominantly on the cross-cultural differences of pro-sociality due to differences between countries’ languages. In contrast, we examined the effect of the pro-drop rule on pro-sociality through the dropping of the pronoun “I” during communication in a decision-making task, using a single language that allowed the retention or omission of the pronoun. This experimental design allowed us to bypass the challenge of isolating the effects of language on decision-making and behavior from those caused by differences in cultural background.Footnote 5 Our investigation into the causal effects of language with respect to pro-sociality was conducted by randomly sorting our subjects into two experimental conditions. Pro-sociality was measured using Murphy et al.’s (2011) social-value orientation (SVO) task. In this task, subjects act as dictators and make decisions about allocating money to an anonymous beneficiary. The instruction reads, “I receive x JPY. The other receives y JPY,” where x and y are assigned real values and varied within and across rounds. We systematically manipulated the use of the first-person pronoun “I” in the questionnaire by taking advantage of the fact that Japanese is a pro-drop language. In one condition, we omitted all first-person pronouns in the entire SVO task (“without-I” condition). In the other condition (“with-I” condition), all first-person pronouns were included. We found that the presence of the first-person pronoun significantly impacts social decision-making in the SVO task. However, our results do not seem to be aligned with the previous cross-cultural and linguistic research, including that of Kashima and Kashima (1998). On the contrary, our respondents become more pro-social in the “with-I” condition. We also found that the effects of pro-drop are more pronounced among those who are older or more educated. To further ensure that our results were due to the self-activation mechanism induced by the repeated use of the first-person pronoun in the task, we conducted a follow-up study and successfully refuted an alternative explanation that Japanese subjects may perceive the omission of “I” as being careless or impolite, thus behaving less pro-socially in the pro-drop condition.",
6.0,1.0,Journal of the Economic Science Association,27 February 2020,https://link.springer.com/article/10.1007/s40881-020-00084-3,The intuitive cooperation hypothesis revisited: a meta-analytic examination of effect size and between-study heterogeneity,June 2020,Amanda Kvarven,Eirik Strømland,Kristian Ove R. Myrseth,Female,Male,Male,Mix,,
6.0,1.0,Journal of the Economic Science Association,19 April 2020,https://link.springer.com/article/10.1007/s40881-020-00085-2,I care what you think: social image concerns and the strategic revelation of past pro-social behavior,June 2020,Ferdinand A. von Siemens,,,Male,Unknown,Unknown,Male,"Field and laboratory experiments suggest that people strategically manipulate and, therefore, consciously care about their social image. Social image concerns seem to influence a wide range of behaviors, such as charitable giving, workplace conduct, voting, consumption choices, financial decisions, and investments in education, see Soetevent (2005), Falk and Ichino (2006), Andreoni and Bernheim (2009), Ariely et al. (2009), Mas and Moretti (2009), and the survey by Bursztyn and Jensen (2017). However, almost all existing studies on social image concerns use the same empirical identification strategy: they argue that people care about their social image, because they change their behavior under the scrutiny of a human audience. 
Bursztyn and Jensen (2017) argue that changing observability might change behavior through channels other than social image concerns. These channels could be privacy concerns, social learning, externalities, and concurrent changes in the decision environment. Observability might also influence behavior by making social norms more salient, see Mazar et al. (2008), or by increasing self-awareness, see Diener and Wallbom (1976) and Falk (2017). Rather than looking at how exogenously imposed observability changes behavior, the present paper investigates whether people themselves want to vary observability of their own past actions. The experiment thereby tests whether people deliberately and consciously control the flow of information to others and thereby their pro-social reputation. In the treatment “Altruism,” participants interact face-to-face with their neighbor. They then make a private charitable donation. Participants are next assigned a color: green if they donated more than two randomly determined other participants, red if they donated less, and otherwise yellow. Participants then determine at some cost the probability with which they reveal their color to their neighbor. Finally, participants learn the color of their neighbor with the probability determined by the latter. Colors in Altruism convey by design certain information: green indicates more pro-social past behavior than yellow, which in turn suggests more pro-social behavior than red. If participants consciously care about their social image, they should set a high revelation probability if assigned green, an intermediate probability if assigned yellow, and a low probability if assigned red. The data show that participants systematically condition their revelation probabilities on colors in Altruism. Average revelation probabilities are 57% for green, 50% for yellow, and 46% for red. However, this is not enough to conclude that people consciously care about their social image for two reasons. First, participants might somehow respond to the experimental procedures and instinctively want to hide colors with common negative connotations. Second, color assignment in Altruism is endogenous, because it depends on past pro-social behavior. Due to unobservable characteristics, participants who behaved pro-socially might also set a high revelation probability, for example, because pro-social participants also value transparency. Pro-social participants are typically assigned favorable colors. Colors and revelation probabilities are then correlated, although participants do not care about their social image. The paper pursues two empirical approaches to deal with this potential endogeneity problem. First, it compares behavior in Altruism and a control treatment “Random”. This control treatment Random is identical to Altruism, with the only difference that colors in Random are randomly assigned and thus reveal no information on past pro-social behavior. If participants strategically want to manipulate their social image, they should condition revelation probabilities on colors only in Altruism but not in Random. Average revelation probabilities in Random are essentially 50% for all three colors. Second, regression analysis can tackle the potential endogeneity problem by controlling for the pro-social behavior of participants. Such regression analysis is possible, because assigned colors do not only depend on the donations but also the pro-social behavior of the randomly composed reference groups. Participants with the same donation are consequently sometimes assigned different colors. See Eil and Rao (2011) for a similar approach studying the effect of positive and negative feedback on self-image. Statistical analysis confirms that participants in Altruism condition revelation probabilities on colors, also when controlling for pro-social behavior. The present experimental paradigm can be easily adapted to study social image concerns in almost any domain. A third treatment “Trustworthiness” illustrates the portability of the design. Participants are assigned colors conditional on their relative trustworthiness in a trust game. If participants care about their social image concerning their trustworthiness, they should condition revelation probabilities on colors. Average revelation probabilities are 64% for green, 56% for yellow, and 45% for red. Participants consciously want to convince others not only of their altruism but also of their trustworthiness. The present paper complements a small number of papers that look at how people want to manipulate the observability of their past behavior. DellaVigna et al. (2017) study whether people want to talk to others about past voting behavior. Eriksson et al. (2017) find that participants in a laboratory experiment pay to avoid public exposure of the least performer in their group. Bursztyn et al. (2018) show that people pay more for credit cards which can signal high income and that demand for these credit cards drops if they become available to lower income groups. Holm and Samahita (2018) document that people are willing to incur costs to manipulate whether information on their contribution to a public good is published on the web. These papers conclude that people care for their social image, because they spend material resources to control whether past behavior is revealed to—or discussed with—others. The results of the present paper point in the same direction. Apart from confirming the importance of social image concerns, the present paper makes two contributions to the existing literature. The first contribution is more methodological: only the present paper generates exogenous variation in the information people might want to reveal or hide. As argued before, if unobservable characteristics drive both pro-social behavior and subsequent information revelation, the observed correlation might be unrelated to social image concerns. For example, people who contributed a lot to the public good in Holm and Samahita (2018) might also have a preference for being transparent. In the present paper, even very pro-social participants are sometimes assigned an unfavorable color. Controlling for past pro-social behavior—and comparison to the treatment Random—allows eliminating any potential endogeneity problem by design. Concerning the second contribution, the present experimental paradigm provides new information on what exactly people want to signal. The current data tentatively suggest that people like to reveal high altruism but do not care so much for hiding low altruism; and that they want to hide betrayal rather than show off trustworthiness. Just varying observability cannot detect such subtle mechanisms of social pressure. The reason is that people acting under scrutiny can both reveal positive and hide negative characteristics only by changing behavior in the same direction, for example, by making a higher donation. But as Bursztyn and Jensen (2017) argue, future insights into the precise mechanisms of social image concerns and social pressure could provide valuable information for the design of effective public policies, organizational structures, and incentive systems.",1
6.0,1.0,Journal of the Economic Science Association,27 July 2020,https://link.springer.com/article/10.1007/s40881-020-00091-4,"Do negative economic shocks affect cognitive function, adherence to social norms and loss aversion?",June 2020,Francesco Bogliacino,Felipe Montealegre,,Male,Male,Unknown,Male,"In both developed and developing countries, it is common for households to face sudden negative changes to their income and wealth. Economists call these Negative Economic Shocks (NES). They can occur in the form of either Negative Income Shocks (NIS), when income flows such as earnings are negatively affected by an event, or Negative Wealth Shocks (NWS), when the value of accumulated assets is reduced. We wish to understand how negative income and wealth shocks affect cognitive function, whether this cognitive toll affects preferences toward risk in the loss domain and cheating, and whether asset or earning losses have similar consequences (to date they are treated interchangeably in the literature). To address these questions, we perform an incentivized controlled experiment. We randomly induce NIS and NWS to participants, by altering either the pay rate of a two-round Real Effort Task (RET), or the accumulated earnings from the first to the second round. We then measure fluid intelligence, short-term memory, cheating, and loss aversion. Cognitive function is the ability to process information to perform the tasks of reasoning, comprehension and learning, and which require a reliance on processes that are neither automatic nor based on instinct (Baddeley and Hitch 1974; Diamond 2013). It is recognized that the human cognitive system has a limited capacity (Kahneman 2011). As a result, differences in cognitive function determine the capacity for information processing and the performance of subjects in decision tasks. NES are expected to act as a cognitive load. This is consistent with the findings of Mani et al. (2013), who find that inducing scarcity in the lab through priming financial worries or exploiting a natural variation of income for sugarcane farmers—due to having to queue for the product to be processed—reduces cognitive function. A similar finding is in Bogliacino et al. (2017), where exposure to violence—associated with NES—shows a reduction in cognitive control and short term memory. Dishonesty is a moral infraction motivated by a personal or group advantage or the reduction of a potential harm. Using incentivized tasks (e.g., Fischbacher and Föllmi-Heusi 2013), experimental economists study situations in which a subject can increase her payoff by lying or deceiving. These tasks have shown to be externally valid (Dai et al. 2018). We are interested in cheating because it does not depend on strategic consideration and has a clear social norm associated with it. A social norm is a behavior whose choice by the agent is causally affected by beliefs over what others will do (empirical expectations) and what others think should be done (normative expectations) (Bicchieri 2017). Shocks can increase cheating, because they may shift either normative or empirical expectations, or because—to the extent that adherence is a pro-social behavior, which is a normal good—losses alter the opportunity cost of being pro-social, or because they change the relative magnitude of costs and benefits of the action, as predicted by rational models (Becker 1968; Ehrlich 1973). In fact, cheating can be less costly when people have to face losses, which could potentially explain why shocks are associated with anti-social behavior (Aksoy and Palma 2019). Loss aversion is the cornerstone of the Prospect Theory model of Kahneman and Tversky (1979). Broadly speaking, it refers to assigning a larger weight to losses from a reference point, with respect to gains of equal magnitude when making decisions (Fox and Poldrack 2009). By making a loss salient, NES may shift risk preferences in the loss domain. This is consistent with the results of Pammi et al. (2017). Moreover, subjects facing losses in the lab are more likely to show present bias and hyperbolic discounting (Haushofer et al. 2013), which is correlated with loss aversion (Dean and Ortoleva 2019). The current literature on shocks does not properly distinguish between income and asset shocks. Looking at the separate and joint effects of income and asset shocks is our first contribution. To the best of our knowledge, this is the first paper that explicitly looks at the cognitive impact of shocks, using experimental manipulation and not natural exogenous variation. Additionally, we analyze whether negative shocks, and the cognitive load induced by them, drives behavioral change, for which evidence is lacking in the literature (Kremer et al. 2019). Finally, by analyzing dishonesty, we provide the first experimental evidence on whether shocks induce anti-social behavior, whereas most of the existing literature is quasi-experimental.",7
6.0,1.0,Journal of the Economic Science Association,01 September 2020,https://link.springer.com/article/10.1007/s40881-020-00093-2,Facilitating efficient coordination in large groups: small incentive payments in nested groups,June 2020,Yohei Mitani,Kohei Suzuki,,Male,Male,Unknown,Male,"Tacit coordination on the payoff-dominant equilibrium is extremely challenging to achieve for large groups in laboratory experiments (Devetag and Ortmann 2007). To overcome large-group coordination failures, previous studies using a minimum effort game have proposed mechanisms that benefit from efficient coordination initially achieved in very small groups. Weber (2006) shows that large groups can coordinate when groups start small and more players are gradually added. Riedl et al. (2016) find that giving players in large groups the freedom to choose neighbors resolves coordination failures. While these studies provide significant insights into better understanding how large groups can possibly achieve efficient coordination, they do not address the question of how to take advantage of the group structures that exist in many real-world organizations. Our starting point is the observation that most real-world groups or organizations contain multiple smaller groups (e.g. work units within firms, departments within universities, assembly lines in factories, core units within football teams). For example, a large firm like Continental Airlines comprises multiple work groups of employees. The firm-wide performance depends on coordinated efforts among all employees in the firm, while work-unit level performance is also separately observable. This paper addresses the question of whether reallocating a small part of a firm-wide bonus to rewarding work-unit level performance improves firm-wide performance. We refer to the larger grouping (i.e. firm) in this nested structure as the global group and the smaller groups (i.e. work units) that it contains as local groups. In our Stag Hunt game, we construct hierarchical groupings containing three local groups of three members nested in a nine-member global group (Fig. 1).Footnote 1 Group composition with three local and one global group In our Baseline (BL) treatment, subjects in a group of nine choose between a risk-dominant (RD) strategy yielding a fixed payoff and a payoff-dominant (PD) strategy that returns a higher payoff if at least six group members choose the PD strategy or a much lower payoff if fewer than six group members choose the PD strategy (Heinemann et al. 2009). Our Nested Frame (NF) treatment differs from the BL only in that each subject also belongs to a local group, in which she receives extra local-level information feedback. In short, a subgroup is assigned in the NF, though the payoff structure is identical to the BL. A further Nested Incentive (NI) treatment employs the same group structure and information feedback as the NF, but its payoff structure slightly differs. In this treatment, players are offered a non-salient reward for achieving three-member local coordination. We use “non-salient” in the sense that the reward is too small to change the equilibrium strategy. The literature shows that the use of additional non-salient rewards facilitates successful coordination in minimum-effort games (Brandts and Cooper 2006a; Hamman et al. 2007). The novelty of our treatment is that we hold the total payment size constant and do not use any additional incentives compared with the BL and NF. Instead, the NI slightly reduces the reward for achieving nine-member global coordination and reallocates the same amount to successful local coordination as a non-salient incentive. Importantly, our design guarantees that when both local and global coordination is achieved, the incentives in the NI coincide with those of the BL and NF. The aim of this paper is to investigate the effectiveness of shifting a small part of the reward from global coordination to local coordination to lead to successful coordination in the global group. To address this question, we compare the NI with the NF, where the group structure is held constant and the only difference lies in the incentive structure. The literature suggests that our non-salient rewards might facilitate efficient coordination in large groups by reducing the relevant group size (Devetag and Ortmann 2007) and deviation costs (Goeree and Holt 2005). Even though it is not clear how subgroup assignments and extra localized information feedback affect successful global coordination in the NF,Footnote 2 rewarding local-group coordination in this group structure may increase the salience of small-group coordination in the NI, which would reduce the relevant group size. Group size influences coordination requirements and previous experiments with minimum effort games show a robust and strong effect of smaller group size on the likelihood of achieving efficient coordination.Footnote 3 At the same time, incentive payments for local-group coordination also reduce deviation costs of choosing the PD strategy in large-group coordination games, given that local coordination is achieved. Furthermore, these changes may affect players’ beliefs about their own and other group members’ actions if they realize that local and global coordination goals do not conflict but complement each other. In addition, under this circumstance, localized information feedback might help mutual monitoring within a local group. Our results indicate that shifting incentive payments to local-group coordination can be effective at improving the efficiency of large-group coordination, whereas nested grouping alone does not mitigate coordination failures.",
6.0,1.0,Journal of the Economic Science Association,22 September 2020,https://link.springer.com/article/10.1007/s40881-020-00094-1,On the effect of anchoring on valuations when the anchor is transparently uninformative,June 2020,Konstantinos Ioannidis,Theo Offerman,Randolph Sloof,Male,Male,Male,Male,"A wealth of evidence has accumulated questioning some of the foundations of expected utility theory, and behavioral theorists have shown how these challenges can be accommodated (Wakker 2010). At the core of standard and behavioral economic modelling remains the assumption that people are endowed with well articulated and stable preferences. This fundamental assumption, however, has been challenged amongst others by Ariely et al. (2003), who have shown that preferences are initially malleable by normatively irrelevant anchors. People subsequently choose consistently with these initial preferences, and thereby end up with preferences that are characterized by what Ariely et al. (2003) call “coherent arbitrariness”. For a series of products that range from familiar (like an average bottle of wine) to unfamiliar (like listening to an unpleasant sound), they find substantial anchoring effects.
 Economists often assign less weight to behavioral anomalies when they are obtained in non-repeated individual decision-making tasks. The line of reasoning is that anomalies may be eroded when people have relevant experience, for instance, as a result of trading in markets. To counter such skepticism, Ariely et al. (2003) included a treatment where subjects, after being exposed to an anchor, submitted a bid to avoid listening to an annoying sound. In the uniform-price sealed-bid auction, the three lowest bidders had to listen to the sound and each of them received a payment equal to the fourth lowest bid. Like in the individual decision-making treatment, sizable (and lasting) anchoring effects were observed in this treatment. This paper aims to make two contributions. A first contribution is that we investigate the effects of uninformative anchoring on valuations for a familiar good in a large sample. This is important because previous papers have provided mixed evidence, from sizable anchoring effects (Ariely et al. 2003) to no anchoring effects (Fudenberg et al. 2012). Our paper stands out because of the combination of two features. First, we have a large sample of 316 subjects who are all exposed to the same anchoring protocol, while previous studies have often been based on rather small samples. Second, we use a transparently random anchor that subjects know to be uninformative because they generate it themselves with a ten-sided die. A second contribution of our paper is that we investigate how elicited preferences are affected in a richer market setting than the one of Ariely et al. (2003), where subjects could not learn from others’ bids during the auction. We employ a standard double auction where traders are continuously updated about other traders’ bids and asks. We believe that a double auction provides a much better chance for market forces to erode initial traces of anchoring. Our experiment consists of three phases. In the first phase, we apply a typical anchoring protocol: we ask whether subjects are willing to sell a bottle of wine for an individually drawn, random price. Then we elicit their valuation (Willingness-To-Accept) for the bottle of wine with the Becker–DeGroot–Marschak (BDM) procedure (Becker et al. 1964). In the second phase, we randomly assign subjects to either a small double auction market (n = 2) or a large double auction market (n = 8). Subjects participate in two trading periods, once as a buyer and once as a seller. In the third phase, we elicit each subject’s valuation once more. The first phase of the experiment allows us to test whether a random anchor influences elicited valuations. We hypothesize that subjects’ valuations correlate positively with their anchors. We further conjecture that market experience will affect subjects’ elicited preferences. Subjects who are not completely sure about their preference may move into the direction of the preferences exhibited by other traders. This way, anchoring effects may diminish or even disappear. Thus, we hypothesize that the valuations elicited in the third phase will exhibit smaller (if any) anchoring effects. We also hypothesize that the large market will have a stronger effect on subjects’ preferences than the small market, and that anchoring effects are eroded more efficiently in the former. Contrary to our first hypothesis, we observe no effect of the random anchor on subjects’ valuations. We believe our null result contributes to the literature on the robustness of anchoring effects. In Sect. 4, we position our paper in the literature and elaborate on what we can learn from our null result. There, we discuss the results of a concise meta-analysis of experimental papers that cite Ariely et al. (2003) and investigate the effects of anchoring on preferences. We do find support for the idea that market participation affects how people value the bottle of wine. The variance in subjects’ elicited valuations after the market shrinks within trading groups. As expected, the effect of other traders’ behavior on a subject’s preference is stronger in the large market. These results underline the potential power that markets may play in eroding individual biases and noise. However, in this study, the double auction is not needed to avoid anchoring effects on valuations. The remainder of the paper is organized as follows. Section 2 describes our experimental design and the hypotheses to be tested. Section 3 presents the results of the experiment. Section 4 provides a discussion of how our results fit in the literature.",8
6.0,1.0,Journal of the Economic Science Association,27 June 2020,https://link.springer.com/article/10.1007/s40881-020-00087-0,LIONESS Lab: a free web-based platform for conducting interactive experiments online,June 2020,Marcus Giamattei,Kyanoush Seyed Yahosseini,Lucas Molleman,Male,Unknown,Male,Male,"A rapidly growing number of behavioural researchers use online experiments to study human decision-making. Online labour markets, such as Amazon Mechanical Turk (MTurk; www.mturk.com) and Prolific (www.prolific.co), allow researchers to conveniently recruit participants for experiments and compensate them for their efforts. The quality of data from online experiments is generally deemed comparable to data obtained in the laboratory (Berinsky et al. 2012; Buhrmester et al. 2011; Hauser and Schwarz 2016; Mason and Suri 2012; Paolacci and Chandler 2014; Paolacci et al. 2010; Snowberg and Yariv 2018; Thomas and Clifford 2017; but see Hergueux and Jacquemet 2015), making online experimentation a promising complement to laboratory research. However, online experiments have typically used non-interactive tasks that participants complete on their own, either using survey software (e.g., SurveyMonkey, Qualtrics) to document decisions or emulating social interactions by using the strategy method and matching participants post hoc. Online studies using designs with live interactions between participants have typically employed tailor-made software (Egas and Riedl 2008; Gallo and Yan 2015; Nishi et al. 2015; Schmelz and Ziegelmeyer 2015; Suri and Watts 2011; Wang et al. 2012). A number of software platforms are currently available for conducting experiments via the Internet, at varying stages of development.Footnote 1 Typically, the use of these platforms for interactive experiments online requires considerable programming skills, and involves substantial installation and setup times. Moreover, these platforms do not provide integrated methods to address the specific logistic and methodological challenges of conducting interactive experiments with participants recruited online (Arechar et al. 2018). As a result, the online use of interactive designs has thus been largely restricted to experimenters with advanced technical skills or considerable financial resources, limiting the potential of online experimentation for behavioural research. Here we introduce LIONESS Lab, a free web-based platform that enables experimenters to develop, test, run, and share their interactive experiments online. The software is developed and maintained at the Centre for Decision Research and Experimental Economics (University of Nottingham, UK) and the Chair of Economic Theory (University of Passau, Germany) and can be accessed via https://lioness-lab.org. LIONESS stands for Live Interactive ONline Experimental Server Software. LIONESS Lab provides an intuitive online interface to develop LIONESS experiments. LIONESS experiments include a standardized set of methods to deal with the typical challenges arising when conducting interactive experiments online (Arechar et al. 2018). These methods reflect current ‘best practices’, e.g., for preventing participants to enter a session more than once, facilitating on-the-fly formation of interaction groups, reducing waiting times for participants, driving down attrition by retaining attention of online participants and, importantly, adequate handling of cases in which participants drop out. A key distinguishing feature of LIONESS Lab is that researchers require only minimal programming skills to develop and conduct their own interactive online experiments. The LIONESS Lab platform provides a user-friendly environment to create and edit LIONESS experiments in a point-and-click fashion. No installation is needed, and programming is only required for calculations inherent to the researchers’ specific experimental design. At the same time, LIONESS Lab supports adding JavaScript to experiments, allowing for great flexibility in implementing design features (for example, dynamic elements or conditional display). Experimenters can create new experiments starting from scratch or import existing designs (e.g., created by other researchers) through a repository. The repository enables experimenters to share their experimental designs with co-workers and other colleagues, allowing researchers to base their experiments on designs of others and facilitating transparency and replicability of research (Camerer et al. 2016; Munafò et al. 2017; Open Science Collaboration 2015). Testing LIONESS experiments is facilitated by a test mode including a ‘robot’ feature that simulates participant responses (or can be programmed to generate custom responses). Experiments can be downloaded and used on the experimenter’s own server. Participants access the experiment through a link (e.g., posted on MTurk or Prolific). Experimenters can monitor the progress of a session through a control panel. Upon session completion, data can be exported as a spreadsheet ready for analysis. This spreadsheet includes a tab for automating the performance-based payment of participants through online labour markets.",35
6.0,2.0,Journal of the Economic Science Association,19 November 2020,https://link.springer.com/article/10.1007/s40881-020-00097-y,Heterogeneous trembles and model selection in the strategy frequency estimation method,December 2020,James R. Bland,,,Male,Unknown,Unknown,Male,"A common issue with experiments studying infinitely repeated games is that while we observe subjects’ actions, we do not observe the strategies that generated these actions.Footnote 1 We can, however, infer strategies from actions using the Strategy Frequency Estimation Method (SFEM) (Dal Bó and Fréchette 2011; Fudenberg et al. 2012). The most commonly used SFEM in the literature assumes a finite, pre-determined list of strategies, and estimates the fraction of subjects who behave according to each strategy. Others’ extensions of this have expanded the list of strategies (Sherstyuk et al. 2013; Rand et al. 2015; Aoyagi et al. 2018; Fréchette and Yuksel 2017), added mixed or behavioral strategies (Fudenberg et al. 2012; Dvorak and Fehrler 2020), and permitted subjects to change their strategies between rounds (Dvorak and Fehrler 2017).Footnote 2 Out of both econometric necessity (the likelihood function is flat if just one subject’s choices are inconsistent with all strategies under consideration) and behavioral plausibility (following a strategy might be cognitively difficult), the SFEM does not assume that subjects implement their strategy perfectly. Instead, subjects are assumed to tremble with positive probability. For a 2-action stage game like the Prisoner’s dilemma, this means that subjects take the action specified by the strategy with probability \(1-\gamma\), and take the other action with probability \(\gamma\). Hence, \(\gamma\) is the tremble probability. In all of the implementations mentioned above, it is assumed that the tremble probability is identical across all subjects within a treatment. I relax this assumption to allow for the possibility that tremble probabilities are heterogeneous. The benefits of this extension are at least twofold. First, this extension allows us to test whether subjects are heterogeneous in their trembles, and if so, quantify the extent of this heterogeneity. As the null hypothesis for this test restricts a parameter to the boundary of the parameter space, this is difficult to test using classical statistics. Instead, I select between models using the Akaike Information Criterion. Second, as demonstrated in Sect. 2, this extension may lead to better estimates of the frequencies. Hence, even if one is not interested in commenting on the trembles directly, one may prefer to make this less restrictive assumption when estimating frequencies. I estimate 60 econometric models using data from the infinitely repeated Prisoner’s dilemma experiment of Dal Bó and Fréchette (2011). These models explore permutations of the original specification in the following directions: (i) how treatments are aggregated, (ii) the list of assumed strategies, (iii) whether the distribution of trembles is identical within a treatment, a strategy, or the entire dataset, and (iv) whether individuals vary in their tremble probability. The selected model allows the distribution of trembles to vary by strategy, and assumes that participants use one of all but the “T2” strategy described in Fig. 1. The seven strategies under consideration. Dal Bó and Fréchette (2011) assume that subjects use one of the following six strategies: AD always defect, AC always cooperate, G grim trigger, TFT tit for tat, WSLS win stay lose shift, and T2 “a trigger strategy with two periods of punishment”. In their analysis, Dal Bó and Fréchette (2018) replace T2 with STFT suspicious tit for tat, which begins with defecting, but is otherwise identical to TFT",3
6.0,2.0,Journal of the Economic Science Association,13 July 2020,https://link.springer.com/article/10.1007/s40881-020-00089-y,Laboratory experiments can pre-design to address power and selection issues,December 2020,Weili Ding,,,Unknown,Unknown,Unknown,Unknown,,
6.0,2.0,Journal of the Economic Science Association,06 June 2020,https://link.springer.com/article/10.1007/s40881-020-00086-1,Instrumental variables estimation of a simple dynamic model of bidding behavior in private value auctions,December 2020,John C. Ham,Steven F. Lehrer,,Male,Male,Unknown,Male,"Many economic relationships involving learning with laboratory data are dynamic in nature. For example, understanding what underlies the learning/partial adjustment processes is endemic in much experimental research and is of growing importance in rationalizing the emergence of Nash equilibria. However, the preponderance of the literature on econometric estimation of dynamic or learning models is based on discrete choice bargaining games, often with two players.Footnote 1 There has been much less work on estimating dynamic models with a continuous outcomes. By addressing the latter, the econometric approach we propose can be widely applied in many experimental studies including auctions, bargaining with transfers, and gift exchange experiments. Among such work, Ashley et al. (2003) use several experimental data sets, but as we note below, their dynamic fixed effect estimator is inconsistent. Alternatively, Brañas-Garza et al. (2011) use a dynamic learning model taken directly from the macro-type literature, e.g., Arellano and Bond (1991). Their estimates are consistent given their assumptions, but we argue below that these assumptions are much too strong for an experimental setting.Footnote 2 In this paper, we consistently estimate a simple learning model of bidding behavior in experimental affiliated private value auctions, where the subjects are generally assumed to adjust their bidding in period \(t\) as a function of their bid in period \(t - 1\). We show that this behavior lends itself to a standard dynamic panel data, instrumental variables, framework without fixed effects. Moreover, we harness Ham et al. (2005, hereafter HKL)’s insight that experiments often generate excellent instruments for use with simultaneous equation techniques.Footnote 3 On the basis of this insight, we argue that estimating a dynamic model is more compelling with experimental laboratory data than with most field data, where instrument validity is often established via debate. We hypothesize that bidders learn (and adjust their bid functions accordingly) from the previous period’s outcome. We hypothesize that bidders who won in the previous period focus on the money they could have had if they had made a lower bid, but that those who lost in the previous period focus on the money they could have had if they had won by making a higher bid. Since every auction in each period has significantly more losers than winners, we expect the losers’ bid behavior to dominate. Hence we expect, on average, this period’s signal minus bid to be a decreasing function of the previous period’s signal minus bid. Our paper proceeds as follows. In Sect. 2, we discuss the dynamic economic model that we will estimate using the data from HKL. We show how to obtain long-run impacts from such a model. In Sect. 3, we consider consistent econometric estimation of a dynamic bidding model using instrumental variables estimation. We note that both the fixed effect and Ordinary Least Squares estimators are inconsistent. We consistently estimate short-run and long-run impacts of changes in the independent variables, as well as their confidence intervals. We show that our instruments must be valid, i.e., they are uncorrelated with the error term in the structural equation. We also consider popular tests for ‘weak IV’ here, and find that our instruments, used independently, are indeed strong instruments. In Sect. 4, we discuss HKL’s affiliated private value auction experimental data, and how we use it to estimate dynamic models. We explain the biases that arise when (i) we ignore the endogeneity of lagged bidding, and (ii) we introduce fixed effects as a ‘cure’ for this endogeneity. We present our empirical results in Sect. 5. Our IV estimates suggest that subjects significantly decrease their signal minus bid this period in proportion to the difference between their signal and bid the previous period. Hence, subjects are learning on average to become less aggressive in terms of the spread between their signal and bid relative to the past. As a result, they bid closer to the risk-neutral Nash equilibrium, and the impact multiplier of the number of bidders is larger than the long-run effect of this variable. However, our OLS and FE estimates suggest that subjects significantly increase their signal minus bid this period in proportion to the difference between their signal and bid the previous period. We would note that subjects will be much better off with the behavior implied by our IV estimates than that implied by our OLS/FE estimates. Consequently, the impact multiplier of the number of bidders is considerably smaller than the long-run effect of this variable. Thus, the econometric issues we discuss are important both in principle and practice. We conclude in Sect. 6.",
6.0,2.0,Journal of the Economic Science Association,07 September 2020,https://link.springer.com/article/10.1007/s40881-020-00092-3,Comparing alternative estimation methods of a public goods game,December 2020,Danielle Kent,,,Female,Unknown,Unknown,Female,"The public goods game (PGG) is extensively used by experimental economists as a tool to study social dilemmas and cooperation.Footnote 1 However, even though it has been over 30 years since the first laboratory Public Goods Game experiments were published (Isaac et al. 1984; Kim and Walker 1984; Isaac et al. 1985) the empirical analysis of the game choice data has still not moved beyond descriptive statistics in most papers. The likely reason for this is that the distribution of the choice data for this game is highly non-standard and is complicated by its discrete, censored and panel nature. There have been a few exceptions though. Carpenter (2004), for example, used Tobit random effects estimation and Ashley et al. (2010) used inconsistent Tobit fixed effects estimation, to account for data censoring to model contribution choice in a 10-period public goods game. Bardsley and Moffatt (2007) made a clear attempt at advancing the analytical toolbox for public goods experiments by proposing that public goods data be modelled using a finite mixture model to incorporate heterogeneity of types within a population with Tobit components to address censoring, and a tremble term to model decision error. Despite the sophistication of the model and compelling rationale for the approach, the approach was never taken up in the Public Goods experimental literature, probably due to its complexity. Random effects estimation has been used by Tan and Bolle (2007), and Nikiforakis (2010). Breitmoser (2013) finds that the experimenter’s choice of structural model can also impact estimation performance as measured by Bayes information criterion (BIC). In this study, the structural model estimated is held constant in order to compare the estimates from each method. An existing data set is used to compare the methods and an out-of-sample data set is applied to further validate the performance between models instead of using the BIC or AIC criteria.",3
6.0,2.0,Journal of the Economic Science Association,22 November 2020,https://link.springer.com/article/10.1007/s40881-020-00098-x,The statistical power of individual-level risk preference estimation,December 2020,Brian Albert Monroe,,,Male,Unknown,Unknown,Male,"In response to growing evidence that some subjects in economic experiments violate one or more axioms of expected utility theory (EUT), several alternative models were proposed which allow for the apparent violations. Prospect theory (Kahneman and Tversky 1979), rank-dependent utility (RDU) (Quiggin 1982), and regret theory (Bell 1982; Loomes and Sugden 1982) are among the best known of these alternative models. Many of the newly proposed theoretical explanations of the apparent violations of EUT have been tested experimentally. A well-known example is the experiment of Hey and Orme (HO) (1994) to test if any of a variety of generalizations (and one restriction) of EUT can explain experimentally collected data significantly better than EUT. HO picked “winning” model specifications for each of their subjects on the basis of the estimates of each model and whether each model can be statistically distinguished from EUT. HO (p. 1322) conclude, “our study indicates that behavior can be reasonably well modeled (to what might be termed a ‘reasonable approximation’) as ‘EU plus noise.’” However, HO (1994, p. 1315) raise concerns that as the number of alternative specifications being tested increases, the probability that EUT will be selected as the “winning” model will decline, even if EUT is the correct specification. HO (1994, p. 1311) also suggest that EUT may be insufficiently rejected in favor of alternative models “because of the rather weak nature” of the “small sample” data used to do individual-level estimation. HO use 100 observations per subject for two of the three analyses which they consider, and 200 for the third. These concerns relate to statistical power, and to the weight economists should place on type I versus type II errors. The degree of confidence in the process used by HO to pick winning models, and indeed most statistical tests in the economic literature, can be assessed through power analyses using a simulation model. Power analyses are rarely conducted either before or after estimation. McCloskey and Ziliak (1996, p. 105) find that only 4.4% of the 182 papers published in The American Economic Review in the 1980s reported the power of the test they were performing. Zhang and Ortmann (2013, p. 6) review all papers published in Experimental Economics for the years 2010–2012, and find that no paper stated the optimal sample size for their analyses, and only one paper mentions power as an issue. Retrospective power analyses of published research and attempted replication of experiments have led to a recent reconsideration of claims of statistical significance in published research across many fields. De Long and Lang (1992) propose a measure of the fraction of unrejected null hypotheses in economic journal articles that are, in fact, false, and infer that less than one third of unrejected null hypotheses are true.Footnote 1 Ioannidis (2005) bluntly states that in the medical sciences, “It can be proven that most claimed research findings are false.” Gelman and Loken (2014, p. 460) write, “There is a growing realization that reported ‘statistically significant’ claims in scientific publications are routinely mistaken.” Continuing the scrutiny around claims of statistical significance, I use a simulation model to conduct power analyses of the ability of two risk preference lottery batteries to correctly distinguish between two possible data generating processes (DGPs), an EUT model and an RDU model. I analyze the original battery proposed by HO and the battery proposed by Harrison and Ng (HN) (2016). The subjects in both studies made choices across many lottery pairs, and a “winning” model was selected for each subject on the basis of that subject’s choices. HO were concerned with whether their subjects systematically deviated from EUT, while HN were concerned with inferences about the consumer surplus for each of their subjects. For both studies, the selected model was critical to the inferential objective of the study. Apart from the goals of these studies, the effect of deviations from EUT is of critical importance to the evaluation of subjective beliefs (Andersen et al. 2014), the calculation of discount factors (Andersen et al. 2008), the applicability of the reduction of compound lotteries axiom (Harrison et al. 2015), and behavior in strategic interactions. The accurate classification of subjects as conforming to EUT or some other theory is therefore of great importance across experimental economics. In Sect. 2, I discuss the EUT and RDU DGPs used to classify subjects, followed by a description of the power analysis process. I then discuss the experimental designs and inferential objectives of HO and HN. Finally, I present the results of a simulation power analysis assessing the ability of the experimental lottery batteries used in HO and HN to classify subjects as either EUT or RDU, and repeat this analysis when subjects have responded to these instruments 4 and 5 times, respectively. In general, the batteries used by HO and HN in their analyses incorrectly classify subjects at high rates. The repeated power analysis with more observations per subject shows that this is due in part to the small sample sizes of the batteries used by HO and HN, but also due to the makeup of the lottery pairs in the batteries.",1
6.0,2.0,Journal of the Economic Science Association,03 August 2020,https://link.springer.com/article/10.1007/s40881-020-00090-5,Power(ful) guidelines for experimental economists,December 2020,Kathryn N. Vasilaky,J. Michelle Brock,,Female,Unknown,Unknown,Female,"In spite of years of teaching and using statistics, we had not developed an intuitive sense of the reliability of statistical results observed in small samples. (Kahneman 2011) The purpose of this paper is to provide a concise and consolidated resource for experimental economists regarding power calculations. The significance of a test is central to our understanding of hypothesis testing, while its cousin, statistical power, remains peripheral. Power calculations are important for experiment and survey design. Nonetheless, researchers are either not performing power analyses, or are simply not reporting them (Zhang and Ortmann 2013; Czibor et al. 2019). Thus, it is important to reiterate and provide additional resources for ex ante analysis of statistical power, and what to report ex post.Footnote 1 In Sect. 2, we provide the formal definition of power, and provide intuition for how to operationalize it. Section 3 describes the contexts in which reporting power calculations is relevant and in Sect. 4, we discuss what calculations can be considered after an experiment has already been conducted. Section 5 considers some experimental designs for which it may be difficult to obtain sufficient power in smaller samples. In Sect. 6, we provide several options for computing power calculations, including simulated power calculations with sample code. Section 7 concludes.",3
6.0,2.0,Journal of the Economic Science Association,08 November 2020,https://link.springer.com/article/10.1007/s40881-020-00095-0,The framing effect of tax–transfer systems,December 2020,Tai-Sen He,,,Unknown,Unknown,Unknown,Unknown,,
6.0,2.0,Journal of the Economic Science Association,07 November 2020,https://link.springer.com/article/10.1007/s40881-020-00096-z,Hot versus cold behavior in centipede games,December 2020,Bernardo García-Pola,Nagore Iriberri,Jaromír Kovářík,Male,Female,Male,Mix,,
7.0,1.0,Journal of the Economic Science Association,04 September 2021,https://link.springer.com/article/10.1007/s40881-021-00105-9,Are women more generous than men? A meta-analysis,September 2021,David Bilén,Anna Dreber,Magnus Johannesson,Male,Female,Male,Mix,,
7.0,1.0,Journal of the Economic Science Association,19 June 2021,https://link.springer.com/article/10.1007/s40881-021-00099-4,Punishing defectors and rewarding cooperators: Do people discriminate between genders?,September 2021,Valerio Capraro,Hélène Barcelo,,Male,Female,Unknown,Mix,,
7.0,1.0,Journal of the Economic Science Association,20 June 2021,https://link.springer.com/article/10.1007/s40881-021-00100-0,Effects of incentive framing on performance and effort: evidence from a medically framed experiment,September 2021,Mylène Lagarde,Duane Blaauw,,Female,Male,Unknown,Mix,,
7.0,1.0,Journal of the Economic Science Association,07 July 2021,https://link.springer.com/article/10.1007/s40881-021-00101-z,Behavioral types of the dark side: identifying heterogeneous conflict strategies,September 2021,Friedel Bolle,Jonathan H. W. Tan,,,Male,Unknown,Mix,,
7.0,1.0,Journal of the Economic Science Association,05 August 2021,https://link.springer.com/article/10.1007/s40881-021-00102-y,Paying with your personal data: the insensitivity of private information provision to asymmetric benefits,September 2021,Bettina Rockenbach,Abdolkarim Sadrieh,Anne Schielke,Female,Unknown,Female,Female,"Many economists believe that “data are becoming the new raw material of business” and that information on economic actors and activities have turned into “an economic input almost on a par with capital and labor.”Footnote 1 Data-driven businesses such as Google Search and Google Maps are amongst the most profitable ones.Footnote 2 In these businesses, asking customers to provide personal data in exchange for the service is ubiquitous. Usually, these services collect the users’ data automatically, without users incurring any cost, once they have given consent. In general, the amount of personal information shared correlates positively to the quality of the service. Since all customers benefit from the improved quality of service, the provision of personal data constitutes a contribution to an information public good (Rockenbach & Sadrieh, 2012). While information providers’ benefits are usually moderate in these public goods, the data collection is often highly profitable for the service providers. They frequently use the aggregated information for other extremely profitable purposes (e.g. for targeted advertisements). Our central research question is whether the presence of a service provider who makes generous profits (i.e., the presence of a substantial payoff asymmetry to the advantage of a single non-providing party) crowds out the customers’ willingness to share personal information. To avoid additional complexities that may generate confounds, we focus on information public goods for which contributions are (almost) costless and are oftentimes collected automatically (e.g. location data collected when using traffic apps, search data collected when using search engines, data collected when using software packages, or customer data originally collected for other purposes). Hence, our setup is not meant to model information public goods that incur high costs on providers (e.g. a high degree of cognitive effort, time, or creativity) such as knowledge collection sites (e.g. Wikipedia or other open science sites), creative entertainment (e.g. Youtube and similar social media sites), or collaborative production sites (e.g. SourceForge, GitHub, or other open-source sites). The analysis of the complex set of motives for contributions in those settings goes beyond the scope of our experiment. In our design, we avoid these complexity issues and focus on the pure trade-off between inequity and the desire to provide personal information for the benefit of others. The parallelism of our setup to the information-sharing settings in the field results from the positive network effect that characterizes these settings, i.e. customers have additional utility gains as more and more other customers actively use the service. In the case of Google Search, Google Maps, Amazon, or Netflix, for example, it seems clear that the more customers contribute their usage information, the better the services can calibrate their recommendations. Often the accuracy of the services also increases as the network of active customers grows, due to the greater diversity of products and interactions. To implement these positive network effects, we model the interaction as a public goods game, in which each customer receives an additional utility gain when others contribute to the service. In the field, most of these services are provided by firms that do not contribute information to the public good but earn profits from the collected data and from the access to the large network of active customers. The “big player” in our game resembles these service providers in the field. We experimentally study how subjects’ willingness to provide personal information to an information public good is affected by the presence of a “big player.” The big player, resembling a data-driven business, cannot provide any own information, but benefits more from the collected data than any of the contributors does. Asking simple personal questions, we compare subjects’ information provision in the treatment with a big player to the provision of information in a control treatment without a big player. Additionally, we compare the difference between the contributions with and without a big player in the information-based setting to that difference in a public good setting with neutral tokens as units of provision. We design the token-based game to have an identical monetary payoff structure as the information-based game and a very similar cost and effort structure. We find that the provision of information is less susceptible to the payoff asymmetry caused by the big player than the provision of tokens. The presence of the big player crowds out the willingness to contribute to the token-based public good, but surprisingly we observe no crowding-out effect in the information public good. In consequence, contributions and contributors’ payoffs are significantly higher in the information-based treatment with a big player than in the corresponding token-based treatment. Our results demonstrate that personal involvement may interact in hitherto undocumented ways with the provision of public goods. Our study provides a first contribution to this area of research by documenting that the crowding out of contributions under payoff asymmetry is diminished in an information public good.",
7.0,1.0,Journal of the Economic Science Association,03 September 2021,https://link.springer.com/article/10.1007/s40881-021-00106-8,"Mutual monitoring, approval motivation and fostering cooperation in teams",September 2021,Jonathan Levy,,,Male,Unknown,Unknown,Male,"Mutual monitoring in teams exists when the actions made by team members are publicly observable. Mutual monitoring is generally perceived to positively influence the level of cooperation in teams. The intuition behind this claim is that mutual monitoring reduces the incentive to free ride by creating peer pressure. However, individuals might only be responsive to peer pressure if they are sufficiently motivated to seek the approval of others. Martin (1984) defines approval motivation as the desire to produce positive perceptions in others and the incentive to acquire the approval of others as well as the desire to avoid disapproval.Footnote 1 In this study we evaluate the efficacy of mutual monitoring in a setting where individuals operate in groups remotely. This setting is particularly relevant given the transition many organizations are making to facilitate remote work during the global pandemic. In addition, we directly examine whether the efficacy of mutual monitoring in fostering cooperation is dependent on the degree of approval motivation within teams. A principal could potentially use this information to filter for agents who have a greater propensity to cooperate in teams operating in such an environment, e.g., recruiters looking to hire employees. The question of how to alleviate the problem of free-riding by fostering cooperation within teams has been investigated from several perspectives in the experimental literature. Fehr and Gächter (2000) provide experimental evidence to suggest that the inclusion of costly punishment can lead to higher levels of cooperation in a public good game. Other researchers such as Hackett et al. (1994) and Ostrom et al. (1994) have shown how communication between team members can reduce the prevalence of free riding in teams. Several studies suggest that subjecting team members to mutual monitoring will result in higher levels of cooperation in teams (Dugar, 2010; Kandel & Lazear, 1992; Masclet et al., 2003; Noussair and Tucker 2007; Rege & Telle, 2004). In particular, Rege and Telle (2004) and Noussair and Tucker (2007) found that individuals cooperate significantly more when their actions are publicly observable. However, Frey and Jegen (2001) and Orr (2001) highlight how mutual monitoring may indeed be ineffective as it may crowd out cooperation in teams. Carpenter (2007) asserts that the efficacy of mutual monitoring in fostering cooperation in teams is dependent on the size of the team. Whereas research conducted by Alchian and Demsetz (1972), Cason and Khan (1999), Croson (2001), Andreoni and Petrie (2004), Rege and Telle (2004), Noussair and Tucker (2007), Ambrus and Greiner (2012) and Filiz-Ozbay and Ozbay (2014) illustrate how the efficacy of mutual monitoring in fostering cooperation in teams may depend on the type of monitoring that is permitted within teams. A more recent strand of literature examines empirically whether the level of cooperation depends on inherent character traits. Al-Ubaydli et al. (2016) found evidence to suggest that an individual’s IQ potentially serves as a useful predictor for the level of cooperation in a repeated prisoners dilemma game. Volk et al. (2012) conducted a study on the big five personality traits. They found that there was a strong correlation between an individual’s degree of agreeableness and their revealed preferences over cooperation in a repeated public good game. Fleming and Zizzo (2011) investigated whether an individual’s degree of social desirability had an impact on their likelihood to cooperate in a repeated public good game. In their study, they employed the Social Desirability Scale-17 (SDS-17) which is an updated version of the Marlowe–Crowne Social Desirability Scale (MCSD).Footnote 2 They found that individuals with a relatively low degree of social desirability behaved more cooperatively than individuals with a relatively high degree of social desirability. Fleming and Zizzo (2011) argue that social desirability is highly correlated with an individual’s degree of conformity. They believe that individuals with high social desirability scores were quick to conform to a social norm which was to contribute a very small amount to the communal pot, and, once this social norm was established divergence from contributing low amounts was extremely rare. However, for individuals who received low social desirability scores conformity to a social norm of making relatively small contributions was not as strong, hence, contributions were much higher. If the SDS-17 scale is a valid proxy measure for approval motivation, Fleming and Zizzo’s main finding is at odds with the theoretical prediction made by Holländer (1990). Specifically, Holländer illustrates how the level of cooperation in groups should increase with respect to the level of social approval. In contrast with the study conducted by Fleming and Zizzo (2011) we use the revised Martin–Larsen approval motivation (MLAM) scale to elicit individual preferences over approval. It is important to distinguish between Marlowe and Crowne’s measure of social desirability and Martin and Larsen’s revised measure of approval motivation. Many studies such as Allaman et al. (1972), Berger et al. (1977), Evans (1979), Millham (1974) and Thaw and Efran (1967) have suggested that social desirability is a measure of defensiveness rather than approval-seeking nature. The revised MLAM measure is believed to be more appropriate for this study as it provides more of a behavioural self-description of reactions to approval and disapproval in social settings. Bell et al. (1996) use the revised MLAM measure to investigate the interaction between approval motivation and compliance in the context of fundraising. Contrary to their hypothesis they did not find that those with a higher degree of approval motivation were more compliant. This study seeks to address whether the efficacy of mutual monitoring in fostering cooperation is dependent on the degree of approval motivation within teams. This paper makes two significant contributions to the literature. First, we show that mutual monitoring is ineffective in fostering cooperation in teams when individuals operate in teams remotely. This result is at odds with the results generated by Rege and Telle (2004). Second, we highlight how the efficacy of mutual monitoring is not correlated with the degree of approval motivation in teams.Footnote 3 The structure of the rest of the paper is as follows. In Sect. 2 we develop a simple model which allows for the derivation of several predictions relating to the research question. Section 3 provides an outline of the experiment that was used to test the hypotheses derived in Sect. 2. Section 4 provides a summary of the results generated from the experiment. Section  5 contains some concluding remarks.",
7.0,1.0,Journal of the Economic Science Association,13 August 2021,https://link.springer.com/article/10.1007/s40881-021-00103-x,The effects of language on patience: an experimental replication study of the linguistic-savings hypothesis in Austria,September 2021,Silvia Angerer,Daniela Glätzle-Rützler,Matthias Sutter,Female,Female,Male,Mix,,
7.0,2.0,Journal of the Economic Science Association,14 December 2021,https://link.springer.com/article/10.1007/s40881-021-00113-9,JESA in the time of COVID,December 2021,Maria Bigoni,Dirk Engelmann,,Female,Male,Unknown,Mix,,
7.0,2.0,Journal of the Economic Science Association,04 December 2021,https://link.springer.com/article/10.1007/s40881-021-00111-x,Fear of COVID-19 changes economic preferences: evidence from a repeated cross-sectional MTurk survey,December 2021,Abdelaziz Alsharawy,Sheryl Ball,Ross Spoon,Unknown,Female,Male,Mix,,
7.0,2.0,Journal of the Economic Science Association,01 September 2021,https://link.springer.com/article/10.1007/s40881-021-00104-w,Viral social media videos can raise pro-social behaviours when an epidemic arises,December 2021,Yiting Guo,Jason Shachat,Lijia Wei,Unknown,Male,Unknown,Male,"On January 23, 2020, local authorities in China imposed a full lockdown of Wuhan city in response to the emergence of a novel coronavirus and associated disease, Covid-19. This event was followed shortly after by the lockdown of other cities across Hubei province. With the movements of over 50 million people in the centre of China being closely monitored, this represented one of the largest forced quarantines in human history.Footnote 1 The lockdown of Wuhan city was the first, and one of the most stringent, to be implemented globally. During those early days of uncertainty, with scant reporting in official media outlets, social media became a key source of information about the virus for ordinary Chinese citizens. The currency of social media are viral videos and associated messages; during this time, many videos were circulated in private chat groups, showing evocative scenes of containment and relief efforts.Footnote 2 Access to information via social media is one of the biggest differentiators of pandemics today from the past (Balinska & Rizzo, 2009). Social media has become an important medium that individuals turn to for information in public emergencies (Reuter & Kaufhold, 2018). Since information systems, rather than personal experience, are the most likely source of information during a crisis, social media is an important agent of risk amplification (Kasperson & Kasperson, 1996; Pidgeon et al., 2003). Recent research recognises the potential of viral social media content to promote collective action in moments of crisis, alongside possible negative effects for trust and risk perception (Alexander, 2014; Haushofer & Metcalf, 2020; Taylor et al., 2012). During a public health crisis, the coordination of individual efforts towards collective demands underpins the success of mitigating measures (Van Bavel et al., 2020). Trust and risk attitudes are associated with the adoption of health behaviours and so indirectly for controlling the rate of disease transmission (Chuang et al., 2015). It is, therefore, important to understand how social media content influences pro-social, trust and risk-related preferences. This study examines the influences of social media content on such preferences via the modulation of a viewer’s affective emotional state. A long literature in psychology emphasises that affective states influence normative judgements and decision-making processes (Forgas, 1995; Loewenstein & Lerner, 2003; Pham, 2007).Footnote 3 Online media content that arouses emotions is more likely to go “viral” in the first place (for an example of this in the Chinese social media context, see Fan et al., 2014). Thus, we conjecture that social media videos of the type used in this study may act as an incidental (that is, not normatively relevant for the judgement at hand) influence on individuals’ emotions and mood, which in turn affects their decisions.Footnote 4 An extensive experimental economics literature explores the ability of induced emotions to affect strategic behaviour and individual preferences. Capra (2004) finds that induced good mood leads to more altruistic giving. Drouvelis and Grosskopf (2016) and Bartke et al. (2019) observe that induced positive (negative) affective states increase (diminish) pro-social behaviour in a public goods game, while findings for cooperation are mixed (Hertel & Fiedler, 1994; Hertel et al., 2000). Dunn and Schweitzer (2005) suggest that incidental anger reduces trust. In a gift-exchange game, Kirchsteiger et al. (2006) observe that those individuals who watched a funny movie clip are more generous, while those who watched a sad clip are more reciprocal. Kugler et al. (2012) show that induced mood can have a systematic impact on individual risk preferences: in their study, fearful participants make more risk-averse lottery choices than angry participants. Our study consists of an economic experiment that measures the behavioural impact of watching viral social media videos, and two follow-up surveys that assess the emotional states induced by the content of those same videos. In the experiment, Wuhan-based students complete a panel of decision tasks to measure the effects of crisis-related social media video stimuli on their pro-social, cooperative and trusting behaviour, as well as their preferences towards risk taking with known and unknown probabilities. The experiment was implemented in late January 2020, the time of greatest uncertainty about the coronavirus in China. All experimental tasks are incentive compatible: all choices have monetary rewards proportional to the good outcomes of the tasks.Footnote 5 The experiment comprises two treatment conditions and a control condition, using a between-subjects design. In the treatment conditions, participants are primed with one of two videos, each of which shows evocative content related to the Covid-19 crisis. The first of these videos shows a senior central government official’s visit to a local hospital and a supermarket (henceforth “Leadership video”). The second of these videos shows health care volunteers from other provinces in transit to Wuhan (henceforth “Volunteer video”). Both videos were circulating widely and anonymously among chat groups on the Chinese social media application WeChat at the time of the experiment. In the control condition, participants watch a neutral product advertisement video, unrelated to the crisis (henceforth “Neutral video”). We find that priming participants with either the Leadership or Volunteer video results in significantly more pro-social behaviour relative to the Neutral video, as measured by participants’ levels of altruism and expectations of reciprocity in the decision tasks. Participants’ also display lesser willingness to take risks in an ambiguous situation in the treatment conditions, although there is no systematic effect of the viral videos on risk preferences in unambiguous situations. The Leadership video alone induces a significant fall in trust, although we caution on drawing generalized conclusions from this result, because we test only one video which involves just one (prominent) government figure. In the two follow-up surveys, we find evidence to support the argument that the videos impact behaviour through the manipulation of affective emotional states. In the first survey, we ask respondents to select five events, from a list of fifteen, which acted as psychologically positive motivating factors during the early stages of the Covid-19 crisis. The two most selected events are health care teams volunteering to assist in Hubei province and national leaders countering the epidemic. In the second survey, we evaluate the impact of viewing the videos in our experiment through a set of questionnaires that assess an inventory of emotional measurements. We find that the Leadership and Volunteer videos each induce a significant rise in positive affect relative to the Neutral video, with underlying increases in joviality and self-assuredness. Those individuals who watch the Volunteer video also report greater attentiveness. There is some evidence that viewers of the Leadership and Volunteer videos feel a comparatively greater sense of guilt. The paper continues in Sect. 2 with a description of the experimental design and procedures. In Sect. 3, we present the results of the economic experiment. In Sect. 4, we describe the two post-experiment surveys we undertook to assess the video-induced changes in emotional states. In Sect. 5, we conclude with a discussion of how to interpret the results and outline some limitations of our study.",4
7.0,2.0,Journal of the Economic Science Association,13 November 2021,https://link.springer.com/article/10.1007/s40881-021-00108-6,Face masks increase compliance with physical distancing recommendations during the COVID-19 pandemic,December 2021,Gyula Seres,Anna Helen Balleyer,Müge Süer,Male,Female,Female,Mix,,
7.0,2.0,Journal of the Economic Science Association,05 November 2021,https://link.springer.com/article/10.1007/s40881-021-00109-5,The effect of COVID-19-induced mortality salience on delay discounting: a replication,December 2021,Fatih Sonmez,,,Male,Unknown,Unknown,Male,"The vast majority of previous mortality salience studies were conducted in environments with little or no explicit real-life mortality threat; thus, participants of these studies confronted a hypothetical death. In contrast, the COVID-19 pandemic provides a natural setting for mortality salience research, offering a more valid ecological context for testing the effects of death thoughts. This situation calls for the replication of previous mortality salience studies. This study aims to replicate Kelley and Schmeichel’s (2015) research, which tested the effect of mortality salience on delay discounting.",3
7.0,2.0,Journal of the Economic Science Association,07 December 2021,https://link.springer.com/article/10.1007/s40881-021-00112-w,Running online experiments using web-conferencing software,December 2021,Jiawei Li,Stephen Leider,Izak Duenyas,Unknown,Male,Male,Male,"With the onset of the COVID-19 pandemic, experimental researchers have faced an increasing need to explore options for running online experiments—both to continue existing projects and to begin new projects. While existing platforms for running online experiments, such as MTurk, have been used successfully to study certain questions (Horton et al. 2011; Paolacci and Chandler 2014), other experiments may be impractical to run on those platforms due to task length, complexity, desired subject pool, or synchronous decision-making.Footnote 1 A natural goal, then, is to find an online experimental format that can approximate as closely as possible the typical offline (lab) experimental setting. To achieve this, we take advantage of another consequence of the pandemic: greater availability and subject comfort with web-conferencing software such as Zoom. Web-conferencing software has potential value for online experiments both in facilitating communication between experimenter and subjects, and to increase subject engagement and focus due to a more direct interaction with the experimenter (closer to what subjects experience in the lab). To explore the efficacy of this approach, we conduct experimental sessions using a combination of the newly developed ZTREE Unleashed (ZTu) (Duch et al. 2020) platform (which allows subjects to participate in an experiment programmed in Z-tree through their web browser) to run the experimental task, and a parallel Zoom session. We then compare both subject recruitment (demographics of participating subjects) and subject performance in the experimental tasks to sessions conducted in person shortly before the pandemic. We explore two protocols for using web-conferencing software: whether subjects are asked to have their webcam on or off during the experiment. In both cases, the experimenter can use voice and text chat throughout the experiment to convey instructions and information, or to answer questions from subjects sent through text chats. Having the webcam off has the greatest level of subject anonymity and control (in terms of limiting the possibility that subjects use the webcam to influence one another); however, one may be concerned that subjects will be less engaged and focused on the task (early pilots suggested this may be a concern). Having the webcam on may help subjects stay on task and engaged, due to a feeling of being observed by the experimenter.Footnote 2 Our experiment uses an individual decision task, where subjects repeatedly solve a complex dynamic resource allocation problem. Therefore, we are not concerned about potential spillover between subjects from seeing others’ reactions.Footnote 3 Our goal is to identify the experimental protocols (Webcam versus no Webcam) that have the best chance of generating comparable results as the offline (lab) experiment. For comparability to lab studies, it is important that our protocol does not create distortions in subject recruitment or participation. For example, certain demographic groups (e.g., men versus women) may be more or less comfortable participating via web-conferencing software relative to the lab, which would create selection effects if those traits were also correlated with behavior in the decision task. We compare several demographic traits of participating subjects in our online formats to our lab data for the dynamic decision task. Neither online protocol leads to significant differences in subjects’ age, gender or STEM major status based on the data from this dynamic decision-making study.Footnote 4 We also hope that subjects will perform the experimental task in a similar fashion to the lab format. We compare decision accuracy (with respect to the optimal policy) and profit earned in our primary dynamic decision problem between the online and lab data. We additionally look at three diagnostic measures: risk preferences, the cognitive reflection test (CRT), and the HIT-15 measure of backward induction ability. Overall, we find that subjects’ performance in both online experimental protocols aligns with the lab experiment for both the primary task and the diagnostic measures. Using these protocols, we are able to generate high quality data using online experiments with complex and lengthy experimental tasks that require substantial subject attention and cognitive effort.Footnote 5 Finally, we give some guidance about how experimenters may want to make design decisions such as sample size using these protocols. While both protocols yield data consistent with the lab data, we note that (1) the No Webcam protocol always leads to directionally worse average performance than the Webcam protocol, although the difference is not statistically significant; (2) in the primary dynamic decision problem, the No Webcam protocol leads to a larger variability in subject performance. This suggests that data with No Webcam is somewhat noisier, which may lead to issues if experimenters use too small a sample size. To examine this concern, using a simulation study, we find that both online experiment protocols have reasonable statistical power to detect the effect sizes observed in our data. However, when we consider a range of possible effect sizes, the Webcam protocol is preferable. When effect sizes are moderate to large, the Webcam protocol has better power (due to lower performance variability) than the No Webcam protocol. For these treatment effect sizes, the statistical power of the Webcam protocol, and hence the required sample size, is comparable to the offline (lab) protocol.",15
7.0,2.0,Journal of the Economic Science Association,18 December 2021,https://link.springer.com/article/10.1007/s40881-021-00114-8,Lab-like findings from online experiments,December 2021,Irene Maria Buso,Daniela Di Cagno,Lorenzo Spadoni,Female,Female,Male,Mix,,
7.0,2.0,Journal of the Economic Science Association,18 December 2021,https://link.springer.com/article/10.1007/s40881-021-00115-7,A case study of an experiment during the COVID-19 pandemic: online elicitation of subjective beliefs and economic preferences,December 2021,Glenn W. Harrison,Andre Hofmeyr,J. Todd Swarthout,Male,Male,Unknown,Male,"With the onset of the COVID-19 global pandemic during early 2020 and the associated social distancing mandates and guidelines that followed, many have adapted to new routines. Experimental economists who rely on traditional physical laboratories for conducting experiments have faced the reality of shuttered laboratories over intervals of uncertain duration. This situation has led many of us to consider conducting online experiments for the first time. We were keenly motivated to conduct a multi-wave experiment to assess risk preferences, time preferences, and subjective beliefs related to the pandemic as it was unfolding, and the only way to do this was with an online experiment. We provide a detailed case study of our experiences, and review issues and solutions associated with designing and conducting online experiments. Our online experiment was designed to explore preferences and beliefs during the evolution of the COVID-19 pandemic in South Africa (S.A.) and the United States (U.S.). While the pandemic unfolded, were risk and time preferences unconditionally stable? Did they vary with the progress of the pandemic in some conditional manner, or were they apparently disconnected from its course? Did subjective beliefs about the prevalence and mortality of the pandemic track the actual progress of the pandemic, the projections of widely publicized epidemiological models, or neither? These are core hypotheses we sought to evaluate with a multi-wave online experiment at monthly intervals between May and November 2020. Subjects were drawn at random from the same populations, with no subject asked to participate twice. Parallel experiments were undertaken in the United States (N = 598) and South Africa (N = 544). The U.S. results from the experiment are presented in a complementary study by Harrison et al. (2022). Our objective here is to review the procedures and software we used to implement this online experiment. We provide our software source code for others to use if they find it useful: see https://github.com/bamonroe/Covid19Experiment. In addition to incentivized elicitation of preferences and beliefs, we administered a complementary series of non-incentivized survey questions. We incorporated these survey questions in our overall experiment, even though the main focus was on incentivized responses. It was useful for us to have all of the data, experimental choices and survey responses, collected consistently and within the same framework. We make no attempt here to undertake methodological evaluations of alternative elicitation methods, alternative recruitment methods, or alternative software for running the experiments online. Our objective was to apply four elicitation tasks that we have employed for many years, to address specific questions about the pandemic in a timely manner. We simply did not have time to evaluate alternatives. We used elicitation tools we have had a large hand in establishing in the field, recruitment from a known database of university students, and software that we were already familiar with. Therefore, this is a case study of successful methods, not an argument for best methods.",1
7.0,2.0,Journal of the Economic Science Association,07 October 2021,https://link.springer.com/article/10.1007/s40881-021-00107-7,"The replication crisis, the rise of new research practices and what it means for experimental economics",December 2021,Lionel Page,Charles N. Noussair,Robert Slonim,Male,Male,Male,Male,"In the wake of the replication crisis in psychology, a range of new approaches has been advocated to improve scientific practices and the replicability of published studies in the behavioural sciences. The ESA Executive Committee commissioned an ad hoc committee to review the issues raised by the replication crisis, and how they affect research in experimental economics. The present report is the result of this review. Its content has greatly benefited from the personal views and insights of a large number of ESA members. The views within the community of researchers in experimental economics are diverse. The present report does not aim at determining a strict ESA policy. Rather, it aims to bring to the community of experimental economists the collective wisdom spread among experimentalists. The report presents a discussion of the different issues related to replicability and discusses the different potential solutions, with their benefits and pitfalls. The report also contains a series of recommendations that aim to address the challenges presented by the replication crisis, while respecting the diversity of views within the ESA community.",9
7.0,2.0,Journal of the Economic Science Association,03 December 2021,https://link.springer.com/article/10.1007/s40881-021-00110-y,A Kuhn–Tucker model for behaviour in dictator games,December 2021,Peter G. Moffatt,Graciela Zevallos,,Male,Female,Unknown,Mix,,
8.0,1.0,Journal of the Economic Science Association,18 July 2022,https://link.springer.com/article/10.1007/s40881-022-00117-z,Trends in the publication of experimental economics articles,December 2022,Ernesto Reuben,Sherry Xin Li,Vasileios Kotsidis,Male,Female,Male,Mix,,
8.0,1.0,Journal of the Economic Science Association,21 July 2022,https://link.springer.com/article/10.1007/s40881-022-00116-0,JUST VENMO ME: Does form of payment affect risk taking and intertemporal choice?,December 2022,Jessica B. Hoel,Prachi Jain,Bridget Galaty,Female,Unknown,Female,Female,"Neo-classical economics assumes that so long as different forms of money are perfectly fungible, form of payment should not affect economic decisions. However, there is extensive evidence that choice architecture influences the measurement of preferences (Thaler et al. 2013; Thaler and Sunstein 2008; Szaszi et al. 2018). We focus on one dimension of the choice architecture: form of payment. The form of payment may influence decisions if forms of payment are not perfectly fungible; for example because of transaction costs or self-control issues. In this paper, we establish participants’ preferences between forms of payment and examine whether payment in mobile money or cash meaningfully affects estimates of intertemporal choice and risk taking. We measure risk taking and temporal discounting using multiple price lists with undergraduate students in the United States. In the risk task, participants make a series of choices between a gamble and a certain payout. In the time task, participants choose between a sooner and one of several later payments. We vary whether participants are paid in cash or Venmo, a commonly used peer-to-peer electronic transfer platform (mobile money). We also measure preferences between forms of payments using an exchange task in which participants choose between differing amounts of cash and Venmo. First, we find that participants frequently use Venmo and often prefer to be paid by Venmo. Using survey data, we find that Venmo is commonly used, with 75% of participants saying they use Venmo at least once a week. In addition, participants reveal a preference for payment in Venmo in the exchange task, as 46% of participants are willing to give up income to receive payment by Venmo instead of cash. Second, we find that estimates of risk taking and temporal discounting do not depend on the form of payment. Specifically, we examine whether form of payment affects the point at which participants switch from choosing the gamble to the certain payment in the risk task and from choosing the sooner payment to the later payment in the time task. The point estimates are small in magnitude, corresponding to a 0.3 row later switch point in the risk task (out of seven choices) and a 0.2 row later switch point in the time task (out of seven choices). Based on the 95% confidence interval, we can rule out effects larger than 0.5 rows and 0.5 rows in the risk and time tasks respectively. Given that participants must have access to a Venmo account to participate in our study, it is noteworthy that the effects are insignificant and qualitatively similar among participants who reveal a preference for Venmo. Given the proliferation of different options for payments, such as cash, debit/gift cards, and mobile money, experimenters have a number of different options available for payment but may be unsure how behavior is affected by mode of payment. Form of payment is a concern if cash and mobile money are not perfectly fungible. Explanations for the lack of fungibility include: transaction costs, trust and familiarity with mobile money, self-control issues, and anticipatory endowment effects. First, transactions costs could differ between cash and mobile money for a number of reasons. On the one hand, cash may be less desirable than mobile money because it is simply annoying to use or carry or it is difficult to procure (Vandoros, 2013; Chakravorti, 2014; Mazzotta and Chakravorti, 2014), perhaps because ATMs are less commonly available. On the other hand, mobile money may be less desirable because it is less widely accepted by merchants and there are fees or time costs associated with transferring mobile money into bank accounts. Second, it may be the case that cash is preferred to mobile money due to familiarity and trust in cash. This familiarity could affect processing fluency (Mishra, Mishra, and Nayakankuppam, 2006). If mobile money is viewed as inherently more risky, since the platform could go out of business or take the individual’s money, this could affect estimates of temporal discounting as participants prefer to receive payments sooner rather than later. Third, cash and mobile money may not be viewed as equal due to self-control issues. In particular, people might believe that they are less likely to spend mobile money as opposed to cash or vice versa. This could occur because individuals believe that they are less likely to spend money in a particular form of payment (Raghubir and Srivastava, 2009), because spending in cash is more subject to temptation (Myrseth, Riener, and Wollbrant, 2015), or because cash is harder to monitor (Jonker, 2016; Hernandez, Jonker, and Kosse, 2017). As a result, discounting may differ based on whether payment is offered in cash or mobile money. Finally, endowment effects could explain differences in the results across payment modes if the anticipation of payment in cash induces a different endowment effect than payment in mobile money (Bushong, King, Camerer, and Rangel, 2010; Svirsky, 2014), perhaps because cash is more tangible.Footnote 1 Our results suggest that form of payment does not affect behavior in the experiment, despite the fact that participants prefer payment via mobile money, indicating that concerns regarding the form of payment in experimental settings with college students are minimal.Footnote 2 Mobile money is an especially attractive option given the proliferation of experiments implemented online, with both student and non-student populations.Footnote 3 Transaction costs for payments by mobile money are also very low (Aker et al. 2016), and contactless methods of payment are preferable during times like the COVID-19 pandemic and normal cold and flu seasons. Our finding that the form of payment does not meaningfully affect decisions within the experiment increases the external validity of studies using mobile money. In addition, the finding that students commonly use mobile money and most of them weakly prefer it to cash suggests that mobile money is a preferable form of payment as compared to cash even for in-person experiments. These results also contribute to a larger literature that compares online experimental studies to “traditional” in-person experiments (Clifford and Jerit 2014; Paolacci et al. 2010; Arechar et al. 2018). The paper is organized as follows: Sect. 2 discusses the background and experimental design; Sect. 3 describes participants’ use of mobile money and preferences for cash vs. mobile money; Sect. 4 presents the results; Sect. 5 concludes.",
8.0,1.0,Journal of the Economic Science Association,11 October 2022,https://link.springer.com/article/10.1007/s40881-022-00120-4,Incentivization matters: a meta-perspective on dictator games,December 2022,Philip D. Grech,Heinrich H. Nax,Adrian Soos,Male,Male,Male,Male,"The economic study on altruistic giving has relied heavily on lab experiments labelled as ‘dictator games’, where one subject is given an endowment (money, tokens, etc.) to be shared with someone else. What has received little attention so far, however, is that different experimental protocols are being used to implement this game (see Fig. 1), namely  protocols (introduced by Kahneman et al. (1986) and Forsythe et al. (1994)) where only half of the subjects acting as the givers make decisions and the other half is entirely passive, protocols (introduced by Andreoni and Miller (2002)) where every subject acts both in the role of dictator and recipient, and thus eventually earns two payments from keeping and receiving at the same time, and protocols, a hybrid of the standard and interactive protocols, whereby all subjects submit dictator decisions ex ante but only half of them are randomly picked eventually and paid out with a randomly paired subject whose decisions do not matter for final payments.Footnote 1 Three flavors of experimental dictator game implementations. Left: standard—half of the subjects are dictators (shaded). Middle: interactive—all subjects give and receive at the same time. Right: role uncertainty—while all subjects make dictator decisions, only for half of those, these decisions are carried out in terms of actual cash payments Until recently, differences between these protocols have tended to remain unacknowledged by experimentalists. Corroborating this point is the fact that in the meta-study on dictator games by Engel (2011), which remains one of the standard references on the subject, there are no variables to control for such protocol differences. To gain a better understanding of whether and how protocol differences matter, we take a fresh look at Engel’s meta-regression by adding additional controls for the three different protocols that have been used under the same ‘dictator games’ umbrella term. We identify for each treatment included in Engel’s meta-study which of the three protocols was used. Our meta-regressions suggest that giving decisions depend on the exact protocol that is being used in a way that has likely confounded earlier studies in the literature that do not account for protocol differences. Our effort to add protocol information to Engel’s meta-study is motivated by our own prior investigations in Grech and Nax (2020) regarding the different strategic incentives that different protocols create, in particular by the discovery that standard versus interactive protocols induce starkly different rational-choice benchmarks (game-theoretic predictions). Furthermore, we have evidence that these protocol effects matter behaviorally from several dedicated experiments that we conducted. In Grech and Nax (2020), for an online convenience sample recruited in that study, the interactive protocol resulted in different distributions of giving decisions and higher giving overall. In that experiment, giving multipliers (that determine how much every unit of giving is worth in the hands of the recipient) of the dictator games that were run ranged from 0.1 to 2, which allows some investigation of subjects’ efficiency preferences. We found that giving under the interactive protocol was more sensitive to the giving multiplier in a way that made giving more efficient (i.e. giving more when it is cheap and giving less when it is expensive). Subsequently, in Nax et al. (2020) and Grech et al. (2020) we ran additional experiments with different populations and with a wider range of giving multipliers. In Nax et al. (2020), we find that subjects of a social elite in the United States give less than subjects in a non-elite sample in the interactive protocol when the giving multiplier is less than 2, but not when the giving multiplier is higher and also not in the standard protocol. In Grech et al. (2020), for a representative population sample for the United States, we find that the protocol effect interacts with gender, with women being more generous in the interactive dictator game, and men being more generous in the standard dictator game. Our own findings add to a growing experimental literature that has investigated through dedicated experiments the effects of protocol differences on giving in dictator games and related contexts; see Iriberri and Rey-Biel (2011), Rigdon and Levine (2018), Greiff et al. (2018); Eckel et al. (2020) and Andreozzi et al. (2021). In sum, all prior studies reject the hypothesis of protocol equivalence. The image that emerges instead is that dictator games run outside the standard protocol render giving behavior more efficiency-oriented (i.e. more positively correlated with the multiplier) and more sensitive to beliefs about others’ giving decisions. In terms of overall levels of giving, effect size and direction depend both on protocol and on the underlying population sample (e.g. Grech and Nax (2020) and Nax et al. (2020) point in different directions for elite and non-elite samples). In the present paper, we complement the single-study perspective from the aforementioned recent experiments with a meta-regression on past experiments. We therefore set out to check the instructions for each of the 131 papers included in Engel (2011)’s 2011 meta-study and code which protocol was used in each treatment in each of those papers.Footnote 2 The meta perspective supports the overall image that protocol effects matter and helps organize the findings emerging from recent experimental investigations further: meta-regressions suggest that, on aggregate, departures from the standard protocol have rendered subjects less generous for low giving multipliers, more generous for higher giving multipliers, and generally more sensitive to the giving multiplier (via a significant positive correlation). Note that these effects are potentially different for different subject pools, as, for example differentiated by gender, age, etc. In this light, the results of several influential papers with ‘big’ messages concluding that systematic differences among humans as distinguished by gender, age, culture, class, etc. exist deserve some further investigation, because several of them have used non-standard protocols [e.g. interactive in the gender comparison of Andreoni and Vesterlund (2001)] or compared populations across protocols [e.g. elite under interactive compared with non-elite under standard in Fisman et al. (2015)]. Understanding whether and how exactly protocol differences matter is helpful to organize these prior findings, and indicates avenues for targeted replications and reproductions aimed at testing certain conclusions.",1
8.0,1.0,Journal of the Economic Science Association,17 October 2022,https://link.springer.com/article/10.1007/s40881-022-00119-x,Selling shares to budget-constrained bidders: an experimental study of the proportional auction,December 2022,Jinsoo Bae,John H. Kagel,,Unknown,Male,Unknown,Male,"Many auctions sell items that could be sold in parts, for example, shares of a company, mineral rights, and shares of facilities. If bidders are willing and able to buy the entire amount offered, the single-unit first price auction (FPA) in which the highest bidder wins the whole item, allocates the item with maximum efficiency and revenue (Myerson, 1981). However, when bidders’ budgets constrain buying the entire item, as shown below, a proportional auction (PA) can be more profitable and achieve higher efficiency than the FPA. In PA each bidder submits a single bid, pays the amount bid, and receives a share of the item equal to the amount of the bid divided by the sum of all bids.Footnote 1Footnote 2  The present paper experimentally explores revenue and efficiency under FPA compared to PA under both tight and looser budget constraints. A proportional auction was used as part of Russia’s privatization of state-owned enterprises and, more recently, with cryptocurrency sales. When Russia privatized its state-owned enterprises, people were given 10,000 Rupel vouchers which would only enable them to buy very small shares of state enterprises. Under these circumstance economists suggested using the PA auction (Boycko et al, 1994). More recently, PA has been used in cryptocurrency crowd-sales (Boreiko, 2019). For example, in 2017, a blockchain company raised $4.2B by selling cryptocurrency in a PA (Howell et al., 2020).Footnote 3 The main goal of this paper is to conduct an experiment comparing revenue and efficiency of PA and FPA under two different budget constraints in a private values setting: (1) a strong/tight budget constraint where PA is predicted to raise more revenue and be more efficient than FPA and (ii) a looser budget constraint where PA is predicted to be less efficient and raise less revenue than FPA. Experimental outcomes are broadly consistent with the predictions of the theory as the PA achieved higher revenue and efficiency under the tight budget constraint, although PA allocates shares to even the lowest valued bidders. In contrast, under the looser budget constraint FPA achieved higher revenue and efficiency than the PA. Under both FPA and PA bidders tend to bid above the risk-neutral Nash equilibrium. Nevertheless, experimental outcomes were close to predicted outcomes assuming risk neutrality. The rest of the paper is organized as follows. Section 2 reviews the previous literature focusing on prior studies of budget-constrained bidding. Section 3 introduces the theoretical framework for analyzing the FPA and PA auctions. Section 4 describes the experimental design and hypotheses. The experimental procedures are outlined in Sect. 5, with the experimental results reported in Sect. 6. Section 7 summarizes the outcomes reported.",
8.0,1.0,Journal of the Economic Science Association,22 October 2022,https://link.springer.com/article/10.1007/s40881-022-00118-y,Intertemporal consumption and debt aversion: a replication and extension,December 2022,Steffen Ahrens,Ciril Bosch-Rosa,Thomas Meissner,Male,Male,Male,Male,"Debt is a powerful tool to allocate resources over time. Used appropriately, it increases welfare and fosters growth (Cecchetti et al., 2011). Yet, many people show an aversion to debt with far-reaching consequences for individual welfare and economic growth. For instance, debt averse entrepreneurs might pass on profitable investment opportunities (Paaso et al., 2021), debt averse households might waive profitable retrofit investments (Schleich et al., 2021), and debt averse high school students might forego a college or university degree (Boatman et al. 2017; Callender & Jackson, 2005; Callender & Mason, 2017). In a recent laboratory experiment with German undergraduates, Meissner (2016) studies the role of debt in an intertemporal consumption and saving problem.Footnote 1 According to theory, agents optimally allocate their expected lifetime income over time, saving when income is high and borrowing when income is low (e.g., Fisher, 1930; Friedman, 1957; Modigliani, 1986). By contrast, the experimental results of Meissner (2016) show that participants generally fail to solve such intertemporal optimization problems. Furthermore, participants are less willing to borrow than they are willing to save to smooth consumption. The author interprets this asymmetry as an indication of debt aversion. This paper is an exact replication in the sense of Chen et al. (2021) of the experiment by Meissner (2016).Footnote 2 There are several reasons to replicate this study. First, debt aversion is a relevant problem that has not yet received much attention in the dynamic optimization literature [see, e.g., Duffy (2016)]. Replicating existing work lends credibility to the limited existing results. Second, the task in the original experiment is complex, so reproducing the original results will help establish a reliable experimental design to study debt aversion. Third, Meissner (2016) uses a sample of the student population in Germany, a country which—by international standards—is known for moderate levels of household debt (e.g., Christelis et al., 2021), an excessive reliance on cash payments (e.g., Bagnall et al., 2016; von Kalckreuth et al., 2014), and low tuition fees for higher education (e.g., OECD 2021), which imply low levels of student debt. Therefore, the observed debt aversion in Meissner (2016) could be specific to populations without previous experience acquiring debt, or even specific to Germany, which is known for its cultural abhorrence of debt. As Nietzsche notes, in German debt is spelled as “Schuld,” which means both “debt” and “guilt,” to argue that “debt” with oneself is the source of guilt and bad conscience (Nietzsche, 2021). It is well-known that culture matters in experimental settings (Chen et al., 2021; Henrich et al., 2001). Against this background, we use a population composed of undergraduate students at the University of Illinois at Urbana-Champaign (UIUC) to test the robustness of the results of Meissner (2016). The US is known for having a more tolerant view of debt (Calder, 2009) and for encouraging it through its institutions (Garon 2011). Therefore, as is common in the United States, students at UIUC incur student debt to pay for tuition fees and other expenses during their studies. The US Department of Education reports an average annual cost of studying at UIUC of $15,880 and a median total debt after graduation between $15,000 and $26,000 depending on the field of study.Footnote 3 Therefore, it is safe to assume that the student body at UIUC is less restrictive about acquiring debt and has more homegrown experience acquiring it compared to German students. Furthermore, we extend the original analysis of Meissner (2016) by developing an index of debt aversion that allows us to compare debt aversion of students in the original sample of Meissner (2016) to the students from UIUC. Additionally, we collect information on participants’ gender, risk aversion, and cognitive reflection ability, as measured by the Cognitive Reflection Test (CRT, Frederick, 2005). We are especially interested in the cognitive reflection of participants, as it is a strong determinant of financial behavior both in and outside the laboratory [see Gomes et al. (2021) and Bosch-Rosa and Corgnet (2022) for an overview of results in the field and the lab, respectively].Footnote 4 Our results show that the findings of Meissner (2016) replicate. Participants fail to smooth consumption optimally and are disproportionately more reluctant to smooth consumption via debt compared to savings. Moreover, the effect sizes are similar and there appears to be no difference in the degree of debt aversion between the two samples. Testing for correlation with individual characteristics, we find no evidence that risk aversion or gender correlate with debt aversion. However, we find some weak evidence suggesting that cognitive reflection ability could be negatively correlated with debt aversion. To our knowledge, this is the first intertemporal consumption and saving experiment to compare the behavior between an American and a European sample. Moreover, existing literature on debt aversion is scant, and we are not aware of any direct intercultural comparisons. However, some recent related empirical evidence exists: Hundtofte et al. (2019) test whether individuals in Iceland and the US use short-term credit to smooth consumption when they experience a transitory negative income shock. They find that individuals from neither Iceland nor the US use short-term credit to smooth consumption, but rather adjust consumption downwards. This is in line with observed behavior in our experiment, where participants are also reluctant to borrow to smooth consumption. The remainder of the paper is organized as follows. Section 2 presents the experimental design, Sect. 3 reports the results of the replicated experiment and how personal characteristics correlate with the new debt aversion index. Finally, Sect. 4 concludes.",2
9.0,1.0,Journal of the Economic Science Association,17 December 2022,https://link.springer.com/article/10.1007/s40881-022-00122-2,Experimental (re-)analysis of the house-money effect in a public goods game,June 2023,Nicholas T. Bailey,Abhijit Ramalingam,Brock V. Stoddard,Male,Unknown,Male,Male,"People often take fewer risks with their own money than with “windfall gains”. This phenomenon has been labeled the house-money effect (Thaler & Johnson, 1990). The house-money effect has been identified in several other contexts, such as gain and loss settings (Thaler & Johnson, 1990), capital expenditures (Keasey & Moon, 1996), concessions spending at a basketball game (Arkes et al., 1994), information acquisition (Davis et al., 2010), and lotteries (Rosenboim & Shavit, 2012). In this paper, we experimentally investigate the existence of the house-money effect in a setting where efficiency requires cooperation among individuals—a public goods game. The need for cooperation is prevalent at individual and global levels, for example, production and research teams, tackling climate change, and more recently, managing the outbreak and spread of a disease. It is thus important to understand behavior in this ubiquitous interaction among agents. The public goods game is the vehicle most commonly used to study cooperation. The game presents a social dilemma where group interest demands full cooperation while individual interest leads to the equilibrium prediction of complete free-riding. However, experimental studies consistently find that contributions are positive, despite the presence of strategic risk (Chaudhuri, 2011). Such behavior would be consistent with a house-money effect. Do public goods studies paint an overoptimistic picture? For example, community organizations request contributions of time, money, or both. However, real-world contributions, where contributors identify these resources as their own, may not be as high as contributions observed in public goods experiments using house money. Experiments are well-suited to investigate the house-money effect. Standard protocol provides each subject an initial endowment of money to be used in the experiment. The endowment is not subjects’ own money that they risk in the experiment and is a windfall, i.e., ‘house-money’.Footnote 1 Are decisions in such settings biased estimates of contribution behavior compared to settings where individuals’ own money is at stake? Clark (2002) was the first, and so far, only experiment to examine the house-money effect in public goods games. Subjects in the Own money treatment were asked to bring $8 of their own money to use in the experiment, but were given an additional $8 participation fee to compensate for it. In the House-money treatment, endowments were provided as standard in experiments. Using groups of 5 and a stranger matching protocol in the repeated game, Clark found no significant differences in average contributions between the two treatments, i.e., no evidence of a house-money effect. Harrison (2007) reanalyzed the data from Clark (2002) and found evidence of a house-money effect on contributions after accounting for individual-level responses and the error structure of the panel data. He also examined the variation in the allocation decisions, rather than exclusively focusing on the mean. Further, Harrison (2007) discusses the unconventional participation fee used in Clark (2002)’s Own money treatment, which ensured subjects would not expect to lose any of their own money. To test for a house-money effect in risk and loss decisions, Cárdenas et al. (2014) implement a procedure (motivated by Bosch-Domenech & Silvestre, 2010) that addresses Harrison (2007)’s concern. In their Advance treatment, subjects were paid three weeks in advance and could lose some of this money during the experiment. Their House treatment followed standard procedures. However, the recruitment procedure in Cárdenas et al. (2014) is subject to some potential confounds. All potential subjects were publicly informed of both treatments before being assigned to a treatment. Evidence suggests that knowledge of other experimental conditions affects behavior by increasing treatment effects (Brañas-Garza et al., 2021). By informing all subjects of both treatments, the house-money effect found by Cárdenas et al. (2014) may be an upper bound of the effect on risk-taking behaviors. Thus, while the issue of the source of funds is more appropriately handled in Cárdenas et al. (2014) than in Clark (2002), the former may not present a ‘clean’ test of differences between treatments. To offer a clean test, we combine design elements from Clark (2002) and Cárdenas et al. (2014). Subjects play a repeated public goods game using the Voluntary Contributions Mechanism (VCM). We use the procedure in Cárdenas et al. (2014) to vary the source of subjects’ funds between our House and Advance treatments. Each subject attended two sessions three weeks apart. Subjects in the Advance treatment received $12.50 in first sessions, which they could lose in second sessions. The House treatment used the standard protocol for payments. Importantly, subjects were only aware of their own treatment conditions. During second sessions of both treatments, subjects played a repeated public goods game. In the House treatment, all earnings were paid to subjects at the end of the session. In the Advance treatment, only earnings above $12.50 were paid to subjects. If their earnings were below $12.50, subjects had to pay the difference to the experimenter. A house-money effect in public goods games would lead people to take more strategic risks, leading to higher average contributions in House compared to Advance. We would also expect less complete free riding and more full contribution in House. The advance payment changes subjects’ reference point from $0 to $12.50. To avoid losses from the advanced $12.50, subjects in Advance move away from full contribution. Risk and loss aversion would push Advance subjects toward complete free riding. In the House treatment, instead, a free rider earns $12.50, which would put him/her in the realm of gains, even in the case of zero contributions. We obtain a per-treatment sample size larger than typical in the literature and increase statistical power further by analyzing the full data panel (e.g., Fehr & Gachter, 2000; Sefton et al., 2007). Average contributions to the public good are not significantly different between treatments. Following Harrison (2007), we also look at individual contributions. Incidences of complete free-riding and full contributions do not support a house-money effect. Thus, using our clean design, we still do not find convincing evidence of a significant house-money effect in our setting.",1
9.0,1.0,Journal of the Economic Science Association,27 January 2023,https://link.springer.com/article/10.1007/s40881-023-00126-6,Correction to: Experimental (re-)analysis of the house-money effect in a public goods game,June 2023,Nicholas T. Bailey,Abhijit Ramalingam,Brock V. Stoddard,Male,Unknown,Male,Male,,
9.0,1.0,Journal of the Economic Science Association,06 February 2023,https://link.springer.com/article/10.1007/s40881-022-00125-z,Do we all coordinate in the long run?,June 2023,Manja Gärtner,Robert Östling,Sebastian Tebbe,Female,Male,Male,Mix,,
9.0,1.0,Journal of the Economic Science Association,29 November 2022,https://link.springer.com/article/10.1007/s40881-022-00121-3,Lying in two dimensions,June 2023,Diogo Geraldes,Franziska Heinicke,Stephanie Rosenkranz,Male,Female,Female,Mix,,
9.0,1.0,Journal of the Economic Science Association,08 April 2023,https://link.springer.com/article/10.1007/s40881-023-00129-3,Reciprocity with stochastic loss,June 2023,Nathan W. Chan,Leonard Wolk,,Male,Male,Unknown,Male,"Reciprocity is central to economic relationships and has particular importance given the prevalence of incomplete contracts (Fehr and Gächter 2000). Intentions, or perceived intentions, may affect agents’ decisions, even when observable outcomes are indistinguishable (McCabe et al. 2003; Dufwenberg and Kirchsteiger 2004; Charness et al. 2007; Stanca et al. 2009; Stanca 2010; Sebald 2010). Yet assessing intentions can be difficult, particularly when they are shrouded by uncertainty. We ask: how does positive reciprocity unfold when outcomes are determined by both intentions and chance? We posit that transparency of intentions may enhance trust in and of itself. This issue is germane to many settings that involve both trust and chance. For example, consider taxi services. A foreign visitor may be unfamiliar with optimal routes and traffic, making it difficult to ascertain whether a circuitous and lengthy journey resulted from the driver’s intentions or from stochastic factors. Absent such knowledge, the foreign visitor may be hesitant to offer a generous tip, whereas a local passenger will have more cause to trust. In politics, voters may reward or punish politicians based on policy outcomes, even though those outcomes are not entirely under the politician’s control. Transparency from the politician may modulate trust and support at the ballot box, even conditional on the same policies being delivered. Intentions, and observability of intentions, may similarly matter for customers and service providers for car and home repairs. Stochastic factors can affect the success of diagnosis and repair, and the customer’s reciprocity (e.g., online review, willingness to rehire) may depend upon the transparency of the provider’s intentions. In all of these examples, observability of intentions can affect underlying behaviors as well as the welfare of the involved parties. To study these settings, we modify the classic gift-exchange game by making it possible for the first-mover’s gift to experience a partial loss. In one treatment (Intentions and Outcomes, or I+O), the respondent observes the amount received and whether a loss occurred, making the first-mover’s intention perfectly observable. We contrast this with two treatments where information about the loss is hidden. In the first such treatment (Outcomes), the respondent can only observe the amount received, leaving uncertain the first-mover’s intention. In the other (Intentions), the respondent observes the amount sent but not how much has actually been received. We find greater reciprocity when intentions are known than when they are not. Differences are economically meaningful: they are roughly the same magnitude as the difference attributable to a full point reduction in the amount received. We find these results in a simple one-shot setting without reputational benefits, suggesting that transparency is a virtue in itself for reciprocity, even while ruling out dynamic strategic considerations. Our experimental setup and results are unique from the extant literature, which has focused primarily on observable intentions and observable outcomes. In reciprocal relationships, one must assess the kindness (intentions) of a partner’s actions (Rabin 1993; Dufwenberg and Kirchsteiger 2004; Falk and Fischbacher 2006), and chance can furthermore influence perceptions of kindness (Sebald 2010). Several studies incorporate chance in experimental settings with reciprocity. Closely related to our work is that of Charness et al. (2007). Their gift exchange game includes a random variable that can increase or decrease the first-mover’s gift. Conditional on the same amount received, respondents are more generous when good intentions (and bad luck) give rise to a given result than when good luck augmented an otherwise small gift. Cushman et al. (2009) use a different experimental design but likewise allow different choice/chance combinations to reach the same consequential outcomes. These studies demonstrate the importance of both intentions and outcomes, with strong parallels to our I+O treatment. However, our additional Intentions and Outcomes treatments shed unique light on the nature of reciprocity when risk and incomplete information are involved. Rubin and Sheremeta (2016) implement random shocks to effort in a three-stage principal-agent game. First, the principal offers a suggested wage and effort combination; second, the agent chooses effort; and third, the principal observes the outcome and can reward or punish the agent. The authors vary whether a random shock alters the agent’s effort in the second stage, and they also vary whether the principal can observe this random shock (in addition to the realized outcome) in the third stage. Adding random shocks to the effort leads to lower effort by agents and lower payoffs for the principal but, interestingly, not for the agents. In Rubin and Sheremeta (2016), the principal can communicate expectations in the first round and use that as a reference point in the third stage; in contrast, our focus is on situations where an individual cannot offer a contract or signal expectations. Other papers also explore related questions in different settings. Rand et al. (2015) use a repeated prisoner’s dilemma and report that observable intentions lead to more cooperation. However, they study cooperativeness in an infinitely repeated prisoner’s dilemma game, which is distinct from reciprocity in a one-shot game like ours. In spite of the one-shot setting, we continue to find that observability of intentions matters for reciprocity. Falk et al. (2008) implement a sequential game to show that intention-based models are limited and that preferences for fairness remain important for the respondent. Gago (2021) uses a dictator game with punishment opportunities, finding that unkind intentions trigger punishments, even if the realized outcome is not a bad one. His subjects are fully informed about intentions, whereas in our experiment, we directly compare behavior when varying the observability of intentions. In a closely related paper, Toussaert (2017) studies the role of intentions using a noisy binary trust game in which the first-mover’s decision can be replaced by a random decision by a computer with some probability. The second-mover faces uncertainty about the likelihood that this happens and is unaware of the true state they are in.Footnote 1 The findings show that trust relationships are less likely to occur when the probability of computer involvement is large, suggesting that players are more prosocial when trust intentions can be more credibly signaled. Building on the insights of Toussaert (2017), we directly vary the observability of intentions, outcomes, or both in this paper. In our case, the respondent always knows that the intention is at least as kind as the outcome. Furthermore, the action sets for both the first- and second-mover are discrete rather than binary in our study. This has the advantage that the second-mover can adjust their response to match their beliefs more closely than when only having two actions (e.g. trust or don’t trust) at their disposal. This makes our game relevant for questions such as: “When something bad happens in a trust relationship, how much reciprocity will we see? How does the level of reciprocity depend on the information available to the respondent?” A further difference is that Toussaert (2017) uses the strategy method; doing so can dampen emotional responses, which may be important for pro-social behavior. In related work by Friehe and Utikal (2018), a player chooses between a probability distribution that will favor herself or a different distribution that will (in expectation) provide better benefits to her partner. The partner only observes the final outcome, but there is some probability that the first-mover’s choice will be revealed. The authors find that intentions and outcomes both matter, but furthermore, the respondent will punish more strongly if the first-mover attempts to conceal the original choice. Their findings suggest that hiding intentions is viewed as unfair. Unlike (Friehe and Utikal 2018), we focus on the (exogenous) observability of intentions rather than (endogenous) concealment of intentions, and we do so in a setting with positive rather than negative reciprocity. Taken together, our study is unique in identifying the dual roles of uncertainty and the overarching information environment. Our work provides new insights on settings with incomplete or unenforceable contracts by investigating how information—or lack of information—on the realization of uncertainty shapes reciprocal relationships. These findings are relevant for wide classes of problems in the real-world where uncertainty may shroud the link between intentions and outcomes.",
9.0,1.0,Journal of the Economic Science Association,06 February 2023,https://link.springer.com/article/10.1007/s40881-022-00124-0,Show no quarter: combating plausible lies with ex-ante honesty oaths,June 2023,J. Jobu Babin,Haritima S. Chauhan,,Unknown,Unknown,Unknown,Unknown,,
9.0,1.0,Journal of the Economic Science Association,25 March 2023,https://link.springer.com/article/10.1007/s40881-023-00128-4,Promises and partner-switch,June 2023,Giovanni Di Bartolomeo,Martin Dufwenberg,Stefano Papa,Male,Male,Male,Male,"Promises may foster trust and cooperation. A literature explores why. Charness and Dufwenberg (2006) (C&D) propose and report experimental support for an expectation-based explanation (EBE): A promise feeds a self-fulfilling circle of beliefs about beliefs. Promises are honored because if a person breaks his promise, then he would experience guilt for letting down the co-player’s expectation.Footnote 1 Therefore, the co-player trusts the promisor. Vanberg (2008) proposes an alternative commitment-based explanation (CBE): People like to keep their word.Footnote 2 To experimentally test CBE it is crucial to develop a design that exogenously varies whether a player sends a promise to another. Vanberg ran an experiment that achieved that by relying on an ingenious “partner-switching” feature. His results support CBE.Footnote 3 While the title of Vanberg’s paper includes the question, “Why do people keep their promises?” his approach to CBE is broader as he also refers to obligations “based on agreements or contracts” (p. 1467). His experiment reflects this too. Let us highlight two differences between C&D’s and Vanberg’s designs. First, C&D focus on a binary trust game, where two players move in sequence. Vanberg instead explores a symmetrized dictator game, where only one player is active along any play path and where players initially do not know their role (dictator or recipient). Second, C&D and Vanberg explore different communication protocols. C&D study a single pre-play message that cannot be responded to. Vanberg instead allows subjects to send messages back and forth. If they then reciprocate each other’s promises, their exchange may have the flavor of a conversation that generates an informal agreement. A summary of Vanberg’s contributions reveals some interesting remaining unchartered research territory: First, Vanberg identified a potential confound to C&D’s result, namely CBE. Second, he also developed a design-tool – partner-switching – that allows testing for CBE. Third, he found support for CBE in a relevant context (with messages back-and-forth). However, he did not run a test of the relevance of CBE in C&D’s context (with unilateral messages). While he identified a potential confound to C&D’s result, he did not test its relevance in C&D’s setting. Since C&D’s study has garnered much interest, and given that the difference between messages back-and-forth and unilateral messages may be psychologically relevant, we propose that running such a test is of interest. In this paper, we report results from a design that accomplishes this. We did not enter this research exercise with strong prior ideas as to how and why promises and informal agreements might trigger different forms of motivation and behavior. Nevertheless, interest in exploring related issues is enhanced by noting that several papers have documented that sometimes the nature of a communication protocol matters to behavior. For example, Brandts et al. (2019) survey how different communication structures have different impacts. In particular, they highlight dimensions that refer to messages’ order, direction, and frequency—all elements that differ in the communication protocols associated with the two designs described in Fig. 1. The classification of communication contents also discovers different channels through which communication affects choices, potentially driven by different rationales.Footnote 4 To give an example, Krupka et al. (2017), investigating informal agreements, emphasize the social norm channel for their efficacy.Footnote 5 Relatedly, it may seem reasonable that communication that goes back and forth through multiple messages could create personal bonds and support the maintenance of agreements through moral commitment mechanisms, as effectively supported by Vanberg’s results. However, the possibility of creating two-way links is nil with unilateral messages, suggesting that the psychology of promise-keeping mechanisms may be different in such context. The game trees: C&D’s (to the left) and Vanberg’s (to the right) Besides evaluating CBE in C&D’s trust game setting with unilateral promises, we also report additional results regarding EBE. Vanberg’s switching feature, in fact, allows a relevant test, although there are limits to which extent this can be done (as noted by Ederer & Stremitzer, 2017 and Di Bartolomeo et al., 2019b.) We postpone a discussion of details until Sect. 2. The rest of the paper is organized as follows. Section 2 provides in-depth scientific background: hypotheses, designs (C&D’s, Vanberg’s, ours, and also that of Di Bartolomeo et al.,’s 2019b, which helps add perspective), and other related literature. Section 3 describes our procedures. Section 4 explains what we found. Section 5 concludes.",
9.0,1.0,Journal of the Economic Science Association,24 February 2023,https://link.springer.com/article/10.1007/s40881-022-00123-1,A practical guide to Registered Reports for economists,June 2023,Thibaut Arpinon,Romain Espinosa,,Male,Male,Unknown,Male,"In recent years, a growing number of researchers have discussed how research practices can influence the quality of evidence published in scientific journals. It is now well-established that the current publication system has contributed to the inflation of positive (i.e. statistically-significant) results in published research. Franco et al. (2014) find that strong results are 40% points more likely to be published than negative (i.e. statistically-insignificant) results and 60% points more likely to be written up.Footnote 1 Fanelli (2010) shows that papers in the social sciences are 2.3 times more likely to report positive results as compared to the physical sciences, leading some researchers to call for the retirement of statistical significance (Amrhein et al., 2019). Economists are no exception, and may engage in controversial research practices (Ferraro and Shukla, 2020) either intentionally or/and unintentionally due to publication pressure (Necker, 2014). Publication biases (journals’ greater propensity to publish positive over negative results and authors’ greater propensity to submit positive results) and citation biases (more citations for positive than null results) are widespread in economics (Christensen and Miguel, 2018), and promote manuscripts that contain statistically-significant results. As a result, researchers tend to over-report positive results, either by actively looking for statistical specifications that reject null hypotheses (p-hacking) or by interpreting unpredicted positive results ex-post (Hypothesizing After the Results are Known—HARKing).Footnote 2 For instance, Bruns et al. (2022) estimate that 56–71% of significance published in economics is inflated. This bias towards false statistically-significant findings (Brodeur et al., 2016) has contributed to the replication crisis (Schooler, 2014; Loken and Gelman, 2017), undermining the credibility of scientific evidence,Footnote 3 Significance inflation can be particularly problematic for laboratory experiments where limited costs may encourage researchers to abandon experiments with null results [i.e., drawer effect, Page et al. (2021)]. The over-representation of statistically-significant results is harmful in two ways. First, for a given study, the strength of the statistical evidence depends on the hidden statistical evidence that is not reported in the manuscript. For instance, listing a statistically-significant result after having explored two null hypotheses is much more informative than after having explored a dozen null hypotheses. The incentive to report statistically-significant results blurs the quality of the evidence provided in manuscripts, which is harmful for long-run knowledge accumulation in science. Second, the under-representation of statistically-insignificant results prevents policy-makers from having access to the entire range of scientific evidence, which may lead them to overestimate the effect of one variable on another as only statistically-significant findings are reported. This overall leads to suboptimal policy-making and a misperception of the world by researchers who only have access to biased or blurred knowledge. A growing number of scientists have called for the use of pre-registration in empirical work to tackle these issues (Miguel, 2021; Nosek and Lakens, 2014; Swanson et al., 2020). In pre-registered studies, researchers pre-specify the analysis to be carried out before examining (or even collecting) the data (Olken, 2015). This includes listing (i) the outcome variables, (ii) the control variables, (iii) the cleaning procedure (e.g., exclusion rules), (iv) the statistical models that will be used in the analysis. The pre-registration also includes the hypotheses and the sampling plan (Van’t Veer and Giner-Sorolla, 2016), describes the significance level that will be used as the decision criterion to reject null hypotheses, how multiple-hypothesis testing will be addressed (e.g., via a Bonferroni adjustment), a description of the sample size, and when data collection will be terminated. By limiting the researcher’s degree of freedom (Bakker et al., 2020), pre-registration with a thorough pre-analysis plan, substantially reduces the risks of p-hacking (Brodeur et al., 2022), HARKing, and forking (i.e., choosing a statistical model conditional on the data, but in an environment where a different model would have been chosen given different data (Gelman and Loken, 2013)). Over the past decade, a number of economic journals have become aware of the necessity to pre-register empirical analyses. For instance, all RCT submissions to the American Economic Association’s journals must now be pre-registered.Footnote 4 Platforms such as the Social Science Registry (AEA RCT Registry), As Predicted (Wharton Credibility Lab) and OSF Pre-registration enable researchers to easily store online, under embargo, their research design and analysis plans. An increasing number of economists are using these platforms. For instance, the number of pre-registrations on the Social Science Registry more than quintupled between 2014 and 2021 (from 223 to 1169 pre-registrations per year). However, pre-registration, even when meticulously executed, only solves part of the issue of the misreporting of statistical findings. First, pre-registration does not preclude publication bias (the greater likelihood of journal publication for positive results), which can still distort the distribution of evidence. Second, researchers can still erroneously anticipate publication bias even if it is absent (incorrect beliefs) or expect positive results to be better/more cited (citation bias). Researchers can still then be more likely to submit manuscripts with positive results and drop work with null results, again leading to the biased reporting of scientific evidence. Registered Reports (RRs) are a new submission format that has been intensively discussed over the past decade as a way of improving credibility in empirical work (Page et al., 2021; Henderson and Chambers, 2022). RRs, also known as Pre-Results Reviews, focus on the scientific process rather than the outcomes. A review of a paper is carried out before any research outcomes are known. Chambers and Tzavella (2022) describe the process as follows (as summarized in Fig. 1): In the first stage, authors submit their research question(s), theory, hypotheses, detailed methods and analysis plans and any preliminary data as needed. Following detailed review and revision-usually according to specific criteria-proposals that are favourably assessed receive in principle acceptance (IPA), which commits the journal to publishing the final paper regardless of whether the hypotheses are supported, provided that the authors adhere to their approved protocol and interpret the results in line with the evidence. Following IPA, authors then typically register their approved protocol in a repository, either publicly or under a temporary embargo. Then, after completing the research, they submit a stage-2 manuscript that includes the approved protocol plus the results and discussion, which may include clearly labelled post hoc analyses in addition to the preregistered outcomes (that is, findings from both confirmatory and exploratory analyses). The reviewers from stage-1 and/or newly invited reviewers then assess the completed stage-2 manuscript, focusing on compliance with the protocol and whether the conclusions are justified by the evidence. Crucially, reviewers do not relitigate the theory, hypotheses or methods, thereby preventing knowledge of the results from influencing recommendations. (Chambers and Tzavella 2022, page 29) Summary of the publication process of Registered Reports [from Chambers and Tzavella (2022)]. Note: We added the word “peer” in “peer review” compared to the original figure in Chambers and Tzavella (2022) An increasing number of scientific journals have adopted RRs as a valid submission format over the past few years (from 3 in 2013 to over 300 in 2022Footnote 5). Economic outlets have also showed a growing interest in RRs. For instance, the Journal of Development Economics, Q-Open, the Journal of Behavioral and Experimental Economics, and the Review of Finance accept RRs on a regular basis. In addition, the Journal of Political Economy Microeconomics plans to accept RRs in the near feature, and Experimental Economics recently published a special issue dedicated to RRs. Last, the Journal of the Economic Science Association now accepts RRs for replication studies. This growing interest in RRs reflects their substantial advantages. First, RRs provide the same benefits as pre-registration (PR) when meticulously implemented. Researchers commit to the way in which they will carry out their research (the research question, theory, hypotheses, statistical models, and outcome and control variables) before the data collection, which eliminates the risk of data mining (p-hacking or HARKing). Second, RRs are preferable to pre-registration as they allow researchers to improve their study design and analytic approach based on feedback from peers. Stage-1 reviews allow referees to make suggestions about the research design that can be implemented before data collection, unlike standard ex-post reviews. Third, RRs also improve pre-registration. There is currently little control over the quality of pre-registrations, and researchers may omit important information (e.g., multiple-hypothesis adjustment), which undermines the very purpose of pre-registration. Bakker et al. (2020) find, for instance, that unstructured pre-registration is much less effective in increasing research transparency than structured pre-registration, and argue that RRs would help to clarify the real degrees of freedom. Ofosu and Posner (2021) show that pre-analysis plans are often not written or used in a way that allow them to solve the issues they are aimed to address. Similarly, Abrams et al. (2020) analyze pre-registrations in experimental economics and conclude that the majority of these pre-registrations are not detailed enough to address the concerns about inference. Fourth, RRs create better incentives for researchers as compared to pre-registration: in-principle acceptance (IPA) increases the likelihood of innovative approaches, as researchers know that high-risk, high-reward protocols will be published when they receive an IPA, regardless of the outcome.Footnote 6 Researchers therefore feel more comfortable in proposing ground-breaking resource-intensive studies, and less pressure to publish positive results.Footnote 7 As a result, Heckelei et al. (2022) suggest that RRs could play a growing role in funding decisions, with research funders potentially being willing to fund pre-accepted studies that provide them with a more-secure research outcome. Overall, RRs can be considered the most advanced form of PR because all the elements that should be included in a PR are not only present in the RR but also peer-reviewed and because they guarantee the publication to researchers. Table 1 summarizes the advantages of RRs over unregistered and pre-registered studies, assuming a high quality of peer reviewFootnote 8. The aim of the current paper is to provide practical guidance about the way in which to write and manage RRs in experimental economics. We discuss the important steps of a RR, including determining the number of hypotheses, writing an analysis plan, carrying out a power analysis or defining sample size more generally, and correcting the level of significance. We show examples of code for the implementation of the statistical analyses in R and Stata (the latter in the “Appendix”). We also provide advice about how to improve a pre-registered study, e.g., by reducing the dimensionality of the outcome variables, distinguishing statistical and economic significance (the smallest effect size of interest), and discriminating between confirmatory and exploratory analyses. We focus here on frequentist approaches to statistical inference, as these are dominant in economics, but RRs can also benefit from Bayesian methods [e.g., stopping rules: see Dienes (2011)]. Last, we provide practical advice for authors, editors, and referees for the writing and evaluation of RRs. The remainder of the paper is organized as follows. Section 2 illustrates the credibility challenge in empirical work, and how RRs can help. Section 3 then presents guidelines for the writing of RRs. Last, Sect. 4 concludes. All of the codes appear in the Supplementary Materials.",1
9.0,1.0,Journal of the Economic Science Association,20 April 2023,https://link.springer.com/article/10.1007/s40881-023-00131-9,Coordination and cooperation in asymmetric commons dilemmas: a replication study,June 2023,Johannes Jarke-Neuert,,,Male,Unknown,Unknown,Male,"In a laboratory experiment, Janssen et al. (2011) studied an asymmetric, finitely repeated common-pool resource dilemma with free-form communication in which subjects made decisions about investments in an infrastructure, and about extraction from a resource made available by this infrastructure. The key feature is that the players in a group occupy distinct positions regarding resource access priority, such that the double problem of cooperation and coordination is elevated compared to a symmetric setting because upstream players (“head-enders”) have material interest to exploit their advantaged position and disadvantaged downstream players (“tail-enders”) hence have a particularly weak incentive to invest.Footnote 1 Nevertheless, infrastructure provision and joint payoffs converged to high levels in the experiment. The key result underlying this outcome is that downstream players tended to condition their investment positively on their share of resource extraction in the previous period. Janssen et al. interpret this as evidence for a reciprocity relationship in which head-enders behave fairly by restricting themselves voluntarily at the extraction stage, and tail-enders respond in kind by investing. The results are interesting and policy relevant. But the data basis of six groups (of five players each) in the main experiment, gathered in a single lab, leaves scope for concern. First, the experimental game is more complex than standard public good or common-pool resource games, involving real-time interaction, a challenging user interface, and free-form communication. This can potentially produce quite unique group dynamics and give specific lab procedures and local sampling population characteristics a pivotal role. Second, the key result mentioned above is not based on treatment-induced variance, but derived from econometric analysis, and the estimation methods used are designed for larger datasets. The aim of the study reported in this paper was to check (1) whether the key findings of Janssen et al. are replicable in a fully independent, pre-registered, double-blind replication attempt conducted in a different lab, (2) to provide elevated statistical power, and to (3) adhere to the highest principles of scientific transparency and openness by making all procedural documents, experimental materials, and anonymized data publicly accessible.",
9.0,1.0,Journal of the Economic Science Association,27 April 2023,https://link.springer.com/article/10.1007/s40881-023-00130-w,ztree2stata: a data converter for z-Tree and Stata users,June 2023,Kan Takeuchi,,,,Unknown,Unknown,Mix,,
9.0,1.0,Journal of the Economic Science Association,18 March 2023,https://link.springer.com/article/10.1007/s40881-023-00127-5,A selected literature review of the effect of Covid-19 on preferences,June 2023,Hamza Umer,,,Male,Unknown,Unknown,Male,"The world is grappled by the health and socio-economic impacts of the Covid-19 pandemic and many countries are still struggling to cope up with the multi-faced challenges posed by the pandemic. As of December, 22, the total number of global cases stand at around 651 million, and unfortunately, about 6.7 million people have died.Footnote 1 Even though social distancing and rapid vaccinations have helped curtail the virus to some extent, the global challenges and uncertainties caused by the pandemic continue to influence socio-economic decisions both at micro and macro levels. The literature that examining the multifaced effects of Covid-19 on economic decisions has increased rapidly, and a recent survey by Brodeur et al. (2021) nicely summarizes several strands of this literature. Brodeur et al. (2021), however, do not synthesize studies focusing on the effect of pandemic on preferences. The synthesis of studies examining the pandemic's influence on preferences is vital because preferences play an important role in individual and collective - decision making and occupy an important position in experimental economics.Footnote 2 This study systematically surveys the rapidly growing literature on the effect of Covid-19 on social and economic preferences (altruism, cooperation, trust, inequity aversion, risk and patience/time discounting) and synthesizes the results based on 33 studies. The synthesis shows heterogeneity in the effect of pandemic on preferences, but there are some noticeable patterns observed in the data. First, there is weak evidence (four out of six studies) that the pandemic positively influenced altruism measured via incentivized dictator games. Second, no significant impact of the pandemic on time preferences or patience is observed in studies that used incentives to elicit these preferences. Third, many studies that used incentivized preference elicitation mechanisms multiple times with same subjects (balanced panel data) do not find a significant effect of pandemic on preferences (nine out of ten studies). Last, studies that used unincentivized methods to elicit preferences show relatively higher variability in results when compared to studies that used incentivized methods. The rest of the study is organized as follows: Section 2 describes the study selection process and provides an overview of the studies. Section 3 summarizes the findings for the effect of the pandemic on preferences. Section 4 concludes the paper.",1
