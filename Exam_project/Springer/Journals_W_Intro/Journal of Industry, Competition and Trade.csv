Volume,Issue,Journal Name,Published Date,Link,Title,Journal Year,Author 1,Author 2,Author 3,Gender_Author 1,Gender_Author 2,Gender_Author 3,Article_Gender,Intro,Citations
1.0,1.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/A:1017385014395,Editors’ Introduction,March 2001,,,,Unknown,Unknown,Unknown,Unknown,,
1.0,1.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/A:1011517724873,The Microsoft Antitrust Case,March 2001,Nicholas Economides,,,Male,Unknown,Unknown,Male,,22
1.0,1.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/A:1011516509852,Innovative Industries and Antitrust: Comments on The Microsoft Antitrust Case,March 2001,Franklin M. Fisher,,,Male,Unknown,Unknown,Male,,1
1.0,1.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/A:1011572626690,Comments on The Microsoft Antitrust Case,March 2001,Daniel P. O'Brien,,,Male,Unknown,Unknown,Male,,
1.0,1.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/A:1011524710760,Comment on The Microsoft Antitrust Policy Case,March 2001,Francis O'Toole,,,Male,Unknown,Unknown,Male,,
1.0,1.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/A:1011576827599,The Microsoft Antitrust Case: Rejoinder,March 2001,Nicholas Economides,,,Male,Unknown,Unknown,Male,,7
1.0,1.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/A:1011528928507,Market Delineation and Product Differentiation,March 2001,Jonas Häckner,,,Male,Unknown,Unknown,Male,,2
1.0,1.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/A:1011533029416,"Patent Protection, Transnational Corporations, and Market Structure: A Simulation Study of the Indian Pharmaceutical Industry",March 2001,Carsten Fink,,,Male,Unknown,Unknown,Male,,10
1.0,2.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/A:1012830529827,Geography and International Inequalities: The Impact of New Technologies*,June 2001,Anthony J. Venables,,,Male,Unknown,Unknown,Male,,47
1.0,2.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/A:1012826530736,Market Structures with Multi-product Firms: Welfare Analysis and Policy Implications,June 2001,Alessandro Sembenelli,Davide Vannoni,,Male,Male,Unknown,Male,,
1.0,2.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/A:1012830631644,Product Differentiation and Process R&D: The Trade-off Between Quality and Productivity in the Spanish Firm,June 2001,Rafael Llorca vivero,,,Male,Unknown,Unknown,Male,,3
1.0,2.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/A:1012834715715,Privatization and Regulatory Reform in Brazil: The Case of Freight Railways,June 2001,Antonio Estache,Andrea Goldstein,Russell Pittman,Male,Female,Male,Mix,,
1.0,3.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/A:1015268420311,Buyer Power and its Impact on Competition in the Food Retail Distribution Sector of the European Union,September 2001,Paul W. Dobson,Roger Clarke,Michael Waterson,Male,Male,Male,Male,,49
1.0,3.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/A:1015269804381,Import Diversion under European Antidumping Policy,September 2001,Jozef Konings,Hylke Vandenbussche,Linda Springael,Male,,Female,Mix,,
1.0,3.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/A:1015221921220,Import Competition and Labor Productivity,September 2001,Harry Bloch,James Ted McDonald,,Male,Male,Unknown,Male,,12
1.0,3.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/A:1015273905290,Telecommunications in the United States and Changing Productive Efficiency,September 2001,Noel D. Uri,,,Male,Unknown,Unknown,Male,,2
1.0,4.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/A:1019521325295,What Do We Know about Success and Failure of Mergers?,December 2001,Gunther Tichy,,,Male,Unknown,Unknown,Male,,47
1.0,4.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/A:1019518909366,Merger and Acquisitions as Adjustment Processes,December 2001,J. Fred Weston,,,Unknown,Unknown,Unknown,Unknown,,
1.0,4.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/A:1019571026204,What Do We Conclude from the Success and Failure of Mergers?,December 2001,Bruce R. Lyons,,,Male,Unknown,Unknown,Male,,2
1.0,4.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/A:1019523110274,A Need For a Substantial Tightening of Merger Control? Comment on Tichy,December 2001,Andrea Coscelli,,,Female,Unknown,Unknown,Female,,
1.0,4.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/A:1019575127113,What Do We Know about Success and Failure of Mergers?—Rejoinder,December 2001,Gunther Tichy,,,Male,Unknown,Unknown,Male,,2
1.0,4.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/A:1019527211183,Competition Policy for High Technology Industries,December 2001,Stephen Martin*,,,Male,Unknown,Unknown,Male,,4
2.0,1.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/A:1020824803225,The California Electricity Crisis: Editors’ Introduction,June 2002,Carl Blumstein,Richard Green,,Male,Male,Unknown,Male,,
2.0,1.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/A:1020822720063,The History of Electricity Restructuring in California,June 2002,Carl Blumstein,Lee S. Friedman,Richard Green,Male,,Male,Mix,,
2.0,1.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/A:1020874704134,"High Natural Gas Prices in California, 2000–2001: Causes and Lessons",June 2002,James F. Wilson,,,Male,Unknown,Unknown,Male,,2
2.0,1.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/A:1020826920972,Boom and Bust in Power Plant Construction: Lessons from the California Electricity Crisis,June 2002,Andrew Ford,,,Male,Unknown,Unknown,Male,,32
2.0,1.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/A:1020878905042,The Issue of Governance and the Role of the Regulator: Lessons from the California Deregulation Experiment,June 2002,Michal C. Moore,,,Male,Unknown,Unknown,Male,,2
2.0,1.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/A:1020831021881,"A California Conundrum: Tradeoffs Among Rates, Reliability and the Environment During California’s 2000–2001 Energy Crisis",June 2002,David Gamson,,,Male,Unknown,Unknown,Male,,
2.0,1.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/A:1020883005951,California Customer Load Reductions during the Electricity Crisis: Did They Help to Keep the Lights On?,June 2002,Charles A. Goldman,Galen L. Barbose,Joseph H. Eto,Male,,Male,Mix,,
2.0,1.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/A:1020835122789,Simulating Effects of Business Decisions on Regional Economy Experience During the California Energy Crisis,June 2002,Ottie Nabors,George Backus,Jeff Amlin,Unknown,Male,Male,Male,,1
2.0,1.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/A:1020887106859,Second Generation Electricity Reforms in Latin America and the California Paradigm,June 2002,Hugh Rudnick,Juan-Pablo Montero,,Male,Unknown,Unknown,Male,,16
2.0,1.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/A:1020839223698,Will California come to Europe? A Numerical Simulation,June 2002,Mark Lijesen,Hein Mannaerts,Machiel Mulder,Male,Male,Male,Male,,
3.0,1.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/A:1025418218566,Vertical Restructuring (or Not) of the Infrastructure Sectors of Transition Economies,March 2003,Russell Pittman,,,Male,Unknown,Unknown,Male,,35
3.0,1.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/A:1025474302636,"Antitrust Laws and the Relationship Between Mergers, Stock Prices and Industrial Production: A Cointegration Approach",March 2003,Kun-Ming Chen,Hsiu-Hua Rau,,,,Unknown,Mix,,
3.0,1.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/A:1025426403545,Price Cap Regulation in the Cable Television Industry: Why was the Demand Stagnant?,March 2003,Yasuji Otsuka,Bradley M. Braun,,Male,Male,Unknown,Male,,1
3.0,1.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/A:1025430520383,European Merger Control: Do We Need an Efficiency Defence?,March 2003,Fabienne Ilzkovitz,Roderick Meiklejohn,,Female,Male,Unknown,Mix,,
3.0,1.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/A:1025482604454,Influences on Pricing and Markup in Segmented Manufacturing Markets*,March 2003,Harry Bloch,Michael Olive,,Male,Male,Unknown,Male,,6
3.0,1.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/A:1025434721292,"Industry Classifications: Aim, Scope and Techniques",March 2003,Michael Peneder,,,Male,Unknown,Unknown,Male,,35
3.0,1.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/A:1025486722201,"On the Relationship Between Acquisitions, Divestitures and Innovations: An Explorative Study",March 2003,Cees van Beers,Bert M. Sadowski,,Male,Male,Unknown,Male,,4
4.0,1.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/B:JICT.0000029239.55756.e6,"Survey on Competing in Network Industries: Firm Strategies, Market Outcomes, and Policy Implications",March 2004,Heli Koski,Tobias Kretschmer,,Female,Male,Unknown,Mix,,
4.0,1.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/B:JICT.0000029240.85701.fc,Network Externalities and Competition Policy. Comments on Koski and Kretschmer,March 2004,Pierre Régibeau,,,Male,Unknown,Unknown,Male,,2
4.0,1.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/B:JICT.0000029243.39685.6f,The Competition Policy Approach in the New Regulatory Framework for Electronic Communications. Comments on Koski and Kretschmer,March 2004,Pierre-André Buigues,,,Unknown,Unknown,Unknown,Unknown,,
4.0,1.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/B:JICT.0000029241.35770.81,Competition and Regulation in Network Industries: Not an Easy Balance to Strike. Comments on Koski and Kretschmer*,March 2004,Stefano Vannini,,,Male,Unknown,Unknown,Male,,1
4.0,1.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/B:JICT.0000029242.58091.fa,Competing in Network Industries—A Rejoinder,March 2004,Heli Koski,Tobias Kretschmer,,Female,Male,Unknown,Mix,,
4.0,2.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/B:JICT.0000037355.82246.e0,Sunk Costs and the Entry Decision,June 2004,T.W. Ross,,,Unknown,Unknown,Unknown,Unknown,,
4.0,2.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/B:JICT.0000037356.85817.e0,Subsidizing Industry: An Empirical Analysis of Irish Manufacturing,June 2004,Mark Cassidy,Eric Strobl,,Male,Male,Unknown,Male,,5
4.0,2.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/B:JICT.0000037357.99142.40,Has Import Disciplined Swedish Manufacturing Firms in the 1990s?,June 2004,Nan Nan Lundin,,,,Unknown,Unknown,Mix,,
4.0,2.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/B:JICT.0000037358.43442.78,Who Survives in Japan? An Empirical Analysis of European and U.S. Multinational Firms in Japanese Manufacturing Industries,June 2004,Hideki Yamawaki,,,Male,Unknown,Unknown,Male,,6
4.0,3.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/B:JICT.0000047300.88236.f1,Firm Growth and FDI: Are Multinationals Stimulating Local Industrial Development?,September 2004,Georgios Fotopoulos,Helen Louri,,Male,Female,Unknown,Mix,,
4.0,3.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/B:JICT.0000047297.54446.b6,Patent Infringement: Lessons from Industrial Economics,September 2004,Bryan R. Krouse,Clement G. Krouse,,Male,Male,Unknown,Male,,1
4.0,3.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/B:JICT.0000047298.70105.72,An Airline Merger in Japan: A Case Study Revealing Principles of Japanese Merger Control,September 2004,Koki Arai,,,Male,Unknown,Unknown,Male,,7
4.0,3.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/B:JICT.0000047299.13443.5a,Mobile Number Portability,September 2004,Stefan Buehler,Justus Haucap,,Male,Male,Unknown,Male,,40
4.0,3.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/B:JICT.0000047301.62206.c2,Global Antitrust Prosecutions of Modern International Cartels,September 2004,John M. Connor,,,Male,Unknown,Unknown,Male,,49
4.0,4.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/B:JICT.0000048718.68898.b1,WTO Dispute Settlement: An Economic Analysis of Four EU–US Mini Trade Wars—A Survey,December 2004,Fritz Breuss,,,Male,Unknown,Unknown,Male,,11
4.0,4.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/B:JICT.0000048719.06536.b7,The WTO Dispute Settlement Mechanism: Battlefield or Cooperation? A Commentary on Fritz Breuss,December 2004,Wilhelm Kohler,,,Male,Unknown,Unknown,Male,,1
4.0,4.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/B:JICT.0000048720.61382.b0,WTO Dispute Settlement and the EU–US Mini Trade Wars: A Commentary on Fritz Breuss,December 2004,Tim Josling,,,Male,Unknown,Unknown,Male,,1
4.0,4.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/B:JICT.0000048721.42975.17,Comment on Fritz Breuss “WTO Dispute Settlement: An Economic Analysis of Four EU–US Mini Trade Wars”,December 2004,Ichiro Araki,,,Male,Unknown,Unknown,Male,,1
4.0,4.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/B:JICT.0000048722.58635.95,WTO Dispute Settlement: What Role for Economic Analysis? A Commentary on Fritz Breuss,December 2004,Alexander Keck,,,Male,Unknown,Unknown,Male,,7
4.0,4.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1023/B:JICT.0000048763.07987.fa,WTO Dispute Settlement: Four EU–US Mini Trade Wars—A Rejoinder,December 2004,Fritz Breuss,,,Male,Unknown,Unknown,Male,,1
5.0,1.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1007/s10842-005-0990-7,When Should an Incumbent be Obliged to Share its Infrastructure with an Entrant Under the General Competition Rules?,March 2005,Mats A. Bergman,,,Male,Unknown,Unknown,Male,,4
5.0,1.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1007/s10842-005-0989-0,"R&D, International Trade and Creative Destruction—Empirical Findings from Finnish Manufacturing Industries*",March 2005,Mika Maliranta,,,Male,Unknown,Unknown,Male,,12
5.0,1.0,"Journal of Industry, Competition and Trade",,https://link.springer.com/article/10.1007/s10842-005-0988-1,"Successive Oligopolies, Vertical Downstream Integration and Foreclosure",March 2005,Manfred Neumann,Uli Fell,Richard Reichel*,Male,,Male,Mix,,
5.0,2.0,"Journal of Industry, Competition and Trade",24 September 2005,https://link.springer.com/article/10.1007/s10842-005-3720-2,"Retailer Heterogeneity, Intra-Brand Competition and Social Welfare",June 2005,Hao Wang,,,,Unknown,Unknown,Mix,,
5.0,2.0,"Journal of Industry, Competition and Trade",24 September 2005,https://link.springer.com/article/10.1007/s10842-005-3719-8,Horizontal Mergers and Successive Oligopoly,June 2005,Steffen Ziss,,,Male,Unknown,Unknown,Male,,6
5.0,2.0,"Journal of Industry, Competition and Trade",24 September 2005,https://link.springer.com/article/10.1007/s10842-005-3722-0,Product-Market Competition in the Water Industry: Voluntary Non-discriminatory Pricing,June 2005,Reto Foellmi,Urs Meister,,Male,Male,Unknown,Male,,5
5.0,2.0,"Journal of Industry, Competition and Trade",24 September 2005,https://link.springer.com/article/10.1007/s10842-005-3721-1,Price Tests to Define Markets: An Application to Wholesale Gasoline in Canda,June 2005,Eva Audy,Can Erutku,,Female,,Unknown,Mix,,
5.0,3.0,"Journal of Industry, Competition and Trade",15 November 2005,https://link.springer.com/article/10.1007/s10842-005-4868-5,Collusion in Industrial Economics—A Survey,December 2005,Switgard Feuerstein,,,Unknown,Unknown,Unknown,Unknown,,
5.0,3.0,"Journal of Industry, Competition and Trade",15 November 2005,https://link.springer.com/article/10.1007/s10842-005-4869-4,Collusion Theory: Where to Go Next?,December 2005,Luís M. B. Cabral,,,Male,Unknown,Unknown,Male,,9
5.0,3.0,"Journal of Industry, Competition and Trade",15 November 2005,https://link.springer.com/article/10.1007/s10842-005-4870-y,Collusion Theory in Search of Robust Themes: A Comment on Switgard Feuerstein's Survey,December 2005,Kai-Uwe Kühn,,,Unknown,Unknown,Unknown,Unknown,,
5.0,3.0,"Journal of Industry, Competition and Trade",15 November 2005,https://link.springer.com/article/10.1007/s10842-005-4871-x,Comments on Switgard Feuerstein's “Collusion in Industrial Economics—A Survey”,December 2005,K. Mehta,,,Unknown,Unknown,Unknown,Unknown,,
5.0,3.0,"Journal of Industry, Competition and Trade",15 November 2005,https://link.springer.com/article/10.1007/s10842-005-4872-9,How to Fight Hard Core Cartels? Comments on Collusion in Industrial Economics,December 2005,Yosuke Okada,,,Male,Unknown,Unknown,Male,,1
5.0,3.0,"Journal of Industry, Competition and Trade",15 November 2005,https://link.springer.com/article/10.1007/s10842-005-4873-8,Collusion in Industrial Economics: A Comment,December 2005,Robert H. Porter,,,Male,Unknown,Unknown,Male,,3
5.0,3.0,"Journal of Industry, Competition and Trade",15 November 2005,https://link.springer.com/article/10.1007/s10842-005-4874-7,Collusion in Industrial Economics—A Rejoinder,December 2005,Switgard Feuerstein,,,Unknown,Unknown,Unknown,Unknown,,
6.0,1.0,"Journal of Industry, Competition and Trade",21 January 2006,https://link.springer.com/article/10.1007/s10842-005-5647-z,How Do Innovations Affect Mergers and Acquisitions—Evidence from Finland?,March 2006,Eero Lehto,Olavi Lehtoranta,,Male,Male,Unknown,Male,,14
6.0,1.0,"Journal of Industry, Competition and Trade",21 January 2006,https://link.springer.com/article/10.1007/s10842-005-5648-y,"Monopoly Prices versus Ramsey-Boiteux Prices: Are they “Similar”, and: Does it Matter?",March 2006,Felix Höffler,,,Male,Unknown,Unknown,Male,,5
6.0,1.0,"Journal of Industry, Competition and Trade",21 January 2006,https://link.springer.com/article/10.1007/s10842-005-5649-x,Competition in the Post-Trade Markets: A Network Economic Analysis of the Securities Business,March 2006,Günter Knieps,,,Male,Unknown,Unknown,Male,,20
6.0,2.0,"Journal of Industry, Competition and Trade",05 October 2006,https://link.springer.com/article/10.1007/s10842-006-9471-x,Revisiting an Evasive Concept: Introduction to the Special Issue on Competitiveness,June 2006,Karl Aiginger,,,Male,Unknown,Unknown,Male,,27
6.0,2.0,"Journal of Industry, Competition and Trade",05 October 2006,https://link.springer.com/article/10.1007/s10842-006-9472-9,Productivity and Microeconomic Reforms: Strengthening EU Competitiveness,June 2006,Isabel Grilo,Gert Jan Koopman,,Female,Male,Unknown,Mix,,
6.0,2.0,"Journal of Industry, Competition and Trade",05 October 2006,https://link.springer.com/article/10.1007/s10842-006-9473-8,The “Lisbon Goal” of the EU: Rhetoric or Substance?,June 2006,Wilhelm Kohler,,,Male,Unknown,Unknown,Male,,12
6.0,2.0,"Journal of Industry, Competition and Trade",05 October 2006,https://link.springer.com/article/10.1007/s10842-006-9474-7,Michael Porter’s Competitiveness Framework—Recent Learnings and New Research Priorities,June 2006,Christian H. M. Ketels,,,Male,Unknown,Unknown,Male,,70
6.0,2.0,"Journal of Industry, Competition and Trade",05 October 2006,https://link.springer.com/article/10.1007/s10842-006-8430-x,International Competitiveness and Comparative Advantage: A Survey and a Proposal for Measurement,June 2006,Eckhard Siggel,,,Male,Unknown,Unknown,Male,,88
6.0,2.0,"Journal of Industry, Competition and Trade",05 October 2006,https://link.springer.com/article/10.1007/s10842-006-9475-6,Competitiveness: From a Dangerous Obsession to a Welfare Creating Ability with Positive Externalities,June 2006,Karl Aiginger,,,Male,Unknown,Unknown,Male,,98
6.0,3.0,"Journal of Industry, Competition and Trade",30 April 2007,https://link.springer.com/article/10.1007/s10842-006-0029-8,On the Robustness of the High-Quality Advantage under Vertical Differentiation,December 2006,Robert C. Schmidt,,,Male,Unknown,Unknown,Male,,4
6.0,3.0,"Journal of Industry, Competition and Trade",30 April 2007,https://link.springer.com/article/10.1007/s10842-006-0028-9,Effectiveness of Antitrust Sanctions on Modern International Cartels,December 2006,John M. Connor,,,Male,Unknown,Unknown,Male,,36
6.0,3.0,"Journal of Industry, Competition and Trade",30 April 2007,https://link.springer.com/article/10.1007/s10842-006-0025-z,Market Concentration and Product Variety under Spatial Competition: Evidence from Retail Gasoline,December 2006,Georg Götz,Klaus Gugler,,Male,Male,Unknown,Male,,9
6.0,3.0,"Journal of Industry, Competition and Trade",30 April 2007,https://link.springer.com/article/10.1007/s10842-006-8429-3,A Mixed Oligopoly Where Private Firms Survive Welfare Maximisation,December 2006,Johan Willner,,,Male,Unknown,Unknown,Male,,9
6.0,3.0,"Journal of Industry, Competition and Trade",30 April 2007,https://link.springer.com/article/10.1007/s10842-006-0026-y,Antidumping as Anticompetitive Practice Evidence from the United States and the European Union,December 2006,Mustapha Sadni Jallab,James B. Kobak Jr,,Male,Male,Unknown,Male,,2
6.0,3.0,"Journal of Industry, Competition and Trade",30 April 2007,https://link.springer.com/article/10.1007/s10842-006-8428-4,Domestic vs. International Spillovers: Evidence from Swedish Firm Level Data,December 2006,Andreas Poldahl,,,Male,Unknown,Unknown,Male,,2
7.0,1.0,"Journal of Industry, Competition and Trade",31 January 2007,https://link.springer.com/article/10.1007/s10842-006-0002-6,Antitrust Policy: The Impact of Revenue Penalties on Price,March 2007,Caroline Elliott,Melinda Acutt,,Female,Female,Unknown,Female,"Assume that a risk neutral firm with sufficient market power to be considered a monopolist (or joint profit maximizing oligopolists) wishes to set price to maximize profits in a single period game. However, suppose antitrust authorities can monitor the profits made by the firm and can choose to impose a revenue penalty if it is believed that the level of profits suggests that the firm is abusing its market position. Given the legal requirement on most firms to report profits, information on profits should be readily available to an antitrust body. Yet, reflecting in part the imperfect and costly nature of regulation and regulatory monitoring, intervention by the antitrust authorities may not necessarily be certain, even when profits are high. Rather, the probability of intervention is, similarly, positively related to the level of profits made. ‘Equal treatment under the law’ implies that antitrust authorities should intervene in all comparable cases when profits are found to be excessive. Hence, it should be noted that in this model the probability of intervention increasing with profits reflects the difficulties facing antitrust authorities in identifying abuses of market power, and the greater likelihood that market power abuses will be detected when profits are higher (and given the visibility of profits for many firms), rather than any choice made not to intervene once profits have been deemed excessive. Throughout the paper it is assumed that: 
 where: 
 Probability of regulatory intervention, twice continuously differentiable Profits in the absence of regulatory intervention Price Average costs of production Output Twice continuously differentiable Also, a potential penalty on revenue is denoted R(π). It is similarly assumed that: 
 and that R(π) is again twice continuously differentiable. Assuming that the magnitude of revenue penalties is a function of a firm’s profits gives rise to the risk of the ‘Averch–Johnson’ effect, whereby a firm may artificially increase costs to avoid a revenue penalty. This clearly increases the informational requirements of the regulator, although it may be hoped that for many firms the discipline of the stock market will curb any tendency to artificially increase cost expenditures. An alternative would be to assume that the revenue penalty is a function of a firm’s price, noting that in 2001 the Office of Fair Trading fined a pharmaceutical company, Napp, for charging ‘excessive prices’ to community users of a drug, decision CA98/2/2001. However, typically, antitrust authorities do not intervene when it is believed that a firm’s price is in some way ‘excessive,’ and the policy of penalizing ‘excessive’ prices has been criticized, see Evans and Padilla (2005). Fixed costs of production are assumed to equal zero.Footnote 4 To maintain the generality of the analysis, linear variable cost and demand functions are not necessarily assumed, rather it being assumed that: 
 where: 
 
C = total costs of production; and both of the above functions are twice continuously differentiable.",
7.0,1.0,"Journal of Industry, Competition and Trade",05 January 2007,https://link.springer.com/article/10.1007/s10842-006-0030-2,"Market Conduct and Endogenous Lobbying:
Evidence from the U.S. Mobile Telecommunications
Industry",March 2007,Tomaso Duso,Astrid Jung,,Male,Female,Unknown,Mix,,
7.0,1.0,"Journal of Industry, Competition and Trade",31 January 2007,https://link.springer.com/article/10.1007/s10842-006-0001-7,Industry Concentration and Strategic Trade Policy in Successive Oligopoly,March 2007,Gjermund Nese,Odd Rune Straume,,Male,Male,Unknown,Male,,4
7.0,1.0,"Journal of Industry, Competition and Trade",18 January 2007,https://link.springer.com/article/10.1007/s10842-006-0417-0,Product Market Reforms and Productivity: A Review of the Theoretical and Empirical Literature on the Transmission Channels,March 2007,Gaëtan Nicodème,Jacques-Bernard Sauner-Leroy,,Male,Unknown,Unknown,Male,,9
7.0,2.0,"Journal of Industry, Competition and Trade",27 February 2007,https://link.springer.com/article/10.1007/s10842-007-0004-z,Infant Firm Subsidization in Industries with Dynamic Structure,June 2007,Vladimir P. Petkov,,,Male,Unknown,Unknown,Male,,1
7.0,2.0,"Journal of Industry, Competition and Trade",23 March 2007,https://link.springer.com/article/10.1007/s10842-007-0008-8,Information and Export Performance,June 2007,Alessandro Nicita,Marcelo Olarreaga,,Male,Male,Unknown,Male,"In shaping their preference towards a specific product, a supplier or a brand, firms and consumers rely on the information that is available to them. For a firm, the choice of supplier is made based on the information available regarding its reliability and the characteristics of the products it offers. These are key factors that will determine the purchasing firm’s own success. Similarly, consumers’ preferences are formed based on their awareness of existing products, as well as their quality, value and reliability. Information-sharing among purchasing firms or consumers will make the success of any product or firm in a particular market dependent on the experience of other purchasing firms or consumers. The need for information is more pronounced in the case of international transactions, where buyer and seller are located in different countries with different legal systems and business customs. Importers, however, may use other importers, who have had direct experience with potential suppliers, as a source of information about the performance of exporters, their product characteristics, and their reliability in terms of credit and delivery (World Bank 1989). Social and ethnic networks may also contribute to the transmission of information across international borders. They help match buyers and sellers, create market similarities and serve as a deterrent for opportunistic behavior (see McLaren 1999; Rauch 1999; Rauch and Trindade 2002 and Casella and Rauch 2002). While information flows are definitely stronger within countries, they are not necessarily limited to national borders. Importers who have had direct experience with an exporter may generate valuable information that can influence importers in other countries. Similarly, consumers in a particular country may influence the preferences of foreign consumers for products originating in other countries (through fashion waves, for example). This implies that the export performance in one market would also affect export performance in neighboring markets due to information-sharing among importers and/or consumers. The objective of this paper is to try to identify the importance of these import demand information spillovers on the export performance of 20 developed and developing countries from various regions and at different stages of development, that account for a significant share of world trade (around 60% over the time span in the sample). We found that information spillovers have significant effects on exports, although they tend to have a larger impact on the export performance of developing countries, where the need for building a reputation in international markets is probably larger. At the bottom of the spectrum exporters from the United States benefit almost negligibly from import demand information spillovers. On the other hand, developed countries’ markets are the main generators of information regarding rest of the world exporters. Increases in market shares in the United States, Canada, Germany and United Kingdom can significantly impact on exports of developing countries to the rest of the world. We found, however, that Hong Kong is the top market in terms of generation of information regarding other East Asian exporters. Similarly, Argentina and Chile are among the top four markets when it comes to generating information regarding the “performance” of other Latin American exporters. The paper is structured as follows. In Section 2, we discuss the importance of information flows across countries and the different measures used in this paper to capture bilateral information flows. Section 3 develops a simple model with export information spillovers across nations. Section 4 focuses on the econometric model, and Section 5 reports the results for the 20 countries in our sample. Section 6 concludes.",11
7.0,2.0,"Journal of Industry, Competition and Trade",26 December 2006,https://link.springer.com/article/10.1007/s10842-006-0027-x,Interdependencies in the Dynamics of Firm Entry and Exit,June 2007,Kristina Nyström,,,Female,Unknown,Unknown,Female,,11
7.0,2.0,"Journal of Industry, Competition and Trade",09 February 2007,https://link.springer.com/article/10.1007/s10842-006-0003-5,"A Note on Quality Choice, Monopoly, and Network Externality",June 2007,Tsuyoshi Toshimitsu,,,Male,Unknown,Unknown,Male,"This note analyzes the implications of the provision of service quality by a monopoly in network industries for social welfare. The effect of network externalities on quality, quantity, price and social welfare, is also examined by looking at the nature of cost functions and the weight of network externalities. To start with, we address the characteristics of network industries. We regard so-called public utility industries—such as electricity, city gas, water, railroads, and airlines—as network industries where a ‘natural monopoly’ exists (through average costs decreasing with output). To avoid market failure, government intervention in these industries has typically been permitted in traditional microeconomics. Moreover, as digital technology progresses, we observe the remarkable growth of Information and Communications Technology (ICT) industries, including telecommunications, computer hardware and software, cable TV, and broadcasting, among others. Many studies have already analyzed the markets for the goods and services that generate network externalities (see, for example, Katz and Shapiro, 1994; Economides, 1996; Shy, 2001; Koski and Kretschmer, 2004). A network externality is commonly defined as a general property that the utility of each consumer increases with an increase in the total number of consumers purchasing either the same brand or a compatible brand. These studies usually distinguish between direct (communications) network effects and indirect (systems) network effects. In the first instance, the utility of an individual consumer increases when there are others to communicate with, while in the second, utility depends on the availability of complementary goods. In turn, this depends on the number of potential buyers, and accordingly generates a positive effect from other users on an individual’s utility. As discussed by Laffont and Tirole (2000), telecommunications services in most countries are often provided with a secure monopoly in the form of a public enterprise or a privately regulated corporation. The absence of competition was motivated by the existence of large fixed costs in several parts and facilities of the network, which have the characteristics of a bottleneck in essential facilities. Thus, the telecommunications industry was usually deemed to be a ‘natural’ or ‘bottleneck’ monopoly. In other industries, e.g., electricity and city gas, we often find large fixed and set-up costs of creating and installing the network and the system, i.e., the essential facilities for providing the various goods and services in network industries. However, once the networks and systems have been built, the running costs per output can be almost constant or negligible. In sum, there are two sides of the scale economy in network industries: (1) network externalities, or ‘demand-side economies of scale,’ and (2) bottleneck (natural) monopolies, or ‘supply-side economies of scale.’ As shown below, we assume that the cost unrelated to output is a convex function of quality. For example, a firm in an ICT industry may incur large research and development (R&D) investment costs in improving the quality of the goods and services or renovating network systems to respond to the needs of customers. In this case, the higher service quality implies conveying more content capacity with higher speed. Now we consider the existing literature. With regard to the comparative analysis of product quality by a profit-maximizing firm and a social-welfare maximizing firm, for example, Spence (1975) and Sheshinski (1976), among others, have already shown that a monopoly does not necessarily supply a socially efficient level of quality. They point out that a source of market failure is the divergence between consumers’ marginal and average valuations of quality. That is, the monopoly chooses the quality level that equates the marginal cost of quality and the marginal valuation by the marginal consumer. However, the social surplus-maximizing quality level equates the marginal cost of quality and the total valuation of quality by all consumers. Therefore, whenever the average valuation of quality over all the consumers in the market is larger than the marginal valuation of quality by the marginal consumer, the monopoly undersupplies quality as compared with the social optimum. Sappington (2005) reviews the economic literature analyzing service quality regulation in network industries. He explains how the effect of network externalities leads to an undersupply of quality relative to the social optimum in the case of multiple suppliers. Introducing network effects into a standard model of vertically differentiated products (Mussa and Rosen, 1978), Lambertini and Orsini (2001), hereafter L–O (2001), have shown that a monopoly yields an oversupply of quality compared with the social optimum. This is because with a network externality, the average valuation can be lower than the marginal valuation. Moreover, they concluded that the effect of a network externality on quality and price is negative. It is assumed in their model that the marginal costs of production are increasing in quality. However, assuming that the cost of quality is unrelated to output and the marginal costs of production are zero, Lambertini and Orsini (2003), hereafter L–O (2003), examined the same issues as in L–O (2001). They showed that even with a network externality, monopoly yields an undersupply of quality and quantity, compared with the social optimum, whereas the social planner always provides products to all consumers in the market. In this note, we reconsider the results of L–O (2001, 2003) and show that at least some of these vary according to the specificity of the cost functions. For example, L–O (2001, 2003) argued that when a cost is unrelated to output, an increase in the weight of a network externality reduces the quality and price of the monopoly in equilibrium but raises the hedonic price. If non-zero marginal costs of production are assumed, however, the opposite holds. The remainder of this note is structured as follows. Section 2 presents a vertically differentiated product model with a network externality. Section 3 derives an unregulated monopoly equilibrium and a social optimum, and then provides a comparative analysis. Section 4 examines the effect of a network externality on quality, quantity, price and social surplus. Finally, Section 5 summarizes the results and identifies a few outstanding issues.",5
7.0,3.0,"Journal of Industry, Competition and Trade",19 July 2007,https://link.springer.com/article/10.1007/s10842-007-0023-9,"Industrial Policy: Past, Diversity, Future; Introduction to the Special Issue on the Future of Industrial Policy",December 2007,Karl Aiginger,,,Male,Unknown,Unknown,Male,,4
7.0,3.0,"Journal of Industry, Competition and Trade",20 July 2007,https://link.springer.com/article/10.1007/s10842-007-0017-7,Industrial Policy in the United States,December 2007,Christian H. M. Ketels,,,Male,Unknown,Unknown,Male,"The USA has a long history of strong denials that industrial policy is part of its overall economic policy tool kit:Footnote 1 “We don’t do industrial policy”.Footnote 2 Given the narrow definition of industrial policy often applied in the USA which views industrial policy as an interference in the market process with the objective of fostering an industry that would otherwise not succeed, this self-assessment seems roughly accurate, at least as a statement of intent. But given a broader definition of industrial policy as all economic policies with an industry-specific impact, the answer is different: the USA clearly engages in policies that are targeted at specific industries or sectors, and it does use horizontal policies that have differential effects across industries. The discussion of whether or not the USA engages in industrial policy is relevant only in terms of politics; it provides little guidance to understanding actual policies. We organize the following discussion by three policy areas rather than by specific industry. First, science and technology policy is a clear priority for the USA and disproportionally affects industries that are knowledge driven. Second, economic development policies include both policies targeted at small- and medium-sized companies and policies directed at regions facing specific economic challenges, and through these objectives affect some industries more than others. Third, trade policies offer a wider variety of tools that are often applied differently from industry to industry. The USA is widely noted as a global leader in science and technology, achieving high wages based on the innovations generated by companies located in the USA. The concerns about whether this position as the global innovation leader is sustainable have, however, increased in the last few years (see Broad 2004). A large number of advocacy reports argue that the USA needs to do more to keep its position as the leading science hub in the world economy as other countries increase their efforts to catch upFootnote 3 and a range of legislative proposal are currently under discussion in Congress.Footnote 4 President Bush has made science and technology a central plank of his American Competitiveness Initiative (ACI) announced at the 2006 State of the Union address (Domestic Policy Council/Office of Science and Technology Policy 2006). ACI proposes to increase basic research by US $50 billion over the next decade, to make the R&D tax credit for companies permanent (US $86.4 billion over the next decade), and to invest another US $380 m in educational programs. To provide the context for assessing these different proposals, we provide an overview of the federal agencies currently engaged in US science and technology policies, the tools they use, and the issues they are facing. The main federal agencies providing funding for science and technology are the Department of Defense (DoD), the National Institute of Health (NIH), NASA, the Department of Energy (DoE), and the National Science Foundation (NSF) (Table 2).
 Given their sheer size, US government spending on defense and space has the potential to benefit US companies in civilian markets, for example through new technologies developed that have uses in both military and civilian markets. But have these policies been designed with industrial objectives in mind, do the benefits of these policies compensate for their costs, and how critical are they relative to other factors in explaining the success of US companies in specific industries? Overall, the evidence suggests that while defense and space programs have created industry-specific benefits, these benefits are more appropriately interpreted as the result of the unique demand structure in the USA, driven by the country’s overall political role and objectives, rather than purposeful industrial policy. Alone these programs are not sufficient to explain the success of the US in these industries and the money could have been spend more effectively if US competitiveness in these industries would have been the primary concern. First, the spending decisions in these programs take place in a political triangle of national security, fiscal, and industrial objectives. In the first half of the 1990s, fiscal considerations came first. The cut down in military spending had a negative effect on many companies supplying the US military.Footnote 5 After 2001, security considerations became central. A good example is the “Buy American”-clause that was proposed in Congress for US military procurement: The DoD successfully argued on security grounds that it had to be able to choose suppliers by merit rather than to be an instrument of industrial policy. The evidence suggests that economic benefits have been a welcome side effect of defense and space funding but not a guiding objective in their design. Second, while the DoD R&D budget is sizable, its large majority is allocated to the development of weapon systems. NASA’s R&D budget, too, is focused on development rather than on more generally applicable research. In basic and applied research, the National Institute of Health NIH, part of the Development of Health and Human Services, controls a far larger budget. Given the focus on development in defense and space spending, the technology spill-over effects into civilian markets is likely to be much smaller than the size of spending suggests. Third, for most industries, it seems unlikely that the defense and space spending was crucial for the success of US companies in civilian markets. The prime candidate for an exception from this rule is the aerospace industry, an area where the USA is exceptionally strong despite a recent loss in world market position. Technologies in the military and the civilian aerospace industries have sufficient overlap for development costs in one area to benefit the other. And the oligopolistic market structure provides companies with secure cash-flow in one area with a strategic advantage in the other. Because of this very nature, however, the aerospace industry has also been the subject of financial intervention by other governments, notably in Europe, such that the US policy stance seems not exceptional. Even outside of military spending, the US government remains to have the largest civilian R&D budget globally. As a share of GDP, however, its R&D spending level only puts it between the leading Asian and Northern European countries on the one hand and the rest of the OECD on the other hand (OECD 2006). US funding levels had dropped in the late 1990s but increased significantly since then. About one third of the US federal R&D budget is used to finance research in government agencies or federally funded research institutions like the Los Alamos National Laboratories. Twenty-eight percent are used to finance R&D at universities and non-profit organizations, and about 40% goes towards research conducted by companies. For universities, colleges, and non-profit research institutions the federal government remains by far the largest source of funding. In 2003, the federal government covered 62% of universities’ R&D expenditures, up from 58% in 2000 (NSF 2006). Most of this money was allocated through peer-reviewed competitive processes. However, there is an increasing concern about the level of earmarks, i.e. funds allocated by Congress for use in specific institutions rather than the most qualified provider in a given field (White House 2004). NIH and NSF funding are the only budgets where Congress has barred the use of such earmarks. Apart from funding, university research is also significantly affected by the regulatory environment it faces, in particular rules around technology transfer. The differentiated system of institutions for higher education in the USA has always provided a fertile ground for economic development to be an important concern (Ketels 2004; Hill 2006). Many colleges in rural regions, for example, were land-lease institutions specifically charged from their establishment with promoting technology in areas dominated by agriculture. Private universities such as the Massachusetts Institute of Technology (MIT) have long been known for their effective programs of technology transfer and start-up support. More recently state universities, like the Georgia Institute of Technology, have also gained a strong reputation for technology transfer (Paytas et al. 2004). These developments, initially driven by the Baye–Dole Act of 1980 which allocated property rights for patents to research institutions instead of individual researchers who in most cases did not have the capabilities to patent and negotiate license agreements, have been going on for a while and continue to gain momentum. For companies, federal funding is in general less important as a share of their total R&D expenditures, although in specific industries like life sciences, energy, and aerospace and defense it can be significant. In addition to funding awarded by government agencies for specific research purposes, companies also have access to a R&D tax credit. This tax credit has remained stable at an effective rate of 7% since the early 2000s (OECD 2004a, b) and provided an estimated US $5.1 billion tax savings to companies in 2004. The tax credit has in the past been temporary but President Bush’s ACI proposes to make it permanent. Apart from direct funding, the federal government also has a number of programs in place that focus on the creation of networks of companies and research institutions (for a case example see Curtis 2003). Two programs of the Department of Commerce are particularly noteworthy, also because they have been repeatedly targeted for elimination by the Bush administration and rescued by supporters in Congress: The Advanced Technology Program (ATP; budget of US $170 million in 2004) funds basic research in cooperation with private companies. While some observers have been strongly supportive of the program (Hill 2003), the Federal Government has repeatedly targeted it for elimination (GAO 2005b). The Manufacturing Extension Partnership (MEP; budget of US $109 million in 2004), administered by the National Institute of Standards and Technology, provides technical support in 350 locations around the USA for manufacturing companies to help upgrade their technological efficiency (Shapira 2003). It, too, has repeatedly been under threat. Another focus of government programs is the inclusion of small- and medium-sized companies in federal research activities. Federal agencies with R&D budgets are part of the Small Business Innovation Research (SBIR, created in 1982) and the Small Business Technology Transfer (SBTT, created in 1992) programs that ensure the participation of small- and medium-sized companies in government sponsored research projects. These programs are viewed positively by many observers: SMEs increased their share of R&D spending by US companies from 12 to 18% in the 1990s (OECD 2004a, b; OECD 1998). But there are also skeptics that find direct effects hard to prove (GAO 2005a). The issues that US science and technology policy is facing are related to both financing and regulation. In terms of financing, there is a concern that past funding patterns have been overly focused on life sciences (which received more than 50% of non-defense related R&D funding) and on applied research, neglecting especially basic research in natural sciences. The Bush administration’s ACI proposes steps to address the problem but it seems likely that the imbalance will stay for some time. Overall funding levels are also a concern. While US federal R&D spending has increased in the last few years, other countries have grown their R&D budgets even more dramatically. Also, US companies have cut-back on their R&D expenditures in response to the end of the “New Economy” bubble in 2000. In terms of the regulatory environment for science and technology a number of topics have dominated the debate: First, concerns about the effectiveness of the US patent system are growing. The number of patents granted in the US has increased significantly in recent years, but there are indications that their quality seems to decline, their legal status seems to deteriorate (many are deemed unenforceable), and that the existing patent pool actually hinders new innovations by creating legal uncertainty and barriers. A key driver is that US courts have taken an increasingly lenient approach to what qualifies as a patent (Quillen 2002); most controversial was the 1998 US appellate court decision in “State Street Bank and Trust vs Signature Systems” which permitted granting patents for methods of doing business. Another factor might be that, since the early 1990s, the US PTO has become a “profit centre” for the Treasury Department, generating up to US $200 million a year, and is therefore potentially more interested in serving the needs of applicants by granting patents than in keeping high standards of patent quality (Jaffe and Lerner 2004). Second, the post-9/11 visa regulations and procedures have created serious concerns about the future ability of US universities and companies to attract and retain foreign talent (American Electronics Association 2006). The administration has recently announced significant reductions of visa processing times but complaints by US universities indicate that damage has already been done. The US government operates a range of policies that aim to support companies or regions deemed to be in distress [see SACAC (2005) for a timeline of programs]. These programs can be broadly distinguished by their focus on the size of the companies at which they are directed [small- and medium-sized companies (SMEs)], their owners (women and minorities), or their locations (rural regions, inner cities, other regions in economic distress). This general approach has changed little in recent years. The programs addressing these three areas cut across a number of different government agencies, including the Small Business Administration (SBA), the Economic Development Administration (EDA), the Department of Agriculture (DoA), and the Department of Housing and Urban Development (HUD). The Small Business Administration (SBA), founded in 1953, has central responsibility for SME policy, focusing on the provision of loans and credit guarantees, export financing, and technical assistance (OECD 2002a, b). More recently the SBA has also branched out into programs for SMEs owned by minorities and women. While the SBA is the main instrument for SME policies in the USA, other agencies such as the Department of Defense and the Department of Energy also have significant SME and minority-owned company programs. The SBA’s programs were last reauthorized in 2002; there has been no major shift in its programs in recent years (OECD 2002a, b). The Bush administration’s current budget plan proposes cuts to a number of SBA administered programs, but with opposition in Congress forming it is unclear whether any of these cuts will materialize. At the same time, new legislation has been proposed that would introduce tax credits for business angels to improve access to capital for entrepreneurs.Footnote 6
 The Economic Development Administration (EDA), founded in 1965 as part of the Department of Commerce, is charged with economic development efforts across US regions. The focus of this work has been on regions that are in economic distress. EDA manages programs to help communities which are undergoing structural change (Economic Adjustment Assistance) or which struggle with international competition (Trade Adjustment Assistance). The EDA is also heavily engaged in rural regions through its regional offices and programs (Porter et al. 2004). The Department of Agriculture, in particular the Rural Development unit, provides an additional array of economic development programs, focused on rural regions but not exclusively limited to the agricultural sector. The Rural Development unit has, for example, in the past administered the Empowerment Zone and Enterprise Community (EZ/EC) and the Renewal Community (RC) programs that provided block grants to communities in economic distress that pass specific conditions in terms of business-friendly policies (GAO 2004). The Bush administration’s 2006 budget proposal included a new US $10 billion (stretched over 10 years) tax incentive program to create Economic Opportunity Zones in areas faced with structural change. The other major new proposal in the budget is a plan to consolidate 18 of the 35 existing grant, loan, and tax incentive programs for economic and community development efforts with a total budget of US $16 billion that are currently spread across seven federal agencies (White House OMB 2005a, b, c). The new unified grant-making program with a budget of US $3.71 billion is to be assigned in its entirety to the Economic Development Administration. The majority of these funds would be made available to communities according to eligibility standards based on recent job losses, unemployment rates, and the extent of poverty. The remaining part would be made available as challenge grants to a small number of communities that have taken the most impressive steps to improve and have the clearest strategy on how to employ the federal funds in their economic development strategies. Traditional economic development policies have been much less in the public debate than science and technology policy. The main concerns in this area relate to the efficiency of many of the programs, especially given the complex organizational structure that allocates responsibility across government agencies and different levels (Drabenstott 2005; Shapira 2001; Porter et al. 2004). Given the overall pressure on the federal budget, spending cuts are likely to be concentrated on areas such as these unless individual interests in Congress defend specific programs important for a particular region. Finally, the USA uses trade policy instruments both as a tool for overall market opening but also to provide short-term economic relief to industries under pressure from foreign competition. In terms of market opening, the USA has combined its efforts to come to a multilateral agreement within the Doha-round with a focus on bilateral free trade agreements (Schott 2004). Better market access in services and better protection of intellectual property rights have been key issues for US negotiators. Bilateral agreements were branded as a way forward while the multilateral talks seemed stuck. But they have also tended to mobilize intense lobbying from specific industries that were to be affected from imports from the country in question. Congressional approval for the most recent trade agreements, like the Free Trade Agreement with the Andean countries, is far from secure. To counter the opposition from labor groups, the USA has been much more active than other countries in providing temporary payments to employees that have lost their jobs due to foreign competition.Footnote 7
 Restrictions towards foreign competition or subsidies for domestic producers have been used in agriculture,Footnote 8 textiles, forest products, and steel (WTO 2006). The USA is, alongside India, the most prolific user of anti-dumping and countervailing duty measures, although filings have declined significantly since 2001. According to the Byrd amendment, the revenues raised through such measures were to be distributed to the affected companies; payments amounted to US $840 million between 2001 and 2003. In 2001, an anti-dumping investigation led to the imposition of higher tariffs and an import quota on steel, a decision that triggered significant protests from foreign trade partners and domestic steel users such as the automotive industry. Both the Byrd amendment and the steel tariffs were the subject of WTO investigations that led to decisions against the policies. The steel tariffs were removed in 2003/2004, after the government claimed success in improving the economic health of the US steel industry (and securing political support for the passage of the Trade Promotion Authority Act of 2002,Footnote 9 the ultimate political goal of the steel tariffs). The Byrd amendment, too, repealed by Congress under growing international pressure, will be finally phased out in 2007. Another bone of contention, the Foreign Sales Corporation tax credit, viewed as an unfair export subsidy by the European Union, was also removed after a WTO ruling in 2002 (Hufbauer 2002). And foreign companies with government-ownerships stakes, such as Deutsche Post, have complained about lobbying from their US competitors that would introduce regulations limiting their ability to compete on the US market. Restrictions toward foreign ownership remain in areas such as airlines and media. Under the Exon–Florio amendment to the Defense Production Act of 1950, foreign acquisitions of US companies are subject to a review by the Committee on Foreign Investment in the United States (CFIUS). Acquisitions can be blocked, if they are perceived to create a threat to national security, for example through critical technology being accessible to other countries. The furor in early 2006 around the acquisition of P&O by Dubai Ports World and the aborted take-over of US Unocal by Chinese CNOOC (Graham and Marchick 2006) brought this legislation to the attention of the broader public. Legislation is currently pending that could make the FDI approval process more cumbersome. The US government also exerts its influence on the behalf of US companies in large procurement decisions by foreign governments or government-owned companies. The most obvious examples can be found in defense procurement but the practice also extends to civilian uses. Industries in which these practices are most common are defense, aerospace, energy, public transportation equipment, and construction services. Others are airlines (use of bilateral agreements to open markets for US airlines), agriculture (opening markets for genetically modified food), and telecommunications (pressure to adopt technology standards developed by the US company, Qualcomm). There are no laws governing these activities and the behavior of the US government in this area has not changed significantly in recent years. The practice is, of course, widespread in other countries as well, and it is not obvious that the USA is in general more active or aggressive in this respect than other countries. For political and economic reasons, however, it is more powerful than most other countries in supporting the interests of its companies in this way. Overall, trade policies in the USA suffer from the same dichotomy as in many other advanced economies: a general commitment towards market opening is mixed with violations of this general principle in a few areas that can muster strong political support. With the stalemate on the Doha-round and the limited political capital available for the Bush administration to secure an extension of the fast track-authority there could be increased danger that trade policy instruments are being used by specific industries to pursue their interests. Overall, the policy mix affecting industry in the USA does not seem unique. The science and technology efforts are stronger than in the average OECD country and seem more effective in mobilizing company R&D, but they are not exceptional when compared to Japan or the Nordic countries. The high spending on defense and space programs has certainly created positive spillovers to companies in a number of industries. But maximizing these benefits was not the guiding objective for these programs, and whether they haven been an efficient use of resources in this respect is questionable. The economic development efforts provide a stronger and potentially more effective focus on small businesses and entrepreneurship than elsewhere, but overall the set of economic development programs in the USA seems even more lacking a coherent structure than in other countries. The international trade policy efforts provide general support to market opening, but also suffer from trade and investment barriers in specific cases that hurt the overall credibility of these policies in many countries. Taken together, these policies have benefited a number of industries, especially life sciences, aerospace, and defense. But whether these specific policies have been crucial for the competitive success of companies in these sectors is at least questionable.",19
7.0,3.0,"Journal of Industry, Competition and Trade",26 July 2007,https://link.springer.com/article/10.1007/s10842-007-0021-y,Economic and Industrial Policy Transformations in Finland,December 2007,Pekka Ylä-Anttila,Christopher Palmberg,,Male,Male,Unknown,Male,"Finland’s prospects at the beginning of the 1990s seemed very gloomy indeed. The country was hit by the most severe economic downturn seen in any OECD country since World War II. GDP fell by 10% in just 3 years, and unemployment rose from 3 to 17%. Finland was able to make a fast recovery, however, based on extensive industrial restructuring. The most important factor was the phenomenal growth of the ICT (information and communication technologies) sector. Some of the country’s more traditional industries, such as pulp and paper and engineering, also reinvented themselves through rapid globalization and more intensive use of ICT. The economy went through both inter-industry and intra-industry structural change. In the case of the former, the immense growth of electronics, primarily in the shape of telecommunications, was key. In the case of the latter, creative destruction, which saw the closure of a large proportion of low productivity plants in almost all industrial sectors, was central.Footnote 4 As a result, manufacturing productivity was among the highest in the world by the end of the 1990s, and the ICT sector played a major role in the economy. Finland went from being one of the least ICT-driven countries to becoming the most ICT-driven economy.Footnote 5 This is exceptional, as laggards rarely catch up in the world of ICT, let alone leapfrog the leaders (Fig. 1).Footnote 6
 Finnish manufacturing production volume by industry (billions of euro in 2000 prices). Source: Statistics Finland Finland’s remarkable recovery from the recession and subsequent stellar performance are attributable in large part to ICT and manufacturing as a whole. Policies had their role, as discussed below, but it was private companies, Nokia and others, that were mainly responsible. Despite outward appearances, there was no master plan aimed at promoting the profound structural change and expansion of the ICT sector. Industrial policy thinking in Finland has gone through a number of substantial changes during the last couple of decades. These have seen the emphasis shift from separate science and technology policy to an integrated approach, from macro-oriented structural policies towards long-term micro policies, and from selective and target-oriented policies to ones targeting the business environment. Since the 1990s, the emphasis has been on a systemic view towards policymaking—putting education, R&D, and innovation at the heart of industrial policy, and seeing the concepts of a national innovation system and industrial clusters as basic policy frameworks. Figures 2 and 3 highlight these changes quantitatively.
 R&D expenditure in selected countries. Source: OECD Main Science and Technology Indicators Higher-level education in science and engineering. Source: Ministry of Education and Vartia and Ylä-Anttila (2003)",16
7.0,3.0,"Journal of Industry, Competition and Trade",26 December 2006,https://link.springer.com/article/10.1007/s10842-006-7185-8,"Industrial Policy, FDI and Employment: Still ‘Missing a Strategy’",December 2007,David Bailey,Nigel Driffield,,Male,Male,Unknown,Male,,30
7.0,3.0,"Journal of Industry, Competition and Trade",24 July 2007,https://link.springer.com/article/10.1007/s10842-007-0024-8,Industrial Policies in France: The Old and the New,December 2007,Elie Cohen,,,Male,Unknown,Unknown,Male,"Industrial policy has never given rise to a specific theoretical corpus, despite the fact that foundations for such a corpus have existed since List and Hamilton, and history has taught us that the visible hand of the state has played a significant role every time an economy has taken off. Economists have often taken part in debates on industrial policy by applying some aspect or another of the discipline or by debating the effectiveness and the legitimacy of government action. But they have rarely undertaken the empirical work needed to confirm their theoretical assumptions. Neoclassical theory accepts industrial policy measures only where the market allocates resources inefficiently. This has inspired a body of literature on market failures. Ever since public intervention has flourished in adjustment policies and in prompting and protecting infant industries, a new sphere emerged dealing with the state’s failures and the impasse confronting the “national champions” policies. However, in the 1980s, a number of economists attempted to establish a theoretical foundation for public intervention by borrowing from a variety of advances in economics such as evolutionary theories of economic change, new trade theory, and new economic geography. More recent advances in new development and growth theories gave rise to more pragmatic views on industrial policies.Footnote 2
 In this paper we contrast competitive environmental policies that have an indirect impact on industry—including macroeconomic and social policies, as well as infrastructure and national defense policies—and vertical industrial policies which are sector-targeted policies and which seek to promote sectors in which state intervention take place for reasons of national independence, technological autonomy, failure of private initiative, decline in traditional activities, and geographical balance. According to this perspective, competition policy has a different aim, namely the prohibition of dominant positions, market abuses, and regulation of state aids. Trade policy tends to promote the free movement of goods and services based on the theory of comparative advantage in order to maximize social welfare. R&D or Technology policy tends to create positive externalities for the whole economy. These delineations, based on the specificity of each tool of intervention, are not that simple in the real world. In fact these different policies have the potential of producing tremendous impacts on industry even on a sector-based level. Historically these tools were used specifically (or in conjunction with other tools) to obtain desirable industrial outcomes. Depending on the country variety of capitalism, any existing sector-based policy is the responsibility either of the state (directly or indirectly), or public banks, or local authorities. For example, in the USA the real minister of Industry and High Technologies is in fact the Department of Defense. In Japan, industry has been protected by trade policy and certain sectors have been promoted through finance, currency allocations and support for large commercial undertakings. In Germany aid to businesses is essentially paid through the Länder under the auspices of technology policies, whilst it is the banks’ responsibility to rescue businesses in difficulty. Although vertical and horizontal policies may play the same role in different periods and countries, it is useful to make analytical distinctions because we need to understand why the apparent successes of certain policies are still contested and if there is more room for industrial policy in a globalized world.",40
7.0,3.0,"Journal of Industry, Competition and Trade",20 July 2007,https://link.springer.com/article/10.1007/s10842-007-0018-6,Industrial Policy in Japan,December 2007,Risaburo Nezu,,,Unknown,Unknown,Unknown,Unknown,,
7.0,3.0,"Journal of Industry, Competition and Trade",02 August 2007,https://link.springer.com/article/10.1007/s10842-007-0016-8,China’s Quest for Innovation-Driven Growth—The Policy Dimension,December 2007,Gernot Hutschenreiter,Gang Zhang,,Male,,Unknown,Mix,,
7.0,3.0,"Journal of Industry, Competition and Trade",24 July 2007,https://link.springer.com/article/10.1007/s10842-007-0020-z,Industrial Policy in the New Member Countries of the European Union: A Survey of Patterns and Initiatives Since 1990,December 2007,Ádám Török,,,Male,Unknown,Unknown,Male,"Each of the transition economies of Central and Eastern Europe had suffered from centralised and inefficient industrial policies prior to 1990. These ranged from the relatively liberal Hungarian (and also to some extent Polish) practice to the extremely interventionist schemes of industrial development regulation in East Germany, Czechoslovakia and Romania. Yet even the Hungarian industry was subject to very serious structural distortions due to Socialist industrial policies. Most of its capacities were found to be unable to compete and therefore became redundant when the country opted for import liberalisation and opened up its markets to all kinds of foreign competition in 1989–1991. The Hungarian example of import liberalisation was followed by all transition countries of Europe in the first half of the 1990s. The COMECON was dissolved in 1991. Both GDP and industrial output declined dramatically: certain transition economies (mainly those from the former Soviet Union, including the Baltic republics) lost more than 50 percent of their pre-1989 GDP during the first years of transition. Even the more advanced transition economies accessing the EU in 2004 were able to return to their pre-1989 GDP levels only in the late 1990s. Between 1988 and 1993, industrial output dropped by more than 40 percent in Hungary and Poland (and even more in less developed economies of the region). The “transitional recession” called for completely new approaches to economic policy in general, and industrial policy in particular. As a rule, the transition economies of Central and Eastern EuropeFootnote 1 (CEECs for convenience) more or less hesitantly adopted the “Washington Consensus” most of the elements of which were regarded as prerequisites for the support by the international financial community for the transition process. These principles and guidelines were also understood as requirements for later admission to the Organisation for Economic Co-operation and Development (OECD) and subsequently to the EUFootnote 2. Industrial policy thinking of the early transition governments was characterised by an outspoken liberal approach, leaving structural change entirely to the market (cf. Biesbrouck and Jackson 1995). For example, a very strict bankruptcy law was adopted in Hungary in 1992. The example of the European Union was also quoted in support of this liberal set of arguments (Török 1995, p. 105). It was pointed out that the Treaty of Rome did not contain any explicit element permitting industrial policy, but the EC Treaty has the chapter “Industry” since Maastricht. The idea of “implicit” industrial policy packaged in technology policy, competition policy and regional policy measures and using a strong horizontal approach was not shared by the majority of decision-makers in those countries at that time. Basically any government role in industrial development was challenged as a return to former policy practices, and a “hands-off” pattern of industrial policy seemed to prevail in most CEECs. The actual policy mix, however, was a bit different. The Hungarian government gave up its extremely liberal approach to industrial policy already in 1992–1993 when it found that it could not remain a passive observer of the collapse of a string of manufacturing firms which were important in exports and employment. Further arguments for government intervention in this respect included corporate debt burdens inherited from pre-1990 times and poor chances of privatisation for indebted firms.
 Crisis management in the Hungarian industry At the start of 1994, the consolidation package of the Hungarian “Dirty Dozen” (12 industrial firms in the engineering, aluminium, fertiliser, rubber and glass industries, to which three more companies were subsequently added) carried the following price tag: USD 700 million in debt cancelled, USD 30 million in debt rescheduled, and USD 500 million in debt swapped for equity. Furthermore, USD 300 million in tax arrears were rescheduled and USD 510 million from privatisation revenues rechanneled to these firms (Török 1995, p. 108). To compare: the expenditure side of the state budget amounted to about USD 23 billion in 1994. Basically all of these firms could be privatised in the second half of the 1990s, but revenue from such privatisation was not much higher than the bill of the consolidation package. Poland has had some kind of industrial policy only from September 1993 onwards (e.g. Lipowski and Kulig 1995, p. 241). Slovenia’s policy for the restructuring of manufacturing firms to be offered for privatisation was carried out by the Development Fund (Stanovnik and Lapornik 1995). Bulgaria had a policy package for “marketisation” in the early 1990s, but industrial policy remained utterly passive due to political changes in 1992 (Dobrinsky 1995). The Romanian government introduced an ambitious industrial restructuring programme in 1993 (Mihaescu and Biesbrouck 1995) but this programme was basically a failure (Balla 2002). Independent Czech and Slovak industrial policies both followed the lines of Czechoslovak demonopolising and restructuring efforts between 1990 and 1992 (Flek 1995). The Czech government was, at least in the early 1990s, the only one in the former CEECs which openly diverged from the neo-liberals approach still dominant in the region at that time. Elements of implicit industrial policy could rather be observed in Slovakia: thus Slovak competition laws (similarly to those in Hungary, Romania and Slovenia, e.g. Kravtseniouk 2002) included exemptions from otherwise strict cartel regulation and merger control where greater domestic market power was considered helpful in increasing the export competitiveness of Slovak firms. The first industrial policy packages in the transition process served a double purpose. The rhetoric was more or less that of the “pure mainstream” borrowed from standard international macroeconomics (e.g. Krugman and Obstfeld 1991, 2000), with a straightforward rejection of any kind of industrial policy. The practice was much more coloured when the industry restructuring process (for its details and a survey of literature see Lavigne 1999, 179–181) was considered a prerequisite for privatisationFootnote 3. Whilst no explicit industrial policy packages were announced, governments became increasingly more active in directing and orientating structural change. Industrial policy thinking in the New Member Countries gradually began to change from the late 1990s onwards when it became evident that “competition policy” in the European Union has been, at least in part, a code name for implicit industrial policy since Maastricht. Two sets of ideas may be identified at this point. First, the stronger profile of strategic thinking in the European Union which emerged with the Lisbon Strategy made it plain to economists in the CEECs that modern economic policy thinking is not necessarily in line with the “Washington consensus”-based set of ideas, and that rejecting (or having reservations on) some elements of the “consensus” does not mean a return to Communist economic policies. Second, the works of Nobel Laureate Joseph E. Stiglitz and his followersFootnote 4 have gained some ground and reputation among the economic and intellectual elites of most CEECs. Parts of these elites became convinced (or at least aware) of the fact that governments need not necessarily be incompetent, bureaucratic and corrupt, and that increases in competitiveness and welfare may potentially also be expected from well-designed government policies. Industrial policies of the CEECs in the early 2000s definitely carry the hallmark of changes in approaches and come up with modernised toolkits. Still, it would be exaggerating to think that these industrial policies can be really effective in helping countries to fulfil their own convergence-related objectives. An attempt towards their balanced assessment is set out below.",14
7.0,3.0,"Journal of Industry, Competition and Trade",16 August 2007,https://link.springer.com/article/10.1007/s10842-007-0019-5,From Industrial to Innovation Policy,December 2007,Luc Soete,,,Male,Unknown,Unknown,Male,"There is probably not one concept in the economic policy field which raises today so much controversy as industrial policy. As Pack and Saggi (2006) e.g. observe in their recent survey of industrial policy: “Few phrases elicit such strong reactions from economists and policy makers as industrial policy”. There are many reasons for this, not in the least the changing global political environment with the end of the Cold War and the ensuing much wider acceptance in national policy circles, not just in small countries, of an increased reliance on the international trading and exchange in goods and services. Industrial policy at least in the definition used here: structural policies designed to strengthen the efficiency, scale and international competitiveness of domestic industrial sectors, typically contains an element of national champion, of self-reliance in bringing about economic growth and development. Not surprisingly, the concept was particularly popular in early post-war Europe and appears today particularly popular in emerging economies, and to a lesser extent some of the new European member states. In this short article we enter in some more details in the underlying analytical underpinnings of this fall and rise in popularity in industrial policyFootnote 1. Industrial policy became rapidly one of the corner stones of economic policy in the early post-war period with the need felt in many national policy circles, and most notably in those economies which had been most devastated by the war, to support a more rapid structural transformation of their economies towards internationally stronger, large industrial sectors and complexes. In Europe, it included alongside the traditional heavy, capital and scale intensive industrial sectors such as coal and steel mining—the European Coal and Steel Community (created in Paris in 1952 and dismantled (formally integrated in the EC) in 2001)—also the agricultural sector with the development of national, and in the case of Europe, a Common Agricultural Policy. Over time with the subsequent GATT rounds of international trade liberalisation, industrial policy became much more dominated by the need to assist the international “adjustment”, as it was called euphemistically, of an increasing number of sectors: from the old coal and steal mining sectors to more traditional labour intensive sectors suffering increasingly from increased international competition, such as clothing and textiles, assisting those sectors by providing financial support for mergers, job displacement and cross-border integration. Viewed ex post, it might well be argued that the absolute height of belief in the virtues of a European as opposed to national industrial policy, was the development under the auspices of the European Roundtable of Industrialists (created in 1983) of the so-called Europe 1992 Single Market, resulting with the removal of internal trade barriers in further inter-sectoral shifts in various manufacturing sectors amongst European countries and as a consequence European industrial specialisationFootnote 2 and increased international competitiveness. In a first section, we turn to some of the modern economic arguments in favour of such industrial policies as exposed for instance in some of earlier work, as summarized in Dosi et al. (1990). In a second section, we broaden the analysis away from the strong sectoral focus of industrial policy towards the much broader notion of innovation policy as it became developed over the last twenty years and gradually rose to popularity in the run up to the Lisbon summit in March 2000. Today innovation has actually emerged as one of the most popular economic terms; as often used on the Internet as the concept of GDP as a search on Google Trends illustratesFootnote 3. This shift in focus cannot be seen independently from the major shifts in the world economy and in particular the much greater readiness to rely on “abroad” to bring about domestic structural change, whether under the form of international trade competition of foreign direct investment, mergers or acquisitions. At the same time the large national champions themselves have gradually transformed into truly “multinational” companies with increasingly multi-national, as opposed to national interests. This holds both for developed countries as well as for many emerging countries. It explains amongst others the eagerness with which the latter have become members of the WTO. In short, the predominance over the last 15 years, of the absolute faith in the benefits of international markets, capital and technology flows as the means of allocating sectoral resources cannot be seen outside of the broader context of the fundamental changes in the global political, institutional and technological environment which took place over the same period. It is within this context that we discuss in Section 2 the emergence of innovation policy as a much broader policy framework bringing to the forefront the local systemic features anchoring so to say nationally industrial production. We conclude with some speculative thoughts on what all this might mean for the design and future development of industrial policy. From something with a distinct negative connotation in the 1980s often resulting from some spectacular particular cases of policy failures, industrial policy under its new form of innovation policy seems to open up new policy priorities: e.g. in the design of appropriate eco-innovation as well as social welfare policies in both the developed and emerging economy world.",55
7.0,3.0,"Journal of Industry, Competition and Trade",26 July 2007,https://link.springer.com/article/10.1007/s10842-007-0022-x,The European Commission’s New Industrial Policy in an Integrating and Globalizing World,December 2007,Heinz Zourek,,,Male,Unknown,Unknown,Male,"In October 2005, the European Commission (2005a) announced a new industrial policy for Europe in the form of a Communication entitled “Implementing the Community Lisbon Programme: A Policy Framework to Strengthen EU Manufacturing—Towards a More Integrated Approach for Industrial Policy”. This policy forms a key part of the Commission’s commitment to focus on growth and jobs as a necessary means to preserve the European Union’s (EU) social cohesion and maintain high environmental ambitions in Europe. Manufacturing industry is important for the EU economy. It directly provides around a fifth of EU output and employs some 34 million people. However, manufacturing’s importance to the dynamism and competitiveness of the EU economy is much greater than its size might suggest. To start with, manufacturing is key to exploiting the new knowledge economy: over 80% of EU private sector research and development (R&D) expenditures are spent in manufacturing. Manufacturing industries therefore provide the major impetus for the development and adoption of new technologies, and they are a key driver of productivity growth. Moreover, the share of manufactured products in international trade is far larger than that of services. Manufacturing provides some three-quarters of EU exports, thus dominating the current account balance. The ability of the economy to pay for energy and the import of other basic resources therefore depends on manufacturing exports. Finally, manufacturing makes intensive use of inputs from other sectors of the economy, creating growth and jobs in the wider EU economy. Input–output tables indicate that manufacturing sales are around three times as large as manufacturing value added. For example, as documented in European Commission (2005b), manufacturing’s purchases from the services sector alone amount to some two-thirds of manufacturing value added. The need for a new and modern industrial policy is therefore almost indisputable. Of course, modern industrial policy has to be sophisticated and intelligent. It is nowadays illusory to think that one can select winning technologies and sectors and try to determine exactly where and how jobs should be created. Nor is it possible in today’s closely integrated world economy to try to resist globalisation and structural change. Instead, the role of industrial policy is to provide the right framework conditions for enterprise development and innovation and to help manage the process of industrial change. This will help make the EU an attractive place for industrial investment and job creation. In addition, industrial policy has a key role to play in addressing market failures and complex coordination issues where technological development, standard setting, and the generation of wider benefits to society are linked. This means that industrial policy covers three distinct, but interrelated elements. First, it is to optimise horizontal framework conditions, as it is necessary to ensure that ‘horizontal’ policies, such as for example competition policy or R&D policy, are conducive to the development of competitive and innovative enterprises. Second, it is to optimise sectoral framework conditions through the development of appropriate regulatory frameworks for individual sectors, including at both national and EU level, with the aim to promote competitiveness. And third, where markets fail due to externalities or complex coordination problems, a sectoral approach is justified. This is likely to be especially important in respect of technology development in conjunction with standard setting and the procurement of (quasi-)public goods. Clearly, this third, more activist, approach will have to be firmly based on robust economic criteria and analysis to avoid a return to the ‘picking-the-winners’ policies of the past. Given that the competences for the policy tools are partly at Community level and partly at Member State and even regional level, coordination of initiatives across different policy levels is essential. Indeed, the Treaty asks the Community and the Member States to coordinate their industrial policies.Footnote 1
",11
7.0,3.0,"Journal of Industry, Competition and Trade",26 July 2007,https://link.springer.com/article/10.1007/s10842-007-0025-7,Industrial Policy: A Dying Breed or A Re-emerging Phoenix,December 2007,Karl Aiginger,,,Male,Unknown,Unknown,Male,"Industrial policy covers a wide range of policy measures, some of which are explicitly put into practise under this heading. In many cases, however, an implicit industrial policy agenda is pursued under diverse policy lines, such as the provision of tangible and intangible infrastructure, public procurement and defence, merger control, antidumping and employment protection. And industrial policy is closely related to other policy areas like regional policy, education and training and last but not least, innovation policy. There have been considerable differences not only in the philosophy, but also in the actual pursuit of industrial policy over time and across countries. The differences may have been larger between the US, Japan and Europe, but were also present within Europe.Footnote 1 Ketels (2007) claims, that the US has a de facto industrial policy focusing on science and technology, small firms and clusters, enabling strong regional specialisation. Finland developed a systemic, proactive policy design, making knowledge the driving force of transformation based on a cluster approach and the search for technologies defining the competitive edge in the future (Ylä-Anttila and Palmberg 2007). In the United Kingdom, the attraction of FDI has always dominated industrial policy (Bailey and Driffield 2007). All country specific approaches have to be adapted in the integrating and globalising world; France can no longer rely on the sector approach and on favouring specific technologies. Firms are international players, and preconditions for “high tech Colbertism” are no longer given (Cohen 2007). Japanese policy abandoned the focus on sectors and specific technologies; it now promotes competition, and links between universities and firms (Nezu 2007). China is beginning to engage in an innovation policy complementing more traditional industrial policies (Hutschenreiter and Zhang 2007). The new member countries of the EU are focusing on foreign investment, while industrial policy strategy is becoming broader as a consequence of the Lisbon Strategy (Török 2007). Soete (2007) analyses the gradual transformation of industrial policy in the direction of innovation policy, with a definition of innovation including social, organisational and environmental innovations. The European Commission recently developed a new concept of industrial policy which complements the dominant horizontal approach—broad measures, which have an impact on most or all industries—with measures specifically important to specific industries. This new approach (Zourek 2007) was labelled the “matrix approach” in Aiginger and Sieber (2005). The columns of the matrix are comprised of individual policy lines, while sectors define the rows. The boxes of the matrix provide information on the expected industry specific impact (be it the importance or the specific nature of the intervention). This paper is structured as followed: Section 2 analyses the content and the scope of industrial policy and relates policy to the changing role of manufacturing in high-income countries. Despite the increasing share of services, manufacturing remains a core sector, even if the distinction between manufacturing and service is increasingly unhelpful. Section 3 provides the rationale for industrial policy, the transition from policy-oriented arguments and static market failure to dynamic positive externalities, failures in co-ordination and informational problems. It also summarises arguments against policy intervention. Section 4 supplies data on real world industrial policy, the strategies pursued and the results achieved. It describes the matrix type approach to industrial policy and the sector taxonomy recently proposed by the European Commission, as well as its first application. Finally, Section 5 provides a vision of what a systemic industrial policy might look like in the future. This vision, which is related to the Lisbon Agenda, is closely linked to innovation strategy and combines industrial policy proper with education, regional strategy, and labour and product market flexibility. Systemic Industrial Policy (SIP) fosters the dynamic competitiveness (Aiginger 2007a, b) of a country or region where competitiveness is defined by a welfare function with a set of goals in which social innovation and environmental progress also play important roles. We argue that a systemic industrial policy can support the EU Lisbon Strategy, while at the same time serving as a new complementary policy strategy in the globalising world economy.",54
8.0,1.0,"Journal of Industry, Competition and Trade",14 March 2007,https://link.springer.com/article/10.1007/s10842-007-0007-9,Merger Review: How Much of Industry is Affected in an International Perspective?,March 2008,Jan De Loecker,Jozef Konings,Patrick Van Cayseele,Male,Male,Male,Male,,2
8.0,1.0,"Journal of Industry, Competition and Trade",15 March 2007,https://link.springer.com/article/10.1007/s10842-007-0006-x,Measuring Price Effects of Concentration in Mixed Oligopoly: An Application to the Swedish Beef-slaughter Industry,March 2008,Azzeddine Azzam,Hans Andersson,,Unknown,Male,Unknown,Male,,7
8.0,1.0,"Journal of Industry, Competition and Trade",27 March 2007,https://link.springer.com/article/10.1007/s10842-007-0005-y,Banking Competition and SMEs Bank Financing. Evidence from the Italian Provinces,March 2008,Mariarosaria Agostino,Francesco Trivieri,,Unknown,Male,Unknown,Male,"Increasing time and effort have lately been devoted to empirically investigating the impact of bank competition on firms’ access to credit. Such an empirical interest has been driven by the failure of the existing theoretical models to provide univocal predictions on the issue. In this work, we use a large set of microdata running up to 2000 from 1995, to test whether local banking competition affects both the probability and the amount of bank financing that Italian firms employ. We focus on small and medium sized manufacturing firms, which have little access to capital markets (either public equity or bond market) and are bound to ask for credit from banks with branches in the same local market where they operate. Consistently with other contributions on the Italian banking market, we define 103 local markets corresponding to the existing administrative provinces. As Bonacorrsi di Patti and Dell’Ariccia (2004) highlight, this disaggregation enables us to take advantage of an important feature of the Italian case. Indeed, Italian provinces are characterized by different banking structures and this provides sufficient cross-sectional variability within a single institutional framework. Given this regulatory uniformity, there is no need to control for different regimes. Building upon previous studies on competition in the banking sector, we recover some measures of local banking competition, such as the Herfindahl–Hirschman Index on deposits (HHI), and the Panzar and Rosse (1987) H statistic. We then employ these indexes as explanatory variables in two regression models: one aimed at estimating the probability that a small–medium sized firm employs bank debt as a source of financing, the other analyzing the amount of this kind of financing. A distinguishing feature of our analysis is that it allows correlation between these models and takes into account the censored nature of the dependent variable. In other words, instead of estimating separate regressions, as most empirical studies do, we adopt Double Hurdle and type II Tobit models (alias sample selection) to shed light on the relationship between bank competition and access to credit in the Italian provinces. In particular, we investigate whether this relationship varies across firms of different age, and, more generally, of different opaqueness by constructing an index of firm transparency. The econometric strategy, the use of both structural and non-structural indicators of local banking competition, which are also combined in a composite index by using Principal Component Analysis, and the measures of firm opaqueness that we employ represent the main distinctive aspects of our paper with respect to the extant literature in the field. The remaining part of the paper is organized as follows: Section 2 presents a brief review of the literature on the economic effects of banking competition; Section 3 summarizes the main approaches we adopt in measuring banking competition and specifies the econometric models we employ; Section 4 describes the data; Section 5 reports the results that are obtained and the robustness checks that are performed; Section 6 concludes.",8
8.0,1.0,"Journal of Industry, Competition and Trade",10 May 2007,https://link.springer.com/article/10.1007/s10842-007-0011-0,Which Targets Stimulate Cross-border Acquisitions? An Empirical Investigation of Industrial Organization and Trade Factors within a Competition Framework of International and Domestic Acquisition Targets,March 2008,Antonios Georgopoulos,George Argyros,Giota Boura,Male,Male,Female,Mix,,
8.0,1.0,"Journal of Industry, Competition and Trade",03 May 2007,https://link.springer.com/article/10.1007/s10842-007-0012-z,A Structural Model for Evaluating the Sector-specific Impacts of Preferential Trade Agreements,March 2008,Jad Chaaban,Alban Thomas,,Male,Male,Unknown,Male,"The debate over the “right” trade liberalization policies has created a rich theoretical and empirical literature. As empirically evaluating the welfare impacts of multilateral trade liberalization remains a considerable challenge, the empirical trade literature has instead focused on evaluating Preferential Trade AgreementsFootnote 1 (PTAs) and the welfare consequences they impose, both on member and non-member countries. The existing studies have been much debated, with one major criticism being that they concentrate only on aggregate trade creation or diversion following a PTA, without looking at sector specific effects (Panagariya 2000). Moreover, almost all of these studies have ignored the role of imperfect competition and strategic interaction in international markets, whereas these aspects have been extensively treated in the theoretical literature. This paper tries to fill in this gap by developing a structural model of imperfect competition in international markets, using a flexible demand form and a general framework for oligopoly behavior. We use a general Conjectural Variation (CV) approach to model firm behavior, and this allows capturing multi-firm strategic interaction beyond the restrictive Bertrand setting, when solving for the structural first-order conditions from the firms’ profit maximization program. Heavily drawing from the New Empirical Industrial Organization (NEIO) literature,Footnote 2 our model both offers a consistent treatment of demand in international markets, and allows several competitors to operate in a market at the same time. We illustrate how our model can be used by evaluating the impact of a PTA signed by Lebanon and Egypt, on the iron and steel import sector. We focus on the Egyptian PTA because this agreement was the most significant one Lebanon signed in recent years, as it resulted in the highest relative decreases in tariffs conceded by Lebanon. The iron and steel sector has been selected in our experiment because of its central role in the post-war Lebanese economy: steel rebar imports were essential in recent years for rebuilding Lebanon’s infrastructure, and Lebanon has an infra-marginal steel production sector. This has placed steel imports at the heart of the Lebanese industrial sectors in recent years, making it a good testing ground for our general model. The availability of highly disaggregated Lebanese customs trade data makes it possible to evaluate in a relatively precise way the impact of a PTA with respect to trade creation and diversion, within the general structural model we develop. The model’s structure allows own-price and cross-price elasticities to vary across competitors and allows market shares to vary across firms as a function of real consumer expenditure. The main results of the paper are as follows. First, we reject the simple import demand model in favor of the developed structural approach we propose. Second, we show that the simple demand model tends to overestimate trade creation and underestimate trade diversion following a PTA, when compared to the structural framework. The paper is organized as follows: Section 2 reviews the related literature surrounding the analysis of PTAs and the structural modeling of international markets. In Section 3 the structural model, which forms the core of our analysis, is exposed. We particularly highlight how the demand and supply side specifications interact to form a set of equations that can be easily estimated. Section 4 presents the data used in our empirical estimation. Section 5 lays down the equations to be estimated, and Section 6 discusses the estimation results and the implications of incorporating a structural analysis into the evaluation of PTAs in general. Concluding remarks are in Section 7.",1
8.0,2.0,"Journal of Industry, Competition and Trade",26 May 2007,https://link.springer.com/article/10.1007/s10842-007-0013-y,Competition for Business Location: A Survey,June 2008,C. Dembour,,,Unknown,Unknown,Unknown,Unknown,,
8.0,2.0,"Journal of Industry, Competition and Trade",23 May 2007,https://link.springer.com/article/10.1007/s10842-007-0010-1,Estimating Switching Costs in Mobile Telephony in the UK,June 2008,Lukasz Grzybowski,,,Unknown,Unknown,Unknown,Unknown,,
8.0,2.0,"Journal of Industry, Competition and Trade",06 June 2007,https://link.springer.com/article/10.1007/s10842-007-0014-x,Effects of Adverse Selection on a Multinational Firm’s Decision on where to Subcontract,June 2008,Rosa Forte,António Brandão,,Female,Male,Unknown,Mix,,
8.0,2.0,"Journal of Industry, Competition and Trade",16 May 2007,https://link.springer.com/article/10.1007/s10842-007-0009-7,Technical Progress and Labour Demand in Swedish Manufacturing Firms,June 2008,Lihong Yun,,,Unknown,Unknown,Unknown,Unknown,,
8.0,3.0,"Journal of Industry, Competition and Trade",03 October 2008,https://link.springer.com/article/10.1007/s10842-008-0037-y,International Trade in Services—Editorial Introduction,December 2008,Arjan M. Lejour,Peter M. Smith,,Male,Male,Unknown,Male,"While the economies of developed countries are dominated by services, the treatment of international trade continues to focus on goods. The most extreme version sees services as non-tradable even though some goods producing industries are non-tradable (construction and mining are location specific) and transportation services have always been at the heart of trade in goods. The nearest equivalent to trade in goods for services is direct cross-border transactions in which the purchaser of the service is located in one country and the provider in another. Services also cross borders when the consumer moves to the country of the provider to obtain a service or when the producer temporarily moves to the country of a client to provide a service. In the terminology of the General Agreement in Services (GATS), the three different types of service provision are known as modes 1, 2 and 4. Collectively they constitute cross-border trade in services. Since there are no custom posts for such services, surveys provide the source of data for these transactions and are published as part of the balance of payments statistics. Statistics on trade in services cover modes 1 and 2 with very limited coverage of mode 4 (Bensidoun and Ünal-Kesenci 2007). Overall, services account for 20% of world exports, a share that has been stable since the mid 1990s. Only one tenth of world services output enters international trade, compared to over half of the production of goods (UNCTAD 2004). The seemingly rather modest contribution of cross-border trade in services compared to its share in output needs to be qualified in a number of ways. First, it measures trade as opposed to tradability. If services can be traded but face non-tariff and other barriers that effectively diminish the extent to which services are traded, there may be considerable untapped potential for trade in services. Second, services enter into trade as inputs to the production process of traded goods. They can do this either directly as intermediate consumption to an industry producing traded goods or indirectly embodied in inputs produced in other manufacturing industries that supply inputs to the final traded industry. According to the OECD, in the mid-1990s services accounted directly or indirectly for about 22% of manufacturing production (Pilat and Wölfl 2005). Furthermore, it found that the importance of services embodied in manufacturing has increased substantially since the 1970s. Even within manufacturing, services contribute a considerable share to the output that is finally traded. In the OECD in 2002, occupations that can be considered as services made up about 40% of all persons employed in the manufacturing sector. Conceptually, the share of service occupations in manufacturing covers three different types of situations. Certain of these occupations could be outsourced but the firm prefers to produce their services in-house. Others are integral to the production process and could not realistically be outsourced (for instance production engineers, sales staff). Finally, manufacturing firms also produce services for sale either as joint products (for instance an operating system with a computer) or as a separate add-on service (a maintenance contract or car finance). Available data on turnover for manufacturing firms broken down by activity is scarce. For the few available countries, service activities make up 10–15% of total turnover of manufacturing firms. When such services are supplied by manufacturing firms across borders, they may or may not be recorded separately from goods. The belief that cross-border trade in services may be under-reported and that in any case there exists potential for greatly increased trade either for specific services or for specific occupations has given rise to a vigorous debate on the extent and possibility of off-shoring for services (Blinder 2005; McKinsey Global Institute 2005; Liu and Trefler 2008). As yet it is accepted that such effects have been modest but views differ sharply about the extent to which the phenomena will grow and the nature of the impact should it do so. All services are tradable through a permanent commercial presence in the host country (mode 3 of the GATS terminology). Indeed on different measures this constitutes the dominant mode of supply of services abroad today. It is therefore surprising that commercial presence has generated relatively modest interest compared to that generated by cross-border trade in services. This in spite of the fact that until recently many services remained closed to investment from abroad either as a result of direct supply through a public administration or through public ownership of network industries or through various restrictions based on the nationality of the individual supplying the service. Data on foreign direct investments (FDI) provide the most comprehensive source for studying trade through a permanent presence. Under the impulse of globalisation both cross border trade and FDI increased significantly during the last 25 years. Contrary to cross-border trade, a clear shift has taken place in the share of services in FDI. By 2005, services represented three fifths of the global FDI stock up from a half in 1990 (UNCTAD 2007). This can be taken in part as an illustration of the difficulties of cross-border trade for services and in part of the need for a direct and on-going presence to supply many services. The figures for FDI tend to underestimate the significance of permanent presence for the provision of services because non-equity forms of participation constitute an important means for foreign companies to penetrate the markets of third countries. They include such techniques as franchising, management contracts, concessions and public–private partnerships and are prevalent in industries as diverse as hotels, restaurants and fast-food, car rentals, retailing and construction. For many professional services, partnerships composed of locally established professionals are often the dominant or even required form of operation. Ownership restrictions of airlines have led to the growth of alliances of major carriers. Data on cross-border mergers and acquisitions (M&As) is more up-to-date than that for overall FDI. It confirms the growing importance of services with world-wide cross-border M&As rising from 37% in 1987–1990 to 58% in 2002–2006. Unlike green field investment which tends to increase competition on the domestic market, mergers can pose the danger of powerful foreign suppliers dominating the domestic market. Perhaps the data of greatest interest is that of the local sales of foreign affiliates that can be compared directly with cross-border sales of services and also with sales of local companies. Data on Foreign Affiliates Trade in Services (FATS) is however very limited. According to the CEPII analysis of FATS data from four major investor countries (US, France, Germany and Japan), commercial presence was the dominant form of exchange varying from 70% for the US and France, 59% for Japan and 49% for Germany.Footnote 1
 To explain these different developments we have to dig a little bit into the concept of trade in services and the content of services. First of all, services are a broad concept covering very diverse activities from hairdressers to IT services, from accountants to retail. The papers in this issue focus on producer services. Producer services cover business services, trade, communication, transport, financial, and energy services (see Rubalcaba and Kox 2007 for an overview). Government services and consumer related services such as personal services and tourism are not included in the analysis. Within the group of producer services most papers concentrate on the globalisation of business services, in some cases to a specific type of business services like knowledge-intensive business services (KIBS). Next, different approaches are possible. One is largely empirical, sometimes unconventional, based on the growing availability of data on services and the possibility of using large sets of micro data. The other is more theoretical, based on models of how trade in services should perform under certain assumptions, using a general equilibrium framework. Examples of both these approaches are provided in this volume.",17
8.0,3.0,"Journal of Industry, Competition and Trade",04 October 2008,https://link.springer.com/article/10.1007/s10842-008-0035-0,Trade in High-Tech Services,December 2008,J. Bradford Jensen,,,Unknown,Unknown,Unknown,Unknown,,
8.0,3.0,"Journal of Industry, Competition and Trade",04 October 2008,https://link.springer.com/article/10.1007/s10842-008-0043-0,"Producer Services, Manufacturing Linkages, and Trade",December 2008,Joseph Francois,Julia Woerz,,Male,Female,Unknown,Mix,,
8.0,3.0,"Journal of Industry, Competition and Trade",04 October 2008,https://link.springer.com/article/10.1007/s10842-008-0039-9,Offshoring of Business Services in Small Open Economies: Toward a General-Equilibrium Modeling Approach,December 2008,James R. Markusen,Bridget Strand,,Male,Female,Unknown,Mix,,
8.0,3.0,"Journal of Industry, Competition and Trade",30 September 2008,https://link.springer.com/article/10.1007/s10842-008-0040-3,The Globalization of Intellectual Property Rights and Innovation in Services,December 2008,Keith E. Maskus,,,Male,Unknown,Unknown,Male,"It may seem odd to include a paper on intellectual property rights (IPR) in a journal issue devoted to globalization of services. The general perception is that services are considerably less dependent on protection of new ideas for building market value than are manufacturing sectors and agribusiness. This perception stems from the fact that service providers generally do not apply for patents as frequently as firms in other industries, reflecting the intangible nature of innovation in services and the difficulty of reducing ideas to novel and commercially useful products. However, there are advanced technologies developed and deployed in a number of service sectors, such as software, information technology, entertainment and media production, databases, and business and financial services. Firms in such sectors find that IPR are becoming increasingly important. Despite this important linkage, however, there is virtually no academic literature addressing the various roles of IPR in service sectors. This is a remarkable omission because both intellectual property and a variety of technical and financial services are at the core of modern knowledge economies and globalization. Thus, the novelty in this paper is to set out the essential issues that should command analytical attention and to provide basic initial empirical analysis. The paper explores whether the standard arguments supporting the need for IPR protection hold in services or whether they need modification. It also describes the processes of innovation in various service sectors and the use they make of formal IPR. Considerable attention is devoted also to the ongoing globalization of both intellectual property regimes and services provision through international trade and investment. These processes are deeply interrelated and have broader economic implications. Innovation is important for growth in particular service industries for a number of reasons. First, services make up the bulk of activity and employment in developed economies and innovation is likely to expand employment and the quality of jobs in the long run. Second, high-technology services are increasingly traded across borders and innovation can be a source of comparative advantage. Third, newer and more efficient service provision can reduce costs and expand competitiveness in using industries (Hanel 2004; Markusen et al. 2005; Feldstein 2003). At the same time, since the mid-1990s IPR have been undergoing the most significant globalizing reforms in history. There are several reasons why changes in the global IPR regime matter for service industries. First, some service firms do produce significant amounts of intellectual property. Second, broader and integrated service suppliers may have a research component that can produce intellectual property. Third, some service enterprises may not produce intellectual property directly but their commercial success depends on offering complementary services. Fourth, intellectual property often is directly used by, or distributed through, such service providers as medical facilities, schools, and telecommunications networks. In short, services are both providers and users of intellectual property. As such, they have an interest in achieving an appropriate balance in IPR regimes in order to encourage the development of new content while ensuring adequate access at reasonable cost. Furthermore, services are increasingly globalized themselves, with the volume and proportion of output traded across borders rising in recent years. For example, Sweden’s exports of commercial services (excluding government services) rose from $21.8 billion in 2001 to $42.8 billion in 2005, while its imports rose from $22.9 billion to $35.0 billion.Footnote 1 The growth in trade reflects both technical change (an increase in portability of services) and trade liberalization, with potentially powerful impacts on further economic development (Hoekman 2006). Services also have been an important focus for liberalization of foreign direct investment (FDI) because many international services can only be offered by facilities located in recipient nations (Hoekman 2006; Hoekman et al. 2005; Markusen et al. 2005). Within the EU a concerted effort has substantially reduced national restrictions on foreign investments in service industries. The successive liberalization of restrictions on services trade and entry are a force for inducing structural change in some service industries, including concentration through mergers and takeovers, movement into new lines of business, and introduction of new products and means of offering services to end users. These are all forms of innovation, some of which may be responsive to improvements in IPR protection. As in other sectors, however, differences in IPR protection in different countries may deter trade and investment in some services. This is perhaps most evident in the case of weak enforcement for trademarks, copyrights, and digital products in developing countries. However, there remains uncertainty about EU policy in such areas as software patents and protection for business methods. Whether additional EU harmonization promises gains for European service providers, or may raise costs of access and impede further innovation, are important questions that will be taken up later. These perspectives raise some basic questions. Are IPR really that important for innovation in services? Are there elements of IPR protection that could be improved? Conversely, does the emerging system raise roadblocks to innovation in countries that both import and generate new technology? These questions are not easy to address, because data on services innovation are extremely scarce and the processes of innovation are still not completely understood. Moreover, the relationships between services and IPR, particularly at the international level, have not been the subject of much study. Thus, this paper is largely exploratory, with the intent of spurring more analytical work on these fundamental relationships. The next section explains the basic economic principles of intellectual property protection. Section 3 provides an overview of innovation in certain service sectors and the importance of IPR for ensuring returns to such investments. Section 4 discusses the recent history of IPR globalization and where things may go from here, paying particular attention to issues that affect particular service industries. Section 5 analyzes the relevance of particular forms of IPR for services. Remaining policy challenges are discussed in the final section.",12
8.0,3.0,"Journal of Industry, Competition and Trade",18 October 2008,https://link.springer.com/article/10.1007/s10842-008-0038-x,Cross-Border Mergers & Acquisitions Policy in Service Markets,December 2008,Pehr-Johan Norbäck,Lars Persson,,Unknown,Male,Unknown,Male,"The structure of foreign direct investment (FDI) has shifted towards services in the last few decades. For instance, in 1981, services accounted for about 5% of FDI inflows in the OECD countries. In 2006, the share of services in FDI flows among the OECD countries had increased to 85%.Footnote 1 The increase in service FDI is partly driven by the increasing share of services in the economy as a whole, but is also due the large liberalization- and privatization programs in the service sector all over the world where, for instance, infrastructure services have been opened to FDI.Footnote 2
 Yet, significant barriers to FDI remain in the service sector. For instance, in the EU there is currently a concern that the creation of the internal market for services is faced with obstacles, and that one such obstacle is that cross-border Mergers and Acquisitions (M&As) are prevented by different national restrictions and specific rules. In 2005, Internal Market and Services Commissioner Charlie McCreevy made the following quote: Cross-border consolidation in the financial sector is weak compared to other sectors. Despite the fundamental single market principles of free movement of capital and freedom of establishment, too many obstacles stand in the way of EU financial institutions that want to go cross-border. In many instances, the business case is simply not persuasive enough. Given the fierce global competition that is emerging, we cannot afford to have 25 medium-sized markets made up of second-division champions. We want to ensure that we extract the still-to–be-realised benefits of scale that the European market of 450 million people can offer. Therefore we must tackle the obstacles identified.
Footnote 3
 In this paper, we present a framework, built on Norbäck and Persson (2007), for studying different policy issues concerning cross-border M&As in liberalized service markets. Our analysis takes its starting point in many of the service markets that are liberalized being markets with high entry barriers which will naturally be characterized by oligopolistic competition.Footnote 4 Moreover, FDI in the service sector predominantly takes place through cross-border M&As, where foreign firms acquire domestic firms, rather than making de-novo entry.Footnote 5 We will assume that service provision by foreign firms requires commercial presence (Mode 3 under the definition of services trade under GATS), but otherwise abstract from the issue of how FDI and cross-border M&As differ between services and goods. In the model, a domestic firm is initially located in the market in the host country. There are also several multinational enterprises (MNEs) located in the world market. The market in the host country will now be exposed to international competition. In a first stage, the host country set its cross-border M&A policy. In the second stage, the MNEs might acquire the domestic firm’s assets. In the third stage, firms have the option of investing in new assets. Some MNEs may not be able to recover the investment costs associated with greenfield entry and will then not enter. Finally, firms compete in oligopoly fashion in the service market. We develop a simple graphical solution to the model which we use to illustrate the results. In the Appendix, we also provide a Linear-Quadratic Cournot Model, with asset complementarities and endogenous investment, which can be used to evaluate different policies in more detail. In the policy debate, the effects of cross-border M&As on the host economy are a greatly discussed issue.Footnote 6 Despite the welcoming attitude towards inward FDI among countries liberalizing their service markets, some concerns are raised about the impact of cross-border M&As. One such concern is that strong foreign entrants can acquire domestic firms at “too low” a price. There is also a concern that, in contrast to greenfield entry, cross-border M&As are driven by market power reasons and do not increase the productive capacity and might lead to lower consumer welfare and layoffs. To address this issue, we first study the impact of a discriminatory cross-border merger law. Our first result is then to show that discriminatory cross-border merger law risks being counterproductive by blocking cross-border M&As associated with complementarities that would benefit both domestic consumers and domestic owners. We also show that there is a limit to the possibility for market power driven cross-border M&As, since they may trigger greenfield entry and expansion by rival firms. These findings thus suggest that a merger law discriminating against cross-border acquisition does not seem generally motivated, since it may hamper an efficient structural change of domestic industry; rather a merger law blocking foreign acquisitions driven by market power motives is to be preferred. We then study other policies towards cross-border M&As. In particular, we show that specific takeover regulations that increase the cost of foreign acquisitions or preferential treatment of specific buyers could be counterproductive. The reason is that these policies imply that there will be few potential buyers of domestic firms. We then show that with seller competition, the gains from an acquisition at high complementarities accrue to the foreign acquirer, in fact leaving domestic firms worse off, and may reduce total welfare. Having policies that give many potential buyers the opportunity to participate in the acquisition market therefore seems well motivated. This seems particularly relevant in the case of privatizations. Moreover, harmonization of the EU takeover regulations is, in this respect, not only beneficial for potential acquiring firms, but foremost for owners of target firms. Another channel through which merger policy can play an important role in liberalized service markets is through the fact that incumbents who have established a strong initial position might try to protect their market from new foreign entry. Indeed, in the analysis, it is established that for sufficiently high entry costs and sufficiently concentrated service markets, preemptive domestic acquisitions can take place, i.e. acquisitions motivated by the desire to prevent a cross-border acquisition that would increase competition in the market. Consequently, competition authorities have an important task in monitoring these behaviors and considering preemptive domestic acquisitions. The related theoretical literature on FDI and MNEs is surveyed in Barba Navaretti and Venables (2004). Typically, this literature does not explicitly address the question of whether entry into a foreign market is greenfield or through the acquisition of assets already in the market, or both, and its welfare implications, an issue which constitutes the focus of our study.Footnote 7 There is also a small theoretical literature addressing the welfare aspects of cross-border mergers in international oligopoly markets.Footnote 8 But this literature typically treats the greenfield investment alternative as cursory. More closely related papers are Mattoo et al. (2004) and Klimenko and Saggi (2007). They study how entry mode affects welfare in markets where foreign technology transfers are possible. They find that restrictions on cross-border M&As can be welfare enhancing in such an environment. The reason is that foreign entrants may use a more updated technology when entering greenfield than by an acquisition. However, they abstract from the competitive bidding over the domestic firm, which is central in our approach. As stated above, the theoretical model is built on Norbäck and Persson (2007), and is also closely related to Norbäck and Persson (2005). Both these papers study welfare effects of cross-border M&A and greenfield entry in an international oligopoly market. The first value added of this paper is that it provides facts about the service markets showing that the general set-up of those models is applicable in studies of the service market. Moreover, in order to simplify the dialogue between researchers and policy circles, we have made the model more reader friendly and have also added an explicit policy stage that makes the model tractable for different policy analyses in a coherent way. We have also extended the Norbäck and Persson (2005, 2007) models by allowing for (i) the possibility that cross-border M&As might trigger more greenfield entry, and (ii) allowing for seller competition. In Section 2, we present facts about FDI in the service sector, on which we build our theoretical policy framework. In Section 3 the base model is described. Section 4 studies the impact on the host country of cross-border M&A policy in liberalized service markets in terms of (i) discriminatory cross-border merger laws, (ii) local equity requirements, and (iii) foreign takeover regulations. Section 5 studies the effects of domestic merger policy in liberalized service markets and Section 6 concludes the paper.",6
8.0,3.0,"Journal of Industry, Competition and Trade",01 October 2008,https://link.springer.com/article/10.1007/s10842-008-0036-z,The General Agreement on Trade in Services: Doomed to Fail? Does it Matter?,December 2008,Bernard Hoekman,,,Male,Unknown,Unknown,Male,"One of the major results of the Uruguay Round was the General Agreement on Trade in Services (GATS). Part of the new World Trade Organization that entered into force in 1995, the GATS greatly extended the coverage of the multilateral trading system by establishing rules and disciplines on policies affecting access to service markets.Footnote 1 The GATS was negotiated during a period of far-reaching unilateral reforms of service sector policies, as “natural monopoly” arguments for State-provision or control of major service industries were eroded, and large-scale privatization programs were pursued in many parts of the world, developed and developing. These reforms were driven by technological changes as well as increasing recognition that the cost and quality of services is important for the growth performance of the economy. An efficient, competitive financial sector is critical in ensuring that capital is deployed where it has the highest returns. Low cost and high quality telecommunications will generate economy-wide benefits, as the communications network is a transport mechanism for information services and other products that can be digitized. Similarly, transport services affect the cost of shipping goods and movement of workers within and between countries. Business services such as accounting, consulting and legal services reduce transaction costs associated with the operation of financial markets and the enforcement of contracts, and are a channel through which business process innovations are transmitted across firms in an industry or across industries. Retail and wholesale distribution services are a vital link between producers and consumers, with the margins that apply in the provision of such services influencing the competitiveness of firms on both the local and international market. Health and education services are key inputs into – determinants of – the stock and growth of human capital. Services are very heterogeneous, and span a wide range of economic activities. This diversity masks a fundamental function of many services: they are inputs into production. This function of many services offsets a long-standing concern in the economic literature that a steadily expanding service sector may (must) be associated with a declining growth rate of the economy. These concerns reflect a presumption that limited potential for productivity improvements in services implies that over time the real costs of—and employment in—services must rise relative to other sectors, reducing the growth potential of the economy to that of the “stagnant” services sectors (Baumol 1967). Once it is recognized that many services are inputs, an expansion of the service sector can increase growth.Footnote 2
 Liberalizing access to service markets (enhancing contestability) will reduce what Konan and Maskus (2006) call the cartel effect—the markup of price over marginal cost that incumbents are able to charge due to restricted entry; and attenuate what they call the cost inefficiency effect—the fact that in an environment with limited competition, the marginal costs of incumbents are likely to be higher than if entry was open. These effects can have significant impacts on all sectors and households in an economy.Footnote 3 There is an emerging body of econometric evidence that policy reforms to increase competition in services industries, including through international liberalization, can help boost growth prospects and enhance welfare. Mattoo et al. (2006) find that countries that fully liberalized the telecommunications and financial services sectors grew, on average, about 1.5 percentage point faster than other countries. Eschenbach and Hoekman (2006a) find that financial and infrastructure services policy reforms had an important, statistically significant positive impact on per-capita growth of transition economies during the 1990–2004 period. Country-specific analyses have found a positive relationship between services liberalization, services sector performance and total factor productivity growth at the level of firms that use the services concerned relatively intensively. These studies tend to find that FDI in services is an important mechanism through which new techniques are diffused to host countries.Footnote 4
 In principle, trade agreements are an instrument to promote market access and own liberalization through quid pro quo bargaining on trade policies. Bagwell and Staiger (1999, 2002) have stressed the importance of the terms of trade in providing a theoretically consistent rationale for the formation of trade agreements. The argument is that countries negotiate away the negative terms-of-trade externalities that are created by the imposition of trade restrictions in partner countries. Terms-of-trade rationales for trade agreements cannot explain why small country governments negotiate limits on their own use of import tariffs and other policies when joining a trade agreement. Tumlir (1985) provides one explanation: trade agreements may offer a mechanism to governments that want to commit to a set of policies that may not be (politically) feasible to adopt or maintain. This rationale has been formalized and extended to encompass the terms of trade rationale by Maggi and Rodriguez-Clare (2008). Thus, trade agreements may serve as a lock-in mechanism or credibility anchor for trade-related policy reforms.Footnote 5
 The stylized fact that looms large here, and that motivates this paper, is that neither of these explanations (rationales) for trade agreements seems to have much relevance for the GATS insofar as very little progress has been made to date in agreeing to liberalize services trade and investment. Nor are WTO members using the GATS framework very extensively to lock-in unilateral reforms that have already been implemented. This paper explores alternative explanations for why this may be the case. Section 2 briefly summarizes recent developments in global services trade and trade policies and the status quo in the GATS with the objective of establishing the “baseline” that confronts firms and trade negotiators. Section 3 discusses a number of hypotheses why the GATS is not “delivering”. Section 4 makes several suggestions regarding what might be done to enhance the relevance of the GATS. Section 5 concludes.",20
8.0,3.0,"Journal of Industry, Competition and Trade",10 October 2008,https://link.springer.com/article/10.1007/s10842-008-0041-2,Services and the Single Market,December 2008,Marcel Canoy,Peter M. Smith,,Male,Male,Unknown,Male,"The single market for services represents the most ambitious attempt to date to promote international economic integration for services. There are international agreements that also seek to promote such integration such as the original US–Canada Free Trade Agreement now superseded by NAFTA and the General Agreement on Trade in Services (GATS) covered by Bernard Hoekman in this issue. However, none of these agreements can be compared in range or depth to the programme that underpins the single market for services. The single market can therefore be taken as a ‘laboratory’ for the possibility of market integration in this field. It can tell much about the fundamental requirements for such integration and about the obstacles that must be surmounted by economic actors for integration to proceed. Two aspects in particular distinguish the single market from standard international agreements on services. First the single market also covers factor movements. Free movement of both labour and capital prove important for integration of markets in services. Second, the EU has legislative powers that enable it to address the regulatory obstacles that constitute the main barrier to integration directly and simultaneously across the twenty-seven Member States. These two aspects imply that the single market cannot easily be transposed other parts of the world. Nevertheless, these special conditions do imply that if services can not be integrated cross-border within the European Union, they are unlikely to do so elsewhere. It follows that is important to assess the functioning of the single market, and in particular for services. The added value of our paper is first and foremost that it adds to better understanding how the single market for services actually functions. The difficulty of analysing this question, which appears to be straightforward, is that is has many facets and requires sometimes non-standard tools and thinking. First, the data often used to assess performance need to be interpreted with great care. This has to do with the endemic poor quality of service data, but also with the fact that for instance trade data provide a misleading picture of the tradability of services, and tradability of services in turn does not tell the full story of how the single market functions. Second, most analyses are still based on goods market logic, while services differ in a significant way from goods. This paper builds on Rubalcaba (2007) and analyses the impact of key characteristics of services for the functioning of the single market. Third, the service sector is often analysed by focusing on cross-border provision, as this special issue demonstrates as well. Our paper looks at the different pillars (free movement of labour, right of establishment, and cross-border provision of services) and recognizes important links and possible substitution between the various modes of single market operation. Fourth, the performance of the single market is not static, but is instead influenced by ongoing trends such as enlargement and ICT. Our paper analyses the impact of these various trends on the way the single market functions. Once we understand how the single market functions, we can evaluate whether or not changes to the single market programme are needed. The added value of our paper is that it combines the above elements to make such an evaluation. The paper comes to the conclusion that the logical policy consequence for the single market is that it needs to be repositioned from a uniform top-down legal construct to a flexible economically based bottom-up one.",4
9.0,1.0,"Journal of Industry, Competition and Trade",28 March 2008,https://link.springer.com/article/10.1007/s10842-008-0032-3,Domestic Regulation and International Trade,March 2009,Øystein Foros,Hans Jarle Kind,Lars Sørgard,Male,Male,Male,Male,"Until a few years ago, information and communication services were offered through what we may call one-service access networks. Books were provided by bookstores, newspapers were delivered by the paperboy, TV-programs by broadcasting networks, and voice telephony by the telecommunication incumbents. Now we see a technological development where multi-service digital access networks deliver a whole range of content services in addition to conventional telecommunication services. One example is that (broadband) digital access networks distribute digital information services like premium entertainment (e.g. movies and sport) to the end-users. Consumers then demand a system of complements, i.e. a combination of (broadband) access and premium content. In contrast to conventional telecommunication services, the system consists of several complementary input components produced by vertically separated firms. Telecommunication incumbents apparently have market power with regard to digital access, and complementary input segments are dominated by other large companies with considerable market power.Footnote 1 However, while access to the local network is domestically regulated both on price and quality, complementary bottlenecks are unregulated. Hence, we have a market with one-sided regulation of complementary inputs. Another distinction between the access bottleneck and complements like premium content is that local access by its very nature is provided locally, while other services typically are offered by multinational foreign firms. The aim of the present paper is to analyze the implications of one-sided regulation of the domestic bottleneck in presence of an unregulated foreign complementary bottleneck. Thus, we analyze a game between a domestic regulator and an unregulated foreign input provider. Who gains from one-sided regulation of the domestic input critically depends on the timing of the interaction between the regulator and the foreign input provider. We show that if the regulator could become a first-mover by imposing one-sided regulation, it would lead to higher domestic welfare. Put differently, if the regulator is able to commit itself, a binding price cap will always improve domestic welfare. This holds regardless of whether the foreign input provider uses linear or non-linear wholesale prices. If the domestic regulator is not able to commit itself in a credible way, a one-sided regulation has an ambiguous effect on welfare. The outcome depends on the degree of differentiation in the retail market and whether the foreign input provider uses linear or non-linear input prices. Indeed, if the regulator cannot ensure that it has a first-mover advantage, the best regulatory policy will often be not to regulate. A price cap would allow the foreign input provider to set a higher price, which in turn results in a large profit shift out of the country. Our paper is related to Economides and Salop (1992), who show that one-sided regulation of one of two complements lowers the end-user price of the composite goods.Footnote 2 As in our model, such regulation benefits the provider of the complementary component. However, they abstract from international trade. Therefore they do not consider profit shifting, and find that one-sided regulation is generally welfare enhancing. The main distinction between our paper and the vast majority of the literature on access price regulation is that we incorporate elements from strategic trade policy. To our knowledge, just a few other papers analyze the relationship between access pricing and international profit shifting. Foros et al. (2002) analyze a related market structure, but assume vertical integration between input providers and retailers, and the focus is whether vertically integrated firms have incentives to practice sabotage towards non-integrated retailers. Moreover, while we consider price competition with horizontal differentiation in the present paper, they assume Cournot competition with homogeneous retail services. However, the assumption of price competition and horizontal differentiation seem quite natural in the present context. We observe that retailers offer premium content only to their own customers (see e.g. Shapiro and Varian 1998). This is often called ” walled garden strategies” , and will by definition create product differentiation. There are also some important distinctions between our study and literature on strategic trade policy. In particular, we focus on the effects of a price cap rather than on the effects of subsidies and tariffs. Moreover, we model a setting with complementary inputs produced by one foreign and one domestic firm, respectively. In contrast, strategic trade policy is typically focusing on downstream competition between domestic and foreign firms producing substitutes, and abstract from possible complementarities.Footnote 3
 The article is organized as follows. In the next section we present the model where we compare the market equilibrium with three different regulatory regimes. In Section 3 we offer some concluding remarks.",2
9.0,1.0,"Journal of Industry, Competition and Trade",15 March 2008,https://link.springer.com/article/10.1007/s10842-008-0031-4,European Union Import Quotas on Chinese Textile and Clothing Exports in 2005: A Panic-Driven Commission or Rational Explanations?,March 2009,Peter Nedergaard,,,Male,Unknown,Unknown,Male,"Based upon a narrative policy analysis, this paper tells an interesting story about extreme political volatility among political decision makers in the European Union. Usually, this kind of political behavior is explained by referring to personnel factorsFootnote 1  or issues such as “managerial lapses”Footnote 2 or “the circus of ministerial panic” (Francois and Wörz 2006: p. 1). Here, however, the rational choice theory will be put to a hard test through using it to interpret volatile political incidences. Rational choice theory is often said to be able to handle volatile markets and voters (Coleman 1994), but not volatile decision-makers, who are supposed to have a set of fixed preferences as the basis for their decisions. The aim in this paper is to discover whether it is possible to use rational choice theory under these circumstances. In this way, the theory concerning interest groups and trade policy put forward by Grossman and Helpman (2002) is expanded and defined more specifically. Thereby, this research contributes to the continued debate about the empirical content of rational choice theory, cf. Cox (1999). For example, Green and Shapiro (1994) have argued that rational choice theory has produced virtually no new propositions about politics that have been carefully tested, and that an empirically successful rational choice theory would be no more universal than ordinary middle-level theories. An attempt to show otherwise is made here. The subject of this paper is the introduction of European import quotas on Chinese textiles in 2005 in order to protect the European textile and clothing industry.Footnote 3 The key questions relating to this issue are as follows: (1) Why, despite the promise to lift them, did the EU re-introduce quotas on textile and clothing exports from China in 2005? (2) Why did the EU (partly) abolish the quotas again just a couple of months later? These two questions will be answered in this paper. The theoretical model presented here makes it possible to rationally explain the two questions mentioned above when they are interpreted as a result of a partial political equilibrium that changes due to the fact that various actors have new opportunities and hindrances in influencing policy-makers in the case of overall political context changes in the relevant area. This new political context is the lifting of quotas on Chinese textile exports to WTO member states on January 1, 2005 and the political situation surrounding the French referendum on the Constitutional Treaty on May 29, 2005.Footnote 4
 Section 2 introduces the empirical background of the case.Footnote 5 In the next section the model of analysis is specified to provide a model of explanation. Sections 4 through 7 analyze the political economy of the case focusing on the political demands of producers, retailers and consumers of textiles and clothing in the market in Section 4; the political supply of politicians and bureaucrats in Section 5; the welfare-economic consequences of the protection of the European textile and clothing industry in Section 6; and the institutional coordination of the member state interests in Section 7. The conclusions are summarized in Section 8.",2
9.0,1.0,"Journal of Industry, Competition and Trade",19 September 2007,https://link.springer.com/article/10.1007/s10842-007-0027-5,Market Share Delegation and Strategic Trade Policy,March 2009,Leonard F. S. Wang,Ya-Chin Wang,Lihong Zhao,Male,Unknown,Unknown,Male,"According to World Trade Report 2006, “In 2005, the value of world merchandise trade rose by 13 percent, to $ 10.1 trillion, and that of world commercial services trade by 11 percent, to 2.4 trillion.” For both merchandise and commercial services, this represented a marked deceleration in growth if compared with the preceding year. Along with the changing path of trade & service volume and value, many governments protect domestic industries through adopting a variety of trade policies, tariff and non-tariff barriers, such as import quotas, export subsidy, voluntary export restraint, etc. A great deal of scholarly effort has been placed on analyzing and comparing strategic trade policies under different competitive product-markets, but the firm has been treated as a simple profit-maximizing entity. In viewing the separation of ownership and management that prevails in most modern managerial enterprises, the owner seeks to maximize profit, but the manager may be more concerned with revenues, output, or market share, rather than profits only. Strategic managerial delegation research started with Vickers (1985), Fershtman and Judd (1987) and Sklivas (1987). It is meaningful to understand how trade policy will be affected by intra-firm incentive schemes, and in particular, to see how optimal trade policy may be designed in light of changes in managerial incentive contracts. Das (1997) and Colonques (1997) extended Brander and Spencer (1984, 1985) by adopting sales delegation specification, to study strategic trade policy in the context of delegated firms. They concluded that strategic trade policy under delegation results in lower levels of the trade policy instruments and greater welfare than under non-delegation. Das (1997) also argued that “...any other form of incentive scheme – whether to managers or workers – which is set strategically (vis-à-vis those offered by other firms) will have a bearing on optimal trade policy (p.187)”. Strategic delegation analysis has been limited to sales delegation cases, until Jansen et al. (2007) presented the case of market share delegation. They pointed out that the manager’s objectives not only focus on sales revenue but on product market share rate as well. In the real world, Matsushita Electric Industrial Co., Ltd., the number one plasma display panel (PDP) manufacturer in the fourth quarter of 2006 in the PDP industry, announced in 2005 that it aims to increase its global market share for large-sized PDP TVs to 40% share of the market in fiscal 2010. Looking at another example, Makoto Ebata, president and CEO of the Hitachi consumer business group, said on April 18, 2007, “As the number of PDP players is limited, we can expect a big market opportunity”. Hitachi aims to achieve a 20% share of the market in fiscal 2010. Moreover, in the 50-in-plus category, the company is aiming for a 30% share. These real-world examples fully reveal that market share is of great importance. While Das (1997) and Van Witteloostujin (1998) have adopted the cost-asymmetry sales delegation specification in trade and management setting, we have modified Jansen et al.’s (2007) model in this paper and present a cost-asymmetry version of market share delegation. This paper assesses the influence upon optimal trade policy of introducing market share delegation in a trade duopoly context. We show that delegation matters, and different forms of delegation coupled with asymmetric costs will imply different degrees of government intervention. Government provides a higher export subsidy in a market share delegation game than in a sales delegation game, and it will be the highest in a simple Cournot game. Given that an efficient tax system has not been set up yet in many developing countries, tariff revenues will play a significant role in national budgets. Therefore, the tariff rate may be determined through revenue maximization. This is the reason why the issue about the relationship between optimum-welfare tariff and maximum-revenue tariff has attracted scholarly attention. In contrast with Johnson’s (1951–1952) argument, Collie (1991), and Clarke and Collie (2006) have shown that optimum-welfare tariff may exceed the maximum-revenue tariff under both Cournot and Bertrand duopoly. However, these studies do not take strategic delegation into account. We demonstrate that in a market share delegation game, the home country will impose a higher or maximum-revenue or optimum-welfare tariff on the foreign firm vis-à-vis the sales delegation game. The remainder of this paper is organized as follows. Section 2 presents the market share delegation model, while Sections 3 and 4 deal with export subsidy policy and import tariff policy, respectively. Section 5 concludes this paper.",23
9.0,1.0,"Journal of Industry, Competition and Trade",19 February 2008,https://link.springer.com/article/10.1007/s10842-008-0030-5,"Monopoly, Pareto and Ramsey Mark-ups",March 2009,Thijs ten Raa,,,Male,Unknown,Unknown,Male,"Monopoly prices are too high. It is a price level problem, in the sense that the relative mark-ups have Ramsey optimal proportions, at least for independent constant elasticity demands. By the same token, Ramsey pricing is considered business oriented (Laffont and Tirole 2000, p. 63). This attractive feature of monopoly prices breaks down for variable elasticities. The reason is that both monopoly prices and Ramsey prices are governed by local inverse elasticity rules, but if the elasticities differ at the (low) monopoly output and the (high) Ramsey output, the mark-ups will differ as well. Hoeffler (2006) illustrates this phenomenon using a kinked demand curve. The break-down of the optimality of relative monopoly mark-ups already occurs once a constant-elasticity demand is replaced by the textbook linear demand. And worse–remaining within the framework of constant elasticities–the break-down also occurs the moment dependence is introduced. Our counterexamples are strong: even the orders of monopoly and Ramsey price components differ! These negative results follow a novel, unifying framework, featuring a Generalized Inverse Elasticity Rule for alternative pricing rules. Hitherto Ramsey rules have been less transparent for interdependent demands (Morhring 1970).",1
9.0,1.0,"Journal of Industry, Competition and Trade",03 October 2007,https://link.springer.com/article/10.1007/s10842-007-0026-6,"Market Concentration, Economic Welfare, and Antitrust Policy",March 2009,James W. Brock,Norman P. Obst,,Male,Male,Unknown,Male,"Combating economic concentration has long been considered a paramount value of American antitrust policy. Competitively structured markets have long been considered an economic counterpart of the nation’s political system of checks and balances, whereby economic decision making is dispersed among a multitude of competing organizations, with each acting as a check and balance on the others. This structural arrangement has long been considered vital, not only for its indirect effect in promoting good economic performance (efficiency, innovativeness) but, just as importantly, directly in its own right for combating the problems of arbitrary economic power and its potential for abuse. This direct concern was clearly evidenced in the national debates triggered by the corporate mergers that spawned the great monopoly “trusts” of the 1880s, and that culminated in the Sherman Act as America’s primary public policy response to the problem of concentrated market power. As comprehensive surveys of the congressional debates during that era have found, American lawmakers viewed the economic concentration problem from the perspective of a tradition “that equated excessive economic power with political corruption as well as oppression of competitors and consumers. This tradition grew out of classical liberal assumptions about the threat to individual liberty inherent in public and private power” (Millon 1988: 1287; May 1989). This focus on economic power and the fear of its abuse was a central concern of Senator John Sherman, Republican of Ohio and namesake of the nation’s first antitrust statute, who observed the “popular mind is agitated with problems that may disturb social order, and among them all none is more threatening than the inequality of condition, of wealth, and opportunity that has grown within a single generation out of the concentration of capital into vast combinations to control production and trade ... If we will not endure a king as a political power we should not endure a king over the production, transportation and sale of any of the necessaries of life” (quoted in Thorelli, 1955: 180). American courts, too, have long recognized excessive economic concentration and power as important factors in their own right in adjudicating antitrust lawsuits. Looking back from 1911, for example, Justice Harlan wrote that at the time of the Sherman Act’s enactment the menace of arbitrary market power was universally perceived in “aggregations of capital in the hands of a few individuals and corporations controlling ... the entire business of the country, including the production and sale of the necessaries of life” (Standard Oil v. United States, 221 U.S. 1, 83 (1911)). Judge Wyzanski later underscored this direct concern about market power in his United Shoe Machinery decision: “Concentrations of power, no matter how beneficently they appear to have acted, nor what advantages they seem to possess, are inherently dangerous. Their good behavior in the past may not be continued; and if their strength were hereafter grasped by presumptuous hands, there would be no automatic check and balance from equal forces in the industrial market” (United States v. United Shoe Machinery Corp., 110 F. Supp. 295, 347 (1953)). Justice Douglas emphasized the same central concern, pointing out that discretionary private economic power “can be benign or it can be dangerous. The philosophy of the Sherman Act is that it should not exist ... Industrial power should be decentralized. It should be scattered into many hands so that the fortunes of the people will not be dependent on the whim or caprice, the political prejudices, the emotional stability of a few self-appointed men. The fact that they are not vicious men but respectable and social-minded is irrelevant. That is the philosophy and command of the Sherman Act” (United States v. Columbia Steel Co., 334 U.S. 495, 536 (1948)). When America’s merger law was re-written in 1950, the Senate report recommending this change in policy put the concern about concentration of economic decision making power at the forefront of its deliberations, declaring : “The purpose of the proposed bill ... is to limit future increases in the level of economic concentration resulting from corporate mergers and acquisitions” (Senate Report 1775, 81st Cong., 2d sess., p. 3 (1950)). In its definitive interpretation of this new statute, the Supreme Court recognized that by enacting this new merger law, Congress resolved “competing considerations in favor of decentralization,” and sought to block “what Congress saw was the rising tide of economic concentration...” (Brown Shoe Co. v. United States, 370 U.S. 294, 317–318, 344 (1962)). In its Von’s Grocery decision, the Supreme Court observed that from the country’s beginnings, there has been an abiding fundamental concern about “the concentration of economic power in the hands of a few. On the basis of this fear, Congress in 1890 ... passed the Sherman Act in an attempt to prevent further concentration ... Like the Sherman Act in 1890 and the Clayton Act in 1914, the basic purpose of the 1950 [merger law] was to prevent economic concentration in the American economy ...” (United States v. Von’s Grocery Co., 384 U.S. 270, 274–275 (1966)). This history demonstrates that the level of market concentration has long been considered an important value and consideration in its own right in American antitrust policy. Abroad, the place of this consideration in EC competition policy has been debated following the advent of an explicit community-wide merger control regulation in the 1980s and its recent revision (Martin 2007; Ilzkovitz and Meiklejohn 2003). This history suggests that if two different levels of concentration were to provide the same output from the same inputs, the less concentrated market structure would be preferred by individuals because (in Justice Douglas’s terms) the fortunes of the many would not depend upon the arbitrary decisions and whims of a monopolist or oligopolists wielding concentrated market power.",4
9.0,2.0,"Journal of Industry, Competition and Trade",18 March 2009,https://link.springer.com/article/10.1007/s10842-009-0052-7,The Meaning of Entrepreneurship: A Modular Concept,June 2009,Michael Peneder,,,Male,Unknown,Unknown,Male,"Entrepreneurship has been correctly characterised as one of the most intriguing but equally elusive concepts in economics (Baumol 1968). Part of the difficulty in pinning down its precise meaning stems from the sheer weight of the very fundamental functions it is held responsible for. If we start with a bold synthesis of the literature, it is responsible for no less than moving the economic system simultaneously closer to and away from equilibrium. Depending on what intellectual tradition we follow, entrepreneurship either enhances the allocative efficiency for given ends and means, or drives the dynamic performance of the system through the progressive creation of new products, processes or markets. Another reason for the puzzling variety of concepts is the interdisciplinary nature of the topic, involving scholars from the fields of economics, business strategy, organisational behaviour, sociology and psychology, often further fragmented in competing strands and research traditions. For instance, scholars of business strategy and management typically apply a behavioural and process perspective, interested in how to act entrepreneurially. Conversely, economists primarily care about how the economic system works, and therefore characterise entrepreneurship by the particular functions it fulfills in order to enhance the operations of the overall system. Yet, when labour economists deal with entrepreneurship, they are specifically concerned with the occupational choice of either being a salaried employee or self-employed. Finally, sociologists and scholars of organisation studies investigate the social and organisational embeddedness of entrepreneurial behaviour, while psychologists add their expertise to explain how entrepreneurship relates to personal characteristics and individual cognitive processes within varying situational contexts. Taking advantage of its openness to such varied inputs, in recent decades entrepreneurship research has emerged as an independent branch of academic inquiry, being multidisciplinary but mostly associated with the management focus of business schools. In one of the earliest attempts for an independent and comprehensive intellectual basis, Casson (1982, p. 23) defines the entrepreneur as “someone who specialises in taking judgemental decisions about the coordination of scarce resources”, further explaining that judgemental decisions are those for which no obviously correct procedure exists in the sense of the routine application of a standard rule. In a similar vein, Hébert and Link (1989, p. 47) conclude that the “entrepreneur is someone who specializes in taking responsibility for and making judgemental decisions that affect the location, form, and the use of goods, resources, or institutions.” Casson et al. (2006) further emphasise that the sources of information are highly localized with different people in different places having different perceptions of a situation. Judgemental decisions thus depend on the identity of the entrepreneur and are potentially unique. Still, the prevalent opinion is that the theoretical and empirical underpinnings of the discipline are either partial or too vague and complain about “the considerable confusion that exists in the way that people use the term entrepreneurship” (Ahmad and Seymour 2008). Similarly, Shane and Venkataraman (2000: 217) critically observed that “entrepreneurship has become a broad label under which a hodgepodge of research is housed,” while Davidsson (2003, p. 2) admits to an apparent “confusion, signs of identity crisis, or widespread frustration.” Against this widespread sense of frustration, this paper applies a constructive approach, first reviewing many intellectual building blocks from the literature and then proposing a novel modular concept that is based on the explicit distinction between the behavioural, occupational and functional dimensions of entrepreneurship. As the paper is going to argue, this relatively straightforward separation helps to illuminate several analytic puzzles and overcome much of the current confusion about the actual meaning of entrepreneurship. To begin with the behavioural explanations, the one aspect that prevailed most is the opportunity-seeking nature of entrepreneurship. For example, we find that in the widely used textbook of Sahlman et al. (1999, p. 7), who define their management approach to entrepreneurship as “the pursuit of opportunity without regard to resources currently controlled.” Venkataraman (1997, p. 120) states that “entrepreneurship as a scholarly field seeks to understand how opportunities to bring into existence ‘future’ goods and services are discovered, created, and exploited, by whom, and with what consequences.” Finally, paraphrasing Robbins’ (1935) popular definition of economics as the science of the relationship between ends and scarce means, Shane and Eckhardt (2003, p. 165) define entrepreneurial opportunities “as situations in which new goods, services, raw materials, markets and organizing methods can be introduced through the formation of new means, ends, or means-ends relationships.” With its emphasis on the ‘individual-opportunity nexus’ (Shane 2004) entrepreneurship research appears to arrive at a unique and independent foundation of its discipline. As the paper is going to argue, its perspective is more comprehensive than any of the individual concepts that have emerged from the economics literature. Its universality, however, also comes at a cost, as many authors remain vague about the precise economic function they have in mind. To give an example, some authors lay particular emphasis upon the Schumpeterian idea of innovative entrepreneurship (e.g. Venkataraman 1997; Ahmad and Seymour 2008), while others stress Kirzner’s process of entrepreneurial discovery (e.g. Davidsson 2003). Ultimately, the proposed definitions typically embrace both in a way that makes the two approaches indistinguishable. The conceptual differences, however, are real and elementary. Lacking the means to discriminate them implies a loss in terms of analytical precision. How can we reconcile the aim of generality with that of analytic specificity? One popular option is to pile up characteristic attributes that take account of the manyfold dimensions of the phenomenon. But following that path easily leads into a ‘complexity trap’. Despite the growing enumeration of important characteristics, the attempted definitions can never become fully comprehensive. At the same time they increasingly loose their discriminatory power as the distinctions between analytically useful categories get blurred. This paper pursues the alternative option of adding analytic structure by means of a deliberate separation of different dimensions of the phenomenon. The focus is on the general economics literature, which is primarily concerned with the functional dimension, explaining the different mechanisms of how entrepreneurship enhances the market process and economic development. In addition, the paper assesses to what degree the economists’ concepts are consistent with the behavioural and occupational definitions, trying to identify the proper place that the different functional theories may occupy within an emerging general paradigm of entrepreneurship. In contrast to the frequent practice of synthesising the variety of ideas into another single, ‘all-inclusive’ definition, the modular approach respects the fundamental differences between concepts. The paper is organised as follows. Section 2 offers a critical discussion of the major intellectual roots of the modern economic understanding of entrepreneurship. It gives evidence to an astounding variety of ideas and distills the major intellectual building blocks. Section 3 then proposes a modular concept that preserves essential distinctions along the behavioural, functional, and occupational dimensions of entrepreneurship. The modular approach helps to understand where the various concepts complement or overlap and what implicit assumptions they involve with respect to the other dimensions. Section 4 discusses empirical indicators and how they relate to the theoretical concepts. Section 5 summarises and briefly discusses the general policy framework.",41
9.0,2.0,"Journal of Industry, Competition and Trade",30 May 2007,https://link.springer.com/article/10.1007/s10842-007-0015-9,Patterns and Determinants of Entry in Rural County Banking Markets,June 2009,Robert M. Feinberg,,,Male,Unknown,Unknown,Male,"While earlier work on banking markets examined similar issues,Footnote 1 Amel and Liang (1997) present interesting results on bank entry fairly closely related to this paper’s focus. They jointly explain bank profits and entry over the 1977–1988 period for about 2000 rural counties and about 300 urban markets (metropolitan statistical areas), and find that supranormal profits promote entry as does population and population growth, and that entry has the anticipated pro-competitive effect of reducing profits—though only in rural markets. Piloff (1999), in a cross-section analysis of 1728 banks in 762 rural counties (spread over 39 states) for the June 1995–June 1996 period, finds the presence of both large and regionally prominent banks to increase profitability of small local banks, consistent more with a reduction in competition due to this presence than with enhanced competition which might result from the greater ability of big banks to limit the market power of locally dominant firms. In contrast, the pooled time-series cross-section study of Berger et al. (2007) finds that while Piloff’s result may have held true in the 1980s, the opposite is found for the 1990s, with large banks competing more efficiently against small local banks. In somewhat the same vein, Berger et al. (2004), Seelig and Critchfield (2003), and Keeton (2000) have all found—though with somewhat differing definitions of merger activity and samples—that merger activity generally tends to promote de novo entry. These findings are consistent with merger activity and/or the presence of “big banks” in a market as signaling to potential entrants the opportunities for supranormal profits to be earned.Footnote 2 Cetorelli (2002) also examines local banking markets, following along the lines of Bresnahan and Reiss (1991) in explaining (equilibrium) market structure by population and other county economic characteristics, analyzes numbers of banks in a large sample of non-metropolitan counties for 1999 (n = 2,257). As was the case with Bresnahan and Reiss, with a single cross-section, Cetorelli is unable to examine gross entry, and only net entry to the extent that is regarded as differences across markets in their equilibrium numbers of firms. In terms of effects of bank entry, recently Giannetti and Ongena (2005) have studied the role of foreign bank lending in stimulating growth of non-bank companies in Eastern Europe, finding a generally positive impact due to improved access to credit. Similarly, Clarke et al. (2001) had earlier found—in a somewhat broader sample of developing economies—a positive impact of foreign bank entry on local firms. What none of the prior studies have done is to examine a time series of US rural markets and determine motivations for both gross and net entry. In addition, it is rare to see a careful discussion of what is meant by “entry” in the banking context, and how this may differ from textbook usage of the term. This is dealt with in what follows.",14
9.0,2.0,"Journal of Industry, Competition and Trade",20 November 2007,https://link.springer.com/article/10.1007/s10842-007-0029-3,Necessity and Opportunity Entrepreneurs and Their Duration in Self-employment: Evidence from German Micro Data,June 2009,Jörn Block,Philipp Sandner,,Male,Male,Unknown,Male,"In many countries, economic policy aims to increase the number of new businesses, but this goal is problematic since many new businesses do not survive for very long. For example, in Germany, an industrialized country, only about 50% of newly established businesses survive longer than 5 years (Fritsch et al. 2006). From a policy perspective, it might therefore be interesting to know more about the determinants of the length of survival of newly established businesses. This is especially relevant given the fact that in many industrialized countries, the state actively promotes entrepreneurship as a way out of unemployment (for an overview, see Meager 1996). In addition to providing insights from the policy perspective, this paper is also interesting from a financial investor’s perspective. Financial investors, whether venture capitalists, banks or business angels, want to calculate the expected return on their investment, and business survival is an integral part of this calculation. Any new information about the determinants of business survival makes their calculation more accurate and helps to avoid systematic decision biases. Apart from the general question about the determinants of business survival, this paper aims to provide new insights relating to the impact of necessity and opportunity entrepreneurship on business survival. Using German micro data, we analyze whether an individual who stepped into self-employment voluntarily (an opportunity entrepreneur) remains self-employed substantially longer than an individual who started self-employment for necessity reasons (a necessity entrepreneur). This question is particularly relevant from a German policy perspective because necessity entrepreneurship has increased strongly over the last few years due to policy measures taken by the federal government (e.g., Bergmann and Sternberg 2007; Wagner 2005). To identify the determinants of duration in self-employment, we estimate several hazard rate models using a stepwise procedure. By employing a stepwise procedure, we aim to determine whether any observable differences between the two groups are due to selection. To further explore the validity of our results, we compare the characteristics of necessity and opportunity entrepreneurs using descriptive statistics and Probit regression models. In line with our ex-ante beliefs, we find that opportunity entrepreneurs stay in self-employment significantly longer than do necessity entrepreneurs. This effect, however, is due to selection, and is not an original effect. After controlling for whether the venture is started in a profession the entrepreneur has learnt, the hazard of leaving self-employment is no longer affected by the individual’s status as a necessity entrepreneur. This result opens an interesting debate regarding the relative economic impacts of opportunity and necessity entrepreneurs. Necessity entrepreneurs are not necessarily less successful and therefore less desirable from an economic perspective, as has been suggested in some literature (e.g., Acs et al. 2005; Acs and Varga 2005). Rather, the observation of differences between necessity and opportunity entrepreneurs is highly sensitive to the definition of success that is used. To some degree, our finding justifies governmental programs of start-up support that are designed for necessity entrepreneurs. The efficiency of these programs, however, can be further improved by including education and other variables in the decision of whether to support a given individual entrepreneur. The remainder of this paper is organized into four sections. In Section 2, we discuss from a theoretical perspective the relative impacts of necessity and opportunity entrepreneurship on self-employment duration. Moreover, we provide a short literature review of the impact of other factors on staying in self-employment. Section 3 introduces the data, gives some descriptive statistics, and describes the econometric models that we use. The estimation results are reported in Section 4. Finally, Section 5 discusses implications from a policy perspective and gives ideas for further research.",201
9.0,2.0,"Journal of Industry, Competition and Trade",18 March 2009,https://link.springer.com/article/10.1007/s10842-009-0048-3,On the Autocorrelation of Growth Rates,June 2009,Alex Coad,Werner Hölzl,,Male,Male,Unknown,Male,"This paper studies the serial correlation of growth rates for firms in Austrian service industries. The serial correlation of growth rates provides important information on the processes of firm growth. It allows to study the persistence of firm growth processes. The persistence in employment growth—are new jobs likely to be discontinued 1 year later or is the growth process continuing—is of special interest, as in recent years there is a growing interest in the job-creating potential of small firms. The study of serial correlation for different size classes helps to get a clearer picture of the differences between small and large firm growth. In addition the study of the serial correlation of growth rates allows to assess theories of firm growth by comparing theoretical predictions with observed regularities. For instance, if serial correlation were observed to be significant this would lead from a strictly methodological viewpoint to a rejection of Gibrat’s Law of proportionate effect and the associated stochastic models of industry evolution. The assumption that firm growth is a purely stochastic and the product of independent growth shocks is not appropriate if growth rates are not serial independent (Chesher 1979). Also the nature of adjustment costs can be studied by looking at the serial correlation of growth rates. Convex adjustment costs prevent firms from immediately attaining their chosen size and lead to a gradual partial adjustment over time. The path to the desired new equilibrium level is a smooth, partial adjustment-like path. We should therefore observe a positive autocorrelation of growth rates. Non-convex adjustment costs in contrast are more easily reconciled with the empirical evidence that employment change is non-smooth but lumpy (Hamermesh and Pfann 1996; Caballero et al. 1997). If non-convex adjustment costs play an important role we should expect to find zero or even negative autocorrelation especially for high growth rates. Firms expand at one point in time and wait for the next expansion in order to economize on fixed adjustment costs. The distribution of employment should be characterized by a high proportion of extreme events. The non-convex adjustment cost hypothesis predicts that sharp adjustment or employment should be followed by relatively long periods of inaction, that is no change in the level of employment. We use a dataset that allows us to identify the growth processes of micro firms. Usually national statistical offices gather data on firms above a certain size threshold (e.g. above 20 employees). The neglect of micro firms is a strong limitation especially if one considers service industries where the average firm size is smaller than in manufacturing. Micro firms face particular difficulties in their very early growth phase, presumably because of high fixed (non-convex) adjustment costs related to their small size.Footnote 1 The growth patterns of fast-growing small firms are thus particularly erratic (Garnsey et al. 2006; Santarelli and Vivarelli 2007). In addition, research suggests that most micro firms do not display any changes in employment for a long time (Hölzl and Huber 2008). In our dataset, 65% of firms in the 1–9 employees category stay at the same size from 1 year to the next. Although researchers often focus on high-growth firms (often referred to as ‘gazelles’), we should acknowledge that most micro firms don’t grow. We also need to know more about the growth history of these gazelles, instead of focusing on their growth in one single year. Our research concentrates on the service sector. Research into firm growth has focused on the manufacturing sector at the expense of the service sector (Delmar 1997). As the major part of economic activity in modern economies takes place in the service sector this constitutes a shortcoming of many studies. The situation is improving, however—in recent years some studies have focused on firm growth in the services sector (Audretsch et al. 1999b, 2004; Lotti 2007; Teruel-Carrizosa 2009). Most studies find that there is a negative relationship between firm size and expected growth rate, indicating that most service sectors have something like a minimum efficient scale of operation (Variyam and Kraybill 1992; Johnson et al. 1999). In addition, the service sector is interesting for the present research as the adjustment costs are most likely related to costly changes in the level of employment. Adjustment costs due to capital investment are likely less important than in manufacturing industries. Thus the finding of a negative autocorrelation would indicate primarily adjustment costs to labor. Third there is not much available evidence for Austria. Weiss (1998) looks at growth dynamics of farms in Upper Austria. He finds that the most dynamic farms are the smallest ones. In addition he observes positive autocorrelation. However, this finding is based on a very specific sector of the economy. Using a 30 year unbalanced panel of Austrian firms, this paper finds that autocorrelation dynamics vary with firm size, such that larger firms display a positive autocorrelation and smoother growth processes than smaller firms. For micro firms we record negative autocorrelation that paints a picture of erratic ‘start-and-stop’ growth dynamics. Indeed, small and large firms seem to operate on different ‘frequencies’. High-growth micro firms are very unlikely to repeat their growth performance the following year, while larger firms experience a positive feedback, that leads to sustained growth. The paper is organized as follows: Section 2 provides a review of the literature. Section 3 presents the database and descriptive statistics on the growth process in the Austrian service sector. Sections 4 and 5 presents the empirical analysis. In Section 5 we start with the presentation of the size and the growth rate distribution and provide evidence that the growth rate distribution exhibits heavy tails. This has implication for the choice of estimation technique. Section 5 presents results for the autocorrelation of growth rates using quantile regression techniques using both at the aggregated data and disaggregating according to time periods and firm size. Section 6 concludes the paper.",60
9.0,2.0,"Journal of Industry, Competition and Trade",10 November 2007,https://link.springer.com/article/10.1007/s10842-007-0028-4,Is Firm Productivity Related to Size and Age? The Case of Large Australian Firms,June 2009,Alfons Palangkaraya,Andreas Stierwald,Jongsay Yong,Male,Male,Unknown,Male,"The relationship between productivity, firm size and age has been an issue of interest in theoretical as well as empirical research in industry organization. Recent empirical literature has cast doubt on the notion of a representative firm; it is typical to find an industry comprising heterogeneous firms and in a constant state of flux, with many firms entering and exiting in any given time period. Furthermore, there is usually a significant heterogeneity in productivity performance across existing firms—some firms are found to be substantially more productive than their peers and the productivity differentials tend to persist over time.Footnote 1
 For the case of Australia, the Productivity Commission (1999) finds a great diversity in productivity performance among the various sectors of the Australian economy (see also Bland and Will 2001). Within the manufacturing sector, for example, the study finds that firm productivity growth is highly variable. Overall, the findings suggests that firms’ productivity performance is unlikely to be explained by a single factor and the evidence lends support to a set of predictions derived from recent theoretical work on industry dynamics.Footnote 2 Among the predictions is competitive firms with widely different productivity levels may coexist and simultaneous entries and exits are common place. To contribute to the growing empirical literature on firm-level productivity performance, we investigate how the productivity of large Australian firms evolves over a specific period of time. This study is different from the two earlier Australian studies cited above in both the data and methodology used to measure productivity. Unlike the Productivity Commission (1999) study, which focuses on the relationship between microeconomic policy reforms and productivity improvements at the sectoral level (i.e., two-digit industry classification), our aims are to investigate productivity dynamics at the firm-level. Although Bland and Will (2001) also perform their analysis at the firm-level, their main focus is on tracing resource movements by decomposing labour productivity. In addition to productivity dynamics, we also investigate the way productivity levels and growth co-vary with firm size and age, albeit the analysis is restricted to our sample of large firms only. Although relatively few in number, large Australian firms account for a significant proportion of the country’s output and employment (Dawkins et al. 1999).Footnote 3 Thus, arguably, the performance of these firms is critical to the economy and social welfare of the country. According to a 2000–2001 Australian Bureau of Statistics (ABS) survey, there are only slightly more than 3,200 operating businesses that can be classified as large, but together these firms employed more than 2.4 million persons—accounting for 38% of all business employment (Australian Bureau of Statistics (ABS) 2000-01).Footnote 4 Moreover, their total net worth is valued at more than 75% of the total net worth of all employing and trading businesses. Finally, they account for nearly 50% of total industrial gross output in the survey year. Therefore, understanding the productivity performance of these large firms is a critical step in understanding the performance of the economy. The rest of this paper is organized as follows. Section 2 outlines the empirical framework that underpins our empirical model. Section 3 specifies the empirical model and its estimation strategy and describes the data used for estimation. Section 4 provides and discusses the estimation results. Section 5 concludes.",13
9.0,3.0,"Journal of Industry, Competition and Trade",16 September 2008,https://link.springer.com/article/10.1007/s10842-008-0042-1,"Agglomeration, Relative Wage Costs and Foreign Direct Investment—Evidence from Swedish MNCs 1974–1998",September 2009,Pontus Braunerhjelm,Per Thulin,,Male,Male,Unknown,Male,"The deregulation created by the European integration process—within as well as between nations—has turned the issue of firm location into a highly topical point on the political agenda in Europe. Integration makes firms more exposed to inter-country differences with respect to production costs, market size, knowledge spillovers, etc., thereby stiffening the competitive pressure under which firms operate. Similarly, differences in macroeconomic regimes and the institutional setting across countries also become more transparent. The spectacular growth in global foreign direct investment (FDI), and the European Union’s (EU’s) increasing involvement in this process since the 1980s and 1990s, leaves little doubt that regional integration does influence the location of firms. This brings up a number of questions concerning the current restructuring of the European industry and its spatial implications. According to mainstream new economic geography models, the basic determinants of firms’ locations can be allotted trade/transport and production costs together with the degree of scale and agglomeration economies (Krugman 1991; Fujita, Krugman and Venables 1999).Footnote 1 These factors clearly allude to strategic FDI-decisions taken by profit-maximizing multinational corporations (Buckley and Casson 1976), as well as the OLI framework frequently imposed in the analysis of international business (Dunning 1977). This paper aims at making a contribution in that direction by examining the relationship between locations of multinational corporations, relative production costs and agglomeration economies. Using country- and industry level data numerous studies have addressed how FDI influence home country employment and production, sensitiveness to wage differences, the impact of existing agglomerations on FDI, knowledge sourcing, etc.Footnote 2 However, to our knowledge, no empirical analysis has examined whether agglomeration economies may compensate for higher wage costs in the presence of the alleged lack of labor mobility in certain regions of the world. That would also influence the spatial distribution of production. In particular, can we expect Europe’s more immobile labor market—where a shift in location of production is not accompanied by labor flows—to generate a more “fragmented” distribution of production as compared to other regions, particularly the U.S.?Footnote 3
 To examine these issues we will pool a unique data set on the location of foreign production by Swedish multinational corporations (MNCs), spanning the period 1974 to 1998, with host-country data (38 countries) for the same period classified on cost-, agglomeration- and policy variables. Swedish industry has been dominated by large MNCs with extensive—and geographically dispersed—international activities for a long time. Their strategies can, by and large, be expected to pertain also to firms originating in other countries. The remaining part of the paper is organized as follows. In Section 2, the theoretical framework is presented and relevant previous findings are reviewed. The section ends with three derived hypotheses to be tested in the empirical part. The econometric method and the data are discussed in Section 3, while Section 4 presents the hypotheses on the explanatory variables. Section 5 contains the results from the empirical analysis, and, finally, Section 6 concludes.",4
9.0,3.0,"Journal of Industry, Competition and Trade",11 September 2008,https://link.springer.com/article/10.1007/s10842-008-0034-1,Grey Power: An Empirical Investigation of the Impact of Parallel Imports on Market Prices,September 2009,Steve Thompson,,,Male,Unknown,Unknown,Male,"The persistence of third degree price discrimination across international markets in the face of the falling costs of unofficial importing is something of a paradox. Absent industries such as vehicle manufacture, where differences in consumer preferences or regulatory standards discourage parallel imports, and it might be expected that declining transport and communication costs would have stimulated international arbitrage and thus negated price discrimination. However, many products including consumer electronics continue to exhibit both manufacturer’s international price discrimination and unofficial importing. For example, Sony has introduced successive versions of its flagship Play Station product at different prices in its key core markets of Japan, Europe and the USAFootnote 1, notwithstanding that arbitrage operates within hours of each version’s release. Unofficial importing, with its resultant “grey” market, has been generally opposed by manufacturers, especially those in short product life cycle industries, who typically see price discrimination as integral to the recovery of development costs. Parallel imports (PIs) are rarely perfect substitutes for their manufacturer-distributed equivalents. There are usually warranty differences that assume ex post significance in the event of defective performance and there may be subtle product variations that cannot easily be determined ex ante. Therefore it is unsurprising that PIs, whilst priced at a discount on regular models, generally appear to constitute a modest proportion of any product’s sales, even in apparently homogeneous products such as pharmaceuticals (Ganslandt and Maskus 2004). If PIs are merely sold to those consumers with a low reservation price for the product, their introduction may extend the domestic market but leave existing trades largely unaffected. However, this paper suggests that given heterogeneous consumer preferences and attitudes to risk, the import model may be attractive to at least some of those who would otherwise have purchased regular models. If so, competition to supply such consumers is likely to lower prices in markets where imports compete with regular models. That is import model availability may have a price impact disproportionate to import sales; an effect comparable to that of low-cost airline entry on full service airline markets described by Richards (1996). The paper explores the price impact of unofficial imports on sellers using a shopbot market mediated by NexTag.com. Using 11 consecutive weekly observations on 53 digital camera model markets, averaging approximately 20 sellers each, it is found that not merely does the presence of an import model among the regular versions on offer depress price, variously measured, but it also lowers mean and minimum prices even after its own magnitude has been expunged from the price distribution. The presence of refurbished model (refurb) substitutes in the market lowers prices in a broadly similar manner. However, while the refurb appears to be merely an inferior substitute, imports demonstrate a more complex story in which the price discount rises over time. This is consistent with the falling importance of model-specific preferences as each model ages. The paper is organized as follows: Section 2 discusses the practice of international price discrimination and the arbitrage role of grey markets for PIs. Section 3, outlining the sample and data, is followed by a discussion of the model in Section 4. The results in Section 5 are followed by a brief conclusion.",14
9.0,3.0,"Journal of Industry, Competition and Trade",11 November 2008,https://link.springer.com/article/10.1007/s10842-008-0045-y,Dumping and Injury Margins in Markets with Horizontal as well as Vertical Product Differentiation,September 2009,Jørgen Drud Hansen,Jørgen Ulff-Møller Nielsen,,Male,Male,Unknown,Male,"The success of the GATT/WTO during the last half century in lowering the most favored nation tariffs (MFN) in the world economy is indisputable. However, international trade has not been liberalized as much as could be expected by the reduction of the MFN tariffs. The pressure for protectionism has not receded, but has made its way to other protectionists’ measures. Increasingly, anti-dumping policy (AD) has become the feasible instrument to shield the domestic market from foreign competition. The woolly WTO/GATT anti-dumping rules are to blame for this substitution of trade barriers.Footnote 1
 The WTO/GATT rules provide for use of anti-dumping measures in a given market when two conditions are fulfilled. First, dumping behavior of a foreign producer should be proved. Secondly, the domestic producer(s) should experience ‘injury’ because of the foreign producer’s behavior. As argued in this paper, the last concept, injury, is ill-defined and opens the door for policy makers’ discretion to promote anti-dumping measures when goods differ in quality. The purpose of the paper is to provide a theoretical analysis of the protectionist bias from this neglect of quality in the present procedures for implementing anti-dumping measures. According to the GATT/WTO rules, dumping occurs when a producer sells his product in a foreign market to a price lower than the normal value, with the normal value typically determined as the home market price or a cost-based price. The dumping margin is the difference between the normal value and the export price. Usually, the company sells identical products in the domestic and foreign markets and in such cases it causes no problem to calculate the dumping margin whether or not the foreign producers’ products differ from his competitors’ products. The other requirement for implementation of an AD measure is injury. Article 3.1 of the Agreement on Implementation of Article VI of the General Agreement on Tariffs and Trade 1994 (in the following called the Agreement) states that “A determination of injury [..] shall involve an objective examination of both (a) the volume of the dumped imports and the effect of the dumped imports on prices in the domestic market for ‘like products’ (our italics), and (b) the consequent impact of these imports on domestic producers of such products”. And in article 3.2 “[..] With regard to the effect of the dumped imports on prices, the investigating authorities shall consider whether there has been a significant price-undercutting by the dumped imports as compared with the price of a like product of the importing Member [..]” (our italics). Article 3.4 gives injury a broader interpretation. This article states that: “The examination of the impact of the dumped imports on the domestic industry concerned shall include an evaluation of all relevant economic factors [..]”, and these include a list of 15 factors, which anyhow is said not to be exhaustive.Footnote 2 Some of these factors have been more in focus than others in the injury part of anti-dumping investigations for different countries. However, many countries use the effect of the dumped import on prices in the importing market as the prominent indicator of injury. The provisions for implementing anti-dumping tariffs in the Agreement provide the legal basis for this strong focus on price differences. To be more specific, Article 9.1 states the so-called ‘lesser than duty rule’ which says that “It is desirable [..] the duty be less than the margin if such lesser duty would be adequate to remove the injury to the domestic industry”. Applying this rule to determine the size of the anti-dumping tariff requires a comparison of the dumping margin (called the ‘margin’ in article 9.1) and the injury margin defined as the difference of prices between the domestic and the foreign producer prices in the domestic market.Footnote 3 The degree of price-undercutting is thus at the center in an anti-dumping procedure. The price comparison should in principle be made for ‘like products’ and this concept is therefore crucially important for the injury calculation. Article 2.6 of the Agreement defines a ‘like product’ as “[..] a product which is identical, i.e. alike in all respects to the product under consideration, or in the absence of such a product, another product which, although not alike in all respects, has characteristics closely resembling those of the product under consideration”. Implicitly, from this definition of ‘like product’ it is reasonable to assume that quality differences between imported products and domestically produced products in the exporting country should be taken into consideration in the AD investigation. However, the Agreement does not indicate what should be considered in determining the ‘like product’. Furthermore, even the ambition to correct for quality differences seems bleak to put it mildly, as the GATT/WTO leaves it an open question whether calculation of price-undercutting should at all include quality differences. In the WTO published Handbook on Anti-dumping Investigations (Czako et al. 2003), the authors suggest that authorities may correct price-undercutting for quality differences. The word ‘may’ does not commit very much and practice among the WTO members on the interpretation of ‘like products’ also shows a wide margin for discretion with different factors being applied. As far as we know, there has not been any systematic investigation of how the quality problem has been handled by the authorities, but scattered observations found in the AD literature all point in the same direction, namely that AD-authorities “[..] can acknowledge the difference in quality that may exist [..], but nevertheless decide to consider the products as similar” (Vandenbussche and Wauthy 2001: 103; see also Nielsen and Rutkowski 2005; and Bronckers and McNelis 1999). Pointing generally to the seeming misleading calculation of injury margin, Tharakan et al. (2006) have investigated 354 EU anti-dumping cases and found the reported injury margins from the Commission to be inflated, not due to influence by lobby groups, but because of a flawed estimation procedure. But their investigation does not specifically look at quality differences. The economic theory provides an analytical framework for analyzing quality. ‘Like product’ refers to cases where we have either homogeneous products or horizontally differentiated products. According to Lancaster (1966, 1979), two products are horizontally differentiated when both products have a positive demand, whenever they are offered at the same price. Furthermore, the different variants in the product group have the same characteristics, but in different proportions, and no variant dominates the others in relation to the content of its characteristics. On the other hand, two products are vertically differentiated, i.e. of different quality, if one of the products dominates the other in relation to amounts of all characteristics. In this case, all consumers rank the two goods in the same order, i.e. if both products should be purchased, the product with more characteristics will sell at a higher price. This basic definition of vertical product differentiation is used in international trade models such as e.g. Falvey (1981), and Shaked and Sutton (1984). In both analytical models of international trade by Falvey (1981) and Flam and Helpman (1987) as well as in empirical investigations by Torstensson (1991, 1996); Schott (2004); Nielsen and Rutkowski (2005) and Hallak (2006), the positive relationship between prices and qualities is combined with a positive relationship between quality of produced goods in the country and the level of economic development of the country. In general, rich countries should therefore be in a better position to claim injury compared with poor countries. This fits in with the fact that the historically heavy users of AD—USA and the European UnionFootnote 4—to a large extent have targeted their AD policies against countries at a lower level of economic development.Footnote 5
 A shortcoming in the contributions above is that these analyses rely exclusively on vertical product differentiation, i.e. horizontal product differentiation is completely neglected. Shaked and Sutton (1987) have specified a model with vertical as well as horizontal product differentiation claiming that “[..] results obtaining in the cases of the “pure vertical” and “pure horizontal” differentiation literatures are sharply different, but the—empirically relevant—case in which both types of attribute are present, has not been widely studied” (Shaked and Sutton 1987: 137). More recently, Garella (2003, 2006) has developed a duopoly model where consumers’ tastes differentiate both vertically and horizontally. Quality and prices are strategic variables used by each of the two producers in a two-stage game at the market. However, in both contributions the companies operate in one market exclusively i.e. international trade is disregarded. Hansen and Nielsen (2006) generalized the model of Garella by assuming two countries with one producer located in each of the two countries. The markets are partially segmented due to trade costs and it is analyzed how market integration, i.e. reduction of trade costs, influences prices and qualities. A similar model with both horizontal and vertical product differentiation is developed in this paper, but now we address the analysis specifically on dumping and injury which was disregarded in the previous analysis.Footnote 6 Due to the partial segmentation of the two markets, both producers price discriminate. However, the main conclusions of the paper relate to injury as prices and qualities in general will differ between the two producers and the issue of ‘like products’ therefore becomes delicate. We suggest distinguishing between formal and real injury (price-undercutting) where the first concept is related to GATT/WTO negligence of quality, while the latter is anchored in the theoretical framework of the model. Based on these concepts, we show that the producer of the relatively high-quality product can successfully claim formal injury although it is the low-quality producer who is exposed to real injury. Neglecting quality differences in implementing AD measures, the ‘convicted’ is therefore mixed with the ‘victim’. The rest of the paper is organized as follows. In section 2, we lay out the general structure of the model. Section 3 determines dumping and injury margins. The analysis highlights the role of country sizes, efficiency in quality development and trade. The importance of market integration for the incentives to claim dumping and injury is also investigated. Section 4 concludes emphasizing the policy implications.",3
9.0,3.0,"Journal of Industry, Competition and Trade",28 October 2008,https://link.springer.com/article/10.1007/s10842-008-0046-x,Third-Degree Price Discrimination in the Presence of Asymmetric Consumption Externalities,September 2009,Takeshi Ikeda,Tatsuhiko Nariu,,Male,Male,Unknown,Male,"Third-degree price discrimination is widely observed, for example, discounts for students or women and premiums on midnight taxi fares.Footnote 1 In these examples, the use of price discrimination depends on the difference in the price elasticity of demand between groups or at different times. In general, as Schmalensee (1983) suggested, the price is reduced for the group that has high price elasticity of demand. A typical example is price cutting for women at cocktail lounges. While this price discount may be explained by the fact that women have high price elasticity of demand for cocktails, another explanation is consumption externalities, which means that female customers attract male customers. Although Layson (1998) and Adachi (2002) consider such externalities, they assume symmetric externalities between the groups involved. In this paper, we consider third-degree price discrimination in two markets in the presence of asymmetric consumption externalities. Our main result is that under plausible conditions, a firm may reduce prices for consumers that have low price elasticity of demand. The firm can enhance its profits by reducing prices for consumers that have high price elasticity of demand in order to promote the consumption of all consumers, provided that there exist positive consumption externalities that expand the other group’s consumption. The remainder of the paper is organized as follows: Section 2 develops the model and shows the equilibrium outcome in the case of both uniform pricing and price discrimination, Section 3 presents our main results, and the last section presents a brief discussion and concludes our results.",10
9.0,3.0,"Journal of Industry, Competition and Trade",03 October 2008,https://link.springer.com/article/10.1007/s10842-008-0044-z,Delegation Commitment in Oligopoly,September 2009,Ya-Chin Wang,Leonard F. S. Wang,,Unknown,Male,Unknown,Male,"In the real world, the distinction between strategy leaders and followers is often based upon the ability to pre-announce their strategic policies, for example, transfer pricing, trade policy and managerial incentives, etc. Strategy leaders and followers tend to emerge from industries that are comprised of some well-established, market leading firms, which are in the position to become leaders. Such leaders have larger market share and sound corporate governance, which may play a lead role in committing incentive schemes to retain managerial executives before making production decisions. Since these strategic variables are substitutes, then the strategy leaders have a strategic incentive to increase the degree of aggressiveness in the market. It has been observed and highly publicized that the semiconductor industry in Taiwan annually increases its export value and is highly competitive in the global market. In this industry, a group of leading firms including Taiwan Semiconductor Manufacturing Company (TSMC) and United Microelectronics Corporation (UMC) have been institutionally providing a cash bonus and stock option scheme which places tremendous pressure on other firms to implement such managerial incentive strategies. The theory of strategic delegation pioneered by Vickers (1985), Fershtman and Judd (1987), and Sklivas (1987; henceforth VFJS) argued that managerial contracts must specifically allow for some weight attached to dimensional variables like revenues or market share as this enhances the firm’s equilibrium profits, even though behavior of managers deviates from pure profit-maximizing objectives.Footnote 1 Witteloostuijn et al. (2007) examined in the sales delegation case how profits and social welfare depend on managerial power, while Jansen et al. (2007) and Ritz (2008) have focused on market share incentive and indicated that both market share and sales delegation models lead to more aggressive managerial behavior than the standard Cournot case. From the theoretical aspect, it has been argued that a multiple leader–follower model is a consistent extension of Stackelberg’s leader–follower duopoly. Okuguchi (1976) and Furth (1979) have presented consistent extensions of Stackelberg’s model to the multiple leader situations in a way that gives equilibrium solutions. Sherali et al. (1983) and Sherali (1984) presented a multiple leader–follower model that employs true follower reaction curves, and is able to yield a true leader–follower extension to Stackelberg’s model.Footnote 2 Daughety (1990) and Feltovich (2001) used such multiple leader models while looking into the effects of horizontal mergers on profit, welfare and concentration. Most studies related to oligopoly theory have constructed models by allowing simultaneous and sequential moves in the market stage. However, less attention has been devoted to the issue of whether the sequential delegation played by multiple managerial firms may lead to the outcome where in these firms move sequentially in the market game. When owners delegate to their managers at different time horizons, sequential strategy equilibria are obtained, while if they decide the incentive scheme at the same time, simultaneous strategy equilibria are observed. Within such context, we wish to examine whether the sequential delegation to managers in Cournot settings is advantageous, in that it may give rise to Stackelberg leadership even though firms move simultaneously in the product market stage. In addition, we aim to come up with some important implications on the number of firms, the unequal distribution of firms and the sequence of delegation, and how they may create profit-shifting and improve social welfare. In this paper, we use the n-firms model and allow unequal distribution between leader firms and follower firms, and determine ways in which this model explores the implications of managerial delegation in a two-stage game. The subgame perfect equilibrium is defined in a quantity-competition model with fully observable information. Dealing with managerial incentive in an oligopolistic competition market, simultaneous delegation and sequential delegation models are considered. In the simultaneous delegation model, strategy and output decisions in both stages are determined simultaneously by firms, while in the sequential delegation model, sequential strategy moves are involved but outputs are maintained by simultaneous moves. It is found that in the sequential delegation model, the leader’s output will not be affected by changing the number of the follower firms when there is only one leader. In addition, more equal distribution of the numbers of leaders and followers will result in higher industry output, lower price, lower industry profit, higher consumer surplus and higher economic welfare; moreover, economic welfare in the sequential delegation model is always higher than in a simultaneous delegation model. The remainder of the paper is organized as follows. “The basic model” considers the simultaneous delegation model as a benchmark, while “The sequential delegation model” explores the sequential strategy game. “Sequential delegation model vs. simultaneous delegation model” provides the results of sequential strategy game vs. simultaneous strategy game. “Conclusion” provides the concluding remark.",2
9.0,4.0,"Journal of Industry, Competition and Trade",08 May 2009,https://link.springer.com/article/10.1007/s10842-009-0053-6,The Paradigm of Knowledge-Oriented Industrial Policy,December 2009,Rumen Dobrinsky,,,Male,Unknown,Unknown,Male,"Industrial policy has experienced periods of rise and fall in real life policy making. It has also long been subject to heated debates and controversies in the economic literature. These controversies concern not only the policy rationale, objectives and instruments but also the very definition and the scope of policy actions that fall under this category. In this paper, it will be assumed that industrial policy in the broad sense relates to public sector interventions that seek to affect the sectoral composition of the economy. In this sense, our understanding is close to that of Bianchi and Labory (2006a, b) who define industrial policy as “a variety of public actions aimed at guiding and controlling the structural transformation process of an economy”. The term “knowledge-oriented industrial policy” is used in the paper to denote a new brand of public sector interventions targeting various structural aspects of the economy through transmission channels and mechanisms that hinge on the driving forces of knowledge flows and stocks and incorporating a systemic understanding of the policy rationale. The distinction between “traditional” and “knowledge-oriented” industrial policy reflects fundamental changes in the global economy during the past several decades, more specifically, the transition of the dominant economic pattern from industrial to post-industrial to knowledge-based (Aiginger 2007; Soete 2007). Knowledge-oriented policy has been gaining ground with the rise of the post-industrial, knowledge-driven economy, when knowledge-based economic activities are gradually taking the lead in terms of value generation within the economy. The transition from traditional to knowledge-oriented policy also partly reflects the emergence or further development of new strands in economic theory such as new/endogenous growth theory, information economics, institutional economics and, especially, of evolutionary economics. While during the last several decades industrial policy has seen ups and downs, there have been some clearly discernible trends both in its design and implementation: from “strong” to “weak” industrial policy, from “interventionist” to “enabling” and “facilitating” policies, from “direct” to “indirect” policy actions, from “vertical” to “horizontal” policy measures, from a “sectoral” to a “systemic” approach, from “picking the winners” to “providing framework conditions”, from “low-tech” to “high-tech” industrial policy, from targeting physical capital to targeting human capital, from “supply push” towards “demand pull”, to name but a few. The paper attempts to synthesize some of the important outcomes of the evolution of thinking on industrial policy in the knowledge-based economy and the related advances in policy practice. While the discussion draws on the results in various areas of the theoretical, empirical and policy-oriented literature, its objective is to come up with original synthetic understanding of the key features of knowledge-oriented industrial policy, its theoretical background, rationale and operational framework. Taken together, these features form the paradigm of knowledge-oriented industrial policy. In synthesizing the newly shaping paradigm, the paper seeks to identify contrasts between traditional and knowledge-oriented industrial policy in order to highlight the results of a long process of gradual change. While in reality the contrasts are not that pronounced, as elements of traditional and knowledge-oriented industrial policy still continue to coexist, drawing the distinction is important when looking into the future, as the rudiments of the past are gradually being phased out and substituted with the emerging new mainstream. The paper also challenges some of the clichés and prejudices associated with the notion of “industrial policy” that largely stem from its traditional interpretation.Footnote 1
 The remaining part of the paper is organized as follows. Section 2 briefly traces the recent evolution of industrial policy and its theoretical foundations, in particular, the changes driven by the growing importance of knowledge in the modern economy. Section 3 looks at the changing role of the state and rationale for policy intervention in the knowledge-based economy. Section 4 presents a typology of the instruments of knowledge-oriented industrial policy and discusses their effectiveness. Section 5 concludes.",
9.0,4.0,"Journal of Industry, Competition and Trade",29 May 2009,https://link.springer.com/article/10.1007/s10842-009-0055-4,Acquisitions in a Patent Contest Model with Large and Small Firms,December 2009,Robin Kleer,,,,Unknown,Unknown,Mix,,
9.0,4.0,"Journal of Industry, Competition and Trade",29 April 2008,https://link.springer.com/article/10.1007/s10842-008-0033-2,The Cost Factor in Patent Systems,December 2009,Bruno van Pottelsberghe de la Potterie,Didier François,,Male,Male,Unknown,Male,"On the 16th of January 2006 the Directorate General Internal Market and Services of the European Commission announced a consultation process on future patent policy in Europe. The public hearing focused on three major issues: the community patent, how the current patent system in Europe could be improved; and possible areas of harmonisation: “the Commission is seeking views on what action could be taken while work on the Community patent is continuing, in particular within the framework of the existing patent system, or by bringing national patent systems more closely in line with each other through either approximation of laws or mutual recognition of national patents.” (Press Releases, IP/06/38).Footnote 1
 This consultation process can be considered as the cutting edge of an escalating and long lasting debate on whether and how Europe should put in place a properly harmonized patent system. The past few years have indeed seen an intensifying politicization of intellectual property (IP) issues. Long considered as a technical/legal issue, intellectual property is increasingly embodied into business strategies, and the IP system is nowadays definitely established in the political arena due in part to the perception that innovation is a major source of economic growth (e.g., the survey by The Economist, October 22nd 2005; on “patents and technology: a market for ideas”; Rivette and Kline’s 2000 book “Rembrandts in the attic: Unlocking the hidden value of patents”; and Arora et al. 2001 book “Markets for technology”). One of the most sensitive and long lasting bones of contention regarding the European patent system is related to the high cost of patenting, which is partly due to the failure to effectively implement the European community patent.Footnote 2 The high opportunity cost of this failure, for firms and society at large, is perceived as one important factor hindering innovation in Europe, which explains why the European Union’ commissioner of Directorate General Internal Market, Mr. McCreevy, wanted to make “one final effort” to resolve the issue.Footnote 3
 This paper aims at contributing to the debate through an empirical and international perspective. The main argument that is put forward is that both the high fragmentation of the European market for intellectual property and the high patenting costs translate into a relatively low demand for patent protection in Europe. The objective of the paper is to assess whether and to what extent the cost of patenting affects the demand for patents. The analysis focuses on the patent offices of the USA (US Patent and Trademark Office, USPTO), Japan (Japanese Patent Office, JPO), and Europe (European Patent Office, EPO). The year 2003 is chosen for the sake of data availability. The paper is structured as follows. The next section is dedicated to a broad presentation of the three regional patent offices and assesses the relative markets for technologies through the number of patent applications they receive each year. Section 3 presents a comparative analysis of the cost of having a patent granted and maintained in force for 10 or 20 years in the three patent systems (for the EPO, the simulation is performed for the three and 13 EPO member countries that are the most frequently designated for protection). As the three regional offices have different granting processes, the cost issue must indubitably be put in perspective with process/quality considerations, which are presented in Section 4. Section 5 concludes with policy and methodological implications. The results show first that the US market for technology is three times more attractive (if measured with the number of filings) than the European market for technology. Second, the cost of a patent (claim) which designates 13 EPO Member countries is 5 to 11 (6 to 14) times more expensive than in the USA, depending on the desired length for protection. Third, when the number of claims is taken into account instead of the number of patents, and when the size of the market is accounted for through the 3C-index (cost per claim per capita), there is a clear negative relationship between the cost of patenting and the demand for patents, witnessing a strong patent applications elasticity with respect to prices. Cost is not the only driving force, as several indicators lead us to conclude that the EPO is more selective in its granting process (longer examination time and smaller granting rate) than the USPTO. The higher rigor of the EPO granting process would justify higher examination costs but not the high complexity and cost burden induced by the current fragmented market for intellectual property. The policy implication is that a better harmonization of the European patent system would drastically reduce the current costs and complexity burdens. These costs do not reflect the effectiveness or rigor of a patent system, but rather a selection mechanism strongly based on the financial resources of the applicants. The various possibilities for improvement range from a simple harmonization of the fee structure across the EPC member states to the effective implementation of the Community Patent project. The larger size of the European market would allow for substantially higher fees that would ensure a rigorous examination process with a relatively low cost per claim per capita.",
9.0,4.0,"Journal of Industry, Competition and Trade",17 March 2009,https://link.springer.com/article/10.1007/s10842-009-0049-2,Lessons for African Economies from Irish and East Asian Industrial Policy,December 2009,David Bailey,Helena Lenihan,Ajit Singh,Male,Female,,Mix,,
10.0,1.0,"Journal of Industry, Competition and Trade",14 April 2009,https://link.springer.com/article/10.1007/s10842-009-0051-8,Competitive Pressure in Transition: A Role for Trade and Competition Policies?,March 2010,Rosen Marinov,,,Male,Unknown,Unknown,Male,"This paper investigates the role and interaction of trade and competition policies in the shaping of competitive markets.Footnote 1 In contrast to ample theoretical analysis, empirical evidence on the effects of market intervention via either of the two mechanisms remains somewhat scarce in the literature. While turnarounds in trade policy have received some attention, cases of gradual transition have proven more difficult to investigate, mainly due to data availability constraints. Likewise, the inability to benchmark antitrust enforcement against a quantifiable common base has discouraged empirical analysis of this important policy instrument’s impact. A growing number of firm-level studies confirm the premise that import competition might play a role in curtailing domestic market power. The effects of trade liberalization on companies’ price-cost margins have been empirically explored by Levinsohn (1993), Harrison (1994), Krishna and Mitra (1998), and Bottasso and Sembenelli (2001). Focusing on instances of increased protection, Konings and Vandenbussche (2005) use a similar approach to investigate the impact of anti-dumping measures. These papers’ findings are in line with theoretical predictions on the coercive effect of enhanced international competition. However, even in a small open economy the influence of import penetration could vary considerably across industries and, in some cases, may prove insufficient to discipline the pricing behavior of domestic firms. For lack of suitable explanatory variables, attempts to estimate the effects of national competition policy on company price-cost margins have remained much more limited. To date, the only firm-level investigation of this kind has been conducted by Konings et al. (2001). In a related analysis based on aggregate data, Hoekman and Kee (2003) use a large cross-country sample to test for structural breaks in estimated industry mark-ups, following the adoption of competition legislation. A common feature of the studies to date is their dependence on a one-time switch of regime to identify the respective effects on market contestability. Moreover, the available enterprise-level evidence is typically limited to the national borders of a single country. In light of the difficulties with quantifying trade and antitrust regimes, the robustness of the studied relationships should ideally be tested using alternative measures and specifications, as well as in consistent cross-country replications. The contribution of this paper to the existing body of literature is twofold. We trace the evolution of trade policy using detailed annual data and document the effects of tariff protection in seven Central and Eastern European countries. In addition, we contribute to the hitherto limited evidence on the role of competition policy implementation, on the basis of transition economies’ informative experience. Former centrally planned economies offer an opportune setting for a study of trade and competition policies’ interaction in influencing the emergence of competitive pressure. Notably, countries acceding to the EU set a particularly interesting precedent, in light of the shared blueprint for legislative and institutional reforms. The common legacy of extensively integrated production, both vertically and horizontally, ensured a broadly equivalent starting point for the economic transformation of post-socialist Central and Eastern Europe. While opening up to international trade and investment in the aftermath of the Council for Mutual Economic Assistance (Comecon/CMEA) introduced some contestability in product markets, imports alone could not foster the formation of strong competitive pressure in all industry sectors. Accordingly, properly designed and enforced antitrust rules had a crucial role to play in narrowing the considerable scope for market power abuses in the course of economic transformation. The interplay of trade and competition policies is also pertinent in light of the latter’s relative decentralization in the process of European integration. Upon accession to the EU, member states adhere to a uniform trade regime, but retain a degree of autonomy in the formulation of antitrust rules. While the prospect of overlapping jurisdictions may have a strong disciplining effect, both on firms and national competition authorities, the possibility of sequential enforcement could undermine effectiveness. In that respect, further parallels can be drawn among transition countries at the outset of institutional reforms. Newly established antitrust agencies typically lacked the expertise to carry out sophisticated context-specific analyses, necessary for effective application of competition rules. Moreover, in the absence of prior experience with antitrust cases, post-socialist judicial systems were poorly equipped to handle appeals. In fact, the case law of the European Court of Justice has served as a natural reference point in this context, particularly at the more advanced stage of preparations for EU membership. Notwithstanding the shared commitment to legal and institutional alignment with the acquis communautaire, the studied economies’ reform experiences are not fully symmetrical. The evolution of national regulatory frameworks exhibits considerable variation in timing and policy-making choices, which provide valuable insights regarding the emergence of competitive pressure. In our attempt to link outcomes to policies, we draw on cross-country, inter-industry and firm heterogeneity to disentangle the effects of changes in national trade and antitrust regimes from the overall impact of structural reforms across the future EU member states.",3
10.0,1.0,"Journal of Industry, Competition and Trade",21 July 2009,https://link.springer.com/article/10.1007/s10842-009-0056-3,Most-Favoured-Customer Pricing and Labour-Managed Oligopoly,March 2010,Kazuhiro Ohnishi,,,Male,Unknown,Unknown,Male,"Most-favoured-customer (MFC) pricing as a strategic instrument has been examined by many economists.Footnote 1 MFC policies may be either contemporaneous or retroactive. A contemporaneous MFC policy prevents price discrimination when the seller offers a discounted price to another buyer in the present. For example, DeGraba (1987) presents a model in which a national firm competes against a local firm in each of two geographically separated markets and shows that, when the national firm includes MFC clauses in its contracts, all firms charge lower prices than they would if no such policies existed. Besanko and Lyon (1993) investigate the economics of contemporaneous MFC policies in a non-cooperative oligopoly and show that not adopting MFC policies can be a dominant strategy. Aguirre (2000) examines the effects of the unilateral contemporaneous MFC policy and shows that the policy can make a firm a tougher or a softer competitor, depending on the circumstances. Under a retroactive MFC pricing policy, the seller promises to give its present customers a rebate of the price difference if the price falls in the future. Salop (1986) argues that the retroactive MFC policy helps sellers cooperate because it raises the cost of price cutting. Cooper (1986) and Tirole (1988) use two-period duopoly models to demonstrate that the retroactive MFC policy enables both firms to offer higher prices and to enjoy higher profits and facilitates collusion between firms. Tirole (1988) asserts that the MFC policy is not a good strategy for entry deterrence purposes because it commits to a less aggressive behaviour that induces its rival to produce more. Neilson and Winter (1992) examine Cooper’s two-period duopoly model and show that the unilateral MFC equilibrium price lies strictly between the Bertrand price and the Stackelberg leader price. Furthermore, Neilson and Winter (1993) also examine Cooper’s model and show that unless one firm’s demand is more responsive to changes in its competitor’s price than to its own price changes, there is no equilibrium in which both firms adopt MFC policies. These studies are models with profit-maximizing firms and do not include labour-managed firms. Therefore, we study the behaviour of labour-managed firms.Footnote 2 The pioneering work on a theoretical model of a labour-managed firm was conducted by Ward (1958). Since then, many economists have studied the behaviour of labour-managed firms.Footnote 3 For example, Laffont and Moreaux (1985) examine the welfare properties of free-entry Cournot equilibria in labour-managed economies and show that Cournot equilibria are efficient provided that the market is sufficiently large.Footnote 4 Okuguchi (1986) compares the Bertrand and Cournot equilibrium prices for the labour-managed oligopoly under product differentiation and shows that the Cournot equilibrium prices are not lower than the Bertrand ones. Zhang (1993) and Haruna (1996) apply Dixit (1980) and Bulow et al. (1985) frameworks of entry deterrence to labour-managed industries and show that labour-managed incumbents have greater incentive to hold excess capacity to deter entry than corresponding profit-maximizing incumbents. Okuguchi (1993) examines two models of duopoly with product differentiation and with only labour-managed firms, in one of which two firms’ strategies are outputs (labour-managed Cournot duopoly) and prices become strategic variables in the other (labour-managed Bertrand duopoly). He shows that reaction functions are upward-sloping under general conditions in both labour-managed Bertrand and Cournot duopolies with product differentiation.Footnote 5 Lambertini and Rossini (1998) analyze the behaviour of labour-managed firms in a two-stage Cournot duopoly model with capital strategic interaction and show that labour-managed firms choose their capital commitments according to the level of interest rate, unlike what usually happens when only profit-maximizing firms operate in the market. Lambertini (2001) examines a spatial differentiation duopoly model and shows that if both firms are labour-managed, there exists a (symmetric) subgame perfect equilibrium in pure strategies with firms located at the first and third quartiles, if and only if the setup cost is low enough. Furthermore, Drago and Turnbull (1992) provide a model of work effort and wage incentives in the worker-owned or labour-managed firm and show that if employee-owners can establish binding effort matching agreements, purely collective incentives are optimal. We consider a price-setting oligopoly model in which labour-managed firms can offer retroactive MFC policies as a strategic commitment. The two periods of the model run as follows. In the first period, each firm non cooperatively decides whether to adopt an MFC policy and chooses a first-period price. If a firm adopts the policy, then it guarantees its first-period customers a rebate if its second-period price is below its first-period price. In the second period, each firm noncooperatively chooses a second-period price. We discuss the equilibrium of the labour-managed oligopoly model with MFC pricing. The purpose of this study is to present the equilibrium of the labour-managed oligopoly model with MFC pricing and show the effects of the MFC policy. The remainder of this paper is organized as follows. In Section 2, we formulate the model. Section 3 presents the equilibrium of the model. Section 4 concludes the paper. All proofs are given in the “Appendix”.",
10.0,1.0,"Journal of Industry, Competition and Trade",18 March 2009,https://link.springer.com/article/10.1007/s10842-009-0050-9,"Buyer Power, Transport Cost and Welfare",March 2010,Hao Wang,,,,Unknown,Unknown,Mix,,
10.0,1.0,"Journal of Industry, Competition and Trade",05 November 2008,https://link.springer.com/article/10.1007/s10842-008-0047-9,Information Exchange as a Means of Collusion: The Case of the Italian Car Insurance Market,March 2010,Paolo Coccorese,,,Male,Unknown,Unknown,Male,"Whether information exchange among firms allows welfare improvements through efficiency gains or produces welfare losses due to anti-competitive coordination is a crucial topic for both economic theory and antitrust policy. However, as Doyle and Snyder (1999) note, in spite of the fact that the issue remains controversial, there has been little econometric work on information sharing behavior. In this paper we consider a recent intervention of the Italian Antitrust Authority in the motor vehicle insurance market,Footnote 1 and its decision of fining several companies for their supposed anti-competitive conduct deriving from the exchange of sensitive information. Our aim is to evaluate this verdict by means of an econometric test, the Panzar-Rosse H-statistic, which has been widely used in other industries for its capacity to assess the type and the level of competition among firms. The investigation started on September 1999, and was completed in July 2000. The Italian Antitrust Authority found 39 companiesFootnote 2 guilty of anti-competitive behavior through two distinct courses of conduct: firstly, 15 of the leading motor vehicle insurers had identical terms and conditions of insurance towards customers, all of them refusing to provide fire and theft insurance separately from third-party liability insurance; secondly, all the investigated companies were characterized by a concerted practice of information sharing, concerning both aggregate and individual data. Therefore, the reference markets under exam (both defined as national) were mandatory car liability insurance and other motor vehicle insurance (particularly, covering fire and theft). The parallel behavior was judged as the consequence of a huge exchange of strategic information among the companies through a third and independent company (Rc Log), whose information circuit was based on the principle of reciprocity. In the view of the Authority, this represented a serious violation of competition legislation in terms of the quantity, degree of detail and frequency of the information exchanged, also considering that the companies constituting this horizontal agreement accounted for about 80% of the total motor vehicle insurance industry. As a consequence, the Authority imposed fines totaling approximately 360 million euro. This decision was challenged by the insurance companies. They appealed both to the Regional Administrative Court of Lazio (2001) and the Council of State (2002), but the verdict was essentially upheld. The Italian Authority based its decision on the presumption that the mechanism introduced by the insurance companies constituted an institutionalized system for the exchange of sensitive data, which allowed to anticipate the conduct of competitors and therefore created an artificial transparency in the market. As underlined before, the information sharing concerned both aggregate and individual data, like revenues from sales of insurance policies, accidents disaggregated according to the Italian provinces, standard terms of communication between the insurer and the insured, and especially current prices of individual firms for a huge number of types of risk (Grillo 2002 p. 162). The Italian insurers association (ANIA) disputed this decision. In its opinion, it did not refer to an understanding on prices, but was based on a supposed information exchange, assessed with rigid formalism. In other words, ANIA argued that the decision had been based on juridical dogmatism rather than on the empirical economic analysis of the facts (ANIA 2002 p. 40–42). The Italian supervisory authority for private insurance (ISVAP) expressed a different judgment: the main cause of the increase in prices was the growth of costs for car damages and physical injures compensation. This standpoint was also supported by a study coming from the British Market Fact and Business Information (MFBI), where it was shown that in the period 1992–1997 the increase of the car repair costs in Italy had been much larger than in other European countries. ISVAP’s view was that the information exchange between insurance companies might have helped the exact determination of the premiums: from an economic perspective, if there are losses in the market (like those deriving from the growing reimbursement costs), an anti-competitive behavior is not conceivable as long as revenues do not cover costs, whilst the information exchange can drive towards the theoretical competitive price that is able to hinder losses.Footnote 3 However, this argument was not sufficient to avoid the conviction. It is worth noticing also that, in order to prevent possible future tensions as regards the pricing structure, in 2003 the Italian Government, ANIA and the majority of the Consumer Associations signed an Agreement Protocol on motor liability insurance, where they have agreed to work together on the crisis factors, combining measures on rates, prevention of risks and cost factors. As a whole, in terms of volume of premiums the Italian automobile liability insurance industry amounted to 17,622 million euro in 2003, more than a half of the total damage liabilityFootnote 4 insurance sector (34,212 millions euro)—which also comprises the premiums related to motor vehicles, houses, etc.—and about 20% of the whole insurance market (96,992 millions euro), including life and health insurance. In Italy, motor vehicle liability insurance is compulsory since 1969. In the period 1969–1994 prices and contract conditions were defined by the State, while from 1994 the market has been deregulated with respect to premiums and contract clauses. As a result, a sharp increase in the average premium for the automobile insurance followed,Footnote 5 amounting to 96.55% in the period June 1994-January 2000 (and especially in the very last part of it), a striking peculiarity of the Italian market when compared to other EC countries (AGCM 2003 p. 116). In the same time interval (1994–2000), the structure of the motor insurance market has remained fairly stable. The 4-firm concentration ratio has been about 27.5% on average, and did not show significant variations. The same has happened to the Herfindahl-Hirschman Index, whose value was around 390 (Turchetti and Daraio 2004 p. 206). However, in 2001 (but the figures are quite similar also for 2003), 49 companies operating in the car segment belonged to the top 10 groups, which owned more than 85% of the market share (it was about 73% in 1995).Footnote 6 This is an outstanding phenomenon, especially considering that the industry structure seems to be characterized by negligible scale economies, and that the minimum efficient scale is not so high to constitute a barrier to entry.Footnote 7 In addition, there exist inter-company interests, like crossed shareholdings and interlocking directorships, while the distribution channel is still characterized by exclusive agencies, which do not help the achievement of a more competitive environment given that they sell just the product of one company. As a result, a noteworthy degree of concentration in the Italian automobile insurance market emerges, although the Antitrust Authority did not consider the oligopolistic nature of this industry as a key factor for its final decision about the presence of a collusive behavior (mainly based on the strong upward trend of the premiums). All the above issues justify our empirical test. Actually, the Panzar-Rosse approach provides an indicator, the so-called H-statistic, which delivers a quantitative assessment of the competitive nature of a market. Its estimation could therefore give useful information on the overall level of competition prevailing in the Italian motor vehicle insurance market, thereby making possible a more accurate evaluation of the Antitrust decision. The structure of the paper is the following. In Section 2 we consider the function of information sharing as a facilitating practice. Section 3 illustrates the Panzar-Rosse approach and its potential for the detection of collusive behaviors within a market, while Section 4 discusses the data and presents the results of our estimations for the period 1998–2003. Section 5 concludes.",7
10.0,1.0,"Journal of Industry, Competition and Trade",21 May 2009,https://link.springer.com/article/10.1007/s10842-009-0054-5,Modelling Competition in the Textbook Market: Some Lessons still to Learn,March 2010,Juan Luis Jiménez,Javier Campos,,Male,,Unknown,Mix,,
10.0,2.0,"Journal of Industry, Competition and Trade",10 September 2009,https://link.springer.com/article/10.1007/s10842-009-0058-1,"Discriminatory Prices, Predation and Signal-Jamming in a Horizontal Differentiation Model",June 2010,Stefano Colombo,,,Male,Unknown,Unknown,Male,"Predatory prices are an issue that has intrigued economists for many years. They are usually defined as prices which are below the marginal costs or the average variable costs (Areeda and Turner 1975).Footnote 1 After a long period of scepticism–consequent to the influential article of McGee (1958)–about the possibility that predation exists, economists have turned their mind and now are well convinced that predation may be absolutely rational.Footnote 2 Whatever is the underlying reason, predation is characterized by the fact that the predator is ready to suffer current losses in change of (expected) future gains. Notwithstanding the importance of the issue, the literature about the effects of predatory pricing is quite scarce. For example, the comprehensive analysis by Bolton et al. (2000), which is very extensive about the rationale of predation, is totally lacking in considering the effects of predation.Footnote 3 Our paper intends to investigate the effects of predation by taking for granted its rationality. Our paper is partially linked to Armstrong and Vickers (1993). They develop an entry model, in which selective above-costs price cuts are considered.Footnote 4 There are two market segments with an incumbent which operates in both markets, and an entrant which can enter only one of the segments. Armstrong and Vickers (1993) investigate the effects of price discrimination on entrance and equilibrium prices. In general, a discriminating incumbent may reduce prices in the attacked segment without changing the price in the uncontested segment. Armstrong and Vickers (1993) show that there exists a range of entrance costs over which entrance does not occur when the incumbent can price discriminate. In this case, the result is that equilibrium prices are higher when price discrimination is possible than when price discrimination is impossible.Footnote 5
 In contrast, we develop a very simple predation model, in which we assume an incumbent firm and a potential entrant firm competing in a linear market à la Hotelling (1929). The predator/incumbent is able to price discriminate, while the prey/entrant is not able to price discriminate when it enters the market (if enters). We rationalize this assumption by arguing that price discrimination is possible only when a firm has a deep knowledge of the market: in this sense, the incumbent has certainly a better knowledge of the market than the entrant, due to the fact that it is in the market when the game starts while the entrant is outside the market. However, we allow the entrant to learn the consumers’ willingness to pay by looking at the prices set by the incumbent. Hence, provided that the incumbent engages in price discrimination, the informative advantage of the incumbent does not persist. Instead, if the incumbent uses a uniform price, the entrant does not learn consumers’ willingness to pay and continues to suffer the informative disadvantage. Therefore, the incumbent may strategically decide to hide consumers’ willingness to pay from the entrant, engaging in a “signal-jamming” strategy (Fudemberg and Tirole 1986). Differently from Armstrong and Vickers (1993) we explicitly admit that the predator/incumbent may price below the marginal costs (predation). Moreover, there are no “captive” markets, since the prey/entrant competes for all consumers, even if the competitive pressure exerted by the prey/entrant is lower the farther the consumers are from it. We obtain the following results. If the discount factor is high enough and accommodation occurs in equilibrium, the incumbent engages in a “signal-jamming” strategy, that is, it accommodates entrance by setting a uniform price in order to hide the consumers’ willingness to pay from the entrant; subsequently the incumbent uses discriminatory prices. Second, both when the incumbent engages in a “signal-jamming” strategy and when it does not engage, we show that under certain conditions the entrant prices aggressively in order to discourage predation from the incumbent: predation does not occur in equilibrium and all equilibrium prices are lower with respect to the case where the threat of predation is absent. This is the central result of the paper, and it implies that under certain conditions consumers gain from the possibility to prey, while both firms are damaged. Finally, in a T-periods model, conditions are derived for the equilibrium prices to increase over time until they stabilize at the level that would result in absence of predation.Footnote 6
 The paper proceeds as follows. In Section 2 we describe the basic two-period model. In Section 3 we solve the model and we characterize the main result. In Section 4 we extend the model to the case of T-periods. Section 5 concludes. The Appendix analyses the role of product differentiation.",
10.0,2.0,"Journal of Industry, Competition and Trade",26 August 2009,https://link.springer.com/article/10.1007/s10842-009-0057-2,"Media Mergers with Preference Externalities and Their Implications for Content Diversity, Consumer Welfare, and Policy",June 2010,C. Anthony Bush,Paul R. Zimmerman,,Unknown,Male,Unknown,Male,"The impact of higher media market concentration levels on the “diversity” of media coverage remains a controversial topic that lies at the forefront of national and local regulatory policy agendas. For instance, in 2002 the U.S. Federal Communications Commission (“FCC”) released a number of academic studies to evaluate the effect of media consolidation on various market outcomes.Footnote 1 The FCC then released an order and notice of proposed rulemaking in June, 2003, that partially repealed its regulation of mass media outlets (FCC 2003). The resulting public outcry against the FCC’s proposed actions was based in part on the fear that further consolidation of the media industry would lead to the foreclosure of programming variety in various media markets, which led to Congressional legislation imposing stricter rules on mergers between television stations.Footnote 2 Subsequently, in Prometheus vs. FCC, the U.S. Third Circuit Court of Appeals remanded several of the FCC’s deregulatory proposals.Footnote 3 Today the FCC continues its investigation into how changing media ownership rules may affect the diversity of media content.Footnote 4
 Several empirical studies have explored the relationship between media ownership concentration and product variety.Footnote 5 Some suggest a variety-enhancing effect of consolidation while others reach the opposite conclusion. Another body of empirical literature examines the role of “preference externalities” on content diversity in media markets.Footnote 6 These studies demonstrate that for industries characterized by high fixed costs of entry and heterogeneous consumer preferences over product variety (which is an accurate depiction of most media markets), the larger the number of individuals belonging to a group with a given preference characteristic the more likely suppliers (i.e., media outlets) will choose to target these consumers. That is, as the number of consumers of a given “type” increases, the more likely they will have the type of products they desire supplied to them.Footnote 7 It is in this sense that consumers with similar tastes exert a positive preference externality on one another: individuals are more likely to consume their preferred output if the market contains more persons with similar preferences and vice versa. This study adds to the above body of literature by examining the effect of media consolidation on pricing and content diversity in the presence of consumer preference externalities. Section 2 begins by introducing a model of consumer choice with two groups of consumers that differ in both size and the type of media output each prefers. The presence of preference externalities and the consumption of preferred versus non-preferred content by consumer type are taken into account within the consumer choice problem. From there expressions for each consumer group’s expenditure function for media output, as well as the corresponding aggregate expenditure function, are derived. Relying on the latter expressions, a model of firm behavior is then developed where, in equilibrium, a representative price- and content-setting media outlet optimally responds to changes in the mix of subscribers by engaging in product repositioning. That is, the outlet devoting a greater proportion of the total content it provides to consumers in the “group” with the relatively greater number of members post-merger. Thus, the model formalizes the conceptualization of preference externalities initially set forth and tested in Waldfogel (2004) and George and Waldfogel (2003). In addition, we demonstrate how the elasticity of demand for media output depends on both quality and price margins in the presence of preference externalities and explore how this elasticity responds to changes in the proportion of content offered by the media outlet to a particular subscriber group. The potential loss in content or “viewpoint” diversity is arguably the most significant concern raised regarding the impact of media mergers. Section 3 considers a merger between two media outlets (each of which serves a distinct customer base pre-merger) that results in the merged firm “homogenizing” its content mix. We show that despite this (presumed) behavior on the part of the merged entity, with preference externalities some minority (majority) consumer types will nonetheless have greater (lesser) access to their “preferred” content while others will necessarily have less (more) post-merger. Finally, we derive sufficient conditions under which the merged entity will in fact possess the incentive to homogenize its content mix, which suggests this particular realization of product repositioning may be empirically relevant in some circumstances. Section 4 then briefly discusses the relation between the model’s theoretical predictions and recent empirical work exploring the effect of media mergers on content diversity. Evidence from a large, recent media merger that appears consistent with the model’s predictions is also presented. Section 5 discusses the model’s implications for subscriber welfare. Although the results suggests that subscriber welfare effects are likely to be ambiguous a priori, the fact that several recent empirical studies have shown distinct differences in the type of media content consumed across demographic groups suggests that such transactions may result in significant losses in consumer welfare for some subscribers. Further, the potential influence that media mergers (through their effect on access to a group’s preferred content) may have on other non-price margins such as voter participation (e.g., as suggested by Oberholzer-Gee and Waldfogel 2005, 2006) and the resultant implications for consumer welfare are also considered. Given the potential adverse price and/or content (diversity) effects to some subscriber groups resulting from media mergers as predicted by the model, Section 6 discusses possible antitrust and/or regulatory policies. “Traditional” antitrust remedies, such as asset divestiture, may not be effective in ameliorating the harms from media mergers in some instances since they do not address the effect of media mergers on content or other non-price margins. Other policy interventions, such as the subsidization of minority-owned media outlets and behavioral remedies that require merged media entities to offer minority-oriented content on an à la carte basis, may preserve consumers’ access to their preferred content while also potentially protecting them from any anticompetitive price increase post-merger. Finally, Section 7 concludes.",2
10.0,2.0,"Journal of Industry, Competition and Trade",16 September 2009,https://link.springer.com/article/10.1007/s10842-009-0059-0,Vertical Integration in the Japanese Movie Industry,June 2010,Mitsuru Sunada,,,Male,Unknown,Unknown,Male,"This study examines vertical integration in the Japanese movie industry. As is well known, in the Paramount case, major U.S. studios were required to divest their theater chains in addition to the prohibition of block booking. Since the ruling, vertical integration in the U.S. movie industry has been almost illegal. On the other hand, in Japan, major distributors operate their own theaters, because vertical integration is not prohibited. Hence, we can observe both vertically integrated and nonintegrated theaters. Vertical integration may resolve inefficiencies such as double marginalization, downstream moral hazard, transaction cost, and free riding, although vertical integration may have anti-competitive effects such as foreclosure and rising rivals costs.Footnote 1 There are several empirical studies that investigate the effects of vertical integration (or divestment): for example, Blass and Carlton (2001), Hastings (2004), Hastings and Gilbert (2005), and Shepard (1993) for gasoline; Chipty (2001), Suzuki (2009), Vita (2000), and Waterman and Weiss (1996) for cable television; Slade (1998) for beer; and Jin and Leslie (2009) for restaurants. Although there are some exceptions, most previous studies appear to suggest that pro-competitive effects of vertical integration tend to overwhelm anti-competitive effects, that is, vertical integration benefits consumers.Footnote 2
 Movie companies have incentives to vertically integrate to avoid inefficiencies due to the complicated nature of the business. There are many empirical works on vertical structure in the U.S. and European movie industries. For example, Corts (2001) examined the effects of the vertical market structure between movie production and distribution on release data competition, and found that complex vertical structures do not lead to efficient movie scheduling. Gil (2006) studies the relationship between integration and the frequency of costly renegotiation in the Spanish movie industry, and the results suggest that movies renegotiated ex-post tend to be distributed by integrated distributors, ex-ante, and are more likely to show in vertically integrated theaters. Gil (2009b) analyzes the effect of vertical integration in the Spanish movie industry on movie run length, which will be affected by the revenue-sharing contracts, and finds that integrated theaters run their own movies longer than others. Gil (2009a) studies the effects of the Paramount ruling on the U.S. movie industry, and shows that theater divesture did not have an effect on economic outcomes, and therefore may have hurt industry agents and consumers. This study first performs simple admission price regressions and examines the relationship between price and vertical integration, utilizing the unique data from Japanese theaters. In the data, we can identify whether or not a theater is owned by distributors/producers. We then estimate the moviegoing demand equation, derived from a version of the structural demand models introduced by Berry (1994) and Berry et al. (1995), and used in Davis (2006) and Einav (2006). In the demand model, if vertical integration improves the quality of movie exhibition services, integrated theaters would have higher attendance than nonintegrated theaters. Therefore, we can directly check whether vertical integration affects demand or not. However, in the estimation of price and demand equations, we have identification problems: are high price and high attendance truly due to vertical integration or, are they due to the inherent high quality of vertically integrated theaters? In the latter case, vertically integrated theaters intrinsically face strong demand, and vertical integration does not have any effects on price and attendance. This study overcomes the problems, exploiting the panel structure of our dataset: theater fixed effects are incorporated into regression equations. The empirical results show that the price of vertically integrated theaters tends to be higher than nonintegrated theaters, but it seems to be due to the inherent high quality of vertically integrated theaters. This means that producers/distributors seem to acquire relatively attractive theaters. On the other hand, vertically integrated theaters are more popular among consumers and have larger attendance than nonintegrated theaters. Even after controlling the theater fixed effects, attendance for vertically integrated theaters is still larger than nonintegrated theaters. This suggests that, although vertically integrated theaters intrinsically have high quality, the integration makes such theaters more attractive to consumers. The results of this study are in line with the previous studies that support the view that vertical integration benefits consumers. The results show that competition agencies must carefully investigate competition effects of respective integrations, and have to be cautious about mandating structural change. The remaining parts of this study are organized as follows: the next section briefly reviews the movie industry. In the third section, I explain the empirical model of price and demand for movie attendance. The fourth section describes the data used in this study, variables and estimation issues. In the fifth section, the empirical results are presented. The last section provides the concluding remarks.",6
10.0,2.0,"Journal of Industry, Competition and Trade",02 February 2010,https://link.springer.com/article/10.1007/s10842-009-0063-4,"Product Market Cooperation, Profits and Welfare in the Presence of Labor Union",June 2010,Arijit Mukherjee,,,Unknown,Unknown,Unknown,Unknown,,
10.0,2.0,"Journal of Industry, Competition and Trade",24 September 2009,https://link.springer.com/article/10.1007/s10842-009-0060-7,Company Taxation and Merger Incentives in International Oligopoly: on International Policy Coordination with Strategic Trade,June 2010,Kjell Erik Lommerud,Trond E. Olsen,Odd Rune Straume,Male,Male,Male,Male,"Firms become more and more globalised, and cross-border mergers is an important vehicle behind this development. Many fear the consequences of globalisation of production, and would perhaps in stead favour that ‘national champions’Footnote 1 were established, that is, firms soundly anchored in the local economy that at the same time have the clout to compete and win market shares at the international arena. This paper does not seek to raise the national champion question in its full complexity, but we do point out that one motive for firms to seek cross-border alliances is that a multinational firm with production in many countries can play policy makers in the various countries out against each other. We ask whether this warrants international policy cooperation, and identify circumstances under which the perhaps surprising answer is ‘no’. We employ a Cournot model of international oligopoly. On the one hand, this is the standard workhorse model in strategic trade theory. The implication is that firms can earn positive profits, so a government might become interested in helping domestic firms to gain higher market shares. At the same time, the Cournot model is also the most commonly used model in merger theory. The distinguishing feature of the model relative to the strategic trade literatureFootnote 2 is that governments have access to two-part taxation. They can both use a uniform tax/subsidy per unit, while at the same time employing a fixed tax element unrelated to output, that in principle also can be positive or negative. In the current context, with a Cournot oligopoly, a government will—at least in the absence of policy coordination—tend to subsidise its national firms on a per unit basis, to gain international market shares, while the lump-sum tax element will be used to shift profit from firms to government. We will discuss below the realism of the assumption that governments can use this type of two-part taxation. One can see two-part taxation as an easy way to introduce profit taxation in combination with per unit production taxes/subsidies, and we will also show later in the paper that also other forms of profit taxation will yield results with the same flavour as those developed here. The basic story of the paper can be outlined as follows. At the outset there are two countries each with two domestic firms. Any two-firm merger is allowed, but not mergers involving three or all four firms. A merger will lead to fixed cost synergies, but also influence how firms compete in the (Cournot) market. The merger decision is taken before taxes are set, but firms know whether international policy coordination will take place or not. At a second stage, governments announce tax variables. At this point in time the merger decision is already undertaken, so the focus of the authorities will be on how taxation affects their domestic firms (or the domestic parts of international firms) in the Cournot market game that takes place subsequent to taxation. However, taxation will be anticipated by firms, so in this way the tax variables can influence the merger decision. In this setting, with two-part taxation, policy makers will extract all private profits if they are able to do so. A potentially successful strategy for firms to escape such confiscatory taxation is to merge cross-border. This will increase the flexibility in terms of production locations and give the internationally merged firm some leverage to react to taxation by shifting production elsewhere. However, with international cooperation on policy, where the lump-sum tax and the per-unit subsidy will be set so as to maximise the ‘cartel profit’, the policy makers’ ability to confiscate this cartel profit through the lump-sum tax might improve. In this case, policy coordination has a dampening effect on merger incentives and can therefore turn out to be unwanted from a domestic welfare perspective; it depends on how important it is to harvest at least some merger synergies relative to what can be achieved by the two producer countries in cashing in on their market power in the ‘third country’ where consumers reside. Non-coordination can be beneficial, but this is in no way a national champion policy. As we have described the policy set of the governments, they have no possibility to promote domestic mergers in order to build up large, viable domestic firms. If a national champion should have existed, the domestic government could not prevent itself from being too heavy-handed as regards profit taxation. The national government is left to choose between a production structure with small domestic firms or with bigger multinational firms. In the tax competition literature the focus is on governments that want to raise money for example by taxing companies, but who fear that capital may flee to low-tax havens. One would immediately presume that international tax coordination would be beneficial, to stop this race to the bottom. Kehoe (1989) argued oppositely, and based his argument on there being a hold-up problem in capital taxation. If the taxation of capital is too high, individuals will not save—and investments will suffer. Not entering into international coordination to avoid tax competition then becomes a de facto commitment device to avoid inefficiently high capital taxation.Footnote 3 When governments engage in strategic trade policy, this clearly entails negative externalities among nations. One country’s gain in international market share is another country’s loss. This seems again a clear-cut case for international policy cooperation. In this context none has pointed out that also here policy coordination can have unwanted side effects. The present paper introduces strategic trade policy in a setting where governments have two tax instruments, namely a per unit subsidy of production and a profit tax possibility. Since the money lost when subsidising local firms now can be recouped through profit taxation, one would presume that the option to subsidise local production becomes even more tempting. However, profit taxation introduces a hold-up problem even in strategic trade models. Since all pure profits can be confiscated, any up-front investment that cannot be fully deducted in the profit tax will simply not be undertaken. We assume precisely that any merger entails, possibly very small, such non-deductible costs. Governments should then worry that too heavy-handed profit taxation would drive out beneficial investments, such as mergers with potentially large positive synergies. Again lack of international policy coordination suggests itself as a commitment device – and the purpose of the paper is to get a handle on when it is and when it is not beneficial for a government to grasp this possibility.Footnote 4
 As already underlined, a main feature of the model is that governments have access to two-part tariffs when taxing firms: they can both use a uniform tax/subsidy per unit, while at the same time employing a fixed tax element unrelated to output, that in principle also can be positive or negative. Throughout the public economics literature two-part taxation has been used as a simple way to introduce profit taxation into the analysis. As we see it, the flavour of the present results will carry over to a setting where profit taxation constitutes some percentage of profits rather than being confiscatory, and we go some way towards confirming this in an extension to the main model. The basic point is that as long there are some non-deductible costs (now not necessarily very small) connected with merger, any taxation of the profit gains from merger will reduce the willingness to undertake such an investment. The remainder of this paper is organised as follows. The model is presented in Section 2. Section 3 studies the baseline case of merger incentives in the absence of international policy cooperation. A corresponding analysis with coordinated policy making is found in Section 4. Section 5 uses an endogenous merger model to predict which mergers will take place in the equilibrium market structure under different assumptions about the regulatory regime. Section 6 is devoted to social welfare issues. After asking what types of mergers are socially desirable under cooperative or non-cooperative policies, we turn to the question if international policy cooperation would be beneficial. Section 7 replaces the two-part taxation scheme with an assumption of ad valorem profit taxation, to investigate the robustness of the results. Section 8 concludes the paper.",3
10.0,3.0,"Journal of Industry, Competition and Trade",14 September 2010,https://link.springer.com/article/10.1007/s10842-010-0088-8,The Economics of Entrepreneurship Policy: Introduction to the Special Issue,September 2010,Werner Hölzl,,,Male,Unknown,Unknown,Male,"Many policy makers and experts consider entrepreneurship to be an important determinant of the long-run competitiveness of countries. However, entrepreneurship is not a well-defined concept in both research and policy. Sometimes a focus on entrepreneurship is considered synonymous with a focus on small and medium-sized enterprises (SME). In other contexts, the concept of entrepreneurship is limited to young enterprises and start-ups. Yet another approach understands the term in a Schumpeterian sense, limiting it to innovative pioneering enterprises. This issue of differing definitions of entrepreneurship cannot be reduced to the fact that entrepreneurship is studied within different disciplines. Much of the disagreement on the proper definition of entrepreneurship originates from the fact that that entrepreneurship is a multidimensional concept (Peneder 2009; Audretsch et al. 2007). Despite the fact that there is no common definition of the term, entrepreneurship is a key focal point of economic policy in many countries. Entrepreneurship policy has emerged as important element in the new industrial policy described by Bianchi and Labory (2006) and Aiginger (2007), which is characterized by a shift in emphasis from declining industries to more horizontal policy measures focusing on research and development, regions and the regulatory framework. This emphasis on ‘competitiveness’ and innovation in the economic policy discourse in Europe has led to a refocusing of industrial policy towards policies that favor the dynamic adjustment of industries to competitive challenges. Thus, in Europe entrepreneurship has emerged as an important focus of public policy in efforts to promote growth and generate employment. Many national and regional governments have implemented new programs and regulatory changes to foster entrepreneurial growth. These initiatives clearly show that entrepreneurship policy is not simply a modernized version of small business policy, but also oriented toward creating an economic environment that encourages entrepreneurial experimentation and firm growth. As a result, today entrepreneurship policy is often considered to be broadly based and horizontally oriented, encompassing many policy areas, such as traditional enterprise promotion, competition, technology, education and science. This broad definition serves to distinguish an entrepreneurship policy that is oriented toward firm growth from a more traditional SME policy focused on firm size (Lundström and Stevenson 2007; Autio and Hölzl 2008). Because of this broad approach to entrepreneurship policy, not all related important topics will be covered in this issue. The heterogeneity of the contributions mirrors both the scope of this policy field and the different approaches towards entrepreneurship as a concept. This introduction to the special issues of entrepreneurship policy is organized as follows: The next section discusses different policy approaches, with special attention given to the distinction between entrepreneurship policy and SME policy. Section 3 presents the papers and Section 4 concludes the paper by discussing the contribution of economics to the study of entrepreneurship policy.",12
10.0,3.0,"Journal of Industry, Competition and Trade",26 June 2010,https://link.springer.com/article/10.1007/s10842-010-0083-0,Subsidizing Start-Ups: Policy Targeting and Policy Effectiveness,September 2010,Sarah Kösters,,,Female,Unknown,Unknown,Female,"Entrepreneurship plays an increasingly prominent role in both academic and policy circles. It is regarded as the driving force behind structural change that links investments in knowledge with economic growth (Audretsch and Thurik 2001). The increased role of new and small enterprises has led to an increase in entrepreneurship policies aimed at encouraging more people to consider entrepreneurship as an option and act on a business idea (Lundström and Stevenson 2005). Especially in East Germany, which still lags behind West Germany in all economic performance indicators, policymakers pin their hopes on various policy instruments (Bundesregierung 2007). Although entrepreneurship policies focus on soft policy instruments like consulting services, the overall subsidy environment is dominated by soft loans, loan guarantees, and grants—offering start-ups an extensive choice of support (Thüringer Aufbaubank 2008). The policy focus on hard policy instruments is also reflected in the allocation of public funds. For example, although 5.3 million Euro were allocated to public initiatives offering consulting services to Thuringian business founders in 2005 and 2006, direct financial subsidies for business start-ups in Thuringia amounted to more than 104 million Euro during that same period (TMWTA 2007).Footnote 1
 Traditionally, policy intervention in favor of nascent and young entrepreneurs and their start-ups is justified by presumed market failure. First, positive externalities accruing from entrepreneurship create a disparity in the valuation of (potential) entrepreneurs by investors and policymakers (Audretsch et al. 2007). Whereas individual entrepreneurs and investors are only interested in single firm performance, policymakers should be more interested to allow for positive external effects. Second, policy intervention aims at remedying asymmetric information, which has been argued to restrict young and small firms’ access to capital and thus hinder entrepreneurial performance (van Praag et al. 2005). Start-ups differ in both their ex-ante characteristics, such as economic and environmental features, and by the individual characteristics of their founders and, therefore, capital constraints will also vary (Blumberg and Letterie 2008). Similarly, positive external effects do not accrue from every entrepreneurial project (Santarelli and Vivarelli 2007; Fritsch and Schroeter 2009). The identification of market failures that hamper the start-up and growth of otherwise efficient ventures is thus a necessary but not sufficient condition for effective and efficient policy intervention. When deciding on policy intervention, policymakers should be aware of the market distortions that can result from subsidization. Market distortions arise because policymakers and program officials do not have complete information which would allow to fund marginal projects. In the absence of complete information, public support schemes give subsidized start-ups an artificial competitive edge that could lead to their substitution for other start-ups or incumbents that are ex-ante more efficient but nonsubsidized. In general, the distortions arising from substitution effects are larger than those resulting from deadweight losses: not only is public money spent ineffectively, but the subsidy enables the subsidized start-up to crowd out a potentially more efficient firm (Santarelli and Vivarelli 2007). The start-up subsidy environment is diverse. Various subsidization policies coexist, leading to a broad range of support schemes administered by a similarly broad range of agencies (TMWTA 2007). In this study, I do not examine a specific scheme but take an aggregate view of the receipt of any kind of financial subsidy within the first three business years of a start-up. I use data from 162 start-ups in innovative industries in the East German state of Thuringia.Footnote 2 More than 45% of these start-ups make use of financial subsidies which are primarily given as soft loans, loan guarantees, or grants. A broad set of ex-ante characteristics allows me to analyze the allocation of subsidies. Does the allocation of subsidies provide evidence of policy geared toward positive external effects? Or is the policy instead focused on remedying capital market imperfections? The answer to both questions turns out to be “no”. Logistic regressions reveal that the allocation of subsidies is neither based on the rationale of positive external effects nor on subsidies’ potential to cure capital market imperfections. Instead, the rather random subsidization reveals likely substitution effects. Moreover, I apply propensity score matching to identify the causal effect of subsidization and find neither a significant effect of subsidies on business survival nor on employment growth. The matching results suggest that subsidized start-ups would have survived and thrived in any case and thus indicate deadweight losses. These findings highlight the relevance of information and incentive problems when designing and allocating start-up subsidies, since policy targeting affects potential market distortions and policy effectiveness. The remainder of the article is structured as follows. The next section contains a review of the literature that examines the market failure argument to justify start-up subsidies. Ex-ante characteristics of start-ups that are most likely to be affected by market failure are derived and the market distortions resulting from policy intervention are discussed. In the empirical analysis (Section 3), a logistic regression first investigates the characteristics of subsidized start-ups. Second, I employ propensity score matching to examine the effectiveness of financial subsidies in the survival and growth of start-ups. Section 4 concludes.",17
10.0,3.0,"Journal of Industry, Competition and Trade",26 June 2010,https://link.springer.com/article/10.1007/s10842-010-0080-3,Phasing Out an Inefficient Venture Capital Tax Credit,September 2010,Douglas Cumming,Sofia Johan,,Male,Female,Unknown,Mix,,
10.0,3.0,"Journal of Industry, Competition and Trade",25 June 2010,https://link.springer.com/article/10.1007/s10842-010-0079-9,Alternative Investment Market: A Way to Promote Entrepreneurship,September 2010,Alessandra Colombelli,,,Female,Unknown,Unknown,Female,"A wide body of literature has analysed the entrepreneurial behaviour at the individual level. The entrepreneurial activity has been associated with the manifest ability and willingness of individuals to perceive and create new economic opportunities and to introduce their ideas in the market (Wennekers and Thurik 1999). Empirical works have focused on the main attributes of the entrepreneur trying to relate common traits of the individual with firm performance. More recently, a strand of literature has shifted the attention to the entrepreneurial behaviour at the organizational level. A firm level model of entrepreneurship seems to be more appropriate as entrepreneurial effectiveness is arguably a firm-level phenomenon that involves the whole organization and goes beyond the abilities of an individual. In order to account for entrepreneurship at the level of organizations the concept of Entrepreneurial Orientation (EO) has been theoretically developed and empirically tested. This concept refers to methods, practices, behaviours and strategies managers adopt to act entrepreneurially. Three main dimensions have been used for characterising and describing companies’ entrepreneurial orientation at both the theoretical and empirical level, i.e. risk taking, innovation and proactivity (Miller 1983; Covin and Slevin 1991; Lumpkin and Dess 1996). One of the main objectives of the literature on this topic has been the understanding of the relationship between entrepreneurial orientation and firm performance. At the theoretical level, Covin and Slevin (1991) and Lumpkin and Dess (1996) developed conceptual models accounting for the firm entrepreneurial behaviour and highlighted a variety of factors, such as external environment, organizational structure, corporate culture and strategy, which may affect firm performance. Following this theoretical framework, scholars have attempted to give empirical evidence to the entrepreneurial orientation effect on firm performance, mainly measured in terms of sales growth (Wiklund 1999; Lumpkin and Dess 2001; Wiklund and Shepherd 2005; Walter et al. 2006; Covin et al. 2006; Keh et al. 2007) but also as employment growth (Wiklund 1999; Walter et al. 2006; Wiklund and Shepherd 2005) and firm profitability (Becherer and Maurer 1997; Lumpkin and Dess 2001; Walter et al. 2006; Wiklund and Shepherd 2005; Keh et al. 2007). However, the literature still has to consider the effects of entrepreneurial orientation on market performances. In our work we extend the literature by investigating the relationship between entrepreneurial orientation and firm market performance in a peculiar entrepreneurial setting, i. e. an initial public offering (IPO) on the junior segment of the London Stock Exchange. By focusing on companies listed on the Alternative Investment Market (AIM), in our work we want to test whether more entrepreneurial oriented firms show better market performances signalling that investors valuate it positively. Our research may contribute to the literature in several ways. First, although empirical evidence has shown that the relationship between entrepreneurial orientation and performance is not always positive but it varies for different types of business, the general belief is that firms benefit from an entrepreneurial behaviour. On the one hand, this may lead managers to act entrepreneurially in order to increase firm performances. On the other hand, investors may evaluate positively a firm showing an entrepreneurial orientation in the expectation of high returns. For this reason in this paper we want to verify if investors give value to the entrepreneurial orientation of companies in the prospect of high returns. Secondly, the literature has shown that the relationship between entrepreneurial orientation and firm performance is moderate by both external and internal factors. In particular, many studies have postulated that this relationship is particularly strong in hostile and technologically sophisticated environments (Naman and Slevin 1993; Covin and Slevin 1998). Hence, a growing interest has been devoted to companies operating in unique settings such as small businesses (Wiklund and Shepherd 2005; Keh et al. 2007) and university spin-offs (Walter et al. 2006). In this work we extend this stream of research by focusing on IPO companies which therefore operate in a peculiar environment, characterised by high level of uncertainty. Actually, a firm undertaking an IPO and entering the arena of public offerings faces new challenges and pressures, such as the acceptance and monitoring activities from a new variety of stakeholders. Moreover, our study may also contribute to the literature by using alternative indicators to proxy for the firms’ entrepreneurial orientation as we can rely on IPO prospectuses as a source of data. In order to operationalise entrepreneurial orientation and test the conceptual framework of entrepreneurial orientation, empirical researches have adopted mainly three approaches: managerial perceptions, firm behaviours and resource allocations (see Lyon et al. 2000 for an extensive review). The first one is the most widely used and requires interviews or surveys so as to measure entrepreneurial orientation as management perceptions. The second approach, firm behaviours, is focused on competitive actions of companies and involves the content analysis of published news. The third one examines resource allocations to operationalise strategy concepts and can be ascribed to Gale (1972) and Miller and Friesen (1978). The main source of data is company’s financial statements. To our purposes the latter approach seems to be the most appropriate. Yet, we are aware that it has pros and cons. On the one hand, an advantage is that measures are standardised and can be compared across time and firms. Furthermore they are easy to confirm. On the other hand, a drawback can be that resource allocation measures may not accurately reflect firm activities and are not suitable for in-depth analysis on managerial practices and strategies. However we can complement these data with information contained in the IPO prospectus which, accordingly, is the primary source of data for our study. This important document gives detailed information about the firm such as the operating history, firm products and ownership structure. Additionally, it includes biographical information regarding the founder, CEO and the firm executive management. The reminder of our paper proceeds as follows. In sections two and three we discuss the theoretical framework and hypothesis. The sample, measures and the econometric model are then presented in the methodological section. Section five describes the results of our analyses. Finally, in the concluding section we discuss our findings, their limitations and policy implications.",13
10.0,3.0,"Journal of Industry, Competition and Trade",19 June 2010,https://link.springer.com/article/10.1007/s10842-010-0081-2,"Taxation, Labor Market Policy and High-Impact Entrepreneurship",September 2010,Magnus Henrekson,Dan Johansson,Mikael Stenkula,Male,Male,Male,Male,"Enterprises exhibit great differences in age, size, industry affiliation, growth ambitions and growth performance. It is well documented that young and small firms contribute disproportionately to net employment and productivity growth (see van Praag and Versloot 2008 for a survey). Meanwhile, most firms grow very slowly, or not at all. Zook and Allen (1999) report that only one in seven companies achieves sustained growth while remaining profitable. Accordingly, some observers point to a small number of rapidly growing firms that contribute a disproportionately large share of net job creation and economic growth (see, e.g., Birch and Medoff 1994; Storey 1994; Schreyer 2000; Acs et al. 2008; and the survey by Henrekson and Johansson 2010). The fact that a small share of all firms plays such a disproportionate role in the economy motivates our emphasis on what Zoltan Acs (2008) has named high-impact entrepreneurship (HIE). Entrepreneurial firms with an exceptional growth trajectory are sometimes termed high-growth firms (HGFs) or “gazelles” as well. (We will use the terms HIE and HGF interchangeably throughout the article.) High-impact entrepreneurial activities commercialize key innovations or create disruptive breakthroughs, extract substantial entrepreneurial rents, spur growth (in both the firm and the economy) and employment, and shift the production possibility frontier outwards. In short, HIE significantly influences the economy. Yet a typical start-up is not characterized by HIE, and HIE is not necessarily performed within new (or small) companies.Footnote 1
 Policy discussions should take note of these facts. Rather than targeting small firms to compensate for their inherent disadvantages—a motivation for many policies in the recent past—focus should be directed towards providing a framework for fostering a dynamic economy conducive to HIE. What bundle of policies ensures that people can start new ventures, develop these ventures into high-impact firms, and expand existing ventures to their full potential?Footnote 2
 The journal article format does not permit an exhaustive treatment of all pertinent policies. Instead we will focus on two policy areas of crucial importance, namely tax policy and polices pertaining to the functioning of labor markets. Other areas, such as private property rights, the functioning of financial markets and the regulation of product markets, are important but will not be dealt with here. Yet the entrepreneur is not the only agent that is of consequence for economic progress. Successful entrepreneurs who identify and exploit new ideas—thereby creating and expanding businesses—depend on a number of complementary agents, such as skilled labor, industrialists, venture capitalists and secondary markets. One should keep in mind that HIE becomes impossible without these complementary competencies and inputs. Focusing solely on entrepreneurship abstracts from other factors necessary for an economy to prosper. Still, entrepreneurship is crucial; a lack of entrepreneurs cannot be fully offset by an ample supply of skilled labor or an extensive capital market.",26
10.0,3.0,"Journal of Industry, Competition and Trade",08 July 2010,https://link.springer.com/article/10.1007/s10842-010-0085-y,Effective Corporate Tax Rates and the Size Distribution of Firms,September 2010,Almas Heshmati,Dan Johansson,Carl Magnus Bjuggren,Male,Male,Male,Male,"The corporate tax affects the expected return after tax on investments and therefore shapes the incentives of entrepreneurs to establish and run enterprises. Tax systems include deductions and loopholes which make the statutory corporate tax rates differ from the effective corporate tax rates. In all their complexity, tax systems may introduce distortions concerning firm size, for instance because small firms are short of organizational and financial resources to take full advantage of incentives and loopholes. In that case, they may affect the selection of firms and, thereby, the evolution of the size distribution of firms over time. The societal costs for such a policy may be profound, since three decades of empirical research has established the importance of small firms for employment and economic growth; see, for instance, Birch (1979, 1987, 2006), Kirchhoff (1994), Storey (1994), Acs (1996, 1999), Robbins et al. (2000), Audretsch (2002), and van Praag and Versloot (2007). The literature on the effects of corporate taxation on investment and entrepreneurship is vast; see, e.g., Jorgenson (1963), Hall and Jorgenson (1967), Auerbach and Hasset (1992), Cummins et al. (1996), Hasset and Hubbard (2002), Cullen and Gordon (2007), Djankov et al. (2008), and Cerda and Larrain (2010). However, there is little discussion on the effect of corporate taxation on the size distribution of firms.Footnote 1 The purpose of this essay, hence, is to analyse these effects. By using a unique data set covering aggregate balance sheets and income statements for firms in different size classes and industries, we are able to improve the analysis on the effects of effective corporate taxation on the size distribution of firms in three ways not previously done. Firstly, the data allow us to calculate effective corporate tax rates for firms in different size classes in the whole economy. Secondly, the analysis is implemented on a long time period, three decades. Thirdly, the data enable us to analyse the effects of effective corporate tax rates on the size distribution of firms econometrically. The data concern Sweden and cover all industries and size classes for the period 1973–2002. We regard the uniqueness of data—the existence of interesting variables, the long time period available and the wide coverage—being of general interest as an analysis of tax-based economic policy. In modelling the relationships between effective corporate tax rates and the size distribution of firms we account for conditional variables as well as unobservable time and industry effects. A number of hypotheses are tested concerning heterogeneity in the impact of corporate taxes on the size distribution of firms across different size classes, industries and over time. During the studied period the corporate taxation in Sweden was altered a number of times with possible great impact on the expected survival and performance of firms. Particular attention is directed towards the differences in responsiveness of small and large firms to tax policy changes. Our study relates to a broader literature studying the effects of institutions—defined as “the rules of the game in society” in North (1990, p. 3)—on entrepreneurship; see Baumol (1990, 2004), Davidsson and Henrekson (2002), Djankov et al. (2002); Björnskov and Foss (2006), Nyström (2008), and Boettke and Coyne (2009) for recent examples. The study is organized as follows. In the next section we present the development of the corporate tax system in Sweden. The data are introduced in Section 3 followed by the empirical model. Its specification and estimation are outlined in the same section. The empirical results are presented in Section 4 followed by a summary in Section 5.",9
10.0,3.0,"Journal of Industry, Competition and Trade",24 July 2010,https://link.springer.com/article/10.1007/s10842-010-0086-x,Varieties of Capitalism and the Limits of Entrepreneurship Policy: Institutional Reform in Germany’s Coordinated Market Economy,September 2010,Alexander Ebner,,,Male,Unknown,Unknown,Male,"The notion of entrepreneurship policy has become a key motive in policy-related discourses on institutional reforms all over the OECD world. The underlying tendency of perceiving entrepreneurship as a key factor in the promotion of innovation, employment and economic growth is closely related with debates on the comparative institutional advantages of diverse national models of capitalist development. A most influential conceptualization in this regard is the ‘Varieties of Capitalism’ approach, which differentiates liberal market economies like the United States dominated by market coordination and coordinated market economies like Germany, whose coordination mechanisms leave considerably more space for nonmarket schemes. Coordinated market economies are said to specialize in incremental innovations carried out by large enterprises. Liberal market economies are said to exhibit advantages in radical innovations, which is due to their flexible institutional setting that is conducive to entrepreneurial start-up activities. This competitive advantage of the liberal type informs market-oriented reforms in coordinated market economies. Entrepreneurship policy is usually addressed as a centrepiece of these efforts. Viewed in this setting, the case of Germany provides further insights on the prospects of these efforts. It gives evidence for the fact that the systemic character of entrepreneurial activity and its embedding institutional environment need to be adequately reflected in the design of entrepreneurship policy. Varieties of capitalism come together with varieties of entrepreneurship. Entrepreneurship policy thus needs to be sensitive to the specificities of historically rooted varieties of capitalism with their complex institutional set-up. The following presentation proceeds as follows. The first section sketches a conceptual framework for assessing the rationale of entrepreneurship policy. As the entrepreneurial operations within an economy are embedded in a distinct socio-economic order, so is the articulation of entrepreneurship shaped by institutional complementarities that specify the corresponding varieties of capitalism and their complementary sub-systems, involving the particular systems of innovation. The second section surveys the institutional determinants of Germany’s social market economy, addressing key complementarities that are subject to ongoing efforts of institutional reform. This leads to an exploration of the ongoing hybridisation of the German variety of capitalism. The third section highlights the matter of entrepreneurship in the context of the German innovation system, which is viewed as a most relevant subsystem of the German variety of capitalism. Its institutional peculiarities are at the root of further concerns with the foreseeable prospects and limits of entrepreneurship policy in Germany.",17
10.0,3.0,"Journal of Industry, Competition and Trade",13 April 2010,https://link.springer.com/article/10.1007/s10842-010-0072-3,Productivity of Czech Small and Medium Enterprises: Lagging Behind Their Potential,September 2010,Jan Průša,,,Male,Unknown,Unknown,Male,"The term small and medium enterprises (SME) has recently gained more attention in general media, eventually reflecting the key contribution of SME to a healthy economy. In the Czech Republic however, where small entrepreneurs had to build from scratch after 1989, research in this field has remained largely untouched. Our paper aims to partly fill this gap, in that it captures main characteristics of the production function of SME. We can regard small and medium businesses from two points of view: static and dynamic. Firstly, we look at their structural position in the economy. Although general public better knows giant brands, the SME matter because they form an economy’s fundamentals. They can be compared to ants, who impact little individually but hugely altogether. Small entrepreneurs build the economy from the bottom, so that they are the true discoverers of market niches that call for filling. Besides their economic impact on the creation of value (GDP), they play a key social role as well. Although many of them start as self-employed, later on as they grow they eventually become important local or national employers. Usually SME lack sufficient sources of capital and rely on more labour intensive production processes, or even they concentrate in industries which are inherently labour intensive. This biases their productivity in terms of value added per employee towards worse ranking (which can be misleading), yet it leads to their prominent position as dynamic and flexible job creators. It follows from Table 1 that in modern market economies, SME employ between one half to three quarters of the workforce in manufacturing. It is true that the breakdown point at 250 employees (or any other number) is artificial, nonetheless it becomes apparent that size of businesses matters—not least to people employed there.Footnote 1
 These figures clearly illustrate the interest of SME for economists. In the rest of our paper, we first present several characteristics of the SME sector. It is clear that there are economies to scale and also its resources need not be allocated in an optimal structure. Section 3 outlines the methodology used to estimate the production function and efficiency of SME: stochastic frontier analysis (SFA). The results are presented in Section 4. Estimating the production function on the macroeconomic level is a common econometric exercise, and appeared in several papers on the Czech economy. To name just one example: Hájek (2005) tracked the determinants of economic growth given by the model of Solow. Yet our approach differs significantly from that of Hájek and similar studies, since we are deriving the model from microeconomics and use the enterprise data. By plugging in data aggregated into industries, the model of course shifts towards macroeconomics, but we will argue that this is both a reasonable and necessary simplification.",1
10.0,3.0,"Journal of Industry, Competition and Trade",26 February 2010,https://link.springer.com/article/10.1007/s10842-010-0069-y,External Economies of Scale and Insufficient Entry,September 2010,Arijit Mukherjee,,,Unknown,Unknown,Unknown,Unknown,,
10.0,3.0,"Journal of Industry, Competition and Trade",18 June 2010,https://link.springer.com/article/10.1007/s10842-010-0078-x,Opening Local Retail Food Stores: A Real-Options Approach,September 2010,Sven-Olov Daunfeldt,Matilda Orth,Niklas Rudholm,Unknown,Female,Male,Mix,,
10.0,3.0,"Journal of Industry, Competition and Trade",09 March 2010,https://link.springer.com/article/10.1007/s10842-010-0071-4,The Exponential Age Distribution and the Pareto Firm Size Distribution,September 2010,Alex Coad,,,Male,Unknown,Unknown,Male,"Early models of industrial dynamics focused on firms above a certain size threshold, because data on larger firms was easier to obtain. These studies generally observed a lognormal size distribution, that can be explained by a Gibrat process (Gibrat 1931; Hart and Prais 1956; Simon and Bonini 1958). More recently, research has shown that firm size distributions can be approximated by a power law (see for example Ramsden and Kiss-Haypal 2000; Gaffeo et al. 2003). In particular, work that takes young, small firms into account observes a Zipf distribution of firm size (Axtell (2001), for surveys see de Wit (2005) and Coad (2009, Chapter 2)). The explanation suggested by Axtell (2001) consists of a Kesten process in which firm sizes are bounded from below (Kesten 1973). The combination of a Gibrat random growth model and lower bounds on firm sizes is seen to produce the Zipf distribution (which is a special case of the Pareto distribution, or power law distribution). A drawback of this mechanism, however, is that firms are implicitly assumed to all be of the same age, which is of course quite unrealistic. In addition, the introduction of a lower bound on firm size, a condition which is crucial for the emergence of the Pareto firm size distribution, seems to lack any strong economic justification, and thus we argue that it is slightly artificial. Steindl (1965) develops a model of the Pareto firm size distribution, focusing first on processes of firm entry and exit, before going on to derive the age distribution of firms. This age distribution of firms is then combined with an expression for firm size distribution, to yield a Pareto distribution with coefficient near unity (see in particular Steindl 1965, pp. 50–55). The difference between Steindl’s model and ours is that we take the (exponential) age distribution as a starting point, and present a simpler, more transparent mathematical model that also yields a Pareto distribution. In our model, we begin with a Gibrat-type process, but we relax the restrictions that firms are all of the same age and that they face a lower bound to firm size. We present the empirical firm age distribution and show that an exponential distribution appears to be a reasonable heuristic. Mixing these two distributions (Gibrat process for incumbents and an exponential distribution of firm age) yields the observed power law distribution (Huberman and Adamic 1999; Reed 2001). The novelty of this paper is the application of the mathematical model to firm age and growth, and the resultant firm size distribution. The basic mathematical model we employ (i.e. integrating a lognormal distribution over an exponential distribution) was already applied by Adamic and Huberman to explain the number of web pages on internet websites (Huberman and Adamic 1999; Adamic and Huberman 1999). Later on, Reed (2001) discusses the same model and briefly describes how the model can be applied to power law distributions in economics—in particular the prices of stock returns, the income distribution, and the city size distribution. In this paper, we present new empirical evidence on the firm age distribution, and explicitly combine the age distribution with the Gibrat model of firm growth to arrive at the firm size distribution.Footnote 1
 The empirical age distribution of firms is considered in Section 2, and then we present our model, in which an exponential age distribution is combined with a Gibrat growth process to obtain the Pareto firm size distribution (Section 3). The model is discussed in Section 4.",37
11.0,1.0,"Journal of Industry, Competition and Trade",07 May 2010,https://link.springer.com/article/10.1007/s10842-010-0074-1,Public Subsidies to Business: An International Comparison,March 2011,Pierre-André Buigues,Khalid Sekkat,,Unknown,Male,Unknown,Male,"This article revisits the role of public subsidies in supporting business in a comparative perspective. It draws on recent development in the theoretical and empirical literature and on the experience of various OECD countries. Although the current financial crisis threatens the global economy and pushes many countries to use State Aids to help firms, this paper refers to the more normal times before then. Over the past half century the mainstream view of public support to business, also called industrial policy, has varied markedly. From the early 1950s to the early 1970s industrial policy was seen as panacea to growth and development problems. The apparent success of some East Asian economies has supported for a long time the conviction of those who were in favor of such policy. By the early-1980s, however, such conviction started being challenged. Evidence was provided to show that industrial policy might lead to misallocation of resources, not improve long-run growth and give rise to rent seeking. A number of countries initiated a dramatic reversal of their strategy toward supporting business. Since the beginning of the 1990, new economic theories (e.g. endogenous growth, economic geography and strategic trade theory) have been developed and tested showing that public support to business should take an intermediate position between the two extremes. State planning and intervention cannot act as the main driving force of economic development. At the same time, public action could combine with private initiative to foster restructuring, diversification, and technological dynamism. Empirical analyses report both cases of successful and failing government intervention. The outcome seems to depend on the issue the government seeks to address, the policy instrument used and the way this is implemented. The mainstream rationale for public interventions principally lies in the necessity to offset some market failures (efficiency objective) and correct for social inequalities (equity objective). These failures can take the form of imperfect competition, technological, information, coordination and other externalities. Public intervention is therefore justified if the Government is able to improve upon market outcome. However, as notes Rodrik (2006) there are two fundamental arguments that cast doubts on bureaucrats’ capacity to correct market failures. These include information issues and incentives. The first refers to the fact that governments might not be able to substitute for the decentralized information processing that markets, in general, can achieve. The secondly relates to elections, lobbying (and capture) and corruption (and favoritism). Thus, the fear of market failures must be balanced with the risks of government failures. The rest of the article is divided into 2 main parts. The first part assesses the well founding of public subsidies to business by examining situations of both success and failure. The second part conducts an international comparison of incidence, objectives and implementation of public support. Since the definition and measure of subsidies vary across institutions, cross-countries comparison is not an easy task. Therefore, the second starts with a discussion of this issue in order to clarify and motivate the comparison. Then, the quantitative importance of subsidies and their components across various OECD countries is examined. Subsequently, the importance of the approaches to implementing support for success and failure is discussed drawing on the book by Buigues and Sekkat (2009). It appears that the way according to which the support is implemented counts as much as the amounts of the support.",16
11.0,1.0,"Journal of Industry, Competition and Trade",23 October 2009,https://link.springer.com/article/10.1007/s10842-009-0061-6,Subsidizing Away Exports? A Note on R&D-policy Towards Multinational Firms,March 2011,Pehr-Johan Norbäck,,,Unknown,Unknown,Unknown,Unknown,,
11.0,1.0,"Journal of Industry, Competition and Trade",19 January 2010,https://link.springer.com/article/10.1007/s10842-009-0066-1,Compatibility Under Differentiated Duopoly with Network Externalities,March 2011,Ho-Chyuan Chen,Chien-Chen Chen,,Unknown,Unknown,Unknown,Unknown,,
11.0,1.0,"Journal of Industry, Competition and Trade",22 December 2009,https://link.springer.com/article/10.1007/s10842-009-0062-5,A Note on the Desirability of Merger among Complements,March 2011,Masayoshi Maruyama,Kazumitsu Minamikawa,Yusuke Zennyo,Male,Male,Male,Male,"Several complementary goods and services are used in combination as a system. For example, recent computer based systems such as the hardware and the software of personal computers, the digital content and network services of digital music (iPod-iTunes), mobile-phone services with i-mode, and even more generally, the products themselves and the distribution service provided by retailers. Recently, much interest of academics and policy makers has been given to the problem of which market structure of complementary goods (e.g. network goods) benefits firms and consumers most. As far as pricing is concerned, it is well-known that joint ownership of complementary components have beneficial effects for firms and consumers. This is due to the resolution of double marginalization, or the externality of pricing decision among independent firms.Footnote 1 In addition to pricing, coordinating the choice of quality of each component is an important problem for system goods. Economides (1999) provided an analysis of pricing and quality choice of complementary components, and established the interesting results that a complementary merger provides products of higher quality, and achieves higher market coverage, higher consumer surplus, and higher profits than independent ownership. His model assumes that (1) the quality of a system product is determined by the minimum quality level of its components, (2) the net utility of consumers is specified a la Mussa and Rosen (1978), and (3) the distribution of consumer types is not explicitly specified. We reexamine the pricing and quality choice of firms producing complementary components. We discuss general quality function, utility function, and distribution function of consumers, and we show that the desirability of merger among complements in a considerably generalized model. The rest of this paper is organized as follows. Section 2 formulates the model and gives key assumptions. Section 3 analyses market structures of integrated monopoly and complementary monopolies. Section 4 presents our results. Section 5 specifies the key assumption for our main result and concludes the paper.",2
11.0,1.0,"Journal of Industry, Competition and Trade",16 March 2010,https://link.springer.com/article/10.1007/s10842-010-0070-5,Robust Event Studies for Derogation from Suspension of Concentrations in Greece during the Period 1995–2008,March 2011,Panagiotis N. Fotis,Michael L. Polemis,Nikolaos E. Zevgolis,Male,Male,Male,Male,"Within the last years there is a substantial body of literature investigating the extent of profitability of concentrations in the market. In these studies there is a wide diversification concerning one or more of the following aspects: a) the country under scrutiny, b) the “nature” of the concentration (i.e tender offer, merger and acquisition), c) the time frequency of the period of the data used and d) the methodology employed in the empirical investigation. On the one hand, many of the studies explore the effect of the announcement of merger and acquisition (M&A) aiming at shareholder value both in the target and the bidder firms. On the other hand, other studies analyse the competitive effects of M&As’ announcements, while many of the event studies may also be used to analyze the effect of antitrust enforcement agencies on the stock value of merging parties.Footnote 1
 The main scope of this paper is twofold: on the one hand, we calculate the sign of the effect of merger announcement on merged firms’ value and on the other hand, we examine whether requested derogations from suspension of concentrations that have been notified in General Directorate of Hellenic Competition Commission during the period 1995–2008 produced positive stock value of the firms that make the request. Despite its crucial importance, this analysis has not yet been prepared for Greece. However, this study is prototype and important besides Greece since, to the best of authors’ knowledge the effect of requested derogations from suspension of concentrations on firms’ stock value, has not been analyzed. In addition, even though Greece is a small country, it constitutes a member of the European Union and a study focusing on Greek merger policy (at least a part of it) is always interesting for other member countries as well. Therefore, the application of event study methodology focusing on investigating the effect on requested derogations from suspension of concentrations tries to make the contribution in the paper more significant and novel. Besides, an understanding of the Greek experience will be useful for other European countries that pursue M&As’. The remainder of the paper is organized as follows. Section 2 provides an analytical description of the legal framework prevailing in the Hellenic Competition Act, while Section 3 tries to encapsulate the substantial body of literature concerning the event study methodology. The next section describes the empirical tools employed in the research methodology of this paper. Using the results from the three alternative empirical models, in Section 5 the case of the derogation from suspension of concentrations is investigated with reference to basic elements of the event study methodology. Along to this analysis, there is a critical discussion over key relationships that may link the application and the robustness of the different methodological tools embodied in the paper. Finally, Section 6 depicts the main findings of our analysis presented together with a few policy propositions.",9
11.0,1.0,"Journal of Industry, Competition and Trade",08 January 2010,https://link.springer.com/article/10.1007/s10842-009-0065-2,Good Governance and Growth in Developing Countries: A Case Study of Regulatory Reforms in the Telecommunications Industry,March 2011,Anne-Marie Mohammed,Eric Strobl,,Female,Male,Unknown,Mix,,
11.0,2.0,"Journal of Industry, Competition and Trade",19 December 2009,https://link.springer.com/article/10.1007/s10842-009-0064-3,The Diffusion of a Process Innovation with Gently Declining Production Cost,June 2011,Qiangbing Chen,Yali Liu,,Unknown,Unknown,Unknown,Unknown,,
11.0,2.0,"Journal of Industry, Competition and Trade",02 March 2010,https://link.springer.com/article/10.1007/s10842-010-0068-z,Outsourcing and Competition Policy,June 2011,Cosimo Beverelli,Kornel Mahlstein,,Male,Male,Unknown,Male,"The objective of this paper is to analyze optimal competition policy when firms delocalize production of intermediate inputs abroad. We use a simple model of offshore outsourcing between final good producers from a nation that we call the ‘North’ and input suppliers from a nation that we call the ‘South’.Footnote 1
 Over the last twenty years outsourcing has become increasingly important. Yeats (2001) finds that trade in intermediates accounts for approximately 30% of total trade in the US. He also notices that this figure may be significantly larger for developing countries, as they have progressively become the focus of outsourcing from developed countries. Hanson et al. (2005) show how foreign outsourcing by US firms has grown at paces exceeding the growth of intra-firm trade within the same firms. As economic integration and global production shifting have processed, policy makers and scholars have recognized the possible links (and conflicts) between trade and competition policy. This paper contributes to this ongoing debate. Our starting point is the observation that offshoring is related to cost savings.Footnote 2 In a less than perfectly competitive market, due to its cost-saving nature, offshoring will be associated with rents. We study how these rents can be appropriated through an active competition policy. We assume throughout the paper an oligopolistic market structure, where firms engage in quantity competition, and a Competition Authority (CA) that optimally sets the number of firms by maximizing domestic welfare. The paper is broadly divided in two parts. The first analyzes the case where the final good—which is just a relabeling of the intermediate input—is only consumed in the North. This could be thought of as the initial stage of a development process whereby Southern consumers progressively acquire purchasing power. When, due to an exogenous reduction in trade costs, outsourcing becomes viable for Northern vertically integrated producers, outsourcing rents are created. If there is free entry on the input market (South), these rents accrue to Northern firms. In the presence of a Competition Authority in the South, with a similar institutional role as its Northern homologue, the Southern CA will entirely appropriate outsourcing rents, making Northern firms indifferent between outsourcing and vertical integration and leaving the problem of the Northern CA unchanged. However, rent-shifting is not Pareto efficient. From a global welfare perspective, free entry in the South would be optimal (we assume no fixed costs for Southern firms). Since the Southern CA has no interest in consumer protection, from an institutional perspective the optimal outcome can only be achieved if we allow for monetary transfers from the North to the South. The second part deals with a scenario where consumers are more evenly distributed geographically—which can be thought of as a more advanced stage of development. If the share of Southern consumers in world consumption is high enough, protecting consumer surplus becomes more attractive for the Southern CA, and the interaction between Competition Agencies assumes the traits of a standard Prisoner’s Dilemma: both would prefer mutual cooperation (defined as free entry in the absence of fixed costs) to mutual defection (defined as the optimal unilateral setting of competition policy), but there is a unilateral incentive to defect that leads to a Pareto-inefficient Nash equilibrium. From an institutional perspective, the optimal outcome can be achieved through an agreement between Competition Agencies that makes mutual cooperation more attractive than unilateral defection.",5
11.0,2.0,"Journal of Industry, Competition and Trade",28 January 2010,https://link.springer.com/article/10.1007/s10842-010-0067-0,Vertical Intra-Industry Trade and Product Fragmentation in the Auto-Parts Industry,June 2011,Kemal Türkcan,,,Male,Unknown,Unknown,Male,"A distinguishing feature of present economic globalization is fragmentation of production.Footnote 1 As world markets have become increasingly integrated in the last few decades due to developments in transportation and communication technologies, the degree of product fragmentation (i.e. production sharing) has increased across countries, leading to an increase in trade in intermediate goods as goods are designed, produced and assembled in different locations. Despite the increase in the intermediate goods trade, the empirical literature on this fragmentation has provided only descriptive statistics on the importance of the trade in intermediate goods induced by international fragmentation of the production process (Feenstra 1998; Hummels et al. 1999; Yeats 2001; Kimura and Ando 2005; Kaminski and Ng 2005; Ando 2006). In contrast, with the exception of Görg (2000), Jones et al. (2005), Egger and Egger (2005), and Kimura et al. (2007), there have been few empirical studies into the shortcomings of fragmentation. One of the empirical problems in these studies has been how to measure the degree of fragmentation. Lloyd (2004) argues that vertical product differentiation can take place because of product stage separation. Ando (2006) argues that vertical intra-industry trade (IIT) in intermediate goods, resulting from production sharing activities seems to be best way to see the extent of fragmentation for a particular industry.Footnote 2 Hence, following Ando (2006), the goal of this paper is to calculate the indices of vertical IIT in the auto industry between Austria and its 29 trading partners, and to analyze the determinants of vertical IIT, which is used in this study as a proxy for the extent of fragmentation.Footnote 3
 The Austrian auto-parts industry is chosen for several reasons. First of all, the auto industry is often regarded as one of the most fragmented industries. Due to this fragmentation, Austria’s export and import levels of auto-parts have been continually increasing. The nominal value of auto-parts imported into Austria more than doubled from $ 5.3 billion in 1996 to $ 12.7 billion in 2006 (Fig. 1c). Likewise, Austria’s auto-parts exports increased significantly from $ 5.3 billion in 1996 to $ 12.9 billion in 2006. This increase in trade in auto-parts implies that IIT has become more prevalent in this sector in Austria.Footnote 4 Second, Austria is ranked amongst the world’s top twenty in terms of auto-parts exports and imports.Footnote 5 Historically, Austria is known as a supplier of auto-parts, largely due to the fact that more than 10 automobile production facilities, including BMW, Skoda, Volkswagen, Audi, Fiat, Renault, and Hyundai Kia,Footnote 6 are located close to the Austrian border. The auto industry is also the most important manufacturing and export sector for Austria, representing 5.3% of Austria’s total manufacturing, 10.3% of total Austrian manufacturing exports and 9.9% of total Austrian manufacturing imports,Footnote 7 as can be seen in Table 10.
 Austria’s auto industry trade with the world, 1996–2006. Source: Authors’ own calculations Finally, major structural changes have taken place in the Austrian auto industry brought about by the accession of the Central and Eastern economies into the European Union (EU). This may impact on the pattern and determinants of the Austrian auto-parts tradeFootnote 8 and, given its crucial importance to the Austrian economy, this is an appropriate case with which to study fragmentation. Using finely disaggregated international trade data, this paper examines the recent changes in trade patterns in the auto-parts industry in Austria, particularly by breaking down the figures into inter-industry trade, vertical IIT and horizontal IIT. As there has been no previous study which has investigated the Austrian experience in this strategically important industry, this paper seeks to fill the void. Vertical IIT was used as an indicator of fragmentation between Austria and its 29 trading partners for the period 1996 to 2006. In particular, various country-specific factors suggested by the fragmentation literature initiated by Jones and Kierzkowski (1990) were tested by utilizing newly developed panel data techniques.Footnote 9 This study, unlike previous literature, is able to provide valuable information about the structure and determinants of vertical IIT as an indicator of the fragmentation process in the Austrian auto-parts industry. The major findings can be summarized as follows. Vertical IIT dominated trade flows in auto-parts during the period 1996–2006, and hypotheses drawn from the fragmentation literature help to explain vertical IIT, with the findings suggesting in particular that the extent of Austria’s vertical IIT in auto-parts is positively correlated with average market size, differences in per capita GDP, and outward foreign direct investment (FDI), while it is negatively correlated with distance. These findings support the claim that IIT in the Austrian trade in auto-parts is mainly a case of international fragmentation of vertical production chains. This paper is organized as follows: Section 2 offers a brief explanation of developments in Austria’s auto industry trade. Section 3 surveys empirical methodologies on the measurement of fragmentation, outlines the methodology for the measurement of IIT, as well as analyzing the patterns of IIT in the Austrian auto industry. Section 4 presents the economic model and the determinants of vertical IIT, while also addressing the key issue of estimation. Section 5 presents the empirical results. Section 6 contains concluding remarks.",8
11.0,2.0,"Journal of Industry, Competition and Trade",06 May 2010,https://link.springer.com/article/10.1007/s10842-010-0073-2,Strategic Trade Policies Under Monopsony and Uncertainty: The Exporter’s Non-Linear Responses Based on the Organization of Its Industry,June 2011,Manitra A. Rakotoarisoa,,,Unknown,Unknown,Unknown,Unknown,,
11.0,3.0,"Journal of Industry, Competition and Trade",31 May 2011,https://link.springer.com/article/10.1007/s10842-011-0108-3,Value Capture and Policy Design in a Digital Economy,September 2011,Dan Breznitz,Martin Kenney,Pekka Ylä-Anttila,Male,Male,Male,Male,"Although digital forms of information and communication technology (ICT) have been commercially available for more than 50 years, we are only now beginning to see their full impact. ICT is causing a similar re-structuring of industries, businesses, and institutions in a way similar to the previous major general purpose technologies, namely steam and electricity (Jovanovic and Rousseau 2005; Helpman 1998; Crafts 2004). This special issue is an effort to extend our current understanding of the ICT-enabled and ICT-driven structural transformation. This special issue will consider how ICT and its applications are changing and re-shaping the future prospects of businesses and countries. The articles shed light on important—but, as yet poorly understood—aspects of the ongoing digital revolution. ICT is systemic in ways that link its evolution intimately with applicable regulation and policies. Due to the penetrating role ICT has in our professional and private lives, it interacts with all policy domains. This special issue demonstrates recent changes in globalization and technology that are not adequately reflected in current policies; our attempt is to initiate a debate on what might be the most appropriate future policies in various contexts.",13
11.0,3.0,"Journal of Industry, Competition and Trade",03 June 2011,https://link.springer.com/article/10.1007/s10842-011-0106-5,Diffusing the Cloud: Cloud Computing and Implications for Public Policy,September 2011,Kenji E. Kushida,Jonathan Murray,John Zysman,Male,Male,Male,Male,"Cloud Computing is rapidly emerging as the new platform for computing. It is, however, much more than simply a new set of technologies and business models. Cloud Computing is transforming how consumers, companies, and governments store information, how they process that information, and how they utilize computing power. It can be an engine of innovation, a platform for entrepreneurship, and driver of corporate efficiency. However, while the term is increasingly commonly used, confusion remains over what exactly constitutes Cloud Computing, how the markets are unfolding, and what forces will drive their evolution and diffusion. This paper provides an overview and conceptual tools for business leaders, policymakers, and non-specialist scholars to identify, distill, and easily understand the core aspects of how Cloud Computing service markets are developing, and how an array of policy issues will influence how this new computing platform unfolds across the world. The introduction of any new platform of this potential opens a wide range of opportunities for firms large and small, countries, regions, and the global economy. At the same time, it raises new challenges for firms, industries, economies, and policies. Cloud services are already transforming the business models of companies around the world—from small startups and medium-size firms to large multinational enterprises. Cloud Computing offers new capabilities for innovation and entrepreneurship, lowering the bar for new entrants and facilitating experimentation. At the same time, it raises the scale required to be an effective computing infrastructure provider, and customer expectations of service flexibility and costs are undergoing a sea change. For advanced industrial countries, Cloud Computing provides new opportunities for innovation and entrepreneurship, and promises substantial efficiency gains. For developing countries, Cloud services open up new possibilities to enter international markets and find niches in global value networks. As with the previous computing platforms—mainframes, PCs, and networks of PCs—Cloud computing is becoming a baseline for national and corporate IT infrastructure against which other forms of infrastructure and service delivery must be measured. Cloud Computing offers unprecedented new levels of configurability for diverse groups of users. Services are dynamically configured to the needs of each user with a single unified, usually global-scaled, architecture. Cloud providers’ scale and cost merits are available to all types of users, from individuals to multinational corporations. Critical to Cloud Computing is the abstraction of end-user applications from the underlying hardware. Put simply, application software is not tied to any particular server or physical hardware; instead, it can utilize the massive scalability and resiliency of the underlying global-scale datacenters to deliver the same services to one user or several million users. In general, users do not know or care about where the datacenters are or how they are configured. The abstraction of user-applications from the underlying datacenter infrastructure, combined with the truly massive scale required to harness the full potential of Cloud Computing makes it susceptible to a wide array of government policies. While the technological logic of Cloud services transcends traditional political and economic boundaries, national and regional-level differences will matter a great deal in its actual patterns of implementation. Policy issues such as information privacy, security, national network policy, and jurisdiction are among the critical issues, and can be settled differently across countries. Moreover, the policy debates opened by Cloud Computing are beginning to reshape these debates within countries across the globe. Many of these policy debates reach the core of how governments interact with their citizens, and can shape a possible international regulatory architecture over Cloud services. Both the central public policy and the business strategy issues about the Cloud are embedded in the details of this new computing ecosystem. This paper begins to provide a guide to policy and strategy debates, both of which will be profoundly recast by Cloud Computing. The paper unfolds in four parts, following a simple logic of inquiry. In Part I we answer the question: what exactly are Cloud Computing services? We provide an operating definition of Cloud Computing as a “dynamic utility,” presenting the major characteristics that define Cloud services and differentiate them from traditional utilities and previous IT platforms. Part II asks the question: How can we make sense of the emerging, complex and confusing Cloud services ecosystem? We offer a simple but powerful typology, the “Cloud Services Framework,” that maps different types of Cloud providers (Cloud Services, Access Networks, Access Devices) onto different Cloud architecture types (Infrastructure, Platform, Applications). This framework allows us to understand the business models in different parts of the Cloud ecosystem, and how they come together in the marketplace. It shows us how different sets of policy issues bear upon different types of providers and their business models. Part III answers the question: How is competition among the actual major Cloud providers unfolding? Using our “Cloud Services Framework,” we analyze the business strategies of paradigmatic global Cloud providers Amazon, Google, Microsoft, Salesforce.com, other major IT vendors, and Apple. Part IV asks: How can we get the big picture for how the Cloud services ecosystem(s) is developing globally? Here we augment our “Cloud Services Framework” with two additional variables to construct a deployment framework with the acronym PLUMS—Providers, Layers, Users, Modality, and Scope. We apply the framework to major global Cloud providers, comparing with a sample national of case of Japan, an example that provides the basis for a comparative discussion of how Cloud ecosystems develop in a variety of places.",37
11.0,3.0,"Journal of Industry, Competition and Trade",07 June 2011,https://link.springer.com/article/10.1007/s10842-011-0105-6,Structuring the Smartphone Industry: Is the Mobile Internet OS Platform the Key?,September 2011,Martin Kenney,Bryan Pon,,Male,Male,Unknown,Male,"The convergence of mobile telephony, Internet services, and personal computing is resulting in the emergence of the smartphone and the “mobile Internet” (Ishii 2004; Funk 2001). Information and communications technology (ICT) firms whose locus of competitive strength was centered in only one of these sectors are entering a new competitive landscape that is redefining and eroding the boundaries between software, hardware, and services. The key firms competing in this new market have each been a market leader in their original industry, and therefore bring previously successful firm recipes and particular core competencies to their smartphone efforts. Analysis of the extent to which firms are trying to leverage their existing assets and strategies to capture market share and value in the smartphone industry may be instructive in understanding how firms create and control value during periods of industry convergence. During such convergences firms must leverage and extend competencies, as they seek to shape the new value chain configuration and position themselves to capture as much of the total value created. The emerging smart phone industry provides an ideal case study for examining firm strategy in a moment of convergence. The interest is understandable. Today more than 1.3 billion mobile phone handsets are being sold annually, and in 2010 smartphones made up almost 20% of that total (Gartner 2011; Ahonen 2010). In contrast to standard mobile phones, “smartphones” are powerful computing devices offering traditional wireless voice service as well as native software applications and, perhaps most importantly, the ability to connect to and run a myriad of Internet-based services including email, geo-location, streaming video, and social networking, while providing a good user experience. Sales of smartphones are increasing almost 100% per year, and total global sales volume is expected to surpass that of PCs by 2012 (Gartner 2010). By collapsing the boundaries between previously distinct devices, smartphones are subsuming sales of mobile phones entirely and, increasingly, netbook and notebook PCs. To complicate the landscape, the smartphone is not the only device at stake, tablets and ebook readers are emerging as key components of the mobile universe. Across all devices, total mobile revenues—including advertising, subscriptions, handsets, applications, and so on—are forecast to surpass $1 trillion by 2014 (Gartner 2010). Given the rate at which smartphone are penetrating the market and component prices are declining by 2015 there will be, at least, 2 billion smart mobile devices in use globally. The nature of the smartphone device and industry lends itself to analysis from a technology platform perspective. Scholars and management consultants have identified platform control as a key feature for business success in the ICT industries. Michael Cusumano, drawing upon his studies of Microsoft, Cisco, and Intel, concluded that the winner of technological competitions is “often who has the best platform strategy and the best ecosystem to back it up (Cusumano 2010, p. 34).” The opportunity to establish platforms often comes in the early phases of an industry’s development or when a major technological/market discontinuity occurs. De novo firms and previously existing firms can use the discontinuities to enter a space and displace or subordinate previous incumbents or, even more cleverly, use new business models to transform the value capture equation. This paper explores the competition in the emerging smartphone operating system race, looking at value capture and customer lock-in strategies through the lens of industry architecture and platform theory. Other potentially important market characteristics were considered but not explicitly included. For example, the potential for anti-trust legislation or other legal challenges to firms’ bundling of software, hardware, services, and content could alter strategies. Given the anti-trust lawsuits against Microsoft for bundling its browser to its operating system, it seems reasonable to expect regulatory scrutiny around any firm or platform that becomes dominant. The smartphone market may also be shaped by geographic considerations, both on the supply side as well as the demand side. Interestingly, the new firms to enter the space—Apple, Google, and HP (through Palm)—are all based in Silicon Valley, pulling the epicenter of mobile innovation away from Europe. Similarly, shifts in market demand away from the North American and European markets toward China, India and other countries introduce additional complexity and uncertainty for lead firms. In this paper, we pose the question of whether the platform literature and its emphasis on platform control is an adequate framework for understanding the complexities of the current struggle in the smartphone OS space.",107
11.0,3.0,"Journal of Industry, Competition and Trade",31 May 2011,https://link.springer.com/article/10.1007/s10842-011-0107-4,Who Captures Value in Global Supply Chains? Case Nokia N95 Smartphone,September 2011,Jyrki Ali-Yrkkö,Petri Rouvinen,Pekka Ylä-Anttila,Male,Male,Male,Male,"In high-income countries, decision-makers and experts alike express their concern regarding production moving to lower-cost locations. Our illustration in this paper suggests that commonly employed measures exaggerate the issue to the extent that some aspects may even be illusory. We agree with the theoretical argument of Grossman and Rossi-Hansberg (2008, p. 1978) that “Revolutionary advances in transportation and communications technology have weakened the link between labor specialization and geographic concentration, making it increasingly viable to separate tasks in time and space… The result has been a boom in “offshoring” of both manufacturing tasks and other business functions.” We demonstrate, however, that value capture—the ultimate variable of interest for both businesses and countries—is considerably less dispersed than tasks within a supply chain. Due to limitations regarding the available statistics, we resorted to grass-roots investigative work to uncover the geography of value added for the Nokia N95 smartphone circa 2007. We find that value capture is increasingly detached from the flows of physical intermediate and final goods. Instead, in-house and market services and various forms of intangible assets command the lion’s share of value added (and thus income and profits earned). Even if final assembly has largely moved offshore, the developed countries continue to capture most of the value added generated globally: even for a “made in China” smartphone exported for sale in the US, we find that Europe (EU-27) still captures half of the value added. Linden et al. (2009), who study the supply chain of Apple’s iPod digital music player in 2005, is the most relevant predecessor of our work. They conclude that even though the iPod was assembled in Asia, Apple’s American workers and shareholders predominantly reaped the benefits. They also emphasize that innovation matters; the greatest value tends is owned by companies and locations providing critical differentiated inputs. Finally, they highlight the fact that international trade statistics can mislead as much as inform. All of these findings are echoed in our work. Our approach and method closely resemble those of Linden et al. (2009). Besides obvious differences in terms of the industry, product, and point in time, our analysis is more detailed in several regards. Furthermore, our analysis focuses on value added (rather than gross margin). Our most important extension concerns the geographical breakdown of value added: we go beyond headquarters locations and allow for the generation of each component’s value added in multiple locations and functions. To our knowledge, this is the first paper to examine global supply chains with regard to value added in such detail.",71
11.0,3.0,"Journal of Industry, Competition and Trade",03 June 2011,https://link.springer.com/article/10.1007/s10842-011-0104-7,Leading without Followers: How Politics and Market Dynamics Trapped Innovations in Japan’s Domestic “Galapagos” Telecommunications Sector,September 2011,Kenji E. Kushida,,,Male,Unknown,Unknown,Male,"Japan’s Information Communications Technology (ICT) sector presents an intriguing puzzle, yielding lessons applicable elsewhere. Over the past 30 to 40 years, Japanese firms in industries such as automobiles, consumer electronics, precision equipment, semiconductors, and various high tech components have been successful in international markets. Indeed, despite the country’s economic malaise from the 1990s, many Japanese firms continue to be world leaders in various product areas: hybrid automobiles, machine tools, and various high-tech components, to name a few.Footnote 1
 In the telecommunications-related portion of the ICT sector, Japanese firms were also leaders in many technologies, products, and markets, but with a critical difference from the sectors above. Japan’s telecommunications-related end-products, services, and content firms led the domestic sector towards ever-high levels of sophistication, but the highly developed domestic sector did not lead to prominence in global markets. Time and time again, despite Japanese ICT firms becoming leaders along a particular technological trajectory, global markets shifted in a different direction rather than following Japan’s lead. Japanese firms, too far along the previous trajectory, then failed to become major players along the new trajectory. They became caught in a pattern of leading without followers. This pattern repeated itself across a wide range of telecommunications technologies and markets surrounding telecommunications. In the early 1990s, Japanese firms were on the cutting edge of a set of networking technologies, ATM (Asynchronous Transfer Mode). However, ATM was rendered largely irrelevant with the advent of the Internet, which is based on TCP/IP protocols. Japan also led the world in deploying a specialized high-speed (at the time) communications network called ISDN (Integrated Services Digital Network). This costly ISDN infrastructure was suddenly rendered almost entirely obsolete in the late 1990s by current broadband Internet access technologies, notably DSL (Digital Subscriber Line), deployed over conventional telephone lines. From the mid-1990s, Japanese firms developed highly sophisticated and advanced mobile handsets, pioneering a myriad of new high-end features. However, Japanese handsets were largely confined to Japan, and it was Apple’s iPhone that spearheaded a worldwide shift towards high performance “smartphones.” Japan also pioneered a dynamic, multi-billion dollar mobile Internet content ecosystem, predating Apple’s iPhone platform and content ecosystem by almost a decade. Yet, the entire ecosystem, with a new breed of Japanese entrepreneurs producing profitable and fast-growing startup firms, was confined to Japan. The iPhone and Android platforms quickly became the dominant global mobile Internet platforms. The list goes on. What accounts for this persistent pattern of leading without followers in Japan’s telecommunications markets? More broadly, what are the implications for understanding the linkages between domestic and international markets? When do we see first mover advantages, and what are the conditions that create first-mover disadvantages? Since these areas in telecom are closely related to services, what can we learn about the nature of services versus manufacturing in international competition? This paper contends that Japan’s leading without followers pattern in telecommunications was not simply the product of misguided government choices, ill-informed corporate strategies, or insular standard-setting processes. I argue that politics and regulatory structures shaped a specific set of competitive dynamics, which in turn shaped the choices of technology, standards, and corporate strategies that ended up isolating Japan’s domestic telecommunications market from global markets despite leading in particular technologies and markets. Government choices were constrained by political dynamics and technological uncertainty, corporate strategies were shaped by the domestic competitive dynamics that proved disadvantageous in global markets, and standard-setting, though initially insular, shifted towards adopting global standards, but to no avail. The competitive dynamics center on four key variables: 1) the actors and their resources; 2) the source of technological trajectories; 3) the source of business models; 4) the overall pattern of interactions at the intra-industry and government-industry levels; and 5) the regulatory stance toward global markets. These variables were shaped and reshaped by politics at key critical junctures. Political choices at the inception of Japan’s telecommunications sector led to a powerful state actor with significant R&D resources. This state actor set the technological trajectory and shaped the business models for equipment manufacturers. The regulatory focus was on building and operating a reliable communications networks and ensuring universal access across geographic regions—with little attention to global markets. This seemed fine in the early developmental phases of telecommunications worldwide. In 1985, the state-owned monopoly Nippon Telegraph and Telephone (NTT) was partially privatized and new competitors were introduced, but NTT was not split apart. At the same time, the Ministry of Posts and Telecommunications (MPT) became a bureaucracy capable of industry policy, resulting in both NTT and MPT setting technological trajectories and business models. The sector, largely closed to new entrants and disruptive business models, was characterized by patterned interactions among a stable set of actors. MPT’s policy concerns were squarely on domestic development, with little strategic consideration for international markets. Beginning in this period, that Japan’s telecommunications sector developed rapidly while becoming decoupled from global markets—leading without followers. Since the late 1990s, major policy changes have significantly reshaped the dynamics of competition. Although NTT and its R&D resources were left largely intact, NTT and MPT are no longer the primary setters of technological trajectories. New entrants introduced new, disruptive technologies and business models. They destabilized the entrenched patterns of interaction, sparking price wars between carriers, mounted new challenges to government-industry relations, and reshaped relationships between carriers and equipment manufacturers. As a result, Japan’s domestic telecom sector has a broader variety of linkages to global markets than ever before. Overall, the danger of new trajectories of leading without followers has decreased. However, some vestiges of the previous era remain; in some areas, mostly infrastructure, the legacy of heavy investments along proprietary trajectories remains substantial. A political economy approach is particularly useful to analyze market dynamics in heavily regulated sectors, since governments and politics strongly shape the actors and what they compete over—the range of strategic choices available to firms.Footnote 2 The salience of this approach is even more pronounced after the financial crisis of 2007–2008, which revealed that particular types of deregulation fueled the crisis, and during the crisis, many of the key decisions were at the national level (Tett 2009; Sorkin 2009).Footnote 3 The US government’s rescue bailouts of AIG, several other Wall Street firms, and even General Motors was unprecedented in scale, decisively influencing the composition of actors and dynamics of competition in finance and automobiles. At the level of capitalist systems of advanced industrial countries, different political settlements around the world have created a diverse array of institutional configurations and market dynamics (Hall and Soskice 2001; Berger and Dore 1996; Yamamura and Streeck 2003; Zysman 1983; Esping-Andersen 1990). Global competition is often shaped by the interaction of these national market dynamics on a global stage, sometimes mediated by international organizations. Major market disruptions and discontinuous technological breakthroughs that spring onto this global stage are usually the result of concrete developments within a particular national context. (Zysman 2006). In telecommunications, domestic politics and government policies are especially influential in shaping the actors and their resources, such as R&D capabilities and funding structures. Most countries began with state-owned monopoly telecom carriers, and political settlements determined the exact nature of privatization, the degree of liberalization, and market rules, such as the terms of competitors’ access to incumbents’ infrastructure. In the US, for example, judicial decisions split up AT&T, separating its carrier functions from its R&D labs and equipment manufacturing operations. Telecommunications is also a prime case where governments influence what actors compete over–the activities to which firms channel their resources to compete–shaping vastly different corporate strategies. Spectrum allocation rules are a powerful illustration. In several European countries, auctions for third-generation (3G) wireless spectrum led a bidding war, leaving telecom carriers lacking the funds to build out their networks for several years in the aftermath of the IT bubble bursting in 2000–2001.Footnote 4 In Japan, by contrast, spectrum was allocated by the government based on its internal evaluation; carriers spent very little to obtain wireless spectrum, but the set number of licenses available drove consolidation in the industry. 3G networks were deployed quickly, despite major losses by Japanese carriers in the IT bubble burst as well. Deep governmental involvement in domestic economies, combined with the diversity of political systems and governmental structures across countries, has resulted in a wide variety of regulatory structures and policy choices across industries—particularly in telecommunications. These differences directly affect the composition of firms, their business model options, and the nature of their competition–hence, the diversity across countries in patterns of innovation, competition, business models, and incumbent carriers’ activities.Footnote 5 A political economy approach captures the politics and regulations interacting with national and sectoral dynamics of competition, allowing us to explore the deeper causes of market outcomes, thereby providing a valuable vantage into global competition. This paper unfolds in three parts. Part I provides an overview of Japan leading without followers in telecommunications by presenting the four technology and market cases. Part II examines the historical origins and evolution of the elements underpinning Japan’s dynamics of competition in telecommunications. It traces the market dynamics and firm strategies through the 1990s, as Japan’s domestic telecommunications market became decoupled from global markets and entrenched in a pattern of leading without followers. Part III analyzes the substantial transformation in the dynamics of competition since the late 1990s and early 2000s.",29
11.0,3.0,"Journal of Industry, Competition and Trade",31 May 2011,https://link.springer.com/article/10.1007/s10842-011-0109-2,"Barcode Empires: Politics, Digital Technology, and Comparative Retail Firm Strategies",September 2011,Bartholomew C. Watson,,,Male,Unknown,Unknown,Male,"The economies of the advanced, formerly industrial democracies are undergoing a radical transformation. Similar to other economic revolutions, this metamorphosis is entangled with technology. Unlike previous industrial divides, however, this transformation is driven by services, not manufacturing (Zysman et al. 2007). Services, once a productivity quagmire, are now recognized as a source of productivity growth and engine of the economy, altering the structure of employment, the division of labor, and the location of value in the economy (Triplett and Bosworth 2004; Levy and Murnane 2004). One of the most radical reorganizations has occurred in the retail trade sector. Over the past 30 years, information technology (IT) has both transformed the sector—including its major players, its geographic location, and the character of its firms—and the basic equation of how value is captured in the consumer retailing value domain. There have been common transnational patterns during retail’s metamorphosis, including two interwoven movements: the increase in the advantages of and the presence of scale in retailing and a dramatic rise in the power of retailers through information gathering and analysis. An extensive convergence literature argues that technology will hasten the move toward the Fordist organizational structures seen in liberal environments. In retailing, these authors argue that were it not for over-burdensome labor and product market regulations, firm strategies would converge on a singular best practice largely synonymous with the American model (Nicoletti and Scarpetta 2003; Gordon 2004; McGuckin et al. 2005; Delpla and Wiplosz 2007). These studies typically base their analyses on evidence from the US-Europe “productivity gap” in the mid-1990s, suggesting that America leads and Europe lags in IT-using services like retail trade and finance due to labor and product market barriers that slow innovation and dampen competition (Van Ark et al. 1999, 2008; O’Mahoney and Van Ark 2003). When broadening our time-horizons, however, a puzzle-emerges: these theories are not supported by the empirical evidence. Table 1 above shows productivity data for various service sectors across five countries from 1977–2007. Note that retail productivity growth exceeded national growth in four of the five case countries. These are not small changes. Distribution is a large sector that captures 10–15% of the jobs and value in every advanced economy. It is also located between producers and consumers, making it ideal to study the conflicts between social and economic goals inherent to the service sector.
 The data, therefore, show that retailing provides an excellent case to examine the services revolution for two reasons. First, the pace of retailing growth has undeniably changed. Secondly, examining firm outcomes in retailing, it is clear that business strategies cannot be reduced to either a techno-determinist convergence story or simply a tale of labor markets, wages, and labor skills. The problems of markets and hierarchies in retailing are in fact being resolved by a variety of political negotiations, demonstrating once more that technical outcomes are not determined by the technology itself, but by social and political rules. The transformation from nations of shopkeepers to nations of retailers, therefore, provides both an intriguing case and a perfect comparative window into how technology transforms not only a sector, its employment, and its firms, but also its political actors, political fights, and an enormous value domain in the economy.Footnote 1 Sector-specific research in comparative context provides an essential tool for examining the services transformation. Sectors control for a variety of issues, highlighting where variation in political, social, and institutional variables alters market and firm outcomes. Sector cases, therefore, allow an investigation of how common technological developments are mediated and interpreted across different sets of formal institutions, political coalitions, markets, and social settings. They also allow insights into the correct level of analysis for studying economic and political change. The nodes of contestation evolve during any economic transformation, while level of governance questions are particularly important for Europe with its patchwork of political actors and regulations. Sector studies illuminate at which level the primary political action is occurring, quickly updating models of political, technological, and economic change. This study, in addition to the empirical data presented in the article, is informed by approximately 100 interviews with sectoral stakeholders, including retail firms, labor unions, policymakers, business associations, and sectoral analysts. It shows that how the retail revolution has unfolded differs dramatically by country, including the character of firms, power relations in the economy, and tangible outcomes like wage and price levels for workers and consumers. This article will use the large-scale chain retailing case as a test case for the larger services transformation research agenda. The evidence shows that the importance of the services revolution goes beyond the growing contribution of services to economic activity in the advanced economies. In addition, retailing underlines a broader story about how digital technology transforms service activities, re-organizes the service components of the economy, and reshuffles relationships between service firms, workers, producers, and policy-makers. In doing so, it highlights the numerous challenges and conflicts that emerge in a political economy where IT-enabled services are central to employment and productivity. Surprisingly, many of these broader political, social, and economic implications are yet to be systematically studied. Importantly, the retailing revolution is both influenced by and has radical implications for politics and coalitions. How retailers organized politically in the 1960s and 1970s to win fights with independent small-shop retailers over rules on such issues as prices, planning, opening hours, and store size and construction locked in particular modes of interaction with suppliers and workers, prompting unique business-model configurations in the search for efficiency and competitive advantage. Tracing forward, these initial political and economic plans continue to shape the business strategies and political alliances of large retailers in the current era—one where growth stems from using technology in core processes to create innovation. Although the marriage of technology and scale has opened a variety of new business strategy opportunities for retailers, firms have implemented quite different scale processes of routinization, data analysis, and value capture. The article highlights three competitive strategies in modern general merchandise retailing. Each has a different primary focus for creating value and exhibits variation in how technology is used, product strategy, labor strategy, supplier-relations, and value-added strategy. In addition, we see very different levels of each across different political settings. The argument is not that these managerial modes are the only game in town, as each may be present at different levels within a country or even a particular firm.Footnote 2 Rather, the argument is that the solutions to the multitude of make, buy, or partner decisions facing the scale of retail firms has been strongly influenced by national political competition. Retailers did not adopt one or another of these strategies simply because any one was initially more economically efficient. In fact, the basic business models of retailers across the affluent economies in the 1960s and 1970s were highly similar, built on the same basic economic ideas, and even disseminated by a limited number of retail gurus, most notably Bernardo Trujillo of National Cash Register. Strategies began to diverge, however, as national political actors, institutions, and levels of power forced retailers to form coalitions with a variety of political partners (including labor, suppliers, and broad political party coalitions). How retailers managed these political choices then shifted firm economic calculations, pushing retailers them toward three ideal types, each of which makes money, distributes value, and works with other economic and political actors in very different ways. Again, each strategy is not about differing levels of efficiency, but different, conditioned trajectories of growth and competition. The first is the American strategy of lean retailing.Footnote 3 Lean retailing is a cost-squeezing strategy, best embodied by the American behemoth Walmart.Footnote 4 Lean retailing emerged where political outcomes were based on a market logic and retailers could use market advantages to dominate other partners. Retailers employ a low-cost, low-service, high turnover strategy based on squeezing costs and contested relationships with labor, suppliers, and local governments. Retailers pass some of the savings from cost-savings on to consumers, while largely excluding workers and suppliers from the gains.Footnote 5 Technology has helped retailers gain the upper hand in these relationships, as firms use technology to gather information, and the information gathered as a club. 
Relational contracting, seen in the Danish case and the German case, is a cost-sharing strategy built on a base of broad political coalitions. It competes by creating long-term savings from cooperative political and economic relationships with workers, suppliers, and social partners. Retailers use technology as an enabler in these relationships, allowing them to up-skill workers and identify areas of collaboration with suppliers.Footnote 6
 The final strategy is the vertical integration strategy seen in France and the United Kingdom.Footnote 7 It is a complementarities strategy where retailers compete by adding value through additional services, value-added products, or private label products in store. In these countries retailers compete against suppliers, but have formed more limited coalitions with political and labor partners. In fact, retailing policy in these countries has developed into an area of perpetual contestation, where retailers consistently struggle with workers and suppliers over the rules of the game. Consequently, retailers employing the vertical integration model use technology to break free of past relationships and add value to product and service offerings. This paper will present significant evidence not only that each of these strategies exists, but also that each is persistent and high competitive. Nevertheless, they should not be interpreted as the only strategy available to retailers, simply as archetypes of nation-specific tendencies. Many of the features discussed, such as the use of product data in supplier negotiations, technology to train workers, or added services and private labels are features of leading retailers across the world. What is different, however, is the level and character of each across national borders (Table 2).
 The rest of this article will trace the development of these managerial styles. A first section will highlight the variety of potential opportunities opened by the marriage of digital technology and scale, elaborating the political decisions that pushed firms down different paths, and presenting evidence of each strategy and its mode of competition. A next section will suggest how new technology platforms may affect each model in different ways. Finally, a conclusion will outline how these changes coupled with retail globalization shift the priorities of policymakers working on the retail sector.",13
11.0,4.0,"Journal of Industry, Competition and Trade",22 July 2010,https://link.springer.com/article/10.1007/s10842-010-0087-9,Pricing Policy and Partial Collusion,December 2011,Stefano Colombo,,,Male,Unknown,Unknown,Male,"Price discrimination has received a good deal of attention by economists (see for example the recent surveys by Stole 2007, and Armstrong 2006 and 2008). A consistent body of literature considers the implications of price discrimination in oligopoly (Thisse and Vives 1988; Kats 1989; Aguirre et al. 1998; Corts 1998; Tabuchi 1999; Ulph and Vulkan 2000; Liu and Serfes 2004; Jeong and Maruyama 2009; Colombo 2009a). This literature emphasizes that under quite general conditions price discrimination tends to decrease equilibrium profits with respect to uniform pricing. This occurs because “competitive price discrimination may intensify competition by giving firms more weapons with which to wage their war” (Corts 1998, p.321). Some authors have investigated the pricing policy equilibrium emerging when firms can commit themselves not to price discriminate before setting prices. Thisse and Vives (1988) show that in a horizontal differentiation model with maximally differentiated firms, the unique equilibrium emerging in a two-stage game in which firms first choose the pricing policy and then set the prices is characterized by price discrimination. Eber (1997) shows that in a three stage model where firms first simultaneously choose where to locate, then choose whether to price discriminate or not, and then set the price schedules, the unique equilibrium is characterized by both firms price discriminating, while when the first two stages of the game are reversed, the unique equilibrium is characterized by both firms committing not to discriminate. Liu and Serfes (2004) and Colombo (2009a) generalize these results to the case of imperfect price discrimination. Encaoua and Hollander (2007), using a vertical differentiation model, show that price discrimination emerges as the unique pricing policy equilibrium. Jeong and Maruyama (2009), focusing on behaviour-based price discrimination, show that when consumers have rational expectations, it is the dominant strategy equilibrium for both firms to select uniform pricing. This paper studies decisions by firms of whether to (perfectly) price discriminate or set uniform prices in a partial collusion framework. Partial collusion (or semi-collusion) is defined as a situation in which long-run decisions are competitively made but with the understanding that collusion will follow in subsequent stages of the game (Grillo 1999). Partial collusion has received extensive attention by economists, which considered different long-run variables: for example, in Davidson and Deneckere (1990) the long-run variable is capacity, in Friedman and Thisse (1993) and Posada and Straume (2004) it is location, in Deltas and Serfes (2002) it is quality, and in Fershtman and Gandal (1994) and Brod and Shivakumar (1999) it is R&D expenditure. While the implications of price discrimination in fully collusive models have received some attention (Espinosa 1992; Gupta and Venkatu 2002; Liu and Serfes 2007; Miklòs-Thal 2008; Colombo 2010), the analysis of price discrimination in a context characterized by partial collusion has not been attempted until now. To this purpose, we model the interaction between the firms as follows. Firms non-cooperatively commit or not commit to uniform pricing at the beginning of the game, and then try to enforce a collusive agreement conditionally on the pricing policies chosen in the first stage of the game. There are many ways in which a firm may commit to uniform pricing. First, one may imagine an explicit contract between the firm and the consumers. An example of such contract is the most-favoured-nation clause, which engages a firm to offer a consumer the same price as its other consumers: if the clause is not respected, the firm must pay back the consumer the difference between the price he effectively paid and the lowest price fixed by the firm.Footnote 1 Also, as Encaoua and Hollander (2007) argue, commitment “may derive from sunk investments in a distribution channel that puts intermediaries between manufacturers and consumers and does not allow the former to ascertain individual consumer preferences” (Encaoua and Hollander 2007, p.6). In any case, a decision to engage in uniform pricing is assumed to be credible. That is, such decision cannot be reversed without costs. In studying partial collusion we adopt the competition framework of Hotelling (1929). However, we introduce a relevant generalization with respect to other works employing the Hotelling model for studying collusion sustainability (see for instance Chang 1991 and 1992; Hackner 1995; Gupta and Venkatu 2002). In fact, firms are not constrained to be spatially symmetric: any degree of spatial symmetry/asymmetry between firms is allowed, keeping fixed the distance between the two firms (Colombo 2009b). As it turns out, the degree of symmetry/asymmetry plays a key role in determining the pricing policy equilibrium emerging in the partial collusion game. In fact, we obtain the following results. In the case of intermediate values of the market discount factor and a high degree of asymmetry between firms, the unique equilibrium is characterized by the larger firm renouncing to price discrimination, while the smaller firm price discriminates. Instead, in the case of intermediate market discount factors but low degree of asymmetry, two equilibria arise: either both firms price discriminate or no firm price discriminates. Finally, when the market discount factor is particularly high or particularly low the unique equilibrium is characterized by both firms price discriminating for any degree of asymmetry between firms. The paper proceeds as follows. In Section 2 we describe the model. In Section 3 we study collusion sustainability when both firms have committed to uniform pricing. In Section 4 we study collusion sustainability when no firm has committed to uniform pricing. In Section 5 we consider the case of asymmetric pricing policies. In Section 6 the pricing policy equilibrium is derived. Section 7 concludes. Proofs are relegated in Appendix 1, while in Appendix 2 are reported the complete expressions of profits’ equations and discount factors.",2
11.0,4.0,"Journal of Industry, Competition and Trade",22 May 2010,https://link.springer.com/article/10.1007/s10842-010-0075-0,Damage at the Pump: Does Punishment Fit the Crime?,December 2011,Xavier de Vanssay,Can Erutku,,Male,,Unknown,Mix,,
11.0,4.0,"Journal of Industry, Competition and Trade",19 June 2010,https://link.springer.com/article/10.1007/s10842-010-0082-1,"To Acquire, or To Compete? An Entry Dilemma",December 2011,Ornella Tarola,Jean J. Gabszewicz,Didier Laussel,Female,Male,Male,Mix,,
11.0,4.0,"Journal of Industry, Competition and Trade",27 October 2010,https://link.springer.com/article/10.1007/s10842-010-0089-7,The Effects of Uncertain Divestiture as Regulatory Threat,December 2011,Makoto Tanaka,,,,Unknown,Unknown,Mix,,
11.0,4.0,"Journal of Industry, Competition and Trade",05 November 2010,https://link.springer.com/article/10.1007/s10842-010-0091-0,Determinants of the European Commission’s State Aid Decisions,December 2011,Caroline Buts,Marc Jegers,Tony Joris,Female,Male,Male,Mix,,
12.0,1.0,"Journal of Industry, Competition and Trade",20 January 2012,https://link.springer.com/article/10.1007/s10842-011-0123-4,Competition and Innovation: Revisiting the Inverted-U Relationship,March 2012,Michael Peneder,,,Male,Unknown,Unknown,Male,,21
12.0,1.0,"Journal of Industry, Competition and Trade",06 July 2010,https://link.springer.com/article/10.1007/s10842-010-0084-z,Reflections on the Relation Between Competition and Innovation,March 2012,Raymond De Bondt,Jan Vandekerckhove,,Male,Male,Unknown,Male,"Since a long time, there has been an intensive debate concerning the impact of market structure on innovation. This vivid discussion stems from two classic but opposing views; the Schumpeterian versus the Arrowian view. According to Schumpeter (1942), large firms and less competition are beneficial for innovation and monopolistic markets are hence the best breeding grounds for new products or new production technologies.Footnote 1 The complete opposite, however, has been claimed by Arrow (1962), who argued that a monopolist has less incentives to invest in research and development (R&D) than a competitive firm due to, what Tirole (1988) calls, the replacement effect.Footnote 2
 As there is a wide consensus that innovation and technological change are driving engines for economic growth and the well-being of society (see a.o. Solow (1957) and Romer (1990)), this relation between competition intensity and research and development (R&D) is of obvious importance for policy makers. However, despite the pile of theoretical and empirical studies on the effect of competition on R&D and innovation, no consensus has been reached. For example, in the empirical literature, Horowitz (1962), Mansfield (1963) and Kraft (1989) support the Schumpeterian hypothesis, while Geroski (1995) and Nickell (1996) find positive correlations between competition and innovative investments, thereby sharing Arrow’s view. Moreover, as pointed out for the first time by Scherer (1967a), the relation between competition and R&D is not necessarily linear. Indeed, using 1960 employment data of US manufacturing firms, he found the highest level of R&D activity, measured by R&D personnel, for an intermediate level of competition, i.e. a C4 index between 50% and 55%. Other early empirical evidence on such an inverted-U relation has been provided by, a.o., Scott (1984) and Levin et al. (1985). The ambition of this paper is not to review the empirical literature, but to pause and to reflect on the theoretical literature dealing with the relation between competition intensity and R&D. More specifically, we aim to provide the reader with some insights in basic oligopolistic models dealing with the relation between competition intensity and R&D investments and the sensitivity of their conclusions to the underlying assumptions. In addition, remark that we limit the analysis to a positive description and do not describe any normative implications. Within the Industrial Organization (IO) literature, a wide variety of models has been employed to analyze the effect of competition on R&D. For the presentation of this paper, a distinction is made between decision-theoretic and game-theoretic models. The main reason is that the decision-theoretic models, which mainly go back to the 1970s, assume that the intensity of rivalry is exogenous and constant and is not affected by any firm’s R&D investment decisions. This assumption can sometimes be considered as realistic: a firm is not always able to identify its rivals or its rivals could be working in other business lines while working on the same innovation. The game-theoretic models, however, take into account strategic interactions among firms, which are typical for oligopolistic markets. Within the class of game-theoretic models, a further distinction is made between partial and general equilibrium models. The paper proceeds as follows. In Section 2, we provide a short overview of the decision-theoretic models. The discussion of the game-theoretic models is dealt with in Section 3, with partial equilibrium patent race models in subsection 3.3, partial equilibrium strategic investment models in subsection 3.2 and the general equilibrium models in Section 3.3. Section 4 concludes.",47
12.0,1.0,"Journal of Industry, Competition and Trade",29 May 2010,https://link.springer.com/article/10.1007/s10842-010-0077-y,The Relationship Between Competition and Incumbent’s Innovation,March 2012,Cátia Felisberto,,,Female,Unknown,Unknown,Female,"Over the past decades, network industries have been going through a process of reform. Many network industries have evolved from being dominated by integrated state-owned monopolies to restructured industries with private sector participation and/or to partially or completely liberalised industries. One of the major motivations for the reform of the network industries, and in particular for the liberalisation process, is the belief that competition stimulates process and product innovation, encourages efficiency, and drives prices down. There is an extensive literature on the relationship between competition and innovation. However, there is no clear consensus on whether competition has a positive effect on innovation or not. Also, the models developed until today only consider profit maximisation as the objective of the firm. Therefore, they do not capture the richness inherent in alternative ownership and governance structures, as well as the historical roots of many incumbents in network industries as public enterprises. Other objectives besides profit maximisation can credibly be advanced as representing those of network industries’ incumbents and, in particular, of postal sector incumbents. For example, a traditional public bureaucracy whose management is concerned primarily with maximising the size of the organisation may engage in maximising sales revenue. By contrast, a public enterprise whose managers operate under a charter directed toward consumer welfare and efficiency (in pricing) may be concerned about welfare maximisation. Of course, welfare maximization is of interest in its own right in providing first-best and second-best efficiency benchmarks. A theoretical model that allows the incumbent to have different maximising objectives is developed in order to analyse the effect of these alternative objectives on the incumbent’s incentives to innovate. The debate about the influence of the intensity of market competition on technical progress started with Schumpeter (1942) and continued with Arrow (1962). Schumpeter argues that monopoly favours the development of R&D activities because it provides the necessary cash flow to invest in such activities and reduces uncertainty in the market. Twenty years later Arrow investigated the effects of market structure on the firm’s incentives to invest in R&D in order to reduce costs. Arrow concluded that under competition the single firm gets more benefits from innovation than under monopoly. The intuition behind this result is that under monopoly, part of the benefits coming from innovation serve only to replace the monopolist’s rents earned before innovating, i.e. the monopolist has greater opportunity costs of innovating. Grossman and Helpman (1991) and Romer (1990) support Schumpeter’s view that monopoly is a precondition for innovation by arguing that firms innovate because they seek profitable opportunities that arise from monopoly. On the contrary, Nickell (1996) and Boone and Dijk (1998) support the existence of a positive relationship between competition and innovation. Other authors have elaborated on the relationship between competition and process (or technical) innovation, introducing additional factors like the value of the innovation and the level of fixed and variable costs. Kamien and Schwartz (1975, 1976) show that for inventions of small value, the absence of rivalry leads to the most rapid development, while a positive level of rivalry will achieve this for more valuable innovations. Loury (1979) finds that, under certain conditions, the incentives to invest in R&D of individual firms decrease as competition increases. The work developed by Lee and Wilde (1980) reaches rather different conclusions from Loury (1979). The authors conclude that an increase in rivalry increases the equilibrium individual R&D effort. In an attempt to reconcile this conclusion with Loury’s earlier work, the authors show that if fixed costs in the R&D technology are larger than variable costs, then an increase in competition leads to a decrease in the equilibrium level of firm investment in R&D. Other authors have made a distinction between individual and industry innovation or investment in R&D, and find a positive effect of competition on aggregate innovation and a negative effect of competition on individual innovation (Cellini and Lambertini 2005, Blundell et al. 1999). Between Schumpeter’s followers and Arrow’s defenders, a third group of authors emerged who have attempted to combine the previous arguments in order to rationalise the “inverted-U” relationship between market concentration and R&D and technological advance found by some authors in the empirical studies. Scherer (1967) observes that the speed of technological research accelerates with rivalry, provided that the number of firms competing is not excessive. Scherer appears to have been the first to suggest an inverted-U relationship between competition and innovation. Later on, Boone (2000, 2001) and Aghion et al. (2005) also find a nonlinear relationship between competition and innovation. Aghion et al. (2005) confirm the inverted-U relationship between intensity of competition and R&D incentives. In short, the literature on the relationship between competition and innovation does not provide a clear answer as to whether competition stimulates innovation or not. Increased competition is said to have both positive and negative effects on innovation. The positive effect is a result of the firm’s quest to optimize profits through increasing its efficiency and reducing its cost of production. Profitability pushes the development and adoption of more efficient technologies and processes. At the same time, competition decreases the rents of the monopolist and might reduce its market share. Therefore, revenue will also decrease. As a result, firms will have fewer resources to invest, for instance, in research and development. Similarly, they are also likely to encounter more difficulties when trying to recover potential investment into new technologies and new processes (where economies of scale have not yet been captured). The lack of consensus is even more apparent when the theoretical results, demonstrating monotonic impacts of increasing competition, are compared with the empirical results, which have shown broadly the mixed or U-shaped consequences of competition. This paper aims at contributing to the literature by developing an extension of the traditional profit-maximising model to investigate whether investment in new technologies and processes is higher under competition or under monopoly. This extension is intended to encompass contexts, not unusual at starting points for liberalization of many network industries, in which the incumbent has the form of a public enterprise or is a part of a government ministry and whose objectives are therefore not prima facie profit maximization. The structure of this paper is as follows. The next section presents the model. In section 3 the model is calibrated with data for the postal sector. Section 4 summarises the results of both the theory development and the computational experiments conducted to illustrate the sensitivity of the monopoly and duopoly solutions to relevant parameter changes. Section 5 concludes. The richness of the model developed does not allow a simple summary of the results. What can be noted here is that the incumbent’s objectives and market structure are both potentially important in understanding and predicting the consequences of liberalization on innovation.",5
12.0,1.0,"Journal of Industry, Competition and Trade",19 January 2012,https://link.springer.com/article/10.1007/s10842-011-0122-5,Market Incentives for Business Innovation: Results from Canada,March 2012,Charles Bérubé,Marc Duhamel,Daniel Ershov,Male,Male,Male,Male,"Are more competitive industries more innovative? There is by now a very large literature on this complex question, going back at least to Schumpeter (1934) and continuing with Arrow (1962).Footnote 1
 Theories of innovation in industrial organization, agency theory, or endogenous growth make diverse predictions with respect to this long-standing open question in economics. In general, the theoretical literature often oscillates between arguing for the positive and negative effects of competitive pressure on business innovation. For example, according to the popular interpretation of Schumpeter’s (1934) work, greater competition reduces post-innovation rents, thereby limiting the incentive to innovate. Footnote 2 Other popular models of firm innovation also suggest that innovation decreases with the level of competitive pressure.Footnote 3Other models (e.g. Aghion et al.
1997; 2001) predict that competitive pressure exerts a positive influence on firms’ incentives to innovate. Empirical research using structural measures of competition (such as Lerner Index) have done little to settle this debate. In this paper, we investigate the empirical relationship between competition intensity and firm innovation using three different measures of competition intensity and include, among other explanatory variables, a measure of industry distance to technological frontier (à la Aghion et al. 2005) to control for the toughness (or neck-and-neckness) of competition. Using a business micro-data set containing a large pooled cross-section of Canadian manufacturing enterprises covering the period 2000–05, we find some evidence that competition intensity is positively related to firm-level expenditures on research and development (R&D) in Canadian manufacturing industries. The results also show that the impact of competition intensity greatly diminishes once we take into account the firms’ distance from the technological frontier of their industry. Indeed, the results imply that if the distribution of firms is greatly skewed towards a relatively high distance to the technology frontier of the leading firm, a factor that can influence negatively the intensity or the quality of competition, the impact of competition intensity could prove to be negative. This paper contributes to the extensive empirical literature that examines the impact of competition intensity on innovation. Empirical efforts in this field ceased in the mid-eighties after studies failed to find residual effects of market structure using cross-sectional data when controlling for industry “fixed effects” (Scott 1984) or introducing proxies for the conditions underlying the fixed effects (Levin et al. 1985).Footnote 4 The consensus was that market structure and innovative behavior were jointly determined by technological opportunity (the returns to investment in R&D, Scherer 1965), appropriability (the likelihood of the firm being able to appropriate returns, Arrow 1962) and market size (the base over which to capture the returns, Schmookler 1966). Theories of innovation agree on the factors affecting the innovative behavior of firms, but not on the directionality. Demsetz (1973) describes the limitations of the empirical measures of market power used in the Structure-Conduct-Performance on the basis of their incapacity to separate market power from technical efficiency and superior performance. Empirical tests of the market structure and innovation hypotheses have used concentration or mark-up measures rather than more structural measures considered in industrial organization.Footnote 5 In general, these tests have been cross-sectional comparisons of industries using different measures of innovation and the results have been equivocal. Tests tend to indicate that innovation is higher in industries with greater concentration, but those effects disappear as controls for industry are introduced (capturing conditions that jointly affect innovation and market structure). The recent renaissance of the empirical approach to the question by Aghion et al. (2005), with the possibility of a non-monotonic inverted-U relationship between competition and innovation first hinted by Scherer (1967), does little to resolve the theoretical dispute. Thus, we can only wonder whether the lack of agreement between theory and evidence comes from the absence of robust theoretical predictions resulting from specious theoretical parameterization of business innovation, or perhaps because the empirical evidence is based on poor measures of competition intensity that fail to recognize the importance of the heterogeneity of efficiency between firms for the equilibrium “quality” of competitive pressure. Given the evidence of extensive productivity heterogeneity between firms within an industry, and its theoretical importance to the quality of competition intensity and market selection, empirical results based on any measure of competition intensity are difficult to interpret.Footnote 6 Duhamel and Kelly (2009) point out that: “Most empirical study relied on two common variations of the Lerner index to measure competition intensity at the industry level.Footnote 7 Although they have been used successfully in the empirical literature, the factors that can affect the measured Lerner index of an industry are not limited to competition. In particular, the measure is known to provide the wrong inference when the industry is concentrated and firms are heterogeneous or when the market is poorly delineated.Footnote 8” Using data from the same source as in his paper, the next chart shows an important non-linear negative relationship between competition intensity (measured by Boone’s Profit elasticity measure) and the average distance to the technology frontier of firms in an industry (Fig. 1).Footnote 9
 Profit elasticity and average distance to technology frontier in Canadian industries The difficulties of measuring competition in the particular circumstances of each industry cannot be ignored given the importance of the empirical relationship between competition and innovation. In particular, it is important for a measure not only to capture the extent of product substitutability that determines the perceived competitive pressure within an industry, but also other characteristics that determine the competitive equilibrium such as the heterogeneity of the cost and product line obsolescence between firms. For example, in the classic asymmetric homogeneous product Bertrand-duopoly equilibrium, the most efficient firm charges a price above its marginal cost, the competitive price of the inefficient firm, and earns positive economic profits. What would be the incentive to innovate compared to another industry where both firm compete on equal marginal cost?Footnote 10 The larger the efficiency asymmetry between the two firms, the smaller will be the difference between the post-innovation and pre-innovation profits, ceteris paribus. Vives (2008) revisits the effects of competitive pressure on process and product innovation using general symmetric oligopoly models of competition (strategic substitutes and complements), where investments in innovation by firms always yields some positive innovation outcomes (i.e. non-tournament/patent-racing models). Motivated by the lack of agreement between the theory and empirics of innovation and competition, he finds R&D efforts increase or decrease depending on the factor driving increased competition intensity, provided that the total market size does not shrink. Again, these ambivalent theoretical predictions about factors that are commonly viewed as increasing competition run contrary to the empirical evidence that commonly rely on commonly used structural measure of competition and suggest that factors that influence the quality of competition (e.g. marginal cost asymmetry, product obsolescence, and other non-price competition attributes) are important factors in the relationship between competition and innovation.Footnote 11
 Boone (2008a, b) proposes a new approach to measure competition that takes into account the heterogeneity of efficiency of firms in a market. His approach is based on the idea that competition rewards efficiency. More efficient firms will have higher market shares and higher profits than less efficient ones. In a more competitive market this effect should be stronger.Footnote 12 He shows that the relative profit of a firm compared to a reference firm is a monotonically decreasing function of the relative marginal cost of the firm compared to the reference firm. This approach, aiming to capture the competitive interaction between competitors, is very similar to other recent approaches used in the economic growth literature (e.g. Aghion et al.
1997; 2005 and Acemoglu et al.
2006) which combine industry profit margins with a measure of distance to the technological frontier to capture the effects of heterogeneity of efficiency of firms on competitive pressure and market selection. Boone’s methodology, however, differs from most measures of competition intensity in that it does not presuppose the causes of changes in competition intensity (e.g. changes in market power for firms, entry or exit of competitors, changes in regulation); it simply observes that competition has changed and points out the direction of the change. In a sense, it is an agnostic structural measure of competition intensity. We depart from previous empirical studies the relationship between competition and innovation in Canada in two important ways. First, this paper is the first one that takes into account the complex nature of the quality of competitive pressure with respect to incentives for innovation by taking into account the firm’s relative efficiency with respect to its competitive peers (the distance-to-frontier effect).Footnote 13 Second, we estimate the same reduced-form model using three different measures of competition using a pooled cross-section of quasi-longitudinal firm-level observations of innovation and competition intensity, effectively forming an unbalanced panel dataset. In doing so we show that the quality of competition is an important factor because it influences the marginal incentives of firms to engage in R&D activities, whether it originates from more technologically advanced manufacturing firms or from more innovative product offerings. The rest of the paper proceeds as follows. First, we describe the empirical approach that decomposes the effects of competition and efficiency heterogeneity into its effects on firm-level innovation efforts. Next, we describe the data. Section 4 then discusses the results. And finally, we outline the conclusions and discuss the implications of this study.",14
12.0,1.0,"Journal of Industry, Competition and Trade",19 January 2012,https://link.springer.com/article/10.1007/s10842-011-0120-7,Innovation and Competition in the Netherlands: Testing the Inverted-U for Industries and Firms,March 2012,Michael Polder,Erik Veldhuizen,,Male,Male,Unknown,Male,"The effect of competition on economic activity has been at the centre of debate for quite some time (see Ahn 2002, for an overview). As noted by Nickell (1996), it is a common belief that competition stimulates firms to improve their performance and distinguish themselves from competitors to attract demand for their products. On the other hand, in line with the more traditional Schumpeterian view, a market where competition is very stiff may offer little room for innovative activities, so that in the long-run competition may negatively affect productivity growth. Thus, the relation between competition and innovativity or productivity may not be unequivocally positive. In line with these two contrasting views on the impact of competition, Aghion et al. (2005) suggest a theoretical model where the relation between competition and innovation is non-linear at the industry level, which they refer to as an inverted-U shape.Footnote 1 They also present empirical results supporting the predictions of their model. Thus, if competition is intensified starting from a low level, innovation activity is stimulated, whereas starting from a high level of competition, innovation activity is discouraged by increased competition. Aghion et al. suggest that this is due to a composition effect in the dispersion of the production technology. In this paper, we investigate the relationship between innovation and competition using firm- and industry-level data for the Netherlands.Footnote 2 The paper consists of two parts: a macro-study and a micro-study. In the macro part we test for an inverted-U relationship between industry-level R&D expenditures and competition. In the micro part, we focus on whether the non-linear mechanism can be explained by differences in the distribution of the production technology as predicted by Aghion et al. model. We make a few contributions. Firstly, since the argument for an inverted-U relationship provided by Aghion et al. is for the industry-level, most of the existing empirics is also at the industry level. We test for a non-linear effect at both the industry- and the firm-level. Moreover, since the theoretical model predicts that the effect of competition on innovative activity should depend on the distribution of technology, we test explicitly for the role of this ‘spread’. Secondly, besides the Price Cost Margin (PCM) we employ a relatively new competition measure called the Profit Elasticity (PE) as proposed by Boone (2008). Thirdly, our dataset is relatively large and rich compared to most of the existing empirical work, with micro-data being sourced from surveys by the statistical office, and industry-level variables being the official figures published in the Dutch National Accounts and R&D satellite accounts. Finally, our dataset includes services and other non-manufacturing industries. This meets the interest in measuring the effects of competition in industries outside manufacturing, on which this type of studies has usually focussed. Especially in the Netherlands, but typically in Western economies, a shift towards services can be noted, making it necessary to go beyond manufacturing in empirical analyses. The setup of the paper is as follows. Section 2 briefly discusses the theoretical arguments for the inverted-U shape, but also presents some caveats and possible counterarguments. It also reviews some related empirical literature. Section 3 puts down the estimation equations for both the industry- and firm-level estimation and discusses the econometric approach. Section 4 describes the data, discusses the measurement of competition and innovation, and presents summary statistics. Section 5 presents the estimation results. Finally, section 6 provides a summary of the conclusions and avenues for further research.",35
12.0,1.0,"Journal of Industry, Competition and Trade",10 June 2011,https://link.springer.com/article/10.1007/s10842-011-0101-x,Competition and Innovation in Luxembourg,March 2012,Chiara Peroni,Ivete S. Gomes Ferreira,,Female,Unknown,Unknown,Female,"The relation between competition and innovation is relevant to both academics and policy makers. Economic and policy-oriented studies often point out the link between the intensity of competition and a country’s economic performance and welfare. Furthermore, competition and innovation are at the core of the programme of structural reform set out by EU countries in the Lisbon Strategy, with the ultimate objective of promoting economic growth and employment. Economists, however, suggest that the relation between competition and innovation is far from being simple. The idea that innovative activities are related to market structure dates back to Schumpeter. Following Schumpeter’s seminal contribution, a stream of research has suggested that innovation is negatively related to competition (Dasgupta and Stiglitz 1980; Aghion and Howitt 1992). This trade-off between competition and productivity growth/innovation has an obvious policy implication: policy makers should accept a certain degree of market power in order to encourage innovation activities. This view, however, has been questioned by several empirical studies linking higher competition to increased innovation efforts. Nickell (1994) finds that competition improves corporate performance and total factor productivity in a panel of UK firms. Griffith et al. (2006) show a positive link between competition and innovation, as measured by R&D intensity, in a panel of OECD countries. The models proposed by these authors are linear specifications, where a change in competition is measured by exogenous changes in policy variables (Griffith et al. 2006), or by a combination of exogenous indicators (Nickell 1994). Aghion et al. (2005) abandon the linearity assumption and find evidence that the relation competition-innovation is non-linear, in the form of an inverted U-curve. (These authors measure innovation by the average number of patents in an industry). The inverted U-curve depicts a positive relation between competition and innovation at low levels of competition, and a decreasing one at high competition levels. Aghion et al. (2005) and Boone (2000) provide theoretical support to the non-linearity of the competition-innovation relationship. The central idea is that profits constitute the firms’ main incentive to innovate. In this context, competition fosters innovation by lowering pre-innovation profits more than post-innovation rents (the so-called “escape-competition” effects). Aghion et al. (2005) argues that this effect is more likely at low-levels of competition, providing an explanation for the non-linear effect found in the data. In contrast, post-innovation profits, hence firms’ incentive to innovate, are hampered by high competition. The competition-innovation issue is of great relevance to small open economies, which are typically highly specialised (at product and industry level) and, as a result, more exposed to the international competition and economic cycle. Among small countries, Luxembourg has a very small size and a high level of GDP per capita. Its economy has a strong focus on the financial services, which account for nearly one third of its GDP. Given these facts, one would expect Luxembourg’s innovation effort and competitive pressure to be quite different from those of other countries. Several international institutions, such as the OECD (Luxembourg Country Report, 2010) and the World Economic Forum (Global Competitiveness Report, 2009–2010), have highlighted weaknesses in the competitiveness of the Luxembourgish economy. The OECD notes that the lack of market competition may endanger recovery and negatively affects the country’s productivity. This evaluation is performed by looking at several indicators such as labour and product costs, product market regulations, barriers to new entrants and competition. Anecdotal evidence exists on the lack of competition in Luxembourg internal markets, but little research has been done to assess the strength of competition in Luxembourgish markets adopting formal statistical criteria. To the best of our knowledge, the only study to assess the intensity of competition in Luxembourg manufacturing and services industries is the one performed by DiMaria (2008). This author rejects the hypothesis of perfect competition in a large majority of Luxembourgish industries using National Account data from 1995 to 2006. Empirical studies on innovation are also rare and are based on Community Innovation Survey (CIS) data. One example is Asikainen (2008), which evidence a positive link between competition, innovation, and productivity. This study attempts to fill these gaps in the empirical literature using firm-level data for Luxembourg manufacturing and some key non-manufacturing sectors. Data are sourced from the Structural Business Statistics, compiled yearly by the Statec. The empirical strategy adopted in this study is largely inspired by the work of Jan Boone and by the “2-step” empirical model of Griffith et al. (2006). It involves choices on how to measure the degree of competition and innovation effort, and comprises two steps:
 
The measurement of competition. The Boone index, obtained from the estimation of a regression of profits on costs, is preferred to traditional direct measures, such as price-cost margin and Herfindhal indices, because it is better suited to the analysis of small open economies and has better theoretical properties. Indeed, Boone (2008a) shows that the PE measure is monotonic in competition, a theoretical fact that has been found to be empirically relevant by Griffith et al. (2005). The link between market structure and competition intensity is also investigated. This is done by looking at the relation between the Boone index and the number of firms in an industry, and by checking whether industries characterised by a large number of small enterprises are more competitive than those with larger firms. (The choice of the competition measure is discussed in Section 2). 
The estimation of the 
innovation equation
, which relates innovation indicators to measures of competition and several control variables. Key variables are R&D expenditures, which proxies the innovation effort, the Boone index, and a technology gap variable that describes how efficiently, on average, firms use the production inputs within an industry. Robustness of results is assessed by using an alternative measure of competition (the price-cost margin) and comparing firm- and industry-level data. R&D expenditure and patents are popular choices for measuring innovation effort in empirical studies. Here, the choice of R&D expenditure as the innovation proxy is dictated by the data available and supported by the evidence on the role of R&D in fostering innovation and technological improvements (see, for example Romer 1990; Mairesse and Mohnen 2002). This empirical strategy has been implemented by several nations involved in the project “Market incentives to innovate”, in the context of the OECD Working Party on Industry Analysis (WPIA). Using this methodology, Polder and Veldhuizen (2010) and Berube et al. (2010) support the existence of the inverted U-curve in Dutch and Canadian data at both firm and industry level. The results in this paper serve as a country specific analysis linked to the above project. The remaining of this article briefly discusses the measurement of competition (Section 2). Section 3 describes the dataset used in the analysis and discusses some issues related to industries’ classification. Section 4 presents the results from the empirical analysis of competition and innovation in Luxembourg’s manufacturing industries. Finally, Section 5 gives concluding remarks and directions for the future research.",20
12.0,1.0,"Journal of Industry, Competition and Trade",27 May 2010,https://link.springer.com/article/10.1007/s10842-010-0076-z,Does a Tougher Competition Policy Reduce or Promote Investment?,March 2012,Afonso Planas Raposo de Almeida Costa,Pedro Pita Barros,,Male,Male,Unknown,Male,"Nowadays, competition policy issues are in the spotlight. In several industries, Competition Authorities (CA) come into play, limiting and conditioning the activities of firms for the greater good of consumers and welfare in general. In recent times, the focus of economic policy has been increasingly on the protection of welfare through the fostering of innovation. The recognition and defense of the latter as the main engine driving consumer welfare in the economy is at the center of this change in stance. Thus, the relationship between investment and competition policy is one that is really relevant for the aforementioned discussion. Of the many influences CAs have on the firms’ decisions, we address the simple question of how an increase in the toughness of competition policy affects the overall level of investment in a given industry. Results indicate that investment is always reduced by an increase in the toughness of the CA’s actions. The type of investments we consider are only cost-influencing operational processes, and so do not innovate the product in terms of its quality, diversity, or in any other way. We use two models, differing in the type of investment firms make, to address the issue in both monopoly and oligopoly. The first model is one in which firms invest to reduce their own costs, whereas in the second model the investment made increases the costs of the other firms in the industry. The reduction in the level of investment has different implications in each setting: in the first case, the reduction in investment per se is bad from the point of view of productive efficiency, because in leads to an increase in production costs; on the other hand, for the anti-competitive investment case, the reduction in the level of investment is good from the point of view of the efficiency of production and resource allocation (fewer resources wasted in anti-competitive practices). Afterwards, we show that the evolution of prices/quantities and welfare-related measures will vary across models. For illustrative purposes, numerical examples are presented. The cost-reducing investment case produces ambiguous welfare results that depend on the investment parameters pertaining to each firm, whereas for the anti-competitive investment case, the results seem to point out in the direction of an unambiguous increase in welfare with increases in the toughness of the competition policy. The organization of the paper is done as follows. Section 2 presents a literature review, followed by the presentation of the models in Section 3. The ensuing Section 4 explores the link between the toughness of competition policy and the level of investment, prices and welfare-related measures. Afterwards, free entry will be addressed in Section 5 and social optimality considerations are explored in Section 6. The conclusion will wrap up the basic insights, while focusing on the possible limitations and further possible improvements to the analysis.",1
12.0,1.0,"Journal of Industry, Competition and Trade",27 December 2011,https://link.springer.com/article/10.1007/s10842-011-0119-0,Impact of Horizontal Mergers on Research & Development and Patenting: Evidence from Merger Challenges in the U.S.,March 2012,Walter G. Park,Ralph Sonenshine,,Male,Male,Unknown,Male,"The purpose of this paper is to provide an empirical analysis of the effects of recent horizontal mergers on the research and development (R&D) expenditures and patent grants of large U.S. companies. Since the drafting of the Gilbert and Sunshine innovation markets approach and the Department of Justice (DOJ) and Federal Trade Commission (FTC) Antitrust Guidelines for the Licensing of Intellectual Property, it is a practice of antitrust policy to examine the innovation consequences of mergers.Footnote 1 In many merger review proceedings, regulators must ask not only whether a proposed combination will likely affect consumer welfare and competition, but also whether it will reduce innovation in a relevant innovation market. The innovation market construct has stirred some controversy (see Carlton and Gertner 2003). First, the harm to competition is anticipatory. Current R&D, for example, affects future new products or improvements of existing goods. Thus, any merger impacts on research and development affect future product markets—or affect potential competition. Thus one option is to challenge market conduct later, to see if product markets become concentrated, rather than take anticipatory action. One response to this is that waiting is not optimal if the harm to innovation affects the path of product market development. Another response is that if the innovation market is concentrated, innovation can be harmed if firms exercise market power over the products of R&D and limit the diffusion of important technological inputs, or if firms scale back on R&D projects because they face weaker pressures to compete. A second issue related to incorporating innovation considerations in antitrust policy is that the relationship between market concentration and innovation is not firmly established. Economic theory provides for different possibilities. For example, leading work by Schumpeter (1950) has argued that innovation increases with market concentration and firm size, while Arrow (1962) contended that incentives to innovate are greater under competition than under monopoly. Our objective in this paper is to address this second issue concerning innovation markets and contribute to the empirical literature on innovation and market concentration. In this paper, we do not measure market concentration directly. Instead we use merger challenges by policy authorities to help us identify cases of concerns about increased market concentration. The authorities follow specific guidelines to determine the mergers that are to be challenged, including criteria related to the scope of the market, ease of entry or collusion, or any efficiency gains; they look at both the levels and expected changes in the Herfindahl-Hirschman Index (HHI) and consider the degree of overlap in the product markets of the acquirer and acquiree. Thus, to infer the effect of market concentration on innovation, we compare the innovation behavior of a sample of R&D-intensive challenged mergers to a similar sample of non-challenged mergers and to a control group of non-merged firms. We exploit the fact that the sample of horizontal mergers challenged by the antitrust authorities consists of those mergers deemed by them to result in a significant increase in market concentration. To our knowledge, this type of sample selection analysis has not been done in previous work. The paper is organized as follows: the next section reviews previous theory and evidence. Section 3 discusses our empirical approach, and Section 4 discusses our dataset, along with some descriptive statistics. Section 5 contains our main results, and Section 6 concludes. Overall, we find substantial differences in the innovation behavior of challenged merger firms and non-challenged merger firms. Compared to a control group of non-merged firms, firms whose mergers were challenged have a statistically significant lower growth in R&D and patenting post-merger, while firms whose mergers were not challenged exhibit no appreciable difference in post-merger R&D and patenting growth compared to a control group.",12
12.0,2.0,"Journal of Industry, Competition and Trade",09 December 2010,https://link.springer.com/article/10.1007/s10842-010-0093-y,Environmental Tax and Public Ownership in Vertically Related Markets,June 2012,Shuichi Ohori,,,Male,Unknown,Unknown,Male,"In many developing and transitioning countries, environmental policies have been imposed on state-owned (or partially privatized) enterprises in vertically related markets, particularly in the energy, mining, and steel industries. Historically, commodities in such industries were provided by regulated, vertically integrated monopolies. Since the 1980s, however, international movements toward economic deregulation and environmental protection have called for the privatization of state-owned enterprises and the implementation of environmental policies.Footnote 1 The problem of the optimal level of public ownership becomes relevant in this context. In addition, poor environmental quality and investments by public enterprises have been revealed. Then, environmental policies have often been imposed on upstream firms in order to control the pollution resulting from production. The purpose of this paper is to consider environmental and privatization policies in vertically separated markets that include one partially privatized (or fully state-owned) upstream producer firm and two private downstream commodity sellers. Our analysis is significant for the following reasons. First, in the real world, producers and sellers are usually different entities, as stated above. Second, it is observed that the governments of certain countries, such as Belarus, China, Malaysia, and Russia, have not allowed full privatization and have set upper limits for private ownership. Interestingly, private ownership restrictions have been imposed on highly polluting industries, such as energy, mining, and steel industries. Such regulation may affect the environment. Third, since pollutants such as those released into air and water are by-products of upstream raw product industries, governments are able to control pollution in the upstream market while taking a firm’s optimal degree of public ownership into account. Once the relationship between two such different types of firms is considered, the distinction may have important implications for optimal environmental and privatization policies. Privatization affects the extent to which an environmental policy can reduce pollution. In order to understand how environmental policy in the privatization process of vertically related markets can be optimally adjusted, our study analyzes the specific characteristics of environmental tax and privatization. Previous studies have focused on privatization and environmental policies. Using a simple model, Beladi and Chao (2006) highlight the possibility of an increase in environmental damage caused by the privatization of a business into a monopoly. Bárcena-Ruiz and Garzón (2006) consider the effect of privatization when the government implements an environmental tax under a mixed oligopoly. Kato (2006) analyzes the welfare effects of tradable emission permits under a mixed oligopoly. Ohori (2006) observes that in an international duopolistic market, the government should partially privatize the firm and set an environmental tax rate that is lower than the amount of marginal environmental damage. Naito and Ogawa (2009) examine the effectiveness of command-and-control and emission tax regulations under a mixed duopoly, in which a private firm competes with a partially privatized firm. Wang and Wang (2009) consider the effects of privatization on environmental damage and social welfare in a mixed duopolistic framework comprising differentiated products. Reflecting the case of Taiwan’s steel industry, Wang et al. (2009) investigate the effect of privatization policy under the equilibrium environmental tax. Environmental policy in vertically related industries has also been recently examined. Hamilton and Requate (2004) consider a case in which an environmental policy is set on the polluting input produced by an upstream firm, while downstream goods are traded in the international market. Sugeta and Matsumoto (2007) analyze the effects of upstream and downstream taxes to control pollution under input price discrimination. Canton et al. (2008) and Greaker and Rosendahl (2008) consider a case in which upstream firms sell environmental goods to downstream polluting firms. The present paper extends Beladi and Chao’s (2006) findings to the case of a vertically separated market model. However, several elements of the present study differ from those of Beladi and Chao. First, our paper assumes that production cost and environmental damage functions are general forms, whereas in Beladi and Chao, these functions are assumed to be linear. Second, in our paper, the producer determines the abatement (emissions) level and output independently, whereas Beladi and Chao assume that pollution is proportional to output and the firm cannot reduce pollution except by reducing output. Third, we consider the effect of privatization on social welfare and the optimal level of privatization, whereas Beladi and Chao do not. Therefore, our results differ from those obtained by Beladi and Chao as well as those reported in the conventional literature on environmental policy under imperfect competition. While the public firm in a mixed oligopoly is assumed to maximize social welfare in most of the theoretical literature on environmental policy and privatization (Kato 2006; Ohori 2006; Naito and Ogawa 2009; Wang and Wang 2009), this paper assumes that the upstream market is monopolistic and that the public producer does not take environmental damage into account. The following reason underlies this assumption. It is often observed that upstream producers in transition economies are monopolistic and publicly owned firms. In addition, the collapse of planned-economic systems indicates poor environmental quality and investments by public enterprises, thus generating a high rate of pollution. This means that many state-owned firms have operated without attention to long-term sustainability, and that the enforcement of pollution abatement requisites associated with weak governance has been either weak or nonexistent. Hence, as in Beladi and Chao (2006), our analysis focuses on the publicly owned and highly polluting monopolistic producer. In other words, it is assumed that the pure public producer maximizes social welfare without regard to the environmental effect. Our first main result is that the optimal environmental tax rate equals the marginal environmental damage, thus satisfying the Pigouvian level. This finding contrasts with the conventional environmental policy result that the optimal environmental tax is lower than marginal environmental costs under imperfect competition.Footnote 2 Our second main result indicates that the government ought not to privatize the producer firm when it can set the environmental tax. In other words, privatization decreases social welfare under the optimal environmental tax. These findings imply that if both instruments are available under vertically separated markets, the environmental tax can be used for the full internalization of pollution, on the one hand, and nationalization works as the implicit production subsidy, on the other. Our paper is organized as follows. Section 2 explains the model. Section 3 presents the results of our general analysis. Section 4 concludes the study and suggests options for further development of our research.",9
12.0,2.0,"Journal of Industry, Competition and Trade",09 November 2010,https://link.springer.com/article/10.1007/s10842-010-0090-1,Product Market Competition and Lobbying Coordination in the U.S. Mobile Telecommunications Industry,June 2012,Tomaso Duso,Astrid Jung,,Male,Female,Unknown,Mix,,
12.0,2.0,"Journal of Industry, Competition and Trade",22 January 2011,https://link.springer.com/article/10.1007/s10842-011-0095-4,Maintaining New Markets: Explaining Antitrust Enforcement in Central and Eastern Europe,June 2012,Robert M. Feinberg,Mieke Meurs,Kara M. Reynolds,Male,Female,Female,Mix,,
12.0,2.0,"Journal of Industry, Competition and Trade",20 January 2011,https://link.springer.com/article/10.1007/s10842-010-0094-x,The Two Faces of R&D: Does Firm Absorptive Capacity Matter?,June 2012,Andreas Poldahl,,,Male,Unknown,Unknown,Male,"The accumulation of knowledge, in a broad sense, is the main factor behind productivity growth. Increases of knowledge may take different forms, such as new and better products, more efficient production techniques or improved methods of organising production, marketing or exporting. The improvements stem from many sources, some may be internal and some may be external to the firm. External knowledge may be dispersed among firms either through purchase or licensing, or as spillovers.Footnote 1
 Griliches (1995) made a clear distinction between rent and knowledge spillovers. Rent spillovers are likely to be associated with trade in intermediate goods, when producers of knowledge and innovations are unable to charge the full quality price because of competition market pressure. This result in a productivity increase measured in the user industry. Knowledge spillovers, on the other hand, may follow many channels. Some of it may be transferred across firms following e.g. I/O channels, labour turnover or just being in the air. Bernstein and Nadiri (1988) classify knowledge spillovers as vertical or horizontal. Horizontal spillovers occur between competitors, and vertical spillovers flow between firms in different sectors. We will focus on spillovers following I/O-links and within-industry catching-up. It is reasonable to assume that spillovers captured through I/O links are to a large extent rent spillovers. However, we are not able to trace spillovers generated by labour mobility and those related to the geographical distance between the source and user of new knowledge. External knowledge spillovers may be created from R&D and spread via I/O flows to downstream firms. However, the actual amount of knowledge absorbed by receiving firms also depends on firms’ own R&D. The R&D efforts therefore play a dual role and one may talk of “the two faces of R&D”. That is, R&D activity does not only stimulate innovation but also enhances firms’ ability to assimilate outside knowledge (see Cohen and Levinthal 1989). The second face of R&D is called the absorptive capacity and is considered to be very important, particularly for assessing the effective contribution of spillovers from others. The absorptive capacity also includes the firm’s ability to exploit outside knowledge of a more intermediate sort, such as basic research findings that provide the basis for subsequent applied research and development. Absorptive capacity can be enhanced in a variety of ways. Studies have shown that firms’ absorptive capacity may be created as a by-product of a firm’s own R&D investments (see e.g. Tilton 1971, Allen 1977 and Mowery 1983). Another suggestion is that absorptive capacity may be developed as a by-product of a firm’s own manufacturing operations. Abernathy (1978) and Rosenberg (1982) have observed that direct involvement in manufacturing makes a firm more able to recognize and exploit new information. Production experience provides firms with information necessary to identify, evaluate and implement more efficient methods of production. In addition, firms invest and build up their absorptive capacity when their own employees are sent for training. The vast majority of literature on the topic of absorptive capacity is focused on how firms’ own R&D interacts with FDI and trade related spillovers. Most of these studies are found to disregard the significance of analyzing and measuring absorptive capacity effects via different forms of trade- or FDI spillovers. Since Sweden is an open economy, a central issue in this context is the impact of R&D spillovers from domestic- as well as international sources. Therefore, by analysing the influences of Swedish firms’ absorptive capacity evaluated through these kinds of different sources of new knowledge, we may provide some new direction for policy reforms in the Swedish economy. Perhaps the government should promote firms by giving them subsidies to establish their R&D activities in Sweden in order to gain from domestic as well as international R&D spillovers. The main objective of this paper is to analyse the influences of the firms’ absorptive capacities via different forms of R&D spillovers on Swedish manufacturing firms’ productivity growth. The second part of the objective concerns the relative role of the firms’ absorptive capacities. More specifically; we are analysing whether the productive effects of absorptive capacities may differ through different sources of R&D spillovers (domestic as well as international). The paper is organised as follows: The theoretical model and its extensions are presented in section two. In section three, we discuss the data. The fourth and fifth sections provide the results and conclusions. Papers analyzing absorptive capacity indicate that the term absorptive capacity is not only used in economic literature but is also frequently cited in management and organization literature. The literature defines the absorptive capacity as the limit to the rate or quantity of scientific or technological information that a firm can absorb. If such limits exist, they provide one explanation for firms to develop internal R&D capacities. R&D departments can not only conduct development along lines they are already familiar with, but they have formal training and external professional connections that make it possible for them to evaluate and incorporate externally generated technical knowledge into the firm better than others in the firm (cf. Econterms). The concept of the “two faces of R&D” was first established by Cohen and Levinthal (1989) in the classic article “Innovation and Learning”. They discussed and offered many theoretical implication of the dual role of R&D. Their research points to the fact that learning and thus technology adoption is affected by the character of the knowledge inputs. They further conjecture that an innovation which is purely capital embodied is less costly to adopt than more disembodied innovations that require more complementary internal effort and more pre-existing expertise in an area. Cohen and Levinthal assert that a product innovation developed on the basis of a well-established underlying knowledge base will diffuse more quickly among users than one grounded in a more recently developed body of scientific or technological knowledge. Griffith et al. (2000) use a panel of industries across 12 OECD countries to investigate whether domestic R&D enhances absorptive capacity. They find that domestic R&D facilitates technology catch-up. Likewise, a study of the Norwegian business sector by Grünfeld (2002) analyses the importance of absorptive capacity effects, claiming that positive contribution from R&D spillovers is an increasing function of the R&D activities carried out by economic agents. The paper found strong support for domestic as well as imported R&D spillovers but no spillovers through foreign direct investments. The absorptive capacity effect enhances the productivity growth when R&D spillovers come through imports, but no such effects exist when spillovers occur through domestic intermediaries. Karpaty and Lundberg (2004) investigated productivity effects, FDI spillovers and absorptive capacity for Swedish manufacturing firms 1990–2000. In addition to a positive contribution of FDI spillovers on productivity level, the paper found evidence for firm R&D enhancing the absorptive capacity of outside technology. The interactions of firms own R&D investments and industry- and region-specific FDI spillovers are positive and significant. Another contribution concerning the topics of productive FDI spillovers and related absorptive capacity was found in the Haskel et al. (2002) study of UK manufacturing firms 1973–1992. Instead of using a direct measure of absorptive capacity they split the sample of firms into three categories representing low, medium and high R&D percentiles by using information on three performance measures; skill intensity, TFP and employment. They found that the presence of foreign-owned firms enhances domestic plants’ TFP. However, measures of foreign direct investments are found to be more important for plants at the lower end of the performance distribution. Greis et al. (2001) investigated the potential for absorptive capacity to enhance the development of new and better modem products in the computer modem industry. Their results indicate that the relationship between absorptive capacity and new product performance is nonlinear. An inverted-U shape relationship suggests diminishing returns for absorptive capacity. There are few empirical papers that explore the contribution of absorptive capacity within transition economies. One exception is Kinoshita (2001). He uses a firm level panel data set on manufacturing sectors in the Czech Republic 1995–1998 and investigates the relative importance of two faces of R&D for firms’ productivity assuming that knowledge flows occur through foreign direct investments. Kinoshita (2001) found the rate of return of investments in R&D to be about 14%. By including the absorptive capacity effects in his analysis, the direct effects of firms’ own R&D becomes less important for productivity growth. It is found that those firms that engages in R&D activity benefit more from technology spillovers through FDI and also grows faster. Mancusi (2004) analyzed six industrialised countriesFootnote 2; but measured the absorptive capacity in terms of self citations. She provides assessment of the effects of national and international knowledge spillovers on innovation at the sector level covering the period 1981–1995. The implied pattern of knowledge spillovers is through domestic- and international patent citation. International spillovers are found to increase the country’s industry-specific innovative productivity. The empirical results show that absorptive capacity increases the elasticity of a country’s innovation to both domestic and international spillovers. Deeds (2001) also used self-citation to measure absorptive capacity using a sample of 80 public pharmaceutical biotechnology firms’ performance. The co-citation index was constructed using citations of scientific publications. Deeds (2001) found a strong and positive relationship between the wealth of pharmaceutical companies and their co-citations. A slightly different approach is taken by Nieto and Quevedo (2005) to construct a measure of absorptive capacity. The measure is very much in line with the proposal of Cohen and Levinthal (1990), where qualitative factorsFootnote 3 affecting the absorptive capacity within the organisation are captured. Controlling for industrial structural variables such as technological opportunity and knowledge spillovers, their measure of absorptive capacity proves to be positively correlated with the degree of innovation efforts among 406 Spanish firms. In contrast to the relevant literature discussed above, the notion of absorptive capacity in this paper is found to be very similar to the one used in Griffith et.al, Cohen & Levinthal and Grűnfeld. The main departing point is in the modelling of the dual effects of firms’ own R&D on productivity growth. We use a nonlinear absorptive capacity construction as proposed and postulated in Cohen & Levinthal. Simple linear absorptive capacity effects used and analysed in the Griffith et.al analysis are of minor importance in this paper and therefore left out for further investigation.",2
12.0,2.0,"Journal of Industry, Competition and Trade",16 December 2010,https://link.springer.com/article/10.1007/s10842-010-0092-z,Heterogeneous Distributions of Firms Sustained by Innovation Dynamics—A Model with Empirical Illustrations and Analysis,June 2012,Martin Andersson,Börje Johansson,,Male,Male,Unknown,Male,"A generic feature of product groups is that they comprise a whole set of product varieties. Within such product groups we can observe that some firms supply many varieties to many markets, while co-existing with firms supplying one or just a few varieties to a limited number of markets. These observations relate to the established literature on skewed firm size distributions (see e.g. Ijiri and Simon 1977; Sutton 1997; Axtell 2001; Coad 2010). While there are several recent contributions that introduce firm-level heterogeneity in models of e.g. international trade (Melitz 2003; Bernard et al 2003) and new economic geography (e.g. Baldwin and Okubo 2006), these often take heterogeneity as given and do not inquire about the sources of heterogeneity. Yet, as Griliches and Mairesse (1995, p.23) remark; “we need a richer theoretical framework to help us understand why firms are different, not only in their capital-labor ratios, but also in the product mix that they produce, the quality of their workforce, the technologies they use, their organizational structures, the markets that they serve.” The purpose of this paper is to introduce a parsimonious model that can accommodate heterogeneity in firm size in a setting where exit and entry of varieties are frequent phenomena for both small and large firms. A second purpose is to demonstrate the empirical relevance of the model with the help of firm-level data which identify variety triplets, specifying firm, destination-market and variety. Any firm size distribution is the outcome of an underlying process of firm growth dynamics that involves entry and exit of firms as well as of their product varieties and markets (cf. Bottazzi and Secchi 2006; Matia et al 2004).Footnote 1 The model in this paper explicitly links firm growth to the introduction of new variety-destination pairs (a combination of a variety and a market) in firms’ supply patterns. When a firm innovates and adds a new variety-destination pair it implies a novel variety triplet. The general idea is that the size of a firm corresponds to its number of variety and destination combinations. The model assigns a fundamental role to entrepreneurship and innovativeness of both existing and potential firms, where innovation efforts allow firms to enter new markets and expand their spectrum of variety supply, as argued by Kortum (2008). The model formulates dynamics of entry and exit of product varieties and allows for the possibility of multi-variety and multi-market firms, representing two forms of scope economies. A new variety may enter a market through the establishment of a new single-variety firm, or the expansion of an incumbent firm’s product line. In a similar fashion, the exit of a variety can imply the exit of a firm (single-variety firm) or the contraction of the supply mix of an existing multi-variety firm. In this way, the model encompasses entry and exit of firms as well as growth dynamics of existing firms through the entry and exit of the variety-destination pairs in their product and distribution mix. The empirical part of the paper confronts the model with firm-level data that makes it possible to empirically capture and assess both forms of dynamics. Hence, the analysis goes beyond the typical focus on firm size in terms of employees. Instead, we study firm size in terms of varieties and markets and assess firm dynamics by studying changes in the supply pattern of existing firms in combination with entry/exit of firms. In most empirical studies, the entry and exit of firms may be observed, but the dynamics of the supply pattern of incumbents typically are not. The model is based on the monopolistic competition framework of Dixit and Stiglitz (1977), but adds three main elements: (i) stochastic firm-level innovation, (ii) stochastic ageing of varieties, and (iii) scope economies arising from our assumptions of innovation costs. Moreover, there are several different markets, each associated with entry costs. Ageing of varieties is introduced in such a way that customers in a given market lose interest of a certain variety as given by a stochastic process. This extension implies that the taste for variety also gets a temporal dimension and introduces taste for novelty. In this setting a firm grows by introducing new variety triplets, stimulated by innovation ideas which specify type of variety and destination market. This reflects Schumpeter’s (1934) observation that innovation includes novelty of both variety and market. The arrival rate of innovation ideas to each firm is determined by a firm-specific and state-dependent stochastic process, and firm heterogeneity arises in course of this process. State-dependence is modeled in such a way that the arrival rate of innovation ideas to a firm depends in a positive manner on the firms’ variety stock, i.e. the stock of already materialized ideas. As in Klette and Kortum (2004), one may think of the variety stock as reflecting a firm’s cumulated knowledge. We show that this model under given conditions predicts a stationary distribution of firms with different numbers of variety-destination pairs. Firms that only supply one variety to one market will co-exist with large multi-variety and multi-market firms. This invariant distribution is sustained by a simultaneous process of entry and exit of variety-destination pairs of incumbents as well as new firms and exit of established ones. With the described firm-level innovation process, a persistent skewed firm size distribution is thus associated with two significant forms of micro-dynamics: turnover of variety triplets associated with innovations, and variety triplets that disappear from customers’ demand such that firms lose sales or exit. The empirical analysis makes use of detailed export data on Swedish firms’, which for each firm provide information about the actual sales of different product varieties in different markets over time. Export data lack detailed information about the supply patterns on the domestic market, but are rich in detail for all supply flows to foreign countries. For a small open economy like Sweden where, in international comparisons, a large fraction of firms are engaged in international trade (Andersson et al. 2008), we argue that for our purpose the downside of the lack of information about domestic flows is outweighed by the richness of the export data. We apply these data to first demonstrate with frequency plots and transition probability analysis that the distribution of firms according to their variety stock is skewed and highly persistent over time. As predicted by the model, however, this invariance in the distribution is associated with significant gross dynamics in terms of entry and exit of variety-destination pairs of incumbent firms’ sales patterns, as well as entry and exit of firms. Secondly, we estimate an empirical model to verify that arrival rates of innovation ideas are different across firms and state-dependent. For this purpose we set-up a Poisson model in which the number of novel variety-destination pairs of each firm is explained by firm attributes including the variety stock. This exercise confirms that the rate of introduction of new variety-destination pairs of a firm is positively associated with its variety stock, supporting the assumption that the variety stock of a firm reflects its accumulated knowledge. Moreover, the analysis also shows that many of the firm attributes and milieu characteristics suggested by the empirical literature on innovating firms come out as important predictors of firms’ rate of introduction of new variety-destination pairs. In view of this, state dependence appears to include the state of the firm and the state of its local economic milieu. The remainder of the paper is organized as follows: Section 2 presents the model. We first discuss the core properties of the model and relate it to previous models. Then we present the structure of fixed and variable cost of each supplier and of each delivery flow, while adding the model of demand for varieties in each destination market. Finally an equilibrium concept is introduced in a discussion of market solutions and the nature of the firm-size distribution. Section 3 presents data and makes assessments on the basis of descriptive statistics. Section 4 provides the regression results and evaluates the findings. Section 5 concludes.",5
12.0,3.0,"Journal of Industry, Competition and Trade",19 February 2011,https://link.springer.com/article/10.1007/s10842-011-0097-2,Duopoly Pricing Under ‘Private Knowledge’ of Product Differentiation,September 2012,Carlos A. Ulibarri,,,Male,Unknown,Unknown,Male,"The Bertrand model of price competition has been extensively analyzed in game-theoretic analysis of product differentiation. The necessary and sufficient conditions for Nash (1950) and Bayesian-Nash equilibria are described in Vives (1990, 1999). In brief the Nash equilibrium is guaranteed in pure strategies under complete information but not under asymmetric information. For the latter, a ‘Bayesian Nash solution’ in pure strategies may be established, or possibly mixed strategies with players randomizing over a certain range of prices. The present study uses an asymmetric information game (AIG) model to examine the Bayesian-Nash price equilibrium (BNE prices) assuming firms have private knowledge of the degree of product differentiation. In this setting we show information sharing is a ‘first-best’ strategy for ‘value maximizing’ duopoly firms. For example, the firms could agree to share product design information through a marketing or trade association. Industrial organization models that incorporate private information are particularly useful in examining problems of oligopoly and imperfect competition, including the incentives to reveal cost or demand information (Milgrom and Roberts 1987). In particular, the information sharing problem in oligopoly/duopoly settings has been examined extensively in the trade association literature. Notable cases include two-stage games with Bertrand or Cournot firms competing under uncertainty about the industry’s demand parameter (common knowledge to all participants), or a cost parameter that is firm-specific (private values).Footnote 1 The present study considers a differentiated product market where duopoly firms are uncertain about each other’s degree of product differentiation, and thus make strategic pricing decisions under asymmetric information over product type. The normal-form representation of Bertrand competition is modeled assuming risk-averse firms move simultaneously in setting prices of differentiated products. The analysis assumes each firm has private information over the degree of product differentiation, and that this is common knowledge. The firms then choose their first-best prices if they are sufficiently compensated for risk-taking, as measured by their ‘certainty-equivalent’ profit \( E[C{E_i}] = {\bar{\pi }_i} - {\rho_i}; \) that is, the expected profit minus the risk premium. Given the utility from the certainty-equivalent profit equals the expected utility from the random profit, \( U({\bar{\pi }_i} - {\rho_i}) = E[U({\tilde{\pi }_i})], \) the risk premiums reflect compensation for incomplete information over product type; or in other words, the maximum firms are willing–to-pay to convert random profits into deterministic profits.Footnote 2
 The study proceeds as follows. Section 2 constructs a normal-form representation of the duopoly industry, deriving BNE prices which maximize ‘certainty-equivalent’ profits. Section 3 examines the comparative statics of the model for substitute and complement products. Section 4 interprets the practical implications of the study relative to the literature.",
12.0,3.0,"Journal of Industry, Competition and Trade",06 April 2011,https://link.springer.com/article/10.1007/s10842-011-0099-0,Maximum-Revenue and Optimum-Welfare Tariffs in International Mixed Duopoly: Does the Order of Firms’ Move Matter?,September 2012,Leonard F. S. Wang,Jen-yao Lee,Chin-shu Huang,Male,Unknown,Unknown,Male,"The issue of maximum-revenue tariff versus optimum-welfare tariff is interesting and has gained attention because the tariffs revenue is an important income source of developing countries before its efficient tax system is built. However, those countries may adjust its goal from maximum-revenue to optimum-welfare along with the economic improvement and the need for fiscal reform. In a traditional tariff analysis, Johnson (1951–1952) argued that the maximum-revenue tariff is higher than the optimum-welfare tariff because a ‘large’ country could change the terms of trade in order to raise its social welfare level. From the strategic trade aspect, Brander and Spencer (1984) have shown that government could improve its terms of trade through tariffs in an oligopoly market and take a leading position to transfer foreign firm’s revenue to domestic firm by using tariff as a strategic instrument. Collie (1991) demonstrated that in a quantity competition oligopoly market with a linear demand function and an asymmetric marginal cost, the maximum-revenue tariff will be raised up if domestic marginal cost is higher, and the optimum-welfare tariff will be higher than the maximum-revenue tariff if the domestic firm’s marginal cost is relatively lower than that of the foreign firm. Larue and Gervais (2002) allowed asymmetric numbers of domestic and importing firms, and showed that if the numbers of domestic firms and importing firms are the same, the maximum-revenue tariff is higher than the optimum-welfare tariff. Recently, Clarke and Collie (2006) found that in a Bertrand price competition model, the optimum-welfare tariff is higher than the maximum-revenue tariff when the product is highly substitutable. Clarke and Collie (2008) have shown that in a game between two exporting countries, both countries may be better off if they both delegate decision to policymakers who maximize tax revenue rather than welfare. However, both countries delegating to policymakers who maximize revenue is not necessarily a Nash equilibrium. Wang et al. (2009) introduced market share delegation in a trade duopoly context, and demonstrated that the home government unambiguously imposes a higher optimum-welfare tariff than maximum-revenue regardless of the form of delegation. Wang et al. (2010) re-examined the tariff ranking issue under a linear mixed oligopoly model with foreign competitors and asymmetric costs. In particular, they demonstrated that under Cournot competition and Stackelberg public follower, when the sizes of domestic private and foreign private firms become more unequally distributed, the optimum-welfare tariff will exceed the maximum-revenue tariff; however, under Stackelberg public follower, the maximum-revenue tariff may be higher than the optimum-welfare tariff. The above papers addressed the tariff issue either in pure oligopoly or mixed oligopoly frameworks without considering privatization policy. Maw (2002) reviewed the empirical evidence and analyzed the justifications that have been put forward for adopting partial privatization in transitional economies.Footnote 1 Chang (2005) adopted Matsumura’s (1998) model to analyze the optimal trade and privatization policies in an international mixed duopoly with cost asymmetry, and discussed how the degree of cost asymmetry between domestic and foreign firms affects the ownership structure in the context of strategic trade policy. Chao and Yu (2006) used Mastsumura’s partial privatization model (1998) to examine the effect of partial privatization or foreign competition on optimal tariffs and found that foreign competition lowers the optimal tariff rate but partial privatization raises it. Van Long and Säthler (2009) established a mixed duopoly model with partial privatization to discuss how state ownership impacts the optimal import tariff and export subsidy, and found that the optimal tariff is independent of the degree of state ownership but the optimal subsidy is negatively related to the degree of state ownership. The above papers concern only how the degree of partial privatization affects optimal tariff. Wang and Lee (2010) show that when the marginal cost of the privatized firm exceeds a critical value, the maximum-revenue tariff is higher than the optimum-welfare tariff in the presence of partial privatization. Otherwise, the optimum-welfare tariff is higher than the maximum-revenue tariff. In this paper we examine Cournot and two Stackelberg cases: firstly, we consider the effect of privatization on the priority of the maximum-revenue tariff and the optimum-welfare tariff in a mixed Cournot oligopoly with partial privatization and foreign competition. We find that the optimum-welfare tariff is higher than the maximum-revenue tariff if the degree of privatization is sufficiently high; otherwise, the maximum-revenue tariff will be higher than the optimum-welfare tariff. Next, we explore two Stackelberg cases, one is the mode where the public firm produces first and then the private firm produces (public leadership). Another one is that the private firm produces first and then the public firm produces (private leadership). Under private leadership scenario, the public firm plays a complementary role of the private sector, while the public firm plays a more active role in the product market under public leadership scenario. Pal and White (1998) showed that when private firms are domestic, private leadership is better than the public leadership for social welfare, while Matsumura (2003b) showed that when private firms are foreign, public leadership is better than private leadership for domestic social surplus. They ignored the ranking issue of tariff policy. We find that when the marginal cost of privatized firm is higher than a critical value, the optimum-welfare tariff will be lower than the maximum-revenue tariff regardless of the order of firm’s move. This paper is organized as follows. Basic model is provided in Section 2. Section 3 contains the analysis of tariff ranking under different order of moves between privatized firm and foreign private firm. Specifically, it examines the order of moves in the Cournot and Stackelberg models drawing on earlier work in Wang and Lee (2010). Section 4 concludes the paper.",4
12.0,3.0,"Journal of Industry, Competition and Trade",06 April 2011,https://link.springer.com/article/10.1007/s10842-011-0098-1,Distribution Channel Management in an Internet Age: Equilibrium and Social Welfare,September 2012,Haiyan Wang,Tatsuhiko Nariu,,Unknown,Male,Unknown,Male,"The rapid development of information technology has led to widespread use of the Internet. Consequently, the number of on-line transactions (also referred to as electronic commerce or e-commerce) has increased significantly since the mid-1990s. According to “The Investigation of Current Status and Market Size of Electronic Commerce”,Footnote 1 the Japanese e-commerce market was worth 152 trillion yen in 2006. Business-to-consumer e-commerce as a percentage of total retail sales was 2.03% in Japan and 4.37% in the U. S. There are two types of retailer in the e-commerce market; (1) pure on-line retailers that only sell goods over the Internet, and (2) brick-and-click retailers who sell goods both on-line and off-line (i.e., through the brick-and-mortar store). The number of brick-and-click retailers has increased dramatically during the past few years.Footnote 2 In this paper, we use the term “e-retailer” to refer to a retailer of either type regardless of whether it owns a physical store. Our aim here is to clarify how a manufacturer would construct its distribution channel in a setting where e-retailers and brick-and-mortar retailers coexist, and explore the impact that the manufacturer’s behavior exerts on consumer and social welfare. Previous theoretical analyses of competition between e-retailers and brick-and-mortar retailers include Balasubramanian (1998), Bouckaert (2000) and Cheng and Nault (2007).Footnote 3 In the same vein, Chiang et al. (2003) and Kumar and Ruan (2006) concentrated on the factors necessary for adding an e-channel by a manufacturer but did not analyze its impact on social welfare. Nakayama (2007) argued that welfare would be worse off if the manufacturer’s wholesale price for the brick-and-mortar retailer remained unaffected by the addition of an e-channel. But that condition is not necessarily sure. Our approach is to remove the assumption that a manufacturer’s wholesale price is unaffected by the addition of an e-channel, and consider the conditions for adding an e-channel along with the welfare effects of such behavior when the wholesale price is endogenous. First, we find that the manufacturer will choose to add an e-channel only if consumers’ travel costs are high and e-retailers’ delivery costs are low. Second, such double-channel operation will decrease consumer surplus when the market is fully covered by brick-and-mortar retailers. If instead the market is partially covered, it will not decrease any consumer’s surplus even if delivery costs are high. Third, if delivery costs are low, social welfare is improved by the profitable addition of an e-channel even if the consumer surplus is reduced by it. Finally, double-channel operation could be Pareto superior even if delivery costs are high. The remainder of this paper is organized as follows. In the next section, we present the model and analyze the situation where only brick-and-mortar retailers exist. In section 3, we elaborate the necessary conditions for adding an e-channel. In section 4, the effects on consumer surplus and social welfare are addressed. Finally, a brief summary and the experimental implication are presented in section 5.",5
12.0,3.0,"Journal of Industry, Competition and Trade",27 April 2011,https://link.springer.com/article/10.1007/s10842-011-0100-y,Enhancing the Efficiency of Water Supply—Product Market Competition Versus Trade,September 2012,Reto Foellmi,Urs Meister,,Male,Male,Unknown,Male,"The existing organization of piped water supply in Europe is very heterogeneous. In most countries, water supply is organized at a local level. Historically, the communities are responsible for water supply systems, such as treatment and storage facilities or pipe networks, because the water supply industry is widely viewed as a natural monopoly. In addition, local authorities choose the form of organization and the permitted degree of private sector participation. Due to these decentralized structures, water supply in most European countries is characterized by a high number of locally operating monopolies. Hence, there are more than 6,500 local operators in Germany, approximately 8,000 in Italy, 3,000 in Switzerland and 2,000 in Sweden (see EEB 2002, p. 24–28). Local operators often face very different marginal production costs due to differences in production scales, the use of different raw water resources, such as surface, ground or spring water, and different conditions of network infrastructure (see Correia and Kraemer 1997). As a result, retail prices vary significantly—even between adjacent water utilities (see Zschille et al. 2009). These cost and price differentials indicate overall production inefficiency for locally organized water supply industries. Hence, regulatory authorities or consumers in high-priced areas may ask for measures that improve productivity of supply. In fact, in 2009, the German Monopoly Commission strongly criticized regional price differentials and inefficiencies in the water supply and claimed institutional adjustments are needed (see Monopolkommission 2009). In its report, the authority proposed regulatory measures that increase the municipality’s incentives to merge neighboring water utilities. Moreover, the Monopoly Commission recommended outsourcing and competition to enhance the efficiency of water supply. There are four prima facie ways to improve productive efficiency in the water sector: concentration, competition for the market, competition in the market and cooperation (see also Ludin et al. 2000). In fact, there has been a progressive concentration process in countries such as Belgium and the Netherlands. In Belgium, there are 109 waterworks, and 93% of total production is concentrated in the hands of only 10 companies. The Netherlands reduced the number of its government-owned water utilities from 111 to only 24 companies (see EEB 2002, p. 26). However, in many other countries, concentration is not a feasible or preferred opportunity due to political, legal or geographical restrictions. Only a few European countries, such as France, Italy, and UK (England and Wales), introduced some degree of competition in the water sector. France and, more recently, Italy implemented competition by the model of franchise bidding based on the idea of competition for the market. Furthermore, the German Monopoly Commission recommended in its report the application of franchise bidding to enhance the efficiency of water supply. However, simultaneously, it pointed to the danger of hold-up problems arising from long-term license contracts within the system of franchise bidding. Hence, in many cases, mergers and competition for the market may not be feasible. However, significant welfare gains can be achieved using the latter of the two alternatives. In a setup with profit-maximizing private companies, we show that welfare gains may be higher in the case of unregulated competition when assuming high efficiency differentials between water utilities. England and Wales have chosen a model of product market competition based on competition in the market. One main element of such competition is common carriage. The concept is based on the shared use of networks, similar to telecommunication, electricity or gas: the incumbent company is required to grant its competitors access to the network, which is assumed to be an essential facility. However, due to difficulties in the regulation of access prices and the physical characteristics of water, competition is expected to be weak and mainly local. In fact, competition by common carriage still plays a minor role in the English and Welsh water industries, even when the government tried to increase the relevance of competition by introducing a sector-specific law in 2005. An alternative way to enhance efficiency might be to increase cooperation between neighboring utilities. One main element of such a cooperation model is the exchange of treated water resources based on trade. Because water utilities often have differing qualities of raw water and therefore face different marginal production costs, trade between neighboring suppliers is expected to reduce total costs. In fact, water trade is already practiced in several countries. However, in most cases, trade is only used to balance peaks in demand, as the non-profit-oriented communal water utilities usually try to be as independent as possible. Hence, trade does not happen even when costs vary significantly between neighboring utilities, although a more consequent implementation of trade might induce extensive efficiency and, therefore, welfare gains. Obviously, such a regime of cross-border trade resembles the regime of competition by common carriage described above. The connection of networks can be used for water trade rather than for competition by common carriage. In both regimes, local and neighboring water suppliers connect their networks and exchange water. Both trade and competition cause the more efficient utilities to increase production volume and the less efficient utilities to reduce volume. One may question whether competition is useful because welfare gains are expected to be small due to the limited degree of competition and the emerging regulation costs. Using a game-theoretic model, we show that competition by common carriage induces stronger production incentives for the inefficient supplier. This implies that not only production efficiency but also the retail price tend to be lower than with cross-border trade. The net effect regarding welfare depends on the efficiency differential. At higher cost differentials, welfare is higher under common carriage, even in a lower-bound benchmark case without regulation of access charges. There is some literature addressing the issue of competition in the market by common carriage applied to the piped water sector. For instance, from economic and regulatory perspectives, Cowan (1993 and 1997), Webb and Erhardt (1998), Grout (2002), Klein (1996), Scheele (2000) and Sawkins (2001) discuss the opportunity for common carriage to be applied to the water sector. Due to technical constraints, regulation difficulties and barriers to entry, most authors indicate that common carriage is not a major opportunity to introduce effective rivalry into the water sector. Nevertheless, Sawkins (2001) concludes that common carriage remains the greatest competitive opportunity in the water sector. However, the main challenges are to reduce the regulatory burden and to lower entry barriers. Saal and Parker (2001) empirically analyze the efficiency effects of privatization and liberalization in England and Wales. They conclude that total factor productivity growth has not been improved after privatization. Additionally, privatization raised retail prices and water suppliers’ profits. However, Saal and Parker analyze the post privatization period of 1990–1999, when competition by common carriage still played a minor role. Using a game-theoretic model, Foellmi and Meister (2005) analyze potential efficiency gains of common carriage. They argue that competition may increase efficiency even in a “worst case” scenario in which regulation is absent. The effects of different access price regulations were analyzed by Hern (2001). He concluded that the Efficient Component Pricing Rule (ECPR) is a superior approach for the development of efficient competition in the specific circumstances of the UK water industry. The role of regulation in practice was also highlighted by a recent market report from the Office of Water Services (Ofwat), which is the regulator for the English and Welsh water industry. Ofwat, which applies a version of ECPR, recommends accounting separation of the contestable markets from the natural monopoly to improve the efficiency of regulation (Ofwat 2008). A wide range of literature is related to trade of water rights. For instance, Hearne and Easter (1997) describe gains from the trading of water rights in Chile, Rosengrant and Binswanger (1994) present potential efficiency gains in developing countries, Pigram (1993) analyzes property rights and water markets in Australia, and Becker (1995) discusses potential gains from trade in Israel. However, few authors have analyzed trade related to spot water markets. Howitt (1998) shows that spot markets are better than water rights markets for stabilizing water availability. Calatrava and Garrido (2005) consider the risk dimension of water markets under conditions of uncertain water supply. They show that spot water markets may allow farmers to reduce their risk exposure caused by an unstable water supply. Additionally, they show that centralized water markets lead to more efficient allocation and resource use than decentralized markets. Carey and Zilberman (2002) investigate farmers’ investments into irrigation technology under conditions of uncertainty and conclude that farmers with access to a spot water market may delay investment. Due to price uncertainty, the option to delay investment has a positive value, and thus, farmers will not invest until the expected present value of investment sufficiently exceeds the cost of investment. There is some literature analyzing bargaining processes and bargaining power in water markets: Kajisa and Sakurai (2000) examine water markets in India, and Meinzen-Dick (1997) examines groundwater markets in Pakistan. However, this literature addresses water trade related to agricultural issues in particular, while our paper rather discusses trade between neighboring water utilities that offer water services to final customers, such as households or industry. Newbery (1999) introduces a model that combines competition and trade in the network industry. Two suppliers compete in a single downstream gas market. Both pay a fee for using the network, which connects the market to the upstream gas producers. Newbery shows that if the suppliers can trade capacity rights amongst each other, they can use the price of these rights to support the joint profit-maximizing downstream price. However, such a setting is not feasible in the piped water market with vertically integrated water utilities. To the best of our knowledge, there is no literature analyzing the comparison of trade and competition between local water utilities. Section 2 evaluates the reasons for the above-mentioned productivity differentials and discusses the relevant approaches to enhance efficiency. Additionally, the section provides evidence on competition and trade in the European water market. In Section 3, we set up a general model that considers the physical restrictions in the water sector, the difficulties of regulation and varying bargaining power to analyze the effects of competition and trade. We then compare the effects of competition and trade on productive efficiency, retail prices and welfare, and the distribution of profits between firms. In Section 4, we consider an example with linear demand and constant marginal costs. In the same section, we investigate the effects of regulation of access prices on the one hand and regulation of retail prices on the other. In Section 5, we present a simulation of the model. It shows that the result of the linear case holds as well for more general demand and cost functions: welfare tends always to be higher with trade because the productive efficiency effect dominates. Section 6 concludes.",1
12.0,3.0,"Journal of Industry, Competition and Trade",24 February 2011,https://link.springer.com/article/10.1007/s10842-011-0096-3,"Entry, Competitiveness and Exports: Evidence from the Indian Firm Data",September 2012,Alokesh Barua,Debashis Chakraborty,Hariprasad CG,Unknown,Male,Unknown,Male,"How does entry affect competitivenessFootnote 1 in an industry and hence welfare? Conventional wisdom suggests that entry in an oligopolistic industry reduces market power of existing firms, i.e., industrial concentration and thereby reduces price-cost margins and improves consumer welfare.Footnote 2 The aforesaid partial equilibrium result holds also in a general equilibrium situation as well (Barua and Pant 1995). Considering an open economy Cournot model, Agarwal and Barua (2004) have shown that the limiting case of entry in such a model confirms a competitive outcome. The theoretical presumptions notwithstanding, there are very few studies being purported to empirical validation of these results in a strict sense. In view of the recent two major policy initiatives of the government of India,Footnote 3 it becomes all the more necessary to conduct such validation if not for anything else then at least for an attempt to judge the impact of the policy changes. The resulting liberalization has significantly facilitated the entry of both domestic and foreign firms across all industries. Much attention has been drawn to the debate whether firm entry has significantly affected the market structure in the industrial sector of the Indian economy or not. The evidence from empirical studies in this area is found to be rather ambiguous (Athreye and Kapur 2003; Barua and Chakraborty 2006; Balakrishnan and Babu 2003; Kambhampati and Parikh 2003). In a recent analysis on the theory and evidence of market power in Indian manufacturing, Das and Pant (2006) have argued that “the new industrial policy has not been able to foster competition” (p. 75), confirming the earlier findings by a number of researchers. One of the central limitations of the existing studies on the effect of entry on competition is their dependence on two or more sources of rather unrelated data for estimating the price-cost margins in industries.Footnote 4 This raises doubt as regards the reliability and also comparability of their estimates. The present study is an attempt to provide a unified model of measurement of price-cost margins using only firm data of the same source. In addition, it also attempts to examine the relationship between firm size, marginal cost structure and exports. The basic theoretical model underlying the current empirical exercise is based on the open economy oligopoly model under segmented market hypothesis as put forward in a series of papers by Agarwal and Barua (1993, 1994, 2004, 2007). The main arguments of these papers are that entry liberalization (whether internal or external) would result in (a) increase in aggregate exports, (b) reduction in industrial concentration, (c) decrease in price-cost margin, and (d) increase in social welfare. It is immaterial whether the firms are of domestic or foreign origin. Thus, the ongoing WTO induced reforms (external liberalization) and the industrial reforms carried out in India since 1991 (internal industrial liberalization) are expected to significantly affect the performance of the manufacturing sector of Indian economy (Kambhapati and Parikh 2005). The paper is organized as follows: Section 2 describes the basic theoretical model to provide empirically testable propositions of the effects of entry liberalization on market performance. A review of the literature is provided in Section 3 and in Section 4 an econometric estimation model is proposed to test the propositions described in Section 2. Analysis of the econometric estimation results as well as other findings is provided in Section 5. Section 6 draws a few policy conclusions based on the current analysis.",4
12.0,3.0,"Journal of Industry, Competition and Trade",31 May 2011,https://link.springer.com/article/10.1007/s10842-011-0103-8,Rationales for Industrial Policy Based on Industry Maturity,September 2012,Finbarr Livesey,,,Male,Unknown,Unknown,Male,"The use of industrial policy in developed economies such as the United Kingdom has gone in and out of favour over the past 30 years. There is a current resurgence in both the use of the term industrial policy and the potential for interventions which will impact the structure of industry. The credit crisis of 2008 – 2009, a major driver of this re-emergence, has led many to believe that a rebalancing of the economy towards manufacturing is required for stability. David Cameron’s first major economic speech after the recent election emphasised the position that most policymakers and commentators are now taking on manufacturing and its role in the recovery. “Our economy has become more and more unbalanced, with our fortunes hitched to a few industries in one corner of the country, while we let other sectors like manufacturing slide.”Footnote 1 This is a significant change in position for British policymakers, who have not intervened in significant ways (beyond providing small business and export support) to increase the share of manufacturing in the economy over the past 30 years. However the foundations for industrial policy, especially in a developed economy, have become unclear. The existing policy rationales, based on market failure and system failure, struggle to explain or guide the policy maker (Zerbe and McCurdy 1999). Over the past 20 years the study of industrial policy has largely taken place in development economics (Rodrik 2008; Pack and Saggi 2006) while at the same time the policy discussion in countries such as the UK moved on to innovation and entrepreneurship. With the re-emergence of industrial policy as an option in countries such as the UK there is a need to revisit and update the frameworks used to analyse and justify industrial policy interventions. This paper proposes a framework for thinking about industrial policy for leading economies based on the maturity of a given industry in a country contrasted to the maturity of the industry in a global sense. This provides a framework for analysis which recognises the relative maturities of a number of industries in a given country, allowing for a more nuanced discussion on the rationales for intervention beyond standard market failure arguments, and which may encourage a portfolio approach to industrial policy interventions. The paper uses the examples of the UK at the macro level and molecular and macromolecular (MMM) based industries to discuss how to further develop this framework for use in practice by policy makers.",8
12.0,4.0,"Journal of Industry, Competition and Trade",22 June 2011,https://link.springer.com/article/10.1007/s10842-011-0110-9,Colluding on a Price Increase,December 2012,Stefano Colombo,,,Male,Unknown,Unknown,Male,"Collusion between firms is a fundamental issue in the theory of industrial organization. Given the relevant welfare implications of collusive practices, economists have devoted much effort to understand how different variables increase or decrease the likelihood of the emerging of a collusive equilibrium.Footnote 1 In general, whether or not a variable makes collusion easier or more difficult to sustain in equilibrium is the result of the interaction between the impact of such variable on the collusive profits, on the deviation profits and on the punishment profits. This often makes it very difficult to obtain an unambiguous relationship between a certain variable and the likelihood of the collusive equilibrium.Footnote 2
 In this article we consider a widely adopted type of price agreement, namely price increasing collusion (that is, a collusive agreement concerning a price increase), and we provide a simple method to derive unambiguous relationships between any variable and the sustainability of collusion in equilibrium. From the point of view of the firms, the aim of price increasing collusion is the same as price fixing collusion: that is, setting a price which is higher than the competitive one. However, the mechanism behind the implementation of the two price agreements is different. In fact, price increasing collusion means that the firms do not fix directly the collusive price, but they agree to increase the price above a previous price level, which may be a competitive price level or another collusive price level. The rationale of this collusive agreement is that firms typically do not try to implement a collusive agreement just after they enter in a market, as they need some time to know both the market and the potential partners of the cartel. In other words, only after a period of fair competition, the firms may try to create a cartel, which is based on the previous non-collusive equilibrium. After this, if collusion is proved to be sustainable, firms may try to increase further the price. This type of agreement is documented in many European antitrust cases, as, for examples, ICI-Dyestuffs (ECJ July 14, 1972), Cast Iron and Steel Rolls (D.Comm. Oct.17, 1983), PVC II (D.Comm. July 29, 1994), British Sugar – Tate & Lyle (D.Comm. Oct. 14, 1998), Dutch Industrial and Medical Gases (D.Comm. July 24, 2002), Methylglucamine (D.Comm. Nov. 27, 2002), Flood flavour enhancers (D.Comm. Dec. 17, 2002) and Organic Peroxides Cartel (D.Comm. Dec.10, 2003). The main ingredients of a price increasing collusive agreement—namely, a moderate price increase with respect to the previous level of the price, and the punishment of a cheating firm by the other participants to the cartel—are well described in the following internal memos, emerged during the investigations by the European Commission relating to the case Dutch Industrial and Medical Gases (D.Comm. July 24, 2002): “Prices cylinder gases/rent and freight…These will be increased as from 1
st
January with 5%. This percentage also counts for freight” (par. 114). “All companies including [firm 1] agreed on using bottom prices—rent and transport charges. In reality [firm 1] uses prices that are far below these prices: 20–30%. This results in a lot of price decreases and/or lost customers…All companies including [firm 2] suffer a lot of the uncontrolled way [firm 1] is behaving in the market. I have two suggestions: discuss with [Mister X], prepare for retaliation on short term…” (par. 120). In order to discuss the conditions for price increasing collusion, we adopt a general spatial framework, were firms pay the transportation costs to carry the good from the plant to the consumers.Footnote 3 This set-up describes well the markets involved in the antitrust cases mentioned above, where firms usually adopt delivered prices. The model we use in this article is kept as general as possible, as we only require symmetry of firms, as usual in the literature studying collusion.Footnote 4 Moreover, similarity between firms tends to make easier to reach a consensus among the firms about the characteristics of the agreement, and, more importantly, about the way to share the collusive profits, and thus tends to increase the sustainability of collusion. The central result of this article is that the way a variable affects the sustainability of a price increasing collusive agreement is driven only by the way such variable affects the competitive profits. That is, the sustainability of collusion is shown to be invariant with the deviation and the collusive profits. In other words, if a variable increases (decreases) the competitive profits, it increases (decreases) also the sustainability of the collusive agreement. Such result has relevant implications for the assessment of the impact of a certain variable on collusion likelihood in equilibrium: what is required is just to evaluate the impact of such variable on the non-cooperative profits. This article proceeds as follows. In Section 2 we describe the model. In Section 3 we define the conditions for the sustainability of collusion in equilibrium and we present the central result of the article. Section 4 concludes.",
12.0,4.0,"Journal of Industry, Competition and Trade",28 June 2011,https://link.springer.com/article/10.1007/s10842-011-0111-8,A Welfare Evaluation of History-Based Price Discrimination,December 2012,Thomas Gehrig,Oz Shy,Rune Stenbacka,Male,Male,Male,Male,"It has become common practice in many industries, for example, cable TV, telecommunication, service industries and energy industries, to apply history-based price discrimination, i.e. to differentiate the prices directed to old and new customers. Typically new customers are targeted by aggressive price offers (introductory offers or poaching prices), which are designed to attract new customers or to induce rival firms’ customers to switch even when those customers are already locked-in in another customer relationship. In this study we will conduct a welfare analysis of history-based price discrimination within the framework of an asymmetric duopoly model where the dominant firm as well as its small rival can apply history-based pricing. More precisely, we compare the effects of history-based price discrimination on consumer surplus and industry profits with those associated with uniform pricing within a framework, where consumers have differentiated preferences and face switching costs. Consequently, we analyze a model where the inherited history matters not only because of the information it conveys on consumer preferences, but also because switching costs directly affect profits and consumer surplus. We also explore to what extent history-based pricing can be viewed as an instrument for a dominant firm to induce exclusion of smaller rivals. Competition lawyers and judges have tended to view history-based price discrimination conducted by a dominant firm, as any form of discrimination, in a rather skeptical, if not resentful, way (e.g. Möschel 1999). Such a view has often been based on a form-based approach to the implementation of competition law. A number of European antitrust cases have established how history-based price discrimination might facilitate predation in a way which would, according to competition authorities or courts, qualify as an abuse of a dominant market position. The ECS-AKZO caseFootnote 1 is the seminal case exemplifying this. AKZO directed poaching prices to ECS’s customers with the intention of excluding ECS from the market. Spector (2005) presents a thorough discussion of this aspect. Another example is the Irish Sugar case, where the dominant firm applied a scheme of target rebates such that the rebate was more favorable to particular customers of competing sugar packers. The Swedish Competition Authority vs. TeliaSonera from year 2005 is another example illustrating how selective poaching offers by a dominant firm to a small rival’s customers may qualify as an abuse of market dominance. In this case TeliaSonera directed selective poaching offers exclusively to customers of Bredbandsbolaget, a small regional rival in the Swedish market for fixed line telecommunications.Footnote 2 For an extensive and systematic account of European competition law towards price discrimination see Geradin and Petit (2005). In this study we adopt a standard Hotelling model to analyze the effects of history-based price discrimination in asymmetric industries, where one of the firms is assumed to have a dominant market position. We focus on a duopoly industry endowed with an inherited position of dominance, where, for simplicity, dominance is assumed to mean a market share larger than 50%.Footnote 3 We find that uniform pricing is a more powerful instrument than history-based pricing for the dominant firm to defend its market share advantage. We show that consumers benefit from history-based price discrimination unless the switching cost is sufficiently high. The switching cost threshold, above which consumers benefit from uniform pricing, depends on whether the inherited dominance is weak or strong. Uniform pricing softens competition in the duopolistic industry leading to higher industry profits under uniform pricing. Consequently, unless the switching costs are sufficiently large, a ban on history-based price discrimination would redistribute surplus from consumers to producers. Finally, we establish that the gains to industry profits associated with uniform pricing under all circumstances exceed the associated losses to consumers. Our study has strong implications for competition policy, not only with respect to the implementation of Article 102 in Europe but also in light of US Section 2 of the Clayton Act, which renders any activity that aims at substantially eliminating competition or creating a monopoly as illegal per se. We find that a policy of banning history-based price discrimination leads to higher prices in most consumer segments, and, therefore, tends to reduce overall consumer surplus. Moreover, a ban on price history-based discrimination tends to soften competition and promote industry profits. Our study is structured as follows: Section 2 presents a short literature review and identifies our contribution to this literature. The analytical part of our study is divided into three sections. Section 3 presents a detailed equilibrium analysis of competition with history-based pricing. Section 4 characterizes the equilibrium with uniform pricing. Section 5 evaluates the welfare implications of history-based pricing. Section 6 concludes.",34
12.0,4.0,"Journal of Industry, Competition and Trade",23 June 2011,https://link.springer.com/article/10.1007/s10842-011-0112-7,Determinants of Firm R&D: The Role of Relationship-Specific Interactions for R&D Spillovers,December 2012,Patrik Gustavsson Tingvall,Andreas Poldahl,,Male,Male,Unknown,Male,"In 2005, expenditures on research and development (R&D) in Sweden accounted for almost four percent of GDP, making Sweden one of the most R&D-intensive countries in the world. Because R&D is a major factor driving technological development, R&D is associated with economic growth. It is therefore worthwhile to consider how different economic factors affect R&D. We analyzed the role played by domestic and international trade as a vehicle for technology (R&D) spillovers and their impact on firm R&D. As Nunn (2007) notes, trade does not occur spontaneously; in some cases, relationship-specific investment must precede trade. We argue that such relationship-specific investments not only enhance trade in certain goods but also ease the transmission of technology spillovers (rent spillovers). As some researchers (e.g., Geroski (1990), Cohen and Levinthal (1989)) have noted, spillovers do not come for free, instead, the absorption of outside technology requires efforts (investments in the absorptive capacity). It is therefore plausible to assume that specific buyer-seller interactions work as oil in the transmission of technology spillovers. The vast majority of empirical studies on spillovers utilize industry-level data or limited surveys, see, e.g., Stoneman (1995) and Aghion and Howitt (1999). However, as detailed firm-level data have become increasingly available, firm-level studies have also become more common. By using highly detailed firm-level data, we are able to analyze not only trade-related technology spillovers but also the effect of specific buyer-seller interactions on spillovers and firm R&D. The significant role played by import-driven technology spillovers is highlighted by the fact that at least 90% of the technology used by most countries is sourced from abroad (Keller 2004). Empirical research has established that spillovers are locally bounded and that trade plays an important role in the transmission of technology and spillovers.Footnote 1 This research demonstrates that technology spillovers exist, they are non-negligible, they tend to follow trade and input–output linkages and they are to some extent locally bounded. In addition, the diffusion of technology is not inevitable or automatic. Investments or other efforts are needed to absorb outside technology. When analyzing spillovers, the unit of observation is crucial. Keller (2004) concludes that macro-level studies cannot control for implicit aggregation biases and that the level of disaggregation affects the results. Thus, we analyzed firms in the Swedish manufacturing sector. Given that R&D is related to decisions made at the firm level, this unit of observation is well chosen.Footnote 2 Moreover, although the manufacturing sector only accounts for a limited share of total employment, it has long been considered the key to industrial and economic growth because of its significant positive effect on technical skills, employment, and efficiency. Because the manufacturing sector is a primary tool for modernizing the economy, it is a primary recipient of various types of positive spillovers (Tybout 2000). Trade contributes to the diffusion of technology by allowing firms access to global technologies. Firm-level empirical studies show that increased trade often leads to within-firm productivity gains (Fernandes 2007, p. 53). Specifically, Fernandes found that increased exposure to foreign competition generates productivity gains for manufacturing plants in Colombia. Using what the author refers to as the “direct” approach, the production function equation includes trade policy as a regressor. A strong impact of trade liberalization on plant-level productivity is found, and large and less competitive plants reap an even bigger return. Regarding Colombia’s export market, Brooks (2006) suggested that foreign experts who train domestic workers in Colombia could have a substantial and persistent positive effect on domestic wages and value-added per worker (Markusen and Trofimenko 2009). Lopez (2006) investigated the role of imports on plant survival in Chile. Additionally, using plant-level panel data on Chilean manufacturers, Pavcnik (2002) provided evidence of within-plant productivity improvements that can be attributed to increased trade. On the export side, Alvarez (2006) searched for factors that contribute to transforming Chilean manufacturing plants into permanent exporters. Results suggest that export experience, multinational spillovers, and an increase in productivity positively contribute to the probability of becoming a permanent exporter. Finally, adding to the topic of technology diffusion, Lopez (2008) examined the existence of intra- and inter-industry productivity spillovers from foreign technology licensing by the Chilean manufacturing sector. Because importing a technology rather than developing new technology does not require complete mastery of it, technology licensing by developing economies is common. Lopez found a positive spillover effect from technology licensing in upstream sectors, but a negative effect in downstream sectors. Other studies suggest that imported capital and intermediate goods may work as channels through which technological knowledge diffuses. Schiff et al. (2002) were among the first to conduct such an analysis at the industry level for developing countries. They examined the effect of North–South and South-South R&D spillovers on total factor productivity (TFP). Utilizing the Coe and Helpman (1995) approach for measuring spillovers, they found that although North–South spillovers were the largest, North–South and South-South spillovers were still positively correlated with total factor productivity. Portugal-Perez and Wilson (2009) analyzed the role of trade costs for developing countries. In their work, they considered import costs, but they primarily focused on high trade costs associated with exports. They concluded that high trade costs limited the full realization of gains from trade in many nations. Anderson and Wincoop (2004) contend that there is a significant relationship between trade costs and market structure. Both of these variables suggest a limiting rate up to which a country or firm can either absorb technological information or exploit external knowledge. Coe and Helpman (1995) have also found significant productivity spillovers driven by imports. Their study examined bilateral import-share-weighted R&D stocks in a sample of 22 OECD countries and concluded that spillovers increase with the degree of openness. Similar effects are found for technology diffusion running from industrialized to less developed countries (Coe et al. 1997). Xu and Wang (1999) adapted a related but slightly different approach to analyze R&D spillovers embodied in the imports of differentiated capital goods. Typically, the measurement of R&D spillovers makes use of current trade only. Lumega-Neso and Olarreaga (2005) studied 22 OECD countries for the period 1971–1990 and found evidence that R&D spillovers exist without direct trade flows. In many ways, indirect trade links through trade partners are more important than direct imports. These results are consistent with the importance of dynamic effects from imports, where the potential technology spillovers stemming from import from country B also depend on technology spillovers from country C to other countries (including country B). Using data spanning 30 years from a relatively large number of countries, Archarya and Keller (2008) have also found evidence of substantial productivity spillovers related to import of foreign R&D stocks. Their results indicate that import spillovers are asymmetrically distributed among receiving countries within the G6 group. The hypothesis widely tested in a number of papers (see Coe and Helpman (1995)) is that foreign R&D elasticities are the same in all countries. Archarya and Keller (2008) clearly reject this hypothesis. Further, previous studies have mainly focused on productivity effects. However, Mancusi (2008) and Malerba et al. (2007) analyze import-driven R&D spillovers using a knowledge-production framework. Mancusi (2008) examines patent applications to measure innovation. R&D spillovers are computed by comparing the relative shares of patent citations within a given industry with patents in other domestic industries and patents in foreign industries. The hypothesis is that more patent citations increase the firms’ ability to benefit from R&D activities performed elsewhere. As Mancusi (2008) concludes, international spillovers are more important in laggard countries than in the technology leaders. The analysis in Malerba et al. (2007) is based on innovation activity in 135 technological fields, classified as chemical-, electronics- and machinery-intensive sectors, and covers six countries (France, Germany Italy, Japan, UK and US). In line with Mancusi (2008), they found both international spillovers and intra-sectoral spillovers to be important determinants of innovation. Additionally, as Nunn (2007) and others have reported, personal interaction between the buyer and the seller may act as a mechanism that enhances trade of certain (non-standard) types of goods. More specifically, Nunn shows that countries with well-functioning institutions have a comparative advantage in the exports of goods that are intensive in seller-buyer interactions.Footnote 3 The relationship-specificity (RS) index used by Nunn (2007) stems from Rauch (1999), and it examines how product differentiation affects the need for interaction between the buyer and the seller. The question of how relationship-specific interactions and investments affect various decisions of a firm has attracted a series of papers. Examples include the following studies: Altomonte and Békés (2010), analyzing trade and productivity; Casaburi and Gattai (2009), examining intangible assets; Ferguson and Formai (2010), analyzing trade, firm choice and contractual institutions; Bartel et al. (2009), analyzing outsourcing and relationship-specific interactions; and Kukenova and Strieborny (2009), analyzing finance and relationship-specific investments. Hence, it seems clear that relationship-specific investments may be related to a wide range of issues. However, given the close relation between trade of intermediate products, technology spillovers and personal interactions, it is surprising that no one has yet analyzed the influence of personal interaction on technological (rent) spillovers; hence, we aim to fill this gap. The paper is organized as follows: Section 2 presents the model and data; Section 3 contains the econometric results; and Section 4 concludes.",5
12.0,4.0,"Journal of Industry, Competition and Trade",18 June 2011,https://link.springer.com/article/10.1007/s10842-011-0102-9,Export and Firm Performance: Evidence on Productivity and Profitability of Italian Companies,December 2012,Marco Grazzi,,,Male,Unknown,Unknown,Male,"The economic literature has recently devoted growing attention to the identification and understanding of the differences between exporting and non-exporting firms (Bernard et al. 2007). Such a trend in the trade literature is part of a broader research project that, employing recently available firm-level database, has contributed to identify relevant and persistent intra-industry heterogeneities (see, among the many contributions, Dunne et al. 1988; Jensen and McGuckin 1997; Haltiwanger et al. 1999; Bottazzi et al. 2007; Bartelsman et al. 2009). Export is considered because it is one of the factors that is associated with the observed differences among firms, and also because trade, via its pro-competitive effects is thought to possibly shape the dynamics of industries, in terms of market shares, average productivity and profits.Footnote 1
 In general, it is possible to identify the common reference to this resurgence in empirical works in those theoretical models of industry dynamics where firms are selected on the basis of their productivity, with more productive enterprises taking on larger shares of the market and less productive units shrinking and eventually exiting.Footnote 2 This concept was initially put forward in an analytical setting of industry dynamics where trade was not contemplated (see, among the others Jovanovic 1982; Hopenhayn 1992; Ericson and Pakes 1995). It was only later that these models started to encompass international trade, too (see for instance Melitz 2003; Melitz and Ottaviano 2008). This reveals an effort of the theory to account for the many empirical contributions that started to appear, reporting substantial productivity differentials between exporting/non-exporting firms (see Bernard and Jensen 1995 for the U.S. and Bernard and Wagner 1997 for Germany). This stylized fact was formalized, generally in a monopolistic competition setting, through the assertion that trade, by substantially increasing the size of the market, would generate pro-competitive effects. In particular, trade would highlight and exacerbate the already existing productivity differences among firms. Firms would now be competing on a bigger market with resulting smaller mark-ups, that would turn the “selection” switch on and, as a result, only firms whose productivity is higher than a given threshold would survive. As a consequence, the resulting distribution of industry productivity after that trade is introduced, would shift to the right as market shares of less productive (shrinking and eventually exiting) firms are re-allocated to more productive  (surviving and expanding) companies.Footnote 3
 The theoretical conjecture that foresees a relevant productivity gap between exporting and non-exporting firms is very well supported by empirical evidence, see Wagner (2007) for a survey of results. Thus attention soon shifted to questions regarding how and when such differential came to be (Bernard and Jensen 1999, 2004; Girma et al. 2004; López 2009). That is, scholars started to investigate if exporting firms were already over-performing before entry on the export market or, on the contrary, if they emerged as more productive afterwards (see for instance Wagner 2002). The latter  hypothesis contemplates various mechanisms of learning that are related to the activity of export, as for instance, climbing up the learning curve thanks to the higher quantity that is being produced, that sort of ‘technological’ learning due to international contacts (Aw et al. 2000), or through yet other mechanisms. Although there exists evidence supporting both hypothesis, self-selection and post-entry mechanisms, respectively, the conjecture that firms are more productive before starting to export has gained consensus, also thanks to some theoretical models that incorporate such hypothesis (most notably Melitz 2003; Melitz and Ottaviano 2008). This brief account of the recent development in the trade literature has shown that the attention, both at the theoretical as well as at empirical level, has for long been much centered on the existence of a productivity gap between exporting and non-exporting firms. More productive firms do expand, and when trade is introduced, they can afford the sunk cost and eventually start exporting. In this paper we investigate the relation between export activity and profitability using a recently released firm level database of Italian enterprises. We directly address the question of whether exporting firms are more profitable and grow more than their non-exporting competitors. In other words, is it possible to identify an export premium also for profitability, similarly to what has been found for productivity? To the best of our knowledge the first attempts in this direction, and the only ones to date, are the papers by Lu and Beamish (2006), Fryges and Wagner (2010), Temouri et al. (2010) and Vogel and Wagner (2010). In Fryges and Wagner (2010), the authors, that employ two surveys from the German Statistical Office, found a significant, though rather small, profitability difference in favor of exporting firms. In Lu and Beamish (2006), which focuses on the effect of internationalization on SME’s performance, the authors report a relation between export and profitability that sometimes is even negative.Footnote 4
 At the theoretical level, the only work to explicitly address the issue of profitability, as price mark-ups, is that by Melitz and Ottaviano (2008). In such a setting, trade, or, for that matter, trade liberalization,Footnote 5 by causing a bigger size of the market, lights up the market “selection” device, so that, due to increased competition, less productive firms, also those with lower mark-ups, are doomed to exit. As in Melitz (2003) it is only a subset of the more productive firms to export. The surviving firms with a higher cost draw would only serve the domestic market and would enjoy smaller mark-ups with respect to exporting, lower cost firms. Thus, as far as profitability is concerned, this framework delivers two main messages. The first concerns the comparative static effects associated to any trade liberalization, that is, all surviving firms are worse off in terms of price mark-ups, and this is due to the pro-competitive effects of trade that affect all firms indistinguishably. Second, trade preserves the rankings of firms by profitability, as price mark-ups. Profitability, is assigned once and for all with the draw of a firm’s productivity. Thus high productivity (low cost) firms will permanently enjoy higher mark-ups than their competitors and in an open economy they will also get a share of their profits from their revenues abroad. In this work we take a different strategy and we directly address the question of whether exporting firms are also more profitable than their industry competitors.Footnote 6 This allows us to relax the implicit assumption that the productivity premia of exporting firms gets automatically channelled into a—comparable by magnitude—premia in terms of firms’ profitability. Further, we also take a broader perspective in the investigation of the relation between international trade and firm performance. In this respect we consider different proxies of firm’s performance, such as productivity (labor and TFP), profitability and firm’s growth. Also in terms of growth rates one would expect that the productivity premia of exporting firms would get reflected in higher growth rates for exporting firms vis à vis non exporting ones. Such dynamics would indeed be coherent with a picture in which more productive and exporting firms takes on larger market shares, thus displaying bigger growth rates, than non exporting firms. In order to investigate the previous research questions we employ the census of Italian firms in the manufacturing sectors. We start by performing some exploratory data analysis—whose results are reported in the Appendix—aimed at looking for the existence of a more adequate definition of exporter that would take into consideration the export intensity and the persistency in the status of exporter. That is, we try to identify if the differences among firms, along several dimensions of their activity, arise with the simple status of exporter, or on the contrary, if they are related only to a more restrictive definition of who is an “exporter”. These analyses show that for those variables (size and productivity) that are able to clearly sort out the categories of exporters and non-exporters, it is not relevant to consider a threshold of export intensity or some proxies for the persistency in the export  status. Then, before attacking head on the issue of profitability, we verify the existence of a significant productivity export premium also after the euro introduction, in order to make sure that this empirical regularity holds across time, as well as under different institutional settings and industrial sectors. After that the productivity premium has been confirmed for both sub-periods, pre and post euro, we show both by non-parametric and parametric methods that there does not exist clear evidence of a positive relation between export activity and profitability; and not only that, but there are even a few sectors displaying a negative effect associated to the export status of a firm. We proceed as follows. Section 2 describes the database that has been used in the empirical analysis. Section 3 reports descriptive statistics on the proportion of firms exporting in the various manufacturing sectors and shows distributional evidence for exporting and non-exporting firms. Further, Sections 4 and 5 report the results, respectively, of the non-parametric analysis and of the regressions.Footnote 7 Section 6 concludes.",29
12.0,4.0,"Journal of Industry, Competition and Trade",19 November 2011,https://link.springer.com/article/10.1007/s10842-011-0116-3,Impact of RTA and PTA on Bangladesh’s Export: Application of a Gravity Model,December 2012,Muhammad Shariat Ullah,Kazuo Inaba,,Male,Male,Unknown,Male,"In the current era of multilateralism, a wave of regionalization is sweeping the globe at an increasing rate. Along with the deeper regional integration of the countries abiding by EU, EFTA, EEA and NAFTA agreements, there has been unprecedented growth in the number of international trade agreements in the developing world. As of January 2011, 205 regional trade agreements (RTAs) were in force and another 37 RTAs had begun negotiations.Footnote 1 The upsurge in regionalism escalated the debate on its potential gains and led to the development of anti-and pro-regionalism camps. Krugman (1991); Bhagwati (1993); and Frankel, Stein and Wei (1994) raised concerns that the current pattern of regionalization is likely to be welfare-reducing.Footnote 2 However, Baldwin (1997) asserted that regional deals make up the half of the “trade liberalization wheel” and will continue to facilitate multilateral liberalization. Plummer (2007) noted that, due to the uncertain outcome of the multilateral negotiations, the regionalism movement currently constitutes the most significant trend in international business policy. Over and over empirical studies have proved that international blocs of advanced countries are welfare enhancing. Baldwin (1997) noted that most of the studies of European and North American agreements showed positive effects on living standards in participating countries. Baier and Bergstrand (2007) found that bilateral trade between two members of an FTA doubles after 10 years. Kandogan (2008) studied the trade effects of regional blocs and reported that both economic cooperation agreements and preferential trade agreements foster trade among partners. Nevertheless, there is a dearth of literature on the trade effects of international blocs of developing and LDC countries, particularly regarding the RTAs in South and Southeast Asia. Regional cooperation in South Asia began with the formation of the South Asian Association for Regional Cooperation (SAARC) in 1985 by seven South Asian countriesFootnote 3 including Bangladesh. Subsequently, the SAARC members signed the South Asian Preferential Trade Arrangement (SAPTA) in 1993 and transformed the SAPTA into the South Asian Free Trade Agreement (SAFTA) in 2004. In addition to SAFTA, Bangladesh belongs to APTA and BIMSTEC FTA that also integrate countries in South Asia, Southeast Asia and East Asia. However, some of the members belong to more than one trade bloc, resulting in overlapping memberships. In particular, Bangladesh, India and Sri Lanka belong to the three regional agreements, and it remains unclear whether such simultaneous participation in multiple agreements fosters or hinders deeper economic integration. Although the trade effects of SAARC/SAPTA have been studied by Hassan (2001); Tumbarello (2006); and Kandogan (2008), little is known about the effects of these RTAs on bilateral trade flows between Bangladesh and other members. Rahman (2003) investigated foreign trade in Bangladesh and explored the effect of SAPTA. Until now, the roles of the other blocs have been rarely studied. Indeed, the high concentration of Bangladesh’s exports in a few developed countries calls for extensive research to investigate the effects of trade blocs on bilateral trade between Bangladesh and other members. Bangladesh is now attempting to sign bilateral free trade agreements (FTAs) with some of the members of SAFTA, and that raises further questions about the viability of the existing trade agreements. Therefore, the present study attempts to address the following research questions: (i) Do existing trade agreements have any significant impact on export flows from Bangladesh and on intra-regional trade flows? (ii) Has the emergence of SAFTA caused any improvement in Bangladesh’s export patterns for regional markets? (iii) Is the proposed free trade agreement with South Asian countries, including India, likely to stimulate export flows from Bangladesh in the future? Our aim is to use the analysis to identify the operational loopholes of existing trade agreements and to suggest strategic actions for stimulating export flows in the future. This research also contributes by using the most recent database. The remainder of the study is organized as follows: Section 2 provides an overview of different RTAs and PTAs; Section 3 highlights the export scenario of Bangladesh; Section 4 reviews the literature on gravity works; Section 5 presents model specifications and findings; and finally, Section 6 provides a conclusion.",7
13.0,1.0,"Journal of Industry, Competition and Trade",02 February 2013,https://link.springer.com/article/10.1007/s10842-012-0142-9,The New Political Economy of EU State Aid Policy,March 2013,Hussein Kassim,Bruce Lyons,,Male,Male,Unknown,Male,"The European Union’s regulation of state aid is inherently political. It restrains the ability of democratically elected governments to invest and subsidise as they wish. It is clearly economic. State aid has the ability to distort markets and undermine competition. It also produces legal clashes as the EU’s evolving legal order confronts established national laws and historic policy settlements. Yet the control of state aid has long been the ‘poor relative’ of competition policy (Hansen et al. 2004: 182), a ‘Cinderella’ (Bishop 1995: 331) or ‘ugly duckling’ (Ahlborn and Berg 2004: 41) ignored by, or peripheralised in, the academic literature. It has been a blindspot for a number of social sciences. Thus, political scientists have typically regarded the EU’s state aid policy as too technical,Footnote 1 legal scholars often do not regard the state aid rules as part of competition law,Footnote 2 and while economists have examined the justifications for industrial policy, they have only recently considered the regulation of state aid to be worthy of serious interest.Footnote 3
 For the European Commission, however, the control of state aid has long been an important policy instrument. The Commission’s decisions in key industries, as well as the horizontal rules that it enforces, have had major consequences in policy sectors, old and new. More recently, the anxiety with which the response of ‘Brussels’ was awaited when governments proposed colossal bailouts following the financial crisis that engulfed the Western economies from 2007 served to highlight the central importance of the EU’s powers over state aid in the member states. The crisis also underlined the extraordinary character of EU powers.Footnote 4 The control of state aid is an exclusive and all-encompassing EU competence. It is an area where the Commission enjoys considerable freedom of action, subject only to the scrutiny of the European courts, exercises far-reaching powers, and where its actions have consequences beyond their immediate impact on governments and firms. Importantly, the control of state aid brings the market economy presumption of the Treaty into confrontation with measures calculated to achieve allocative efficiency or redistributive justice in the member states (Friederiszick et al. 2006). This special issue proceeds from two assumptions: the first is that the control of state aid is a central issue in market regulation; and the second is that a full assessment of its impact requires multi- or interdisciplinary approach. As the following articles demonstrate, the effects of state aid regulation are felt at all levels of governance, from sub-national authorities in the member states to global regulation in the WTO, and across a broad range of policy domains from social policy to macroeconomic stability. At the same time, action on the part of the EU or its institutions fails routinely to attract interest beyond a small community of experts. Nor are there many attempts in the literature to track the long-term effects of EU action, even though decisions taken in Brussels or Luxembourg can have far-reaching effects on established national policy and law, member state decision making, and third country governments and firms. Assessing the impact of the EU’s control of state aid, domestic and international, is the first objective of this special issue. In examining the impact of EU actions on policy, policy making, and territorial relations in the member states, the articles that follow seek to contribute to closing an important gap in the scholarly literature. A second aim is to assess the European Commission’s response to the financial and economic crisis. Governments came under strong political and economic pressure to provide state support for firms in distress. The pressure was especially intense in regard to banks, which have systemic importance in the national economy, but it applied also to other sectors, traditionally considered strategic and symbolic, such as the automobile industry. Of particular interest is how the Commission reacted to member governments’ resort to protectionist measures that threatened to undermine the single market.Footnote 5 An evaluation of levels and trends in state aid is a third ambition. Particularly important in this regard are identification of the conditions under which governments are likely to grant aid and how effective the European Commission’s efforts to control it.Footnote 6
",31
13.0,1.0,"Journal of Industry, Competition and Trade",10 October 2012,https://link.springer.com/article/10.1007/s10842-012-0140-y,Managing the Dilemma of Discretion: The European Commission and the Development of EU State Aid Policy,March 2013,Thomas J. Doleys,,,Male,Unknown,Unknown,Male,"This article examines the role played by the European Commission in the development of the European Union’s (EU) state aid policy. It does so through the prism of a “dilemma” that exists at the nexus of the Commission’s delegated authority to administer EU treaty state aid provisions, the discretion conferred on Commission authorities to exercise that authority, and the political and institutional mechanisms EU member governments use to shape how that discretion is exercised. We argue that the source of this “dilemma of discretion” is found the imprecise language of EU treaty rules. Article 107 of the Treaty on the Functioning of the European Union (TFEU) constitutes the substantive heart of this rule framework. In its general thrust, Article 107 is clear enough: EU member governments are to refrain from using public resources to support domestic undertakings insofar as the implementation of that aid distorts cross-border economic activity. Exceptions are possible, but only where the assistance serves pre-defined policy objectives. Though the general thrust of the rules is clear, Commission efforts to apply and enforce those rules is rendered problematic by the imprecise language in which they are written. Neither the concepts anchoring the prohibition against government support nor the circumstances under which otherwise prohibitable aid may be granted are stated with precision. This lack of precision leaves their meaning open and potentially a source of conflict between Commission authorities and member governments. For Commission authorities, the malleable language of Article 107 serves as both opportunity and constraint. Imprecision can be a valuable resource. It affords Commission authorities the interpretive space to apply rules in light of pertinent political, economic and/or social circumstances. But the unsettled meaning of the provisions can also constrain Commission actions. The Commission must be aware that any effort to exploit the interpretive space in Article 107 might be challenged by governments whose understandings of the provisions differ. The Commission, mindful that the smooth functioning of the common market depends ultimately on the willingness of governments to observe EU competition strictures, finds itself in the position of having to constantly weigh its treaty-mandated responsibilities to prevent anti-competitive interventions against the threat that its efforts will be challenged, circumvented, or, worse, ignored by national authorities. The “dilemma” of whether to act and, if so, with how much vigor, is an endemic feature of state aid policy. And, for this reason, it is an aspect of EU policy that observers must acknowledge. Further, the existence of the dilemma compels observers to acknowledge that state aid policy cannot be understood simply as a technical exercise in the application of EU law or the pursuit of some abstract notion of market competition. State aid control is, at its heart, a profoundly political enterprise (Wilks 1993). It is the political dimension of this policy domain that we seek to illuminate. This study makes two contributions to the literature on EU state aid policy—one substantive, one theoretical. Substantively, the article furthers our knowledge of the role played by Commission authorities in this policy domain. To be sure, legal scholars have produced a robust body of commentary on the technical aspects of state aid case law (e.g., Nicolaides et al. 2008; Hancher et al. 2006). But the scholarship examining the politics of state aid remains at a relatively early stage of development (though see Smith 1996, 1998; Lavdas and Mendrinou 1999; Cini 2001; Blauberger 2009; Zahariadis 2010). The article’s theoretical contribution lies in the development and application of the “dilemma of discretion” as an analytical lens through which to understand Commission behavior. Drawing inspiration from the new economics of organization (NEO), the dilemma of discretion brings together NEO’s focus on contracting with the role hierarchical governance structures play in administering contractual relationships (Moe 1984; Williamson 1985). Specifically, we extend the application of principal-agent governance models to explore how the incomplete-ness of contracts struck among multiple principals (EU member states) shape subsequent relations between those principals and their agent (the European Commission). The balance of the article proceeds as follows. Section 2 provides an overview of EU treaty state aid provisions and explains how the mix of delegation and control requires the Commission to confront a dilemma of discretion. Section 3 explores how Commission authorities have navigated the dilemma at different stages in the development of EU state aid policy. The concluding section reviews the major findings and offers some observations on what we see as the limitations to the framework’s explanatory scope.",12
13.0,1.0,"Journal of Industry, Competition and Trade",06 October 2012,https://link.springer.com/article/10.1007/s10842-012-0145-6,Compensating Competitors or Restoring Competition? EU Regulation of State Aid for Banks During the Financial Crisis,March 2013,Bruce Lyons,Minyan Zhu,,Male,Unknown,Unknown,Male,"Forty European banks required specific and urgent rescue during the global financial crisis of 2007–10 and most others received huge amounts of assistance through general schemes.Footnote 1 Thirty-nine percent of EU GDP was committed to supporting banks from October 2008 to October 2010. Footnote 2 This provided a very sharp reversal of a trend that had seen the total state aid bill fall from 1 % in 1992 down to 0.5 % in 2007.Footnote 3 Under Treaty provisions, the European Commission provided supranational regulation of Member States in their specific bank rescues and more general support schemes involving state subsidies to banking. It imposed constraints on the amount of aid each bank could receive. It also required ‘compensation’ in the form of punitive asset sales and price restraints on individual banks in receipt of specific aid. In this article, we address the following questions. How well did the European Commission deal with the particular circumstances of bank bailouts? Was it right to intervene in national aid decisions? Did its interventions result in markets that were more or less competitive than would have emerged otherwise? Was it more intent on compensating rivals or on restoring competition? Could its decisions have been better designed to benefit consumers? Our focus is on specific aid granted to individual banks, the Commission’s unusual choice of ‘compensatory measures’ in relation to banks, and the impact of restructuring aid and ‘compensation’ on bank competition. Both the specific rescues and dozens of general schemes were reviewed by the Commission for compliance with Article 107 TFEU. This put enormous pressure on the Commission’s resources, especially as the urgency of rescue and restructuring (R&R) aid cases made them particularly difficult to deal with. Following the wording of Article 107, state aid for most sectors, including finance, falls under the competence of DG Competition. This reinforces the view that it is appropriate to evaluate the success of the Commission’s interventions in national state aid decisions in the context of its role as protector of competitive markets, in addition to any achievements in stabilising (or not further destabilising) financial markets. Although the Commission was a stabilising influence in the heat of the crisis, we find that it did not take the specific externalities created by a financial crisis sufficiently into account when designing its ‘compensation’ packages for state aid. We also question its policy of using divestitures as a punishment to prevent future moral hazard. In section 2, we contrast the justification for both allowing and controlling restructuring aid to banks as compared to other firms. In section 3, we compare the Commission’s published guidelines behind rescue and restructuring aid in general with the guidance for such aid to banks during the financial crisis. Section 4 analyses the Commission’s practice, in particular through four case studies of how individual banks got into difficulty, received aid from a Member State, and were required by the Commission to restructure or change their behaviour. Section 5 brings together the problems highlighted by the case studies.",6
13.0,1.0,"Journal of Industry, Competition and Trade",05 October 2012,https://link.springer.com/article/10.1007/s10842-012-0146-5,Aiding Car Producers in the EU: Money in Search of a Strategy,March 2013,Marcella Nicolini,Carlo Scarpa,Paola Valbonesi,Female,Male,Female,Mix,,
13.0,1.0,"Journal of Industry, Competition and Trade",14 June 2012,https://link.springer.com/article/10.1007/s10842-012-0132-y,The Effect of ‘State Aid’ on Market Shares: An Empirical Investigation in an EU Member State,March 2013,Caroline Buts,Marc Jegers,,Female,Male,Unknown,Mix,,
13.0,1.0,"Journal of Industry, Competition and Trade",05 October 2012,https://link.springer.com/article/10.1007/s10842-012-0138-5,"Economic Patriotism, the Clash of Capitalisms, and State Aid in the European Union",March 2013,Ben Clift,,,Male,Unknown,Unknown,Male,"This article explores state aid in relation to the concepts of economic patriotism and models of capitalism. Economic patriotism is conceived here as political economic activity in contemporary Europe which seeks, by a number of means, to advance the perceived economic self-interest of particular groups and actors (firms, workforces, or sectors) defined according to their territorial status (see Clift and Woll 2012).Footnote 1 The French government’s coining of the term in mid-2005 is not,Footnote 2 in one sense, the point. Economic patriotism is conceived here not as a sui generis French phenomenon, but a broader trend within contemporary advanced economies. The notion is also interesting because it is related to, albeit distinct from, a much longer established set of practices and approaches to economic policy such as neo-mercantilism, economic nationalism, and protectionism. It shares some common ground with the notion of ‘industrial patriotism’ introduced by Jack Hayward (1986: 68). Yet economic patriotism, as deployed here, is more encompassing. As explained below, it is of broader political economic significance because it reveals enduring and intriguing contradictions within state/market interactions in the context of internationalised liberal market capitalism. 
Varieties of Capitalism, a seminal text in debates of the late twentieth and early twenty-first century, identifies two prevailing ideal-types of capitalism, the liberal (LME) and the co-ordinated market economy (CME) (Hall and Soskice 2001: 1–70; see also Albert 1991 and Crouch and Streeck 1997). France is a particularly statist variant of the CME variety or model of capitalism (Levy 1999; Schmidt 2003), the prime European exemplar of the ‘Developmental State’ (Woo-Cummings 1999; Shonfield 1969; Marquand 1988), with a long history of directing financial support to strategic sectors and companies. State aid has been an important policy instrument of dirigisme (Shonfield 1969), the French economic ideology of directive state intervention in economic activity (Kassim 1997; Schmidt 1997; Hayward 1997). In this light, evolutions of state aid are therefore indicative of broader dynamics in the trajectories of contemporary capitalisms. The first section (below) begins with a definition of economic patriotism and a brief tracing of its origins to what Colin Crouch has called the paradox of globalised neo-liberal democracy;Footnote 3 namely, how governments pursue the political economic interests of their populace (in order to get re-elected) under conditions of complex economic interdependence which they cannot fully control. This lack of control results from the ‘institutionally incomplete’ nature of contemporary national economic governance regimes (Deeg and Jackson 2007). These coexist with constraining supranational regulatory regimes (such as the EU and WTO), and as a consequence, aspects of market regulation of today’s complex economic interdependence effectively lie outside national governmental control. The second section sets out how forms of economic patriotism are shaped partly by national institutional and social configurations, with particular reference to state traditions and intellectual traditions of political economic thought. This will be illustrated with reference to how corporate governance and company law in United Kingdom, France and Germany are shaped by particular political traditions—neo-liberal, dirigiste, and ordo-liberal respectively. The remainder of the article explores the particularities of French economic patriotism with specific emphasis on state aid. The central argument of the article is that the paradox of neo-liberal democracy generated by liberalised international markets, overlapping economic governance regimes, and nationally delimited political mandates presents new problems for economic policy elites. In the European context, the politics of state aid is particularly affected by these overlapping mandates and conflicting models of political economy, which shape different economic governance regimes. Specifically, the political economic model underpinning EU economic governance draws on neo-liberal conceptions of competition and markets. In broad terms, it aligns more closely with the LME than the CME variety of capitalism. The partiality characteristic of French economic patriotism—the protection and promotion of national champions—is at odds with the neo-liberal principles underpinning the policing of the Single European Market and the EU competition regime. Thus, some argue, completing the single European market entails the dismantling of elements of France’s dirigiste and colbertist policy regime (Clift 2003, 2004; Hayward 1995; Kassim 1997). This explains why EU state aid politics involves a ‘clash of capitalisms’ (Callaghan and Hoepner 2005; Clift 2009; Hooghe and Marks 1999). In relation to state aid, particular national approaches to state/market relations (especially in CME-oriented economies) are threatened by LME-oriented market re-regulation by the European Commission. The second argument is that the response to the more challenging regulatory environment for traditional industrial policy, which has state aid at its heart, involves the development of new forms of political intervention in economic and corporate activity (see Levy 2006). Through these new modes of intervention, such as the reinvention of urban policy as industrial policy, prevalent in France and elsewhere, economic patriotism is inscribed within contemporary processes of market-making, and the re-regulatory activity framing European markets. These modes of intervention, which combine neo-liberal and protectionist elements, are geared towards advancing the economic interests of particular territorially defined groups—at times French, at times European. Third, the contemporary economic crisis has seen a changing political economic mood. The current global economic downturn and financial crisis may signal a sea change in political economic ideas. The recent resurgence of Keynesian thinking is one manifestation of this. The retreat of neo-liberal ebullience of institutions like the European Commission is part of a wider questioning of laissez faire and self-regulating markets. This has created an environment conducive to the resurgence of the French dirigiste approach to state aid, so that the politics of economic patriotism in relation to state aid will have important policy consequences in the years ahead.",19
13.0,1.0,"Journal of Industry, Competition and Trade",29 September 2012,https://link.springer.com/article/10.1007/s10842-012-0141-x,The Constitutional Structures of the National Political Economy: Barrier to or Precondition for European Integration?,March 2013,Michelle Everson,,,Female,Unknown,Unknown,Female,"The problem of co-ordination of economic with welfare (or social) policies within the European Union is well documented (Scharpf 2002). In a nutshell, the problem is one of mismatch, or the different level at which each set of policies is pursued, as well as the subsequent difficulty of national/supranational policy co-ordination. Even since the conclusion of the Lisbon Treaty, the EU’s social competence still remains weak in relation to its economic role; meanwhile member states continue to bear primary responsibility for the formulation and management of socially redistributive mechanisms. Member states remain jealous of their interventionist competence and the EU is still denied meaningful revenue-raising powers in order to enable its own co-ordinated social intervention. Accordingly, conflict cannot but arise between the fiscal probity demanded by, for example, the ‘Growth and Stability Pact’ at supranational level and socially-corrective interventionist demands arising at national level. So far, so conventional: yet, from the legal point of view, this obvious lack of economic and social co-ordination is also merely the tip of a ‘mismatch iceberg’ between the deep constitutional commitments of the member states to democratically-legitimated or redistributive ‘economic policies’ (both within industrial policies and within market regulation), and a body of European Union law whose object and legitimacy is—according to the European Court—increasingly anchored within pursuit of the efficiency paradigms of economic rationality and, more particularly, the concomitant assumption that socially-redistributive goals can only be pursued within a distinct and identifiable ‘social budget’.Footnote 1 In an apparently stark contrast to the political consensus since the 1980s that an efficient, market-oriented, economic policy can and should be prosecuted in strict isolation from social goals, many national constitutions stubbornly retain their post-war commitment to a comprehensive politically-interventionist economic competence, or to a structural—that is, constitutionally-secured—‘political economy’. For many a national constitution, it is still a commonplace for market regulation or industrial policy to be governed by a political competence that encompasses socially distributive goals. At one political economic level, such residual constitutional commitments may be identified as the nexus at which conflicts arise between different varieties of capitalism within an increasingly global world (Hall and Soskice 2001; Hirst and Thompson 1999). At legal level, they nonetheless prove highly disruptive within EU law as the application of the European legal economic competence to national regulatory provisions can give rise to wholly unexpected conflict with the complex constitutional provisions of the member states. Within the legal world, one particular phenomenon is thus one of diagonal conflicts between European economic provisions in one policy area and national constitutional provisions governing a very different economic regime (Joerges 2004). For example, this article addresses the case of Rüffert, decided by the CJEU in 2009,Footnote 2 in which European judges sought to adjust the public procurement regime of German Länder to the then Article 49 commitment of the EU Treaty to freedom of services, and in particular to the free movement of workers across national borders within a services regime (now Article 56 TFEU). In so doing, the CJEU significantly altered its distinctive treatment of procurement within the overall EU state aids regime. Where once it recognised the legitimacy of pursuit of the redistributive social and ethical concerns of the member states within procurement, Rüffert placed this understanding in doubt. In this case, and having considered the matter outside the provisions of EU state aids law, the CJEU was thus to find itself in potential conflict with the powerful German Constitutional Court (Bundesverfassungsgericht), and more particularly that Court’s earlier treatment of the same material within a national constitutional state aids framework which privileges a politically interventionist discretion above economically rationalising arguments. At yet another level, however, the residual constitutional commitment to the national political economy also poses a far greater challenge to European law. Certainly, from the point of view of the CJEU, and in the pragmatic light of challenges made to this model at the national level (see below), it is surely tempting to view such national constitutional peculiarities as the swansong of the post-war constitutional settlement, and to happily set them aside in line with the motto ‘the structural flesh may be weak, but the political will (for economic rationality) is strong’. Nonetheless, when set in the parallel context of the Bundesverfassungsgericht’s judgment on the compatibility of the Lisbon Treaty with the German Constitution (BundesverfG, 2BVE 2/08), it becomes readily apparent that what might be dismissed as an outdated national commitment to the securing of a national political economy is also an expression of intricate legal and constitutional considerations on the democratic legitimacy of the conduct of economic and social policy. In turn, such conflict thus also reflects a potential mismatch between the understandings of constitutional legitimacy now maintained at national and European level; a mismatch which must surely be overcome if we are ever to secure continuing legal integration.",
13.0,1.0,"Journal of Industry, Competition and Trade",20 November 2012,https://link.springer.com/article/10.1007/s10842-012-0144-7,"State Aid Policy, Territoriality and Federalism: EU Scrutiny and Control of Regional Aid and the Supranationalisation of Subnational Autonomy in Federal Member States",March 2013,Hagen Streb,,,Male,Unknown,Unknown,Male,"To the extent that it addresses the impact of EU state aid policy, the political science literature has focused mainly on how decisions taken in Brussels or rulings laid down in Luxembourg have affected national industrial policy.Footnote 1 In this context, attention has been focused on how EU action has operated as a constraint on traditional patterns of state interventionism and, in particular, how it has eroded the ability of member governments to promote ‘national champions’ (see, e.g. Hayward 1995; Kassim and Menon 1996; Kassim and Stevens 2010; though also see Nicolini et al 2013). Yet, as the articles in this special issue show, the effects of EU state aid policy extend a lot further even within the industrial policy domain and indeed can be felt far beyond (see, e.g., Everson 2013). In line with this special issue’s aim of highlighting the importance of EU state aid policy and drawing attention to areas where its consequences have gone hitherto unexplored, this article examines the EU’s impact on territorial relations in three EU member states: namely, Austria, Belgium and Germany. Whereas much of the existing literature has theorized relations between the EU and national executives (see, e.g., Moravcsik 1994) or investigated the effects of EU action on national governments (see, e.g. Kassim and Menon 1996; Hine and Kassim 1998), this article focuses on subnational authorities. It shows how the EU’s control of state aid has circumscribed the autonomy of subnational governments. EU action has subjected the regional policy pursued by subnational states to control by the European Commission, compelling them to define policy within terms set by an EU template, and forcing them to abandon long-standing regional policy goals and practices. The article has two objectives. As well as attempting to take a first step towards filling a lacuna in the scholarship on state aid, it seeks to challenge a general presumption in the literature on EU and territoriality that European integration has been an unequivocally positive and beneficent development for the regions of Europe. A central feature of this literature, as exemplified by multi-level governance (MLG) (Marks 1992, p.212; see also Hooghe 1996, pp. 90; Marks 1993, pp. 391; Marks et al. 1996 pp.342; Hooghe 1996 pp.1), the dominant theoretical approach, is the emphasis on the new structures of opportunity that developed and the new resources that became available in the wake of the Single European Act (1986). A key contention is that these developments have encouraged the mobilization of regions, enabling them to bypass central government and to establish a direct presence in Brussels, where they can influence policy outcomes and secure access to EU funds. MLG’s mapping of how regions have escaped from the traditional hierarchy of the state reflects a behaviouralist methodology. It is actor-centred and pays limited regard to institutional structures. According to MLG, regions have been strengthened by the new channels of influence associated with Brussels’ emergence as an authoritative decision-making arena and by the EU’s adoption of policy programmes, such as structural policy and cohesion policy. As a result, the conception of empowerment offered by MLG is one-sided at best. In its account of how European integration has affected the regions, MLG does not take account of formal competencies or responsibilities as either resources or constraints. Critically, it overlooks the extent to which new opportunities to lobby or building coalitions have been gained at the cost of, in addition to, or irrespective of, the effect of European integration on the de jure powers or prerogatives of subnational authorities. Drawing on the experience of the impact of EU state aid policy on the regional policy pursued by subnational authorities in three federal member states, this article underlines the significance of MLG’s “blindspot” (Ipsen 1966 p. 248) in regard to formal or constitutional powers. It shows that far from an unequivocal strengthening of the regions in Europe, the EU has in fact restricted their freedom to originate and determine policy, and curtailed the formal powers to act that they enjoyed under their national constitutions. The EU’s state aid policy provides strong evidence for the argument that European integration has reconfigured territorial relations within the federal order of EU member states, and effected a constitutional change in those member countries, bringing about a comprehensive supranationalisation of subnational jurisdiction.Footnote 2 Five Decades after the signing of the Treaty of Rome, the European Commission initiated a process that issued ultimately in a detailed framework that imposes severe limits on the latitude of subnational authorities to design and implement regional development. Not only has the total area where aid is permissible been reduced, but there are detailed provisions that specify where and what kind of regional aid is permitted, as well as how it can be delivered. The study that follows examines the impact of EU action on the regional development policies pursued by Bavaria, Flanders, and Upper Austria. After a brief review of the suitability of the cases for testing the claims and assumptions made by MLG, it tracks the development of the Commission’s approach to member state regional aid policies before and after the key year of 1988. It then examines the effects of EU policy in Germany, Belgium and Austria, focusing on the 1998 Commission Guidelines that applied to regional aid from 2000 to 2006. The analysis draws on interviews with senior officials from the ministries involved in regional policy and relevant primary documentation.",1
13.0,1.0,"Journal of Industry, Competition and Trade",06 October 2012,https://link.springer.com/article/10.1007/s10842-012-0143-8,Winners and Losers in EU State Aid Policy,March 2013,Nikolaos Zahariadis,,,Male,Unknown,Unknown,Male,"Aid allocations depend on a government’s desire to give aid and its ability to get it past the Commission. Desire is conditioned by domestic macroeconomic conditions and political pressure. If the Commission is generally more reticent about disapproving aid allocations given by powerful Member States, it must perform a delicate balancing act as the scrutineer and arbiter of state aid and an institution subject to the political power of member governments. State aid involves state intervention to promote a certain economic activity. It is important because disparities in the levels of aid between member governments and between companies within national boundaries jeopardize the objective of economic and social cohesion and impair the development of the single market. The Treaty on European Union considers that aid confers unfair advantage to the recipient firms. Although some aid may be considered permissible under specific national circumstances, such as steep recession or high unemployment, or if it fulfills Community objectives, such as technology development, state aid is generally prohibited. The identification of winners and losers in state aid allocations therefore sheds light into the political underpinnings of the integration project itself. I first discuss state aid policy and outline the model. Using data published by the Competition Directorate (DG Comp) from 1992 to 2007, I employ pooled time series analysis to assess winners and losers in EU state aid policy. I then bring the analysis to the level of individual states to examine how specific countries have fared. I conclude with implications for state aid policy and market integration.",11
13.0,1.0,"Journal of Industry, Competition and Trade",30 September 2012,https://link.springer.com/article/10.1007/s10842-012-0139-4,EU State Aid Policy and the Politics of External Trade Relations,March 2013,Chad Damro,,,Male,Unknown,Unknown,Male,"While scholarly work on the external dimensions of European Union (EU) competition policy is become increasingly voluminous, state aid remains relatively under-scrutinised in this academic literature. Such an oversight may be understandable given that state aid policy is directed at the intra-community activity of EU member states and firms, and the EU does not possess the authority to oversee or control the various forms of state aid that may be provided by foreign governments to their own firms. As a result, most scholars investigating state aid confine their queries to what the EU considers state aid, which limits the analysis to the intra-community dimension. This article argues that EU state aid policy does in fact have important external consequences for non-EU firms, governments and consumers, which the existing literature has hitherto overlooked. Focusing on the intra-community dimension paints an incomplete picture because the EU’s external trade policy includes measures broadly associated with state aid activities. This article seeks to illuminate the extra-community dimension by focusing on the ways in which different actors—in particular, private economic interests—and factors shape the EU’s decision-making when state aid and external trade policies interact. EU state aid is most clearly linked to external trade policy in so far as it affects market access. While the EU has a rigorous state aid control regime, the authorisation of certain types of domestic state aid can act as a barrier to market access and run counter to the international trade rules of the World Trade Organization (WTO). When limited to intra-community activities, state aid control is clearly politically sensitive (Cini and McGowan 2009, 162). But when the trade linkage is made, state aid disputes become internationally contentious and create further opportunities for politics to influence decision-making and behaviour at the multilateral level. Such disputes give rise to a complex array of international political interactions in which various public and private actors pursue and defend their interests. The complex interactions occur because state aid measures that inhibit market access can be countervailed against under the WTO’s Subsidies and Countervailing Measures Agreement or brought to the WTO’s Dispute Settlement Mechanism (DSM).Footnote 1 This international regime, therefore, creates a setting in which decisions and complex interactions become ‘confrontational’ and highly politically charged (Palmeter 2003). The EU is very much involved in these interactions as one of the most active users and primary targets of such measures. But what are the factors that help to explain how and why the EU addresses the issues arising from the state aid-trade linkage? Under what conditions does the EU decide to pursue such politically contentious measures? To begin answering these questions, the following analysis provides an understanding of the EU’s role in these complex interactions that takes into account the institutional landscape of the Union and the competing preferences of different private interests. In particular, the role of firms is revealed as an important determinant for EU decisions whether to impose countervailing measures or initiate DSM cases. The discussion below proceeds in four sections. Section two identifies the legal context of the state aid-trade linkage in relation to the EU, noting especially the potential for state aid policy to act as a barrier to market access. Section three describes the most important legal aspects of the WTO’s controls on subsidies and countervailing measures. The section highlights the potential clashes that may arise due to differences between the EU and WTO regimes. The fourth section discusses the complex interactions and factors that play a role in the political decision-making associated with the state aid-trade linkage. In particular, the EU’s institutional landscape and the role of private interests are highlighted as important elements in the decision to countervail against a subsidy and/or bring an offending measure to the WTO’s DSM.",4
13.0,1.0,"Journal of Industry, Competition and Trade",30 September 2012,https://link.springer.com/article/10.1007/s10842-012-0136-7,European Competition vs. Global Competitiveness Transferring EU Rules on State Aid and Public Procurement Beyond Europe,March 2013,Michael Blauberger,Rike U. Krämer,,Male,Female,Unknown,Mix,,
13.0,2.0,"Journal of Industry, Competition and Trade",17 September 2011,https://link.springer.com/article/10.1007/s10842-011-0114-5,Boosting Manufacturing Productivity Through R&D: International Comparisons with Special Focus on Italy,June 2013,Alessandro Sterlacchini,Francesco Venturini,,Male,Male,Unknown,Male,"The main motivation of the present paper stems from the debate on the weak productivity performance of European countries as opposed to that recorded in the US since the second half of the Nineties. Although a substantial share of the productivity gap is attributable to services, also the performance of European manufacturing industries has been disappointing. Both in the light of endogenous growth models and the empirical evidence across countries, industries and firms, the above productivity divide has been mainly ascribed to the lower accumulation of knowledge and human capital experienced in the EU countries. It is also on this basis that, in 2000, the European Council launched the Lisbon strategy which established, for 2010, the target of a 3% share of R&D expenditures on GDP for the whole EU. According to recent records, this goal is far from being achieved so that, in 2010, the new growth strategy of the EU for the coming decade—Europe 2020—re-established, among its main goals, the same target for 2020.Footnote 1 In this respect, a pivotal role should be played by the manufacturing sector since this is where the bulk of a country’s R&D is performed. Among the largest European countries, Italy has experienced a slowdown in total factor productivity (TFP) that has been particularly evident in manufacturing. Being coupled with decreasing shares in the international trade of industrial products, the reduction of productivity growth has pushed many scholars to contend that Italy is experiencing an ‘industrial decline’. With respect to the causes of this phenomenon, most of them have pointed their fingers at the inadequate knowledge base of Italian firms. As a consequence, if the therapies designed within the Europe 2020 strategy are necessary for the whole EU, Italy should undertake exceptional efforts in terms of R&D activities. The above argument is hardly debatable. However, for countries like Italy—characterised by a prevalence of low and medium-tech industries—there is little knowledge about the expected size of this R&D-induced enhancement of TFP. By using data for twelve manufacturing industries of five developed countries over the period 1980–2002, we perform a panel cointegration estimation of the long-run elasticity of TFP with respect to the stock of R&D capital based on the panel DOLS estimator. The highest elasticity is found for the US (0.39), followed by Germany (0.29–0.32); intermediate values are achieved by France (0.19–0.21) and Spain (0.19), while the long-run impact of R&D is significantly lower in Italy (0.08–0.12). These findings provide strong support to the ‘research and innovation’ pillar of the Europe 2020 Strategy. Although R&D is not a panacea for all the European economic diseases, to reduce the productivity gap with respect to the US the high-tech industries of the EU should substantially increase their R&D investment. While the message for Germany, France and Spain seems quite clear, the same does not apply to Italy. In this case, the estimated long-run effect is so low that even with an increase of research expenditures four times bigger than that performed in the US the raise in TFP will be lower. How to explain the anomalous performance of Italy? The widely used (and abused) interpretation relying on the low R&D intensity recorded, on average, by Italian firms is discarded by the result arising for Spanish manufacturing industries (quite similar to the Italian ones in terms of specialization and prevalence of small firms). In Spain the average R&D intensity is lower than that performed in Italy but the elasticity of TFP with respect to R&D capital turns out to be significantly higher (and not far from that found for France). An alternative and more plausible explanation relies on the declining R&D efforts experienced, during the Nineties, by Italian manufacturing industries. As it is well documented in the paper, such a declining (or, at best, stationary) trend is peculiar to Italy since all the other countries considered, especially from 1995 on, have increased their R&D investment. This is particularly the case of the US manufacturing industries producing ICT goods in which the accumulation of technological capital has been much more intense than that recorded in European countries. This second interpretation is supported by the findings of a focussed analysis performed for the Italian case. In fact, by extending the time period considered from 1970 to 2002, we found that, across Italian manufacturing industries, the long-run impact of R&D capital on TFP increases when the period of declining R&D investment is neglected. Accordingly, the weak relationship between R&D and TFP arising for Italy is not due to structural (and, as such, not easily modifiable) features but is the outcome of a decade of slowdown in R&D investment (the Nineties) which followed a period of remarkable expansion (the Eighties). As a consequence, to say that R&D activities are of little use for a country like Italy would be a very misleading conclusion. On the contrary, for its R&D-based industries, there is a strong and urgent need to re-take the path of the Eighties. Although a substantial boost in productivity cannot be expected in the short- and medium-run, investing heavily in research and knowledge seems an inescapable condition to reverse the Italian productivity decline. The paper is organised as follows. Section 2 reviews the debate on the productivity slowdown experienced in the EU and Italian manufacturing. Section 3 introduces a standard production function framework for shaping the relationship between TFP changes and R&D capital. Section 4 compares the R&D intensity and capital stock across industries and countries. In Section 5, after checking the unit roots and cointegration properties of the series, we present country-specific panel DOLS estimates of the long-run relationship between R&D capital and TFP across manufacturing industries. Section 6 provides a discussion of the main findings and related policy implications.",6
13.0,2.0,"Journal of Industry, Competition and Trade",30 December 2011,https://link.springer.com/article/10.1007/s10842-011-0121-6,"Third-Degree Price Discrimination, Consumption Externalities, and Market Opening",June 2013,Tomohisa Okada,Takanori Adachi,,Male,Male,Unknown,Male,"This paper analyzes monopolistic third-degree price discrimination for a single final product in an economic environment where consumer’s tastes are exhibiting consumption
externalities between two separate markets. In particular, we study the effects of price discrimination on market opening. In the literature of third-degree price discrimination, it is widely held that price discrimination necessarily enhances social welfare if it opens up a new market that is not served under uniform pricing.Footnote 1 In contrast, this paper shows that market opening by price discrimination may lower social welfare if negative consumption externalities damage the main market too much. Consumption externalities refer to a situation where the more the customers purchase or use, the more or the less they are willing to pay. This feature of demand is found in many network or communication industries such as electronic mailing services and cellular phones.Footnote 2 In addition, demands for fashionable clothes and popular songs share this feature (bandwagon effects). Consumption externalities may also work negatively congestion or snob effects can make goods less valuable to consumers. The common condition in all these cases is that the valuations of goods depend on not only their intrinsic value but also the amount of aggregate consumption or the total number of customers who actually use these goods. Consumption externalities have been analyzed in the context of third-degree price discrimination by Adachi (2002, 2004, 2005) and Ikeda and Nariu (2009). One of the main findings of these studies is that price discrimination can improve social welfare even if the aggregate output is unaffected by a plan change from uniform pricing. In these studies, parametric assumptions are made on market demands to ensure that all markets are served under uniform pricing. The present study instead focuses on the effects of consumption externalities on market opening.Footnote 3
 Third-degree price discrimination in sales is ubiquitous in industries such as computer software and foodservices. For example, many software companies offer student discounts. In addition, women are sometimes offered a discounted admission fee at night clubs. In some cases, however, price discrimination is prohibited by the authority. For example, the Robinson–Patman Act prohibits sales that discriminate in price on the sale of goods to equally-situated distributors. The law was enacted to protect small businesses from large retailers which were using their market power to exact special deals. However, if the law brings a higher price for some retailers, it might exclude them from their market. In other words, prohibiting price discrimination might close some potential markets. Following the seminal work by Battalio and Ekelund (1972), several works such as Hausman and MacKie-Mason (1988), Layson (1994a) and Kaftal and Pal (2008) have investigated the situation in which price discrimination opens new markets that are not served under uniform pricing. These results imply that the feasibility of discriminatory pricing affects a monopolist’s market opening decision and social welfare. For example, Layson (1994a) derives demand and cost conditions on when only a strong market is served under uniform pricing. Conversely, the conditions are those favoring market opening if price discrimination is allowed. As for the welfare effects of market opening by price discrimination, it is well known that if allowing price discrimination leads to opening a new market and without externalities, then social welfare unambiguously improves as long as marginal cost is non-increasing.Footnote 4 This is because, in addition to the profits from consumers in the new markets, the monopolist never reduces its profits in any existing market since it can treat each market independently and fully exert its monopoly power under price discrimination. Thus, one might be tempted to state that from the social welfare viewpoint, it is preferable to abolish anti price discrimination laws rather than to exclude some retailers. In this study, we posit that market opening can reduce social welfare. In particular, we incorporate symmetric inter-group consumption externalities into a monopolistic model of third-degree price discrimination and characterize the range of consumption externalities where social welfare is higher under price discrimination by relating it to the relative market size. These findings demonstrate that in the presence of negative externalities, opening new markets by permitting price discrimination may reduce social welfare. This result brings a different perspective to the effectiveness of the Robinson–Patman Act. Since the total demand by retailers relies on the demand by final consumers, it is plausible that an increase in trade volume by one retailer group would often have negative effect to the others. Thus, our result can be interpreted as follows: Even though some potential retailers wanted to enter the retail market if the monopolist could set differential prices, the welfare-maximizing authority could be better off to prevent their entrance (that is, to close a market) in a certain circumstances. In this case, the authority can utilize anti price discrimination laws to control the monopolist’s market opening decision, not to control her pricing behavior. That is, no other policy instrument is necessary to close the unfavorable market. Therefore, our findings suggest the possibility that in contradiction to the initial purpose, the Robinson–Patman Act could be improve social welfare by excluding small businesses. The remainder of the paper is organized as follows. Section 2 describes the model. Section 3 presents the analysis. Section 4 briefly discusses several applications. Finally, Section 5 contains concluding remarks.",5
13.0,2.0,"Journal of Industry, Competition and Trade",09 November 2011,https://link.springer.com/article/10.1007/s10842-011-0115-4,Patterns and Effects of Entry in U.S. Airline Markets,June 2013,Kai Hüschelrath,Kathrin Müller,,Male,Female,Unknown,Mix,,
13.0,2.0,"Journal of Industry, Competition and Trade",20 September 2011,https://link.springer.com/article/10.1007/s10842-011-0113-6,Applying the Theory of Small Economies and Competition Policy: The Case of Switzerland,June 2013,Samuel Rutz,,,Male,Unknown,Unknown,Male,"Competition policy is generally viewed as a public policy to promote competition or more specifically to ensure that competition is not restricted by private actors. The core subject areas of competitive restrictions by private actors are cartels, the abuse of market power and mergers. The possible anti-competitive effects of such behaviour are well established in theory and practice. For this reason, competition laws and competition authorities enforcing these laws are largely undisputed today.Footnote 1
 Debatable is however the question whether there is a standardized formula to achieve the goals of competition policy, i.e. a formula which can be applied to all economies irrespective of their specific characteristics. There is currently a tendency in many countries to simply adapt the competition law and the best practice of either the USA or the European Union (EU). To what extent competition legislation and best practice, which was primary conceived for large, market-based and open economies, can be incorporated indiscriminately into “young” economies, developing and emerging countries, small and/or geographically isolated states, is a priori unclear.Footnote 2 This article attempts to provide some answers to the question whether the Swiss economy represents a typical small economy as pertaining to competition policy and—if so—whether this should have implications concerning the substance of the Swiss Cartel Act and the design of institutional aspects of the law enforcement process. The question whether optimal competition policy depends on the size of an economy has lately received considerable attention from theorists as well as practitioners. In particular the contributions of Gal (2001, 2003) have triggered a debate at international level about the effects of size on competition policy.Footnote 3 For example, is it reasonable to assess a merger in a small, isolated economy with highly concentrated markets by the standards used in the USA or the EU? If in such a small economy the same rules are applied as in the USA or the EU, it is likely that a relatively large fraction of all mergers would be considered as problematic due to high post-merger market concentration. The size of the merging firms in such a small economy may however be below average on an international scale, and a merger may therefore possibly be welfare enhancing (e.g. because of the realization of economies of scale or scope). In particular in export-oriented industries the realization of economies of scale and scope may only be achieved at the cost of domestic concentration although the corresponding international markets are contestable and competitive. The case of Switzerland may be an interesting one since, compared to other European countries, Switzerland—in terms of surface area, population, GDP etc.—may be characterized as a typical small economy. Further, Swiss competition legislation is heavily influenced by larger economies, in particular by the EU, in several ways: with the revision of the Swiss Cartel Act in 2003, Switzerland introduced a competition law which is in large parts comparable with EU competition law. Several notices published by the Swiss Competition Commission (ComCo) are basically identical in form and content with the respective EU notices.Footnote 4 Also, when assessing specific cases, ComCo often seeks guidance from EU case law. It is of course reasonable that a small competition authority like ComCo does not constantly “reinvent the wheel” and tries to benefit from the experience and case law of larger states. In the context of the discussion about small economies and competition policy this practice however raises the above-mentioned question whether it is an efficient strategy for Switzerland to simply copy the competition law and mimic the law enforcement process of the EU. This article attempts to provide some answers to this question. Based on the contributions by Gal (2001, 2003) Section 2 summarizes the typical features of small economies. Section 3 analyses whether, according to Gal’s definition, Switzerland must be rated as a small economy. Several (socio-)economic indicators are discussed, which in their sum point to the result that Switzerland does not suffer from a “small economy syndrome”. Section 4 assesses whether the Swiss Cartel Law and the law enforcement process accounts for possible efficiency problems of small economies. Section 5 concludes.",2
13.0,2.0,"Journal of Industry, Competition and Trade",13 January 2012,https://link.springer.com/article/10.1007/s10842-011-0124-3,Should Variable Cost Aid to Attract Foreign Direct Investment be Banned? A European Perspective,June 2013,Mario Mariniello,,,Male,Unknown,Unknown,Male,"In principle, the use of state aid is banned by the Treaty establishing the European Community. One of the main reasons for the ban lies in the fact that subsidies, altering the relative positions of competing firms, usually lead to welfare reducing distortions in the market. The Treaty, however, allows for a number of exceptions to the general ban whenever the potential distortion of a subsidy is low enough to be overcome by its potential benefits, such as the support of a disadvantaged area or the growth of a particular sector of a country’s economy. This paper focuses on aid to attract foreign direct investment (FDI). In such a context, the purpose of this paper is to analyze a well-established policy of the European Commission on the compatibility of state aid with the Treaty’s rules according to which subsidies which lower firms’ variable cost (VCA) are more distortive than subsidies which lower firms’ fixed entry cost (FCA). The intuition behind such an approach is simple: fixed cost aid affect equilibrium price only indirectly by increasing the number of competing firms, if entry barriers were previously preventing one or more firms from entering the market. On the other hand, variable cost aid may impact equilibrium prices not only by altering the number of competing firms (if they allow firms to overcome existing barrier to entry) but also by affecting firms’ cost structure, thereby altering companies’ relative competitive strength. To a certain extent, the definition of variable cost aid coincides with what the Commission calls operating state aid i.e. aid ordinarily associated with business’ normal operations.Footnote 1 As an illustration, consider the Ryanair—Charleroi case.Footnote 2 In short, the publicly controlled airport of Charleroi granted some benefits to the air carrier Ryanair in order to encourage the opening of new routes to Charleroi. These benefits have been considered state aid by the Commission, but only some of them have been found to be incompatible with EU rules, given the exceptional features of the depressed area of Charleroi. The Commission decided that those benefits which were sufficiently tied to the start-up of new routes and to the development of the airport could have been considered compatible with the Treaty of Rome under the provision of Article 107(3)(c). However, those aids which were intended to reduce Ryanair’s variable cost had to be given back, since they did not meet the compatibility criteria established by the Commission.Footnote 3 Examples of the first type of subsidies—those that were finally allowed—are: 160,000 euros per new route opened, up to a maximum amount of 1,920,000 euros; 200 square meters free of charge to be used for offices and as engineering store; a lump sum contribution to promotional activities. Examples of the second type of subsidies—those that were banned—are: a preferential rate for landing charges of 1 euro per boarding passenger, which is about one half of the official standard rate charged to airlines in Belgium; a rate of 1 euro per passenger for ground-handling services which is about ten times lower than the average rate charged to other airlines.Footnote 4
,
Footnote 5
 Rather than being an isolated case, the Ryanair—Charleroi case decision is a manifestation of a general approach which has become evident during past years in the Commission’s official documents and decisions. The Commission’s guidelines on national regional aid clearly state that, in the context of aid to stimulate the development of depressed areas, aid to initial investment is allowed while aid aimed at reducing a firm’s current expenses is normally prohibited.
 Our aim is to study whether this approach is consistent with a rigorous competition policy analysis. Although it is true that state subsidies may introduce distortions in the market, it is not generally true that banning variable cost subsidies and allowing start-up subsidies is always optimal for a welfare maximizing Competition Authority. Generally speaking, the European State Aid policy aim at balancing: from the one hand the ability of the aid to correct for market failure or to effectively target another objective of common interest (such as social or regional cohesion) and from the other hand the distortion in the market which are introduced by the very same aid. To the extent that the balance is in favour of the first effects and the total outcome is overall positive, the aid can be allowed under the European Treaty common rules.Footnote 6 Therefore, any optimal choice requires consideration of the trade-off between the possible gain in welfare due to an increase in competition (which may be brought by variable cost aids too) and the possible loss of welfare brought by the distortions introduced in the market. The model presented in this paper addresses that concern focusing on the competition policy aspect of state aid only and leaving aside alternative possible concerns such as lobbying or public choice issues. The focus is on a specific kind of aid, that is aid to attract FDI, and in the basic setting the two competing firms are foreigners. The European Union Treaty rules are rather open to FDI. Article 63 TFEU establishes that movements of capital, including investment, are free within the European Union. By internationalizing production, FDI can indeed increase competitive pressure and innovation within the common market. On the other hand, FDI can introduce distortions by displacing players’ economic incentives. Therefore, the European policy towards state aid to attract FDI has evolved in the last years, recognizing the value of capital mobility but refining its control towards those behaviors that, if implemented by Member States, could lead to sub-optimal equilibria where welfare is not maximized. The growth in the number of FDI cases, requires a well-thought policy and an efficient allocation of resources for the assessment of such cases. This paper aims at contributing to the debate on possible refinements to the state aid policy in the context of FDI by suggesting a methodology for assessing state aid to attract FDI on the basis of their primary target: firms’ variable or fixed cost. In the economic literature, much has been said on state aid to attract FDI (Brander and Spencer 1985; Krugman 1987; Markusen et al. 1995; Markusen and Venables 1997; Barros and Cabral 2000; Fumagalli 2003) but these works exhibit significant differences with the model presented in this paper. Usually the presence of more than one government competing in order to attract FDI is assumed, local firms are assumed to play a role in host markets and the analysis does not include a comparison among different possible aid instruments which could be implemented. Leahy and Neary (2009), for example, model a multilateral subsidy game with multiple countries and identify the conditions under which a general ban of subsidy increases total welfare. In this paper, on the contrary, I abstract from inter-governmental competition and I focus on the welfare effects of different ways of financing foreign direct investments. Therefore, in the model there is only one government, there are no local producers (the incumbent is also supposed to be foreign-owned) and externalities are not modelled for simplicity. That is: the focus is not on what is the reason why the government wants to subsidize entry—spillovers, labor market imperfections, and so on. The robustness of the model’s results are however tested when these assumption are relaxed in Section 2.1. Even if relaxed in the extensions, the assumption that only foreign firms are competing in the basic model might appear artificial at first sight: a scenario where the incumbent is domestic and the entrant is foreign, is indeed at least as common as a scenario where the incumbent and the entrant are both foreign. However, as we shall see, the analysis of such a scenario is straightforward: a rational government has no incentive to grant VCA if FCA can instead be used to trigger entry, since VCA harm the domestic firm. The object of our analysis is however the welfare effect of an indiscriminate ban of VCA by a supranational authority; thereby the analysis makes sense only insofar VCA can emerge at the equilibrium as a strategy that a rational government could potentially implement to maximize welfare. If not, clearly a ban of VCA would not have any welfare effect. The same reasoning explains why the analysis performed in this article does not consider competition between different governments to attract foreign direct investment. The European Commission exerts a control on state aid to prevent negative spill-over within the European Union. Broadly speaking, this spill-over effect can be triggered by intergovernmental competition or by the alteration of the merits of competition between companies belonging to different member states. The negative presumption towards VCA aims at targeting mostly this second effect. Arguably the same spill-over effects may indeed materialize if competition between Member States is allowed, independently of the type of aid used.Footnote 7 Thereby this papers abstracts from inter-governmental competition and explores the effect of a single government’s equilibrium strategies on competition. As we shall see, the model outlined in Section 2 suggests that VCA is always preferred to FCA whenever the government decides to intervene and both state aid instruments do not cause the incumbent firm to exit the market. This result has at least two significant implications, from a supra-national perspective. As described in Section 2.1.1, the model suggests that banning VCA is a sub-optimal policy if the European Commission adopts a consumer welfare standard or if the competing firms do not belong to the European Union. Conversely, the model suggests that prohibiting VCA is an optimal policy if (and only if) the European Commission adopts a total welfare standard and the incumbent firm originates from a Member State which is not the one granting the aid. Intuitively, in a static setting where the government is assumed to be rational, if both the government and the European Commission maximize the same welfare function, a general ban of subsidies based on the type of instrument used to allocate the resources to the aid recipients cannot be welfare improving. Although the basic setting of the model is rather stylized, the results of the paper appear to be robust to generalization. Garcia and Neven (2005) show how the impact of state aid depends on market concentration: they find that the distortions induced by entry of a subsidized firm tend to be reduced when competition between domestic firms is increased. The results of my paper are shown to be robust to the extension of the game to n playing firms and to the introduction of an externality function which links entry to the local economy. The model is extended for the case in which the incumbent firm is domestic as well. In that case the government internalizes the negative effect on the incumbent’s profits due to entry and state aid becomes less likely. Moreover, the unique kind of aid which is granted at the equilibrium is FCA, because the implicit further reduction in the incumbent’s profits due to a reduction of the entrant’s marginal cost makes VCA always inferior to FCA in terms of welfare. This result suggests that, according to the model, the likelihood of a negative impact of a ban on variable cost aid by the European Commission is reduced whenever domestic firms play a significant role in the game. The model’s results have a clear policy implication: a Competition Authority should assess the impact of an aid on competition and welfare independently of the way in which it is granted, VCA or FCA. A decision which depends largely on the kind of state aid instrument used might then require additional justification and should be carefully analyzed. We are aware that contingent rules are difficult to administer, though. Indeed, the model suggests a rule of thumb which can be used to select those cases where variable cost aid should be looked at with suspect. These are those cases where the incumbent firm is foreigner with respect to the government granting the aid but domestic with respect to the supranational Competition Authority. These results may be naturally compared with those few works in the literature where the authors focus more closely on subsidies and competition in the context of European Union’s competition policy. Collie (2000, 2002) models a situation where governments subsidize their own firms in order to increase their competitiveness and to catch the increasing oligopolistic profits. He then concludes that the shadow cost of subsidization is crucial in determining whether prohibiting state aid is welfare enhancing. In the model outlined in this paper the shadow cost λ of the subsidy has, instead, a secondary impact on the general conclusions. An increase in λ reduces state intervention’s likelihood and increases the advantage given by granting FCA rather than VCA. It turns out that the impact of a ban of VCA on welfare is lower since the government is willing to use VCA in fewer cases. Nevertheless, even taking into consideration that FCA improves its relative advantage with respect to VCA when the entrant is inefficient, FCA would never arise for any value of λ in the basic setting i.e. when both competing firms are foreigners. Thus only VCA can occur at the equilibrium and the general conclusions are unaltered. Besley and Seabright (1999) analyze the role of subsidies in a static and dynamic framework and suggest a way of using the strategic trade literature to assess the European Union’s approach to state aid. Nicolaides and Bilal (1999) check the validity of EU rules on state aid in promoting efficiency arguing that aid aimed to correct market failure should be allowed even if they may have cross-border effects. More recently, Buts et al. (2010) explore empirically the determinants of the Commission’s state aid decisions, finding evidence of consistency between the decisions and the Commission’s general policy’s aims. Compared to these researches, this paper proposes a new theoretical setting in which to assess the European competition policy on state aid. The paper is organized as follows: In the following section I describe the basic setting, solve the model and test the robustness of the results obtained through several extensions to the basic model. In Section 3 I describe the conclusions and discuss the policy implications of the model. The proofs of the results are illustrated in Appendix A (Appendix B contains the minor proofs with all the algebraic expressions, which are not reported in the paper for ease of exposition).",1
13.0,3.0,"Journal of Industry, Competition and Trade",28 February 2012,https://link.springer.com/article/10.1007/s10842-012-0126-9,Collusion in Spatially Separated Markets with Quantity Competition,September 2013,Kai Andree,,,Male,Unknown,Unknown,Male,"In spatial markets the collusive behavior among firms acting has been studied in a large number of papers. The first approach in this area use a linear city model with mill pricing firms and analyzes the relationship between firm locations and sustainability of collusion. For example Chang (1991) and Hackner (1995) use this kind of model with symmetrically located firms and find that collusion is easier to sustain if firms are located further apart.Footnote 1 However, Gupta and Venkatu argue that 
“Typically when transport cost is large relative to total production cost, for example as in the ready-mix cement industry, spatial discriminatory (or delivered) pricing is more appropriate than mill pricing” (Gupta and Venkatu 2001, p. 52). Therefore, these authors study collusive behavior in a linear city model where firms are able to adopt spatial price discrimination. Gupta and Venkatu (2001) show that in their model a smaller firm dispersion is more likely to sustain the collusive agreement. The assumption of price competition is not appropriate for all industries. If quantity is less flexible than the price of the good, then using competition in quantities is more likely. Colombo (2012) analyzes collusion with quantity setting firms that spatially discriminate in two different models: in a linear and in a circular city model. He shows that higher transportation costs increase collusion sustainability. On top of that he investigates the welfare implications and finds that collusion leads to a lower social welfare in a linear city model. In contrast to this in a circular city model a higher welfare might occur. All these approaches make use of the standard assumption of uniformly distributed consumers. However, this assumption does not capture all relevant geographic distributions of population, e.g. consider two large cities that are connected with a highway. In that case, the assumption of uniformly distributed consumers does not reflect reality. Because of that Hwang and Mai (1990) introduce a spatial model with concentrated demand at the two endpoints of a line.Footnote 2
 Using the model setting of Hwang and Mai (1990), Gross and Holahan (2003) study collusion in a model with spatially separated markets, assuming that firms compete in prices in both markets. They show that increasing transportation costs tend to destabilize collusion. In this article we study sustainability of collusion with concentrated demand and quantity setting firms. We use the model setting of Hwang and Mai (1990) and introduce two firms that are able to spatially discriminate, i.e. they are able to sell different quantities at each location. Therefore our paper is closely related to Gross and Holahan (2003). Comparing the results of price vs. quantity competition yields some fruitful insight into the role of the mode of competition on stability of the collusive agreement in a spatial world. Our results indicate that with quantity setting firms an increase in transportation costs leads to a more stable collusion. Furthermore we get the result that rising demand destabilizes collusion with quantity but not with price competition. On top of that we compare social welfare in the case of collusion with the case of competition and show that collusion may lead to higher welfare if transportation costs are relatively high. The paper is organized as follows. Section 2 describes the model and the main results. Section 3 presents the result of the welfare comparison and Section 4 concludes the paper.",5
13.0,3.0,"Journal of Industry, Competition and Trade",06 March 2012,https://link.springer.com/article/10.1007/s10842-012-0127-8,Uncovering Entry Deterrence in the Presence of Learning-by-Doing,September 2013,Ana Espínola-Arredondo,Félix Muñoz-García,,Female,Male,Unknown,Mix,,
13.0,3.0,"Journal of Industry, Competition and Trade",22 May 2012,https://link.springer.com/article/10.1007/s10842-012-0130-0,"Monopoly, Time Consistency, and Dynamic Demands",September 2013,Luca Bossi,Vladimir Petkov,,Male,Male,Unknown,Male,"Past consumption levels can have significant repercussions for current purchase decisions of some commodities. Examples include durable goods (Bulow 1982; Stokey 1981), addictive goods (e.g. Becker and Murphy 1988), storable goods (e.g. Dudine et al. 2006) and goods with switching costs of consumption (e.g. Klemperer 1995). To model the dynamics of consumer decisions, the literature usually assumes preferences that are not time separable. They give rise to intertemporal complementarities or substitutabilities which link consumption today to marginal utility tomorrow. Utility maximization translates these preferences into dynamic demands: purchases will depend on past and current prices, as well as on expectations regarding subsequent market policies (Pollak 1970). It is well-known that dynamic demands may generate a time consistency problem for firms that have market power. Their current profits will depend on expectations of subsequent choices, creating a strategic conflict between a producer’s current and future interests. The reason for this conflict is that a subsequent decision maker will not internalize the effect of his policies on past profits, as they will be considered sunk. Thus, at any point in time, firms will have an incentive to deviate from the plans considered optimal by their predecessors. If they are unable to precommit to future choices, internal competition will impose constraints on their behavior and erode producers’ market power. This paper explores how a monopolist’s choice of instruments affects equilibrium profits and welfare. We analyze a general two-period setting with time non-separable consumer preferences that can incorporate both durable and habit forming goods. In our setup producers no longer have a “natural” state variable. Hence the structure of our setting has important implications for instrument selection. We study and compare the subgame-perfect equilibria associated with two of these instruments: output levels and prices. Our main conclusion is that when firms cannot precommit to future policies, different instruments will generate different equilibrium outcomes. In particular, we find that a time consistent monopolist producing a habit forming good obtains higher profits when he chooses prices rather than quantities. If, however, the monopolist produces a durable good, he is better off choosing output levels instead. The issue of instrument selection is relevant only when precommitment is not feasible. With binding contracts, price postings, or strong reputational mechanisms in place, output policies are always equivalent to pricing policies. The intuition for our results is based on the strategic properties of the monopolist’s intra-personal game. The decision maker’s instruments give rise to different intertemporal considerations, and thus impose different constraints on his behavior. When consumer preferences exhibit intertemporal complementarities, the producer perceives prices as strategic substitutes, while output levels may be strategic complements. Consequently, price choice creates restrictions that are more benign for the monopolist: they allow him to choose policies which are closer to his precommitment optimum. The presence of intertemporal substitutabilities reverses the strategic properties of these variables, making output choice the less restrictive regime. Instrument selection also has interesting implications for welfare. Under some conditions on the instantaneous utility function, price choice may deliver a Pareto improvement over output choice: it yields both higher profits and higher consumer surplus. In other cases, the welfare ranking of these regimes could be reversed. Moreover, producer commitment is Pareto-superior to both time consistent regimes in settings with addiction. This result, however, does not generally apply to durable goods. In light of these findings, we suggest that modeling decisions should account for the strategic properties of the producer’s intra-personal game, as they will affect market conduct when precommitment is infeasible. Since the players in the monopolist’s intra-personal game are agents of a single decision maker, it is plausible that they will coordinate towards the more profitable equilibrium. Our paper is related to several strands of economic literature. It is an example of what Karp (1996) refers to as disadvantageous market power. The idea is that time consistency problems impose constraints on the choices of a monopolist who is unable to precommit. This may prevent him from exerting his full market power. Commitment opportunities can increase profits by eliminating these constraints. The implications of dynamic demands for firm conduct has gained particular prominence in the context of durable goods. Coase (1972) recognizes that durability creates expectations for future price reductions, adversely affecting monopoly profits. The Coase conjecture states that, in the absence of precommitment, the monopolist’s market power will be completely eroded. It inspired a number of papers (Stokey 1981; Bond and Samuelson 1984; Kahn 1986; Gul et al. 1986, and others) which verify the validity of this hypothesis in various settings. A related strand of research (Bulow 1982, 1986) explores mechanisms that allow firms to overcome their time consistency problem. These include renting, planned obsolescence, guaranteed buy-back, and building reputation for maintaining high prices. Other papers have demonstrated that habit formation can also have adverse consequences for market power. Driskill and McCafferty (2001) use a continuous time setting to explore the effect of habit persistence in monopolistic and oligopolistic industries. They find that, in the absence of precommitment, industry profits may be higher under less concentrated market structures. Fethke and Jagannathan (1996) develop a model with two types of buyers: habitual and non-habitual consumers. They show that: (i) when firms choose output levels, steady state consumption under a time consistent monopoly is lower than under commitment or perfect competition; and (ii) the strength of habits and the fraction of habitual consumers does not affect the outcomes under commitment and perfect competition. In a recent paper, Dudine et al. (2006) study time consistent monopolistic pricing of storable goods. They analyze the effect of consumers’ stockpiling in anticipation of higher future prices on the producer’s behavior with and without commitment. In contrast to models of durable goods, the monopolist’s inability to precommit leads to higher prices and lower welfare relative to the precommitment equilibrium. Our model differs from the aforementioned studies in the ability to introduce alternative instruments through simple transformations of the state variable. This would yield multiple subgame-perfect equilibria even in a finite-horizon setting. The objective of our paper is to investigate the implications of instrument selection for the monopolist’s intra-personal game by characterizing and comparing these equilibria. The remainder of the paper is organized as follows: Section 2 presents a general two-period model with time non-separable preferences. Section 3 characterizes the equilibrium outcomes under precommitment, subgame-perfect output choice and subgame-perfect price choice. We then compare output levels, profits and welfare under the three regimes. Section 4 illustrates our results with a linear-quadratic example. Section 5 concludes the paper.",
13.0,3.0,"Journal of Industry, Competition and Trade",05 May 2012,https://link.springer.com/article/10.1007/s10842-012-0129-6,Managing Strategically Outside Options under Incomplete Contracts,September 2013,Antonio Nicita,,,Male,Unknown,Unknown,Male,"The literature on incomplete contracts (Klein et al. 1978; Williamson 1985; Hart and Moore 1990; Hart 1995) has generally focused on the hold-up problem that arises in the absence of ex-post verifiability. Absent contractual safeguards, investments in specific assets may expose investors to the risk of opportunistic renegotiation of the terms contracted upon (the so-called hold-up problem). Under this framework, contractual parties maintain strong incentives to under-invest in asset specificity. In this paper–following previous works by MacLeod and Malcomson (1993), Ishiguro (2009), Nicita and Sepe (2010)–we argue that the standard incomplete contract theory is generally based on a very peculiar notion of market transaction. Indeed, one implicit assumption behind the traditional approach is that the bilateral monopoly situation that does emerge after specific investments are made—the so-called ‘fundamental transformation’ (Williamson 1985)–cannot, in any respect, affect the structure of market competition. In other words, parties’ investments may eventually generate joint surplus for contractual parties, other things being equal. In this respect, parties’ outside options are exogenously determined. Here, we remove the above assumption and extend the traditional framework, in order to analyze the interface between parties’ contractual behavior within the transaction and parties’ competitive options in the market. In particular, we consider the case where contractual parties’ investments may affect competitors’ market options (on their own side of the market) and/or potential counterparts’ offers (on the other side of the market) at the stage of contractual renegotiation. We focus on two polar cases. First, we analyze the case in which transaction-specific investment by one party reduces the outside option of the counterpart. We then investigate the case in which one party’s investment increases her own outside option (thus reducing, in fact, the degree of asset specificity, ex-post). To illustrate the first case (where specific investment by one party reduces counterpart’s outside options), we focus our attention on a framework in which specific investments are made on crucial or ‘essential’ inputs that are scarse in nature. Specific investments in essential inputs may have a dual effect: on the one side they generate contractual quasi-rents (reducing the costs of the seller and/or increasing the value for the buyer); on the other, since they require an intensive use of scarse inputs, these investments reduces competitors’ opportunities to use those inputs. Thus, as the level of transaction-specific investments increases, the investment generates a sort of ‘hoarding effect’ on crucial ‘inputs’ that reduces market opportunities for competitors. In other words, we are considering an investment that is, at once, specific to the transaction (generating quasi-rents) and ‘rival’ for competitors in the market (being scarce or, even, unique). Several examples fit with this case. The simplest is the situation where the investment involves an essential facility (Areeda 1989; Areeda and Hovenkamp 2003), i.e. an asset that is a ‘nonduplicable’ and ‘indispensable’ input for providing services or goods in downstream markets. Electricity and telecommunications networks, gas pipelines, transport infrastructures are all examples of traditional essential facilities requiring transaction-specific investments with dedicated counterparts (for maintenance services, network interconnection/interoperability, capacity expansion, quality enhancement and so on). Besides, also spectrum resources, patented inputs, and copyrighted works may constitute essential or ‘convenient’ facilities (Ridyard 2004; Castaldo and Nicita 2007), as long as they are scarcely available and access to them is necessary to enter downstream markets. Examples of transaction-specific investments involving scarce inputs may include: a telecommunications mobile operator investing in given spectrum resources and a partner, a handset manufacturer patenting compatible wireless technology for dedicated spectrum frequencies; a pay-tv operator investing in the satellite platform and in broadcasting frequencies and a set-top box manufacturer developing a patented encrypted system; a railroad locomotive manufacturer investing in bi-directional locomotive power and a railways network operator investing in power grid interconnection; a gas producer connecting its pipeline into another one whose owner invests in enhancing transmission capacity. Under the above cases, transaction-specific investments increase the value of the transaction, while affecting the structure of the market, as the availability of essential inputs to competitors is decreased ex-post (for instance as the consequence of patent or spectrum hoarding) or simply because investments increase competitors’ opportunity costs to access the networks, and so on (the enhancement of the quality of essential networks will result in higher access prices for competitors). The main consequence would be here that transaction-specific investments also influence the competitive conditions in the market. As investor’s competitors may face ex-post higher opportunity costs to compete in the market, this would result in turn in reduced outside options for the investor’s counterpart (Nicita and Sepe 2010; Nicita and Vatiero 2012). On the other side, we may even think to the opposite situation: additional investments in transaction-specific assets, may eventually increase the investor’s ex-post outside option. This is the case when additional costly ‘versioning’ of a specific technology does open new valuable opportunities in the market. For instance the owner of a gas pipeline–who made transaction-specific investment over the transmission plant in order to maximize the joint surplus deriving from the contract with a gas supplier–may further invest in enhancing transmission capacity, by allowing reverse flow so as to enhance his own outside option as it may transmit now in both directions, contracting with suppliers at the two extreme of the pipeline. Similarly, in the railways sector, additional investments allowing multi-purpose or high-performance universal locomotives to run efficient three-phase AC traction, may increase the outside options of the manufacturer. A decoder manufacturer involved in a contractual relationship with a pay-tv operator may additional invest in order to make their decoders more universally usable (for instance, simulcrypt and multicrypt variants). Besides, another example is given by a patented, transaction specific technology that, once deployed and revealed to the market, ‘creates’ a new standard. The Silicon Graphics/Industrial Light & Magic case illustrates this situation (Varian and Shapiro 1999). A leading company specialized in motion picture visual effects (Industrial Light) signed a contract involving very specific technology with a small firm (Silicon Graphics) making high-end graphics workstations, for 3D visual effects. Since the Silicon Graphics Crimson system with the three-dimensional file system navigator appeared in the movie Jurassic Park, the technology provided by Silicon Graphics became a standard and for 8 years in a row all films nominated for an Academy Award, for distinguished achievement in visual effects, were indeed created on Silicon Graphics computer systems. Thus what was initially a specific investment soon turned out to ‘create’ a market, therefore reducing, the degree of specificity ex-post. All the above examples entail situations in which parties’ outside options might be endogenous, being affected by the nature of transaction-specific investments. The standard literature on incomplete contracts has almost neglected the above situations, being firmly grounded on the assumption that parties’ transactio-specific investments in an incomplete contract are always monotonic in their specificity degree and that technology cannot affect parties’ opportunities outside the transaction. In this paper we remove this assumption, considering situations in which co-monotonicity may emerge between investments that are ex-ante specific and parties’ outside options. In one case, we assume a negative co-monotonicity between a party’s investments and counterpart’s outside options; in the other we explore a positive co-monotonicity between one party’s investments and her own outside options. These are entirely new circumstances that have not been explored so far. The case in which, once made, specific investments affect not only contractual quasi-rents, but also the structure of market competition is particularly interesting, in that, contrary to standard literature, investments may also reduce competitors’ options (thus decreasing the counterpart’s outside options) or increase investor’s options (thus increasing counterpart’s competitors). The research question we investigate here is then the impact of such endogenous outside options on parties’ incentives to invest in incomplete contracts. Indeed, following the ‘outside option principle’ (Binmore et al. 1989), parties’ outside options affect their bargaining power at the renegotiation stage of an incomplete contract. In this respect, a reduced counterpart’s outside option (or an increased investor’s outside option) at the renegotiation stage may improve the bargaining power of the party with ex-post better outside options and hence, her ability to protect the noncontractible specific investments made in the transaction, against counterpart’s hold-up. When this is the case, we find that, contrary to standard literature, parties’ maintain strong incentives toward specific investments, as the latter reduce, rather than increasing, the probability of hold-up. Once we allow parties’ investment to affect outside options, several interesting equilibria may emerge. In some circumstances, parties may even over-invest in incomplete contracts rather than under-invest, as standard literature would predict. Moreover, under some equilibria, over-investment may act as an endogenous enforcement device for incomplete contracts. This is a surprising result as it shows that, contrary to standard literature, under given circumstances parties’ may start (over)investing in an incomplete contract relationship, despite the risk of hold-up. When ex-ante transaction-specific investments reduce a counterpart’s outside options, the investor will indeed increase his ex-post bargaining power, with a countervailing effect against counterpart’s opportunistic renegotiation. The same result applies when a party will increase, through (over)investment, her own ex-post outside option. We discuss the implications of our analysis for the management of incomplete contracts and for the competitive assessment of vertical integration processes. The paper proceeds as follows. In section 2 we recall the standard underinvestment result in an incomplete contracts framework, while in sections 3 and 4 we consider the case of endogenous outside options. Section 4 outlines the main results reached. Section 5 draws the main conclusions.",1
13.0,3.0,"Journal of Industry, Competition and Trade",02 December 2011,https://link.springer.com/article/10.1007/s10842-011-0117-2,Competition Effects in a Liberalized Railway Market,September 2013,Markus Lang,Marc Laperrouza,Matthias Finger,Male,Male,Male,Male,"The introduction of competition in the European railway market lies at the center of the reforms initiated by the European Commission. Competition was expected to play several roles: revitalize the sector, increase efficiency among the railway firms as well as have positive spillover effects on the European economy in general. As a general rule in Europe, one can observe more competition in freight than in the passenger segment. For instance, the Swiss incumbent operator SBB Cargo has lost more than 10% market share between 2006 and 2009 for transalpine rail freight passing through Switzerland (SBB 2010). In Romania, private freight firms have captured 25% of the total ton-kilometer, whereas the figure stands at 15% in Poland (Pittman et al. 2007). The situation is not identical in the passenger segment as only very few countries have witnessed the emergence of competition on the tracks (e.g., United Kingdom). Notwithstanding structural reasons this can be explained by an earlier mandated opening of the freight segment to competition.Footnote 1 Except for the United Kingdom, which is characterized by an oligopoly of private train operating companies, long-distance passenger services are by-and-large dominated by the incumbent operators (Beckers et al. 2009). In addition, access to the rail infrastructure is a crucial component of the European railway liberalization process (Gibson et al. 2002; Crozet 2004; ECMT 2005; Nash 2005). For instance, the European Union legislation requires Member States to separate the rail infrastructure from operations and to calculate access charges for the use of the rail infrastructure on a transparent and non-discriminatory basis.Footnote 2 The First Railway Package required Member States to separate the management of infrastructure, freight and passenger services into separate divisions with their own profit and loss accounts and balance sheets.Footnote 3 While no particular organizational model was required by the EU Directives, one can identify three alternative models of railway restructuring: complete separation, the holding company and the separation of key powers (Nash 2008). Although the exact degree of separation between infrastructure and operations differs across countries, complete separation is the most commonly used restructuring scheme in Europe. It has been adopted by Member States in northern and western Europe. Access charges to the rail infrastructure should be set in a way that encourages efficient use while avoiding discrimination among similar users (Thompson and Perkins 2006). In practice, one can observe large difference in access charges between freight and passenger transport and across European countries. Member States follow three broad models for infrastructure access charges (OECD 2005): (i) social marginal cost pricing, in which the state covers the difference between total financial costs and revenues, (ii) the full financial cost minus subsidies in which access charges are set to cover the difference between state transfers and the full financial cost and (iii) mark-ups to social marginal costs, which serves both efficiency goals and budgetary pressures. In addition, the structure of access charges can be divided into single and two-part tariffs. In the former case, prices are set in relation to the usage of the network (e.g., train-kilometer or gross-ton kilometer). In the latter case, operators pay a mixture of fixed and variable prices (Freebairn 1998). In short, access charges remain an important issue for the European railway policy in its attempt to ensure non-discriminatory access to the existing network. At the same time, they play an important role in determining the competitiveness of new railway lines (Sánchez-Borràs et al. 2010).Footnote 4 It is therefore not surprising that access charges in railway economics have drawn significant interest at the theoretical level (Dodgson 1994; Bassanini and Poulet 2000; Nash and Sansom 2001; Quinet 2003; Link 2004; Erhan and Robert 2005). While the existing literature has focused largely on cost-allocation methods, empirical studies, and analytical studies of access charges in a vertically integrated railway market, this paper presents a game-theoretic model of a liberalized railway market, in which train operation and ownership of infrastructure is fully vertically separated. To the best of our knowledge, we are the first to model a vertically separated railway market. In particular, we apply non-cooperative game theory to model the interactions between decision-makers in the railway industry to determine their optimal behavior. Our model incorporates operators, consumers, the regulatory agency and the infrastructure manager. We further differentiate two segments in the railway market: the passenger segment and the freight segment. Moreover, our analysis features a two-stage setup: in the first stage, the regulatory agency sets access charges to maximize social welfare and in the second stage, the operators simultaneously maximize their profits. Besides the contribution to the literature on railways, we contribute to the literature on access pricing. Existing studies mainly concern situations in which infrastructure and service provision are integrated in an incumbent firm, which then provides access to the essential facility to its competitor(s) on the service market, and/or the price to final consumers is regulated (e.g., Vickers 1995; Armstrong and Vickers 1998; Armstrong et al. 1996; Cave and Vogelsang 2003; Armstrong 2008). Our paper looks at a novel case that is becoming increasingly important in practice, after the recent adoption of vertical-separation and price-deregulation policies. The objective of this paper is to analyze how a regulatory agency will optimally set access charges to the infrastructure in a vertically separated railway market and how this price-setting behavior changes with increased competition in this market. Moreover, we explicitly assess the effect of increased competition on the price per kilometer, the outputs and profits of the operators, consumer surplus, and finally, we assess the welfare implications. The paper is of interest to operators, infrastructure managers, regulators and policy makers in the railway industry because recommendations can be derived on how to optimally set access charges from a social welfare perspective. The remainder of the paper is structured as follows. Section 2 presents the model framework of a separated railway market and introduces its main actors. In Section 3, we solve the maximization problems of the operators and the regulatory agency. In Section 4, we analyze the effects of more competition. Section 5 extends the model to two-part tariffs and discusses different objective functions of the regulatory agency. Finally, Section 6 discusses the main findings and concludes the paper.",9
13.0,3.0,"Journal of Industry, Competition and Trade",07 June 2012,https://link.springer.com/article/10.1007/s10842-012-0131-z,"Ownership, Scale Economies and Efficiency in the Italian Water Sector",September 2013,Valeria Di Cosmo,,,Female,Unknown,Unknown,Female,"The European water framework directive 60/2000 (WFD thereafter), establishes that the water tariffs should lead the water companies to fully recover their capital costs and to efficiently charge the final consumers for the water provision; in Italy the regulators fix the final water price by following a benchmark rule, which estimates the operative costs of the firms given the price of materials, the length of the pipelines and the water delivered.Footnote 1 It is then important to evaluate whether inefficiencies arise from the firm’s proposed benchmark and which gains can be achieved by correctly monitoring them. The first scope of the paper is to calculate the inefficiencies of the Italian water sector by stochastic frontier analysis. Second, I examine whether the firm ownership and location are related to the company inefficiencies. Finally, I estimate the degree of economies of scale in the Italian water sector. The Italian water sector is characterized by the presence of almost 100 water companies regulated by 92 regulators (ATO). Even if the number of regulators has been recently discussed and should be redefined in the next years, the large number of regulators associated to the presence of different ownership types pose some interesting questions related to the company efficiencies. Although the relation between company ownership and efficiency has been analyzed by a large number of researchers, the final results are quite controversial.Footnote 2 As result, it is difficult to establish if the private water companies are effectively more efficient than the public ones. The first reform of the Italian water sector was the so called “Galli’s Act”, which allows the (partial) liberalization of the water sector and splits the Italian climate homogeneous areas into 99 sub-regional administrative divisions (ato), that represent the local authorities, and can autonomously decide their water company concession. The constitution of the local authorities has been a slow process: until 2009 only 92 of the 99 regulators were effectively working. The existing works which study the determinants of the inefficiencies in the Italian water sector could not properly analyze the effect of the regulators on the sector performance, either because they use 10 years old data, that don’t include the ownership type of the water companies (Antonioli and Filippini 2001 or Fabbri and Fraquelli 2000) or use data on the forecasted costs to assess the role of the heterogeneity in the sector, but cannot investigate the impact of the ownership type on the efficiency (Abrate et al. 2011). Moreover, from the recent past, the number of regulated companies has significantly changed: the merging process of different water firms has potentially fulfilled the demand of economies of scale highlighted by Fabbri and Fraquelli (2000). To assess these issues I estimate a translog cost function, whose determinants are the input prices, the water delivered, the number of consumer served and the geographical area. I follow both the Battese and Coelli (1995) and the Pitt and Lee (1981) approaches to estimate the firm inefficiencies and identify their determinants.Footnote 3 I verify whether the theoretical conditions that characterize this functional form are satisfied in my sample; where the standard properties are not verified, I impose them following the three steps procedure proposed by Henningsen and Henning (2009). This research contributes to the literature because (i) it analyzes the Italian water sector performance with (almost) all the regulators effectively at work and (ii) it presents some highlights on the ownership and scale effects that should be taken into account when determining the optimal tariff scheme. Therefore, my results can be directly compared with similar studies, but also provide some insights on the Italian water sector that can be useful implemented under the WFD. First, my results show that the relation between the firm’s inefficiencies and the firm’s ownership is not statistically significant. This means that the recent privatization process has not affected the performance of the companies. This result seems counter intuitive, but it is not surprising considering the specificity of the Italian water sector. On one hand, the absence of a strong and independent regulator leads to regulation uncertainty that negatively affects the water firm performances, independently from their ownership. On the other hand, the presence of 92 different ato can lead to the well known “regulator’s capture” problem, and then discourage the positive firm’s performance. Second, my results show that the number of consumers served are significant determinants of the firm inefficiencies. Third, the estimation results reveal the existence of a positive degree of the scale economies in the analyzed sector. Although the Galli’s Act explicitly encouraged the consolidation between different companies, the small local communities may still benefit from merging into water districts. The outline of the paper is as follows. Section 2 briefly reviews the existent literature on the water sector efficiency. Section 3 describes the data and presents the estimated cost function, the results of the estimation of the elasticities are discussed in Section 4, while the economies of scale are presented in Section 5. Conclusion of the study are summarized in the final section. The data and variables construction are presented in the Appendix.",3
13.0,3.0,"Journal of Industry, Competition and Trade",21 April 2012,https://link.springer.com/article/10.1007/s10842-012-0128-7,Marginal Intra-Industry Trade and Employment Reallocation: The Case Study of Iran’s Manufacturing Industries,September 2013,Saeed Rasekhi,Saman Ghaderi,,Male,,Unknown,Mix,,
13.0,3.0,"Journal of Industry, Competition and Trade",21 November 2012,https://link.springer.com/article/10.1007/s10842-012-0149-2,Estimating Consumer Lock-In Effects from Firm-Level Data,September 2013,Gábor Kézdi,Gergely Csorba,,Male,Male,Unknown,Male,"Consumer lock-in is a critical factor in evaluating firms’ market power in a dynamic framework. If consumers’ ability to change their service provider is limited, due to the presence of switching costs for instance, then it decreases the elasticity of demand, which can lead to price increases in later periods. Consumer lock-in may also contribute to raising barriers to expansion for competitors, enabling incumbent firms to conserve their strong market position. These theories of harm imply that lock-in is an important concern for competition authorities and sectoral regulators alike,Footnote 1 and regulatory policies were specifically designed to increase consumer mobility in most network industries.Footnote 2
 This paper proposes a practical and intuitive approach for estimating lock-in effects in a direct way, which has two practical advantages. First, it stays within a demand analysis framework and thus there is no need to make strong assumptions on market structure. Second, it requires only firm-level data, which are less expensive and easier to collect than consumer-level data, and most regulatory bodies have the legislative power to acquire them. We develop an empirical method that compares the reactions of new consumers to the reactions of old consumers with respect to price changes.Footnote 3 The difference between these two reactions will give an indication on firms’ market power over old consumers. The basis of our identification is the idea that the behavior of new consumers can describe the behavior of old consumers in the absence of lock-in. In other words, the group of new consumers can provide the counterfactual outcomes to the group of old consumers, in the spirit of the program evaluation literature (see, for example, Imbens and Wooldridge 2009).Footnote 4
 When we have ideal data at hand, our empirical model consists of a system of two panel regressions estimated in first differences, which measures the effect of a change in the relative price of a given firm on the respective firm’s “market share” between two groups of consumers. The dependent variable in the first equation is the market share of the respective firm in terms of consumers who are new to the market. The dependent variable in the second equation is the retention rate, i.e. the “market share” of the firm among its own customers from the previous time period. The lock-in effects are measured by comparing the effects of the same price change on these two market shares. The difference of the two responses is the fraction of old consumers who would have switched if they had been new consumers but were prevented from doing so because of lock-in. This identification strategy is very similar to a “difference-in-differences” approach, in which one compares the behavioral response of a group that may be locked-in to the behavioral response of another group that is not. For the counterfactual approach to successfully identify the lock-in effects, the two groups of old and new consumers have to be similar in terms of their price elasticity and switching behavior. This assumption does allow for differences among consumers entering the market in different time periods, as long as such differences are controlled for or are unrelated to the behavior we examine.Footnote 5 We believe that this condition is more likely to be satisfied in developed markets and/or markets with relatively homogenous goods, in which market entry may be due to exogenous shocks. Examples for such markets include loan contracts—which we analyze in our application—, consumer utilities and standard telecommunication services. Incidentally, these are also the typical industries where competition policy and regulation are more concerned with problems of market power. With appropriate data, this counterfactual approach can be implemented in a relatively straightforward fashion by panel data methods with firm-specific and time fixed effects. Unfortunately, however, information on consumers who are new to the market and old consumers who switch to other firms is typically not present in firm-level data.Footnote 6 We therefore implement the proposed method by using the number of consumers joining firms and the number of consumers leaving firms and construct proxy variables for changes in the fraction of new and old consumers. We address the potential biases due to the use of such proxy variables, and develop an easy-to-implement formula that corrects for the biases under reasonable assumptions. Data on prices and the number of consumers joining and leaving firms are usually available in markets with long-term contracts. As an illustration, we apply the estimation method to the market of personal loans in Hungary. According to our estimates, a one percentage point increase in interest rates leads to a 0.61 percentage points decrease in demand among new consumers, compared to a 0.13 percentage points decrease among the banks’ old consumers. This means that old consumers’ responsiveness is four fifths lower than the responsiveness of new consumers. Our bias-corrected estimates indicate substantial lock-in as well. We can reject the hypothesis of perfect consumer mobility, while the hypothesis of complete consumer lock-in (as assumed in many theoretical models) cannot be rejected. Our method was applied in the banking sector inquiry of the Hungarian Competition Authority, and as a result, several regulatory recommendations were made to facilitate consumers’ switching between firms.",1
13.0,4.0,"Journal of Industry, Competition and Trade",09 October 2012,https://link.springer.com/article/10.1007/s10842-012-0137-6,Price-Increasing Competition on Two-Sided Markets with Homogeneous Platforms,December 2013,Enrico Böhme,Christopher Müller,,Male,Male,Unknown,Male,"When teaching students the basic insights of microeconomics, most economists claim that competition decreases prices and increases welfare as compared to a monopoly market. This standard view of the relationship of competition and prices is further deepened when teaching the standard Bertrand-model of duopolistic competition, i.e. when claiming that price competition among two firms is sufficient to create perfect competition. But is it really that clear, easy, and straightforward? A number of theoretical contributions present models that predict the opposite effect. Price-increasing competition on one-sided markets has been reported as the result of product differentiation (see Chen and Riordan 2008; Melzer and Morgan 2009; Bertoletti et al. 2008 for recent contributions and the references therein) and in the presence of search costs (Janssen and Moraga-González 2004; Schulz and Stahl 1996). In contrast, we argue that the “two-sidedness” of markets might also be an explanation for this phenomenon without relying on product differentiation or the like. The question of price changes with regard to market structure becomes relevant when policy makers consider subsidies in order to attract new entrants to given monopoly markets. Reversely, antitrust authorities need to assess the impact of mergers on prices. A positive correlation of price and market concentration is also the fundamental assumption of the empirical price-concentration literature that aims at measuring the price effect of market concentration. An industry is two-sided, if there are two groups of agents (the market sides) that use an intermediary service (the platform) to interact. The market sides exert indirect externalities on each other: The benefit of each Side 1 agent depends on the number of Side 2 agents and vice versa. The literature distinguishes three types of platforms: market-makers, demand-coordinators, and audience-makers (Evans 2003a, b).Footnote 1 Our model focuses on audience-making platforms, that is, we consider media platforms that try to get audience or consumers (one market side) on board and sell the attention of their audience or “pairs of eyeballs” (Ambrus and Reisinger 2006, p. 24) to advertisers (the other market side). Most theoretical models of audience-makers assume that consumers wish to see, read or listen to the media content only, and are “coerced” to consume advertising as well (see e.g. Anderson and Coate 2005; Gabszewicz et al. 2004; Gal-Or and Dukes 2003; Peitz and Valletti 2008).Footnote 2 Empirical results support this ad-aversion assumption for television viewers (see e.g. Danaher 1995; Wilbur 2008) and magazines (Kaiser and Wright 2006), but find ad-liking for other print media (Kaiser and Song 2009; Rysman 2004). Ad-aversion means that advertisers exert a negative externality on the audience. To get audience on board anyhow, the platform operator offers an intrinsic benefit to consumers, for instance a movie, news or other content. The advertisers’ benefit stems from the positive externality only. This is in contrast to the prominent examples of credit cards (Rochet and Tirole 2003) and internet dating platforms (Caillaud and Jullien 2001, 2003), in which both market sides exert positive externalities on each other and agents do not obtain intrinsic benefits. Depending on the context, agents may be restricted to using one platform only (single-homing) or they may be able to join more than one platform (multi-homing). Platform competition is fiercer, if agents are restricted to single-homing, because interaction with single-homing agents can exclusively take place via the platform the agent chose, while multi-homing agents may be contacted using a rival platform as well. More generally, it is well-known that on two-sided markets the traditional price–cost relationship with respect to the degree of competition does not hold, because the degree of competition might differ between market sides so that an increase in the number of rival platforms might lead to a higher price on the less competitive side to subsidize (price below marginal cost) the more competitive side (see e.g. Wright 2004). If one market side is restricted to single-homing, while the other market side is able to multi-home, we have a “competitive bottleneck” (Armstrong 2006).Footnote 3 For such a competitive bottleneck, Armstrong finds that competition only emerges on the single-homing market side and that even under duopolistic competition, the platform is a monopolist towards the multi-homing side: Media providers compete for audience, because advertising demand depends on the size of the audience. To reach this single-homing audience, the advertiser must place an ad on this platform. If the advertisers’ willingness to pay is sufficiently high, the platform might subsidize consumers out of advertising revenues. However, while Armstrong finds the regular price-concentration relationship (prices decrease in the number of platforms) on the competitive market side (consumers), we find that also the contrary may be the case. Our result is driven by the increase in total consumer demand that occurs because of a decrease in advertising levels per platform under duopoly. We call this the demand-enhancing effect of competition. This effect cannot occur in Armstrong’s duopoly model, because he models platform heterogeneity by placing consumers along a Hotelling line with fixed platform locations at each end of the line. He studies symmetric equilibria, thereby excluding local monopolies. This implies that he has full market coverage with inelastic demand (in price and ad-quantity), and therefore no demand-enhancing effect. A similar argument holds for Anderson and Coate 2005, who find that advertising levels do not depend on the number of firms if (subscription) pricing is possible. Their model also strictly requires heterogeneous platforms, which per se reduces price competition in their duopoly case. While our model entirely focuses on homogeneous platforms, Anderson and Coate 2005 do not provide a solution for this case. We assume a specific competitive bottleneck in which consumers single-home and advertisers multi-home. To keep the results comparable, we use the same modeling framework for monopoly and duopoly. Our argument is that the demand-enhancing effect drives prices upwards, but platform competition has the opposite effect. We show that it is possible that the competition effect does not fully compensate the demand-enhancing effect. As a result, consumer prices may increase as the market concentration decreases from monopoly to duopoly or, if these effects are of equal magnitude, there is no observable price effect of competition. Since the advertising price remains at the monopoly level, this price increase is not offset by a price decrease on the other market side. Hence, we find that competition may result in an increase of the total price (i.e. the sum of prices). However, the results of our paper are only valid for a very specific type of two-sided market, i.e. the media and advertising market. Chandra and Collard-Wexler 2009 also find counter-intuitive price effects with regard to competition on a competitive bottleneck duopoly empirically. They compare pricing under duopolistic competition and joint management of two platforms. Similar to our paper, they find that under specific conditions a merger might lead to a price decrease instead of a price increase. However, their argument and setting is completely different from ours. In their model, platforms can exert negative externalities on each other’s profit by increasing their prices. Under joint management this externality would be internalized, which might result in lower monopoly prices. The basic economic effect in their model is analog to the well-known effects occurring when merging two firms with complementary products on a traditional one-sided market. To focus solely on the effects of the two-sidedness, we neither allow for platform differentiation, nor do we impose structural differences in terms of costs, scale effects or capacity constraints that might per se favor the one or the other market structure. To prove our claim and illustrate the intuition, we proceed as follows: In Section 2, we develop a monopoly model and derive the monopolist’s optimal pricing policy, whereas in Section 3, we suggest a model of duopolistic competition that is founded on the same assumptions as the monopoly model, thus being fully comparable. In Section 4, we compare the equilibrium outcome under duopoly and the monopolist’s optimum. We show that there are parameter sets that yield price-increasing competition as a result. In Section 5, we illustrate our proposition using numerical examples. Finally, we conclude and highlight some implications of our findings in Section 6.",1
13.0,4.0,"Journal of Industry, Competition and Trade",07 July 2012,https://link.springer.com/article/10.1007/s10842-012-0134-9,Stability Analysis in a Bertrand Duopoly with Different Product Quality and Heterogeneous Expectations,December 2013,Luciano Fanti,Luca Gori,,Male,Male,Unknown,Male,"It is observed that firms often supply differentiated products on the market, so that consumers face a large domain of varieties, which can sometimes unambiguously be ranked along some quality ladders. The focus of the present study is the analysis of the local stability properties of a nonlinear duopoly (see Bischi et al. 2010) with price competition and vertical differentiation. There exists an established literature that deals with problems of horizontal (quantity) and vertical (quality) differentiation of goods and services in static oligopolies, essentially to rank equilibrium outcomes in both Cournot and Bertrand competition models. Studies that deal with the former type of product differentiation date back at least to the works by Dixit (1979), Singh and Vives (1984) and Vives (1985), while examples of the latter can be found in Gabszewicz and Thisse (1979), Shaked and Sutton (1982), Motta (1993), Wauthy (1996), Häckner (2000) and Correa-López and Naylor (2004). The findings of this literature represent a cornerstone of the oligopoly theory. Another strand of literature on nonlinear oligopolies analyse several aspects of dynamic phenomena (e.g., local and global stability of dynamic systems). This literature is of increasing importance and makes expectations formation mechanisms different from the rational expectations paradigm relevant (see, e.g., Chiarella 1986, 1990; Puu 1991, 1998; Agliari et al. 2006). As is known, the Nash equilibrium in a dynamic duopoly with standard linear demand and cost functions is stable if expectations of every firm are “naïve” (i.e., each firm expects that the value of the strategic variable set by the rival to maximise profits in the future period is equal to the current period one), as shown by Theocharis (1960) in a duopoly with quantity competition à la Cournot (1838). However, if expectations of one or both firms are those of the type suggested by, e.g., Bischi et al. (1998, 1999), i.e. firms do not perfectly infer the decisions of competitors (bounded rationality) and increase/decrease their control variable in the current period depending on information given by marginal profits in the previous period (see Dixit 1986; Bischi and Naimzada 2000), then the equilibrium in a duopoly game with standard linear demand and cost functions may be destabilised when the reaction of every firm is large enough, as shown by Kopel (1996). In particular, the stability issue in duopoly games without vertical differentiation has been analysed, amongst others, by (a) Agiza and Elsadany (2003, 2004), Zhang et al. (2007), Tramontana (2010) and Fanti and Gori (2012), as regards quantity competition, and (b) Zhang et al. (2009) and Fanti and Gori (2011), as regards price competition. However, at the best of our knowledge, the stability analysis in a duopoly with price competition (Bertrand 1883) in which firms provide products of different (say, high and low) quality, has not been so far tackled on. In this paper we aim to fill this gap by studying two distinct cases with both covered and uncovered markets: (a) the high-quality firm has bounded rational expectations and the low quality firm has naïve expectations; (b) the low-quality firm has bounded rational expectations and the high-quality firm has naïve expectations.Footnote 1 With regards to covered markets, we find that stability of prices in the long run depends only on the extent of consumer’s heterogeneity. With regards to uncovered markets, the quality differential matters. The remainder of the paper is organised as follows. Section 2 introduces the model. Section 3 (resp. Section 4) studies the stability properties of the dynamic system under the hypothesis of covered (resp. uncovered) market. Section 5 concludes.",3
13.0,4.0,"Journal of Industry, Competition and Trade",05 October 2012,https://link.springer.com/article/10.1007/s10842-012-0147-4,Reimbursement and Investment: Prospective Payment and For-Profit Hospitals’ Market Share,December 2013,Seungchul Lee,Robert E. Rosenman,,Unknown,Male,Unknown,Male,"This work is motivated by two observations. One is that over the past decade hospitals have become increasingly concerned about cost control, sometimes, it appears, at the expense of investment that would enhance the quality of patient care. The second observation is the significant growth in market share of for-profit hospitals. From 1980 to 2007, the growth of for-profit hospitals among U.S. community hospitals was 5.3 %, faster than the 2.7 % growth of not-for-profit hospitals. Government hospitals’ market share declined by 7.8 % during this same period, (Table 1). One question to arise from these observations is whether these simultaneous adjustments are coincidental or has the the hospital market undergone a fundamental structural change that is responsible for both these adjustments?
 The most obvious structural change since 1980 is the shift from retrospective to prospective payment for a large share of patients, starting with those covered by Medicare. This paper provides a theoretical argument that the move to prospective payment is at least partially responsible for shifting the focus of hospital investment from quality-enhancing technologies to cost-saving technologies, and this change has allowed for-profit hospitals to become more competitive in the hospital market. The source through which reimbursement affects hospital behavior comes from the fact that hospitals, whether for-profit or not-for-profit, can improve their bottom lines either by attracting more patients or by controlling costs. One way to attract patients is with high quality, while investments can serve to increase quality or lower costs or both. How a hospital is reimbursed changes its payoff from each type of investment. If, as we conjecture, the payment system affects investment strategies, it becomes an important tool for quality as well as for cost. This last point is not particularly novel. Weisbrod (1991) discussed at length about how the payment system affects investment strategies by hospitals, noting that retrospective payment induces the development of quality enhancing technologies, while prospective payment induces the development of cost saving technologies. What is novel, however, in this paper, is how the change in the payment system caused a structural shift leading to a growing market share for for-profit hospitals, increasing mixed competition in hospital markets. There are three issues relevant to our analysis: how a shift from retrospective to prospective payment changed the investment strategy hospitals follow; the link between payment system and quality; and finally, what all this means for mixed competition between for-profit and not-for-profit hospitals. There exists an extensive and varied literature on competition between for-profit and not-for-profit hospitals. Gaynor and Town (2012) provide a comprehensive review of the literature on hospital competition. What is relevant for the present paper is competition between hospitals under administratively set prices. Gaynor and Town note that “entire health systems (e.g. the British National Health Service), or sectors of health systems (e.g. the Medicare program in the US)” operate this way, and in such a situation, the currency of competition is “quality” broadly defined. In a market allowing for entry, they show that quality is increasing in the administratively set price, the elastiticity of demand with respect to quality and total demand, and decreasing in the marginal cost of quality and quantity, with similar results if hospitals are for-profit or not-for-profit, although equilibrium quality is higher if hospitals are not-for-profit. Their review of empirical studies on quality and hospital competition find ambiguous results, although a majority of such studies finds more competition increases quality. Recently Brekke et al. (2011) explain the ambiguous empirical results by allowing quality and costs to be complements (for example, when more practice makes for better results) or substitutes (so increasing quality increases per unit cost) and having differing degrees of altruism among hospitals. Herr (2011) finds public welfare and quality can improve if a private hospital drives out a less efficient public hospital. Gaynor and Town do not directly confront mixed competition. Explanations for why mixed competition can exist fall into two general classes, those predicated on different preferences on the part of consumers of hospital services, and those that are modeled around a shortage of providers with not-for-profit preferences. An example of the first is Friesner and Rosenman (2002). They model two types of consumers—those who are price sensitive and those who, because of insurance or payment by government programs, are not. Both types of consumers also care about quality. In an equilibrium, mixed competition results from profit maximizing hospitals catering to the price sensitive consumers, while not-for-profit hospitals, which care about quality and/or quantity as well as profit, cater primarily to those consumers who are not price sensitive. In this framework, for-profit hospitals give a lower quality of care and lower prices than do not-for-profit hospitals Different types of hospitals exist to better match consumer demand. Lakdawalla and Philipson (2006) exemplify the second explanation, where mixed competition is possible through a shortage of providers with not-for-profit (profit deviating) preferences. Noting that a preference for output is similar to taking wealth in an alternative form, for-profit hospitals compete with not-for-profit hospitals, who otherwise come to dominate the market, only because there is a shortage of potential providers with profit-deviating preferences. Preferences may also deviate from profit maximization along a quality dimension, with the result being mixed competition at all levels of quality. At any quality level where demand exceeds the supply from profit deviators, for-profit firms enter and control the market by being the marginal firm. Lakdawalla and Philipson provide a concise review of the empirical literature that supports their conclusions. Our approach to mixed competition embraces elements of both Lakdawalla and Philipson and Friesner and Rosenman. Like Friesner and Rosenman, we have a duopoly supply facing heterogeneous consumers who differ along relative preferences for quality and the opportunity cost of time; which plays essentially the same role that price sensitivity did in their model. As in Lakdawalla and Philipson, the not-for-profit hospital will dominate the market due to its willingness to accept part of its return in utility rather than money. At the extreme, as in Lakdawalla and Philipson, the for-profit hospital can compete only if the not-for-profit hospital supplies an insufficient level of quality to attract all consumers. At all other times it is heterogeneous consumer preferences that allow the for-profit hospital to compete. Our contribution to this literature is that we explain how the for-profit firm can better compete under prospective payment systems than under retrospective payment systems, and the increased ability to compete works through a greater investment in both quality and cost technologies. In terms of quality, for-profit firms unambiguously increases quality while not-for-profit firms likely decreases quality when there is a switch from retrospective to prospective payments. This is consistent with Brekke, Siciliani and Straume who conclude that competition should lead to a convergence between the quality at for-profit and not-for-profit hospitals. Our results are driven by the fact that consumers, all else equal, prefer higher quality health care. The impact of prospective payment on hospital quality is well-studied. Allen and Gertler (1991) found that DRG type payments cause a distributional loss when compared to retrospective payment, and that government rate setting cannot induce first-best quality for heterogeneous patients. They provide an early review of the literature on how prospective payment might affect quality. More recently Siciliani (2006) shows that a fully prospective payment system may lower quality by inducing more intense treatment than is necessary – in his model patients who would be best served by low-intensity medical treatment get high-intensity surgical treatment because the DRG payment is higher. Selder (2005) finds that if physicians switch from fee-for-service payment capitation would lower the treatment given severely ill patients. Empirical analyses have focused more on specific treatments. A meta-analysis of RAND Corporation studies on how prospective payment affected the quality of care for a variety of treatments (RAND 2006) found little or no change in the direct quality of care, although it did find that patients were discharged in poorer conditions after prospective payment was implemented. To the extent that early discharge can be interpreted as lower quality, this is consistent with what we find. The novel idea in our paper is the avenue for-profit hospitals used to compete when prospective payment is implemented—an increase in both quality improving investments and cost saving investments. Not-for-profit hospitals, on the other hand, invest less in quality improving technology after a switch from retrospective to prospective payment, but more in cost saving technology. With regard to the investment changes, we extend the theoretical analyses of Ma (1994), Selder (2005) and Miraldo (2007) to a competitive environment. All three of these studies assumes a single decision maker (a for-profit firm or a social planner) with a single provider of hospital services and come to the common conclusion that the hospital (or social planner) will invest more in quality under retrospective reimbursement than under prospective payment. The empirical literature, for the most part, supports this conclusion. Teplensky et al (1995) and Hillman and Schwartz (1985) find that the likelihood of adopting new medical technology, in their study MRI, is reduced under prospective payment. Kesteloot (1995) concludes that cost based retrospective reimbursement is more conductive to the rapid adoption and diffusion of quality improving innovations for cancer care, while prospective reimbursement typically favors the introduction of cost reducing technologies. Other studies reaching similar conclusions include Kane and Manoukian (1989), for cochlear implantation and Burtler et al. (1985) for medical intensive care. Although we make no contribution to the empirical evidence our findings are consistent with these results.",2
13.0,4.0,"Journal of Industry, Competition and Trade",30 June 2012,https://link.springer.com/article/10.1007/s10842-012-0133-x,Indirect Exporters,December 2013,Fergal McCann,,,Male,Unknown,Unknown,Male,"The role played by intermediaries in international trade is a topic of growing interest. The literature has provided ample evidence, across countries of varying levels of economic development, that these firms account for a significant portion of trade flows.Footnote 1 These studies have been accompanied by a range of papers embedding the intermediation sector into models of international trade. This theoretical treatment of the role of trade intermediaries has usually involved either network or matching frameworksFootnote 2 or extensions of the model of Melitz (2003).Footnote 3 In Blum et al. (2009), the largest firms choose a direct distribution technology to reach foreign consumers themselves. Less productive firms choose an intermediation technology by pairing up with large trading firms to export indirectly. In Ahn et al. (2011) the fixed cost of selling to an intermediary in the firm’s own country is lower than the fixed cost of exporting directly. This leads to an identical sorting to that in Blum et al. (2009) where the most productive firms export directly, less productive firms export through intermediaries, and the least productive active firms sell on the domestic market only (termed here “domestic firms”). Akerman (2010) models wholesalers as having an advantage through economies of scope, i.e. they smooth the fixed cost of selling abroad across many products. He then shows that wholesalers will export a lower volume but more products, and predicts that the sorting mentioned above will hold. Felbermayr and Jung (2011) present a slightly different set-up, focusing on the hold-up problem. They also predict the same sorting pattern as the above three papers. Crozet et al. (2010) introduce a specific (non ad-valorem) trade cost to arrive at the prediction that wholesalers will be more present in less accessible markets and that they channel exports from less-efficient firms who otherwise would not reach the export market. At the micro level, empirical evidence on the sorting pattern provided by the theory is more sparse. Kruger (2009) provided initial evidence of productivity sorting for a small sample of Ghanaian firms. Abel-Koch (2011) shows that firm size negatively predicts the share of indirect exports in total exports, suggesting that as firms get larger, direct exporting becomes the more important export mode. This finding is also confirmed in Ahn et al. (2011). Lu et al. (2010) more directly address the hierarchy prediction of the theory, showing in an ordered probit setting that as productivity increases, the likelihood of moving up the hierarchy from non-exporter through indirect exporter to direct exporter increases. This paper contributes to the growing literature on the choice of export mode by confirming that the sorting pattern predicted by the literature holds for a range of proxies for firm performance. Beyond the firm performance hierarchy, this paper also provides a more complete characterisation of indirect exporters by observing their likelihood of importing, being foreign owned, licensing foreign technology, being multi-product firms, and engaging in R&D. Findings on multi-product firms are particularly novel, in that despite multi-product firms generally being more productive, indirect exporters are more likely to be multi than single-product firms, and multi-product firms have higher shares of indirect exports in their export total than single-product firms. This provides an avenue for potential future research on the mixed exporting strategies employed by multi-product and multi-destination exporters. I also provide suggestive evidence on the significant reduction in sunk export costs brought about by exporting through an intermediary, by showing for a small panel data set that the status of indirect exporter exhibits far more churning than that of non-exporter or direct exporter. This suggests that intermediaries play an important role in facilitating entry to foreign markets, as well as export discovery and experimentation for firms with uncertain export profit horizons.Footnote 4
 The paper proceeds with a description of the data (Section 2), empirical analysis (Section 3) and a conclusion (Section 4).",22
13.0,4.0,"Journal of Industry, Competition and Trade",02 November 2012,https://link.springer.com/article/10.1007/s10842-012-0148-3,Productivity Dispersion and its Determinants: The Role of Import Penetration,December 2013,Daniela Maggioni,,,Female,Unknown,Unknown,Female,"Recent firm and plant-level studies have found large and persistent differences in productivity levels across firms even within narrowly defined sectors (Bartelsman and Doms 2000; Haller 2008; Escribano and Stucchi 2008). The growing availability of micro level datasets has allowed to investigate the factors affecting sectoral productivity dispersion; however, to date the scant empirical evidence is not conclusive. A new strand of literature in international economics builds on firm heterogeneity (Melitz 2003; Bernard et al. 2003) and points at the role of trade liberalization as an important driver behind within-industry firm dynamics and productivity dispersion. In this paper I first provide new evidence for Italy on the existence of a large within-sector disparity in firm productivity and, secondly, I try to shed some light on its determinants with a special focus on the role of import penetration. I test whether the predictions of the new heterogeneous firm models in international trade are supported by the data. The period of my analysis, 1998–2004, is interesting in this perspective because Italy has experienced, in most sectors, an increase of its imports, especially from less developed countries due to both the EU-enlargement and the increasing involvement of the latter in international markets. My working hypothesis is that a restructuring process has been at work in the Italian manufacturing sector following the growing inflows of foreign goods. International trade changes the context where firms operate, gives them the possibility to access foreign inputs, increases competitive pressure and opens up new business opportunities. Hence, international openness may shape sectoral dynamics. The existing evidence for Italy on this topic is limited to the paper of Del Gatto et al. (2008) showing a reduction of productivity dispersion caused by trade openness. Within this framework my main contribution is to examine, for the first time, the existence of heterogeneous effects of imports according to the origin country. Also, as opposed to Del Gatto et al. (2008), I implement a comprehensive investigation of dispersion determinants and, in addition to import penetration, I shed some light on other explanatory factors capturing the technological level of sectors and the domestic competitive context. Finally, I account for the spatial dimension computing sectoral dispersion indicators by geographical area. Local conditions matter for the competition process, firms dynamics and growth (Ottaviano and Puga 1998) and the spatial perspective may help to understand the drivers behind the within-sector differences in firm productivity. This point may be relevant for Italy, which is characterised by deep differences in the business and economic environment among regions, especially between the Centre-North and the South of the country. My results confirm that imports in the sector and area shape the sectoral distribution of productivity although different effects are found according to the origin country. In particular, exposure to low income countries decreases the heterogeneity in productivity in a sector while imports from developed countries display a positive effect. I provide some explanations for this opposite impact of import flows from the two groups of countries on productivity dispersion. The analysis rests on a sample constituted mostly of medium and large firms neglecting the population of micro and very small firms. The sample composition may thus affect the results and, for example, the import competition effect may be underestimated since it is likely that the competitive pressure from foreign countries has larger detrimental effects on small firms often at the lower tail of productivity distribution. Hence, caution should be paid in generalizing the conclusions of the paper to firms of all sizes. The paper is organized as follows. The next section reviews the related literature. Section 3 describes the data and shows some descriptive statistics. Section 4 investigates the determinants of sectoral dispersion and proves the robustness of my findings. Section 5 investigates the channels behind the effects found for import penetration and trade openness. Section 6 concludes.",2
13.0,4.0,"Journal of Industry, Competition and Trade",21 July 2012,https://link.springer.com/article/10.1007/s10842-012-0135-8,Capacity Constrained Firms and Expansion Subsidies: Should Governments Avoid Generous Subsidies?,December 2013,Felix Munoz-Garcia,Gulnara Zaynutdinova,,Male,Female,Unknown,Mix,,
14.0,1.0,"Journal of Industry, Competition and Trade",03 February 2013,https://link.springer.com/article/10.1007/s10842-012-0150-9,Does Vertical Integration Promote Downstream Incomplete Collusion? An Evaluation of Static and Dynamic Stability,March 2014,Mariana Cunha,Paula Sarmento,,Female,Female,Unknown,Female,"The theoretical and empirical literature on vertical integration has gained a great contribution from researchers on industrial economics over many years. It has been very important for economists to understand the main determinants of vertical integration, to identify the type of transactions that are mediated within firms through vertical integration or conducted through the market. In this paper we focus on the coordinated effects of vertical integration that have been ignored for several years. Chicago scholars emphasized the pro-competitive effects of vertical integration (Stigler 1963, 1971). However, with the introduction of game-theory tools, post-Chicago scholars claimed that vertical integration could also have anti-competitive effects (Riordan 2008; Riordan and Salop 1995; Salop and Scheffman 1987). Therefore, the analysis of the anticompetitive effects of vertical integration has been a debated topic of research in Industrial Organization. Sometimes, vertical integration is used as a strategy to eliminate the rivals from the market, allowing the achievement of greater efficiency and higher profits. Also, occasionally, firms adopt this type of organization in order to create barriers to entry, to increase market power and to facilitate collusion. Antitrust authorities have remained concerned that vertical integration might facilitate collusion at upstream and downstream levels (Riordan 2008). Vertical integration might facilitate collusion by supporting the punishment and monitoring mechanisms and also by allowing agreement between firms. Vertical integration facilitates collusion if, after the merger, upstream or downstream firms are able to coordinate in a more effectively way than if they were operating separately. Further, vertical integration may increase the degree of symmetry between firms and the level of market transparency, which in turn makes it easier for firms to collude. The main contribution of this paper is to highlight the importance of considering, simultaneously, two types of firms’ strategies: vertical integration and collusion, in a context where some firms have no incentives to collude (incomplete collusion). This analysis is useful to antitrust authorities in order to more properly evaluate situations where vertical integration is used to enforce collusion, even when there are fringe firms involved and also to quantify its impacts on social welfare. When evaluating a vertical merger, usually, antitrust authorities focus on the coordinated effects, on the impacts on competition and on market foreclosure, which in turn, reduce social welfare (Ordover et al. 1990; Hart and Tirole 1990). However, here we show that vertical merger and incomplete collusion can actually promote social welfare. Similar to Salinger (1988) we conclude that vertical integration does not necessarily result in market foreclosure of the unintegrated firms and that the vertical merger can eliminate the double marginalization problem, by decreasing the price of the final good. There are a few real examples of situations where this question is important. For instance, in 2011, the UK’s Office of Fair Trading (OFT) issued an infringement decision against the following supermarkets: Arla, Asda, Dairy Crest, McLelland (prior to its acquisition by Groupe Lactalis), Safeway (prior to its acquisition by Morrisons), Sainsbury’s, Tesco, The Cheese Company and Wiseman. OFT found that the parties had infringed the Competition Act 1998 by coordinating increases in the final prices of certain dairy products (cheese, milk, butter) in 2002 and/or 2003.Footnote 1 Similarly, German antitrust authority reported that German retail gasoline firms such as Aral (BP), Esso (EXXonMobil), Shell, Total, Orlen, OMV, Agip (Eni), Avia and Westfalen were operating a cartel and coordinating their retail fuel prices (Bundeskartellamt 2011). Moreover, in the report, German antitrust authority concluded that there was a “tremendous price transparency” in the market. However, German antitrust authority did not take into account the possibility that there was a casual relation between this emergence of the cartel and the vertical relationships in this sector. These are two important examples of downstream incomplete collusion, in industries characterized by significant vertical relations. Further, in 2008, the European Commission (EC) has approved the proposed acquisition of Tele Atlas, a navigable digital map manufacturer, by TomTom, a retailer of portable navigation devices (Commission 2008). The EC was first concerned on whether the vertical merger would lead to a decrease of competition or increase of other retailers’ costs and, consequently, harm consumers. However, EC did not take into account that the merged firm could increase retailers’ ability to collude through sales of navigable digital maps. In 2001, the Department of Justice (DOJ) challenged Premdor’s acquisition of Masonite from International Paper Company. The DOJ was concerned that the vertical merger between Masonite, a manufacturer of molded doorskins and Premdor, a retailer of molded doors, would facilitate collusive pricing in the upstream market but also in the downstream market (DOJ 2001). In 1999, the U.S. Federal Trade Commission (FTC) was concerned that the merger between Barnes & Noble, the largest book retailer, and Ingram, the largest wholesaler, would raise other retailers’ costs and lead to foreclosure of this retailers from access to an important upstream suplier (FTC 1999). FCT used these arguments to decline the acquisition, however there are other arguments, namely that the vertical merger could also increase coordination between retailers if, for instance, Barnes & Noble manipulated the wholesale prices charged to its’ competitiors. As we can see from the above examples, the link between vertical integration and downstream collusion is very important in real cases and the study of its effects using theoretical models will significantly contribute to understand the behavior of the distinct decision makers (firms, antitrust authorities, consumers, among others). We could not find any academic literature that considered simultaneously both incomplete collusion and vertical integration. The related literature analyses either collusion and vertical integration or only incomplete collusion, separately. Therefore, our contribution is twofold. Firstly, our paper adds to the literature that studies how vertical integration facilitates downstream and upstream collusion. Chen (2001), Nocke and White (2007, 2010) and Normann (2009) analyzed this question in relation to upstream collusion while, Chen and Riordan (2007) and Mendi et al. (2011) investigate the effects on downstream collusion. However, the referred works assumed that all the firms in the industry accept the collusive agreement. Secondly, our paper adds to the literature on the sustainability of incomplete collusion. Despite the limited literature, there are some studies of incomplete cartels available such as: Selten (1973), D’Aspremont et al. (1983), Donsimoni et al. (1986), Martin (1993), Shaffer (1995), Escrihuela-Villar (2004, 2008). These works differ not only on the type of framework (dynamic or static) but also on the type of competition (price or quantities) and the type of game (simultaneous or sequential). However, in these studies, it is not assumed that the industry has a vertically integrated structure. In this paper we combine the two issues to study how vertical integration affects downstream collusion when there are fringe downstream firms. In the static framework our paper is closely related to D’Aspremont et al. (1983) that studies the necessary internal and external conditions for static stability. More recently, Escrihuela-Villar (2008) studied how the number of firms in the cartel affects the possibility that its members can sustain a collusive agreement. Following D’Aspremont et al. (1983), Martin (1993), Thoron (1998), Escrihuela-Villar (2008) we also endogeneized the cartel formation by analyzing the number of firms that are willing to accept the collusive agreement. Also, our paper is close to Shaffer (1995)’s who analyzed the size and uniqueness of the stable cartel when the fringe is Cournot and the cartel behaves as a Stackelberg leader. Moreover, like Escrihuela-Villar (2009) we assume that, when there is collusion, fringe firms choose the output that maximizes their profit, taking cartel firms’ output as given. In the dynamic framework, our paper is closely related to Martin (1993) that analyzed the conditions for dynamic cartel stability when collusion is enforced with two alternative punishment strategies: a trigger strategy (Friedman 1971) or a stick-and-carrot strategy (Abreu 1986). Martin (1993) found that either a trigger strategy or a stick-and-carrot strategy sustain cartel joint profit maximization in the presence of a fringe. Furthermore, Escrihuela-Villar (2004) analyzed the effects of the cartel size on the sustainability of a collusive agreement and concluded that, with both trigger and stick-and-carrot strategies, collusion is easier to sustain the larger the cartel is. In order to analyze the effects of vertical integration on downstream incomplete collusion, we construct three models: a model without vertical integration, a model where there is vertical integration with a cartel downstream firm and, finally, a model where there is vertical integration with a fringe downstream firm. In particular, we study each model alone and then we compare the results between these models. Moreover, we provide a numerical example to illustrate the results of these three theoretical models. We find that, in general, a vertical merger with a cartel or a fringe downstream firm enforces collusion. The main reason is that the vertical merger increases the difference between collusive and Nash Equilibrium (NE) payoffs. Additionally, the vertical merger with a fringe firm always promotes collusion because it also decreases the difference between deviation and collusive payoffs, and hence cartel firms have fewer incentives to deviate from the collusive agreement. However, for low downstream market concentration the opposite occurs when the vertical merger is with a cartel firm. In this case, the vertical merger increases the difference between deviation and collusive payoffs and therefore hinders collusion. Further, the vertical merger with a cartel or a fringe firm increase upstream competition and therefore the final result is an increase in the total wholesale quantity. Finally, a welfare analysis shows that social welfare can increase with the vertical mergers due to the partial elimination of double marginalization. The remainder of the paper is organized as follows: Section 2 introduces the common assumptions of three models and analyzes the general static and dynamic stability conditions for the industry without vertical integration (Section 2.1), with vertical integration with a downstream cartel firm (Section 2.2) and with vertical integration with a fringe downstream firm (Section 2.3). Section 3 presents the welfare analysis and Section 4 discusses the results of both stability conditions obtained for the three models. These two sections are also based on the numerical simulation results. Finally, Section 5 concludes.",1
14.0,1.0,"Journal of Industry, Competition and Trade",20 February 2013,https://link.springer.com/article/10.1007/s10842-013-0151-3,The No Surcharge Rule and Merchant Competition,March 2014,Frans Saxén,,,Male,Unknown,Unknown,Male,"Academics, legislators, and regulators have recently taken a keen interest in payment card networks. The academic literature on payment card networks can be traced to Baxter (1983), who analyzed how a four-party payment card (the term payment card refers to any kind of card that can be used for making payments, and is as such a generic term covering charge, credit and debit cards) network works. During the 2000s the literature has grown considerably, largely based on the two-sided market framework (cf. Rochet and Tirole 2002, 2003, 2006; Wright 2004). Issues like the multilateral interchange fee (MIF) have received much attention. Another feature of payment networks that has gained attention is the presence of “no surcharge rules” (NSRs). NSRs have often been part of agreements between merchants and card associations (or their agents), forbidding the merchant from charging a different price depending on a buyer’s choice of payment method (eg. card, check, cash). Such price differences could come about through surcharges on card payments, or alternatively discounts for cash payments.Footnote 1 A NSR may also be the result of legislation that forbids surcharging, as is done in some states in the US (Levitin 2008). In this paper we analyze how the presence (or absence) of a NSR affects merchant competition, a theme that has received scant attention in the literature. This is an interesting question, as it affects how merchants price their products, and how pricing affects card use. Card use may impose additional costs on merchants. These costs are passed on to consumers, and not necessarily only to the card-using consumers. We show that under a NSR, if a card-accepting merchant’s card acceptance costs increase, a competitor only accepting cash payments will also raise his prices. The NSR is highly topical. The recent EU directive on payment services forbids NSR-clauses, but leaves open the possibility for national legislation to impose NSRs, or constraints on surcharging (European Commission 2007). In the US, the Department of Justice has sued American Express, MasterCard and Visa, for their use of NSRs. The Department of Justice reached a settlement with MasterCard and Visa, whereby cash discounts would be allowed in the future (US Department of Justice 2010). The settlement gained court approval in July 2011 (Schuh et al. 2011). American Express is fighting the suit in court, a fact that limits the ability of merchants to exploit Visa’s and MasterCard’s concessions. The fees paid by merchants for payment card processing constitute the second largest operating cost for many businesses in the US according to lobbyists (cf. Merchant Payments Coalition 2012). The US Department of Justice estimates that credit card acceptance costs US merchants 35 billion dollar annually (US Department of Justice 2010). This constitutes only part of the magnitude of the issue, as debit cards are typically also subject to NSRs. Australia has been a forerunner in regulating payment cards. NSRs were outlawed in 2002 (Chakravorti 2010), but recently concern over surcharging has increased, as some merchants have imposed surcharges well in excess of actual cost (MarketWatch 2011). Already Epstein (2005) suggested that some merchants in Australia used excessive surcharges as a way to price discriminate, exploiting credit card customers’ higher willingness to pay. More recent studies have cited further evidence, leading the regulator to consider reregulating surcharges or to allow card companies to constrain surcharging (cf. MarketWatch 2011; Reserve Bank of Australia 2011). In the UK the government has committed to ban “excessive surcharges” (Hayashi 2012). Thus the NSR is the focus of regulatory intervention in most of the western world. In much of the literature, the NSR is analyzed in conjunction with the interchange fee (IF) and other prices in the payment systems. The main focus has been on the NSR’s effect on competition in the market for payment methods. As part of that analysis, the NSR has been analyzed under various modes of merchant competition, but merchant competition has been taken as exogenously given. Prager et al. (2009) is a recent overview of the general literature on payment networks, while Hayashi (2012) provides a recent study of the effects of surcharging on the choice of payment method. Gans and King (2003) analyze when the IF is neutral, and develop the concept of payment separation. Payment separation means that a consumer facing a “card price” of a good always pay by card, rather than cash. Payment separation may occur through merchants’ surcharging. Alternatively, under a NSR, with perfectly competitive merchants, merchants split into those who do and those who do not accept cards. Merchants that do not accept cards will then charge lower prices than card accepting merchants. This results in consumers wishing to pay by card buying from the card accepting merchants, while consumers with low valuations for card payments buy from cash-only merchants (more or less simultaneously, Wright (2003) reached the same conclusion). In their analysis, Gans and King (2003) thus briefly touch upon the effects of a NSR on merchant competition. However, the result of their brief analysis is that the NSR will not impact the competition between merchants. The contribution of our paper is that we show that a NSR may soften competition between merchants, and as such a NSR increases merchant profitability. We interpret a NSR as any regulation (be it as a result of regulatory decisions, card association terms, etc.) forbidding merchants to charge different prices based on the customer’s choice of payment method. We analyze the NSR in a price discrimination framework, where the NSR constitutes a restriction on a merchant’s ability to price discriminate based on customers’ choice of payment method. We conduct the analysis in a Hotelling setting, in the spirit of for example Thisse and Vives (1988), Bester and Petrakis (1996), Gehrig and Stenbacka (2005). Gehrig and Stenbacka (2005) analyze how price discrimination can increase competition in a setting with two firms selling a differentiated good. In our model there are two firms, selling an identical good, but the firms are horizontally differentiated with respect to the payment methods they accept (cash or cash and card). The decision whether to accept card payments is here a strategic device the firm uses to differentiate itself from the other firm. In modeling how merchant competition is affected by the NSR we make a contribution to the literature. Our chosen framework, the Hotelling model, while seldom used in the card payment literature, is common in the price discrimination literature. Our focus on differentiation through card acceptance is novel in this context, yet closely related to how the payment literature has analyzed payment cards. For example Rochet and Tirole (2006) analyze the use of card acceptance as a way to attract customers. Thus, we draw on both the payment card literature as well as the price discrimination literature. Our analysis is partially motivated by the lack of attention the issue has received in the theoretical card payment literature previously, partially by the fact that empirical studies have suggested that surcharges on card payments are used for price discrimination (eg. Epstein 2005). The previously highlighted perceived need to reintroduce regulation highlights the importance of the issue. We show how surcharges can be used for price discrimination, and what implications this has for merchant competition. Our model helps rank surcharging regimes in terms of consumer prices and merchant profitability. It also shows how consumer surplus and the market shares of cash and cards (of interest to card issuers and perhaps to the government) are affected under different surcharging regimes. We also analyze the implicit surcharge faced by consumers (the difference between what a consumer would pay for the good if paying by card or cash, of interest to card issuers among others), which determines whether there is too much or too little card use from a social welfare point of view. The paper is organized as follows. Section 2 presents the model. Section 3 presents equilibria under three different settings. The first forms the benchmark case, the NSR, while the remaining two present alternatives to the NSR: constrained and unconstrained surcharging. Section 4 presents the fundamental contribution of the paper, comparing and contrasting equilibria under the different regimes. Section 5 concludes.",
14.0,1.0,"Journal of Industry, Competition and Trade",03 May 2013,https://link.springer.com/article/10.1007/s10842-013-0162-0,Duopolists’ Retail Pricing Behavior in Multiple Markets,March 2014,Mark David Witte,Rachel Williams,,Male,Female,Unknown,Mix,,
14.0,1.0,"Journal of Industry, Competition and Trade",15 February 2013,https://link.springer.com/article/10.1007/s10842-013-0154-0,Anti-Competitive Impact of Pseudo-Generics,March 2014,Vasco Rodrigues,Ricardo Gonçalves,Hélder Vasconcelos,Male,Male,Unknown,Male,"In recent decades, generics became an important competitive force in pharmaceutical markets, gaining considerable market share from branded products. Generics, according to the US Food and Drug Administration, “(...) are copies of brand-name drugs and are the same as those brand name drugs in dosage form, safety, strength, route of administration, quality, performance characteristics and intended use”.Footnote 1 Generics may enter the market if a patent-holder waives its rights or, more often, when the patents that protect a branded product expire. As imitators, generic producers do not incur significant research and development costs and are able to charge very competitive prices. It has been observed that, sometimes, the producer of a branded pharmaceutical will sell a generic version of its own branded product, either directly or through license agreements.Footnote 2 These versions are often known in the literature as pseudo-generics. The competitive impact of pseudo-generics is not obvious. On one hand, they increase the low-cost alternatives available to consumers. But on the other hand, it is not implausible that they have some type of strategic impact on other generic competitors that may hurt consumers. The theoretical literature on the competitive implications of pseudo-generics is rather limited and not conclusive. Ferrándiz (1999) presents a model in which the incumbent seller of a branded drug competes against another imperfectly substitutable branded drug under two alternative scenarios: in one of the scenarios, a third firm sells a generic version of its branded drug; in the other scenario, the third firm does not exist but the incumbent itself sells a pseudo-generic. Unsurprisingly, this author concludes that the incumbent prefers to sell a pseudo-generic itself rather than facing competition by an independent generic producer, although this would be better for consumers. Kamien and Zang (1999) assume that, when patents for branded drugs expire, there is free generic entry. They build scenarios with and without pseudo-generics to study the conditions under which incumbents would prefer to sell them and conclude that selling pseudo-generics is a dominant strategy. But these authors assume that the type of interaction between the brand-name producer and its competitors depends on whether the former is selling a pseudo-generic: if she is not, all firms choose quantities simultaneously (Cournot) but if she is, then she has a first-mover advantage towards the competitors in choosing the quantities of both the branded drug and the pseudo-generic (Stackelberg). We find this crucial assumption unconvincing and feel it casts doubt on the generality of their conclusions: why would selling the pseudo-generic determine whether the firm has a first-mover advantage in selling the branded drug? Kong and Seldon (2004) have tried to rationalize pseudo-generics as an instrument to deter entry, in a model a la Dixit (1979), but their results seem flawed (Rodrigues 2006). Entry deterrence is also the motivation for pseudo-generic production in a limit-price model proposed by Granier and Trinquard (2010). More recently, the same authors (Granier and Trinquard 2012) explore the possibility that pseudo-generic production may be used by brand-name producers to reduce the value of their generic competitors and thus facilitate their acquisition. Generally, pseudo-generics are sold side-by-side with generic and branded versions of the same drug. Models of entry deterrence (or merger to monopoly) seem unable to explain this. The new theoretical rationale for the potential anticompetitive effects of pseudo-generics advanced in this paper is based on entry accommodation, not entry deterrence, and thus seems more apt to explain the simultaneous presence in the market of different varieties of a drug. In our model, firms are price-setters in a market where both vertical and horizontal differentiation are present: branded pharmaceuticals are vertically differentiated towards generics, and generics are horizontally differentiated among themselves. Vertical differentiation translates consumers’ common perception of branded pharmaceuticals as better, or safer, than generics as a result of their prolonged presence in the market while under patent. And, as we argue more extensively below, horizontal differentiation among generics is a plausible assumption if they differ in observable dimensions (e.g. flavour, shape or identity of producer) other than their active substances. A consumer considering switching between the true generic and the pseudo-generic will trade-off any reduction in price against the loss due to horizontal differentiation. No such trade-off exists if he switches between the true generic and the branded pharmaceutical, as this is of better quality. Thus, a reduction in the price of the branded product will attract more consumers away from generic competitors than an equal reduction in the price of the pseudo-generic: therefore, the former price reduction can be profitable even if the latter would not. This is the intuition behind our results. If the pseudo-generic does not exist, the branded pharmaceutical will compete head-to-head with the true generic. But, if the pseudo-generic exists, in equilibrium, it will be perceived by consumers as an “intermediate” product between the generic and the branded product: in that situation, the pseudo-generic, not the branded product, competes directly against the true generic. Because pseudo-generic price reductions are less successful in “stealing” consumers away from the true generic than equivalent reductions in the price of the branded pharmaceutical in the absence of a pseudo-generic, the incumbent now has an incentive to set higher prices. This incentive is compounded by the fact that lowering the price of the pseudo-generic does not only “steal” market share away from the generic producer but also from the incumbent’s own, more profitable, branded product. Thus, the presence of the pseudo-generic can reduce the incentive for the incumbent to charge low prices. And prices being strategic complements, the generic producer’s incentive to charge low prices is also reduced. In this setting, the presence of pseudo-generics may result in higher prices for every variety of the product, to consumers detriment. Our model is built on a Hotelling-type framework that gives it some resemblance to spatial preemption models, as those pioneered by Hay (1976) and Schmalensee (1978) and then developed by many others. The resemblance is superficial, however. In the typical spatial preemption model, scale economies require entrants to achieve a minimum market share in order to be profitable. If the incumbents can commit to certain courses of action (not to change location, not to exit, etc.), they may then be able to “block” entry by making it impossible for the entrants to achieve the required market share even if they are earning a profit themselves. This is not the type of mechanism at work in our model and to make it absolutely clear we make the extreme assumption that firms have no costs: our model focuses on the possibility that pseudo-generics may be used to “soften” competition, not on their entry-deterring properties. This is not to say, of course, that pseudo-generics may not be used for that purpose, as well. The Hotelling framework might also suggest a price-discrimination argument to explain our results: by offering a second variety of the product, the incumbent would “get closer” to consumers and be able to charge higher prices. But, this is not, also, the mechanism at work here. Neither is it simply that a multi-product monopolist has an incentive to charge higher prices than independent monopolists that sells the same products, as in Tirole’s (1988) textbook. The vertical differentiation element in our model invalidates these arguments, as can be seen from the results of Section 3: absent competition, the incumbent would not sell the pseudo-generic. The rest of the paper is organized as follows. The next section introduces our model. For benchmark purposes, in Section 3 we apply it in a monopoly situation. In the fourth section, we analyze oligopolistic competition under two alternative scenarios: with and without the pseudo-generic. Section 5 builds on previous results to determine the competitive impact of the pseudo-generic. We then discuss our results and conclude.",3
14.0,1.0,"Journal of Industry, Competition and Trade",28 August 2013,https://link.springer.com/article/10.1007/s10842-013-0167-8,Regional Patterns in Gasoline Station Rationalization in Canada,March 2014,Andrew Eckert,Heather Eckert,,Male,Female,Unknown,Mix,,
14.0,1.0,"Journal of Industry, Competition and Trade",23 May 2013,https://link.springer.com/article/10.1007/s10842-013-0166-9,Detecting Market Competition in the Japanese Beer Industry,March 2014,Craig R. Parsons,Xavier de Vanssay,,Male,Male,Unknown,Male,"The beer industry is a popular topic to investigate. It is a fairly well-understood product which seemingly exhibits little change over the years, unlike say, semiconductors, which are being reinvented every two years or so. It is a widely consumed product and often included in demand elasticity studies. At the same time, it is an addictive alcoholic beverage often “sin-taxed” quite heavily. This makes it an interesting topic in public finance. Lastly, in some countries, indeed, internationally, it is an industry which is dominated by several large firms, which makes it an ideal focus of study in industrial organization. Despite these observations, the beer industry in Japan seems to be very much understudied, at least in any rigorous, empirical work.Footnote 1 This is even more puzzling given the fact that in many ways the Japanese beer industry represents a near-textbook example of a potentially collusive oligopoly. Approximately 99 % of the domestic market is captured by four firms.Footnote 2 Imported beer is tiny, amounting to 33,706 KL in 2008 (Source: Japan Trade Statistics, Gaikoku Boueki Gaikyou).Footnote 3 As total consumption of beer in Japan was approximately 5,813,000 KL in 2010 (and 5,981,000 in 2009) (source: Kirin Institute of Food and Lifestyle), imports are only approximately 0.6 % of the market.Footnote 4 Thus, with such a closely held market, application of either traditional or more recent methods empirical industrial organization seems warranted. This paper aims to fill that gap. The next section will briefly describe some characteristics of the Japanese beer industry. Section 3 will discuss empirical methods for assessing market structure and power in oligopolistic settings, with emphasis on the so-called NEIO or New Empirical Industrial Organization approaches summarized in Bresnahan (1989) and the more recent Boone et al. (2007; Boone 2008a, b) method. Section 4 will present econometric evidence on the degree of competition based on tests developed by Boone (2008a, b). The results of these regressions based on market shares and firm-level accounting data suggest that, contrary to prima facie evidence of little competition and monopoly power by traditional indicators, the Japanese beer industry is characterized by competitive behavior. Section 5 will conclude with a summary of the main findings, and discuss remaining puzzles.",3
14.0,2.0,"Journal of Industry, Competition and Trade",17 March 2013,https://link.springer.com/article/10.1007/s10842-013-0157-x,Does New Information Technology Lower Media Quality? The Paradox of Commercial Public Goods,June 2014,Man-Lui Lau,Bruce Wydick,,Unknown,Male,Unknown,Male,"As new information technology has lowered the costs of entry into media markets, the number of news sites has proliferated. In the course of this proliferation, the attention of the public has been diffused, drawn away from “old media” such as traditional network television, radio, and big-city newspapers. There are numerous positive effects of the new media technology on consumer welfare. The proliferation of firms allows for the development of new media market niches and for catering to a greater heterogeneity of consumer tastes. In this paper, however, we set aside these more obvious and salient advantages of new media technology, instead focusing on a potentially negative impact. We demonstrate that due to reduced industry concentration brought about by lower barriers to entry in media markets and because consumption of media is purchased through viewers’ time rather than through a market price, innovations in information technology may actually reduce the quality of news available to consumers. The typical television or radio broadcast, or web-based media site, provides content that is non-rival and non-excludable and that is typically underwritten almost exclusively by advertising rather than prices paid by consumers. This type of news media provision is a special case of a two-sided market, where we believe it is more straightforward to refer to such a product as a commercial public good. We demonstrate in this paper that when news media is delivered to consumers as a commercial public good, higher costs of market entry and a higher degree of industry concentration may be beneficial to viewers because it provides for a more efficient synthesis of news content for a given amount of consumer viewing time. Economists have traditionally regarded industry concentration as detrimental to consumers. In markets for private goods, industry concentration can result in equilibrium prices that remain above average costs of production. Higher industry concentration reduces consumer variety. Lower fixed costs reduce industry concentration and prices, and are thus generally beneficial to consumers. However, when media is provided as a commercial public good, we demonstrate that lower costs of entry and lower industry concentration may actually hurt consumers. This occurs because lower industry concentration implies that viewer-minutes are divided among more media firms such that the revenue generated by each media firm through advertising falls. As advertising revenues fall to each firm, so does the quality of the commercial public good provided by it. In the example we present in this paper, this decline in quality is the investigative quality of the news broadcast by each media outlet, although with some modification, our results can be broadly generalizable to other types of media. Previous work such as Rochet and Tirole (2003), Anderson and Coate (2000), and Anderson and Gabszewicz (2005) has viewed the provision of commercial media through the lens of a two-sided market. In products with two-sided markets, such a product or “platform” caters to two simultaneous markets. With video games, for example, video hardware must cater to both game developers and game users. Credit card companies must cater to both card users and merchants. Likewise, news media firms must also cater to advertisers and viewer/readers. Decline in television ratings Advances in new technology have opened up myriad new sources of media, but have resulted in the decline of traditional two-sided-market media in traditional newspapers, television, and radio. Figure 1 illustrates the precipitous decline in viewership of the three major network evening news broadcasts, where the mean percentage of households tuned into the programs has fallen from 14.1 in 1980 to 10.4 in 1990, and to 6.3 in 2005. In recent years nearly all major newspaper dailies in the United States have laid off workers and reduced circulation. From January 2007 to October 2009, at least 10 major daily papers closed their doors (see Table 1), with dozens of other newspapers converting to an on-line format. Table 2 shows the decline in daily newspaper circulation, which reached its height around 1990, falling from 62.6 million households to 49.1 by 2008. Trends in radio listening, while not quite as steep as other traditional media, have also declined in the last decade as shown in Fig. 2. A recent news consumption survey of 3,003 adults by the Pew Charitable Trust found sharp declines in adults reading print newspapers and watching television news (Pew Research Center 2012, see Fig. 3). Although part of this has been made up by increased use of online news sources, the study also reports that the number of adults reading a daily newspaper in any form fell from 54 % in 2004 to 38 % in 2012. Percentage of people listening to radio at least once per week Percentage of people who viewed or read news by various media platforms. (Among Those Who Viewed or Read News Yesterday) We argue here that part of this news media decline may be attributable to lower fixed costs of entry into media markets where news is supplied as a commercial public good. While variable costs such as the cost of labor and technical skill remain high, the cost of establishing a “broadcasting platform” (such as a news website, podcast, or a cable network channel) has substantially declined relative to labor costs. Given the standard assumptions about cost structures in competitive markets, as fixed costs decline, the equilibrium number of firms in a market increases. In a normal market for private goods, lower fixed costs reduce the market price, yielding an unambiguous benefit to consumers. However, with commercial public goods, a relative reduction in the fixed costs of entry at least initially causes the number of firms to expand, causing viewers’ attention to be diverted across a greater number of media outlets. A smaller viewing audience then results in lower advertising revenue to each firm in the market, and a commensurate reduction in the quality of the product produced by each firm. Since the cost of these goods to consumers is a function of time rather than money, consumers become worse off because the quality of the commercial public good is lower given any fixed amount of time devoted to reading, viewing, or otherwise interacting with media. Competition from low-cost providers of media is particularly evident among traditional television networks, newspapers, and radio, who have struggled to maintain advertising revenue with the increasing number of entrants into their markets. Much of this entry has occurred via the internet, where firms are able to compete with each of these types of media, respectively, via video clips on YouTube, writers’ blogs, informal web-based news sources, and online podcasts. Our main example in this paper focuses on journalistic news quality. Some journalists at leading newspapers have even questioned if professional journalism (and the accountability of our institutions) will be able to survive in a media environment in which access to media broadcast is so low that everyone can be a reporter, yet nobody is fully accountable for holding “journalists” accountable.Footnote 1
 A number of more comprehensive articles on the industrial organization of the media have preceded our analysis. Seminal articles in the newspaper and television industries include Steiner (1952), Rosse (1967) and Spence and Owen (1977), respectively. Rosse’s empirical work investigates the reason for strong geographical segmentation in the newspaper industry, finding economies of scale to be the most important determinant of tendency toward geographical monopoly in the newspaper industry, which in most media markets is able to overwhelm the opposing force of heterogeneous preferences among readers (New York City being one clear counter-example). Spence and Owen’s (1977) seminal paper on the television industry considers the biases in program selection that arise under advertiser-supported and pay television, respectively and whether either type of regime creates a bias in the number of programs offered that departs from optimal consumer welfare. They show that an advertiser-supported regime biases against programs that are appealing to a minority of voters and against more expensive programs because pay television prices reflect preferences of viewers more clearly than the flat rate paid by advertisers. Anderson and Coate (2000) consider whether the market yields the correct number of programs and types of programs under advertiser-supported regimes. Their results indicate that market competition can yield either too few or too many varieties of television programs, depending on the relative size of viewing benefits and the benefits to advertisers from their commercials, but that it is possible that the market equilibrium could reach close to an optimal solution. Searching for common themes across different types of media, Anderson and Gabszewicz (2005) develop a model showing that under weak advertising demand, equilibrium program selection may cater to extreme consumer tastes as broadcasters strive to avoid subscription-price competition. In contrast, strong advertising demand may lead to little media product differentiation. Kind et al. (2006) find in a model of a television oligopoly that the more viewers dislike ads, the more likely it is that welfare is increasing in the number of advertiser-supported television channels, where they show public television may be able to correct the distortions introduced by advertiser-sponsored networks. While these papers have focused on the industrial organization of traditional forms of media, our paper most closely resembles the recent work of Frijters and Velamuri (2010), who develop a model that analyzes the changes brought about by new and less-costly forms of media. Among other findings, they argue that new internet-based media firms reduce the effective property rights of more established professional news media, creating a disincentive for the more established outlets to invest in high-quality news production. This kind of undermining of professional news organizations is similar in spirit to the main point we develop about how declining barriers to entry may have deleterious effects on professional media.",8
14.0,2.0,"Journal of Industry, Competition and Trade",25 January 2013,https://link.springer.com/article/10.1007/s10842-013-0152-2,Sectoral Technical Progress and Aggregate Skill Formation,June 2014,Saibal Kar,Chaitali Sinha,,Unknown,Unknown,Unknown,Unknown,,
14.0,2.0,"Journal of Industry, Competition and Trade",02 March 2013,https://link.springer.com/article/10.1007/s10842-013-0155-z,"Firm Turnover and Productivity Growth in Canadian Manufacturing and Services Industries, 2000 to 2007",June 2014,John R. Baldwin,Amélie Lafrance,,Male,Female,Unknown,Mix,,
14.0,2.0,"Journal of Industry, Competition and Trade",22 March 2013,https://link.springer.com/article/10.1007/s10842-013-0156-y,A Tree-form Constant Market Share Model for Growth Causes in International Trade Based on Multi-level Classification,June 2014,Yuanhua Feng,Zhichao Guo,Christian Peitz,Unknown,Unknown,Male,Male,"Constant market share (CMS) analysis is an accounting method for decomposing a country’s export change into the “demand growth” (or “structural change”), the “competitive” and the “interaction” components. This method, known as shift-share analysis, was first applied in the empirical studies of structural changes in industrial and regional economics (Creamer 1943). Reviews on the development in these fields may e.g. be found in Houston (1967), Stevens and Moore (1980), and Loveridge and Selting (1998). CMS analysis became popular in applied international economics with the pioneering work of Tyszynski (1951) and it has been increasingly used and refined despite continued criticism both on its theoretical and empirical aspects (see e.g. Richardson 1971a; Jepma 1986; Merkies and van der Meer 1988 and Milana 1988). In recent years, in addition to its application in international economics (see e.g. Chen et al. 2000; Simonis 2000; Memedovic and Iapadre 2010) and regional economics (see e.g. Esteban 2000 and Blien and Wolf 2002), CMS or shift-share analysis is also widely applied in other fields, such as tourisms (see e.g. Sirakaya et al. 1995 and Toh et al. 2004), energy economics (see e.g. Sun 1998; Zhang 2003 and Mazzanti and Montini 2009) and firm performance (see e.g. Fotopoulos 2007 and Marini 2010). Moreover, results of the CMS decomposition can also be used for further statistical analysis (Patterson 1991 and Batista 2008). Despite long history and wide application of the CMS model, there are still many open questions in this context. A traditional question is with the definition of the three basic components, because they can be defined following the Laspeyres- or the Paasche-type index, or some mixture of both (Richardson 1971a and Milana 1988). Another question is with the further decomposition of a basic component. To this end, different ideas are proposed in the literature (see e.g. Jepma 1986, 1989). Usually, the three components are decomposed in different ways according to the purpose of application. Furthermore, the traditional CMS model is defined for a cross-table with one observation in each entry, which cannot be applied directly, if multi-level classified data for bilateral trade is considered. For data classified at two levels, Toh et al. (2004) and Lu and Mei (2007) propose to fit a CMS model first only using data of the first-level categories and then to fit one CMS model to each first-level category using data of the second-level sub-categories. Guo et al. (2011) call this a hierarchical CMS model and discuss its theoretical background briefly, which only involves data at two levels and can be iteratively used at each level using data classified at the next level. The hierarchical CMS model is easy to understand and to use. But it seems there is a lack of theoretical foundation of this proposal. In particular, for measuring the overall changes, data classified at the second level or above cannot be used, and for measuring the change of a first-level category, data classified at the third level or above cannot be used. To solve the above questions, we will introduce a tree-form CMS model based on multi-level classified data. Comparing with known approaches, the tree-form CMS model could obtain very detailed CMS decomposition, which can provide not only the final decomposition results at the lowest level of disaggregation but also the intermediate decomposition results at any given level of disaggregation and can illustrate the changes between CMS decomposition results obtained used data at different levels of disaggregation as well. The last two sets of information cannot be provided by any other known approaches. In particular, decomposition results at each given level can be summarized from the complete decomposition results, which we define as branch-models and leaf-models. To describe the model clearly, we call the three common CMS-terms at each level of disaggregation the (CMS-) components, and the differences between the same named components at two levels above each other the effects. Furthermore, sources of effects caused by each level of classification are discussed in detail, which show that under certain sufficient conditions some or all of the level-effects vanish. Particularly in the special case with only two categories, the obtained sufficient conditions such that the level-effects vanish are also necessary at the same time. And it is shown that the well known CMS formulations indeed form a linear class with two parameters, which control how the interaction term is distributed into the other two. The choice of a CMS formulation hence reduces to the question how we should (or would like to) divide the interaction term. Based on this finding we propose to decompose each of the three components in the same way over all classification levels. This means that the demand growth and competitive components are treated equally. Moreover, a similar decomposition of the interaction term makes sure that the results can still be summarized according to different definitions of interest. Further statistical analysis using the detailed decompositions shows that the theoretical results on the tree-form CMS model are correct and useful in practice. In summary, the current paper provides a systematic methodological discussion on some problems related to the CMS model and contributes to the research on the theory and practice of the CMS model and related contexts. The paper is organized as follows. Section 2 defines the (entire) tree-form CMS model and its branch- and leaf-models. Then the properties of effects caused by each level of classification are discussed in Section 3. In Section 4, relationship between the tree-form CMS model and existing ideas in the literature is compared and a general CMS formulation for the basic CMS decomposition is introduced. Results of application to China-Germany trade are reported in Section 5. Final remarks in Section 6 conclude the paper. Proofs of the results are put in the Appendix.",
14.0,2.0,"Journal of Industry, Competition and Trade",20 March 2013,https://link.springer.com/article/10.1007/s10842-013-0158-9,Beyond Trade Costs: Firms’ Endogenous Access to International Markets,June 2014,Armando J. Garcia Pires,,,Male,Unknown,Unknown,Male,"Trade costs are one of the main ingredients in the theoretical and the empirical models of international economics.Footnote 1 For instance, the most influential models in international economics developed in the last thirty years rely heavily on trade costs. This is the case for the ‘new’ trade theory (Krugman 1980), the ‘new’ economic geography (Krugman 1991), the multinational firms (Horstmann and Markusen 1992) and the heterogeneous firms models (Melitz 2003). In effect, in these models, trade costs give rise to the well-known home market effects, agglomeration effects, the proximity-concentration trade-off and the firm entry-exit productivity dynamics in export markets, respectively.Footnote 2
 It therefore comes as no surprise that there is a long tradition of empirical studies that try to estimate the magnitude of trade costs in international trade (Moneta 1959; Waters 1970; Finger and Yeats 1976; Harrigan 1993; Rauch 1999) and (Hummels 1999, 2001). Also, the most influential empirical trade model is the gravity equation where trade costs are quintessential (see Anderson (1979), Anderson and van Wincoop (2003, 2004; Chaney (2008; McCallum (1995; Santos Silva and Tenreyro (2006) and (Ullah and Inaba 2011). Furthermore, some stylized facts on international trade are explained based on trade costs. For example, the exponential increase in the world trade in the last century (Baier and Bergstrand 2001) and the “border puzzle” (McCallum 1995; Trefler 1995) and (Anderson and van Wincoop 2003).Footnote 3
 Another “puzzle” has received less attention: why international trade has continued to increase even after trade costs reductions have flattened out (Hummels 1999, 2001). In fact, while in most part of the 20th century there was a clear negative correlation between trade costs and international trade, the same trend has not been as pronounced in the last thirty years. There are certainly many factors that can explain the decoupling of international trade and trade costs, and we discuss some of these reasons in Section 3. However, in this paper, we focus on one of the factors that could help to explain this puzzle: R&D investment and strategic competition in R&D. Note, then, that in this paper we do not deny the importance of trade costs in international trade. However, we follow the industrial organization literature on innovation (see Spence 1984), by highlighting the role of strategic interactions between firms in R&D investment on international trade. The basic ideas that we explore are the following. In the first place, R&D investment can affect trade patterns, since it increases the productivity of firms. Second, if this is the case, firms can also play strategically in R&D to affect rivals’ exports and in the end trade flows. In the next section, we present empirical evidence on these two arguments. With this purpose, we use a simple and stylized Cournot duopoly model with three R&D scenarios. In the first, firms do not invest in R&D (benchmark no R&D game). In the second, as in Leahy and Neary (1997), firms invest in process R&D that reduces marginal costs but increases fixed costs (symmetric commitment power in R&D game). The main difference of this game relatively to Leahy and Neary (1997) is that we do not consider export and R&D subsidies, and just focus on trade flows. In the third, following Garcia Pires (2009), we extend the previous case to allow firms to differ in their capacity to commit to the R&D decisions, i.e.: one firm moves in R&D before the rival (asymmetric commitment power in R&D game). Accordingly, the first game is used as a benchmark to compare with the second and third games. With these three games we derive two main results. First, we show that trade is always higher in the presence of R&D (symmetric and asymmetric commitment power in R&D games) than in the absence of R&D (benchmark no R&D game), given that R&D reduces marginal costs. Additionally, higher efficiency of R&D, a metaphor for technological progress, promotes international trade, since the return on R&D activities (in the form of cost reductions) and, therefore also exports, increases with the efficiency of R&D. In this way, R&D investment can have similar effects to a reduction in trade costs in standard trade models. The second set of results relates to the asymmetric commitment power in R&D game. We show that differences between firms in commitment power in R&D are a door opener for the R&D leader to affect international trade patterns by acting strategically against the R&D follower. To be more precise, the R&D leader over-invests in R&D in order to achieve higher competitiveness than the R&D follower. As a consequence, the former ends up exporting more than the latter or even being the only firm active in international markets. This result, that the more efficient firms tend to export more than the less efficient rivals, is in effect one of the most prominent stylized facts of international trade unveiled in recent years (see Bernard et al. 2003). In this way, although asymmetries in commitment power in R&D give the R&D leader a first-mover advantage in the spirit of von Stackelberg (1934), the consequences are more pervasive than the standard output leader advantages. This is so because differences in commitment power in R&D can also endogenize competitiveness asymmetries in marginal costs between firms. In a standard Stackelberg model this is not possible, since independently of being an output leader or an output follower, firms are always symmetric in marginal costs and therefore in competitiveness. In Sections 2 and 3, we present and discuss the available empirical evidence and the related literature on R&D and trade, respectively. In Section 4, we introduce the base model and define commitment power in R&D. In Section 5, we derive the production equilibrium. In section 6, we study firms’ access to international markets. In Section 7, we look at the effects of technology on R&D. In Section 8, we analyze how R&D affects international trade. In section 9, we discuss the robustness of the main assumptions in the paper. We conclude by discussing our results.",2
14.0,2.0,"Journal of Industry, Competition and Trade",06 February 2013,https://link.springer.com/article/10.1007/s10842-013-0153-1,"Service Firms Heterogeneity, International Collaborations and Export Participation",June 2014,Fulvio Castellacci,,,Male,Unknown,Unknown,Male,"A flourishing strand of literature in international economics investigates the reason why firms differ in terms of their propensity to enter foreign markets and their ability to do so. Melitz (2003) and Helpman et al. (2004) represent two of the seminal papers in this new modelling literature on firm heterogeneity and international trade. In short, this class of models points out that, in order to commercialize their products overseas, enterprises must pay a sunk export cost: since firms are characterized by different productivity levels, only high productivity enterprises will be able to make this investment and become international, whereas most other firms will only produce for the domestic market.Footnote 1
 At the same time as these new theoretical ideas were proposed, a large number of applied contributions have analysed the empirical relevance of this class of models by making use of firm-level data for manufacturing enterprises in a number of different countries. The micro-econometric literature on firm heterogeneity and international trade has found substantial support for the key ideas proposed by Melitz-like models, and shown the great differences that characterize exporting firms vis-a-vis domestic enterprises. Specifically, this applied literature has so far focused on two main sets of factors explaining firms’ export propensity. The first is productivity, which has been shown to be substantially larger for exporters than for domestic firms by a great number of contributions (Wagner 2007; Mayer and Ottaviano 2007; Bernard et al. 2007a; Greenaway and Kneller 2007; Castellani and Giovannetti 2010; Moxnes 2010). The second set of explanatory factors refers to firms’ innovative activities. The R&D intensity of firms and their innovative output (e.g. patents, commercialization of new products) have been found to be closely related to the enterprises’ performance in international markets (Aw et al. 2007; Barrios et al. 2003; Roper and Love 2002; Lachenmaier and Wöbmann 2006; Damijan et al. 2008). Despite the great progress achieved by the firm heterogeneity literature, one aspect that has not yet received proper attention refers to the strategy that firms pursue in order to enter the export market. Specifically, once a firm realizes to have a high enough productivity to pay the sunk export costs, how precisely does it organize in order to set up a distribution and commercialization network abroad? What strategy does it adopt, and what obstacles or barriers to internationalization does it encounter? A new strand of firm heterogeneity research has very recently begun to investigate the role of intermediaries in international trade. Empirical evidence does in fact indicate that intermediaries (e.g. wholesale, retail and distribution firms) account for a substantial share of international trade (Bernard et al. 2010). Models in this recent literature have extended the firm heterogeneity framework by pointing out the existence of indirect exporters, i.e. firms that are not able to export directly but make use of an intermediary in order to distribute and commercialize their products overseas (e.g. Felbermayr and Jung 2009; Blum et al. 2010; Antras and Costinot 2010; Ahn et al. 2011). Our paper intends to take this literature one step further by extending it to the service sectors. Only few empirical studies are available on the important theme of service firms’ export (Blum and Goldfarb 2006; Gourlay et al. 2005; Love and Mansury 2009; Vogel and Wagner 2010; Breinlich and Criscuolo 2011; Eickelpasch and Vogel 2011), and no previous study exists, to the best of our knowledge, on the more specific topic of service firm heterogeneity, intermediation and export participation. The extension we put forward is based on the idea that, in the service sectors, pure intermediation is either not feasible (for services that are non-storable and non-transportable) or too risky (for highly innovative services whose development requires close interaction between the provider and the user). Service firms, therefore, do not typically make use of intermediaries to the same extent that manufacturing enterprises do, but they rather build up a distribution and commercialization network abroad by undertaking international collaborations with foreign firms that are located overseas. Specifically, we present a firm heterogeneity model in which service firms, in order to enter the export market, can engage in a collaboration agreement with a foreign partner. Firms may either enter cooperation agreements with foreign partners to favour the commercialization of existing services, or also engage in collaborations to develop new (innovative) services. The collaboration strategy adopted by the firm will then affect its export propensity. The paper analyses the empirical relevance of this model by means of a new survey dataset providing highly representative information on the internationalization activities of 814 Norwegian firms in the service sectors for the period 2004–2006. The econometric results – based on various regression methods as well as propensity score matching – point out that international collaboration, both on existing and on innovative services, is indeed an important factor to foster firms’ decision to enter the export market.Footnote 2
 In summary, the contribution proposed by the paper to the firm heterogeneity literature is twofold. First, the theoretical framework sheds new lights on the export decision process of service firms, and on how these organize in order to set up a distribution and commercialization network in the foreign market. Secondly, the empirical analysis provides new firm-level evidence on the process of internationalization in the service sectors, which have frequently been neglected in the previous literature due to the lack of available data. The paper is organized as follows: section 2 presents the theoretical model, section 3 the survey data and indicators, sections 4 and 5 the results of the empirical analysis, and section 6 concludes and outlines the main results of the work.",11
14.0,2.0,"Journal of Industry, Competition and Trade",26 March 2013,https://link.springer.com/article/10.1007/s10842-013-0159-8,Rules of Origin and Strategic Choice of Compliance,June 2014,Kazuhiro Takauchi,,,Male,Unknown,Unknown,Male,"In a free trade area (FTA), all exporters have a choice between compliance and noncompliance with rules of origin (ROO); some exporters comply with ROO, but some do not. To enjoy duty-free access to a member country’s market within an FTA, producers must include a minimum fraction of inputs produced within the area.Footnote 1 However, if producers do not comply with ROO, they must pay an external tariff when they export to a member country’s market. Although ROO are required in FTAs to distinguish between intra-regional preferential trade and outside trade, these producers do not always comply with the regulation.Footnote 2 For example, as empirically shown by Anson et al. (2005), only 64 % of Mexican exporters meet NAFTA’s ROO requirement.Footnote 3
 When we consider the above-mentioned exporters’ choice, it is emphasized that the monopoly power of the regional input supplier has an important role. This is because the exporters’ choice between compliance and noncompliance with ROO affects the demand for the regional input. An increase in the number of complying exporters sharply increases demand for the regional input such that the regional input supplier may jump the input price when it has monopoly power. If so, one exporter has an incentive to choose noncompliance with ROO when the rival exporter chooses compliance. Our purpose is to consider the effects of the monopoly power of the regional input supplier when exporters choose whether to comply with ROO or not. To capture the role of a monopolistic input supplier in a vertical related market, we present a Cournot-type FTA model with ROO. We consider an FTA comprising two countries: one with a final-good market (called the importing country) and the other without (called the exporting country). The importing country has one input supplier and one final-good producer, and the exporting country has two final-good exporters. The final-good producer in the importing country exclusively uses the domestic input. To enjoy zero tariff, the exporters must use at least some amount of the regional input; otherwise, they must pay the external tariff. The following three-stage game is considered: first, the exporters choose whether to comply with ROO or not. Second, the input supplier in the importing country sets the price. Last, the final-good producer in the importing country and the two exporters engage in Cournot competition in the importing country’s market. We provide three main results. First, for some combinations of the content rate of the ROO and the external tariff rate, the equilibrium is such that one exporter complies with the ROO while the other does not; we call this the “mixed regime”. A key to this result is that the price of the local input depends on whether the rival exporter complies with the ROO. If the rival complies, it has to procure the input from the local supplier. This raises the price of the local input, making it expensive for the exporter to comply with the ROO. Conversely, if the rival chooses not to comply, it lowers the price of the input and makes it cheaper for the exporter to comply. This strategic substitution between exporters produces a mixed-regime equilibrium. Second, we consider the relationship between the importing country’s welfare and the content rate. We show that the content rate that induces a mixed-regime equilibrium is the worst policy for the importing country. A key to this result is a trade-off between the local input supplier’s profits and tariff revenues from noncomplying exporters. As the content rate increases, the tariff revenues rise since the number of noncomplying exporters increases. On the other hand, the profit of the input supplier decreases as the content rate increases. This is because the supplier’s monopoly power decreases with the number of complying exporters. Once the content rate reaches the level where one exporter switches to noncompliance, the monopoly rent of the input supplier drops sharply since the monopoly price drops sharply. This result is explained by the following logic. When the regime shifts from an all-compliers regime to a mixed regime, the demand for the local input decreases and flattens. If the price of the local input is high, the decrease in demand is large. This is because cost differences between compliers and non-compliers are large. In a mixed regime, the demand for the local input is more elastic, and hence the good becomes cheaper. Since the number of complying exporters is half and the price of the local input falls, the profit of the input supplier in a mixed regime decreases to less than half of that in an all-compliers regime. Third, we show that within a regime where at least some exporters comply, the content rate affects the output of the final-good producer in the importing country in a U-shaped fashion. The content rate directly increases the exporters’ costs. In ordinal Cournot games, an increase in the rivals’ costs raises one’s own output. Hence, one might think that a rise in the content rate always increases the output of the local final-good producer. In our model, however, a rise in the content rate may reduce the output of the local final-good producer if the content rate is low. The reason for this is that as the content rate increases, the demand for the local input increases, raising its price. This leads to higher costs for both the local producer and the exporters. However, if the content rate is low, the exporters do not suffer greatly because they do not need to procure much of the input from the local supplier. Thus, the local producer suffers more than the exporters from a higher price of the local input, thereby reducing its output. In the above mentioned regimes, the welfare of the importing country is U-shaped with respect to the content rate. The shape of the welfare is determined by the profit of the local final-good producer. The reason is explained by the trade-off between consumer surplus and the profit of the input supplier. An increase in the content rate increases the profit of the input supplier but decreases the consumer surplus, and these two effects offset each other. Thus, when the content rate changes, a change in the welfare mainly depends on the change in the local final-good producer’s profit. We obtain the following policy implication: when the combinations of the content rate of ROO and the external tariff rate result in a mixed regime, it is desirable for the importing country within the FTA to reduce the external tariff. This is because of the following two points. First, a policy that can be individually changed by the importing country is the external tariff of that country. Second, the welfare in a non-mixed regime where all exporters do not comply is the best for the country, and in that regime, the welfare of the importing country is monotonically increasing with respect to the external tariff. Therefore, the most desirable policy for the importing country is to impose the highest tariff level that does not cause a mixed regime. This paper relates to two distinct strands of literature. First, it relates to the studies on ROO and exporter choice.Footnote 4 Ju and Krishna (2005) find that in a three-country perfect competition model, all regimes arise depending on the level of the regional input price. Demidova and Krishna (2008) introduce Melitz-type firm heterogeneity and show that the mixed regime occurs depending on the content rate of ROO. The reason for this is that firms have different levels of productivity (Melitz 2003). Although these studies provide an interesting insight, monopoly power in the regional input supplier is neglected. Therefore, the U-shaped relationship between the content rate of ROO and the welfare of the importing country is not found. Second, this paper relates to some recent works on vertical structures, which mainly consider the effects of entry and technology licensing in different models of upstream-downstream agents. Mukherjee and Ray (2007) examine the licensing decision of a monopoly input supplier when entry occurs in the final-good market. Mukherjee et al. (2008) consider the final-good producer’s licensing decision when a labor union (wedge-setter) exists. In a successive Cournot oligopoly, Mukherjee et al. (2009) analyze welfare effects of entry in the final-good market. Although our model is similar to these studies in view of a vertical related market, we newly analyze the effects of ROO on firm strategy and welfare. The remainder of this paper is organized as follows. Section 2 describes the model. Section 3 derives the equilibrium outcomes and examines the strategic choice of exporters and its effects on the other producers. Section 4 examines the welfare implication, and Section 5 concludes.",5
14.0,3.0,"Journal of Industry, Competition and Trade",30 April 2013,https://link.springer.com/article/10.1007/s10842-013-0161-1,Who Benefits from Industrial Concentration? Evidence from U.S. Manufacturing,September 2014,Rigoberto A. Lopez,Elena Lopez,Carmen Lirón-España,Male,Female,Female,Mix,,
14.0,3.0,"Journal of Industry, Competition and Trade",24 May 2013,https://link.springer.com/article/10.1007/s10842-013-0164-y,When Do State-Owned Firms Crowd Out Private Investment?,September 2014,Stefan Buehler,Simon Wey,,Male,Male,Unknown,Male,"Competition between state-owned firms and private firms is a commonplace phenomenon in market economies. Traditionally, state-owned firms play an important role in the provision of network infrastructure in telecommunications, energy, and railroads, but they also operate in many other industries. La Porta et al. (2002) and Andrianova et al. (2012), for instance, show that government ownership of banks is pervasive around the world.Footnote 1 Also, it is well known that state-owned firms compete with private firms in extracting crude oil and other crude materials, manufacturing aircraft and cars, broadcasting, education, health care, insurance, etc. While there has been considerable debate regarding the pros and cons of state-owned firms (we will discuss the related literature in Section 2),Footnote 2 the strategic interaction of investment decisions by state-owned and private firms is not very well understood. In particular, the literature has largely ignored the common concern that state-owned firms might crowd out investment by private firms. This concern is particularly relevant in industries where firms must make large up-front investments (e.g., in building network infrastructure, enhancing product design, ramping up advertising campaigns, etc.) to compete effectively in the product market. In this paper, we provide a formal analysis of the strategic interaction of investment and pricing decisions by state-owned and private firms, and we work out the conditions under which a state-owned firm strategically crowds out investment by a private firm. Specifically, we model the rivalry between a state-owned firm and a private firm as a duopoly with differentiated products, allowing for the possibility that the state-owned firm adheres to a “political agenda.” In doing so, we account for the fact that the state-owned firm might be under political pressure from the politicians who control it (Shleifer and Vishny 1994; Bennedsen 2000).Footnote 3 Assuming that firms make demand-enhancing investments before they compete in the product market, we employ reduced-form analysis and the taxonomy of business strategies introduced by Fudenberg and Tirole (1984) to characterize strategic public and private investment. Our key result is that, for strategic crowding out to occur, two conditions must be satisfied: (i) the private firm regards investments as strategic substitutes; (ii) private investment is “undesirable” from the state-owned firm’s perspective. The intuition for this result is straightforward. If the private firm regards investments as strategic substitutes (complements, respectively), an increase in the state-owned firm’s investment reduces (increases) private investment. Consequently, public investment can crowd out private investment only if the private firm regards investments as strategic substitutes (condition (i)). Moreover, the state-owned firm must have an incentive to strategically crowd out private investment. This incentive is generated by an adverse effect of private investment on the state-owned firm, in which case private investment is undesirable from the state-owned firm’s perspective (condition (ii)). We will make this intuition more precise below. Our analysis provides a consistent explanation for the ambivalent empirical evidence on the effect of public investment on private investment (David et al. 2000):Footnote 4 Since the extent to which conditions (i) and (ii) are satisfied depends on the details of the industry under study, estimates of the effect of public investment on private investment are unlikely to be robust across industries. The linear demand example considered in Section 4 below illustrates this: Allowing for a business-stealing effect of private investment is sufficient to turn strategic complements into strategic substitutes, even if everything else remains unchanged. To see how our analysis can be applied to real-world markets, consider the telecommunications industry where “next-generation” fibre-optic networks are being built in many industrialized countries (Body of European Regulators for Electronic Communications 2010; Noam 2010). In Switzerland, for instance, there are several cities (e.g., Basel, Geneva, and Zurich) in which both the local public utility and Swisscom, the country’s leading telecommunications operator, invest in fibre-optic networks. There is anecdotal evidence that, in some of these cities, the local public utility’s investment has encouraged Swisscom’s investment (cf. Body of European Regulators for Electronic Communications 2010, p. 8). This suggests that investments in fibre-optic networks in urban areas are viewed as strategic complements (rather than substitutes) in Switzerland, such that strategic crowding out is unlikely to be a concern.Footnote 5
 We are well aware that our simple analytical framework necessarily provides an incomplete description of the rivalry between state-owned firms and private firms in real-world markets. In particular, it treats the political pressure on the state-owned firm in a reduced-form manner and does not derive the political agenda from first principles. Nevertheless, we are convinced that our analytical framework captures the essence of strategic interaction in public and private investments in many real-world markets. Our analysis shows that the role of state ownership in explaining strategic crowding out is subtle: Adhering to a political agenda is neither necessary nor sufficient for strategic crowding out to occur. The remainder of the paper is structured as follows. In Section 2, we discuss the related literature. Section 3 introduces the analytical framework, motivates the modeling of the political agenda, and identifies the conditions under which the state-owned firm practices strategic crowding out. In Section 4, we illustrate our analysis with a simple linear demand example. Section 5 discusses implications of our analysis, and Section 6 concludes.",3
14.0,3.0,"Journal of Industry, Competition and Trade",10 November 2013,https://link.springer.com/article/10.1007/s10842-013-0170-0,Compatibility Under Differentiated Duopoly with Network Externalities: A Comment,September 2014,Tsuyoshi Toshimitsu,,,Male,Unknown,Unknown,Male,"Chen and Chen (2011), hereafter Chen–Chen, analyze the effects of compatibility under system product Cournot competition with network externalities. They show that a firm’s optimal strategy is to set an incompatible system standard, even though perfect compatibility is socially optimal. In this case, a social dilemma arises. This result has important policy implications for administrators in the information and communications industries. However, Chen–Chen’s result depends on a specific assumption about the network size. That is, Chen–Chen assume that the effect of the network size of a given system product is composed of the own effect and the spillover effect. The latter effect is determined by the market share of a rival firm, multiplied by the degree of product compatibility of the rival firm’s system product. Although an increase in the degree of product compatibility of a system product has no effect on the consumer’s willingness to pay for it, greater compatibility increases the consumer’s willingness to buy a competing system product. Thus, if a firm raises the degree of product compatibility of its own system product, its output falls whereas that of the rival firm increases. This is because of the strategic substitutability relationship under Cournot competition. Hence, a firm that increases the degree of product compatibility of its own system product reduces its own profits but raises those of the rival firm. Therefore, the firm’s optimal strategy is to set an incompatible standard system, even though a perfectly compatible standard is socially optimal. In this paper, we use the framework of Shy (1995) to modify Chen–Chen’s assumption about the network size. To be specific, we assume that the spillover effect is determined by the market share of the rival firm multiplied by the degree of product compatibility of the firm’s own system product. In this case, an increase in the degree of product compatibility of the system product increases the firm’s own output and profits. Therefore, no social dilemma arises.",3
14.0,3.0,"Journal of Industry, Competition and Trade",10 September 2013,https://link.springer.com/article/10.1007/s10842-013-0168-7,The Economic Contribution of High-Growth Firms: Do Policy Implications Depend on the Choice of Growth Indicator?,September 2014,Sven-Olov Daunfeldt,Niklas Elert,Dan Johansson,Unknown,Male,Male,Male,"In recent years, a small number of high-growth firms (henceforth HGFs) have received increasing attention from policymakers, arguably because they create most new jobs (Birch and Medoff 1994; Storey 1994; Henrekson and Johansson 2010; Hölzl 2010). The Europe 2020 strategy, for example, explicitly mentions support of high growth SMEs as a political objective (European Commission 2010), and a country’s share of fast-growing innovative firms has been proposed as a top indicator to measure the progress of the strategy. A report from OECD meanwhile explicitly asks the question of what governments can do to promote high-growth enterprises (OECD 2010a). Researchers have also begun to argue that policies should be re-directed towards targeting potential HGFs. Shane (2009), for example, argues that the importance of a small number of HGFs suggests that policies should be re-directed from subsidizing the typical start-up company towards encouraging high-growth start-ups. Mason and Brown (2013) support the idea of targeting high-growth start-ups, and present a number of initiatives that policymakers can implement to actually generate and promote HGFs. The recent focus on HGFs is, however, not unproblematic. One question of importance is whether policymakers should target firms that experience high growth in terms of employment, sales, value added or productivity. There may for example be large societal costs to targeting HGFs in terms of employment by economic policy if the policy at the same time disfavors HGFs in terms of productivity (cf. Aiginger 2006; 2007). Theoretical predictions on the relationship between employment and productivity growth are contradictory (Penrose 1959; McCombie 1987; Metcalfe 1994), and empirical studies (Foster et al. 1998) have in most cases failed to find any significant relationship. One exception is Coad and Broekel (2012), who found that an increase in employment growth in general was associated with a decrease in productivity. On the other hand, their results also indicated that an increase in productivity had a positive effect on employment growth for the fastest growing firms. Another concern is whether HGFs will repeat their high growth rates in coming periods. If not, this seriously challenges the notion that policymakers can target high-growth firms in order to promote future firm growth. In addition, a more extensive targeting of firms may also result in more unproductive entrepreneurship since the return to such activities increase. Firm managers may perceive that they are better off applying for government subsidies than producing goods and services demanded by consumers (Baumol 1990). The purpose of this paper is to examine whether the results of supporting HGFs depend on which growth indicators are used to identify these firms. More specifically, we are interested in whether HGFs defined in different ways are equally important to the growth in different economic output variables if HGFs are the same firms irrespective of definition if the growth persistence of HGFs depend on the chosen definition, and whether firm age and size have the same influence on the probability of a firm being a HGF irrespective of how we choose to identify these firms. Our analysis is based on a comprehensive dataset covering all limited liability companies in Sweden from 1997 to 2010. While prior research analyzing the economic contribution of HGFs has identified them as fast growers in terms of firm employment or firm sales, we also identify HGFs by growth in firm labor productivity and firm value added. We thus employ four different indicators of firm growth. We measure firm growth in both absolute and relative (percentage) terms. When employment is the growth indicator, growth is also measured using a combination of absolute and relative numbers, the so-called Birch Index. In total, this results in nine types of growth. The one percent of firms exhibiting the highest growth rates are defined as HGFs in each of these nine groups. Correlation analysis is used to determine to what extent the nine definitions of HGFs overlap. Following Capasso et al (2009) and Daunfeldt and Halvarsson (2012), we also estimate transition probabilities in order to analyze the growth persistence for the different types of HGFs. The contribution of each group of HGFs to the output variables aggregate economic growth, employment growth, productivity growth, and sales growth is then analyzed. To study whether firm age and size influence the probability of being a HGF, probit regression models are estimated. The results indicate a trade-off between fast growers in employment and fast growers in productivity, implying that policies targeted towards employment HGFs will disfavor productivity HGFs (and vice versa). Estimated transition probabilities also show that HGFs that are defined in terms of relative change are unlikely to repeat their high growth rates in coming periods, whereas HGFs that are measured in absolute numbers show a high degree of growth persistence. Regression results show that young firms are more likely to be HGFs irrespective of how HGFs are defined. Hence, the conditions for new firm formation and early growth of firms appear to be crucial for the prevalence of HGFs and for economic development. We begin with a theoretical discussion on firm growth in Section 2. Thereafter, we review the empirical literature on HGFs in Section 3. The data and the descriptive statistics are presented in Section 4. In Section 5 we undertake our transition probability analysis. In Section 6, the contribution of HGFs to different output variables is investigated. The influence of firm age and size on the likelihood of being a HGF is studied in Section 7. In Section 8, we summarize and draw conclusions.",82
14.0,3.0,"Journal of Industry, Competition and Trade",21 May 2013,https://link.springer.com/article/10.1007/s10842-013-0165-x,Services vs. Manufacturing – How Does Foreign and Domestic Sales Impact on Their R&D?,September 2014,Olof Ejermo,Karin Bergman,,Male,Female,Unknown,Mix,,
14.0,3.0,"Journal of Industry, Competition and Trade",20 April 2013,https://link.springer.com/article/10.1007/s10842-013-0160-2,Spillover Effects from Inward FDI on the Exporting Decisions of Chilean Manufacturing Plants,September 2014,Ivan A. Duran,Michael Ryan,,Male,Male,Unknown,Male,"We study the spillover effects generated by both domestic and foreign firms’ export activity on the exporting decisions of Chilean manufacturing firms for the period 2001–2004. In regions and industries where more export activity is noted, externalities often exist in regard to other firms’ exporting decisions. In particular, the presence of multinational firms, embedded with better technologies and better distribution networks, might facilitate the participation of other firms in international markets. The relevance of this study relies on the importance that the promotion of inward foreign direct investment (FDI) normally plays in economic programs that try to foster economic growth and development. Understanding the implications and effects of the presence of foreign firms in different aspects of the economic activity is, therefore, important in order to validate the promotion of FDI in a given country. We choose Chile, a country typically known for its production/mining of precious metals, as our focus to investigate these spillover effects as, beginning in 2000, Chile’s economic development agency (CORFO) intiated its InvestChile program to attracht inward FDI. The program’s original goal, attract inward FDI with high technological content, included subsidies to foreign firms locating in Chile to produce goods and sevices in the ICT (or ICT-related sectors) (Alatorre and Razo 2010). In doing so, this builds a critical mass of human capital in these areas, allowing local Chilean firms to become more productive, efficient, and competitive in global markets. Given the expansion of InvestChile into other non-mining industries (eg, agribusiness,biotechnology), it appears that the Chilean government has been pleased with InvestChile’s performance in attracting inward FDI.Footnote 1 In this light, this study focuses on not on the subsidies that brought the foreign firms to Chile, but rather how their presence in Chile has spilled over to affect the exporting behavior of local Chilean firms. To do so, we include two measures of export activity that might spill over to the domestic firms’ exporting decisions. The first one is the total value of exports of both domestic and foreign firms in the industry–region combination, while the second only includes the total exports of foreign multinational firms (MNE) located in the same industry–region.Footnote 2 We evaluate the effects of these two measures on three firm-level decisions: first, whether the firm decides to export (export likelihood); second, how much the firm exports to the foreign market (export quantity); and third, what proportion of the firm’s total production is exported (export propensity). We use the annual survey ‘Encuesta Industrial Anual’ (ENIA), provided by Instituto Nacional de Estadistica de Chile (INE), which covers the universe of Chilean manufacturing firms with more that 10 employees, to asses these spillover effects. The methodology followed in this paper is closely related to Aitken et al. (1997) and Greenaway et al. (2004) which focus on the firm’s decision to export (export likelihood). However, we differentiate from the former by extending the analysis on spillover effects in two ways: first, their effect on the firm’s total exports (export quantity), and second, how these spillovers affect the overall percentage of total production that is exported (export propensity). While these decisions are somewhat related, they each address different aspects of the extent to which the firm participates in foreign markets. Additionally, we control for endogenity issues that arise from the total and MNE export activity measures in the industry–region by using a different set of variables that relate more closely to each particular industry. Greenaway et al. (2004), on the other hand, check for spillovers in the allocation of total production but do not control to a great extent for the above endogeneity issues. Our results indicate that, in regard to export likelihood, total export activity in the industry–region combination positively affects the exporting decisions of Chilean firms, confirming the presence of spillover effects in the Chilean manufacturing sector. This finding indicates that policies that promote exports in a particular industry will generate positive externalities on existing and new firms, facilitating their participation in foreign markets. However, the evidence also indicates that MNE export activity causes negative spillovers on the likelihood that a firm decides to export. In contrast, MNE employment does generate positive effects on the likelihood of exporting, suggesting human capital spillovers. Similar spillover effects are found on the proportion of firms’ total production that is exported (export propensity decision) but not on how much the firms decide to export (export quantity). The implications of these results are important as they indicate that the local industries benefit more from inward FDI in terms of human capital development than from higher competition, and technologies and products benchmarking. The outline of the paper is as follows. In Section 2, a review of previous studies is presented. In Section 3, we describe the empirical model used to assess the effects of export and MNE activity, and in Section 4 we describe the data, and present and discuss the results derived from the estimations. We finalize with some conclusions in Section 5.",4
14.0,3.0,"Journal of Industry, Competition and Trade",07 May 2013,https://link.springer.com/article/10.1007/s10842-013-0163-z,Information and Disclosure in Strategic Trade Policy: Revisited,September 2014,Fabio Antoniou,Nikos Tsakiris,,Male,Male,Unknown,Male,"The main theoretical foundation of the strategic trade policy literature has its origins to the seminal study of Brander and Spencer (1985). This paper prompted a large literature extending the basic outcome (see, among others, Eaton and Grossman 1986, Horstmann and Markusen 1986, Neary 1991), as well as a great deal of criticism about its limitations. One of its limitations highlighted in later research is that it is highly unlikely for a government to attain all the required information. In general, the studies dealing with this issue are based on two approaches. One to determine optimal policies (see Qiu 1994, Maggi 1996, 1999, Brainard and Martimort 1996, 1997), and the other, to compare various policies under various situations (see Cooper and Riezman 1989, Qiu 1995, Grossman and Maggi 1999, Ishikawa and Kuroda 2007). In a recent paper, Creane and Miyagiwa (2008), hereafter CM, show that the standard assumption in the Brander-Spencer setting, which states that governments have complete information about the economy, is justified when firms compete over quantities.Footnote 1 This appears to be an important result and it is founded on the fact that when the firms commit to reveal information to be acquired to their governments, they adjust their subsidies accordingly. This increases the variability of outputs and leads towards higher expected profits and welfare levels. Similarly, although following a different methodology, Ishikawa and Kuroda (2007) argue that subsidies may induce the firms to reveal their information as long as subsidies remain positive. In addition to that, the authors illustrate that the use of export quotas always induces the firms to disclose information. However, their general formulation comes at a cost. In particular, the authors assume a single active government and they argue that the results hold for policies relatively close to free trade, without investigating if they do hold at the equilibrium level. Within a framework that is essentially that of CM but appropriately modified to deal with multiple firms in each country, this paper shows that when firms compete over quantities and the governments use a price instrument to promote or demote exports, the relative number of firms in each country is a critical determinant of information sharing between the firms and the governments. In particular, when two countries are asymmetric in terms of the number of firms located in each of them, information disclosure will occur only in the country that subsidizes production, i.e., the country with relatively few firms. In the rival country, the firms will prefer to keep information private because the government implements an export tax. When there are several firms, CM’s model applies to both information sharing and the informational prisoner’s dilemma in the special case of an equal number of firms in each country. Contrary to these, when the governments determine quantities, then information sharing among the participants always takes place, irrespective of the number of firms in the two countries, and no informational prisoner’s dilemma is present in equilibrium. This in turn, in terms of Cooper and Riezman (1989) model, retrieves the advantage in favor of the quantity over the price instrument.",2
14.0,4.0,"Journal of Industry, Competition and Trade",20 December 2013,https://link.springer.com/article/10.1007/s10842-013-0171-z,Asymmetric Collusion with Growing Demand,December 2014,António Brandão,Joana Pinho,Hélder Vasconcelos,Male,Female,Unknown,Mix,,
14.0,4.0,"Journal of Industry, Competition and Trade",20 March 2014,https://link.springer.com/article/10.1007/s10842-014-0176-2,Why Do Japanese Non-Local Regional Banks Enter Other Prefectures Under the Region-Based Relationship Banking Policy?,December 2014,Kazumine Kondo,Kozo Harimaya,,Unknown,Male,Unknown,Male,"In the theoretical debate around the financial deepening hypothesis, financial structure is regarded as a significant factor for economic growth (Stiglitz 1985; Allen and Gale 1999; Levine 2002). However, previous studies have shown no clear empirical evidence about the relationship between financial deepening and growth. For instance, Arestis et al. (2001), Shan et al. (2001), and Shan and Morris (2002) found that the hypothesis that financial development leads to economic growth was supported in only a few of the countries surveyed. On the other hand, Beck and Levine (2004) found that stock markets and banks positively influence economic growth, after controlling for country-specific effects and potential endogeneity. While these studies consider the economic growth at the country level, none of them consider the regional economic growth in a specific country. Although the opinions of previous studies on the causal relationships between banks and economic growth are in disagreement, the Japanese government has been promoting region-based relationship banking since 2003. The government considers that the banking system plays an important role in regional economies; therefore, the region-based relationship banking policy mainly aims to leverage financial institutions and boost the economies in each prefecture. Interestingly, only regional financial institutions, except for city banks that have nationwide branch networks, are required to practise region-based relationship banking. Across Japan, there are more than 500 regional financial institutions, including first- and second-tier regional banks, credit associations, and credit cooperatives. With a few exceptions, regional banks have a larger presence than the other types of regional financial institutions in each prefecture. In general, regional banks have most of their branch networks inside the prefectures where their headquarters are located. Therefore, it can be considered that they are suitably positioned to conduct region-based relationship banking and activate regional economies, which is also a view of the Japanese government. However, contrary to the objective of the policy, many regional banks have expanded their branch networks into other prefectures where their headquarters are not located. In Section 2, we review previous studies on bank branch expansion. Although some studies have investigated the relationship between bank consolidations and subsequent changes in bank branches, only a few studies have independently investigated the determinants of bank branch expansion, most of which suggest that banks tend to enter markets where economic wealth is higher; thus, the presence of high-performing companies is expected to attract more banks to an area. In addition, Harimaya and Kondo (2012) revealed that the more non-local regional banks expanded their branch networks beyond the prefectures where their headquarters are located, the less they provide financing to their local markets and small- and medium-sized enterprises (SMEs).Footnote 1
 This study aims to clarify why Japanese non-local regional banks choose to enter other prefectures in the face of strict government regulation requiring regional financial institutions, including non-local regional banks, to actively stimulate their local economies through lending to local SMEs. In particular, the characteristics of prefectures are investigated where many non-local regional banks of other prefectures enter. The results suggest that non-local regional banks that are dissatisfied with commercial lending opportunities in their own prefectures will seek growth opportunities by expanding their branch network into more lucrative regions. The remainder of this paper is organized as follows. Section 2 reviews previous studies on market entries by financial institutions. Section 3 discusses the analytical method and data used in this study. Section 4 describes the empirical results and robustness checks, with a summary and conclusion presented in Section 5.",5
14.0,4.0,"Journal of Industry, Competition and Trade",17 December 2013,https://link.springer.com/article/10.1007/s10842-013-0172-y,The South African Wheat Flour Cartel: Overcharges at the Mill,December 2014,Liberty Mncube,,,Female,Unknown,Unknown,Female,"One important presumption of competition law, and the least controversial, is that cartels are bad for consumers because they increase prices and reduce the supply. The South African competition regime, like elsewhere around the world, prohibits cartels.Footnote 1 Yet, firms continue to find collusion to be very profitable. Perhaps one reason for the persistence of cartels is a desire to have a ‘quite life’ on the part of managers. Managerial slack may provide a motive of managers forming a cartel that may not show up in the form of profitability but x-inefficiencies. The per se illegality of cartel conduct has not been an efficient deterrent. For this reason, competition authorities around the world, including in South Africa, have recently increased their effort to detect and deter cartels. Complementing the work of competition authorities, academics such as Harrington (2004), Levenstein and Suslow (2004), Connor (2004, 2001) have improved our understanding of the pricing dynamics of cartels. On the empirical side, there exist a number of case studies focusing on the workings of specific cartels. These case studies investigate how the cartel operated, how effective it was in sustaining collusion and how large the generated welfare losses actually were. Examples of these studies include Porter (1983), Ellison (1994), Porter and Zona (1999), Genesove and Mullin (2001), Röller and Steen (2006), Asker (2010) or de Vanssay and Erutku (2011).Footnote 2
 The legacy of apartheid in South Africa, largely due to extensive regulation and state support, resulted in an economy that was highly concentrated. Protectionist policies were aimed primarily at encouraging import substitution industrialization. Post-apartheid, the South African government took significant steps to liberalize many of the formerly price regulated markets. Industry restructuring led to the break-up of regulated cartels, but what lagged behind was the strict enforcement of competition policy to ensure that competition was being preserved. It turns out that liberalization inadvertently, by increasing competition in formally regulated markets, increased the incentives for firms to participate in cartels. Hence, many formerly price regulated industries turned to collusion after liberalization. For example, the wheat value chain was extensively regulated by the state from 1937 to 1996. The Wheat Board was the main intermediary between the farm gate and the processing level of wheat products. Marketing of wheat was regulated through a single channel marketing system administered by the Wheat Board. The Wheat Board was sole buyer and seller of wheat at predetermined prices. The Wheat Board also controlled imports and exports of wheat and flour. With liberalisation, the expectation was that millers would compete. Competition it was hoped would result in low prices of flour and bread. But instead of competing, the millers simply replaced state regulation with private regulation.Footnote 3 The flour cartel was uncovered in 2007. The cartel was uncovered when, Premier Foods, one of firms involved in the cartel applied for and was granted corporate leniency. The cartel fixed the price of flour, bread and maize meal and allocated customers in flour and bread from 1999 to 2007. Before analysing the effect of the wheat flour cartel on prices, an understanding of both the wheat flour market and the cartel arrangement is an essential precondition. In section 2 we outline the policy background and market dynamics of the flour industry. Section 3 describes the flour cartel. After the liability of the cartel is established, the task is to determine overcharge estimates due to price-fixing using a reduced-form price equation. In Section 4, we present the estimated results of the overcharge. We use both private and publicly available price data to estimate the cartel price overcharge. In particular, we find that the overcharges to independent bakeries in flour range from 7 % to about 42 %. Section 5 concludes.",18
14.0,4.0,"Journal of Industry, Competition and Trade",19 January 2014,https://link.springer.com/article/10.1007/s10842-013-0173-x,An Anonymous Buyer of Intangible Property,December 2014,Yoichi Nishihara,,,Male,Unknown,Unknown,Male,"On 23 March, 1989, the Exxon Valdez, an oil tanker, loaded 53 million gallons of crude oil and left Alaska for California. The tanker weaved its way through icebergs. Around 23:00, only third mate Cousins piloted the tanker, instead of the captain, Hazelwood, who was drunk. The tanker collided with Bligh Reef, and as a result, 10.8 million gallons of oil was split into Prince William Sound.Footnote 1 More than 2000 sea otters and 200,000 birds were killed over a period of years because of this accident (Piatt and Ford 1996). Microbial, flammable and chemical substances have been used in an attempt to clean up the oil spill at the cost of ocean life, but this has all been in vain. One obstacle in this attempt is that the oil is frozen with water. The oil industry has been incompetent in dealing with the immense amount of ice. John Davis, who had no background in the oil industry, applied a method he had seen being used in the concrete industry, wherein vibration is used to keep viscous cement liquid, to this problem. Davis believed that this technique could potentially contribute to separating oil from blocks of ice. In 2007, his invention was awarded $20,000 by InnoCentive,Footnote 2 the world’s first ‘crowdsourcing’ website, a market for ideas, which began operation in 2001.Footnote 3 Everyone believed that the oil industry would never have come up with the idea on its own. In markets for ideas or ‘technology’, firms with assets and complementary ideas can approach outside inventors (Gans and Stern 2010). In fact, various inventions, from ways of cutting lead time to a protein holding specific properties, are demanded by firms, such as IBM and P&G, on InnoCentive’s website. It may not be an exaggeration to say that exploring for major inventions in markets for ideas is becoming inevitable for surviving harsh competition. At the same time, prudent managers may also be concerned that such exploration conveys strategic information to rivals (Chesbrough 2006). For example, if an automobile company calls for an invention with a notice containing a phrase such as ‘For Improvement of Toyota’s Brake System’, rivals would immediately find out something about the firm’s strategy and respond to its solicitation. Particularly before an invention is patented,Footnote 4 such imitation can seriously depress an innovator’s motivation. Therefore, InnoCentive has employed scientists with doctoral degrees and developed cutting-edge technologies to obscure information when firms post solicitations. This study sheds light on obscuration, which may harm a market. In the next section, obscuration will be defined as ‘noise’, which is a suitable metaphor for partially concealing information (‘jamming a signal’) in a market for ideas. The literature has hitherto mainly shown how intermediaries remove noise for efficient trade (Garella and Peitz 2000; Lizzeri 1999; Masters 2007; Kennes and Schiff 2008); however, the addition of noise by intermediaries has been scarcely examined. There are few exceptional papers on the addition of noise. Hagiu and Jullien (2011) clarify that an intermediary can divert search, which explains why a recommendation program can provide options to consumers. In this paper, we will consider the opposite position, i.e. the role of the intermediary in preventing producers’ strategies from being revealed. Our analysis is largely based on Farrell and Saloner (1985), who showed that prudent managers account for the fact that when firms call for inventions, a bandwagon effect emerges. In other words, if a leader adopts an invention, then a follower may also adopt it. This threat depresses the motivation to innovate. In markets for ideas, the depressive effect seems to be weakened by obscuration. In the abovementioned example, if the post by the automobile company were rewritten as one for invention of a decelerating vehicle, then the firm might not be identified. If inventors and firms are fortunate enough to deal with each other directly, the bandwagon effect may not emerge. However, according to Arrow (1962), players then encounter the following paradox. A seller may be reluctant to demonstrate an invention before selling it because a buyer may not need to buy it to understand and use the technology after having seen it demonstrated. Anton and Yao (2002) solve the paradox theoretically using a signalling approach. That is, an inventor can sell his invention to firms by partly disclosing the value or content. Moreover, Hellman and Perotti (2011) argue that in the context of search among inventors, firms and free riders, non-disclosure agreements designed to exclude free riders ‘shrink the size of the pie’ created through market exchange. Although these analyses are very important because they point to inefficiency in markets for ideas, we will focus on how markets for ideas act as intermediaries connecting inventors with firms. We believe that this study will complement other analyses. The rest of the paper is as follows. Section 2 constructs a model. We set up a three-stage game in which there are two firms and an agent. The model is akin to one of standardization. On the basis of this model, we express obscuration as noise. To illustrate its role vividly, we concentrate on an invention that would not be devised without noise. Section 3 briefly states how firms act. In the context of a bandwagon effect, firms employ cut-off strategies. In other words, firms’ attitudes towards innovation are divided into three categories—active, moderate and passive—depending on their cost structures, which are assumed to be monotonic in output. Section 4 clarifies that in the absence of the intermediary agent, excess inertia prevails in our model. If both firms become worse off when they both adopt a new technology, they avoid innovation. By contrast, Section 5 shows that the agent solves the problem of excess inertia; that is, noise facilitates innovation. Since noise obviates the efficacy of a ‘wait-and-see’ strategy, firms, instead, attempt to acquire innovation ahead of each other. Section 6 concludes with a discussion of welfare implications.",
14.0,4.0,"Journal of Industry, Competition and Trade",20 December 2013,https://link.springer.com/article/10.1007/s10842-013-0174-9,Do Partial Cross Ownership and Budget Constraints Matter for Privatization Policy?,December 2014,Leonard F. S. Wang,Chu Chuan Hsu,Jen Yao Lee,Male,,Female,Mix,,
14.0,4.0,"Journal of Industry, Competition and Trade",20 October 2013,https://link.springer.com/article/10.1007/s10842-013-0169-6,Distance Sensitivity of Export: A Firm-Product Level Approach,December 2014,Viroj Jienwatcharamongkhol,,,Unknown,Unknown,Unknown,Unknown,,
15.0,1.0,"Journal of Industry, Competition and Trade",10 February 2015,https://link.springer.com/article/10.1007/s10842-014-0187-z,The Digital Disruption and its Societal Impacts,March 2015,Martin Kenney,Petri Rouvinen,John Zysman,Male,Male,Male,Male,"This special issue studies the “nuts and bolts” of the globally ongoing societal transformation induced by recent advances in digital technologies and deepening globalization. The lingering economic crisis has somewhat hidden the fact that we are heading to some new—yet to be appropriately named—economic era. And while the crisis has largely taken our collective attention elsewhere, overall it is probably accelerating the ongoing transition. The long discussed digital convergence has finally occurred in a major way and early competitive positions in the post-convergence digital agglomeration have been established. The information and communication technology (ICT) industry has been, and will be, significantly restructured. The benefits of this merger are many. And yet, for previous industry leaders, and sometimes for national economies hosting them, the change has been most unpleasant. Japan and Europe have been mighty in certain ICT sectors in the 1990s and in the early 2000s; for the current ICT revolution, the key new aspects—discussed in detail in this special issue—are emerging from Silicon Valley and the US.",21
15.0,1.0,"Journal of Industry, Competition and Trade",15 February 2015,https://link.springer.com/article/10.1007/s10842-014-0188-y,Cloud Computing: From Scarcity to Abundance,March 2015,Kenji E. Kushida,Jonathan Murray,John Zysman,Male,Male,Male,Male,"Throughout history, computing power has been a scarce, expensive resource. Now, with the advent of cloud computing, it is becoming abundant and cheap, driving a fundamental paradigm shift—a transformation from the computing of scarcity to the computing of abundance. This revolution in computing is accelerating the commoditization of products, services, and business models and it is disrupting the existing Information and Communications Technology (ICT) industry. Moreover, the spread of cloud computing raises significant policy issues that have yet to be resolved, which will affect how it is adopted and develops around the world. Cloud computing, in its simplest sense, is a computing resources management model. It is a method for pooling and sharing hardware infrastructure resources on a massive scale. Finite hardware resources are shared between competing demands, giving each user the illusion of exclusive control over the underlying environment and without the user needing to know anything about how the physical resources are configured. Cloud computing is uniquely new, simultaneously serving as an innovation ecosystem, production environment, and a global marketplace (Kushida et al. 2011). It affects the very underlying activities of production, influencing not only where work takes place, but also how it is done. Cloud computing lowers the bar for entrepreneurship and innovation. Large, cutting-edge enterprises are also entering a new era of how they can organize themselves and compete. We view this as an integral part of the ICT-enabled services transformation that creates ICT-enabled services systems (Zysman et al. 2013). For general consumers, tasks involving computer processing and storage become ubiquitous—already, some estimate that a third of all websites visited by the general public are built on Amazon’s cloud service (AWS—Amazon Web Services) (Labovitz 2012). Email services such as Gmail and storage services such as Dropbox are offered without upfront fees, and video streaming service Netflix depends on Amazon’s AWS. Much of the impact of cloud computing on the economy will be through how it affects enterprise computing, where lead users are moving to deploy cloud computing architectures for their computing to provide vastly greater flexibility and speed at far lower cost than ever before. Historically, large corporations have been the lead users of technology, responsible for driving new disruptions in production and economic activity by deploying new technologies in new ways at scale, shaping how the technology is adopted and used throughout economic activity. The shift in computing resources from scarcity to abundance, combined with how lead enterprise users are reconfiguring their computing, is also driving a new wave of disruption for the Information and Communications Technology (ICT) industry, broadly conceived. The advent of cloud platform services is radically accelerating the commoditization of existing services; users are unlikely to pay a premium for solutions designed to optimize scarce resources—the previously dominant paradigm in successful business models. It is this commoditization of computing resources and services that gives rise to new possibilities for enterprise users of the technology to reorganize themselves and position IT as a strategic competitive weapon. This paper asks the following questions: how did this revolution in computing come about; how is it unfolding; and what the implications are for industries and policies? It answers these questions in three parts. Part one delves deeper into understanding cloud computing itself since there is still confusion about what it is—to some degree intentionally exacerbated by IT vendors relabeling existing offerings. Part two examines the drivers of the disruption: how computing power transformed from a scarce to an abundant resource as the computer industry developed, and the role of lead users in driving new uses. Part three shows how the dynamics of the disruption will play out in various parts of the ICT industry, with rapid commoditization of previously high-end offerings. This paper concludes by pointing to critical policy issues raised by cloud, which will shape how cloud technologies, services, business models, and lead user adoption will unfold around the world.",32
15.0,1.0,"Journal of Industry, Competition and Trade",13 February 2015,https://link.springer.com/article/10.1007/s10842-014-0189-x,"One Ring to Unite Them All: Convergence, the Smartphone, and the Cloud",March 2015,Bryan Pon,Timo Seppälä,Martin Kenney,Male,Male,Male,Male,"Convergences are particularly interesting industrial periods because at these moments entire industries can be restructured as firms compete to achieve positions of architectural advantage. Today, the long discussed digital convergence appears to be finally occurring, with telecommunications in the form of the Internet and cloud computing at its unifying center, but with a myriad of intelligent communicating and sensing devices at its edges. In the still-evolving smartphone space, firms from the telephony, computing, and internet industries have come into competition with each other and are attempting to navigate the convergence using a range of platform strategies. Those strategies are situated within an increasingly complex technological and economic space, characterized by multi-sided markets, a significant variety of business and revenue models, ever-advancing technologies, changing standards and regulations, and the layered nature of the computer-telephony industry itself. Theory suggests that in the information and communication technology (ICT) industries, technology platforms are a key way in which firms can control value creation and position themselves to capture a disproportionate share of industry profits (Gawer 2011; Jacobides et al. 2006). By developing a core platform and attracting complementors to build on and extend it, platform firms harness external innovation to create value for the entire ecosystem. Successful platforms are able to attract both complementors and end-users in a virtuous cycle of network effects, which can lead to dominant market share and entrenched competitive advantage for the firm controlling the platform (Katz and Shapiro 1985). Kenney and Pon (2011) considered a number of the key players in terms of platform theory, and found that Google and Apple’s smartphone strategies were at odds with the traditional platform theory as described by Gawer and Cusumano (2002). This paper extends that analysis beyond the device and the operating system to focus on the role of Internet-based services, and how they may be influencing firms’ platform strategies (for a more general discussion of platforms and services, see Cusumano and Suarez 2009). This paper has two goals: first, to demonstrate that the increasing importance of the Internet and cloud-based services is moving platform power from the device into the cloud. If true, this shift has significant implications for firm strategy, as it signifies not only a new playing field where the competition will be waged, but an opportunity for restructuring power and relationships within the merging value networks. One key trend is the convergence in smartphone hardware and software, which suggests that a dominant design, based on the iPhone, has been established. Beyond the smartphone itself, there is a proliferation of other “smart” and “sensing” devices connected to the Internet—from mobile devices such as tablets, watches, and automobiles, to stationary devices such as TVs, refrigerators, and home energy thermostats—illustrating the broad range of functionality that is almost certain to be connected wirelessly. Even as this intelligent hardware diversifies and multiplies, the long-running trend toward data processing and storage in the cloud is accelerating. Software-as-a-service (SaaS) appears to be the future for not only mobile devices, but most devices including the desktop computer. The result of these trends looks to be a quality and degree of connectedness that only a decade ago was unimaginable. The second goal is to explain how the key platform firms are responding to these shifts in the mobile industry landscape. We apply concepts from the industry architecture and platform literatures to interpret the actions of Apple, Google, and Microsoft, who have all launched mobile operating systems that have become powerful and, for some, profitable technology platforms. The platform literature suggests that the key to securing architectural advantage is owning the “bottleneck,” or the core asset that is used across complementors within the ecosystem, yet has high barriers to entry. This allows the owner to extract rents from those requiring the platform for their businesses (Jacobides et al. 2006). Up to this point, similar to the PC industry, the bottleneck in the smartphone industry has been the operating system installed on the device. However, the increasing centrality of cloud services suggests that the locus of power may be shifting from the operating system to the service providers. For the platform firms, this forces strategic decisions around the scope of their business, and whether they need to strengthen or fully integrate complementary assets to maintain control over a shifting bottleneck. Given the substantially distinct business models of Apple, Google, and Microsoft, this analysis raises questions around the traditional tradeoffs between vertical and horizontal integration—a dichotomy that may not mean much in complex, multilayered techno-economic systems. This complexity is underscored by the emergence of new platforms from Amazon and Xiaomi, who have each built proprietary platforms on top of Google’s open-source Android OS (Pon et al. 2014). We conclude with a discussion of how this shift in mobile telephony is part of broader alignment of many types of networked devices and service platforms connecting to the cloud through Internet protocols, thereby creating a “meta-platform” or additional layer that may challenge firms’ platform strategies.",12
15.0,1.0,"Journal of Industry, Competition and Trade",18 February 2015,https://link.springer.com/article/10.1007/s10842-014-0190-4,Awaiting the Second Big Data Revolution: From Digital Noise to Value Creation,March 2015,Mark Huberty,,,Male,Unknown,Unknown,Male,"We believe that we live in an era of “big data”. Firms today accumulate, often nearly by accident, vast quantities of data about their customers, suppliers, and the world at large. Technology firms like Google or Facebook have led the pack in finding uses for such data, but its imprint is visible throughout the economy. The expanding sources and uses of data suggest to many the dawn of a new industrial revolution. Those who cheer lead for this revolution proclaim that these changes, over time, will bring about the same scope of change to economic and social prosperity in the 21st century, that rail, steam, or steel did in the 19th. Yet this “big data” revolution has so far fallen short of its promise. Precious few firms transmutate data into novel products. Instead, most rely on data to operate, at unprecedented scale, business models with long pedigree in the media and retail sectors. Big data, despite protests to the contrary, is thus an incremental change—and its revolution one of degree, not kind. The reasons for these shortcomings point to the challenges we face in realizing the promise of the big data revolution. Today’s advances in search, e-commerce, and social media relied on the creative application of marginal improvements in computational processing power and data storage. In contrast, tomorrow’s hopes for transforming real-world outcomes in areas like health care, education, energy, and other complex phenomena pose scientific and engineering challenges of an entirely different scale.",37
15.0,1.0,"Journal of Industry, Competition and Trade",13 February 2015,https://link.springer.com/article/10.1007/s10842-014-0191-3,"The Politics of Commoditization in Global ICT Industries: A Political Economy Explanation of the Rise of Apple, Google, and Industry Disruptors",March 2015,Kenji E. Kushida,,,Male,Unknown,Unknown,Male,"One of the most recent dramatic developments in global Information and Communications Technologies (ICT) industries has been the rapid, radical reorganization of industry leaders and business models in mobile communications. New players abruptly redefined the industry. Apple, new to the mobile industry in 2007, transformed the functionality of mobile handsets with its iPhone and App Store. It created a new “dominant design” of touch screen smartphones and transformed handsets into platforms. Google, following on the heels of Apple, introduced its Android operating system (OS) in 2008 with its own app store, distributing Android free to manufacturers. Together, Android and Apple quickly displaced all other mobile operating systems and designs—the “smartphone revolution.” Shortly thereafter, Apple and Google became among the world’s valuable companies, both by market capitalization and cash holdings. The fall of incumbent communications equipment firms was dramatic. In 2011, Motorola sold its mobile division to Google. It had been a leading manufacturer second only to Nokia in global market share, but it was unable to effectively compete with its smartphones. More shockingly, in 2013, Nokia, dominant worldwide for over a decade, sold its core handset business to Microsoft. Apple and Google also pushed aside other value-added service business models. Japan’s mobile industry had been a leader in value-added services, including mobile Internet platforms, downloadable apps, and Internet email for almost a decade before the advent of Apple’s iPhone and Google’s Android. It also had the world’s most sophisticated mass-market handsets, although Japan’s mobile industry had not globalized effectively. Yet, even in their home market, Japanese firms were pushed aside by Apple and Google. What happened? The smartphone revolution was, in essence, a takeover of the mobile communications industry by the computer industry (West and Mace 2010; Pon et al. 2014). Mobile handsets transformed from “phones with enhanced capabilities” to “miniature computers with phone capabilities.” This takeover by computing industry players is likely to spread dramatically, as the transformation of computing power from a scarce to an abundant resource (Kushida et al. 2015) enables an almost limitless expansion of the domains in which data can be gathered and processing devices embedded. The expansion of computer industry players into new industries threatens incumbent players by radically accelerating the competitive logic of commoditization, which disrupts existing firms and business models. Mobile communications provides the most dramatic example of this. Commoditization entails competition based primarily on price, with prices approaching costs, leaving little profit or economic rent for firms. Commoditization traditionally refers to products, but services can be commoditized as well. Moreover, commoditization does not necessarily imply an immediate drop in financial performance; for example, demand for commoditized services such as flat-rate mobile data provision may rise in the short run, or regulations could limit competition despite undifferentiated services. However, without value-added strategies, firms’ longer-term growth potential is limited, and innovation to drive the next round of value-added activity is unlikely to occur. The smartphone revolution commoditized telecommunications carriers by reducing their offerings to commodity voice and data services. Carriers’ own proprietary services lost value when consumers faced a wealth of smartphone apps that provided better functionality, regardless of carrier. The ecosystem of apps, platforms, and operating systems were controlled by Apple and Google rather than carriers. Carriers’ previous offerings of simplified web surfing capabilities that required truncated versions of the World Wide Web were rendered obsolete by smartphones’ capabilities to access the “real” web (West and Mace 2010). The rapid growth of smartphones did increase revenues for carriers as customers added data plans, but carriers effectively ceded the possibility offering value-added services to differentiate themselves. The smartphone revolution also accelerated the commoditization of handsets. Since core functionality was controlled by the OS, and app stores provided a broad range of configurability, manufacturers were far less capable of differentiating themselves. Unlike previous generations of phones that competed on the basis of various designs and features, smartphone designs rapidly converged to large touchscreens, and hardware performance was differentiated primarily by how well it ran the OS, rather than distinctive features. The form factor of iPhones and Android-based handsets quickly converged, as did app store offerings for popular apps. Android handset manufacturers faced ever-decreasing margins, and only firms such as Samsung, which attempted to “outrun commoditization” continued to succeed, though under increasing pressure. Since this wave of commoditization hit the mobile industry so dramatically, and is likely to spread into new domains such as energy, transportation, healthcare, medical devices, and others, it is worth understanding the origins of this trajectory of computer industry expansion more clearly. Put simply, what are the underlying technological and industry trajectories of development that led to this outcome of commoditization driven by the US computer industry? New technologies, new management strategies, corporate organizations, and industry structures are often used to analyze these sorts of disruptions (Christensen 1997; Funk 2002; Gawer and Cusumano 2002; Jacobides et al. 2006; Tee and Gawer 2009). This paper, however, argues that if we look deeper into how industries were shaped and reshaped over time, it was actually a set of political bargains during initial phases of telecommunications liberalization, which differed across countries, that set the trajectories for everything else—technologies, corporate strategies, and industry structures. This paper shows how different sets of winners and losers of domestic and regional commoditization battles emerged in various parts of the world as a result of differences in the politics of telecommunications liberation. Global competition was shaped by the interaction of these different sets of winners and losers. Scholarship focused on technology, management strategies, and industry structures tend to treat political and regulatory factors as exogenous. This paper contends that a political economy approach, tracing how politics and regulatory processes shaped industry structures, allows for a better understanding of the underlying path dependent processes that shape global technological and industry outcomes. The core contention of this paper unfolds in two steps. First, it shows how different sets of winners and losers emerged in the telecommunications industries of Europe, Japan, and the US—the countries with the most developed telecommunications R&D capabilities. In Europe, communications equipment firms emerged as industry leaders spearheading R&D and the technological trajectory of ICT sectors. In Japan, carriers won, resulting in a specific form of industry and technological leadership in which the industry advanced rapidly along particular trajectories, but failed to transform domestic sophistication into global leadership. In the US, firms from the US computer industry emerged as winners, spreading into global markets, entering and dominating the traditional domain of telecommunications Table 1. The second part of this paper traces the politics shaping the different sets of winners. It contends that during the initial politics of liberalization in the 1980s, incumbent monopoly telecom carriers with the greatest political leverage and interest to dominate the sector, given the local political and institutional system, won. The politics of telecommunications liberalization unfolded as follows: The US moved first, and the incumbent AT&T was in the politically weakest position despite strongly desiring to maintain its dominant position. Once antitrust suits were brought by the Department of Justice, it had little political recourse. The resulting settlements broke apart the firm in the early 1980s. The Japanese incumbent, NTT, was politically strong and keenly interested in continuing its dominance. NTT held a privileged position in the country’s clientelistic political system, exercising its political muscle during political battles over liberalization in the early 1980s. It succeeded in avoiding a breakup, retaining its R&D and financial resources that enabled it to shape the industry and propel its rapid technological advancement even after competition was introduced. In Europe, the UK was the only liberalizer in the 1980s, but the incumbent was performing poorly and was not interested in consolidating resources or leading the sector’s development. It did not resist politically driven liberalization, which weakened domestic equipment firms. France and Germany did not liberalize until the 1990s, providing an opening for Nordic firms to emerge as winners when mobile communications became the growth-driver from the 1990s. The European, Japanese, and US telecommunications industries were commoditized by actors from the US computer industry, which arose from a separate but closely related regulatory context. While often depicted as market actors in a free entrepreneurial environment, the US computer industry actually owed much of its independence and dynamism to US telecommunications regulation and the liberalization process. The nascent computer and networking industry was protected from domination by telecommunications incumbents, and was also subject to antitrust that facilitated the rise of new firms and disruptive business models. The Internet originated as a government program and was carefully handed off to commercial management, and the broader US institutional structure that enabled the rise of venture capital and the Silicon Valley entrepreneurial ecosystem fueled the structural opportunities put into place by the US telecommunications regulatory process. This paper therefore makes a claim that is not obvious to most observers and participants—that the rise of Silicon Valley commoditizers actually owes much of its origins to the US telecommunications liberalization process.",13
15.0,1.0,"Journal of Industry, Competition and Trade",10 February 2015,https://link.springer.com/article/10.1007/s10842-014-0192-2,Slicing Up Global Value Chains: a Micro View,March 2015,Jyrki Ali-Yrkkö,Petri Rouvinen,,Male,Male,Unknown,Male,"On 22 September 1996, the Los Angeles Times provided a shocking piece of news: only 3.5 % of the $10 overall value added of a “Tea Party” Barbie doll (Mattel Inc.) remained in the location suggested by the “made in…” label of mainland China (Tempest 1996). Subsequently, this line of inquiry has largely concentrated on high-end electronics (see, e.g., Ali-Yrkkö et al. 2011; Dedrick et al. 2010; Linden et al. 2011, 2009), although other products have been analyzed as well (for reviews, see Kenney 2012; Sturgeon et al. 2013). Since the Barbie incident, scholarly discussions have been significant in disciplines ranging from economics and business studies to geography and sociology. The impact of global value chains (GVCs) has been transformative. Cattaneo et al. (2010, p. 7) note that “… GVCs have become the world economy’s backbone and central nervous system.” Backer and Miroudot (2013) note that over half of global trade currently consists of transactions in the context of GVCs and yet, this perspective has not been fully recognized in the public debates about labor market and trade policy, as many politicians and even experts still presume that goods and services are produced in one well-defined location. In reality, however, all but the most basic products are an assemblage of inputs sourced from around the world. Timmer et al. (2014) provided a macro-view of the “made in the world” phenomenon and used the World Input–Output Tables (Dietzenbacher et al. 2013) to document the rapid fragmentation of production and increasing value-added share being captured by the owners of capital and highly skilled labor since the early 1990s. In addition, these researchers also noted that the developed countries increasingly specialize in functions carried out by highly skilled workers and that the developing countries have increased their specialization in capital-intensive functions. Our current work is a micro-equivalent of the empirical work performed by Timmer et al. (2014); whereas they observed the aggregate outcomes of GVCs operations over time, we observe the operation of specific GVCs for individual products with actual internal firm data; a feature that none of the other “bottom-up” studies has. These macro and micro approaches are complementary and yield similar conclusions. However, many important features—e.g., the role of transfer pricing—are lost with the macro approach. The increasing geographic and organizational dispersion of production raises the question of where the value added is created and by whom. Our approach can provide insight into this question. We derive the value added by the companies within GVCs, by the various business functions involved (e.g., assembly and logistics), and the geographical locations of the functions (for example, the value added share of distribution largely resides in the country of final sale). Our analysis is informed by 45 case studies of GVCs, each of which uses company-confidential invoice-level data with respect to specific products and services. This is the largest, most rigorous (in terms of using actual data), and most diverse (in terms of the industries covered) set of GVC case studies conducted to date. To highlight the rigorousness of the data, we are able to see not only where profits are taken in the internal trade of these firms, but also logistics and inventory costs—a significant advantage over other studies that simply tear down a product, estimate its component costs and allocate profit to the firm’s headquarters. Obviously, for a GVC of a physical product, logistics and inventory are serious issues and costs. Our GVC cases show considerable variation across dimensions within and especially between industries. Thus, current discussions, which are largely based on generalizations, often do not appreciate the subtleties of the real world. Moreover, most of these generalizations are based on a few iconic case studies and do not capture the realities in understudied sectors such as services and raw material intense process industries. While all of the attention has gone to GVCs, many value chains are still best characterized as regional or even local. With these caveats, we nevertheless conclude that value added is dominated by the intangible aspects of GVCs, i.e., market and internal services, as well as the creation and appropriation of intellectual property. Value added shows a tendency to migrate to either the earlier or later stages of the value chain at the expense of assembly/processing or service provision toward the middle (akin to Shih’s smiling curve, http://v.gd/g3EJcd). The high value-added functions still tend to be performed by highly skilled labor located in the developed countries, even though the role of the developing countries is on the rise in this respect. Although the GVC-induced shift in policy thinking is rather profound, many previously cherished principles of good policy conduct remain intact. However, in this work as well, the devil is in the details, and micro-level and practical considerations reveal thorny issues. For example, although laissez-faire is the applicable rule-of-thumb and although there appears to be little scope for active or targeted enterprise policies (in the developed countries), we identify situations in which a nation-state might seek to apply more hands-on policies. Furthermore, the prevailing principles of good conduct are at times directly in doubt, e.g., with respect to competition policy. On a few occasions, we observed an increased need for certain policy measures, i.e., social transfers, but less scope with which to implement them.",20
15.0,2.0,"Journal of Industry, Competition and Trade",02 May 2014,https://link.springer.com/article/10.1007/s10842-014-0175-3,Chain-Store Pricing and the Structure of Retail Markets,June 2015,Matthew Olczak,,,Male,Unknown,Unknown,Male,"Chain-stores are increasingly dominating many retail markets, for example in the UK multiple retailers increased their market share from around 23 % to 65 % between 1950 and 1995.Footnote 1 In addition, the Competition Commission (2008) found that since the 1950s there has been a significant decline in the number of specialist stores. Within the policy literature this has generated some concern, in particular due to the impact on product choice and local economies.Footnote 2 However, as discussed below, empirical evidence on the impact chain-store entry has on smaller retailers is mixed. This paper examines competition between chain-stores and independent retailers in the retail opticians’ market in England. Deregulation of this industry in the mid 1980s brought about many significant changes, particularly the removal of restrictions on entry and advertising.Footnote 3 This immediately lead to rapid entry and growth of chain-store retailers, increasing their market share from 46 % to 75 % between 1985 and 1991.Footnote 4 A key feature of chain-store opticians is that, like a number of other chain-store retailers,Footnote 5 they set a single national price.Footnote 6
 In contrast, in other industries chain-stores tailor their prices to local market conditions.Footnote 7 This practice has raised some policy concern. For example, in their 2000 investigation of the UK groceries industry, the Competition Commission was concerned over the common use at that time of price flexing, defined as: ‘setting retail prices across different geographic areas in the light of competitive conditions, such variations not being related to costs’.Footnote 8 One reason for their concern appears to have been the possibility of a link between price flexing and below-cost selling. The fear is that such strategies may in particular adversely effect smaller convenience stores (see also Association of Convenience Stores 2006). Dobson and Waterson (2005) consider the rationale for chain-stores to choose to adopt such a pricing strategy. In their theoretical model a chain-store faces competition in some local markets and enjoys a monopoly position in others. Compared to when it sets different prices across local markets, under a national pricing strategy the chain-store sets a lower price in the monopoly markets but higher prices in markets where it faces competition. They show that this can be profitable because competition in the competitive markets is dampened. We demonstrate that whether chain-stores adopt national or local pricing strategies can affect the impact chain-store entry has on independent retailers. The starting point for our empirical analysis is a methodology developed by Bresnahan and Reiss (1991). This uses evidence on the relationship between the number of firms and the market size to make inferences about the degree of competition. In order to illustrate this, consider a market where at least X consumers are needed to support a monopolist. If a rival was also present in the market competition would lead to prices below below the monopoly level. A fall in margins means a firm must sell to more consumers in order to break even. Consequently, a market with a total of more than 2X consumers is needed to support the two competing retailers. Therefore, examining how much larger the market size needs to be to support an additional firm provides information on the intensity of competition. We draw upon a recent literature which introduces firm heterogeneity to this methodology. Dinlersoz (2004) introduces competition between chain-store and independent retailers using a vertical product differentiation framework. In the manner of B&R this leads to predictions on the relationship between the number of each type of retailer and market size. Dinlersoz then finds evidence consistent with these predictions in the Californian retail alcoholic beverage industry. As discussed in the next section, the model developed by Dinlersoz fits the characteristics of the retail opticians’ market in England, with one exception. The one exception is that Dinlersoz models competition between chain-stores as Cournot competition. This implies that the price a chain-store sets will vary across local markets, depending upon the number of chain-store rivals present. To fit the opticians’ market, in Section 2.4 we modify the Dinlersoz model to allow for chain-store national pricing strategies. Introducing national pricing leads to a revised prediction on the relationship between the number of independents and market size. In the opticians’ market, evidence consistent with the prediction under national pricing is then found in markets where chain-stores are present. This suggests that chain-stores adopting national pricing strategies helps to protect independents from the intense local competition between chains that would otherwise occur in markets where a number of chain-stores are present. Unlike Dinlersoz, our sample also includes markets where no chain-stores are present. Therefore, we also test for differences in the relationship between the number of independents and market size, depending upon whether or not a chain-store is present. Here, a key issue is that chain-store entry is endogenously determined. The previous literature has dealt with this issue in a number of ways. Griffith and Harmgart (2012) treat the number of larger supermarkets as an exogenous determinant of the number of smaller ‘top-up’ shops, arguing that this is reasonable because typically consumers make their main purchases from larger ‘one-stop’ stores with smaller stores receiving any residual demand. Cleeren et al. (2008) and Toivanen and Waterson (2005) exploit the sequential order of entry in the industries they study. Our approach is closest to (Borraz et al. 2013) who use variability in the availability of permits for commercial expansion as an instrument for supermarket entry. In a similar fashion, we make use of information on the number of planning grants for retail premises that have been accepted in the preceding years. Crucially, this data is separated between grants for minor and major retail premises. Therefore, this allows us to distinguish between retail premises suitable for independents and chain-store outlets. In other settings (Igami 2011; Sobel and Dean 2008), geographic affiliations have been used as an alternative instrument. Our results provide some evidence to suggest that the nature of competition between independents is affected by whether or not chain-stores are present in the market. When no chain-store is present, competitive intensity between independents increases as the number of independents goes up. A related literature has examined the impact of chain-store entry on smaller stores, typically focusing on the supermarket industry. As Borraz et al. (2013) conclude, the findings from this literature on the impact chain-store entry has is mixed. For example Jia (2008) finds that the entry of Wal-Mart has a substantial negative effect on smaller discount competitors, whereas Sobel and Dean (2008) find that Wal-Mart has no long-run effect on overall small business activity. In contrast, Igami (2011) finds that entry of large supermarkets in Japan may force out other large scale competitors, but have a positive effect on smaller retailers. In line with our findings, it is argued that this is because the smaller retailers are sufficiently differentiated from the larger outlets. In contrast to these previous papers, we examine a different industry and to the best of our knowledge are the first to focus on the different effects chain-store national rather than local pricing strategies can have. The remainder of the paper proceeds as follows: Section 2 shows how the predictions of the Dinlersoz (2004) model differ when national pricing is introduced. Section 3 describes the retail opticians’ market in England and Section 4 examines the relationship between the number of independents and market size in markets where chain-stores are present. Section 5 then compares markets with and without chain-store presence. Finally, Section 6 offers some brief conclusions and avenues for further research.",3
15.0,2.0,"Journal of Industry, Competition and Trade",02 September 2014,https://link.springer.com/article/10.1007/s10842-014-0182-4,Mergers in Stackelberg Markets with Efficiency Gains,June 2015,Mariana Cunha,Hélder Vasconcelos,,Female,Unknown,Unknown,Female,"Horizontal mergers are often seen as anticompetitive and harmful to social welfare because they increase market concentration by eliminating at least one competitor in the market and by creating entry barriers. However, a merger can also be welfare-enhancing if it generates efficiency gains, increases incentives for innovation or creates synergies and scale economies among firms. In this paper, we analyze mergers’ profitability, the so called free-riding problem and the merger induced effects on social and consumer welfare in a setting where: (i) firms are in a Stackelberg market; and (ii) mergers can create cost heterogeneity between the remaining firms in the industry. The literature on profitability and welfare effects of horizontal mergers involving firms competing à la Stackelberg includes important contributions by: Daughety (1990); Feltovich (2001); Huck et al. (2001); Heywood and McGinty (2007, 2008); Escrihuela-Villar and Faulí-Oller (2007) and Brito and Catalão-Lopes (2011).Footnote 1 The main message of these papers is that different types of mergers may occur in an industry characterized by Stackelberg competition, that is, mergers may occur when firms have asymmetric strategic power. In particular, one can observe mergers between leaders, mergers between followers or even mergers between leaders and followers that give rise to a leader. It should be highlighted, however, that these papers differ on the type of cost function assumed by the authors. Daughety (1990); Feltovich (2001); Huck et al. (2001); Escrihuela-Villar and Faulí-Oller (2007) considered a linear cost function while Heywood and McGinty (2007, 2008) and Brito and Catalão-Lopes (2011) assumed a convex cost function.Footnote 2 To the best of our knowledge, however, none of these previous studies has addressed the role played by efficiency gains when mergers involve firms in Stackelberg markets with linear costs. In this paper, we contribute to cover the gap in this literature by showing that conclusions about merger profitability, social welfare effects and the existence of a free-riding problem crucially depend on whether the merger creates synergies, allowing firms to produce using a more efficient technology after the merger takes place. In particular, we show that allowing for merger induced synergies in Stackelberg markets (i) increases the incentive for mergers by reducing the free rider problem associated with mergers (that outsiders benefit more than insiders when a merger take place), and (ii) implies that profitable mergers can be welfare improving also in a setting with linear costs. The intuition is that variable cost synergies associated with mergers imply that the merged entity increases its output and that rivals then expand less, which makes the merger more profitable. Moreover, the more aggressive behaviour by the merged entity implies that consumers will be less hurt by the merger. Although this paper encompasses a theoretical exercise, it is also motivated by the profitability of real-world mergers involving firms with asymmetric strategic power. A case in point is the DRAM (Dynamic Random Access Memory) industry, where the leading manufacturers announce their production plans in advance and manufacturers, which enter the market later, respond by adjusting their quantity of DRAM produced. In addition, in this specific industry, the last decades have witnessed a wave of mergers.Footnote 3 Another example is Microsoft’s dominance in software markets. In this case, although Microsoft usually makes decisions first, other smaller companies typically react to Microsoft’s actions when making their own decisions. Obviously, these subsequent followers’ actions, in turn, affect Microsoft (see e.g. Graham 2013). In both examples, it seems reasonable and plausible to analyze the induced impacts of Stackelberg mergers. The remainder of the paper is organized as follows. Section 2 introduces the baseline assumptions of the model and presents the pre-merger results. Section 3 shows the effects induced by the mergers. In Section 4 we present and discuss the results of the numerical simulation. Finally, Section 5 concludes. All proofs are relegated to the Appendix.",10
15.0,2.0,"Journal of Industry, Competition and Trade",18 June 2014,https://link.springer.com/article/10.1007/s10842-014-0178-0,Signalling Rivalry and Quality Uncertainty in a Duopoly,June 2015,Helmut Bester,Juri Demuth,,Male,Male,Unknown,Male,"It is well established that in markets with asymmetric information firms may use prices, possibly in conjunction with additional marketing devices, to signal quality information to uninformed market participants. In particular, if only some fraction of consumers is informed about quality, then firms may signal their qualities to the uninformed by setting prices higher than under perfect information. The idea is that high-quality firms suffer less from decreased sales to informed consumers due to price increases than low-quality firms. Therefore a high-quality firm can separate itself by setting a high price which is not profitable to imitate for the low-quality firm. Signalling thus leads to distorted pricing and an inefficient reduction in the supply of high-quality goods. This paper studies an extension of the standard price signalling model to a durable goods duopoly. In this environment the informative signalling equilibrium is free of distortions and identical to the perfect information equilibrium. This observation has significant welfare implications. The existing literature concludes that under incomplete information about quality, prices are distorted upwards in order to signal private information. Therefore price competition is softened and the firms’ market power increases. This causes a welfare loss because buyer decisions are distorted and their choice of qualities may be socially inferior to the full information outcome. Our paper shows that at least for some class of markets, when signalling occurs it must be non–distortionary and does not lead to market power. Further, when signaling is possible, regulations that e.g. require mandatory disclosure of quality are not likely to lead to any welfare gain. We obtain our results for a horizontally and vertically differentiated duopoly market with price-setting competitors engaging in a game of signalling rivalry: An established firm (“incumbent”), whose quality is known by all market participants, faces a competitor (“entrant”) who is either supplying the same quality as the incumbent or a superior quality acquired through some product innovation. Both firms and some fraction of consumers know the entrant’s quality. The uninformed consumers use prices set by both firms to infer quality information. An important feature of price competition is that the two firms have opposing interests in conveying information, because the incumbent gains and the entrant loses when observed prices make the uninformed consumers more pessimistic about the entrant’s quality. In our model consumers are confronted with two price signals concerning a single uncertain variable, the entrant’s quality. For the analysis of equilibrium, we apply two standard refinements for the uninformed consumers’ out-of-equilibrium beliefs. First, we use the ‘intuitive criterion’ of Cho and Kreps (1987). Second, in situations where one of the firms’ pricing is informative we adopt the ‘unprejudiced belief criterion’ of Bagwell and Ramey (1991) to the pricing strategy of its competitor, because the intuitive criterion is no longer applicable. Under the unprejudiced belief criterion the consumers trust in the price signal of the non–deviating competitor whenever only one of the two firms selects an out-of-equilibrium price. This means that, given the other firm plays an equilibrium separating strategy, a deviating firm cannot influence beliefs by deviating to a non-equilibrium price and therefore always sets its best response price as under perfect information. The unprejudiced belief criterion therefore excludes all separating equilibria with prices distorted from full-information prices. We show that these prices constitute the unique separating equilibrium outcome in our model as long as the fraction of informed consumers is not too small. If only rather few consumers are informed, there is no informative equilibrium. The reason is that either the low-type entrant could gain by deviating to the high-type equilibrium price or the incumbent playing against the high-type would deviate to the low-type equilibrium price. Thus the firms’ price signals would become contradictory: The entrant would signal that his quality is high and the incumbent that the entrant’s quality is low. The standard prediction of the literature on price signalling is that quality uncertainty leads to distorted pricing for signalling purposes. The earliest contributions to this literature consider a market with a single seller. For example, Milgrom and Roberts (1986) show that a monopolist may use price and advertisement to convince consumers of the quality of a newly introduced product. In their model, which is based on repeat purchases of a non-durable good, prices can be distorted up– or downwards depending on expectations over future sales. Bagwell and Riordan (1991) consider a monopolist who produces a durable good whose quality may be high or low. The existence of informed consumers and cost differences between qualities allow the monopolist to signal high quality through an upward distorted price.Footnote 1 Basically, our model extends Bagwell and Riordan (1991) to a horizontally differentiated duopoly in which one of the two firms offers a quality that is known to the competitor but not to all consumers. One strand of the literature extends the analysis of price signalling to oligopolistic markets under the assumption that firms have private information only about their own quality. They are not informed about the other firms and, therefore, have the same prior about their competitors’ qualities as the uninformed consumers. Daughety and Reinganum (2007) and Daughety and Reinganum (2008) examine a horizontally and vertically differentiated duopoly and n–firm oligopoly, respectively. Price setting takes into account the ex-ante probabilities of rivals to be high– or low–quality types. Separating equilibria imply upward distorted prices, increasing in the ex-ante probability of firms being high–types. Similarly, Janssen and Roy (2010) show for a homogenous oligopoly that fully revealing mixed strategy equilibria exist in which high–types distort prices upward and low–types randomize prices over an interval, thereby generating sufficient rents to avoid mimicry of the high–types. Closer related to the information structure in our model is the other strand of the literature that assumes the oligopolists to be informed about their rivals’ qualities. Hertzendorf and Overgaard (2001a) analyze price setting and advertising in a duopoly. To keep the analysis tractable, they assume that qualities are perfectly negatively correlated and consumers only know that one firm offers high quality and the other low quality. They apply two refinements that lead to a unique separating and a unique pooling equilibrium. In the separating equilibrium, a high degree of vertical differentiation leads to upwards distorted prices and a low degree to downward distorted prices. Yehezkel (2008) introduces some informed consumers into a similar model and examines how pricing and advertising strategies depend on the fraction of informed consumers. In Fluet and Garella (2002) the ex ante distribution of the firm’s qualities is such that either both firms offer low quality or one firm offers low and the other high quality. The authors avoid the use of selection criteria and find multiple separating and pooling equilibria. For small quality differences separation can only be achieved with a combination of upward distorted prices and advertisement. This result is similar to a finding by Hertzendorf and Overgaard (2001b), who show that fully revealing separating equilibria satisfying the unprejudiced belief condition do not exist. These papers differ from our model in that they consider product differentiation only in the vertical dimension. This implies that the duopolists have a common interest in signalling different qualities since they earn zero profits if consumers believe that they both offer the same expected quality. In our model of signalling rivalry such a common interest does not exist because consumer preferences are differentiated horizontally between the firms, and in the vertical dimension all consumers have identical preferences. As a consequence, the incumbent always prefers the consumers to believe that the entrant’s quality is identical to his own quality, whereas the entrant gains by convincing the consumers that he offers a superior quality. Another feature that distinguishes our model from the above literature is that the duopolists are not in a symmetric position. In contrast with Hertzendorf and Overgaard (2001a, 2001b) and Fluet and Garella (2002), firms are not “anonymous” but consumers know which firm is quoting which price. The consumers are uninformed only about the entrant’s and not about the incumbent’s quality, and they interpret the prices of both firms as signals only about the entrant’s quality. In our analysis, there is no role for expenditures on directly uninformative advertising as an additional signal. This observation differs from Barigozzi et al. (2006), who in a closely related framework show that the entrant may prefer advertising together with price over pure price signaling. In their model, however, all consumers are uninformed and so a separating equilibrium without distortions does not exist. In contrast, in our model there are some informed consumers and under our belief refinements only the full–information equilibrium without distortions survives. Thus, dissipative advertising cannot occur in equilibrium. From a methodological perspective our analysis is closely related to Bagwell and Ramey (1991) and Schultz (1999). They study limit pricing by two incumbents to affect the entry decision of a third firm. The incumbents’ prices signal their information about an industry–wide parameter. The third firm enters the market only if it concludes that the probability of a favorable state is sufficiently high. In the paper by Bagwell and Ramey (1991) the competitors have a common interest, both want to signal an unfavorable state in order to prevent entry. Introducing the unprejudiced belief refinement, the authors find that only non–distorted separating equilibria exist. Further, under additional assumptions the intuitive criterion of Cho and Kreps (1987) eliminates all equilibria with pooling. By applying the same belief refinements to our context, we arrive at similar conclusions for the qualitative features of equilibrium. Schultz (1999) considers a variation of Bagwell and Ramey (1991) where the incumbents have conflicting interests, i.e. one incumbent prefers the entrant to stay out of the market, whereas its competitor profits from entry. Again, separating equilibrium prices are not distorted. But due to signalling rivalry these equilibria only exist if the effect of entry on the incumbent’s profits is relatively small. We obtain a related result in our model when the fraction of informed consumers is rather small. This paper is organized as follows. In Section 2 we describe the model and, as a reference point, we derive the equilibrium under full information. Section 3 defines the Perfect Bayesian Equilibrium and explains the belief refinements of our analysis. In Section 4 we show that under our refinements only the full information equilibrium prices can survive in an informative equilibrium and that such an equilibrium exists if the fraction of informed consumers is not too small. Section 5 provides concluding remarks. The proofs of all formal results are relegated to an appendix in Section 6.",4
15.0,2.0,"Journal of Industry, Competition and Trade",20 June 2014,https://link.springer.com/article/10.1007/s10842-014-0179-z,Product Bans May Benefit Consumers: Implications from a New Model Of Vertical Product Differentiation,June 2015,Toker Doganoglu,Firat Inceoglu,,Unknown,Unknown,Unknown,Unknown,,
15.0,2.0,"Journal of Industry, Competition and Trade",03 July 2014,https://link.springer.com/article/10.1007/s10842-014-0180-6,R&D and Social Inefficiency of Entry,June 2015,Leonard F. S. Wang,Angela C. Chao,Jen-yao Lee,Male,Female,Unknown,Mix,,
15.0,2.0,"Journal of Industry, Competition and Trade",23 April 2014,https://link.springer.com/article/10.1007/s10842-014-0177-1,"Subsidies, the Shadow of Death and Labor Productivity",June 2015,Heli Koski,Mika Pajarinen,,Female,Male,Unknown,Mix,,
15.0,3.0,"Journal of Industry, Competition and Trade",01 July 2014,https://link.springer.com/article/10.1007/s10842-014-0181-5,"Endogenous Markups, International Trade, and the Product Mix",September 2015,Carlo Altomonte,Alessandro Barattieri,,Male,Male,Unknown,Male,"“More than half of the surveyed manufacturing firms have changed strategy in the last 5 years. The 12 % of firms who have switched products in new industries have generated profits higher than the average.” [translation from Mario Draghi, Bank of Italy Governor, Annual Relation, 31 May 2007, p. 8] A survey on a sample of roughly 3,100 manufacturing firms undertaken by the Bank of Italy (2007) revealed that only 27 % of the surveyed firms were seeing themselves as having an advantage with respect to competitors. More specifically, international competition (particularly from low-cost countries such as China and others in South East Asia, Central, and Eastern Europe) is seen as a major source of potential weakness for the firms. Within the period between 2000 and 2005, more than 50 % of the surveyed firms changed their business strategy: 7 % of firms have internationalized their activities, 15 % have increased investment in core products, while 31 % of the surveyed firms have changed the range of products produced. Within the latter group, 88 % of firms have changed products within the same sub-sector, while the remaining 12 % have switched production to contiguous (10 %) or totally different (2 %) industries, thereby experiencing higher-than-average profits. The international economics literature (see for example, the survey by Tybout 2003), has studied the effects of trade liberalization on average price–cost margins, exports, productivity, and net entry dynamics across countries and industries. More recently, starting from the seminal works of Bernard et al. (2003) and Melitz (2003), the ‘new-new’ trade models have also explicitly taken into account the heterogeneity of firms. Melitz and Ottaviano (2008) have combined the supply-side features of the Melitz’s (2003) model of firm heterogeneity with a demand system different than the traditional CES demand function, thus adding the dimension of heterogeneous markups into models of trade with imperfect competition. The further dimension of product heterogeneity, which seems relevant in the above quoted example, has also been increasingly explored: based on US data, Bernard et al. (2006) show that some firms might react to international competition endogenously by self-selecting into the production of a different product mix. Whether this is also leading to different reactions of the markups to pressure from international competition remains a relatively unexplored question.Footnote 1 In this paper, we take some steps in exploring this issue from an empirical point of view. We have estimated price–cost margins for a sample of roughly 28,000 firms operating in the Italian manufacturing sector over the period of 1998–2003. In line with the standard results of the literature, on average, we have found broad evidence of pro-competitive gains from trade, i.e. firms’ markups tend to be negatively associated with an increase of import penetration indices. However, when performing the same exercise at a more disaggregated level, the analysis has revealed a huge variation in the responses: in some industries we confirm the aggregate result of a negative effect of import penetration on the price–cost margin; however, in other industries (for instance, textiles), the standard pro-competitive result is reverted, and an increased exposure to international trade is associated with higher price–cost margins. Footnote 2 For a third group of industries, the effect does not seem to be significant. We have then tried to relate this evidence to some structural characteristics of industries. We find that sectors displaying a positive impact of import penetration on price–cost margins exhibit, on average for the industry, a different variation in the composition of their product-mix, measured by an index of entropy. These results allow us to contribute to the existing literature in at least three ways. First, we provide some evidence that might inform the literature on multiproduct firms. This literature has been recently blossoming: Eckel and Neary (2010) present a model of flexible manufacturing where an increase of international competition skews the range of products exported toward the firm’s core competencies. Bernard et al. (2011) present an extension of the Melitz (2003) model featuring multiproduct firms. However, the assumption of CES preferences results in constant markups, which by definition cannot be affected by international competition. Mayer et al. (2014) present an extension of the Melitz and Ottaviano (2008) model featuring multiproduct firms where different level of competition in the export market endogenously affects the product mix exported, and through this channel, productivity. However, these models do not have a clear prediction on how trade liberalizations impact average industry markups. Our findings could stimulate further theoretical investigations on the interplay between trade liberalization, markups and the endogenous evolution of the product mix. Second, we provide evidence, for given industries, of a positive correlation between import penetration and markups associated to product dispersion, rather than concentration. We link this result to another phenomenon detected at the empirical level by Bernard et al. (2006) for the US: firms might react to an increase of international competitive pressures by endogenously switching their product mix. The evidence for Italy shows that such an endogenous switch does not necessarily lead to a concentration of products, but rather, in given industries, to higher product dispersion. The novel implication of such a defensive strategy is that changes in product mix induced by increased trade pressures might have a positive impact on firms’ markups, thus reverting in specific industries the traditional finding of pro-competitive effects of trade. Finally, from a methodological point of view, the analysis capitalizes on Konings and Vandenbussche (2005) and Konings et al. (2005), who have refined an algorithm allowing to consistently estimate average price–cost margins starting from balance-sheet, firm-level observations. The algorithm overcomes the traditional critique of the Hall (1988) type of approach for estimating markups, i.e. a potential simultaneity bias between output growth and the growth in the input factors.Footnote 3 It also avoids relying on imperfect measures of firms’ marginal costs in order to observe firms’ markups, since price–cost margins can be estimated consistently starting from nominal balance sheet data on sales and input. We provide here a new application for this econometric technique. The remainder of the paper is structured as follows: Section 2 presents our methodological framework in detail, relating a proper estimation of markups to the effects of trade penetration. Section 3 discusses the dataset and its validation with respect to official data. Section 4 presents our results on the relationship between import penetration and price–cost margins, as well as the relative robustness checks. Section 5 discusses our product mix hypothesis in further detail, while Section 6 concludes.",7
15.0,3.0,"Journal of Industry, Competition and Trade",31 August 2014,https://link.springer.com/article/10.1007/s10842-014-0184-2,Free Trade Networks on Non-tariff Barriers,September 2015,Yasunori Okumura,,,Male,Unknown,Unknown,Male,"Generally, trade barriers are classified into two types, tariff barriers and non-tariff barriers (hereafter NTBs). In many countries, the tariffs on many kinds of commodities have significantly fallen owing to several rounds of trade negotiations in GATT and WTO, and the formation of trading blocs, such as EU and MERCOSUR, and bilateral free trade agreements (hereafter FTAs), such as that between Japan and Singapore. On the other hand, since NTBs take many different forms and often are not transparent, it is difficult to judge whether the use of NTBs is decreasing or increasing. However, according to OECD (2005), “What seems clear is that the reduction or elimination of import tariffs resulting from past trade liberalization has made NTBs relatively more conspicuous.” Therefore, in recent FTA negotiations, countries especially have attempted to reduce or eliminate NTBs. For example, a European commissioner for trade stated that “In line with the ambition stated in the Global Europe communication, the EU-South Korea FTA is the first FTA to include specific sectorial disciplines on NTBs to trade. NTBs are all barriers to trade other than tariffs and arise in many different shapes. The costs created by non-tariff barriers are a high burden, often higher than custom duties, particularly for smaller and medium enterprises.”Footnote 1 Moreover, OECD (2005) provides many examples of the trading agreements that eliminate NTBs in the real world. In this paper, we discuss the formation of bilateral FTAs in eliminating NTBs. Studies by Goyal and Joshi (2006), Furusawa and Konishi (2005, 2006), Mukunoki and Tachi (2006), Saggi and Yildiz (2010, 2011) and Zhang et al. (2014) examine the FTAs on eliminating tariff barriers as a network formation game.Footnote 2
,
Footnote 3 See Jackson (2008) for other models of networks formations. We use a network formation model with import volume quotas, which determine the quantity that a firm can sell to a foreign country.Footnote 4 An FTA between two countries eliminates the quotas of the countries’ national firms and enables them to freely sell without a quantity limit in the countries. In this paper, we focus on the stable FTA networks on eliminating quotas. There are many other types of NTBs, numbering over 100 according to the UNCTAD.Footnote 5 We demonstrate that our results on the stability of networks and market outcomes continue to hold regardless of the type of NTBs, such as import licences, import share quotas, and technical measures for increasing the production costs of foreign firms. First, we discuss the model where volume quotas are exogenously given and are zero or not binding. To be more precise, if two countries form an FTA between them, then the volume quotas assigned to their national firms are not binding; otherwise, the quotas are zero. This setting is essentially the same as that of Goyal and Joshi (2006; Section 3), where the tariffs are either prohibitively high or zero. Although we consider a modified stability notion, the stability results of this model are the same as that of Goyal and Joshi (2006). Second, we consider a model where volume quotas are endogenously decided; that is, if two countries do not form an FTA between them, then the national firms of a country face the volume quotas determined by the government of the other country. In our model, we provide a complete characterization of stable networks. We show that global free trade, which allows all firms to freely sell in every country, may not be achieved in any stable network because a country can free ride on the FTAs between other countries. Furthermore, the empty network, in which all countries are autarkic, can be uniquely stable because the benefits of forming an FTA may be smaller in the case where volume quotas are endogenously decided than in that where they are exogenously given. These results imply that the bilateral FTA negotiations for reducing NTBs may fail to promote free trades. The rest of this paper is organized as follows. In Section 2, we describe a model and introduce the stability concept. In Section 3, we discuss the case where the volume quotas are exogenously given and are zero or not binding. In Section 4, we examine the case where the volume quotas are endogenously determined. In Section 5, we discuss other types of NTBs. Finally, in Section 6, we present our conclusions.",7
15.0,3.0,"Journal of Industry, Competition and Trade",27 February 2015,https://link.springer.com/article/10.1007/s10842-014-0186-0,Unification of Oligopolistic Markets for a Homogeneous Good in the Presence of an Antitrust Commission,September 2015,Raúl Bajo-Buenestado,Dodge Cahan,,Male,Unknown,Unknown,Male,"Countries are every day more globalized; and markets too. In some cases it is fairly easy to talk about markets without borders even though the political frontiers are still present. A case in point: the elimination of economic borders has been especially intense in Europe over the past half-century or so. As was the intention of the founders of the European Union, the so-called old continent tends progressively forward in its process of economic and market integration. This intention can be seen reflected in numerous Treaties, Agreements and rules approved with the aim to create institutions to foster the idea of a single market. Given such a climate, it is not surprising to see that firms within some sectors are rethinking their target market - the free movement of goods principle allows them to sell to both domestic and foreign buyers without restriction. However, it seems that many of the legal efforts put forward to achieve a single market have not had a substantial effect in certain sectors. A clear example of this fact is given by the electricity sector: even though there were several Directives and rules encouraging the creation of a single market for electricity, recurrent empirical evidenceFootnote 1 leads us to believe that true integration is far from occurring, as the European Commission recognized itself in the 2007 Energy Inquiry.Footnote 2 Undoubtedly, European policymakers have shown a clear intention to achieve this integration by promoting cross-border cooperation in terms of transmissions rights, imposing mandatory network access to third parties in other countries, and creating interconnected systems since the nineties. Therefore, and considering the idiosyncratic elements of markets such as the electricity sector, what could be the reason for the failure of these initial initiatives? Were the incentives incorporated in the Directives the right ones to achieve market integration? In this paper, we want to explore one of the issues that legislators did not properly address from the beginning and that proves to be a determinant factor in the process of market integration: the lack of a European-wide electricity antitrust regulator. Directive 96/92/EC of the European Parliament, the first one issued to foster the idea of a single electricity market, completely ignores this element. In fact, the Directive urges each country in the EU to create its own “authority [..] to be responsible for the organization, monitoring and control of the tendering procedure”,Footnote 3 and to settle disputes “concerning contracts, negotiations and refusal of access or refusal to purchase”.Footnote 4 As a result, and as Hancher (1997) points out, “under Europe’s recent Directive (96/92/EC) [...] Member States retain immense autonomy to set the competitive agenda within their borders. The result may well be a distinctly skewed–and far from open–trade in electricity, and little opportunity for even large customers to make a meaningful choice of suppliers”. The initial efforts toward the creation of a European antitrust authority for the electricity markets came in dribs and drabs in the 2000s. The very first came in 2000 with the creation of the Council of European Energy Regulators (CEER), whose goal is to facilitate the creation of a single, competitive, efficient and sustainable EU internal energy market.Footnote 5 In 2003, Directive 03/54/CE and Regulation 1228/2003 address for the first time cross-border issues and cooperation of national authorities, an idea that was further extended in Directive 09/72/CE. Not surprisingly, in the 2000s we start to observe the beginnings of a process of market unification; the paradigmatic case usually cited is the unification of the Portuguese and Spanish markets to create the single Iberian Electricity Market (MIBEL) in 2004; another example is given by the Nord Pool, which resulted from the progressive integration of the Norwegian, Danish, Swedish, Finnish, Estonian, Latvian and Lithuanian markets since 2002.Footnote 6 But it seems that the unification process has been as slow and tardy as the evolution of the legal framework for the creation of a unique antitrust authority in the electricity sector. With the previous ideas and examples in mind, we are interested in analyzing whether firms in different countries have incentives to create a unified single market to serve a homogeneous good. The proposed theoretical framework assumes that each country has an oligopolistic market serving that country’s demand. Following the elimination of the economic borders, firms have the opportunity to merge their market with those of other countries, forming a single oligopoly that serves the demand resulting from aggregating the demands of the individual countries involved in this coalition. We model this “unify-or-not-unify the market” decision as a simple non-transferable utility (NTU) cooperative game. Since we are only interested in the cross-border result,Footnote 7 we restrict focus to the case in which firms in a given country can either: keep their market segregated from the markets in other countries, continuing as an oligopoly serving the homogeneous good in the given country; or, if it is mutually beneficial to all parties, they can unify their market with that of one or more other countries, resulting in a new oligopoly that now serves the aggregated demand of all the countries involved and consists of all the original firms. As a second step, we introduce into the model a common antitrust commission that attempts to prevent concentration in the market. Such an antitrust commission, as Pouyet and Verouden (2002) and Bartolini and Zazzaro (2011) assume, is exogenously introduced and has the ability to impose a fine with some probability. In contrast to the extant literature, we introduce a specific assumption about the probability of getting a fine: this probability is strictly decreasing in the number of firms in the market. By making this assumption, it is implicitly assumed that the smaller the number of firms, the greater the probability they collude. This basic result, at least for the case of oligopoly, is vastly supported – a well-known piece backing up this idea is, for instance, Dolbear et al. (1968).Footnote 8
,
Footnote 9 The particular functional form for the probability of receiving a fine is determined by the severity of the antitrust law. As the main result of this paper, we find that the commission plays a crucial role in the market integration process, providing incentives for firms in different countries to create “international coalitions”. In other words, the higher the probability of being levied a fine, and the harsher the fine, the more desirable it is for firms to merge their markets and create a single, less concentrated one. Such an increase in the probability of getting a fine can be introduced from two sources: namely, a smaller number of firms in the market (i.e., an increase in market concentration) as well as from an increase in the severity of the antitrust policy. Importantly, such unification cannot be achieved in the absence of an antitrust commission. In this case, we find it is never mutually beneficial for any subset of markets to unify. The impact of an antitrust commission on total welfare in the framework of an oligopolistic market has been widely studied, sometimes with contradictory results. For instance, while Besanko and Spulber (1989) and Neven (2006) found that, under certain conditions, greater penalties can hurt social welfare, Bartolini and Zazzaro (2011) have challenged that. In the context of Research Joint Ventures (RJV), Femminis and Martini (2008) have analyzed the impact of the antitrust commission on welfare. An interesting feature in this paper – that provided inspiration for the model we present below – is that the authors allow for a parameter that represents the “power” of the antitrust authority. Other researchers have focused on the anticompetitive effect that the introduction of fines produces in the market – for instance, Cyrenne (1999) and Harrington (2004) have found that incentives to deviate from the collusion equilibrium price increases in the presence of an antitrust authority. Nevertheless, to our knowledge, there are no pieces that have attempted to analyze the impact of an antitrust commission on the process of market unification and integration – up to this paper, this area has been largely ignored in the literature. Of course, incentives to integrate markets without such commissions have been studied in depth. The simplest analysis can be found in Martin (2010). The rest of the paper is organized as follows: in Section 2, we present the benchmark model without an antitrust commission – we model it as a Cournot game environment and an equilibrium is obtained for the segregated markets case as well as for the integrated markets case. Given these equilibria, the result obtained is that no “unify the market” coalitions can be supported. In Section 3, an antitrust commission is introduced into the model. We show the presence of such a commission is able induce the formation of integrated markets coalitions if the antitrust policy is chosen appropriately. Section 4, as a case example, relates our findings to the recent creation of the Iberian Electricity Market (MIBEL). Section 5 concludes and outlines some ideas for extensions. Appendix A contains the proofs and Appendix B remarks on an alternative assumption on the probability of receiving a fine (see footnote 9).",2
15.0,3.0,"Journal of Industry, Competition and Trade",22 August 2014,https://link.springer.com/article/10.1007/s10842-014-0183-3,Industrial Policy for Growth,September 2015,Kristine Farla,,,Female,Unknown,Unknown,Female,"Followers of neoliberal theory believe in the efficient and self-organizing capacity of free markets to the extent that market liberalization, deregulation, openness, and competition are key to economic growth. Policies that favor given sectors or industries are generally criticized for inducing firms to lose competitive drive and lower investment. More recently, Aiginger (2007) argues that in developed countries policy supporting specific sectors and industry has re-emerged. Similarly, Peres (2009) finds that, contrary to the conventional notion, Latin American countries have implemented more industrial policy in combination with an outward oriented policy approach. What is the benefit of the government taking on a more active role in terms of market intervention? To what extent is industrial policy aimed at supporting existing industry competitiveness and/or at supporting market competition and consumer protection? Do such policies effectively stimulate growth? We use cross-country data to estimate the relation between countries’ perceived industrial policy and growth. Industrial policy is generally understood to refer to a mix of policies that support the structural transformation and development of a country’s industry. This study is based on a broad understanding of industrial policy, in line with, for example, the broad selection of policies Di Maio (2009) identifies as industrial policies: innovation and technology, education and skills formation, trade, targeted industry support measures, competitiveness, and competition regulation. Rodrik and Subramanian (2005) distinguish between policy that targets the development of business—‘pro-business’ policy—and policy that targets the development of free markets—‘pro-market’ policy. The authors define pro-business policies as policies that support the development of existing industry and are “aimed primarily at benefiting incumbents in the formal industrial commercial sector” (Rodrik and Subramanian 2005, pp. 215). Furthermore, the authors define pro-market polices as policies that are aimed at stimulating competition and benefit new entrants and consumers. Rodrik and Subramanian find that in India high levels of growth in the 1980’s were triggered by pro-business rather than by pro-market policy.Footnote 1 Also, Khan and Blankenburg (2009) and Acemoglu et al. (2006) suggest that, in countries at early stages of development, industrial policy should focus on supporting industrial development and, in a latter stage, industrial policy should stimulate competition. The policy classification as offered by Rodrik and Subramanian (2005) is particular useful for our analysis mainly because it allows for a ‘de-facto’ distinction between policies rather than a ‘de-jure’ distinction of policies. The distinction between pro-market and pro-business policy is similar to the policy contrast of market-oriented and structuralist policy but we assume that the focus of the former is on industrial policies and that the focus of the latter additionally extends into other policy areas. We use cross-country data (for 59 countries) to empirically assess the extent to which there is a trade-off between the pro-market and pro-business type policy, at the macro level. On the basis of perception-based policy data on industrial policy and principal component analysis we seek to differentiate between different aspects of policies that support business development and policies that support free markets. We find that it is possible to distinguish between pro-market and pro-business type policies and, on the basis of this categorization of data, we construct an indicator for each policy type. Contrary to the description of pro-market and pro-business policy that is proposed by Rodrik and Subramanian (2005), our policy measures do not specify which industries/actors are targeted by the policies. In particular, as a result of data limitations we cannot distinguish between policy that specifically targets incumbents and policy that specifically targets new market entrants. Our measures of pro-market and pro-business policy are positively correlated implying that at the macro-level there is no strict trade-off between the perceived implementation of pro-market and pro-business type policy. We analyze the relationship between countries’ industrial policy and economic performance. Fixed effects analysis using data for 56 countries suggests that our pro-business indicator is positively related to GDP per capita growth and income in middle income countries but not in high income countries. We find no evidence that pro-market policy, as perceived, is positively associated with economic performance.",12
15.0,3.0,"Journal of Industry, Competition and Trade",09 November 2014,https://link.springer.com/article/10.1007/s10842-014-0185-1,Public Support to the European Car Industry: The Impact of the Financial Crisis,September 2015,Laura Grigolon,Nina Leheyda,Frank Verboven,Female,Female,Male,Mix,,
15.0,4.0,"Journal of Industry, Competition and Trade",28 August 2015,https://link.springer.com/article/10.1007/s10842-015-0198-4,Biased Managers as Strategic Commitment in a Mixed Duopoly with Relative Profit-Maximizers,December 2015,Yasuhiko Nakamura,,,Male,Unknown,Unknown,Male,"Numerous studies on strategic managerial delegation have shown that a candidate’s aggressiveness is an important determinant in the hiring choice for CEO positions in the real business world. As one of the classical and pioneering works in this field, Drucker (1967) emphasized the importance of the top executive’s individuality for firm performance. Various empirical studies, including Bertrand and Schoar (2003), Bennedsen et al. (2007), and Graham et al. (2013), have shown a significant relationship between individual managers’ attitudes in the market and corporate policies. Recently, Englmaier and Reisinger (2013) provided a theoretical explanation for why each firm’s owner in a private duopolistic market in the real world tends to systematically hire a relatively aggressive manager by using the new strategic managerial delegation.Footnote 1 More precisely, they considered the possibility of each firm’s owner hiring a manager biased with respect to the market size he faces, showing that each owner hires an aggressive manager in the contexts of both quantity competition and price competition. Nakamura (2014a) confirmed the robustness of the results obtained in Englmaier and Reisinger (2013) from the perspective of a mixed duopoly wherein a social welfare-maximizing public firm and an absolute profit-maximizing private firm hire absolute profit-maximizing managers. Nakamura (2014a) showed that in such a mixed duopoly, the owners of both firms hire aggressive managers in the contexts of both price competition and quantity competition. Thus, the results obtained under the private duopoly investigated in Englmaier and Reisinger (2013) are robust against the introduction of a social welfare-maximizing public firm. The purpose of this paper is to check the robustness of the results obtained in Nakamura (2014a) against the situation in which the owners of both firms hire relative profit-maximizing managers in a mixed duopoly. Managers who outperform others are frequently observed to obtain good positions in the management job market. Taking this into account, before the current analysis, Nakamura (2014b) investigated whether the firms in a two-firm private duopoly with relative profit-maximizing owners and managers hire aggressive or conservative managers by following the approach of Englmaier and Reisinger (2013). The relative performance approach of two private firms adopted in Nakamura (2014b) is based on Matsumura and Matsushima (2012) and Matsumura et al. (2013), and this study also adopts such an approach. More concretely, we adopt π

i
−α
π

j
 as the objective function of firm i, where π

i
 and π

j
 denote firm i’s absolute profit and the absolute profit of opponent firm j, respectively, (i≠j). Parameter α implies the degree of importance of each firm’s relative performance.Footnote 2 In this paper, we focus on quantity competition because the difference between the results obtained in Nakamura (2014a) and this paper can be more clearly realized.Footnote 3
 In this paper, we show that the aggressiveness of the manager hired by the private firm depends strictly on the degree of importance of each firm’s relative performance; this result is strikingly different from that obtained in Nakamura (2014b). More concretely, we find that as long as the degree of importance of each firm’s relative performance is high, the owner of the private firm hires a conservative manager and otherwise hires an aggressive manager. This result is explained by the increase in intensity of market competition following an increase in degree of importance of each firm’s relative performance and the strategic substitutability between the expectations of the managers of both firms on the market size they face. Moreover, as the goods produced by the public firm and private firm become more homogeneous, the owner of the private firm tends to hire an aggressive manager. This result also is explained by the intensity of market competition and strategic substitutability between the expectations of the managers of both firms based on market size. Note that the above two results on the attitudes of firms’ managers should be strictly related to the change in intensity of market competition, represented by change in degree of importance of each firm’s relative performance, as indicated by Matsumura and Matsushima (2012). Moreover, the owner of the public firm hires his manager with her salary based on social welfare. In this case, we show that the owner of the public firm hires a conservative manager irrespective of the degree of both product differentiation and importance of each firm’s relative performance, although the aggressiveness of the manager of the private firm depends on the degree of product differentiation as well as importance of each firm’s relative performance; this result is the same as that obtained in the case wherein the managers of both the public firm and private firm maximize their relative profits. The former result is explained by the fact that the owner of the public firm refrains from hiring an aggressive manager to enhance social welfare by increasing the quantity of the private firm, which is strikingly different from the standard mixed duopoly considered in Nakamura (2014b). The remainder of this paper is organized as follows. In Section 2, we build the basic model. In Section 3, we derive the subgame Nash equilibrium market outcome in the context of quantity competition and investigate the attitudes of the managers hired by the public firm and private firm. In Section 4, we extend the analyses conducted in Section 3 by exploring the situation wherein the owner of the public firm hires his manager with her salary based on social welfare. Section 5 concludes the paper with several remarks.",3
15.0,4.0,"Journal of Industry, Competition and Trade",09 June 2015,https://link.springer.com/article/10.1007/s10842-015-0196-6,Counterfeiting and Negative Consumption Externalities – A Closer Look,December 2015,Jonas Häckner,Astri Muren,,Male,Female,Unknown,Mix,,
15.0,4.0,"Journal of Industry, Competition and Trade",18 August 2015,https://link.springer.com/article/10.1007/s10842-015-0199-3,Interlocking Directorates and Concentration in the Italian Insurance Market,December 2015,Giovanni Di Bartolomeo,Paolo Canofari,,Male,Male,Unknown,Male,"The Italian insurance industry represents a special case within the European Single Market. Since the 1994 deregulation, many companies have operated in a more liberalized market, thus exhibiting a low level of concentration. Nevertheless, consumer insurance costs are still the highest in Europe.Footnote 1 Companies operating in this market have been fined several times by the Antitrust Authority for their collusive practices; in particular, their anti-competitive behavior seems to be driven by ad hoc reciprocal information sharing (Coccorese 2010). Our paper aims to better understand the structure of the Italian insurance market and to study a potential channel for information transmission between companies. Specifically, we focus on (interlock) linkages among companies that occur when at least one individual (director) belongs to more than one company board (or other governance body) (Mizruchi 1996). Interlocking directorates occur regularly across industries and have shown potential benefits, e.g., they mobilize a scarce resource such as the expertise of senior managers and directors in large corporations. Nevertheless, the multiplicity of coexisting positions in different boards may represent a serious risk when interlocks involve competitors because they potentially support and facilitate collusive practices or otherwise contribute to the establishment or the maintenance of a tacit or oligopolistic coordination.Footnote 2 Specifically, interlocking directorates “may facilitate tacit collusion or other means of oligopolistic coordination through anticompetitive exchanges of sensitive information regarding sales and prices, product design, and firm strategy. These exchanges may make it easier for economic actors to reach common understanding regarding future behavior and also help firms to more readily detect deviations by others, thus lessening any incentive to deviate.” (Jacobs 2014: 652). Interlocking directorates can therefore represent an antitrust problem when the “interlocked” firms are competitors (direct interlock) because they can give access to sensitive and not publicly available information, e.g., firm strategies, demand, costs, and potential entry into other market segments and/or other geographic areas (OECD 2009). It is worth noting that potentially anti-competitive behavior associated with interlocking directorates cannot be detected by standard market concentration indexes. According to a report assigned by the European Commission, a comparison of the market concentration between EU countries measured by the Herfindahl-Hirschman Index shows that Italy stands out as a market with a comparatively low concentration ratio in many different sub-markets (Europe Economics 2009). The report also claims that the market share of the five largest operators in the Italian life- and non-life sector is among the lowest in Europe. However, the same report shows that Italy has the highest average premium on third party liability motor insurance compared to the other countries.Footnote 3 However, Europe Economics does not distinguish between single standing firms and a network of firms under join ownership (holding). As a consequence, the concentration ratio may be underestimated at the aggregate level. The high cost of insurance in Italy has been the subject of debate for a long time. Since deregulation in 1994, according to which public authorities can no longer control tariffs and insurance policy conditions, the Italian insurance market has been in fact the source of many discussions and studies concerning its actual degree of market concentration,Footnote 4 which have often been translated into fines imposed by the Italian Antitrust Authority and different legislative reforms (see AGCM 2008, 2010). In 2000, only six years after the deregulation, a large number of companies were sanctioned by this authority for violations of the competition regulation.Footnote 5 In 2004, the Antitrust Authority also imposed a fine of two millions euros on the Italian Association of Insurance Companies (ANIA). The motivation for this intervention was that it favored the diffusion of uniform cost parameters for insurance compensations. The Antitrust Authority also forced ANIA to interrupt its activity of coordination among insurance companies. The antitrust decisions are supported by empirical evidence. Considering firms for which business in the motor segment exceeds 60 % of their total gross premiums during the years 1998–2003, Coccorese (2010) shows that fined companies acted as if they were under collusive oligopoly conditions, extracting monopoly profits. In line with the Antitrust Authority, the author concludes that their anti-competitive behavior has been mainly founded on information exchanges. Our claim is that information sharing can be related to a sort of institutionalized and structured channel rather than single actions or temporary agreements to facilitate the exchange of information detected by, e.g., Coccorese (2010). Interlocking directorates can act as a tool to minimize reciprocal trust problems by placing insiders in places in which they can both monitor and affect other companies’ behavior. Specifically, interlocking directorates could compromise market competition by enhancing coordination among firms and strengthening the sustainability of implicit agreements between competitors. On the one hand, successful coordination requires “agreement” on the common strategy that the different market participants undertake to follow, which can be simplified by the interlocking directorates; on the other hand, the sustainability of implicit agreements strongly depends on the speed and accuracy by which “cheating” can be detected (OECD 2009). The stability of collusive practices is strengthened by the trust generated through the interlocking directorates: By placing a director on a cartel partner’s board, each one can rely on an “observer” who can monitor partner activities that could compromise the agreement—such as plans to reduce prices, expand capacity, or introduce new products.Footnote 6
 However, interlocking directorates may also represent a business strategy for using different brands within the same group while still achieving gains from cooperation and scale effects (although limited in insurance markets; see Cummins and Weiss 2000). As long as companies may be organized in multi-brand groups, the holding company determines the managers and the directors for all its subsidiaries; optimal business strategies then require that there will be persons serving in several directorates to coordinate the actions of individual firms operating under different brands but characterized by a common ownership. Within a group, therefore, interlocking linkages do not represent a collusive practice. These linkages clearly operate as a coordination device among firms belonging to the same group. In such a case, concentration is captured considering the market share of the holdings instead of the single companies. If data about holdings are not available, however, data on interlock directorates may represent an alternative measure to assess the effective degree of market competition. It should also be noted that interlocking directorates may represent a part of an overall corporate governance policy, and they can help to mitigate agency problems between owners and managers (e.g., Berle and Means 1932; Dooley 1969; Jensen and Meckling 1976).Footnote 7 If corporate governance can reduce inefficiencies leading to lower costs, consumers may eventually improve their condition. Because effective governance assumes effective oversight, there is a rationale to justify the fact that directors are chosen between industry members. However, there appears to be substantial evidence that interlocks and other outside personal relationships can be associated with poor performance although causality is not trivial (see e.g., Richardson 1987; or the survey by Adams et al. 2010: 85).Footnote 8
 We aim to contribute to the understanding of the structure of the Italian insurance market by focusing on interlocking directorates to disentangle the creation of linkages between companies belonging to the same holding from the creation of linkages among independent companies. The former represents a business strategy within an industrial group, whereas the latter may affect the degree of market competition—by potentially supporting collusive practices through information sharing. We first look at the market considering a map of the company connections by interlocking directorates and discuss the aggregate network statistics. Then, we identify insurance groups and study the networks among and within them. Specifically, we look closely at the structure of each group from a network analysis perspective, attempting to identify similar business strategies, and then we consider the relationships between different holdings. Finally, we compute the Herfindahl-Hirschman Index for companies, holdings and also networks of different holdings to relate these different levels of organization to a measure of market concentration. The remainder of our paper is structured as follows. Section 2 describes our data and methodology. Section 3 reports our results by considering the network of companies and holdings. A final section concludes.",6
15.0,4.0,"Journal of Industry, Competition and Trade",14 July 2015,https://link.springer.com/article/10.1007/s10842-015-0197-5,Service Offshoring and Corruption: Do Firms Escape Corrupt Countries?,December 2015,Patrik Karpaty,Patrik Gustavsson Tingvall,,Male,Male,Unknown,Male,"In many countries, the service sector accounts for two-thirds of GDP or more, and services account for approximately 20 % of world exports (Lejour and Smith 2008; UNCTAD 2009). These numbers are also representative for Sweden, where trade in services represents approximately 20 % of total trade. The relatively low share of services in world exports can partly be explained by the fact that only 10 % of service output is tradable, while the corresponding number for materials is over 50 %. Lejour and Smith (2008) argue that this difference is not exclusively due to non-tradability in services; they claim that services constitute a larger share than the directly measurable 20 % of trade because services implicitly enter into trade as inputs in the production of traded goods. Lejour and Smith (2008) argue that in OECD countries, nearly 40 % of employment in the manufacturing sector can be considered services work.Footnote 1 Parallel with this development, services have become increasingly internationalized. The share of foreign direct investment (FDI) in services of total FDI has increased from approximately 24 to 66 % for the period 1970–2005 (Ramasamy and Yeung 2010). However, despite the large and growing importance of the service sector, trade in services is relatively unexplored. Here, we analyze a specific type of trade in services, namely, the sourcing of business services and how service offshoring is affected by corruption in source countries. Corruption is often portrayed as a barrier to trade and investment (Márquez-Ramos et al. 2012; Hakkala et al. 2008).Footnote 2 Ignoring the direct cost of bribes, it has been found that corruption is correlated with opportunistic behavior and that theft and waste of project funds are relatively common in corrupt environments. Therefore, corruption increases the need for monitoring and control (North 1991). Other uncertain costs include fines and costs that occur if an issue is taken to court and goodwill losses that occur if corrupt behavior is made public. Obviously, there is a moral side that also needs to be considered. In addition, the cost of corruption is not uniform across different products. For offshoring to occur, agents from different jurisdictions must agree on a contract, and the cost of a contract increases with the share of sensitive information involved (Nunn 2007). International offshoring can involve transfer of management control, decision-making or firm-specific knowledge. Therefore, complex contracts can be relatively costly to design, and corruption increases this cost. For standardized tasks, corruption is less likely to be an issue (North 1991; Massini et al. 2010). Despite the associated costs, there are several examples of firms that engage in corrupt behavior. For the principal, one reason to engage in corrupt behavior and pay bribes for permits and services is that it can shorten lead times. According to the so-called grease the wheels hypothesis, corruption can be beneficial for an economy by allowing business people to avoid restrictions that would otherwise discourage investment (Shleifer and Vishny 1993; Wei 2005). Hence, the extent to which corruption is harmful for international exchange is partly an empirical issue. It is therefore surprising to find that there are no empirical studies on the relationship between corruption and service offshoring. The most closely related exception is Niccolini (2007), who studies the impact of institutions on the trade of US firms with their affiliates abroad (FDI/in-house offshoring). Niccolini (2007) finds that weak institutions hamper trade in intermediate goods, whereas the impact on final consumption goods is less clear. Considering that contract costs are greater when negotiating with an external supplier than with an agent within the corporation, these results may be indicative, although they may not fully capture cross-border, cross-firm contract costs. Contrary to offshoring and corruption, a series of papers analyzes corruption and FDI. In this literature, most papers examine total FDI rather than FDI in services. To the best of our knowledge, there are no analyses on FDI in services and corruption, but in a related paper, Ramasamy and Yeung (2010) analyze determinants FDI in services. Ramasamy and Yeung (2010) find that risk, defined as a composite index of country risk, is a deterrent to FDI in services. Even though the evidence is mixed, most results point to a negative relationship between FDI and corruption. Brada et al. (2012) summarize the recent research and analyze outward FDI in a sample of Eastern European countries. Brada et al. (2012) find that corruption is a deterrent for location selection, but when the selection is completed, there are no significant volume effects of corruption on FDI, whereas Habib and Zurawicki (2002) and Egger and Winner (2006) find corruption to be detrimental to the volume of FDI. Evidence suggests that the effect of corruption is non-uniform. Hakkala et al. (2008) find corruption to be more detrimental to horizontal FDI than to vertical FDI, and Smarzynska and Wei (2000) find corruption to alter the composition of FDI by shifting investments toward joint ventures rather than wholly owned affiliates. Dahlström and Johnson (2007) and Caetano and Caleiro (2005) find the impact of corruption on FDI to be negative and significant, but only for developing countries. The non-uniform effect of corruption found by Caetano and Caleiro (2005) is consistent with the threshold value effect of corruption found by Bose et al. (2008), who analyze investments in public infrastructure and find that corruption adversely affects the provision of public goods only when it exceeds a certain threshold value.Footnote 3
 We add to this literature in several ways. First, by explicitly focusing on corruption and service offshoring, we analyze a relationship that has been overlooked in the empirical literature. Second, we analyze whether the impact of corruption is uniform across rich and poor countries and types of services. Third, knowledge about how sensitivity to corruption differs across types of firms is thin. We add to this literature by analyzing whether large global firms with international networks react differently to corruption than other firms. Finally, our analysis is based on detailed firm- and country-level data. These types of detailed data are rare in the previous literature. The data allow us to apply several different econometric approaches, thus limiting the risk that the results will be driven by the choice of econometric model. We saw that the large mass of services are sourced from relatively rich and corruption free countries such as the US and that corruption is a deterrent for both the choice of destination country and the volume of services sourced. Using the Heckman estimator, our overall findings suggest that a one unit decrease in corruption, on a five graded scale, leads to increased outsourcing by approximately 13 %. This effect is mainly driven by the poor countries. For the poorest income group, decreasing corruption by one unit (which is approximately equal to one standard deviation) leads to an estimated increase in service offshoring of almost 50 %, whereas the volumes are not significantly affected for middle- and high-income countries. In addition, we find that large and internationalized firms use their flexibility to avoid corrupt countries to a larger extent than other firms. Taken together, these results suggest that the gains from fighting corruption are likely to be the largest for poor countries. The paper is organized as follows. In Section 2, outsourcing, services, corruption and the theoretical link between corruption and service offshoring are discussed, in Section 3, we present the data, the gravity model, and discuss econometric considerations. The results are provided in Section 4, and Section 5 concludes.",3
15.0,4.0,"Journal of Industry, Competition and Trade",26 May 2015,https://link.springer.com/article/10.1007/s10842-015-0194-8,Technology Transfer in Oligopoly in Presence of Fixed-Cost in Production,December 2015,Neelanjan Sen,,,Unknown,Unknown,Unknown,Unknown,,
15.0,4.0,"Journal of Industry, Competition and Trade",17 April 2015,https://link.springer.com/article/10.1007/s10842-015-0193-9,Technology Import and Manufacturing Productivity in India: Firm Level Analysis,December 2015,R. Rijesh,,,Unknown,Unknown,Unknown,Unknown,,
15.0,4.0,"Journal of Industry, Competition and Trade",07 July 2015,https://link.springer.com/article/10.1007/s10842-015-0195-7,A Reappraisal of Strategic Trade Policy,December 2015,Elizabeth Schroeder,Victor J. Tremblay,,Female,Male,Unknown,Mix,,
16.0,1.0,"Journal of Industry, Competition and Trade",10 September 2015,https://link.springer.com/article/10.1007/s10842-015-0202-z,Optimal Rules of Origin with Asymmetric Compliance Costs under International Duopoly,March 2016,Naoto Jinji,Yoshihiro Mizoguchi,,Male,Male,Unknown,Male,"The world economy has witnessed a rapid proliferation of regional trade agreements (RTAs) over the last two decades. Most of the RTAs that are currently in force take the form of a “free trade area/agreement” (FTA). In contrast to a “customs union” (CU), in which member countries have to set common external tariffs, each member of an FTA has the freedom to maintain its own external tariffs. As there may be heterogeneity in external tariffs among members of an FTA, firms in non-member countries have an incentive to export their goods to member countries with the lowest external tariffs and re-export them to other member countries with higher external tariffs. To prevent such tariff circumvention, FTAs usually set rules of origin (ROO), which specify detailed conditions under which goods are regarded as produced within the FTA so that they are eligible for trade among members of the FTA without tariffs.Footnote 1
 Despite its legitimate reason for utilization in FTAs, the ROO have been criticized for their protectionist effects (Krueger 1999; Krishna and Krueger 1995). Krueger (1999) argues that the ROO induce final good producers in member countries of an FTA to shift their sources of intermediate inputs from low-cost non-member countries to high-cost member countries to make their products eligible for tariff-free exports to other member countries. The ROO may also generate another protectionist bias if they are set such that producers in FTA member countries have an incentive to comply and those in non-member countries do not. Another issue regarding the ROO pointed out more recently is related to the rates of FTA utilization by producers in FTA member countries. In fact, the rate of utilization is surprisingly low for some FTAs. For example, Anson et al. (2005) report that the utilization rate of the North American Free Trade Agreement (NAFTA) for Mexican exports to the United States (US) was 64 % in 2000. According to James (2008), the utilization rate of the US–Chile FTA for Chilean exports to the US in 2005–2006 was about 55 %. The utilization rate is much lower for FTAs in Asia (Hayakawa et al. 2013). Utilization of the ASEAN Free Trade Area (AFTA) for exports of Japanese firms and their affiliates operating in ASEAN countries was only 15–20 % during the period 2003–2006. One possible reason for such low utilization rates of FTAs is that firms are reluctant to incur additional costs to comply with the ROO. The use of preferential tariff rates under FTAs requires firms to comply with the ROO specified in the FTAs, “to obtain certificates of origin (COO) in exporting countries and to submit the COO to the customs in importing countries” (Hayakawa et al. 2013, 246). The procedures that firms have to follow to utilize the FTAs’ preferential tariff rates generate additional production and administrative costs. Anson et al. (2005) provide empirical evidence that the compliance costs of ROO are not negligible.Footnote 2 Firms located in FTA member countries, as well as those in non-member countries, incur compliance costs (Augier et al. 2005; Cadot and de Melo 2008). For example, when firms in FTA members initially import intermediate inputs from FTA non-members, they may partly change the source of the intermediate inputs from non-members to members, with possibly higher prices. In addition, compliance costs will be generally higher as the ROO are more stringent. In this paper, we examine whether the ROO that are optimally set by FTA member countries involve a protectionist bias and, also, cause low utilization of FTAs. We focus on the effects of asymmetric compliance costs of ROO between firms of FTA members and non-members on market competition among firms. We employ a stylized three-country partial equilibrium model of an international duopoly. Unlike previous studies in the literature of ROO (e.g., Falvey and Reed2002; Ju and Krishna2005; Chang and Xiao2013; Takauchi2011, 2014), however, we construct a simple model in which the intermediate input market is abstracted and directly introduce compliance costs of ROO into firms’ cost functions. This simple approach allows us to identify the optimal choice of ROO for FTA members, combined with the external tariff set by an FTA member, by analyzing the relationship between asymmetric compliance costs of ROO among firms and their behaviors in a tractable way. The basic structure of our model is as follows. Two firms produce a homogeneous good and compete in a Cournot fashion in a market located in one of two FTA member countries (country A). One of the two firms (firm I) is located in an FTA member country (country B), which is different from the country in which the market is located (country A), and another firm (firm E) is located in an FTA non-member country (country C). Firm I is less efficient than firm E; hence, its marginal production cost is higher than that of firm E. Country A imposes its own external tariffs on imports. However, it imports goods without tariffs if they comply with the ROO of the FTA. Both firms E and I can comply with the ROO by incurring compliance costs. Firm I has some advantage in complying with the ROO compared with firm E; hence, firm E must incur relatively higher compliance costs. The FTA member countries (i.e., countries A and B) set the stringency of ROO to maximize their joint welfare. More stringent ROO impose higher compliance costs on firms. We consider a four-stage game. In stage 1, the member countries (A and B) set the optimal level of ROO to maximize joint welfare of countries A and B. In stage 2, country A sets its external tariffs to maximize domestic welfare. Here, we explicitly take into account the restriction imposed by GATT Article XXIV that country A’s external tariff should not be raised above the pre-FTA level. In stage 3, the two firms simultaneously decide whether to comply with the ROO. In stage 4, they compete in country A’s market in a Cournot fashion. The main results are as follow. The equilibrium outcome depends on both the degree of the relative cost disadvantage of firm I and the degree of relative disadvantage of firm E in complying with the ROO. First, when the marginal cost of firm I is sufficiently higher than that of firm E, the optimal ROO are set to induce firm I to comply and firm E not to comply with the ROO. Second, when the cost disadvantage of firm I is at a medium level, the optimal ROO is set to induce both firms not to comply with the ROO if the disadvantage of firm E in compliance costs is less serious and to induce only firm I to comply with the ROO if the disadvantage of firm E in compliance costs is serious. Finally, when the cost difference between the two firms is relatively small, the optimal ROO are set to induce, again, only firm I to comply with the ROO if firm E’s compliance costs are sufficiently higher than that of firm I and to induce both firms to comply with the ROO if the difference in compliance costs between the two firms is also relatively small. Thus, our analysis reveals that ROO involve a protectionist bias in the sense that they are set for only firm I to comply if firm I’s marginal cost is sufficiently higher or the difference in compliance costs of ROO between the two firms is sufficiently large. Our results also explain low utilization of FTAs due to the ROO for a medium range of cost disadvantage for firm I and a small difference in compliance costs between the two firms, in which the ROO are set such that neither firm complies with them. The reason why the joint welfare of the FTA members becomes higher when only firm I complies with the ROO is not as straightforward as expected. Actually, different mechanisms work, depending on the case. We argue that in case of a relatively small cost disadvantage of firm I and a medium difference in compliance costs, double rent-shifting improves FTA members’ welfare by shifting rents from firm I to firm E and shifting rents back by imposing tariffs. To our knowledge, this mechanism is new to the literature. On the other hand, for a range of medium cost disadvantage of firm I, the ROO enable FTA members to liberalize trade preferentially; hence, a rent-shifting effect from firm E to firm I and a pro-competitive effect improve members’ welfare. Though there are a number of existing studies related to our paper, our analysis and results differ from these. First, as mentioned above, Krueger (1999) and Krishna and Krueger (1995) illustrate the protectionist effects of ROO, which distort the demand for intermediate inputs.Footnote 3 In contrast, we focus on a possible protectionist bias in the final-good market in the sense that the ROO are arranged by FTA members so that only internal firms have an incentive to comply. Similar to this study, the strategic interactions among firms in final-good markets is the center of the analysis in Ishikawa et al. (2007). However, their focus is quite different from ours. They consider Bertrand competition between an internal and an external final-good producer of an FTA and illustrate anti-competitive and anti-protectionist effects of ROO due to the market power mitigation for the internal firm. However, in their model, goods produced by the internal firm always qualify for tariff-free exports, and goods produced by the external firm have no option to comply with the ROO in the presence of ROO. Second, Ju and Krishna (2005) and Takauchi (2014) address the issue of low FTA utilization rates due to ROO. Under perfect competition, Ju and Krishna (2005) show that in response to the restrictiveness of the ROO, all or only a fraction of the firms in an FTA comply with the ROO at equilibrium. Depending on the type of equilibrium, more stringent ROO may raise or reduce the demand for inputs manufactured within the FTA. The effects of ROO on market access by firms outside the FTA also depend on the type of equilibrium. Takauchi (2014) considers the case in which a monopolist supplies intermediate inputs within an FTA. As the input price charged by the monopolist is affected by the number of firms that try to comply with the ROO, a strategic interaction among final-good producers in the FTA may result in an equilibrium in which compliers and non-compliers coexist. Whereas both studies focus on possible non-compliance by internal firms of an FTA, we consider the case in which both internal and external firms have the option of compliance or non-compliance and show that ROO may be set to induce even the internal firm to choose non-compliance for certain parameter values. Finally, Falvey and Reed (2002), Takauchi (2011), and Chang and Xiao (2013) are closely related to this paper. All of these studies investigate policy combinations of optimal external tariffs by individual FTA members and ROO in FTAs. However, these studies are still different from us in some important respects. Similar to this paper, Falvey and Reed (2002) consider the case in which there are one importing country and two exporting countries, and wherein the importing country forms an FTA with one of the two exporting countries. In the situation where the importing country has an incentive to impose discriminatory tariffs on imports from the two different countries, the ROO specifying the minimum share of domestically produced intermediate inputs in the exporting country determines whether the goods qualify for preferential tariffs. However, they assume that the importing country unilaterally sets the optimal ROO and tariffs and examine how the importing country will change the stringency of the ROO after forming an FTA (i.e., in response to a marginal reduction in tariffs imposed on one exporting country). They also ignore the possibility of non-compliance. In these respects, their focus is quite different from ours.Footnote 4Takauchi (2011) investigates the welfare effects of ROO with optimal external tariff in a three-country three-firm oligopoly model. In his model, each firm engages in cost-reducing R&D, which is different from other studies including our paper. Unlike Falvey and Reed (2002), ROO in Takauchi (2011) take the form of content requirement for intermediate inputs produced in the importing FTA member country. Then, he derives the optimal content rate of ROO for the importing FTA member. Thus, his study is different from us by focusing on the optimal ROO for an importing country within an FTA rather than for the joint welfare of all FTA members. Moreover, as in our paper, Chang and Xiao (2013) consider that in a three-country model of trade under international oligopoly, FTA members jointly set the ROO and individually choose their optimal external tariffs. They analyze the effects of an FTA with ROO on equilibrium variables and showed how the optimal external tariffs are related to the restrictiveness of ROO. However, there are a number of key differences between their study and ours. First, they limit the choice of optimal external tariffs to the case of full compliance by internal firms. Second, in their model, external firms cannot comply with the ROO. This assumption is important because FTA members can always earn tariff revenues from non-members as long as imports from non-members are positive. Third, there is no heterogeneity in compliance costs among firms in their study. Fourth, they only derive the range of ROO restrictiveness that improves welfare of each FTA member and do not analyze the optimal choice of ROO. Given the above mentioned differences between this and previous studies, our study contributes to the ROO literature in at least two respects. First, we derive optimal policy combinations of ROO for FTA members as a whole, and external tariffs for the importing country within the FTA when both internal and external firms have options of compliance and non-compliance. Second, we illustrate that the optimal ROO may actually have protectionist bias and also cause low utilization of FTA in one model, depending on the parameter values. The remainder of the paper is organized as follows. In Section 2, we present the model setup. In Section 3, we analyze the equilibrium prior to forming an FTA. In Sections 4 and 5, we solve the model and analyze the optimal ROO. In Section 6, we present the conclusions.",3
16.0,1.0,"Journal of Industry, Competition and Trade",21 August 2015,https://link.springer.com/article/10.1007/s10842-015-0200-1,Vertical Relations in the Presence of Competitive Recycling,March 2016,Liliane Giardino-Karlinger,,,Female,Unknown,Unknown,Female,"The goal of this paper is to study vertical relations in an industry where a monopoly manufacturer of a durable good faces competition for its primary good output from a competitive recycling sector which collects and resells the manufacturer’s past output. Examples for such industries abound: In the truck tire industry, about 40 percent of all tires sold are so-called “retreaded” tires, i.e. worn tires re-manufactured by replacing the outer shell, the so-called “tread”. Another case in point is the internet-based retailer Amazon; on the one hand, Amazon sells new books and CDs to final consumers, and on the other, it serves as a platform for peer-to-peer and business-to-consumer retail trade of used books, CDs and similar items. More often than not, the same title will be available both “new” and “used” and Amazon lists them next to each other. Amazon’s relations with publishers and record labels, i.e. the “primary output” producers, cannot but take this supply of secondary goods into account. Another example that comes to mind are car dealers who carry the new models of a particular car manufacturer along with used cars of the same brand. Similarly, many stationery retailers will offer original color cartridges for various printer brands along with cartridge refills produced by no-name manufacturers (or they may directly offer the refill service to consumers who bring their empty cartridges). The focus of this paper is on the structure of wholesale contracts between, say, the manufacturer of new tires and their retailers who also carry retreaded tires. I consider a two-period model where a manufacturer of a recyclable good has to decide under what terms to sell its output to one or more retailers. A competitive recycling sector will recover and recondition first-period output (either partially or fully). In period 2, the retailer(s) will then sell the recycled quantity along with the second-period quantity of the manufacturer’s primary good. As it turns out, the downstream market structure is crucial for the outcomes that can be achieved by simple two-part tariffs. As a benchmark, I start with the analysis of bilateral monopoly. I show that the efficient outcome (i.e. the outcome that maximizes industry profits) calls for the retailer to carry both the primary and the recycled good in period 2 (“multi-product retailing”). At the beginning of each period, the manufacturer offers a simple two-part tariff to the retailer (I rule out period-1 commitment to prices or outputs in period 2). If the retailer rejects the manufacturer’s offer in the second period, he can decide to sell the recycled good only, where period-2’s supply of recycled output depends on how much of the primary good was produced in the first period (I assume that there is no supply of the recycled good in the first period). The retailer’s payoff from this outside option determines its share in the second-period multi-product profits. I show that in this setup, simple two-part tariffs are sufficient to achieve the industry-profit maximum: If the retailer is not credit-constrained in the first period (i.e. payments to the manufacturer can exceed first-period retailer revenues), then the retailer’s share in the second-period profits will be extracted by the manufacturer in the first period, thus neutralizing any possible distortion due to the retailer’s bargaining power in the second period. This efficiency result is in contrast with most of the early literature on the impact of recycling on monopoly (Swan 1980; Martin 1982), which found that the monopolist’s first-period output is likely to be distorted downward; the rationale for this first-period output contraction is that in the second period, the recycling sector would steal some of the demand for the monopolist’s primary good output. Thus, by reducing first-period output, the monopolist can soften competition from the recycling sector in the next period. Instead, in my setting, there is no immediate competition between the manufacturer and the recycling sector: rather, the retailer’s marketing recycled output in the second period is very similar - if not equivalent - to upstream entry by another strategic agent. As was shown by Aghion and Bolton (1987), in a model with sequential contracting, the buyer and the first seller can extract all the surplus from the second seller by agreeing to an exclusive-dealing contract in which the buyer must pay a lump-sum penalty to the first seller if it buys from the second seller. The penalty is set high enough to extract all rent, but not so high as to discourage entry altogether; thus, inefficient exclusion will never arise. This reasoning carries over to our setting: the manufacturer has no incentive to pre-empt the entrant-retailer or distort output choices as long as the manufacturer can fully extract the entrant’s rent at an early contracting stage. The major difference to the Aghion and Bolton setting is that, here, the parts of retailer and entrant are played by the same agent; however, the retailer cannot afford to reject the manufacturer’s contract in the first period because failing to market the incumbent’s primary output in the first period implies that there will be no supply of the recycled good (and hence no rent for the retailer) in the second period. In the second major section of this paper, I introduce downstream competition into the model. I assume that there are two undifferentiated retailers who first contract with the manufacturer, and then compete for the acquisition of the recycled good, before offering their supplies on the final consumer market. The interaction on the recycled good market is modelled as a split-award auction following Anton and Yao (1989). Now, a rather different picture emerges: Through the auction mechanism, some of the rent generated by the vertical structure will be siphoned off by the recycling sector. This rent leakage can only be prevented if the manufacturer can use vertical restraints which allocate primary and recycled output efficiently across retailers. Otherwise, the manufacturer will either overproduce the primary good in the second period, or underproduce in the first period. The contraction of early period output is reminiscent of the early literature on monopoly and recycling discussed above. There, too, the output distortion was a reaction to the threat of rent being competed away in the future. In my setting, however, it is the downstream competition among retailers through which rent leeks out, not upstream competition between the manufacturer and the recycling sector. As it turns out, the level of rent lost to the recycling sector depends not only on the aggregate level of primary output produced in period 2, but also on its distribution across retailers: The manufacturer has an incentive to discriminate among her retailers, creating one large and one small retailer, in order to soften competition for the acquisition of the recycled good. However, even such discriminatory two-part tariffs will not be sufficient to replicate the first-best outcome. Consequently, the manufacturer may resort to various vertical restraints to eliminate competition between its retailers. The welfare effects of such vertical restraints are ambiguous: they are efficiency-enhancing whenever recycled output is in short supply (because they promote early-period production in this case), but they will harm consumers when recycled output is abundant, as they lead to contraction of output in later periods. The latter result is particularly interesting in a policy context, because most research on cross-market controls such as loyalty rebates has so far only found efficiency defenses, but rarely offered a rationale for the skepticism displayed by most antitrust authorities regarding such restraints when used by a dominant firm. My results contribute to the recent literature on loyalty rebates, which takes a contract theoretic approach and shows how the various types of loyalty rebates can be used to overcome some of the standard problems in vertical relations, like double marginalization (Kolay et al. 2004), asymmetric information about the state of demand (Majumdar and Shaffer 2007), risk-aversion (Chioveanu and Akgun 2007), and asymmetric information about product quality (Mills 2004). Apart from Marx and Shaffer (2004), there are very few papers which study the use of loyalty rebates in a dynamic setting. Ordover and Shaffer (2013) analyze a two-period model with two sellers and one buyer where the buyer incurs switching costs: purchasing a unit from a seller in period 1 locks-in the buyer to purchasing a unit from the same seller in period 2. In this setting, a dominant firm can profitably exclude an equally efficient, but financially constrained rival, monopolizing the market when the efficient outcome would have the buyer purchase one unit from each seller in each period. This paper is among the very few in this literature to find an anti-competitive effect of loyalty rebates. To my knowledge, the only other formal model of exclusionary rebates is Karlinger and Motta (2007). There, an incumbent and a more efficient entrant simultaneously make offers to a number of buyers who differ in size. Network externalities among these buyers imply that the entrant can profitably serve the market only if it reaches a certain minimum size. The incumbent can then use rebates to play a “divide-and-conquer” strategy, thereby breaking entry equilibria that would exist under uniform linear prices.",
16.0,1.0,"Journal of Industry, Competition and Trade",10 November 2015,https://link.springer.com/article/10.1007/s10842-015-0207-7,Measuring the Magnitude of Significant Market Power in the Manufacturing and Services Industries: A Cross Country Approach,March 2016,Michael L. Polemis,Panagiotis N. Fotis,,Male,Male,Unknown,Male,"Estimating the degree of competition in an industry is crucial for regulatory and competition authorities as well as the policy-makers. Regulators would like to know whether current regulation is conducive to competition. Likewise, competition authorities might gauge the current competitive situation in a sector (Christopoulou and Vermeulen 2012). As a consequence, boosting competition in the markets for goods and services is a growing economic policy concern, as evidenced by the policies employed by the European Commission and the OECD. Specifically, the European Commission, has recently announced its intention to amend the competition law legislation by fine tuning certain regulatory measures (i.e EC merger regulation, leniency program, application of State aid rules, etc) in order to facilitate competitive conditions across the member states. It is noteworthy, that competition, inter alia, enhances economic activity and increases the level of employment by improving purchasing power and spurring firms to innovate. In this context, there is a need for structural indicators allowing the researchers and the government officials to identify clearly those sectors of the economy for which competition could be increased. Among the most commonly used indicators are the degree of market concentration in the sector, such as HHI and CR 4 indexes, and the degree of sectoral regulation. However, these indicators do not always reflect the real degree of competition in a sector. An alternative approach is to use national accounts data to infer conclusions about the difference between the selling price (P) and the marginal cost (MC), since the less competition there is in a sector, the more the price can diverge from the marginal production cost. In other words, we can use the ratio between the sale price and the marginal production cost (mark up ratio) in order to gauge the intensity of competition in a sector. As a consequence, mark-up estimates of different sectors and different countries allowing for comparisons of the degree of competition, they should help in identifying which sectors and/or countries would benefit most from changes in legislation or regulation that affect competition. The approach adopted here is to estimate econometrically the level of market power by following the methodology developed by Hall (1988) and extended by Roeger (1995). This methodology is based on the hypothesis that in a situation of perfect competition the selling price is equal to marginal cost. The equality of marginal cost and price is essential for the efficiency of the economy since, first, competitive markets can achieve higher productivity levels, and second, competition provides consumers with products of higher quality, increased variety and lower prices (Rezitis and Kalantzi 2013). However, this condition does not apply in a less competitive environment (i.e oligopoly markets, monopolies), since the price deviates from marginal cost. Therefore, the ratio between the selling price and marginal cost assesses the competitiveness of the market. However, while selling price is directly observable, the marginal production cost is not. This drawback was overcome by Hall (1988) and Roeger (1995) who both showed that under perfect competition, the nominal growth rate of the Solow residual is independent of the nominal capital productivity growth rate. It then follows that the coefficient linking the nominal growth rate of the Solow residual to the nominal capital productivity growth is the Lerner Index defined as the ratio of the price minus marginal cost to price (\( L=\frac{P-MC}{P} \)). Despite the voluminous amount of work on the topic, none of these studies –to the best of our knowledge- has examined this relationship for the Eurozone countries.Footnote 1 Furthermore, unlike previous studies, we use an array of econometric techniques such as Ordinary Least Squares (OLS), Two Stage Least Squares (2SLS) and bootstrap methods to test the robustness of the results. Investigating this relationship for the sample countries (i.e Eurozone, USA and Japan) will be interesting on many fronts, discussed next: First, mark-up ratios can provide valuable information on competitive pressures in various sectors of the economies, reflecting pressures stemming from rules of conduct imposed by regulators as well as those arising from such factors as increasing consumer demands in terms of price and quality. Moreover, the estimation of mark-up ratios in manufacturing and services industry may benefit policy makers and government officials to pursue pro-competitive regulatory reforms in order to maximize consumer surplus. Second, it will be interesting to measure the magnitude of market power which can be considered as large for the sample economies and thus, have some effects on the industrial production, as well as their degree of persistency. The latter may be associated with the duration of the business cycles or inflationary pressures of the sample economies. Third, it will be considerable for researchers to examine if market power changes over time or not. Our analysis will be a useful policy tool to achieve structural micro-economic goals in light of the on-going financial crisis. Firstly, given the primarily indications regarding the high mark ups for services, a suitable ex ante policy is linked with a thorough investigation of mergers and acquisitions. Secondly, in order to enhance the level of internationalisation in manufacturing, the economic policy authorities may pursue horizontal strategies focusing on the further opening of the markets. Since the vast majority of the manufacturing firms in the sample countries are small and medium sized (SMEs), the governments must improve the access of micro and small SMEs to existing financial support mechanisms and to relevant information sources. The remainder of this paper is organised as follows: Section 2 reviews the literature, while Section 3 discusses the data and outlines the methodology applied. Section 4 illustrates and evaluates the results of the empirical analysis, while Section 5 depicts some stylized facts. Finally, Section 6 provides some conclusions and policy implications.",5
16.0,1.0,"Journal of Industry, Competition and Trade",17 September 2015,https://link.springer.com/article/10.1007/s10842-015-0204-x,"Cartelization, Cartel Breakdown, and Price Behavior: Evidence from the German Cement Industry",March 2016,Kai Hüschelrath,Tobias Veith,,Male,Male,Unknown,Male,"The desire of firms to ease competitive pressures and increase joint profits through the implementation of cartel agreements has long been recognized by academics such as Adam Smith back in 1776. Although incentives to form cartels generally exist, more recent economic research has not only shown that the costs and benefits of reaching such agreements differ substantially between industries – depending on various economic characteristics such as the number of firms, the type of product, or the significance of entry barriers – but also came to the conclusion that successfully implemented cartels face the constant danger of breaking down; either internally through the deviation of cartel members or externally through the detection by a competition authority or a significant increase in non-cartel supply. Although a substantial theoretical literature investigates the effects of cartelization and cartel breakdown, at least two important – theoretically ambiguous – questions on the price behavior of cartels before and after their breakdowns remain understudied from an empirical perspective. First, particularly in intermediate goods markets, prices communicated in official price lists can differ quite substantially from transaction prices, i.e., the prices actually paid by the customers. Although a large theoretical and significant empirical literature on these rebate negotiation processes exist, in a cartel context, the question is raised to what extent average list and transaction prices differ before and after the cartel breakdown and whether they are used for strategic purposes. While the cartel agreement is active, cartel members are typically only able to monitor list prices but not transaction prices. As a consequence, cartel members might have possibilities (and incentives) to secretly deviate from the cartel agreement by reducing transaction prices rather than list prices thus affecting the cartel’s profitability and stability negatively. On the other hand, after the breakdown of the cartel, cartel members might have incentives to (strategically) reduce transaction prices to a larger degree than list prices as the former are much more difficult to observe and competition authorities, courts or private parties may therefore be forced to use (higher) list price data to, e.g., investigate actual market behavior and subsequently estimate cartel damages. 
Second, although economic theory suggests that cartels must include the firms with the majority of overall market shares in order to achieve the desired increase in profits, it may be individually profitable for especially smaller firms to stay out of the cartel thus raising the question to what extent the price behavior of cartel members and non-cartel members diverge before and after the cartel breakdown. An empirical assessment of these differences are of interest to, first and foremost, test the theoretical result that especially smaller firms may increase their profits by staying out of the cartel, however, still raise their price above the competitive level (under the price umbrella of the cartel). In this respect, the cartel breakdown provides a suitable opportunity to particularly investigate possible changes in the pricing behavior of both cartel- and non-cartel members thereby contributing to our understanding of the economics of cartel agreements. Against this background, we use a unique dataset of about 340,000 market transactions from 36 smaller and larger customers of German cement producers to study the price behavior before and after the breakdown of a German cement cartel. We find that, first, while the cartel agreement was active, cartel members set higher list prices than non-cartel members; however, larger rebates granted by the cartel members led to similar transaction prices. Second, after the cartel breakdown, both cartel- and non-cartel members reduced transaction prices to a far larger extent than list prices. We build on these results and discuss implications for competition policy. The remainder of the article is organized as follows. The second section provides an overview of existing research on, first, differences between list and transaction prices and, second, the price behavior of cartels. Following a brief overview of the German cement industry and the cement cartel in the third section, our empirical analysis is presented in the fourth section. After a detailed description of the dataset and the descriptive statistics in Section 4.1, the subsequent Section 4.2 explains our modeling approach. Section 4.3 then continues with the presentation and discussion of our estimation results – differentiated between the analysis of list and transaction prices on the one hand and the analysis of list-transaction price differences on the other hand. Section 4.4 builds on the obtained results and discusses several implications for competition policy. Section 5 concludes the article with a review of the key results.",10
16.0,1.0,"Journal of Industry, Competition and Trade",17 September 2015,https://link.springer.com/article/10.1007/s10842-015-0203-y,Which Companies Benefit from Liberalization? a Study of the Influence of Initial Productivity,March 2016,Delia Baghdasaryan,Lisbeth Funding la Cour,Cédric Schneider,Female,Female,Male,Mix,,
16.0,1.0,"Journal of Industry, Competition and Trade",07 December 2015,https://link.springer.com/article/10.1007/s10842-015-0211-y,Nationalization as Credible Threat Against Collusion,March 2016,Flavio Delbono,Luca Lambertini,,Male,Male,Unknown,Male,"The view that the public firm is one of the instruments to correct market failures and to improve social welfare is well established.Footnote 1 The presence of market failures like those associated to imperfect or distorted competition may clearly motivate some form of public intervention as, for instance, the creation of a mixed oligopoly. This outcome may be achieved by the policy maker either by creating a new (publicly owned)Footnote 2 company or by nationalising a private one. The market structure emerging from such operation can then be viewed as intermediate between the extreme situations of “complete government ownership and control, and private ownership restricted by close government supervision in the form of regulation and anti-trust laws” (Merrill and Schneider 1966, p. 400). While we share the above view about the ability of public firms in correcting market failures, in this paper we focus on the capacity of nationalization in preventing the important instance of market failure represented by collusion. More precisely, we shall show that the threat of nationalization may discipline oligopolistic firms by forcing them not to collude, not even tacitly. This happens because the game where one firm is public ceases to be a prisoners’ dilemma as seen with the eyes of profit-seeking agents. Hence, the motive for setting up a cartel in a repeated game disappears. Our paper aims then at filling a gap in the by now large literature on mixed oligopolies. To the best of our knowledge, indeed, such a literature deals with the role of a public firm in altering the equilibrium of an otherwise fully profit-oriented oligopoly. Under different specifications of the oligopolistic game, this debate has improved our understanding of how the policy maker may undertake welfare-improving strategies, for instance by nationalising or privatising firms in an industry.Footnote 3 However, we believe that the public authority may successfully enhance social welfare without playing directly as a producer inside the market, but simply by (credibly) threatening of doing it. Within a model of differentiated oligopoly, we actually show that collusion may be deterred by the threat of nationalising a private company and the appropriate choice of the weight given to private profit in the nationalised firm’s objective function. We characterise the relevant features of such a threat and show that it may be able to credibly deter collusion among private firms. The remainder of the paper is organised as follows. Section 2 presents the model. Section 3 illustrates the different scenarios emerging under competitive or collusive behaviour. The strategy of the policy maker to prevent collusion is presented in Section 4, whereas the consequences of the nationalization threat on private and public incentives are examined in Section 5. Section 6 concludes.",5
16.0,2.0,"Journal of Industry, Competition and Trade",13 August 2015,https://link.springer.com/article/10.1007/s10842-015-0201-0,"Competition and Environmental Policy in the EU: Old Foes, New Friends?",June 2016,Jesper Fredborg Hurić-Larsen,Angela Münch,,Male,Female,Unknown,Mix,,
16.0,2.0,"Journal of Industry, Competition and Trade",23 November 2015,https://link.springer.com/article/10.1007/s10842-015-0208-6,Peer Pressure in Voluntary Environmental Programs: a Case of the Bag Rewards Program,June 2016,Jingze Jiang,,,Unknown,Unknown,Unknown,Unknown,,
16.0,2.0,"Journal of Industry, Competition and Trade",29 December 2015,https://link.springer.com/article/10.1007/s10842-015-0213-9,Environmental Certification and Technical Efficiency: A Study of Manufacturing Firms in India,June 2016,Santosh Kumar Sahu,K. Narayanan,,,Unknown,Unknown,Mix,,
16.0,2.0,"Journal of Industry, Competition and Trade",12 October 2015,https://link.springer.com/article/10.1007/s10842-015-0205-9,Bilateral Trade under Environmental Pressure: Balanced Growth,June 2016,Feng Dai,Songtao Wu,Zifu Qin,,Unknown,Unknown,Mix,,
16.0,2.0,"Journal of Industry, Competition and Trade",19 November 2015,https://link.springer.com/article/10.1007/s10842-015-0210-z,European Wines Exports Towards Emerging Markets. The Role of Geographical Identity,June 2016,Mariarosaria Agostino,Francesco Trivieri,,Unknown,Male,Unknown,Male,"When the characteristics of an agricultural product are determined by the interaction between geographical factors and human local expertise, and hence are not replicable elsewhere, it is possible to refer to the concept of geographical identity, or geographical indication (GI) of that product. Since 1992, the European Union (EU) has adopted a system of protection of designations of origin (PDO) and geographical indications (PGI) to protect the collective reputation of local producers that comply with specific rules of cultivations (Schamel 2000; Winfree and McCluskey 2005). The rationale underlying this kind of institutional intervention is benefiting both consumers and producers of traditional and regional agricultural products. Indeed, by alleviating asymmetric information problems and safeguarding from the deception of not authentic products, geographical indications may shelter producers from price competition thereby ensuring higher prices. Besides, as a consequence, rural communities could adopt less intensive agricultural approaches and extract rents respecting local traditions and the natural vocations of their territory. The reform of the common market organisation for wine, originated with Regulation 1234/ 2007, has extended to the wine sector the PDO and PGI categorizations. Thus, since 2009 the PDO (or PGI) logo can be added to the national designations on the label. More precisely, the PDO mark can be displayed by quality wines produced in specified regions (QWPSR), while the PGI label can be added to wines with geographical indication.Footnote 1
 Using Eurostat data on bilateral exports of wine originating from France, Italy and Spain in the period 2010–2013, our work aims to provide empirical evidence on the economic influence of geographical identity in international markets. In particular, we investigate whether there exists a pay-off in terms of greater export values and greater export quantities associated to the PDO and PGI institutional labels, in emerging export markets. Our work builds on the analysis of Agostino and Trivieri (2014), the two papers sharing methodological approach and interest in the relationship between wine exports and geographical identity. Nevertheless, whilst Agostino and Trivieri (2014) represents the first broad analysis on the issue, covering a time span (1995–2009) during which the relevance of BRICS economies as importers of wines is still limited, the present study focuses on the BRICS quintet in a more recent period, when emerging countries have started absorbing non trivial shares of PDO and PGI exports. A great challenge ahead wine producers is trying to expand their exports to new destinations areas, employing appropriate strategies to conquer consumers that may be not acquainted to the wine culture (Belletti et al. 2007). A key to open new markets may be represented by superior quality and unique characteristics. The PDO and PGI labels may be regarded as a certification of quality, differentiating the product in the consumers’ taste and eye. Indeed, only wines complying with requirements aimed at ensuring specific characteristics are allowed to exhibit the geographical identity labels, hence these labels should convey to consumers the signal of higher quality standards. Since we cannot disentangle the quality effect from the label effect, the expected pay-off in terms of higher prices and/or volumes may be driven by both an intrinsic higher quality and a perceived superior quality, thanks to the reduction of asymmetric information problems. Furthermore, before 2010, the combined nomenclature allows only to distinguish QWPSR from all other table wines, without discerning table wines with geographical indication. Hence, the finer distinction between PDO and PGI wines is another novelty of the present study. To investigate both the quantity and the price effect of geographical identity, we adopt a gravity model where wine exports flows are either expressed in terms of values or quantities. As far as the econometric method is concerned, we adopt the BVOLS (Bonus Vetus OLS) estimator, suggested by Baier and Bergstrand (2009), to make gravity equations consistent to the Anderson and Van Wincoop’s (2003, 2004) theoretical model. According to our evidence, the PDO labelling appears associated to surpluses in terms of values and quantities. Further, since the value premium is always much higher than the quantity one, PDO greater exports values seem driven by higher prices, especially in the French case.",13
16.0,2.0,"Journal of Industry, Competition and Trade",03 December 2015,https://link.springer.com/article/10.1007/s10842-015-0206-8,R&D Policy Involving Consumer-Friendly Strategy: Cooperative and Non-Cooperative R&D,June 2016,Ya-Chin Wang,,,Unknown,Unknown,Unknown,Unknown,,
16.0,3.0,"Journal of Industry, Competition and Trade",30 January 2016,https://link.springer.com/article/10.1007/s10842-015-0214-8,Optimal Substantive Standards for Competition Authorities,September 2016,Yannis Katsoulacos,Eleni Metsiou,David Ulph,Male,Female,Male,Mix,,
16.0,3.0,"Journal of Industry, Competition and Trade",22 February 2016,https://link.springer.com/article/10.1007/s10842-016-0218-z,Competition and Corporate Control in Partial Ownership Acquisitions,September 2016,Torben Stühmeier,,,Male,Unknown,Unknown,Male,"Recent partial ownership acquisitions have led competition agencies to take a closer look at the effects of such acquisitions. For example, in 2006, the British Sky Broadcasting Group (BSkyB) announced the acquisition of 17.9 % of ITV. The UK Competition Commission concluded that such acquisition would lessen competition considerably, and ordered BSkyB to reduce its shareholding to below 7.5 %. Comparably, in 2010, the UK competition authority was re-opening a merger investigation into the acquisition of the minority shareholding of Ryanair in Aer Lingus. It concluded that the shareholding of approximately 30 % would give Ryanair a “material influence” on Aer Lingus’s commercial policy. The authority considered that an effective remedy which would address their concerns would require a partial divestment of the shareholding down to 5 %. These are just two of many examples where competition authorities assessed the effects of partial ownership acquisitions on competition in the markets. Scholars have discussed the extent to which a minority ownership can cause similar negative effects on competition to those associated with mergers. Reynolds and Snapp (1986) and Bresnahan and Salop (1986) first demonstrated that financial interest among competing firms may lead to less vigorous competition. Similarly, O’Brian and Salop (2000) point out that the welfare effects of a partial acquisition may be worse than those of a merger if the acquiring firm obtains control over the pricing decision of the target firm. The key to their result is that when the acquiring firm has only a small financial interest in the acquired firm, it benefits from reduced competition when the acquired firm charges high prices. Hence, merger regulations are typically not applied exclusively to mergers, but also to so-called “concentrations.” These arise where there is a change in control of a target firm on a lasting basis, for example, because of a merger or where one or more undertakings acquire control over the whole or part of a previously independent firm. By Article 3(2) of the EU Merger Regulation, control is defined as the possibility of exercising decisive influence on an undertaking and can be acquired through purchase of securities or assets or by rights, contracts, or any other means. There is no prescribed minimum level of shareholding above which minority shareholding acquisitions will necessarily be prohibited. It is a question of law and fact in each case.Footnote 1
 Theoretically and empirically, it is moreover still not well understood when exactly firms prefer partial acquisitions to mergers. Ouimet (2013) reports merger and acquisitions data of US public firms from 1994 to 2006. The study documents that minority acquisitions, that is, acquisitions of less than 50 % of the target firm, involve a transfer with a mean purchase of 12 %, whereas most majority acquisitions (of more than 50 %) involve an ownership stake of 90 % and more. Ouimet (2013) reports that minority acquisitions are more common when, for instance, keeping target managerial incentives intact is important. Majority acquisitions are more likely in acquisitions of the same industry. In the merger literature, it is usually assumed that it is jointly beneficial for firms to merge. Whereas in most of the economic literature, the ownership structure is assumed to be exogenous, Foros et al. (2011) allow the acquiring firm and the target firm to decide endogenously on their preferred ownership stake. In a spatial model similar to Salop (1979) with three firms, they find that both firms have a joint interest in a partial acquisition rather than in a merger. The main reason for their result is the favorable reaction of the independent firm. The present paper complements their analysis and shows that this conclusion is sensitive to the intensity of competition in the market. In a Salop setup with four or more firms, the present analysis shows that firms prefer a merger to a partial acquisition, because both neighbors to the entity respond differently to the acquisition. In an alternative product differentiation model, it is shown that firms prefer a merger if product differentiation is high. Otherwise, if products are close substitutes, they prefer a partial acquisition. The reason for this result is that firms balance two effects. They benefit from reduced competition under partial acquisition, otherwise, they are best off internalizing the externality of pricing under a merger. The preferred ownership stake also depends on the internal governance structure of the firms, because the acquiring firm and the target firm individually, have different preferences as to the best strategy. For the target firm, it pays to give some control to the acquiring firm, such that it internalizes the externality of its pricing decision with respect to the target firm. From a joint profit perspective, it turns out that the acquiring firm should exert full corporate control over the target. Conclusions with respect to welfare thus both depend on the financial interest and on the level of corporate control. We conclude that a divesture of control more effectively addresses the concerns of competition policy than a divesture of financial assets. The paper is organized as follows. Section 2 provides the base model and Section 3 allows for endogenous corporate control. Section 4 confirms the main results in a different product differentiation model. Finally, Section 5 discusses and concludes.",7
16.0,3.0,"Journal of Industry, Competition and Trade",08 March 2016,https://link.springer.com/article/10.1007/s10842-016-0223-2,Competition between Vertically Differentiated Platforms,September 2016,Yusuke Zennyo,,,Male,Unknown,Unknown,Male,"In the hardware/software systems industry, in which various platforms produce hardware devices and independent programmers develop software for these devices, we can easily discern a quality gap between platforms (e.g., Sony’s PlayStation 3 vs. Nintendo’s Wii; Apple’s iPad vs. Amazon’s Kindle). Conventional wisdom argues that firms choose these different qualities to avoid fierce price competition (Mussa and Rosen 1978; Gabszewicz and Thisse 1979). It is well known that higher-quality firms have an advantage in competition, unless higher-quality products require greater costs to produce. For example, Shaked and Sutton (1982) show that a higher-quality firm may be more profitable than its rival when the level of quality does not depend on production costs. Conversely, Wang (2003) suggests that if the variable cost function increases with quality, the higher-quality firm does not necessarily enjoy greater profit than its lower-quality rival. The failure of higher-quality firms occurs frequently in two-sided hardware/software systems markets. The purpose of this paper is to better understand the relationship between platform quality and profitability in such markets. In the two-sided markets literature, most studies assume symmetric equilibrium pricing (Rochet and Tirole 2003; Armstrong 2006). Recently, several papers have employed an asymmetric approach, including vertical differentiation. Gabszewicz and Wauthy (2014) assume that consumers differ in their valuation of the indirect network externalities, and show that platform competition induces a vertical differentiation structure, despite the fact that the ex ante settings of their model are symmetric. Belleflamme and Peitz (2010) consider that the sellers’ investment raises their net gains from trade. These two papers regard platform quality as an extension of indirect network externalities. As an alternative, Lin et al. (2011) focus on product qualities and investigate how this affects optimal pricing strategies. However, product qualities are determined by the sellers who adopt the platform. In addition, unlike this analysis, they assume that the utility of consumers does not depend on the number of sellers. We assume that consumers benefit from the large variety of software developers (indirect network externalities). Njoroge et al. (2013) is relevant to the present paper because they argue that platform suppliers choose the qualities of their devices. They show that investment in platform quality increases the profits of software developers. However, they did not assume that the software development costs increase with hardware quality. In hardware/software systems industries, high-quality hardware devices tend to increase software development costs (Corts and Lederman 2009). Thus, we consider the competition between vertically differentiated platforms in a situation where software development costs increase with hardware quality. This paper also relates to the literature on two-sided pricing theory, in which many existing studies examine the pricing mechanism (Armstrong 2006; Weyl 2010). In the hardware/software systems industry, royalty fees are more common than lump-sum fees as the prevailing fee structure for software developers. Most empirical (Corts and Lederman 2009; Dubé et al. 2010) and theoretical (Hagiu 2006, 2009) studies assume this type of fee structure. In addition, we consider a sequential-move game in which software developers decide upon their chosen platform before users as in Hagiu (2006). For example, in the video game industry, because consumers usually decide whether or not to purchase a hardware device after they have observed the variety of software available for that device, software is developed before hardware devices are introduced. As it takes considerable time to develop the software, it is natural to assume that platforms offer contracts, which include the royalty rates (for software developers), before setting their hardware prices (for consumers). In this paper, after analyzing a model that includes these real-world examples, we derive the following two results. First, we demonstrate that, in a sequential-move game, platforms select the same royalty rate in equilibrium, even with quality asymmetries across the hardware devices. The intuition is as follows. If a given platform selects a higher royalty rate than its rival, it may reduce the variety of software developed, which will then decrease its advantage in the final stage (where it determines the price for the device). Therefore, both platforms have no incentive to set a higher royalty rate and therefore both will choose the same royalty rate. In the video game industry, software developers are charged about $7–8 as a royalty fee by Nintendo, Sony, or Microsoft. Therefore, we can claim that the platforms with different qualities actually select the same royalty rate because there is little difference in the price of the game titles across these video game console manufacturers. This paper contributes to the literature by providing a theoretical mechanism to explain such a real-world phenomenon. Second, we show the potential higher profitability of the lower-quality platform under a parameter range in which the extent of the indirect network externalities is relatively large compared with the quality of the hardware device. The intuition is as follows. A high-quality hardware device tends to decrease the range of software developed for the device. However, given indirect network externalities, consumers prefer a platform with a large variety of software. Therefore, when the advantage of software variety dominates the disadvantage of low hardware quality, the lower-quality platform has the opportunity to enjoy greater profit than does its higher-quality rival. In fact, Sony introduced a very high-quality video game console, PlayStation 3, which imposes high costs on game developers in developing game titles. Thus, Sony has been in a desperate battle with its rival firm, Nintendo, because of a lack of launched titles. This paper contributes to the literature by proving the existence of an equilibrium in which, in the two-sided hardware/software system markets, the profit of a higher-quality platform falls below the profit of a lower-quality rival. The remainder of the paper is organized as follows. Section 2 introduces the model. Section 3 characterizes the equilibrium of this model. Section 4 provides a profit comparison between higher- and lower-quality platforms. Section 5 discusses the robustness of one of our key assumptions. Section 6 concludes.",5
16.0,3.0,"Journal of Industry, Competition and Trade",11 April 2016,https://link.springer.com/article/10.1007/s10842-016-0224-1,Pricing Decisions in Dual-Channel Supply Chain Including Monopolistic Manufacturer and Duopolistic Retailers: A Game-Theoretic Approach,September 2016,Hamed Jafari,Seyed Reza Hejazi,Morteza Rasti-Barzoki,Male,Male,Male,Male,"Recently, the Internet has revolutionized not only customers’ purchasing patterns, but manufacturers’ selling models (Hsieh et al. 2014). Commerce on the Internet (e-commerce) has become increasingly attractive to more manufacturers and customers (Davila et al. 2003). This rise in the Internet-based sales has provided a strong incentive for manufacturers to redesign their traditional selling channel structures and start selling directly in order to reach customers who cannot be reached by traditional retail channels (Hua et al. 2010). It is reported that about 42 % of top manufacturers like Dell, Pioneer Electronics, IBM, and Nike employ the Internet-based channels to sell their products (Tsay and Agrawal 2004). Dual-channel supply chain is one in which a manufacturer sells his products to consumers both through a retailer (hereafter referred to as “retail channel”) and directly online (hereafter referred to as “direct channel”). Thus, the dual-channel has a twofold structure. On the one hand, the manufacturer should design a competitive direct channel comprising pricing decisions to compete with the retail channel (Tsay and Agrawal 2004). On the other hand, in a dual-channel supply chain, both the manufacturer and retailer sell the same product. Therefore, customers have alternatives to select the channel that satisfies their shopping requirements, mostly (Takahashi et al. 2011). Figure 1 depicts the general structure of a dual-channel supply chain. The general structure of a dual-channel supply chain Game Theory is a mathematical instrument for investigating the complex interactions among interdependent rational competitor players (Huang 2010). Game theory has recently found wide applications in supply chains to obtain the equilibrium strategies in process of buying/selling in stock markets. Below, several studies in area of developing the game-theoretic approach in the dual-channel supply chain are addressed. The need to increase the theoretical understanding of complicated interdependent relationships in pricing strategies has motivated a great deal of research (e.g., see: Feuerstein 2005; Andree 2013; Böhme and Müller 2013; Cunha and Vasconcelos 2014; Cunha and Sarmento 2014; Witte and Williams 2014; Sen 2015; Nakamura 2015). We address several studies that develop the game-theoretic models in the dual-channel supply chain. Pricing is one of the most vital decisions in supply chains (Mankiw 2014). Yao and Liu (2005) considered price competition between the direct and the retail channels under different game theoretical models: Bertrand and Stackelberg. In Bertrand competition, the manufacturer and retailer simultaneously select e-tail and retail price, respectively, while in Stackelberg competition, the manufacturer as a leader selects the e-tail price, and then the retailer selects the retail price. Xiong et al. (2012) studied a problem in which a manufacturer sells a durable product. They established two Stackelberg models. In the first model, the manufacturer acts as the leader and the retailer is the follower while, in the second one, the retailer is the leader and the manufacturer performs as the follower. Moreover, Hua et al. (2010) examined optimal prices in a centralized and a decentralized (i.e., manufacturer-Stackelberg) dual-channel supply chain to respectively maximize profits of the whole system and members. They analyzed the impacts of customer acceptance of a direct channel on the manufacturer’s and retailer’s pricing behaviors. Dai et al. (2005) analyzed pricing strategies when demands in the retail channel are deterministic as well as stochastic. Huang et al. (2012) and (2013) developed a pricing model when production costs are disrupted, while Liu et al. (2010), Cao et al. (2013) and Mukhopadhyay et al. (2008) investigated the impact of asymmetric cost information on the equilibrium prices. Chen et al. (2013) investigated pricing policies in a supply chain in which the retailer sells a substitute product produced by another manufacturer in addition to the manufacturer’s product. Moreover, Hsieh et al. (2014) considered multiple manufacturers and a common retailer facing uncertain demand. Manufacturers produce substitutable products and sell their products through the common retailer, and a portion of the manufacturers sell their products through the direct channels in addition to the retail channel. To our knowledge, the game-theoretic models developed in the dual-channel structure have considered a single retailer in the retail channel (as stated in above paragraphs), whereas in some practical structures, duopolistic or oligopolistic retailers can exist in the retail channel. The aim of the current study is to analyze pricing and ordering decisions in a dual-channel supply chain including monopolistic manufacturer and duopolistic retailers. The manufacturer controls the market. Thus, the manufacturer is assumed to be leader and the two retailers to act as followers. Moreover, due to establishing this new structure, different game-theoretic models including Bertrand, Collusion, and Stackelberg are developed to investigate pricing strategies based on the various interactions between the two retailers. The remainder of this paper is organized as follows: Section 2 provides a detailed description of the research problem. The equilibrium pricing strategies are obtained under various game-theoretic models in Section 3. Section 4 deals with the comparisons of the equilibrium decisions given by the game models. In Section 5, a numerical example is provided to illustrate the research problem. The effects of parametric changes on the equilibrium decisions are investigated in Section 6, and conclusions are presented in Section 7. Finally, the proofs of lemmas and theorems appear in the appendices.",24
16.0,3.0,"Journal of Industry, Competition and Trade",15 June 2016,https://link.springer.com/article/10.1007/s10842-016-0227-y,The Coordinated Effect of a Merger with Balanced Sharing of Collusive Profits,September 2016,Pierluigi Sabbatini,,,Male,Unknown,Unknown,Male,"In order to place the assessment of the coordinated effect of a merger in its appropriate framework, keeping into consideration the real attitude of coordinating firms, we start by providing a general discussion on their attitude regarding how they split collusive gains. Distributive issues have not generally attracted the attention they deserve, as is conclusively demonstrated by the considerable credit still enjoyed by Joint Profit Maximization (JPM) as a collusive goal. Ever since the article of Patinkin (1947), this has been the most common assumption in the literature on cartels. Seemingly intuitive, this framework is not actually very plausible. As Bain observed in a prompt comment to Patinkin’s article (Bain 1948), “perfect collusion” (that is, joint profit maximization) is not an option where firms have different costs.Footnote 12 The reason is simple: when products are homogeneous but costs are different, joint profit maximization generates an unequal distribution of collusive earnings. For example, with constant return to scale, strict adherence to joint maximization implies that only the most efficient firm will survive. For this reason, Bain reaches the conclusion that sub-optimal collusive agreements, which he does not specify, are more plausible. With reference to the oil cartel Bain observed (p. 621): 
Conservationists [that is those people who want to preserve oil reserves] wish to determine individual quotas according to engineering considerations, so as to maximize the yield from an entire pool. But considerations of “equity” – i.e. the assumed right of each firm to produce and sell an “equitable” share of the output drawn from the common pool – dominate the allocation. So long as each firm is left dependent for earnings on its own output [i.e. there are no side payments], as it is in absence of “unitization”, output allocation must be dominated by “equity” and pay only secondary heed to considerations of conservation and of aggregate costs.
 The case examined by Bain refers only to homogeneous products, but the logic of the argument is more general and extends to collusion with differentiated products. The empirical literature on cartels reminds us that colluders pay attention to the stability of market shares,Footnote 13 a fact which clearly contrasts with joint profit maximization, except in the unlikely event of perfect symmetry. Parallel price increases, another recurrent element in past episodes of collusion, are also at odds with the JPM hypothesis, again, with heterogeneity in costs or demands.Footnote 14
 In the literature on collusion the reconciliation between JPM and profit redistribution rests on the presence of side payments like: 1) penalties to those firms more advantaged by the concrete enforcement of the collusive mechanism; 2) buy-backs of products; 3) litigations among colluders which mask money transfers. Not surprisingly, Bain reaches its conclusion having excluded the presence of side payments. However, the recourse to side payments has been considered unlikely because of the risk of antitrust intervention. Notice that, apart from this, there is a more basic reason why side payments do not seem to be an option in order to countervail the asymmetric effect of a perfect collusive scheme. Firms do not want to be dependent on the benevolence of competitors (Friedman 1977, p.29). In particular, it is hard to imagine that a firm would adhere to a collusive mechanism that (if joint profit maximization shrank its market share) would leave it in a weak position should the cartel collapse. On the basis of records of discovered cartels, it must be stressed that side payments generally play a residual role.Footnote 15 The empirical literature shows quite consistently that cartel meetings are called for fixing prices and market shares. Side payments enter the scene only if market shares do not comply with the original plan, so as to serve a correcting purpose. Furthermore, whatever this role may be, it is conceivable only in cases of auvert cartels. When collusion is tacit, by definition, there is no room for side payments, as cooperation can only be based on price signals. In conclusion, it seems rather uncontroversial that firms, when colluding, pay also attention to the way in which extra gains are shared, accomplishing this task by fixing an appropriate price structure and by applying a mutual satisfactory allocation of market shares. In the case of explicit collusion, firms employ a variety of instruments to reach an agreement. In the case of tacit collusion, the level and distribution of collusive profits must be obtained only through a process of price signals. That is, in assessing the coordinated effect of a merger, which has to be traced back to tacit collusion, we are in a world where prices achieve two tasks (level and distribution of profits) and are generally unable to lead to the maximization of joint profits, except in very exceptional circumstances. This conclusion is still inadequate for the assessment of the coordinated effect of a merger, because it is silent regarding the mechanism (based on a sequence of prices) which guarantees an acceptable division of spoils among colluders. We do not expect a wholly egalitarian solution, as the distribution of gains clearly depends on the market power of each firm. But also powerful firms must keep into consideration the needs of smaller operators as long as they want them to join the cartel: in short, there is a limit to very uneven distributions of collusive gains. On the basis of similar considerations, some authors,Footnote 16 when dealing with collusion, opted for more balanced mechanisms (compared to JPM), the most frequently used being the Nash Bargaining equilibrium (NB) for cooperative games. It is located in an intermediary point, on the Pareto Frontier, between where total utility is maximized and the egalitarian solution that evenly shares gains from negotiation (Mas-Colell et al. 1995, pp.842–843). Another equilibrium, which shares the same attitude for relatively balanced collusive outcomes, is the Balanced Temptation Equilibrium” (BTE) (Friedman 1971, 1977, 1983) which is the point, on the Pareto frontier, in which all firms’ incentives to deviate (that is, all their critical discount factors; see below) are equal. The ratio of gains from cheating to losses seems a natural way to incorporate all the relevant elements that colluding firms take into account: it transforms the inevitable differences among competitors into a single, equal common reference, and appears an attractive solution to explain a distribution of collusive gains which embodies a balancing principle. In proposing this equilibrium Friedman noted: “One way to view the property is that it is characterised by all players having
the same
‘
break even
’
discount parameter
. (…) Another, equivalent, property is that
the ratio of the one-period gain to the per-period loss is the same for all players” (Friedman, 1977,p.180-181).
 “Where the temptation to deviate is, in a sense, equalized among firms, [it ] might be a natural outcome that the firm could think of and implement without communication …, a candidate for tacit collusion” (Friedman
1983, p. 132).
 Although NB/BTE nicely comply with the balancing attitude of colluders, in tune with facts and bargaining models,Footnote 17 they do not seem perfectly suitable for analyzing collusion because of their common assumption regarding the localization of the equilibrium only on the Pareto Frontier. We wonder whether this condition is justified, as, for example, all price combinations that lead to equal incentives to deviate would appear to be likely candidates to be the outcome of tacit collusion (even if located below that frontier). Therefore, we need a method to identify the set of such possible combinations and to point out those conditions (and indicators to reveal them) that enable firms to increase their collusive profits in a “balanced” way. These conditions refer to product and cost characteristics and, what is crucial for our argument, to market structure. By modifying the market structure, a merger can realign incentives and make it possible to increase total profits while respecting the balancing-share rule. A coordinated effect arises whenever this effect is substantial. “Collusion of firms can take many forms”.Footnote 18 The approach we are going to illustrate is suitable for environments where all firms have enough spare capacity and are reasonably informed on demand conditions. Therefore, each firm supplies as many products as market demands, according to preferences of consumers, prices and product characteristics. Furthermore, no firm has such superior information as to enjoy a competitive advantage when interpreting demand shocks. In this environment also small competitors can be, and often are, in the best position to constrain the formation of a cartel. Not surprising it will be shown that the practical consequences of our analysis are consonant with the maverick firm narrative. We do not claim that this is the only possible environment and neither the most widespread. Records of explicit collusion show that differences in production capability or asymmetric information are often crucial elements in conditioning the bargaining position of firms also in view of establishing the terms of a cooperative conduct.Footnote 19 In these circumstances the so called “leadership model” might be in a better position for assessing the collusive impact of a merger so as to reveal a coordinated effect which results from the strengthening of the market leader. It should be noted, in passing, that in these cases the assessment of unilateral and coordinated effects of a merger should lead to the same prescriptions (although not to the same effect evaluations). It is precisely for this reason that the emphasis on the coordinated effect, which was so popular in the second half of the last century when also the “leadership model” gained acceptance, has then migrated towards the unilateral effect without appreciable discontinuities in the choice of indicators (e.g. HHI) to be considered in the analysis.",4
16.0,3.0,"Journal of Industry, Competition and Trade",16 April 2016,https://link.springer.com/article/10.1007/s10842-016-0225-0,Empirical Analysis of the Assessment of Innovation Effects in U.S. Merger Cases,September 2016,Benjamin R. Kern,Ralf Dewenter,Wolfgang Kerber,Male,Male,Male,Male,"Despite the consensus that competition policy should also protect innovation competition, it is still very unclear whether and how competition authorities should take innovation effects into account. This is particularly true for merger policy, where the growing emphasis on case-specific economic analysis has led to a greater focus on the assessment of short-term price effects of mergers, whereas the potentially negative effects on consumer welfare through less innovation are in danger of being ignored. This asymmetry can also be seen very clearly in the Horizontal Merger Guidelines both of the EU and the U.S., in which innovation effects of mergers play only a small role (EU Commission 2004; DOJ/FTC 2010). One important reason is the uncertainty of competition authorities about how innovation effects of mergers can and should be assessed (for an overview about the discussion see Katz and Shelanski 2007). However a crucial part of the problem is the conceptual issue whether the traditional approach of defining product markets and analyzing the anticompetitive effects of a merger on these markets is also suitable for assessing innovation effects of mergers or whether a more innovation-specific assessment approach should be used? In the U.S., this question led to the development of the Innovation Market Analysis (IMA) as a new approach for the assessment of innovation effects in antitrust law in the mid 1990s (Gilbert and Sunshine 1995). The problems with the traditional product market approach are, firstly, that the competitors in regard to the innovation of new products might not be identical with the competitors in a traditional product market, as some incumbent firms might not innovate or also non-incumbent firms might take part in innovation competition. Secondly, market shares and concentration levels on product markets might not be good indicators for assessing the effectiveness of innovation competition. Therefore, the basic idea of the innovation market analysis focuses on a direct identification of the relevant innovation competitors by asking for the firms that have the necessary resources for innovation (in form of specialized assets), leading to so-called innovation markets. Subsequently, it is asked whether a merger would lead to negative effects on innovation (with the possibility of balancing anticompetitive effects with efficiency effects). This new approach of the innovation market analysis had been criticized vigorously from its beginning. The major points of criticism were that a new concept is not necessary (claiming that the traditional concepts are sufficient) and that such an analysis is unfeasible, given our limited knowledge about the innovation effects of mergers.Footnote 1 Nevertheless, and despite this critique, the innovation market analysis appears to have influenced considerably U.S. antitrust policy. One important application was the explicit inclusion of the concept of innovation markets in the “Antitrust Guidelines for the Licensing of Intellectual Property” in 1995 (DOJ/FTC 1995). At the same time, a considerable increase of concerns in regard to innovation effects in the merger reviews of U.S. antitrust authorities can be observed (Gilbert 2008a). Later, however, the support for the innovation market analysis in the academic discussion has waned dramatically. This has become evident in the discussion about the reform of the U.S. Horizontal Merger Guidelines (DOJ/FTC 2010) with its mixture of broad support for assessing innovation effects in merger analysis but its rejection of recommending the innovation market analysis.Footnote 2
 The objective of our paper is an empirical analysis investigating to what extent and how the U.S. antitrust authorities, i.e. the Federal Trade Commission (FTC) and the Department of Justice (DOJ), took account of innovation effects in their assessments of mergers. Although the EU merger policy also considered innovation effects to some extent, the U.S. experiences are much richer and more interesting, because the innovation market discussion allowed for a more explicit experimentation with new assessment approaches. In our empirical analysis, we have examined all 399 mergers that were challenged by the FTC and DOJ between 1995 and 2008.Footnote 3 Our sources are the “complaints” of FTC and DOJ. By analyzing all 399 complaints in these cases, we could identify a sub-sample of 135 merger cases, in which innovation concerns have been mentioned explicitly (FTC: 91, DOJ: 44). Therefore, in the U.S., a large number of relevant cases exists. In addition to that, the innovation concerns of the agencies also led to a considerable number of innovation-related settlements with structural remedies. These settlements required the merging firms to far-reaching divestitures, especially in regard to parallel R&D projects, which had to be sold to competing firms in order to maintain innovation competition (for an overview see, e.g., Carrier 2008). Although there is considerable literature on merger cases with respect to innovation aspects that analyze cases in a qualitative way,Footnote 4 only Gilbert (2008a) has so far analyzed cases also quantitatively. To the best of our knowledge, our study is the first econometric analysis on how the U.S. merger policy assessed innovation effects of mergers. In comparison to Gilbert (2008a), our study encompasses more cases due to a longer investigation period (1995–2008) but also focuses not only on the question to what extent but also how the U.S. agencies assessed innovation effects of mergers. Additionally, we also ask whether the two agencies FTC and DOJ used the same or different assessment approaches in regard to innovation effects of mergers, and whether we can observe developments during our investigation period 1995–2008 in regard to these assessments.Footnote 5
 Therefore our empirical study can also contribute to the ongoing discussion about dual antitrust enforcement in the U.S., albeit only in regard to the assessment of innovation effects of mergers. First, there have always been concerns about differences in the antitrust enforcement between FTC and DOJ, which might lead to different outcomes depending on the agency reviewing a merger. Reasons for possible differences can be that both agencies review mergers in different industries, the different procedural rules for antitrust adjudication, and the different institutional design of the agencies (FTC as an independent antitrust agency and the Antitrust Division of the DOJ as part of the Administration). Since our study also looks at two different sub-periods, it will also shed some light on the discussion about increasing convergence or divergence of the antitrust enforcement of both agencies.Footnote 6 Secondly, there is also a direct link to the controversial discussion triggered by Baker and Shapiro (2008), whether there was under-enforcement in mergers during the Bush Administration compared to the Clinton Administration. Although we have chosen to define our two periods 1995–2003 and 2004–2008 according to other criteria and they hence do not coincide directly with the periods of both Administrations, we will see that the empirical results about changes between our sub-periods do not offer new evidence for supporting the thesis of Baker and Shapiro (2008).Footnote 7 Since we also look at the extent that agencies offer clear theoretical reasonings about alleged innovation effects and the consistency of their reasonings, this study also contributes to a third discussion about dual antitrust enforcement in the U.S., namely the problem of the quality of enforcement (transparency, accountability etc.).Footnote 8
 The first part of our empirical study (in section 2) focuses on the extent the antitrust agencies took innovation concerns into account. How important were innovation concerns? Under what circumstances did the agencies assess a merger also in regard to innovation effects? Were there differences between the agencies? Our results will show that in a third of all challenged merger cases the agencies also raised innovation concerns, and in this regard we also could not find significant differences between the agencies or a change during the entire period. In the following sections 3 and 4, we examine how the FTC and the DOJ assessed innovation effects in particular. This analysis takes place on the level of markets. Section 3 addresses the crucial question whether the agencies try to assess innovation effects more within the traditional approach of defining product markets, and only investigate negative effects on innovation in the ensuing competitive assessment, or whether they use a newer, more innovation-specific approach, which already considers innovation in the market definition. We will see that in a large number of markets, innovation was explicitly taken into account already in the market definition, and not only in the competitive assessment analysis. Our results will also show that both assessment approaches were used by both agencies, however, to a significantly different extent. It is particularly interesting that the FTC used more an innovation-specific approach than the DOJ in regard to market definition, whereas the DOJ stuck more to the traditional product market approach. The last part of our empirical study (in section 4) analyzes the theoretical reasoning the agencies gave why the mergers might have negative effects on innovation. We investigate not only what kind of theoretical reasoning have been mentioned, but also to what extent the agencies provided specific arguments at all. Although increasingly innovation incentive arguments were used, the results will show that in more than 50 % of all assessed markets the agencies gave no specific reasons for their alleged innovation concerns (particularly the FTC). The agencies also increasingly claimed static price effects in those markets, in which they had innovation concerns. Our concluding section 5 will discuss the results of all three parts of the empirical study.",4
16.0,4.0,"Journal of Industry, Competition and Trade",29 February 2016,https://link.springer.com/article/10.1007/s10842-016-0220-5,How Does FDI Affect Productivity at Home?: Evidence from a Plant-Level Analysis,December 2016,Kazunobu Hayakawa,Toshiyuki Matsuura,Kazuyuki Motohashi,Male,Male,Male,Male,"The effect of multinational enterprises’ (MNEs) foreign direct investments (FDI) on their performance at home has received considerable attention in recent years. In particular, the expansion of MNEs’ production activities in developing countries has contributed to the closure of their domestic plants in developed countries. In turn, this expansion has incited anxiety about the “hollowing out” of domestic industries in developed countries. On the one hand, the relocation of production has forced MNEs to concentrate their domestic activities on specific production processes, such as upstream processes, and to shut down activities engaged in processes shifted abroad. On the other hand, the potential improvements in firm performance and productivity at home resulting from outward FDI must be weighed against concerns such as “hollowing out.” For example, the active vertical division of labor with Japanese affiliates in China has resulted in a rapid increase in Japanese exports to China. Against this backdrop, a substantial body of empirical literature has examined the effect of FDI on firm performance—particularly productivity—at home, which is known as the learning effect of FDI. Examples of studies in this field include those by Navaretti and Castellani (2004), Castellani et al. (2008), and Imbriani et al. (2011) for Italian MNEs; Hijzen et al. (2011) for French MNEs; Navaretti et al. (2010) for French and Italian MNEs; Kleinert and Toubal (2007) for German MNEs; Ito (2015), Hijzen et al. (2007), and Edamura et al. (2011) for Japanese MNEs; Debaere et al. (2010) for Korean MNEs; and Masso et al. (2008) for Estonian MNEs. The econometric identification of the learning effect is one of the most important issues in this literature. As theoretically demonstrated by Helpman et al. (2004), FDI also has a selection effect: only firms with good performance can invest abroad. Therefore, empirically differentiating between the learning and selection effects of FDI is important. The aforementioned studies primarily used the instrumental variable method or the matching method. Studies that used the latter method often employ the propensity score matching method from Rosenbaum and Rubin (1983). However, the results obtained remain inconclusive. For example, Navaretti and Castellani (2004) found significant positive effects, but Hijzen et al. (2007) and Ito (2015) did not. Therefore, more detailed analyses are required to derive meaningful conclusions regarding the effect of MNEs’ FDI on their performance at home. One possible reason for our inability to obtain conclusive results is the qualitative differences between the effects of two types of FDI: horizontal FDI (HFDI) and vertical FDI (VFDI). Whereas HFDI is a strategy for avoiding broadly defined trade costs by setting up plants within the target country rather than exporting from the home country, VFDI is a strategy that exploits low-cost production in the host country.Footnote 1 As illustrated in the next section, the resulting effect of HFDI on productivity at home is ambiguous from a theoretical point of view. The positive effect of HFDI results from the acquisition of advanced knowledge and technology used in producing products in the host country. If this positive effect is greater than the negative effect from the loss of economies of scale, the net effect of HFDI is positive. On the other hand, the effect of VFDI should be positive because of the total cost reduction achieved through the international vertical division of labor. To account for the qualitative difference between HFDI and VFDI, some studies examined performance changes according to FDI type (Debaere et al. 2010; Edamura et al. 2011; Hijzen et al. 2007; Navaretti et al. 2010). Debaere et al. (2010), Edamura et al. (2011), and Navaretti et al. (2010) classified FDI in developing and developed countries as VFDI and HFDI, respectively. Hijzen et al. (2011) defined VFDI as investments in developing countries by firms in industries in which the investing country has a comparative disadvantage and HFDI as investments in developed countries by firms in industries in which the investing country has a comparative advantage. These studies found different effects on firms’ performance in the home country according to FDI type. For example, Edamura et al. (2011), Hijzen et al. (2011), and Navaretti et al. (2010) found a positive significant effect of HFDI on productivity at home but not a significant effect of VFDI. Debaere et al. (2010) did not detect any positive effects on the number of employees from either FDI type. In short, the empirical evidence according to FDI type remains mixed and inconclusive. This paper empirically investigates performance changes according to FDI type at a more-detailed level than in previous studies. An important difference between the two types of FDI is whether investors’ main activity at home changed after the investment abroad. In contrast with HFDI, VFDI changes the main home activity at the firm level, such as a shift from a downstream to an upstream activity. Because such a change implies an alteration in the firms’ home production function per se, evaluating the effect of VFDI at the firm level is qualitatively difficult. In other words, we cannot differentiate performance changes through the learning effect of FDI from those caused by changes in the main activity. In short, firm-level analysis appears too broad when examining performance changes caused by VFDI. The different findings among the aforementioned studies may be the result of their analysis occurring at the firm level. In this paper, instead of firm-level data, we employ plant-level data to examine the effect of Japanese MNEs’ FDI on their performance in Japan. The best type of data for this analysis is activity-level data (downstream or upstream activity). However, performance measures, such as the number of employees or amount of tangible fixed assets, are not usually available at the activity level. Therefore, as the second-best type of data, we employ plant-level data. Suppose that a Japanese MNE has two plants in Japan: an upstream-activity plant and a downstream-activity plant. The MNE relocates the downstream activity from Japan to China. In this example, examining the performance of the upstream activity plant before and after the relocation of the downstream activity enables us to successfully explore the effect of VFDI on performance at home. To highlight the advantages of using plant-level data to measure the productivity effect of FDI, we also conduct a sensitivity analysis by applying the same model to firm-level data. In doing so, we find that the choice of the data unit makes a significant difference in our estimate of the effect of FDI. We investigate the effect of Japanese FDI in the electrical machinery and electronics manufacturing industry by applying the Blundell and Bond System GMM (general method of moments) estimation technique to plant-level data (Blundell and Bond 1998). We focus on this industry because it exhibits the largest outward FDI stock among manufacturing industries in Japan. Furthermore, because of the modularization of products in this industry, its production processes can be more easily fragmented than those of other industries.Footnote 2 As a result, VFDI is more technically possible than in other industries. We distinguish between HFDI and VFDI for each pair of domestic plant and overseas affiliates at the four-digit industry level, similar to the methodology proposed by Alfaro and Charlton (2009). If firms have overseas affiliates that produce the same products as their home plants do, those affiliates are regarded as HFDI. If the production activities of overseas affiliates have an input–output relationship with domestic production activity, we consider such activities VFDI. This identification strategy at a detailed level becomes possible because of the use of plant-level data. The remainder of this paper is organized as follows. The next section theoretically discusses the effects of HFDI and VFDI on productivity at home. Section 3 outlines our empirical methodology used to examine the effects of HFDI and VFDI. Section 4 presents our estimation results. Our empirical results are consistent with our theoretical predictions. HFDI does not necessarily have a significant positive effect on productivity in home plants that become engaged in the same activities as their overseas affiliates. VFDI significantly enhances productivity in home plants that become engaged in an activity with an input–output relationship with the activity relocated abroad. In contrast to this positive effect of VFDI observed through plant-level analysis, our firm-level analysis yields an insignificant effect of VFDI, perhaps because the firm-level estimates include not only performance changes through the learning effect of FDI but also those caused by changes in the main activity. Thus, our analysis proves the importance of the type of data used to examine the effect of FDI on performance at home. Section 5 concludes the study.",1
16.0,4.0,"Journal of Industry, Competition and Trade",22 February 2016,https://link.springer.com/article/10.1007/s10842-016-0217-0,Trade with Endogenous Market Power Under Asymmetric and Incomplete Information,December 2016,Manitra A. Rakotoarisoa,,,Unknown,Unknown,Unknown,Unknown,,
16.0,4.0,"Journal of Industry, Competition and Trade",27 June 2016,https://link.springer.com/article/10.1007/s10842-016-0228-x,Trade Intermediaries and the Tariff Pass-through,December 2016,P. Lelio Iapadre,Giuseppe Pace,,Unknown,Male,Unknown,Male,"Static and dynamic benefits generated by trade liberalization arise mainly from its price effects. A tariff reduction is expected to lower the domestic price of imported goods, inducing a welfare improvement through a better allocation of existing resources and a stimulus to their accumulation. In a simple partial equilibrium model of a small country under perfect competition, any tariff reduction translates into an equal fall of the domestic price of the imported good. In other words, the so-called tariff ‘pass-through elasticity’, defined as the ratio between changes in price and tariff rate, is equal to one (complete pass-through). In the case of a large country, the tariff reduction affects not only the domestic price of the imported good, but also its foreign price. So, even if the wedge created between these two prices is equal to the tariff, the pass-through elasticity is lower than one. Under imperfect competition firms enjoy a certain degree of market power, but trade liberalization brings about a pro-competitive effect, squeezing the mark-up between price and marginal cost. However, at the same time, trade liberalization generates terms-of-trade changes even in small countries, because foreign suppliers find it profitable to use their market power in order to counteract the domestic price effect of the tariff cut. As a result, the tariff pass-through is normally lower than one, in analogy with what observed for the exchange rate pass-through (Feenstra 1995).Footnote 1
 A common assumption in traditional and new models of international trade is that domestic and foreign producers sell their goods directly to final consumers (Feenstra and Hanson 2004). Yet, in the real world, trade is normally made possible through intermediaries that perform all the activities required to match demand and supply, including transportation, wholesale and retail distribution. More generally, intermediaries reduce transaction costs with respect to direct exchange between producers and consumers (Spulber 1999). On the empirical ground, several papers witness the importance of intermediaries in international trade. Morisset (1998) shows that, over the period 1975–94, declines in world commodity prices were imperfectly transmitted to domestic consumer prices, and finds that “the spread between world and domestic prices almost doubled in all major commodity markets during 1975-94” (p. 503). Shepherd (2004), echoing the well-known Oxfam report by Gresser and Tickell (2002), studies market power in the international coffee processing chain, and shows that trade liberalization brought about only limited improvements in price transmission from producer countries to the world market and to consumer countries: “Although liberalisation seems to have delivered on its promise of reduced marketing margins in most producer countries, there is some evidence to suggest that margins have increased on the consumer side” (p. 24). Both these authors argue that one possible explanation for these problems is due to the role of international trading companies that can influence the relationship between world and domestic prices. Their dominant position in most commodity markets enables them to affect the spreads between buyer and seller prices simultaneously in many countries. More recently, Porto et al. (2011) provide ample evidence of the role played by oligopsonist trade intermediaries in agricultural supply chains. McCorriston (2012) studies how vertically related market structures affect commodity and food prices, showing the complementarity between trade and competition policies. Hoekman and Shepherd (2015) address similar questions for the effects of trade facilitation measures. The importance of these issues goes beyond the agricultural sector. The market power of large trade intermediaries such as Wal-Mart, may have affected the price impact of trade liberalization measures as envisaged by the WTO Agreement on Textiles and Clothing (Francois and Wooton 2010). Similarly, Olarreaga and Özden (2005) argue that the tariff rents created by preferential access to the US apparel market under the African Growth and Opportunity Act were captured only in part by foreign exporters, due to the market power of large importing enterprises. This paper aims at improving our understanding of the price effects of trade policies following two perspectives. First, building on the literature about the role of intermediaries in international trade, we wish to study the relationship between the degree of competition in the distribution-service market and the transmission of tariff changes to domestic prices. Second, we explore how our results are affected by the link between trade and competition policies. In section 2, after a brief survey of the related literature, we present our model, which is used in section 3 to show the price effects of a tariff reduction. Section 4 extends the model to consider the effects of competition policies in the distribution-service sector. Section 5 presents the welfare analysis. Section 6 concludes.",
16.0,4.0,"Journal of Industry, Competition and Trade",13 October 2016,https://link.springer.com/article/10.1007/s10842-016-0234-z,Determinants of Trade: the Role of Innovation in Presence of Quality Standards,December 2016,Maria Cipollina,Federica Demaria,Filomena Pietrovito,Female,Female,Female,Female,"The main goal of the paper is an assessment of the trade effects of quality standards, applied by importers in the manufacturing industries, achieved through improvements in the technological level of exporting industries. In particular, we apply a gravity model to examine whether the increase in exports (intensive margin) might be attributed to their ability to deal with increasing standards of product quality through innovation, where quality is widely interpreted to incorporate several features of products. Over time, in a context of tariff reduction/elimination, due to the proliferation of preferential trade policies, the role of non-tariff measures (NTMs) has been increasing. While the positive impact of tariff reduction is by and large confirmed, empirical evidence on the trade effects of NTMs is controversial and a clear prediction on their impact cannot be found. On the one hand, the literature analysing the impact of NTMs on trade argues that facing higher requirements in foreign markets is likely to reduce trade, both in terms of imports and exports (Chen and Mattoo 2004; Moenius 2006). For many traded products, NTMs such as standards, restrictive sanitary and phytosanitary regulations, are an obstacle for the access to foreign markets. Indeed, NTMs are often used to protect the domestic market in place of classical trade policy instruments and they are likely to play a much larger role than tariffs (Bureau et al. 2004; Iimi 2007; Desta 2008; Medvedev 2010; Okumura 2015). Complying with standards is therefore likely to increase costs for exporters because of the investment required, and higher costs may discourage producers to sell their products abroad. On the other hand, the literature on non-price competitiveness and trade states that stricter standard and/or regulation promote the domestic product quality and information on quality may increase the confidence of foreign consumers, thereby fostering exports (Fontagné et al. 2005; Moenius 2004). Innovation is an important factor of the non-price competitiveness of a nation’s products (Buxton et al. 1991) and it takes the form of an expansion of the number of varieties of products or quality improvements for a range of existing kinds of products. Recent advances in international trade show, indeed, a strong impact of innovation activity on export performance (Chen 2013; Garcia Pires 2014). The first strand of the literature predicts that innovation has a positive impact on extensive margin of trade, by introducing new products and varieties that a country exports (Grossman and Helpman 1989).Footnote 1 The second strand stresses, instead, the impact of innovation also on intensive margin of trade by increasing product quality (Grossman and Helpman 1991a, 1991b) or productivity (Eaton and Kortum 2001, 2002) and competitiveness (Siggel 2006). In this article we refer to the literature analysing the effect of innovation on volumes of trade (intensive margin). While the literature on the standards and innovation trade effect (Swann et al. 1996; Blind 2001; Blind and Jungmittag 2005) argues that besides innovations, national technical standards provide additional indicators for the technological potential of a country, in this paper we argue that if producers in an industry aim to export products in presence of importer quality standards, those that innovate are more able to face the complex rules and then gain a competitive advantage in foreign markets. In other words, innovation becomes a key determinant to entry foreign markets that require quality standards and the net effect of standards on trade depends on the producers’ ability to innovate and comply with these requirements. We make the assumption that the greater the number of standards, the higher the quality of products that is required by the importing countries. Thus, the effects on trade are linked to the ability of a single industry in adapting products to the requirements of target markets: exports increase if industries stand out product quality. Although the impact of standards and innovation on export performance has been extensively analysed (and discussed in the Section 2), a further investigation of their interaction is needed. In this respect, the contribution of this paper is threefold. First of all, instead of focusing on country-specific analysis, we construct a large dataset including (i) 60 exporting countries and 57 importing countries, (ii) a wide range of 26 manufacturing industries at the 3 digit ISIC level and (iii) the period 1995–2000. Secondly, our improvement consists in adopting a different source for quality standards, the TradeProd Cepii database, providing data disaggregated by industry for a sample of developed and developing countries. The advantage of using this specific database consists in providing a frequency index for NTMs taking into account for quality control measures. From a methodological point of view, the use of disaggregated data and a specific measure of quality standards lead to a more accurate assessment of policies that often discriminate among products and countries. Thirdly, we include an interaction term between standard and patent counts to explore whether more innovative industries are able to implement the requirements of foreign industries in terms of product quality and, therefore, to improve their trade performance. To this end, we use a standard gravity model augmented by the measure of quality standards, innovation and their interaction. Our results show that: (i) producers sustain international market access by means of innovation; (ii) quality standards required by the importing country are likely to enhance exports and (iii) consistent with the quality ladder model (Grossman and Helpman 1991a), a higher level of innovation yields a better export performance for industries interested by higher quality standards. The intuition is that more innovative industries are able to implement the requirements of foreign countries in terms of product quality and therefore to export more. We also check whether these results depend on the level of technology intensity of industries considered. Furthermore, the analysis by exporting countries reveals how the accelerator effect of innovation on quality standards is strongly related to the degree of development. However, both quality standards and innovation might be affected by trade flows. We can think, for instance, that a country has more incentives to impose quality standards or to introduce innovations in products that have a high import penetration. For this reason, our results should be interpreted as conditional associations, rather than causal relationships. The rest of the paper is structured as follows. Section 2 provides the most influential literature on standards, innovation and exports. Section 3 introduces the theoretical framework and empirical strategy, including the gravity equation, and the estimation technique. Section 4 provides the data description. The results are described in Section 5, while conclusions are presented in Section 6.",6
16.0,4.0,"Journal of Industry, Competition and Trade",16 January 2016,https://link.springer.com/article/10.1007/s10842-015-0215-7,Migrants’ Influence on Firm-level Exports,December 2016,Andreas Hatzigeorgiou,Magnus Lodefalk,,Male,Male,Unknown,Male,"A large number of studies have found a positive relationship between migration and trade. Following the pioneering studies of Gould (1994), Head and Ries (1998) and Rauch and Trindade (2002), the general conclusion in the literature has been that migrants’ knowledge about their countries of birth, together with contacts and access to networks, can lower trade costs associated with imperfect and asymmetric information.Footnote 1
 The aim of this paper is to subject the general view that migrants facilitate trade across the board to empirical scrutiny using a firm-level approach. We do so by exploiting a new employer–employee panel for Sweden, which encompasses close to 600,000 full-time employees, approximately 12,000 Swedish firms, and data for 176 of Sweden’s trading partners for the period 1998–2007. In specific, we are interested in examining whether migration has an unconditional positive impact on trade, or if certain characteristics of firms and migrants matter. To our knowledge, this is the first firm-level study using a rich employer-employee dataset to analyze the role of foreign-born workers in trade from a multidimensional perspective.Footnote 2 In a policy context, this approach is important since the notion of migration as a ubiquitous trade facilitating force could result in misguided policy decisions, not the least concerning migration policy. The contribution of this paper is fivefold. First, using a heterogeneous firm trade model as our point of departure, we analyze the within-firm-country influence of hiring foreign-born workers on foreign trade at the firm level. As such, this paper contributes to a nascent yet scarce literature on firm-level studies of the role of immigration on international trade. The second contribution is that we analyze the potential role of different migrant characteristics with respect to the influence on trade. Our matched dataset is the largest and most detailed to be used in the firm-level literature on migration and trade thus far. The previous literature has largely treated migrants as a homogenous group, but our data allow for examining the trade-migration link according to migrants’ skills and time since immigration. We expect that not all migrants possess the knowledge and contacts necessary for them to act as host-country agents for trade. Third, we analyze whether migrants’ presumed ability to spur trade differ depending on firm size. As predicted by the heterogeneous firm trade literature, firms differ in a number of respects, not the least in terms of aptitude for overcoming impediments to international trade. We expect the impact of hiring foreign-born workers with respect to trade costs to differ according to firm size. In specific, we anticipate larger firms to have less to gain from hiring immigrants. Fourth, we thoroughly address the potential endogeneity of foreign-born employees with respect to firm trade. There is an obvious risk of reverse causality since firms could be more prone to hire workers born in countries with which they already have trade relationships. We do so by examining the causal relationship using instrumental variable (IV) analysis, as well as with a lagged variables approach. Finally, we examine the role of labor market integration among foreign-born individuals. We do this through separate controls for foreign-born employees in the specific firm and the total stock of immigrants across all source countries. The previous macro literature has largely failed to determine whether it is immigration in general that facilitate trade, or if the possible trade facilitating effect is derived from dissemination of information and contacts within firms. We find that the hiring of foreign-born people is positively related to more trade with immigrant source countries: hiring one additional immigrant is associated with a 1 % increase in a firm’s exports. This result is in line with the other firm-level study in the literature (Hiller 2013). However, we find that this pattern of results is only prevalent for certain firms, and for subset of immigrants. Only smaller firms gain from hiring immigrants in terms of increased exports. Skills and time since migration are important factors that influence the link to firms’ trade, with skilled and recent immigrants being found to have the strongest impact. Although the prevalence of immigrants from a certain country is positively related to more firm exports, the strongest impact is estimated for foreign-born individuals employed in the firm. Further, unlike previous studies, we find no clear impact on imports, which we attribute to the large share of immigrants in Sweden coming from countries experiencing conflict and low overall production and export capacity. In what follows, Section 2 explains the context and presents a conceptual framework for the role of migration in trade; Section 3 explains the empirical framework, including the model and estimation strategies; Section 4 describes the data; Section 5 presents the results of the analysis; and Section 6 concludes.",19
16.0,4.0,"Journal of Industry, Competition and Trade",07 January 2016,https://link.springer.com/article/10.1007/s10842-015-0212-x,Weather as a Competitive Factor between Local and Foreign Manufacturing Companies in Russia,December 2016,Simo Leppänen,Svetlana Ledyaeva,Riitta Kosonen,Male,Female,Female,Mix,,
17.0,1.0,"Journal of Industry, Competition and Trade",15 June 2016,https://link.springer.com/article/10.1007/s10842-016-0226-z,Absorptive Capacity and Geographical Distance Two Mediating Factors of FDI Spillovers: a Threshold Regression Analysis for Spanish Firms,March 2017,Fernando Ubeda,Francisco Pérez-Hernández,,Male,Male,Unknown,Male,"Foreign direct investment (FDI) is perceived as a knowledge source for host economies, and in many cases, it has been an essential element in strategies for economic development. The empirical evidence is not conclusive because it shows strong methodological heterogeneity, provides partial results of the analysed phenomenon and is greatly determined by the available statistical information (Blomström and Kokko 1998; Görg and Strobl 2005; Saggi 2006; Görg and Greenaway 2004; Crespo and Fountoura 2007; Javorcik 2008; Smeets 2008). An ownership advantage is a necessary condition for firm multinationalization; this makes it possible to assume the cost of foreign operation (Hymer 1976; Dunning 1988; Buckley and Casson 1976; Makino and Delios 1996). In the multinationalization process, the firm transfers and adapts its distinctive capabilities to a foreign environment. In this sense, tacit knowledge-intensive assets are internationally transferred; these assets are partially appropriated by domestic firmsFootnote 1. Additionally, the presence of multinational firms (MNCs) may have a significant impact on competition, driving domestic firms to use resources more efficiently, or even foster higher levels of technological innovation (Blomström and Kokko 1998; Aitken and Harrison 1999; Kokko 1996; Keller and Yeaple 2003; Smeets 2008). The knowledge provided by MNCs is especially valuable for domestic firms that are technologically backward. Similarly, a reduction in technological backwardness implies an increase in similarity between the endowment of intangible assets of both types of firms, thereby reducing the value of knowledge and the magnitude of spillovers (Findlay 1978; Wang and Blomström 1992). On the other hand, we must consider that knowledge transfers require absorptive capacity, which implies that domestic firms close to a technological frontier possess greater potential for knowledge appropriation than those characterized by a greater technological gap (Kinoshita 2000; Kokko et al. 2001; Barrios and Strobl 2002; Griffith et al. 2002; Castellani and Zanfei 2003; Barrios et al. 2004; Peri and Urban 2006; Criscuolo and Narula 2008). Girma (2005) and Girma and Görg (2007) attempt to resolve this dispute, and they propose a nonlinear relationship between absorptive capacity and FDI spillovers. The results confirm a U-shaped relationship between absorptive capacity and the generation of spillovers for UK firms. Theoretical, methodological and empirical contributions are made in this paper. First, we propose an upgraded theoretical framework to improve the understanding of absorptive capability as an essential variable in spillovers generation. The theoretical model is based on Cohen and Levinthal (1989), and we incorporate the knowledge duplicity effect on the absorptive capacity (Lane and Lubatkin 1998; Gupta and Govindarajan 2000; Zahra and George 2002). Because of knowledge duplicity, we view technological gaps as a significant variable when computing absorptive capacity; however, this relation is not linear. Thus, we integrate both theoretical issues and justify the existence of a nonlinear relation between spillovers and the absorptive capacity of a firm. Our proposal is based on the existence of three types of firms. The first type is known as pre-catching-up firms; their absorptive capacities are insufficient for learning from MNCs, and as a consequence, these firms experience losses in productivity due to the increased competition caused by inward FDI. The second type is catching-up firms, which have enough absorptive capacity to gain partial knowledge from MNCs without generating knowledge duplicity problems. In this case, the benefits obtained from learning are higher than the cost of intensified competition. Finally, the last type is pre-frontier sharing, where knowledge duplicity reduces its relative absorptive capacity; this should lead to a reduction in positive spillovers intensity. Second, geographical proximity is another significant factor in absorptive capacity. The available evidence seems to confirm that geographical proximity increases the intensity of the spillovers. This evidence is based on aggregated data; however, there is a lack of evidence that employs microdata (Barrios et al. 2004; Mariotti et al. 2015). Using the bi-dimensional variables proposed by Girma (2005), we differentiate the MNCs in the region where the firm develops its operations from the MNCs outside the region. This second variable introduces the geographic distance between the capitals of both regions. The third contribution is a new method for measuring inward FDI. We elaborate a bi-dimensional construct of inward FDI that attempts to attenuate the measurement error incurred when estimating inward FDI with firm data instead of production plant data. This variable allows us to estimate a specific exposure to the MNC presence for each firm, which helps solve the endogeneity problems that are characteristic of this type of work. Finally, the possibility of a nonlinear relationship between the absorptive capacity and the generation of spillovers is taken into account; however, there is little evidence that threshold models have been used to analyse this relationship (Girma 2005). We have adopted this methodology to analyse the effect of the entry of FDI on productivity using a sample of 2722 Spanish manufacturing firms from 1993 to 2006. With this data, a non-equilibrated panel has been computed. For the Spanish case, a group of firms that could be defined as pre-catching-up firms has been identified. We find that firms with high absorptive capacities benefit positive spillovers. This result is consistent with the model of Criscuolo and Narula (2008) and the evidence in Barrios and Strobl (2002). Additionally, we find that mid- or low-absorptive capacity firms generate negative spillovers. This finding contrasts with the crowding out hypothesis proposed by Aitken and Harrison (1999), and it is coherent with the evidence in Castellani and Zanfei (2003). Finally, the empirical evidence confirms that the spillovers intensity increases with geographic proximity (Mariotti et al. 2015). The rest of this paper is organized as follows. In section two, we review the literature on the role of absorptive capacity and geographic distance in generating spillovers and propose a theoretical model. In section three, the threshold estimation is described and justified. In section four, the variables are described. Section five presents the results and conclusions.",18
17.0,1.0,"Journal of Industry, Competition and Trade",18 July 2016,https://link.springer.com/article/10.1007/s10842-016-0229-9,Asymmetric Payoffs and Spatial Competition,March 2017,Yusuke Zennyo,,,Male,Unknown,Unknown,Male,"We investigate the location choice of firms whose objectives are the weighted average of their own profit and social welfare. The objectives of maximizing a firm’s profit and social welfare have been studied as partial privatization in the context of a mixed oligopoly, in which a partially privatized public firm competes against other private firms (Matsumura 1998). However, two or more partially privatized public firms do not normally exist together in the same market. Thus, in the literature on mixed oligopolies, almost all studies focus on competition between one public or partially privatized public firm and the private firm(s). A notable exception is Matsumura and Shimizu (2010), who assume that several public firms compete against private firms in a market and then consider the sequential privatization of public firms. Some recent papers have interpreted an objective function containing a firm’s profit and social welfare as exhibiting CSR (Ghosh and Mitra 2014; Matsumura and Ogawa 2014; Hino and Zennyo 2015). This interpretation creates a need to investigate models in which two (or more) firms have objective functions consisting of their profits and social welfare. The purpose of this paper is to investigate how the equilibrium location strategies are affected by the firms’ objectives because there is a close relationship between firms’ location strategies and social welfare in the Hotelling model. To this end, we generalize the analyses of location choice in the context of a mixed oligopoly in a way that considers the competition between two firms whose objectives are the weighted average of their own profit and social welfare. We focus on how the equilibrium locations are characterized by either asymmetry of firms’ objectives or asymmetry of marginal costs, respectively. There are numerous studies on location choice in Hotelling’s model. d’Aspremont et al. (1979) investigated the location choice of private firms and then showed that firms locate at the ends of the market, thus maximizing their differentiation, to avoid fierce competition. Cremer et al. (1991) focused on location choice in a mixed oligopoly model, in which a public firm competes with a private firm. They demonstrated that the existence of a public firm could achieve the first-best location configuration even if the private firm attempts to maximize its own profit. Matsumura and Matsushima (2004) generalized the result of Cremer et al. (1991) to show that the equilibrium location is optimal for social welfare even if there are cost differences between public and private firms. Lu and Poddar (2007) also generalized the result of Cremer et al. (1991) to partial privatization. In other words, the private firm and the partially privatized public firm that maximizes the weighted average of its profit and social welfare simultaneously decide their location. As a result, in the case of a high share of private ownership in the partially privatized public firm, the two firms maximize their differentiation as shown in d’Aspremont et al. (1979). On the other hand, in the case of a low share of private ownership in the partially privatized public firm, both firms symmetrically locate inside the market. In sum, Lu and Poddar (2007) showed that, when both firms have the same marginal cost, the equilibrium locations are always symmetric regardless of the formulation of the partially privatized firm’s objective function. Kitahara and Matsumura (2013) introduced elastic demand into a location–price model in a mixed duopoly. They showed that under elastic total demand, the private firm has a weaker incentive to differentiate its product from the public firm. Therefore, a private firm locates too close to the public firm in equilibrium. We formulate the location choice of firms whose objectives are the weighted average of their own profit and social welfare, where they simultaneously decide their locations before setting their prices to maximize these objectives. We assume that the firms have intrinsic exogenous weights. Therefore, we study a general model including the analyses of the previous studies (d’Aspremont et al. 1979; Cremer et al. 1991; Matsumura and Matsushima 2004; Lu and Poddar 2007). We show that, if firms have the same marginal cost, the equilibrium locations are always symmetric, even though firms have different objective functions. This result implies that the symmetric location equilibrium derived by Lu and Poddar (2007) still holds under more general cases of the objective function consisting of the firms’ profit and social welfare. On the other hand, if there exists a cost difference between two firms, the equilibrium locations are asymmetric, in which the cost-efficient firm comes closer to the midpoint of a linear market than the inefficient rival, as in the case of competition between profit maximizers. Therefore, the comparison between the results derived in the case with and without the cost differences yields that the asymmetric location comes from the cost asymmetry, and not from the asymmetry of firms’ objectives. We also show that, given the objective function of one firm, the more emphasis the other firm puts on social welfare, the closer the two firms come to the midpoint of the market. The equilibrium locations of both firms, therefore, converge to the first-best location as the weight on social welfare goes to one, as shown in Cremer et al. (1991) and Lu and Poddar (2007), and also in the case where both firms have objective functions that include social welfare. Moreover, the comparative statics show that an increase in the weight on the cost-inefficient firm’s profit decreases the equilibrium prices of the two firms when the degree of product differentiation is small enough. In this case, the firms’ locations are shifted to the endpoint of a linear market, which in turn increases the trip costs of consumers. In the parameter space in which the positive effect may dominate the negative effect, the pursuit of profit by the inefficient firm may increase the consumer surplus in equilibrium. This paper is organized as follows. In Section 2, we develop our basic location model. Section 3 investigates location and price competition. Section 4 concludes.",2
17.0,1.0,"Journal of Industry, Competition and Trade",24 February 2016,https://link.springer.com/article/10.1007/s10842-016-0219-y,Optimal Timing of Advertising with Demand Spillovers,March 2017,Tsuyoshi Toshimitsu,,,Male,Unknown,Unknown,Male,"In modern economies, nonprice competition universally prevails in most goods and services markets. In particular, advertising is found everywhere around us through various media, including newspapers, magazines, radio, television, and the Internet. Importantly, many firms in a number of industries (e.g., automotive, retail, telecommunications, and financial services) spend huge amounts of money in advertising to obtain more customers and greater market shares. In addition, we often observe that small and medium sized-firms spend money on advertising through local newspapers, fliers, and more recently, websites. For example, in 2015 alone, an advertising spending in the US was $182.62 billion, $74.31 billion in China, and $42.29 billion in Japan.Footnote 1 As a result, advertising competition is a prominent problem in economics, business administration, and marketing.Footnote 2
 In this paper, by following the terminology in Marshall (1919, pp. 304–307) for explaining the effects of advertising actions, we focus on its combative and constructive role.Footnote 3 That is, we construct a model of advertising competition in a horizontally differentiated duopoly with demand spillovers. Among three distinct views of advertising, i.e., persuasive, informative, and complementary,Footnote 4 we consider a persuasive advertising view that affects consumer preferences and taste for and choice of goods and services. In this case, such advertising plays a combative role. With a combative effect, an increase in the advertising action by one firm takes the rival firm’s customers and reduces its profit.Footnote 5
 Furthermore, we consider an informative advertising view, which conveys information concerning the functions and qualities of products to consumers, and thus enhances the level of total market demand. In this case, such an advertising action plays a constructive role. In particular, an increase in advertising action by one firm may attract new customers from other (outside) markets into the market, and thus can expand the potential size of the market. As a result, the advertising action may increase the rival firm’s customers and profit. Thus, our model incorporates both a persuasive and an informative view of advertising. In terms of the specific features of our model, i.e., homogeneous consumers, demand spillovers, and a timing decision game, there is some important literature as follows. Using a Hotelling-type differentiated duopoly model, Von der Fehr and Stevik (1998) and Bloch and Manceau (1999) investigate the effects of informative advertising. In particular, Von der Fehr and Stevik (1998) show that informative advertising increases the level of perceived product differentiation. Bloch and Manceau (1999) demonstrate that because persuasive advertising may intensify competition and induce a decrease in the price of the advertised product, a firm does not necessarily have an incentive to engage in advertising. In these Hotelling-type models, such informative advertising affects market share and the distribution of consumer tastes. However, in our model, when assuming homogeneous consumers in a horizontally differentiated products market, we illustrate that advertising competition with demand spillovers induces a market expansion and thus can increase total market demand. We consider the demand spillover effects for advertising actions, i.e., advertising spillovers. For example, Balachander and Ghose (2003) deal with reciprocal spillover effects, while Sahni (2015) empirically demonstrates advertising spillovers. In other work, Nakata (2011) deals with informative advertising with spillover effects based on Grossman and Shapiro (1984) such that the spillover effects make the environment more monopolistic, i.e., with higher prices and lower demand. Because its basis is also a Hotelling-type model, there is not the effect of informative advertising on total market demand. However, in our model, an increase in the parameters relating to demand spillovers increases the advertising actions, outputs, and prices in the symmetric equilibrium. Thus, advertising spillovers may not necessarily induce a monopolistic environment. With respect to advertising competition in previous models, it is typical for a simultaneous decision game to derive the (symmetric) Nash equilibrium. In our model, to consider the timing as well as the level of advertising actions—points hitherto not discussed clearly—we examine a sequential decision game to derive Stackelberg equilibria, focusing on asymmetric advertising spillovers. By employing the endogenous timing decision framework provided by Hamilton and Slutsky (1990), we consider the optimal timing of advertising actions. We demonstrate that if there are sufficient asymmetric demand spillovers between firms, the difference in timing induces that in the level of advertising action. Consequently, the larger the difference in the level of advertising action and the greater the difference in the perceived product (or quality) differentiation, the softer the market competition and the more profitable it is for the firms. In particular, we show a counterintuitive result that a firm producing the product with small (large) demand spillovers, i.e., a small (large) firm, commits to a small (large) advertising investment earlier (later). In this case, the small firm free rides on the advertising spillovers of the larger firm. The remainder of the paper is organized as follows. In Section 2, we construct a horizontally differentiated products model, assuming a quasilinear utility function incorporating demand spillovers associated with advertising actions. In Section 3, we first show the subgame perfect Nash equilibrium (SPNE) in the advertising competition. We then extend the advertising competition to a sequential decision game and demonstrate the Stackelberg equilibrium. Using the framework of an endogenous timing decision game with an observable delay (i.e., Hamilton and Slutsky 1990), we then consider the optimal timing of advertising actions and demonstrate the existence of a natural Stackelberg situation (NSS), given asymmetric demand spillovers. Finally, to show that the results do not depend on the mode of competition, we examine the Bertrand duopoly case. Section 4 summarizes the results and we deal with some remaining problems.",2
17.0,1.0,"Journal of Industry, Competition and Trade",03 March 2016,https://link.springer.com/article/10.1007/s10842-016-0221-4,Indirect Taxes in Oligopoly in Presence of Licensing Opportunities,March 2017,Neelanjan Sen,Rajit Biswas,,Unknown,Unknown,Unknown,Unknown,,
17.0,1.0,"Journal of Industry, Competition and Trade",25 August 2016,https://link.springer.com/article/10.1007/s10842-016-0232-1,Price Versus Quantity in a Duopoly with a Unilateral Effect and with Bargaining over Managerial Contracts,March 2017,Yasuhiko Nakamura,,,Male,Unknown,Unknown,Male,"This study considers an endogenous choice game of a firm’s strategic contract in a duopoly. Here, two absolute profit-maximizing firms, with separation between ownership and management, have asymmetric (inverse) demand functions, following Choi and Lu (2012) and Nakamura (2013, 2015b).Footnote 1 More precisely, this study adopts the approach of bargaining over the sales delegation parameter, after (Van Witteloostuijn et al. 2007) and Nakamura (2015a), in order to investigate the situation wherein each firm’s owner chooses a price contract or quantity contract as its strategic variable in the market competition with respect to their profits. We consider the case wherein each firm adopts the sales delegation contract, à la Fershtman and Judd (1987), Sklivas (1987), and Vickers (1985). The aim of this study is to check the robustness of the results for the endogenous choices of strategic contracts by the owners of the two firms in a duopoly with asymmetry between their demand functions, following Choi and Lu (2012) and Nakamura (2013), against the bargaining power of the manager relative to that of the owner. Bargaining occurs over the sales delegation parameter between the owner and the manager.Footnote 2 We revisit the classic strategic contract choice problem in the fashion of Singh and Vives (1984) and Klemperer and Meyer (1986) in a private oligopoly. In a real-world economy, firms often choose between adopting their price levels (price contracts) and output levels (quantity contracts) as their strategic variables in market competition. Thus, under various economic environments, it is important to endogenize whether firms choose price contracts or quantity contracts in several multiple-stage games in various economic contexts. In particular, in a standard private duopolistic market, Singh and Vives (1984) found that both firms choose quantity contracts when their goods are substitutes, but they both choose price contracts when their goods are complements. Tanaka (2001a, 2001b), and Tasnádi (2006) extended the analysis conducted in Singh and Vives (1984) and Klemperer and Meyer (1986). Here, we address the robustness of the result obtained in a standard private duopoly à la Singh and Vives (1984) and Lambertini (2000a, 2000b), from the managerial delegation perspective, with bargaining over the sales delegation parameter, taking into account the asymmetry between the two firms’ demand functions.Footnote 3
 On the other hand, the change in the strategic relation between the goods produced by the two firms, along with the change in the degree of asymmetry between their demand functions, is theoretically and empirically important because such asymmetry between firms is frequently observed in real-world economies. For example, proceedings Cabral and Majure (1994) found theoretical and empirical evidence of asymmetry between strategic relations in the Portuguese banking industry such that the number of branches of rival banks is a strategic complement for some banks but a strategic substitute for others.Footnote 4 In addition, Tombak (2006) considered a two-stage game in which one firm regards its rival’s second-stage strategic variable as a strategic complement, whereas the other firm regards its rival’s second-stage strategic variable as a strategic substitute.Footnote 5 In real-world economies around world, codes of corporate governance have been introduced ever since the early 1990s, as indicated in Van Witteloostuijn et al. (2007). More precisely, whereas only the UK and the US were involved in codifying the shareholder–management relationship in the early 1990s, 24 countries had introduced corporate governance codes by the end of that decade. In addition, by the end of 2005, Aguilera and Cuervo-Cazurra (2004) argued that this number had increased to more than 50. The aim of such corporate governance codes is to protect owner-shareholders against opportunistic behavior by managers. Clearly, a key aspect of corporate governance codes relates to managerial compensation decision-making and disclosure. The underlying logic is that remuneration transparency is needed to keep managerial compensation in check. In this paper, α denotes the parameter in our model, which is interpreted as the bargaining power of the manager relative to that of the owner in firm i, (i = 0, 1). A sufficiently high α realistically and theoretically means that without transparency of the managerial contracts entered into in each firm, managers would boost their own remuneration against the interest of shareholders. Thus, they misuse their power in the bargaining process with the non-executives who determine their compensation, based on Van Witteloostuijn et al. (2007) and Nakamura (2008a, 2008b). Thus, a high value of α implies that managers’ remunerations run counter to the interests of shareholders, whereas a low value of α implies that managers do not boost their own remunerations at the expense of shareholders’ interests. The purpose of this study is to consider the influence of the following two elements: (1) the increase in α (i.e., the increase in the bargaining power of the manager to relative that of the owner in firm i), (i = 0, 1), which reflects each firm’s opportunistic behavior, because we appropriately consider how the opportunistic behavior influences the market structures observed in equilibrium; and (2) the (inverse) demand functions that firms 0 and 1 face in the equilibrium market structure (s) occurring as a combination of the two firms’ strategic contracts, as selected by the owners of firms 0 and 1, on the observed equilibrium market structures in the (𝜃, α)-plane. Then, we adopt the bargaining approach over the sales delegation parameter in the fashion of Van Witteloostuijn et al. (2007), which was developed to consider the effect of the disclosure of managerial compensation on the equilibrium market outcomes and structures in a homogeneous goods industry.Footnote 6
 Thus, in this study, we adopt bargaining between the owner and the manager in each firm as the means of determining each firm’s sales delegation parameter, à la Van Witteloostuijn et al. (2007), Kamaga and Nakamura (2008), and Nakamura (2008b). In particular, we show that when the bargaining power of the owner relative to that of the manager in each firm is sufficiently high, only quantity competition can become the equilibrium market structure, regardless of the degree of asymmetry between the firms’ demand functions. This result follows from the fact that when the degree of asymmetry between the firms’ demand functions is sufficiently low, both firms change their strategic approach from price to quantity contracts, provided that the rival firm chooses a price contract, and the bargaining power of the manager relative to that of the owner in each firm increases. However, when the degree of asymmetry between the firms’ demand functions is sufficiently high, provided that the rival firm chooses a quantity contract, it is optimal for each firm to choose a quantity contract. Thus, when the bargaining power of the manager relative to that of the owner in each firm is relatively high, it is reasonable to suppose quantity competition in the analysis of a private oligopoly.Footnote 7 Note that when the two goods are complementary to each other, the two types of asymmetric games related to strategic contracts have a narrow area to become the equilibrium market structure. This implies that the asymmetric market structure can become an equilibrium only when α is near zero.Footnote 8
 The remainder of this paper is organized as follows. In Section 2, we formulate a duopolistic model, with asymmetry between the firms’ demand functions, in order to explore the endogenous choice of each firm’s strategic contract. In Section 3, for the case wherein the strategic managerial delegation parameter is determined through bargaining between the owner and the manager in each firm, we consider a subgame perfect Nash equilibrium in the endogenous strategic contract selection model developed in Section 2. In Section 4, we investigate an asymmetric bargaining power case wherein the bargaining power of the managers relative to that of the owners differs between the two firms. More precisely, we consider a distribution of equilibrium market structures wherein the bargaining power of the (assumedly female) manager relative to that of the (assumedly male) owner is fixed at 1/2 in one firm but freely moves in the interval (0, 1) in the other firm. Section 5 concludes the paper. We relegate the calculation of the equilibrium market structures and outcomes to the Appendix.",5
17.0,1.0,"Journal of Industry, Competition and Trade",22 September 2016,https://link.springer.com/article/10.1007/s10842-016-0233-0,A Stochastic Production Frontier Estimator of the Degree of Oligopsony Power in the U.S. Cattle Industry,March 2017,Dimitrios Panagiotou,Athanassios Stavrakoudis,,Male,Male,Unknown,Male,"The U.S. agricultural sector has been revolutionized by a process called agricultural industrialization. This process refers to the production, coordination, and distribution of food products using modern methods typically associated with industrial manufacturing. In the beef sector, the benefits of industrialization include higher productivity and the availability of leaner and higher quality beef products. Despite these benefits, some aspects of industrialization raise questions about the performance of the beef marketing system. One particular aspect is rising concentration in the beef-packing industry and its effect on live cattle prices. Since the 1980s, the U.S. fed–cattle industry has experienced shifts of production to larger farms. At the same time, the beef-packing industry has become much more concentrated than cattle feeding (MacDonald and McBride 2009). Data from the United States Department of Agriculture – Packers and Stockyards Program (2014) show that both the number and the size distribution of beef-packing plants has changed dramatically in the recent years. Between 1980 and 2012 the number of plants decreased from 704 to 168 and the share of the top four firm in steer and heifer slaughter increased from 35.7 % to 85 %. During the years, the four-firm concentration ratio (CR4) reached the level of 85 percent in 2010, dropped to 84 percent in 2011, and raised again to 85 percent in 2012. According to the same report, the four-firm concentration ratio has remained around 80 % in the last ten years. In theory, the higher the CR4, meaning the closer it approaches 100 %, the greater the likelihood the four largest firms are exercising market power. Whether such high levels of concentration are detrimental to competition in live cattle markets has been the subject of many studies using different economic models, time spans, and statistical techniques. More importantly, as more slaughter cattle is now procured through contracts, otherwise know as captive supplies, there is also concern that packers may also manipulate cash prices to influence the base price used to negotiate contracts. Higher levels of concentration generally lead to lower prices paid for fed cattle indicating that the beef-packing industry exerts some degree of market power when procuring live cattle (Azzam, 1997; Cai et al., 2011a, 2011b; Marion and Geithman, 1995). That degree of oligopsonistic power, according to some studies, is not large enough to warrant concern (Schroeter 1988; Azzam and Schroeter 1991). In most of these studies, the magnitude of market power is relatively small and seemingly within an acceptable public policy level (Ward 2010). On the other hand, since beef-packing is a high-volume/low-margin business (Ward 2002), some researchers argue that given the large volume of cattle slaughtered every year, even a small degree of market power can translate into large transfers from the cattle producers to beef-packers. Hence, a seemingly small impact in dollars per hundredweight ($/cwt) can make a substantial difference (losses) to livestock producers (Ward 2010). Yet some authors report that losses to cattle producers are more than offset by the cost savings generated by increased concentration in the beef-packing industry, suggesting this way that structural changes are beneficial from an efficiency viewpoint (Sexton 2000; Azzam and Schroeter 1995). Lastly, some studies find no evidence of market power exercised by the beef packers during the time period considered in their study (Paul, 2001a, 2001b). Granted that there is merit to each of the preceding arguments, all of them hang to a large degree on the academic research that guides them. The most influential research in the past few years has been what is commonly known as the New Empirical Industrial Organization (NEIO). In a nutshell, NEIO is an econometric approach that treats market power as a parameter to be inferred from single industries data (Bresnahan 1989). Against this background, the objective of the present work is to revisit the econometric problem of estimating the degree of oligopsony power in the U.S. cattle industry with the use of the recently developed stochastic frontier (SFA) estimation technique by Khumbhakar, Baardsen and Lien (2012). In their article, Kumbhakar et al. (2012) propose a new method of estimating market power in an output market at firm level. They draw on the stochastic frontier methodology from the efficiency literature in order to estimate markups in the Norwegian sawmilling industry. The authors use both primal and dual specifications to represent the technology and consequently estimate the degree of oligopoly power. Both approaches reveal statistically significant evidence of market power. The primal and dual specifications of the technology is a big advantage of the stochastic frontier approach of market power estimation: in an output market, based on duality theory of cost and input distance functions, either input price data or quantity price data can be used. On the other hand, duality of revenue functions and output distance functions can be utilized for the case of the input market. Furthermore, the stochastic frontier estimation technique allows us to estimate market power under constant or variable returns to scale, which is not always the case in the NEIO approach, providing us with more flexibility in the measurement of mark-ups/downs of an industry. In the most recent paper, Bairagi and Azzam (2014) used the stochastic frontier estimator in order to test if the Grammen Bank exercises market power over borrowers. The authors employed a stochastic translog cost function. More specifically, the authors used annual time series for the 1985-2012 period in order to test whether the Grameen Bank’s lending rates are consistent with marginal cost pricing. Their results indicated that on average the lending rate is about 3 % above marginal cost. This study proposes a stochastic production frontier estimator in order to estimate the mark-down in an input market at industry level. The input market under investigation is the U.S. cattle industry. To the best of our knowledge, there has been no published work which has used the stochastic frontier approach in order to estimate the degree of oligopsony power exercised by the U.S. beef–packing industry when procuring live cattle. The present work is structured as follows: Section 2 contains the theoretical framework. Section 3 presents the empirical model to be estimated at aggregate level and Section 4 the data and estimation results. Section 5 provides a summary and conclusion.",6
17.0,2.0,"Journal of Industry, Competition and Trade",04 August 2016,https://link.springer.com/article/10.1007/s10842-016-0231-2,Competitiveness of Firm Behavior and Public Policy for New Technology Adoption in an Oligopoly,June 2017,Masahiko Hattori,Yasuhito Tanaka,,Male,Male,Unknown,Male,"We consider the following story. There is an oligopolistic industry in a developing country. Firms in the industry produce a homogeneous good. The firms can use a common new production technology which is more efficient than the present technology. This new technology is developed by a laboratory or a firm in a foreign developed country, and the government of the developed country wants to transfer new technology to the developing country as a foreign aid free of charge. However, each firm must expend a fixed set-up cost such as training employees. Economic growth requires that firms adopt new technologies. However, it may be insufficient or excessive in less competitive industries from the social welfare point of view. In this case, a government subsidy or tax is necessary. This paper is based on our two-fold interests in analyses of duopolistic or oligopolistic industries.
 The first is an interest in the relation between technology adoption and competitiveness under oligopoly. There are many references about licensor’s strategic behavior, under duopoly or oligopoly such as Katz and Shapiro (1985), Kamien and Tauman (1986), Sen and Tauman (2007), La Manna (1993), and under Stackelberg competition such as Filippini (2005), Kabiraj (2004), Kabiraj (2004), Wang and Yang (2004). Using cooperative game theory, Watanabe and Muto (2008) studies the equilibrium among licensor and licensees. Also, we introduce two papers concerning competitiveness. Boone (2001) analyzes the relation between licensor’s incentive to innovate and licensee’s competition, and has found the U-shaped relation. In Matsumura et al. (2013), the relation between competitiveness, which is represented by the relative profit maximization as this paper, and endogenous R&D investments is analyzed. It has shown that the R&D investment is U-shaped with respect to competitiveness like Boone (2001). About social welfare and optimal policy, it has shown that enhancement of competitiveness changes the optimal policy from subsidization to taxation. The result about optimal policy is the same as this paper, but the model in Matsumura et al. (2013) is restricted to a symmetric equilibrium, and do not refer to fixed cost and the difference of cost functions. The model about technology adoption behavior where new technology is exogenously given as this paper is discussed in Zhang et al. (2014) which focuses on the uncertainty of R&D investment, and Hattori and Tanaka (2014) which focuses on the relation between technology adoption and competitiveness using the relative profit maximization, but these do not analyze the social welfare. About social welfare, Pal (2010) shows that technology adoption may change the market outcome, and the social welfare is larger in Cournot competition than in Bertrand competition. The model in Pal (2010) and the model of this paper are similar. But in Pal (2010) government’s policies are not analyzed. Moreover, Elberfeld and Nti (2004) focuses on the spillover of new technology, and Hattori and Tanaka (2015) focused on the difference of cost functions, and these claim the over or under investment for the society in some situation. This paper extends Hattori and Tanaka (2015) to an oligopoly with various competitiveness. Concerning empirical studies (Tanaka 2004; 2013) examined success factors of technology transfer from Japan to Taiwan (Republic of China) in post Word War 2 period. He stressed the importance of social capability which reduces the technology transfer cost such as human capacity of bureaucracy and managers, and the role of the government for improvement of infrastructure, education and training of workers and engineers. Also, he claims that government should choose the industry where foreign company can receive the tax benefit. And he concludes that these factors which promote technology transfer lead Taiwan to economic growth. The second is an interest in the property of relative profit maximization, or maximization of weighted average of absolute and relative profits of firms. Theoretical justification of relative profit maximization is mainly based on evolutionary game theoretic point of view. Schaffer (1989) demonstrates with a Darwinian model of economic natural selection that if firms have market power, profit-maximizers are not necessarily the best survivors. A unilateral deviation from Cournot equilibrium decreases the profit of the deviator, but decreases the other firm’s profit even more. On the condition of being better than other competitors, firms that deviate from Cournot equilibrium achieve higher payoffs than the payoffs they receive under Cournot equilibrium. He defines the finite population evolutionarily stable strategy (FPES). It is a strategy of a player that maximizes his relative payoff. And in Vega-Redondo (1997) it was shown that FPES is a strategy that survives in the long run equilibrium or stochastically stable state of a dynamic stochastically evolutionary game developed by Kandori et al. (1993). Also, Vega-Redondo (1997) showed that in a homogeneous good case if firms maximize relative profits, a Walrasian equilibrium can be induced. But in the case of differentiated goods, the result under relative profit maximization is different from the competitive result. We analyze the optimum subsidy or tax policy for new technology adoption by firms when firms maximize the weighted average of absolute and relative profits. We do not consider that firms really maximize the weighted average, but the weight on the relative profit is used as a parameter indicating competitiveness of firm behavior. We show that the optimum policy is likely to be subsidization (or taxation) when the set-up cost for new technology adoption is large (or small). And it is likely to be subsidization (or taxation) when competitiveness is large (or small), that is, it is near to perfect competition (or joint profit maximization). In the next section we explain competitiveness of firm behavior expressed by maximization of the weighted sum of absolute and relative profits, in Section 3 the main results of this paper are presented, in Section 4 we present the model of this paper, in Section 5 we examine the equilibrium firm behavior, in Section 6 we consider the social welfare, in Section 7 we examine the optimum policies, and in Section 8 we present an analysis about consumers’ surplus.",1
17.0,2.0,"Journal of Industry, Competition and Trade",01 February 2016,https://link.springer.com/article/10.1007/s10842-016-0216-1,Can Firms Grow Without Credit? A Quantile Panel Analysis in the Euro Area,June 2017,Sophia Dimelis,Ioannis Giotopoulos,Helen Louri,Female,Male,Female,Mix,,
17.0,2.0,"Journal of Industry, Competition and Trade",06 August 2016,https://link.springer.com/article/10.1007/s10842-016-0230-3,The Economic Approach to European State Aid Control: A Politico-Economic Analysis,June 2017,Karsten Mause,Friedrich Gröteke,,Male,Male,Unknown,Male,"The 1957 Treaties of Rome not only created the European Economic Community (EEC) but also European state aid control. Since then, it has been the task of the European Commission (EC), and particularly its Directorate-General (DG) for Competition, to prohibit “any aid granted by a Member State or through State resources in any form whatsoever which distorts or threatens to distort competition by favouring certain undertakings or the production of certain goods ... in so far as it affects trade between Member States” (Art. 107(1) of the Treaty on the Functioning of the European Union, TFEU). However, the interpretation and implementation of the two decisive prohibition criteria – distortion of competition and influence on cross-border trade – remained vague because this ‘effects-on-rivals’ approach lacked a clear competition-theoretical basis and economic methods known from other competition-policy instruments such as European merger control or cartel policy. In fact, it was simply assumed that prior to being granted a subsidy payment, tax relief or another type of state aid, a situation of ‘perfect’ or ‘well-functioning’ competition existed in the particular sector. In relation to this hypothetical reference point, however, any state aid that favours a certain undertaking leads to actual or potential distortion of competition and trade (Jenny 1994, p. 549; Bacon 2003, p. 60; Heidhues and Nitsche 2007, p. 323). In other words, the reason and the justification for the EC’s intervention – namely, the risk of distorting competition and trade in the European internal market – was simply taken for granted. Therefore, observers repeatedly (i) criticised European state aid control for lacking a sound economic-theoretical basis, and (ii) recommended a reform towards a more economic approach that takes into account instruments from microeconomic analysis and competition theory (see e.g. Evans and Martin 1991; Jenny 1994; Campbell et al. 1994; Bishop 1997; Friederiszick et al. 2008). In the mid-2000s, the EC began to address this criticism. For example, former Competition Commissioner Monti (2004, p. 8) announced an “improvement of the economic under-pinning of state aid control” as an important element of “state aid reform”. And his successor, Competition Commissioner Kroes (2005, p. 4), acknowledged that “[e]conomic analysis of state aid is still in its infancy, compared to the achievements in other areas of competition policy”. In 2005 she therefore presented a “State Aid Action Plan” (EC 2005) which, among other things, outlined the fundamentals of a “refined economic approach” to European state aid control. In line with previous research, in what follows we use the term ‘more economic approach’ or the acronym ‘MEA’ for this refined approach employed by the EC since 2005. Inspired by a comment by Kirstein (2007) on the MEA to European competition law, in this article we contribute to the politico-economic literature on EU state aid policy (for surveys, see Cini and McGowan 2009, chap. 7; Blauberger 2011; Kassim and Lyons 2013) by pleading for an ‘even more economic approach’ in European state aid control. Within such an approach, concepts and insights from the economic toolbox are not only integrated (a) in the analysis of (planned) state aid activities of the Member States (as the EC explicitly has done since the ‘more economic’ reform) but also (b) in the analysis of the activities of the state aid controllers at the supranational EU level. In so doing, two fundamental conceptual issues in particular stand out, which will be discussed in more detail below. Firstly, from the perspective of economic theories of federalism (e.g. Oates 2008) and regulatory competition (e.g. Kerber and Wendel 2016) which, among other things, deal with the vertical allocation of competences within multi-level systems such as the EU, it is by no means clear that the (potential) problem of socially wasteful state aid at the national level, which has been explicitly tackled by the supranational EU state aid control since the introduction of the MEA, is (i) unsolvable at the national level and (ii) is a case for the EC’s controllers (see Section 3). In this context, Haucap (2007, pp. 352–353) remarks that, interestingly, the inventors of the MEA (i.e. EC, DG Competition and its Chief Competition Economist’s team) did not address, at least not publicly, “the question of what institution is best suited to deal with state aid. As in many other areas of economic policy, the European Commission immediately jumps from the definition of a problem to the conclusion that itself should be in charge in order to alleviate the alleged problem [...] The mere fact that a problem exists does not mean that the European Commission is best suited to solve it”. Secondly, though the EC’s ambitious goal aimed at implementing a “coherent ... reform of state aid policy” (Kroes 2005, p. 2; see also EC 2005, p. 6: “The aim is to present a ... consistent reform package”), the current MEA in European state aid control is inconsistent in terms of its behavioural assumptions. The national governments – in the spirit of Public Choice theory (Downs 1957; Mueller 2003) – are pessimistically assumed to pursue their own self-interest (e.g. improving approval ratings and re-election chances by means of state aid) and are suspected of wasting taxpayers’ money. At the same time, the EC’s own policy – in line with the welfare-economic concept of a benevolent ‘social planner’ (Feldman and Serrano 2006) – is regarded as being in the public interest and welfare-enhancing (e.g. protecting taxpayers and consumers throughout the EU).Footnote 1 But to be conceptually consistent, following Public Choice approaches within the literature on the political economy of international organisations (see Vaubel 2013, for a survey), Public Choice reasoning has to be applied to actors at both the Member State and supranational EU level (see Section 4). Before presenting our considerations towards an ‘even more economic approach’ in European state aid control, in Section 2 we briefly explain why the MEA marks a paradigm shift in this specific subfield of EU competition policy. Finally, Section 5 discusses the policy implications of our politico-economic analysis.",3
17.0,2.0,"Journal of Industry, Competition and Trade",14 March 2016,https://link.springer.com/article/10.1007/s10842-016-0222-3,State Aid and Export Competitiveness in the EU,June 2017,Roman Stöllinger,Mario Holzner,,Male,Male,Unknown,Male,"The continuous loss of jobs in the European manufacturing sector over the past two and a half decades has revived the debate on industrial policy in Europe. This debate gained momentum due to the economic crisis in 2008 and the subsequent unresolved problems of the euro area. The fact that Member States which have maintained a larger manufacturing base fared better after the crisis intensified the concerns about the declining role of manufacturing in the European economy. The painful bursting of real estate bubbles and the ongoing turmoil in the financial sector nurtured doubts about the market’s universal ability to bring about an efficient allocation of resources in the economy thus leaving potentially a more prominent role for governments to influence or even shape the structure of the economy. Against the backdrop of long-term structural shifts out of the manufacturing sector, industrial policy targeted at the manufacturing sector seems to be the order of the day.Footnote 1
 At the same time, industrial policy is still regarded with considerable scepticism in Europe due to the rather disappointing experiences with government interventions in the 1960s and 1970s. Large, selective and often ill-designed backward-looking subsidies to ailing firms and sunset industries earned industrial policy a bad name (Crafts 2010). These rather unsuccessful policy experiments, together with the internationalisation of the European economy starting in the 1980s (Owen 2012) and the emergence of the ‘Washington Consensus’, induced a paradigm shift in the way industrial policy is conducted in Europe. Public interventions in favour of specific firms and sectors were increasingly replaced by framework policies and ‘horizontal’ policies. Despite the often heralded return of industrial policy (Wade 2012),Footnote 2 state aid provided by EU Member States to industry and services is at a historical low level. Subsidies amounted to about 2 % of EU GDP during the 1980s (European Commission 2011), went down to about 1 % in the 1990s and are currently less than half a per cent of GDP. In 2011 the combined state aid to industry and services of all EU Member States was down to EUR 58 billion.Footnote 3 This marked drop in the amounts of state aid is partly owed to frustrations with disappointing outcomes of active state aid policy but was also induced by a strengthening of state aid rules by the Commission. In general, industrial policy in the form of state aid came increasingly out of fashion and the policy focus shifted towards market-oriented measures such as changes in product and labour market regulations and privatisations, developments which Wade (2012) has described as a weakening of the ‘interventionist priors’. In the context of this downward trend state aid it should be stressed that by international standards Member States still appear to be active providers of aid. Judged by WTO notifications of subsidies EU Members States’ state aid amounts exceed those of the US by a factor of six (Buigues and Sekkat 2011). In this paper we exploit data on state aid granted to the manufacturing sector by 27 EU Member StatesFootnote 4 over the period 1995 to 2011 in order to investigate the impact of subsidies on exports. The focus on international competitiveness as the primary objective of the EU’s industrial policy strategy (European Commission 2010a, b, 2012a, 2014) makes exports a logical candidate for the performance measure. Since national policies – which is what we look at here – typically aim at domestic value added creation, we make use of recent advances in research on global value chains and use value added exports (Johnson and Noguera 2012) as our proxy for export performance. We confine the analysis to the manufacturing sector because it accounts for the bulk – some 73 %Footnote 5 – of Member States’ total exports. The high tradability of manufacturing goods implies that subsidies for the sector are likely to target exports. For this reason there is also a loose relation between our investigation and the Mill test. The Mill test requires subsidies to be granted only temporarily and that an industry receiving such temporary support is, after termination of the support, viable without government assistance and capable of generating export revenues (see for example Kemp 1960; Harrison and Rodriguez-Clare 2010). One of the unique institutional features of the European Union is that the sovereign governments of all EU Member States agreed to have their state aid activities monitored and even restricted by the European Commission.Footnote 6 All Member States have to comply with EU competition law which also includes detailed rules on state aid. According to these rules, governments are not allowed to grant aid ‘which distorts or threatens to distort competition […] in so far as it affects trade by Member States’..Footnote 7 The Commission is also empowered to prohibit planned aid measures or programmes of Member States. The state aid rules also imply that, in principle, all aid measures of Member States have to be notified ex ante to the Commission. The control of state aid of sovereign governments is obviously a delicate issue and the European Commission has shown a large degree of pragmatism in this respect (Doleys 2013). The general prohibition of trade distorting aid is qualified by a number of exceptions and additional considerations. For example, aid may be considered compatible with the Single Market if it is related to a project of common European interest. Moreover, not all state aid is necessarily trade distorting. Indeed, in the case of most aid programmes that aim at ‘horizontal’ objectives (‘horizontal aid’) the European Commission assumes a priori that these are not trade distorting, if they comply with the conditions laid out in the Commission’s General Block Exemption regulation,Footnote 8 which is why such aid programmes are exempted from the ex-ante notification obligation. Horizontal aid includes for example R&D aid or aid for training measures. The Commission’s obvious preference for horizontal state aid may also help to resolve a seeming contradiction between the prohibition of trade-distorting state aid and the hypothesis that state aid may spur national exports. While direct export subsidies clearly violate state aid rules, the European Commission considers state aid that aims at improving firm productivity and economic growth by removing or reducing market failures (or system failures) as compatible with the rules of the Single Market. In open economies, however, any measure that improves firm productivity is also likely to induce additional exports (see for example Melitz 2003). Therefore state aid, if provided in a non-discriminatory manner, may be at the same time export enhancing and compatible with EU competition law. In fact, state aid that positively affects national exports would only be automatically trade-distorting if one were to assume that state aid is a zero sum game with respect to growth and exports, in which one country’s export gain implies a loss of exports of some other country or loss of sales for local firms in the importing countries. Moreover, the Commission only looks at possible trade distortions within the EU, but not outside the EU. The fact that state aid is potentially export enhancing also becomes obvious in the Commission’s General Block Exemption Regulation, particularly in the context of R&D and training aid. These types of aid are explicitly exempted from the ex ante notification because of their alleged potential to improve the EU’s competitiveness which (may not be limited to but certainly) includes the capability of EU firms to sell their products in foreign markets. The Commission is more sceptical about sector-specific aid which is increasingly limited to rescue and restructuring aid measures. The European Commission’s preference for horizontal state aid is founded in the belief that horizontal aid is less distortive to competition than sectoral aid (Friederiszick et al. 2006). Moreover, it contributes to the Commission’s own market-correcting or redistributive policy goals and is therefore linked to an objective of ‘common interest’ (Blauberger 2008). This preference for horizontal aid on the side of the Commission has a big impact on the type of state aid provided by Member States – or at least the way it is notified: the overwhelming majority of EU state aid is currently provided in the form of horizontal aid with 90 % of state aid being notified under some block exemption scheme (Szczepanski 2013). The notification requirement for Member States’ state aid implies that there is systematic information on their state aid activities which is also published in the so-called State Aid Scoreboard. Therein the information on the actual aid amount is recorded annually and according to ‘objectives’ in the case of horizontal aid and according to broad sectors in the case of sector-specific aid. We use this data from the EU State Aid Scoreboard, which is expressed in real Euros with the base year of 2010, for the period 1995 to 2011. There are several important aspects concerning the scope, definition and compilation of state aid as registered in the State Aid Scoreboard that are worth mentioning. First of all, it is essential that the data from the State Aid Scoreboard contains exclusively aid that is provided and notified by Member States. Aid that is disbursed by the EU Cohesion and Structural Funds is not included. Secondly, only ‘specific’ measures by governments are considered as state aid. General measures for the economy and in particular general tax regulations do not fulfil this criterion of specificity. For example, a tax exemption for a particular company from the corporate tax constitutes state aid. A general reduction of the corporate tax rate or even the abolition of the corporate tax would not constitute a state aid measure. Thirdly, since state aid comes in different forms and shapes, including outright grants, tax breaks, state guarantees at preferential fees, subsidised loans etc., the State Aid Scoreboard reports aid figures in terms of the ‘aid element’ contained in the respective aid measure. For example, the aid element of a grant is 100 %, i.e. the full amount of the grant while for an interest-free loan the aid element would be much lower than the nominal loan amount, equal to the interest payments that would accrue for a loan provided at market interest rates. Fourth, while certain horizontal aid programmes are exempted from the ex-ante notification requirement, the actual aid amounts paid out of these programmes still need to be notified to the Commission (ex post information sheets). Therefore they are included in the aid figures of the State Aid Scoreboard. In contrast, so-called ‘de-minimis’ aid, that is aid measures not exceeding EUR 200,000, is not considered to threaten competition and therefore does not constitute state aid. Hence, de-minimis aid is not included in the state aid figures (see European Commission 2008a). Fifth, in 2008 the European Commission temporarily introduced additional state aid rules as a reaction to the economic crisis. For the real economy, some state aid rules where relaxed under the so-called ‘Temporary Framework’. Aid granted under the Temporary Framework which was terminated by the end of 2011 is accounted for separately in the State Aid Scoreboard (see for example European Commission 2012b). Unfortunately, for the crisis-related aid to the real economy no break-up by sector or objectives is available which is why we do not include the state aid provided under the Temporary Framework in our econometric work.Footnote 9
 Obviously, the impact of subsidies on export performance (or any other performance indicator for that matter) depends on how they are provided. Governments may spend aid money to remedy market imperfection – a motive that Rodrik (2012) refers to as the ‘developmental’ view. In this view state aid can be expected to push exports. Such well-intended policy initiatives may, however, be plagued by a lack of information on the side of governments giving rise to the well-known ‘picking the winner’ problem (e.g. Pack and Saggi 2006; Harrison and Rodriguez-Clare 2010). The picking the winner problem is present irrespective of whether a government decides to support a specific sector with the objective of turning a ‘latent’ comparative advantage into an effective comparative advantage (vertical policies) or whether subsidies are provided in order to support certain activities prone to positive externalities such as R&D (horizontal policies). Obviously, the hoped-for impact of subsidies on exports will not materialise if governments target the wrong industries or the wrong activities. More devastating consequences can be expected if the allocation of subsidies by governments is dictated by vested interests and politicians use industrial policy to transfer resources to favoured (or influential) groups. The capture of government by vested interests is a major and long-standing argument against the provision of state aid (e.g. Naudé 2010). In this narrative – the ‘political’ view in Rodrik’s terms – governments will grant subsidies to the strongest lobbies (which are typically not in new promising industries but in well-established industries) to the detriment of the country’s international competitiveness and export performance. There is ample evidence that subsidies are often granted to large (and sometimes ailing) firms and ‘sunset industries’. For example, in 2008 large amounts of subsidies were handed to carmakers, first in the US, and then all over Europe (Hufbauer and Stephenson 2009; Francois and Stöllinger 2009). In an analysis of the car scrappage premia in Europe Leheyda and Verboven (2013) come to the conclusion that, while the subsidies to the car industry helped to temporarily stabilise car sales, there would have been more productive investments for the public money spent on subsidies. Clearly, if such government failures were pervasive in Member States we should find no or even a negative effect of manufacturing aid on exports. Such a negative impact on exports may materialise if the state subsidy programmes cause additional or intensify existing misallocations of resources (e.g. a shift of resources from high productive to low productive firms within an industry or from high productive industries to low productive industries) which would result in a reduction of aggregate productivity and aggregate exports.Footnote 10
 Looking for a final verdict on whether subsidies are supportive of competitiveness would be an elusive quest. Therefore, our objective is more modest and we intend to shed light on the question whether state aid to the manufacturing sector that was provided by EU Member States between 1995 and 2011 had a measurable impact on sector-level export performance. We embed this hypothesis that state aid is a potential policy tool for EU Member States to foster manufacturing exports in a macroeconomic export function for the manufacturing sector and test it empirically. The choice of such a high level of aggregation necessarily causes a problem. Unlike in the evaluation of more specific policy measures where matching techniques, difference-in-difference estimations or regression discontinuity designs can be applied, our general approach does not allow to control for potential policy endogeneity and to identify causal effects. In such circumstances Rodrik (2012) predicts that the estimated policy effects in a framework like ours is likely to result in a negative coefficient irrespective of whether EU governments are in the ‘developmental’ mode or the ‘political’ mode. Despite these difficulties we take up the issue in the sectoral set-up and hope that a generous set of control variables reduces the degree of policy endogeneity even if it cannot be fully eradicated. Given the intensive revival of the industrial policy debate we believe that investigating the effect of subsidies, the primary tool of industrial policy, on export performance, the primary objective of modern industrial policy, is necessary. To our knowledge this relationship has never been empirically analysed in the framework of a macroeconomic export function. The paper’s contribution to the literature is then to test the effect of 27 EU Member States’ state aid to the manufacturing sector on value added exports of the manufacturing sector in such a framework. We believe that our choice of the export variable is the most appropriate one in this context for two reasons. First of all, industrial policy is typically targeting domestic value added which is what we capture with value added exports (as opposed to gross exports). Secondly, by isolating the domestic value added that is exported we do not need to care about import-dependence of exports. Therefore it is also theoretically correct to use value added exports as the dependent variable in the estimation of an export function. The paper is structured as follows. Section 2 reviews parts of the related literature. Section 3 discusses the data followed by the presentation of the empirical strategy in Section 4. The empirical results are presented in Section 5. Section 6 concludes with some policy implications.",6
17.0,2.0,"Journal of Industry, Competition and Trade",25 November 2016,https://link.springer.com/article/10.1007/s10842-016-0235-y,Strategic Trade Policy and Network Compatibility,June 2017,Tsuyoshi Toshimitsu,,,Male,Unknown,Unknown,Male,"Since the seminal work of Brander and Spencer (1985), which presents a model of international rivalry in third-market trade, many studies have considered strategic trade policy in various environments. Ghosh and Pal (2014) consider strategic trade policies in a network goods duopoly. In fact, given the rapid progress in information and communication technologies (ICT), during the past two decades, we have witnessed a proliferation of goods and services that exhibit network externalities and product compatibilities, e.g., personal computers, smartphones, application software, operating systems, and Internet services. Furthermore, international oligopolistic competition prevails in these product markets. With respect to the production and international trade of ICT products, the OECD (2014, Ch. 5, p.144) reports that “…between 2000 and 2012 world exports of manufactured ICT goods grew by 65% to more than USD 1.5 trillion. Production and exports of ICT goods are increasingly concentrated in a few economies. Owing in part to the offshoring of production, the shares of Japan and the United States in world exports of ICT goods halved from 2000 to 2012, while China’s grew from 4.4% to over 30%, with a tenfold increase in USD terms. Korea and Mexico were the only OECD economies of the top ten exporters to maintain their share of the world market for ICT goods, where Mexico benefited from the relocation of international (not only the United States) activities linked to NAFTA.” We can confirm this situation by using OECD (2015) data. In light of these developments, we consider the role of increasing exports from newly industrializing countries, e.g., China, Korea, and Mexico. These countries make it possible to implement various kinds of trade and industrial policy to expand market share in international ICT product markets and to improve welfare. Therefore, the first purpose of this paper is to consider what strategic trade policies are optimal in ICT product markets with international rivalry. Ghosh and Pal (2014) offer an analysis closely related to our model and demonstrate that under price competition, it is optimal to tax (subsidize) exports, if network externalities are weak (strong). Under quantity competition, the optimal trade policy always involves an export subsidy. They consider a specific case where the degree of product compatibility between firms is symmetric and equal to that of product substitutability. In this case, the effect of network externalities from another user disappears. However, we observe that there are several degrees of product compatibility between products and services in network industries. That is, asymmetric product compatibilities between firms arise. Belleflamme and Peitz (2010, p. 576) consider a software program that allows users to make telephone calls over the Internet (e.g., Skype) as an example of communications network. The software is a partially compatible product because an off-net call (i.e., a call outside the community for a fee) has lower utility than an on-net call (i.e., a call within the community free of charge). Furthermore, estimating network effects and compatibility in the Polish mobile market, Grajek (2010) finds that there are strong network effects and that the estimated degree of compatibility is very low, despite full interconnection with the mobile telephone network. Another example is word-processing software. That is, various types of word-processing software (e.g., WordPerfect, Corel Write, and King Writer) are perfectly or partially compatible with Microsoft Word. Gandal (1995) empirically analyzes complementary network externalities in PC software markets because users need to exchange data files between spreadsheets and database management systems. He describes, for example, a statistical analysis package such as TSP, which is fully compatible with Lotus files, but not with Dbase files. In this paper, by allowing for asymmetric product compatibilities, we consider how the degree of network externality associated with product compatibilities (hereafter, network compatibility) affects optimal strategic trade policies. Incidentally, there has been a suggestion that the optimal strategic trade policy depends on the mode of competition. For example, Brander and Spencer (1985) demonstrate that an export subsidy is optimal with Cournot duopoly (quantity competition). By contrast, Eaton and Grossman (1986) establish that an export tax is optimal with Bertrand duopoly (price competition).Footnote 1
 In the real world, as discussed in Tremblay and Tremblay (2012, p.269), Cournot competition is common in farmers’ markets, whereas in the fast food industry, restaurants compete Bertrand fashion via prices, while in the small car market, we often observe a mixture of Cournot and Bertrand behavior. The mode of competition is then dependent on the properties of markets where firms provide various products and services. Thus, in a market for products and services with varying degrees of network compatibility, the strategy firms choose is an important issue. Recently, Schroeder and Tremblay (2015) consider strategic trade policy with Cournot–Bertrand competition. Their research question is whether the optimality of an export policy depends on the mode of competition and the market structure. That is, assuming that the mode of competition is exogenously given, they consider the optimal strategic trade policy under three modes of competition, namely, Cournot (quantity–quantity) competition, Bertrand (price–price) competition, and Cournot–Bertrand (quantity–price) competition. Overall, Schroeder and Tremblay (2015) establish that the strategies of foreign firms determine the optimal export policy of a home country’s government. That is, an export subsidy (tax) by the home country’s government is optimal if the foreign firm chooses the quantity (price) setting. However, Schroeder and Tremblay (2015) do not examine the endogenous choice of strategies, i.e., quantity and price, by firms. In this paper, we relax the exogenously given mode of competition. Thus, the second purpose of this paper is to investigate the relationship between the mode of competition and the optimal strategic trade policy. Related to this issue, Toshimitsu (2016) considers how strategic variables (price or quantity) are endogenously determined by the level of network compatibility and demonstrates that if the degree of network compatibility of the rival firm’s product is larger (smaller) than that of product substitutability, the firm chooses the price (quantity) setting. Some studies investigate the endogenous decision of strategy and trade policy, including Laussel (1992) and Maggi (1996). These typically address supply-side factors such as the endogenous choice of supply functions or capacity constraints. By contrast, we deal with demand-side factors such as network externalities and product compatibility, as included in consumer preferences and utilities. We particularly focus on the case of asymmetric product compatibilities. The remainder of this paper is organized as follows. Section 2 considers an optimal strategic trade policy given the case of Cournot competition with network compatibilities. In Section 3, we examine the case of Bertrand competition. In Section 4, we first analyze the case of Cournot–Bertrand competition, and then investigate the relationship between the mode of competition and the optimal strategic trade policy. In Section 5, we summarize the results.",1
17.0,3.0,"Journal of Industry, Competition and Trade",13 December 2016,https://link.springer.com/article/10.1007/s10842-016-0236-x,Income Distribution in Network Markets,September 2017,Corrado Benassi,Marcella Scrimitore,,Male,Female,Unknown,Mix,,
17.0,3.0,"Journal of Industry, Competition and Trade",22 December 2016,https://link.springer.com/article/10.1007/s10842-016-0238-8,Nothing so Certain as your Anchors? A Consumer Bias that may Lower Prices and Prevent Cartels,September 2017,Barna Bakó,András Kálecz-Simon,,Male,Male,Unknown,Male,"Though utility is at the heart of the economic understanding of behavior, its usual interpretation might be a bit restrictive. The findings of behavioral economics suggest that besides price and the good itself, other – mainly psychological – factors related to the transaction affect our assessment. Thaler RH (1985) makes a distinction between the “classical” notion of utility (which he calls acquisition utility) and transactional utility which is one’s appraisal of the deal. Was it fair? Do we feel cheated? Was it a good buy? One of the most illuminating examples given by Thaler to illustrate transaction utility is the following: a person lying on the beach. She is thirsty and a friend offers her to get her a beer. Though nothing else should matter here but the beer and the amount one has to pay for it, most people’s willingness to pay does depend on the fact whether the same bottle of beer is bought from a grocery store or from the bar at the hotel. Transaction utility, according to Thaler, depends on the relationship between the actual price and some reference price, the price consumers compare the shelf price to or would consider fair. Although there is a wide variety of conceptual definition of reference price (see Winer, 1988), empirical findings (see e.g. Rajendran and Tellis, 1994 or Kalyanaram and Winer, 1995) point out that the reference price seems to be determined primarily by the latest price, the original price or the lowest price. Yet, several studies suggest (see Mazumdar et al., 2005) that the latest price encounters have the largest effect on the reference price and according to the field study of Dickson PR and Sawyer AG (1990) the effect of past prices beyond the very recent ones can be insignificant.Footnote 1 These results are in line with Gabor A (1980)’s findings as well, who argues that the reference price of a good is the very last price paid for it. When thinking about how reference prices affect one’s willingness to pay, it might be useful to think of them as anchors.Footnote 2 This approach is supported by Monroe KB and Petroshius SM (1981), Urbany JE et al. (1988), Simonsohn U and Loewenstein G (2006) or Chandrashekaran R and Grewal D (2006) as well. Anchoring in a broad sense refers to the phenomenon that prior numerical cues could influence our later decisions. For example, if we are asked first whether we would be willing to pay $10 for a watch, our valuation for it could be lower than if we are first asked a similar question but with $1000. Of course, this is clearly not consistent with the model of rational consumers who derive their valuations from their system of preferences. Many studies have tried to deepen the understanding of this regular quirk of consumer behavior. For example, Tversky A and Kahneman D (1974) asked subjects about the percentage of African nations in the United Nations. However, firstly a wheel of fortune (with numbers between 0 and 100) was used to obtain an initial guess and before giving their own guess, the subjects had to answer whether the percentage is higher or lower than the one drawn. This chance number has clearly influenced the final guess given by the subject. Ariely D et al. (2003) carried out ground-breaking experiments on how anchoring affects consumer valuation. They first asked the subjects to write down the last two digits of their Social Security number: this has provided them with a random numerical cue, just as the wheel of fortune in the experiment carried out by Tversky A and Kahneman D (1974). The subjects first had to answer whether they would buy a certain good (e.g. a bottle of wine) for that number of dollars. Then they had to state their willingness-to-pay for the said item. They also had to indicate their willingness-to-pay for a fancier product in the same category (e.g. a bottle of “rare” wine). Their valuations were strongly influenced by the random numerical cue – the anchor –, however, relative valuations were in order, that is one would pay more for a bottle of “rare” wine than for a bottle of “average” wine. The authors interpret these results that the foundations of our valuations are arbitrary, nevertheless, our system of valuations is still internally consistent. Both reference prices and anchoring as a phenomenon have a very extensive empirical literature, however, the logical follow-up of behavioral economics findings (as seen, for example, in Kőszegi and Rabin, 2006; in Schipper, 2009 or in Jansen et al., 2009) would be to extend previous models of consumer-firm interactions using these results. The first step in this direction was taken by Nasiry J and Popescu I (2011), who have investigated the effect of price anchoring on the dynamic pricing problem of the monopoly and found that ignoring the behavioral effects can lead to under- or overpricing. Under the peak-end rule they applied (ie. the reference price is a combination of the lowest price and the last price), they have shown that the optimal price path will always be monotone; thus the monopoly will employ skimming or penetration pricing. In this paper, we continue this direction by incorporating the effects of reference prices into oligopoly models, which to our knowledge was not considered in the literature yet. More specifically, we analyze the pricing strategies and equilibrium outcome for a differentiated Bertrand game assuming that consumers’ decisions are influenced by the prices of the last period. Based on the previous literature, one might expect that firms can exploit consumer bias to increase their revenues (see e.g. Kőszegi et al., 2014 or Wenzel, 2014), however, we claim that under certain circumstances anchors can benefit consumers and harm firms. As we show in this study, the presence of anchoring enhances the incentives of firms to cut prices, since setting the price below the reference price further increases the demand for their products. However, today’s prices are tomorrow’s reference prices and such a price cut has a negative effect in the long run. Obviously, firms could benefit from a high reference price, yet in a competitive environment, it would be too risky to set a high price because it hurts the firm’s own profit and benefits its rival. Thus anchors do not necessarily yield higher prices as one would expect based on the previous literature on consumer bias, but they can lead to fiercer price competition and eventuate in lower prices and lower profits. To our knowledge, such consequence of a consumer bias was not presented and discussed in the literature yet. In addition, we find that the existence of price anchoring has a bearing on cartel stability. Our results suggest that in the presence of anchoring, collusion is less likely since anchors may make it more profitable to deviate from the cartel price. This is because both the costs and the benefits of the deviation are altered by the presence of anchors while leaving the cartel profits unchanged. As it turns out, anchors lower the costs and increase the benefits of leaving the cartel which results in a lower level of cartel stability. This may have important implications for regulatory policy since it suggests that markets where price anchoring is more strongly present need less monitoring regarding collusions.",
17.0,3.0,"Journal of Industry, Competition and Trade",23 January 2017,https://link.springer.com/article/10.1007/s10842-016-0242-z,Industrial Policy to Develop a Multi-Firm Industry,September 2017,Tigran Melkonyan,Dwayne Banks,Jeanne Wendel,Male,Male,Female,Mix,,
17.0,3.0,"Journal of Industry, Competition and Trade",27 December 2016,https://link.springer.com/article/10.1007/s10842-016-0240-1,Fighting Capital Flight in Africa: Evidence from Bundling and Unbundling Governance,September 2017,Simplice A. Asongu,Jacinta C. Nwachukwu,,Unknown,Female,Unknown,Female,"Capital flight which is a consequence of the offshore financial economy is fundamentally traceable to poor governance (see Christensen 2011; Gankou et al. 2016). Notwithstanding the evolving stream of research on governance (Musila and Sigué 2010; Kangoye 2013) and capital flight (Mpenya et al. 2016; Ndiaye and Siri 2016), the literature remains unclear about how governance affects capital flight. Against this backdrop, the purpose of this study is to present a comprehensive assessment of the governance-‘capital flight’ nexus. For this purpose, we bundle and unbundle six governance indicators. The motivation for bundling governance indicators builds on evolving paradigms in the conception, definition and measurement of governance (see Asongu 2016). For instance, it is inappropriate to employ the term political governance unless the variable underlying the term is a composite measurement of ‘voice and accountability’ and political stability/non-violence. The inquiry is focused on Africa for two main reasons. First, the continent as a principal source of capital flight has experienced substantial levels of capital outflows over the past decades (Boyce and Ndikumana 2012a). According to the narrative, thirty-three Sub-Saharan African (SSA) countries lost about 814 billion US Dollars (in constant of 2010 US Dollar) during the period 1970–2010 (see Boyce and Ndikumana 2012a). This amount lost to the flight of capital surpasses official development assistance and foreign direct investment of respectively 659 and 306 billion US Dollars by the same countries in the sub-region during the same period. Shortage in financing has been documented to be the main cause of poverty and underdevelopment in Africa (see Bartels et al. 2009; Tuomi 2011; Boyce and Ndikumana 2012a; Darley 2012). The shortage of finance has hindered the socio-economic investment needed to alleviate extreme poverty. Accordingly, a recent report on attainment of the Millennium Development Goals (MDGs) by the World Bank has revealed that extreme poverty has been diminishing in all regions of the world with the exception of Africa, where 45% of countries in Sub-Saharan Africa were substantially off-track from attaining the MDG extreme poverty target (World Bank 2015). 
Second, contemporary African development literature on capital flight has failed to substantially capture the role of institutions in fighting the scourge. Accordingly, recent literature has focused on the lessons from case studies on the causes and consequences of capital flight (Ndikumana 2016), inter alia: the relationship between capital flight and fiscal policy (Muchai and Muchai 2016); determinants of capital flight in Madagascar (Ramiandrisoa and Rakotomanana 2016); trade misinvoicing and capital flight in Zimbabwe (Kwaramba et al. 2016); the nexus between capital flight and natural resources in Cameroon (Mpenya et al. 2016); public social spending and capital flight in Congo-Brazzaville (Moulemvo 2016) and linkages between capital flight and tax revenue in Burkina Faso (Ndiaye and Siri 2016). In the light of the above, this study complements the literature by investigating the incidence of governance on capital flight with particular emphasis on the bundling and unbundling of institutions. It is of policy relevance to use composite governance indicators because concepts of governance have been used in the literature without an all-inclusive measurement. For example, Kangoye (2013) has used ‘corruption-control’ as ‘governance’. Moreover, the concepts of institutional governance, economic governance and political governance have been employed in the literature without statistical validity (Kaufmann et al. 2007ab; Kurtz and Schrank 2007ab). We argue that it is inappropriate to employ the term ‘economic governance’ unless it translates an indicator that is composed of government effectiveness and regulation quality. We address this conceptual shortcomings by using nine bundled and unbundled governance indicators, namely: political governance (voice & accountability and political stability/no violence); economic governance (government effectiveness and regulation quality) and institutional governance (corruption-control and the rule of law). The rest of the study is structured as follows. Section 2 clarifies the concepts of governance and covers the theoretical underpinnings. The data and methodology are described in Section 3, while Section 4 presents the empirical results and related argument. Section 5 concludes with future research directions.",20
17.0,3.0,"Journal of Industry, Competition and Trade",06 December 2016,https://link.springer.com/article/10.1007/s10842-016-0237-9,"On the Middle Income Trap, the Industrialization Process and Appropriate Industrial Policy",September 2017,Murat A. Yülek,,,Male,Unknown,Unknown,Male,"Industrialization and industrial policy are back on the agendas of decision makers, academics and even journalists. Among developing economies, there is an intensifying but uneven interest in industrialization. China has become the world’s largest manufacturer and, together with South Korea, it houses some of the largest industrial corporations in the world. Countries like Bangladesh or Cambodia in Asia are starting an industrizalization cycle with the textile industry. In other developing countries, such as in Latin America and Africa, industrialization is less impressive and some even face “premature” deindustrialization. In the developed economies, the USA has increased its manufacturing value added over the last two decades (Peneder and Streicher 2016). It is the second largest industrial country in the world after China, and the size of its manufacturing value added is larger than the total GDP of countries like France or the UK. Other European nations, such as Holland and Switzerland, as well as Germany, are among the largest exporters in the world due to their industrial production. Industrialization is important for these countries because the manufacturing sector is recognized as the engine of growth, as Kaldor recognized, and because the majority of the world’s exports and imports mostly comprise manufactured goods. On the other side of the spectrum, many resource-poor nations of the world, including in Europe, face challenges in their industrialization processes. These challenges are reflected in different ways, such as falling into the so-called middle income trap or wide current account deficits. Industrial policy that consists of a set of different policy tools may be instrumental in accelerating the industrialization of challenged countries and rescuing them from the middle income trap. However, there is a disagreement on the merits of industrial policy as well as its tools, particularly sectoral (or traditional) industrial policies. There is also an increasing interest in science, technology and innovation (STI) policies in both developing and developed countries. This begs the question of how to sequence industrial and STI policies to attain the best development outcomes. This paper, in Section 2, attempts to explain critical features of the manufacturing sector and the industrialization process with a view to identifying specific roles for industrial policy. It also discusses critical skills and capabilities necessary for a successful industrialization process. Section 3 builds on the previous section to define the role of industrial policy and discusses sequencing issues covering industrial and STI (science, technology and innovation) policies. Importantly, it sets out a methodology for identifying strategic sectors that should be the priority of industrial policy. Industrial policy, after all, has budgetary and resource implications, and it is not possible to support all sectors at all times. The relevant literature lacks alternative analytical methods to identify strategic sectors that would yield high social returns as a result of policy. Thus, the industrial policy should have a methodology for allocating scarce public resources towards priority manufacturing sectors.",12
17.0,3.0,"Journal of Industry, Competition and Trade",19 January 2017,https://link.springer.com/article/10.1007/s10842-016-0239-7,Multilingualism and the International Patent System: an Assessment of the Fairness of the Language Policy of WIPO,September 2017,Michele Gazzola,,,Female,Unknown,Unknown,Female,"List of non-standard abbreviations: EPO (European Patent Office), EPC (European Patent Convention), International Bureau (IB), International Preliminary Report on Patentability (IPRP), International Search Authority (ISA), International Search Report (ISR), Korean Institute of Intellectual Property (KIPO), National phase entries (NPE), PCT (Patent Cooperation Treaty), Return on Fee Income Index (RFI), Representation Index (RI), Receiving Office (RO), WIPO (World Intellectual Property Organisation), Written Opinion (WO). The role of language policy in the area of Intellectual Property (IP) rights has remained relatively under-explored in the literature. The few existing contributions in this area focus most often on the estimation of translation costs to validate European patents granted by the European Patent Office (EPO),Footnote 2 or on the translation costs borne by applicants who enter into the national phase of the Patent Cooperation Treaty or PCT (WIPO 2008), which is administered by the International Bureau (IB) of the World Intellectual Property Organisation or WIPO.Footnote 3 Nonetheless, provisions determining the set of official languages of IP organisations and the related translation requirements (a.k.a. ‘language regime’ or ‘language policy’) do not affect exclusively the translation costs just mentioned. They also affect a whole range of language-related costs arising at different stages of the patenting procedures, from the moment in which a patent application is filed to opposition and appeal procedures. For example, applicants seeking IP protection may have to bear preliminary translation costs when they file an application with an IP authority if their working language is not one of the official languages of the authority concerned. The potential economic consequences of language regimes should not be underestimated. The language regime of the EPO, based on three official languages, namely, English, French and German, makes the average cost of accessing patenting procedures for European applicants whose first language is not one of these three languages at least 27% higher than the average cost borne by English-, French- or German-speaking applicants (Gazzola 2015). Besides, this generates the paradox that it is de facto cheaper for a US or Canadian company to file a European patent application with the EPO than it is for a Spanish or Polish inventor. Generally speaking, language policies, just as is the case for any type of public policy, are a form of regulation whose effects must be evaluated (Grin 2003). This article aims at contributing to the research in technological innovation and IP rights by discussing some links between language policy and patenting, focusing on the PCT system. There are ten official languages (or ‘languages of publication’) of the PCT system, i.e. Arabic, Chinese, English, French, German, Japanese, Korean, Portuguese, Russian and Spanish. The most recent reform of the language regime of the PCT happened in 2008, when Korean and Portuguese were included in the languages of publication. It is therefore useful to provide an evaluation of this change, by discussing its costs and its effects on fairness. In line with the literature on economics and policy analysis, there is no particular moral or ethical content in the notion of fairness (Just et al. 2004). Assessing fairness simply implies identifying the distributive effects of a policy, that is, who loses, who gains and (if possible) how much, and how the costs of alternative policies are shared among individuals or groups. The main contribution of this article is to identify and clarify the distributive effects resulting from the addition of Korean to the languages of publication of the PCT. This article is organised as follows: Section 2 briefly describes the language regime of the PCT. Section 3 presents some unpublished data on the use of languages in the PCT system, showing that innovation is more multilingual than is commonly believed. In Section 4, I explain the analytical framework, and I identify the costs and the distributive effects of the language policy of the PCT. In Section 5, such effects are estimated. Section 6 critically discusses the empirical results obtained. The last section summarises and concludes the article.",2
17.0,4.0,"Journal of Industry, Competition and Trade",04 January 2017,https://link.springer.com/article/10.1007/s10842-016-0241-0,"Environmental Policy, North-South Trade and FDI",December 2017,Juan Carlos Bárcena-Ruiz,María Begoña Garzón,,Male,,Unknown,Mix,,
17.0,4.0,"Journal of Industry, Competition and Trade",21 February 2017,https://link.springer.com/article/10.1007/s10842-017-0248-1,Inefficient but Robust Public Leadership,December 2017,Toshihiro Matsumura,Akira Ogawa,,Male,,Unknown,Mix,,
17.0,4.0,"Journal of Industry, Competition and Trade",04 January 2017,https://link.springer.com/article/10.1007/s10842-016-0243-y,Analysing the Impact of Regulation on Disruptive Innovations: The Case of Wireless Technology,December 2017,Dmitrii Trubnikov,,,Male,Unknown,Unknown,Male,"Despite the different views in Economics on the relationships between innovation and competition, some aspects seem pretty obvious and even trivial. The best incentives for innovation activity is the “the difference in profit that a firm can earn … compared to what it would earn” otherwise (Gilbert 2006). Opportunity to escape competition and gain a monopoly and, thus, to charge prices higher than the competitive level is one of the main driving forces of innovations.Footnote 1 Therefore, the conduct of a company that innovates is anti-competitive by its nature, but it does not mean that such behaviour is undesirable from the point of view of social interests and, thus, is not considered in such a way by antitrust policy.Footnote 2 What is really desirable is that competitors of the innovator also have opportunities to innovate and positively affect the innovative conduct of the leader. However, at this particular point the triviality of the problem disappears and we enter the field of different legal and economics concepts, tools and methods of dealing with issues related to allocation of exclusive privileges and antitrust investigations. The understanding that the aspiration of monopoly is the best incentive for innovation has moved the economics mainstream to the promotion of the idea that there are needs for government interventions that would provide exclusive rights for innovators. However, we can hypothesise that the market per se could be sufficient to the promotion of incentives for innovatorsFootnote 3 and, at the same time, could, possibly, make obsolete any needs to antitrust interventions. Therefore, it is quite risky to make conclusions that reasons for the victory of the leaders are their best business practices without paying attention to the fact that regulation played certain role in this superiority. For instance, antitrust authorities might investigate the conduct of a company that had, allegedly, abused their intellectual property rights, inducing the discussion about the validity of such suspicion, but they can not affect the core of the problem, since the privileges to exclude others are precisely the main intention of the institution of intellectual property. They can be trying to assess the potential harm to consumers after a merger of some significant market players, but it is difficult to take into consideration that the structure of this market had been already transformed to the oligopolistic form by the regulatory policy and the real market forces have not already played a noticeable role in the field. Dogan and Lemley (2008) notice these shortcomings of antitrust law when they point out that “threats to competition do not come only from private conduct in unregulated industries, … [but] also come from government regulation itself. … Where it is the state itself that decides upon an anticompetitive end, the antitrust laws have not intervened.” Meanwhile, the problem becomes more complicated when the task of antitrust investigation is not only to develop the theory of harm to consumers, but to understand how the opportunities of market participants for innovations might be harmed.Footnote 4 However, it should be noticed that innovations very often come to our life in completely unpredictable ways, and, thus, it might be merely impossible to assess the potential harm for innovations if even the source of such unpredictable innovations is uncertain. What is more important is that the real threat for innovations comes not only from the conduct of leaders, but from the legal frameworks that determine such conduct and protect positions of incumbents. One of the popular theories dedicated to innovations that appeared in the middle of the 1990s (Bower and Christensen 1995), and since that time has been embraced by many scholars, claims that “leading firms almost always triumphed in battles of sustaining innovation and that entrant firms typically beat the incumbent leaders when disruptive innovations emerged” (Christensen 2006). Disruptive innovation is one of those forces that can yield the real threats to established firms and “generates the kind of ‘creative destruction’ described by Schumpeter” (De Streel and Larouche 2015). Shelanski (2013) points out that due to the importance of creative destruction, the Schumpeterian approach, despite its arguments about the negative relation between competition and innovations, does not exclude antitrust interventions in the regulatory policy.Footnote 5
 Meanwhile, for established firms the best way to protect their positions is to capture the control over innovations, and here both kinds of innovations, sustaining and disruptive, are equally important to be controlled. In highly regulated industries, such as telecommunications, the “anticompetitive end” might be the result of regulatory activity, and the opportunities for disruptive innovations might be harmed by regulation. Since the source of the disruptiveness is not always certain, the possible response to the attempts to control the development and innovations in telecommunications industry is the placement of the crucial resources of the field in the realm of “commons”. Lawrence Lessig (2001) uses the similar idea when he talks about the control over the physical layer of a communications system. The problem is that the most of them by their economic nature are classic examples of private goods, since they are both rivalrous and excludable. Possibly, we could base some hypothesis on the enormous potential of the capacity of fiber-optic infrastructure, but since the access to this infrastructure has physical barriers, its exploitation in the way of an uncontrolled “physical layer” seems difficult. At the same time, the radio spectrum by its nature is “common good”, and it is quite possible that technological solutions might alleviate the problem of the rivalry of this good, and, thereby, transform it into the economic realm of “public goods”. Another crucial resource of telecommunications, that is also by its nature is non-rivalrous and non-excludable, is information and knowledge that are controlled by the incumbents through the institution of intellectual property. It is possible to assume that the mechanisms of control over these resources maintain the oligopolistic structure of the field and facilitate the development of the mainstream part of the industry. The purpose of this paper is to highlight the role of regulation in the suppression of disruptive innovations in telecommunications and to show that this process is explained not mainly by explicit actions of government in the interests of incumbents, but rather by the dependance on the path of joint evolution of regulation and the mainstream technology. In the beginning of the paper, I provide a brief analysis of disruptive innovations in telecommunications and distinguish WiMAX as a real life example of disruptive technology in the industry, explain this position and describe the economic model of the technology. Then I use this case to demonstrate that the failure of this disruption was determined by state interventions in market mechanisms that, eventually, did not allow to put into practice the economic model, and protected the established status quo of the area. In the final section I argue that the current paradigm, that justifies regulatory interventions, heavily depends on the previous way of interaction of regulation and technology, and it locks the evolution of the industry on the mainstream technology, protecting business interests of incumbents.",9
17.0,4.0,"Journal of Industry, Competition and Trade",06 March 2017,https://link.springer.com/article/10.1007/s10842-017-0244-5,Protective Excise Taxation,December 2017,Michele Santoni,,,Female,Unknown,Unknown,Female,"Excise taxes are often imposed in imperfectly competitive product markets (for example, alcoholic and non-alcoholic beverages, tobacco products, oil products and vehicles) in which home and foreign firms compete for domestic consumers. In such a situation, a domestic government can use specific consumption taxes under the destination principle (meaning that taxes are paid where the good is consumed) not only for raising revenue, but also for favouring domestic over foreign producers, especially in industries with dominant foreign firms. This strategic motive for excise taxation is likely to have become more important over the years, given that discriminatory trade and industrial policies are becoming harder or impossible to implement in the face of international trade agreements and anti-trust legislation. Moreover, as long as these policies are effective, domestic producers have potential incentives to lobby the government for protection by means of excise taxation. There is a lot of anecdotal evidence on the potential use of excise taxation as a protectionist device. For example, articles 95–97 of the European Community treaty prohibit a Member State from using internal taxes to discriminate between imports from other Member States and similar domestic goods. However, between 1957 and 1999 the European Commission brought before the European Court of Justice (ECJ) more than one hundred cases regarding national tax laws that were alleged to be discriminatory. For excise taxation to be considered protective by the ECJ, however, it is not sufficient that tax rates differ across similar goods. For example, in 2001 the EU Commission raised the issue of the protective use of excise taxation by Sweden. The EU was concerned for the higher excise tax rate imposed on wine, which is mainly imported, compared to beer, which is mainly domestically produced.Footnote 1 Sweden did not amend its tax law and in 2004 the Commission took it to court. In 2008, however, the ECJ ruled that the “different tax treatment of beer and wine in Sweden did not infringe Community law”. The ECJ pointed out that “the price difference between the two products is virtually the same before taxation as after it (a liter of wine of 12.5% vol. costing just over twice the price of a liter of beer). In that context, the Court finds that the Commission has not shown that the difference between the price of strong beer and the price of wine in competition with that beer is so slight that the difference in the excise duty applicable to those products in Sweden is likely to influence consumer behavior” (Europa Press Release n.23/08). However, high excise tax rates on wine could qualify as a “profitable cost increase” of the kind considered by Seade (1985) and Février and Linnemer (2004) among others. In this case, they could have benefitted fringe Swedish wine producers (meeting less than 1% of domestic demand in 2009), thus achieving effective protection in the wine industry. This paper will address the issue of protective excise taxation by presenting a model of a small open economy with an import-competing Cournot-Nash sector and a competitive export sector. The paper will show that, under some conditions, excise taxation in the import-competing sector may favour fringe domestic producers over dominant foreign producers. In such a situation, excise taxation may emerge endogenously in political-economy equilibrium with lobbying. More specifically, by assuming unit-elastic product demand curves, domestic union wage bargaining and a self-interested government, the paper derives the following main results. Firstly, provided that the typical domestic firm is sufficiently smaller-thus inefficient- than the typical foreign firm, a marginal increase in the excise duty lowers imports and raises domestic workers’ utility and home firms’ profits at the industry level (Proposition 1). This result implies that, depending on the initial foreign market share, taxes become a profitable instrument for protection, potentially inducing domestic producers to lobby for taxation. Second, when these conditions occur, the revenue-maximising tax rate is an increasing function of the degree of foreign penetration (Proposition 2). Finally, as long as the self-interested government is prepared to trade off tax revenue and political contributions, under some conditions industrial lobbying by firms and unions leads the government to set a higher tax rate than without lobbying, other things being equal (Proposition 3). The paper is organised as follows. Section 2 presents an overview of the related literature and of the main assumptions of this paper. Section 3 outlines a model of a two-sector small open economy in which the excise tax may become a protectionist device for the net import sector. Section 4 analyses the optimal tax rate a rational Leviathan government would choose had no lobbies existed. Section 5 considers the excise tax rate in equilibrium with lobbying by domestic producers. Section 6 discusses the model’s main assumptions. Section 7 concludes.",
17.0,4.0,"Journal of Industry, Competition and Trade",02 February 2017,https://link.springer.com/article/10.1007/s10842-017-0245-4,An Investigation of the Degree of Market Power in the Greek Manufacturing and Service Industries,December 2017,Chrysovalantis Amountzias,,,Unknown,Unknown,Unknown,Unknown,,
17.0,4.0,"Journal of Industry, Competition and Trade",10 February 2017,https://link.springer.com/article/10.1007/s10842-017-0246-3,"A Single Espresso, Please! Rationalizing Espresso Price Dispersion Across Italian Cities",December 2017,Flavio Delbono,Gemma Dipoppa,Carlo Reggiani,Male,Female,Male,Mix,,
18.0,1.0,"Journal of Industry, Competition and Trade",24 April 2017,https://link.springer.com/article/10.1007/s10842-017-0251-6,Manufacturer Mergers and Product Variety in Vertically Related Markets,March 2018,Chrysovalantou Milliou,Joel Sandonis,,Unknown,Male,Unknown,Male,"Mergers among final product manufacturers constitute a common business strategy. They take place in almost every market. For instance, in the mobile phone manufacturing market, Sony and Ericsson merged with each other, and so did Colgate-Palmolive and Sanex in the market of personal care goods, Oracle and PeopleSoft in the software programs market, and Panasonic and Sanyo in the electronics manufacturing market.Footnote 1
 One of the recent concerns of the U.S. antitrust authorities regarding manufacturer mergers is whether and how they alter the merged firms’ decisions regarding their product lines, and in turn, how they affect product variety in the market.Footnote 2 This concern has been explicitly expressed in the most recent U.S. Horizontal Merger Guidelines (2010), which state that the authorities should focus not only on the impact of horizontal mergers on cost-related efficiencies, but also on their potential impact on product variety. Furthermore, in the assessment of a number of merger cases, the U.S. antitrust authorities, have incorporated merger impact on product variety. For example, in 2003, the Federal Trade Commission (FTC) challenged the merger of Nestlé Holdings, Inc. and Dreyer’s Grand Ice Cream, Inc., in the super-premium ice cream market, citing that “the market for super-premium ice cream is already highly concentrated, and this deal will reduce the number of significant competitors from three to two” and it would “lead to anticompetitive effects... including less product variety and higher prices”.Footnote 3
 In this paper, we study the relationship between manufacturer mergers and product variety. A key novelty of our approach is that we consider a setting where manufacturers operate in a vertically related market, i.e., in a market where the production and the distribution of products are undertaken by different firms that operate at distinct market levels. In such a setting, a manufacturer merger can affect not only the number of products offered in the market but also the terms of vertical trading, which, in turn, can determine the efficiency of the distributors - retailers and the final prices. Our purpose is to address a number of fundamental questions of both theoretical and practical importance, such as: How are the investments in new product introduction affected by the intensity of market competition? What is the relationship between product variety and the terms of vertical trading? Does a manufacturer merger alter the investments in product introduction? If so, how? Does a manufacturer merger harm consumers and decrease welfare? To address the above, we construct a framework in which two upstream manufacturers initially produce two horizontally differentiated goods, which they distribute to consumers through two competing multiproduct retailers.Footnote 4 Manufacturers decide, first, whether they will merge, and second, whether they will introduce additional products into the market after incurring the respective fixed costs. Next, manufacturer(s) set the wholesale prices of their products and, in turn, the retailers choose their quantities. In order to examine the role of vertical relations and the potential importance of accounting for them and for vertical trading in the analysis of the merger implications, we also analyze the benchmark case in which manufacturers operate in a one-tier market, i.e., they sell directly their products to consumers. The introduction of a new product into the market gives rise to two opposite effects, regardless of whether manufacturers have merged or not and of whether they operate in a vertically related market or in a one-tier market. First, by increasing product variety, product introduction expands the market size. We refer to this positive effect as expansion effect. Second, product introduction causes a negative cannibalization effect: the new product that a manufacturer introduces steals away demand from its already existing product(s). Besides these effects, product introduction also gives rise to a competition effect when the manufacturers remain separated. This effect corresponds to the intensification of competition among the manufacturers that results from the fact that the new product competes against the product(s) of the rival manufacturer. Therefore, product introduction can bring about, on the one hand, the gains of increased demand, and on the other hand, the losses of increased competition (either intrabrand alone or both intrabrand and interbrand). We demonstrate that when the manufacturers do not sell directly their products to consumers, product introduction causes a decrease in the wholesale prices. This effect - the wholesale pricing effect, however, is present only when the manufacturers remain separated. When they are merged, there is an “indifference result”: the number of products has no impact on the wholesale prices. Intuitively, in the non-merger case, product introduction, by causing the competition effect, reinforces the incentives of each manufacturer to behave more aggressively and lower the wholesale prices of its product(s). This does not occur in the merger case, since the merged manufacturers fully internalize the competition effect. In both the merger and the non-merger cases though, the wholesale prices exceed the manufacturer’s marginal cost of production; hence, neither the industry profits are maximized nor the manufacturers manage to fully appropriate them. Not surprisingly, the wholesale prices can be affected not only by product variety, but also by the upstream market structure. In particular, we demonstrate that the wholesale prices are higher when the upstream merger materializes. In other words, double marginalization is more severe then. This result is a straightforward implication of the fact that, as mentioned above, the merged manufacturers internalize the externality that they would otherwise impose on each other by offering lower wholesale prices in order to promote their products against the products of their rival. Importantly, our analysis reveals that a manufacturer merger can affect product variety. In fact, we show that product variety increases when manufacturers merge as long as products are sufficiently close substitutes and the investments in product introduction are not too costly. Why is that? The merger allows the manufacturers to extract a higher share of the industry profits, through the higher wholesale prices, as well as to internalize the competition effectwhich is strong when products are not too differentiated. When, instead, products are sufficiently differentiated, product variety can be higher in the non-merger case. This occurs not only because the negative competition effect is weak then, but also because the manufactures overinvest in product introduction, being trapped in a prisoners’ dilemma situation. The presence of vertical relations is crucial for the emergence of the product variety related merger induced efficiencies: in markets in which the manufacturers sell directly their products to consumers, product variety is never higher when the manufacturers are merged. This is so because in such markets, in contrast to what happens in vertically related markets, there are no wholesale prices and the manufacturers fully capture the profits that arise from their production activities. As a consequence, in one-tier markets, the wholesale pricing effect is absent and the manufacturers do not capture a larger share of the industry profits by merging. It follows from this that the exclusion of vertical relations in the analysis of manufacturer mergers could result in different policy implications. A manufacturer merger, although it can enhance product variety in a vertically related market and increase the manufacturers profits, it hurts the retailers and the consumers, and reduces total welfare. In other words, the increase in the severeness of the double marginalization problem always dominates the merger’s potential product variety induced synergies. Clearly, this suggests that in cases in which the merger enhances market power significantly, the merger induced product variety synergies cannot be used as an argument in favor of the merger in its evaluation by the antitrust authorities. Our prediction that a manufacturer merger can affect the number of products in the market seems to accord well with a number of empirical studies. In particular, Alexander (1997) and Watson (2009), studying respectively the music distribution industry and the eyewear retailing market, find a non-monotonic relationship between concentration and product variety. George (2007), instead, in her study of the U.S. daily newspapers market, concludes that more concentrated markets tend to have more variety both in terms of the number and of the variety of topics covered. Focusing on the issue of product variety in response to a merger, Berry and Waldfogel (2001) find that mergers in the U.S. radio broadcasting market prompted an increase in both variety per station and overall variety. In contrast, according to Gotz and Gugler (2006) and Fan (2013) mergers in the Austrian gasoline market and in the U.S. daily newspapers market caused a decrease in their product variety. Although the empirical evidence indicates that mergers can affect product variety, the existing theoretical work on horizontal mergers has little to say about this. The standard merger theory focuses almost exclusively on horizontal pricing effects (e.g., Reynolds et al. 1983; Davidson and Deneckere 1985) and/or on cost related efficiencies (e.g., Farrell and Shapiro 1988; Perry and Porter 1985).Footnote 5 A notable exception is the paper of Lommerud and Sørgard (1997) which studies how a merger affects firms’ decisions regarding the expansion of their product lines. Specifically, Lommerud and Sorgard consider a market with three firms that produce differentiated goods. They assume that each firm initially offers one product and that there is a fixed non-sunk cost of marketing a brand. They find that whenever a merger among two firms is profitable, it either has a negative impact or no impact at all on product variety and that it is often detrimental to welfare. When instead the merger triggers the introduction of a new product by the outsider and, thus, causes an increase in the product range, the merger is unprofitable. Another exception is a recent paper by Chen and Schwartz (2013), who consider mergers to monopoly and assume that initially only a single product is offered by all the market participants.Footnote 6 They find that when product introduction is not too drastic, the incentives to innovate are stronger when the merger takes place, and subsequently, that consumer welfare and overall welfare can be higher under monopoly than under more rivalrous regimes.Footnote 7 Importantly, all the above mentioned papers consider only one-tier markets. Therefore, in contrast to us, they do not take into account the fact that product manufacturers often do not sell directly their products to consumers. By not doing so, clearly, they do not explore the role of vertical relations and trading for the merger implications on product variety. Our paper contributes to the recently growing literature on horizontal mergers in vertically related industries. Horn and Wolinsky (1988), Ziss (1995), O’Brien and Shaffer (2003), Inderst and Wey (2003), Froeb et al. (2007), Milliou and Petrakis (2007), and Milliou and Pavlou (2013), similarly to us, study mergers in the upstream market.Footnote 8 Within this literature, only Milliou and Pavlou (2013) analyze the potential efficiency gains of upstream mergers. However, Milliou and Pavlou (2013) consider a market with exclusive relations pre-merger and cost-related efficiency gains. We complement their work by using a less restrictive market structure, and importantly, by analyzing product variety induced efficiency gains of upstream mergers. The only papers that, to the best of our knowledge, consider product variety issues within the literature on horizontal mergers in vertically related industries are the papers by Inderst and Shaffer (2007) and Fauli-Oller (2008), which focus though on downstream mergers and not on upstream mergers. Both of these papers demonstrate that a merger among retailers allows them to commit to not selling one of the goods supplied by manufacturers, and thus, that such a merger can result in a welfare-detrimental decrease in product variety. These papers differ from ours not only because of their different focus, but also because in their setting there is no product introduction; the number of products manufactured by the upstream firms is exogenous and the downstream firm(s) choose how many of them they will distribute.Footnote 9
 The rest of the paper has the following structure. In Section 2, we describe our model. In Section 3, we perform the equilibrium analysis. In Section 4, we examine the merger implications on the wholesale prices and on product variety. In Section 5, we explore the merger incentives and merger impact on retailers, consumers and welfare. In Section 6, we discuss the role of vertical relations. Finally, in Section 7, we conclude.",7
18.0,1.0,"Journal of Industry, Competition and Trade",29 March 2017,https://link.springer.com/article/10.1007/s10842-017-0250-7,"Horizontal and Vertical Firm Networks, Corporate Performance and Product Market Competition",March 2018,Oliver Bischoff,Achim Buchwald,,Male,Male,Unknown,Male,"In this paper we study the effects of horizontal and vertical firm networks via multiple directorships on corporate firm performance and examine whether the potential relationship is affected by the intensity of product market competition. The causes and effects of director firm linkages have been widely debated by the public, political decision-makers but also in academic research, in particular in the field of finance and corporate governance. The relevance of this issue is also highlighted by recent prominent business cases. For instance, on August 29th, 2006 Apple Inc. appointed the incumbent CEO of Google Inc., Eric Schmidt, to its board of directors.Footnote 1 Following the announcement Eric Schmidt was supposed to contribute to Apple’s innovativeness by providing his industry-specific insights and experience. Indeed, three years later in August 2009, Eric Schmidt resigned from Apple’s board of directors. In the press release, Apple explained that increasing rivalry between both firms in the market for operating systems intensified potential conflicts of interest.Footnote 2 The Eric Schmidt case clearly illustrates motives to establish respective director firm linkages and possible consequences which have been discussed exhaustively but still controversially in the theoretical and empirical literature (e.g. Adams et al. 2010; Mizruchi 1996). From an institutional perspective the formation of interlocks can be motivated by the establishment of intended relationships between firms. Building on resource dependence theory, board interlocks may facilitate coordination and an exchange of information between supplier-customer relationships of up- and downstream firms (Pfeffer 1992). Similar, director linkages within the same industry allow firms to share internal or industry-specific information or to coordinate strategic decision-making, for example regarding investments in new products or technologies (Grant and Baden-Fuller 2004). Focusing on an individual perspective, researchers are interested in the specific individual characteristics of outside directors with multiple mandates. For instance, outsiders may be selectively co-opted to a board to improve monitoring or advising capacities as these directors provide scarce knowledge and expertise and respectively increase the human capital of the board (Grant 1996a; Kor and Sundaramurthy 2009). Firms might also realize reputation benefits through the appointment of well-known and proven managers (Fahlenbrach et al. 2010). Indeed, observations from business practice and theoretical considerations also point to a negative assessment of outside directors on the board. For instance, multiple directorships may be associated with conflicts between the aims and objectives of the linked firms (Dittmann et al. 2010). Further, outside directors might have incentives to maximize individual benefits preventing them to spend sufficient effort to monitoring and advising responsibilities (Conyon and Read 2006). In the present study we aim to shed new light on the assessment of the effects of firm networks via outside directorships by (1) distinguishing between horizontal linkages within the same industry and vertical linkages between up- and downstream firms and (2) taking account of the moderating role of product market competition. To do so, we build on a comprehensive balanced panel of interlocking directorships between 833 different firms in 17 Western European countries in the period 2003 to 2011 with 7497 firm-year observations and use a sophisticated measure of product market competition based on industry-specific Lerner indices. We apply the system GMM estimator to address potential endogeneity of the explanatory variables and find that the number of linkages to other firms in the network has no significant effect on financial corporate performance. When we distinguish between linkages within the same industry and vertical connections the results show a negative influence on performance. However, we find a significant and positive relation between the number of horizontal linkages and competition intensity. This finding highlights the moderating effect of product market competition: in industries with relative high competition connections via multiple directorships seem to be a beneficial mechanism to gain competitive advantages. The interaction term of vertical linkages and competition has indeed no significant effect on firm performance. Based on these findings, several conclusions can be drawn. First, although inter-firm connections hamper firm performance, product market competition subsequently compensates for this negative effect. In situations of fierce competition firm networks via multiple directorships seem to be an important mechanism to exchange knowledge and to gain (information) advantages. Second, only horizontal linkages seem to be crucial in terms of corporate performance implying that information gained by multiple directorships is more valuable when transactions are related to the same market compared to vertical or conglomerate relations. It could therefore be concluded that multiple directorships also function similarly to tacit collusion. The remainder of this paper is organized as follows: Section 2 presents the literature review and summarizes the aims of the study. Section 3 describes the data sample and the empirical method. Section 4 discusses the results, and Section 5 concludes and gives an outlook on further research in the field.",3
18.0,1.0,"Journal of Industry, Competition and Trade",24 February 2017,https://link.springer.com/article/10.1007/s10842-017-0249-0,Is the Retail Gasoline Market Local or National?,March 2018,Michal Kvasnička,Rostislav Staněk,Ondřej Krčál,Male,Male,Male,Male,"A proper geographic delineation of retail gasoline markets may be crucial for competition authorities if they need to define relevant markets. In merger cases, competition authorities usually acknowledge that there is a local element to the retail fuel market, but the effects of the proposed mergers on concentration are typically assessed from a national perspective. For example, the European Commission defined the market as national in cases No COMP/M.3516 - Repsol YPF/Shell Portugal, No IV/M.1383 – Exxon/Mobil, and No COMP/M.5005 - Galp Energia/ExxonMobil Iberia. The EC supported these decisions with several arguments. First, the catchment areas of the service stations overlap, which creates a “chain-reaction” effect on more distant stations. Moreover, many parameters of competition in the supply side, such as products, quality, advertising, and pricing, are decided at the national rather than the local level. In addition, the price is strongly influenced by excise and value-added taxes, which are also set at the national level. On the other hand, the argument for a local perspective in merger assessment could be based on the fact that consumers usually consider only a handful of geographically close service stations, which means that the stations compete locally. Therefore, it is important to examine whether the concentration effect of mergers should be dealt with at a local rather than a national level. This paper uses price and location data from the Czech retail gasoline market to identify the impact of local station density on prices of individual stations. In this way, we provide some evidence on whether the gasoline retail market is local or national. If the relevant market is local, an additional station has a negative effect on the price charged by a station, and that effect decreases with distance to the station. On the other hand, if the relevant market is national, as the European Commission suggests, the effect of station density on prices should be independent of the distance. Many studies measure the effect of local station density on prices, but they set the size of the local market arbitrarily, either by using a specific distance around each station (Shepard 1993; Hastings 2004; Barron et al. 2004; Hosken et al. 2008; Pennerstorfer 2009), political boundaries such as municipalities or districts (Sen 2003, 2005; Clemenz and Gugler 2006), or specific commuter routes (Cooper and Jones 2007). This arbitrary choice of relevant market boundaries is problematic if the aim is to study local effects in gasoline retail. Instead of imposing ad-hoc boundaries on markets, we calculate the number of competing stations in several driving-distance ranges around each station. In this way we can find out more about the local forces in the gasoline market. Our analysis shows that an additional station has a negative effect on prices. The size of the effect decreases over distance and is consistently statistically significant only at distances below six kilometers. These findings suggest that the gasoline retail market is local rather than national. The rest of the paper is organized as follows. Section 2 discusses why the gasoline market is suitable for a study of local competition and provides a short characterization of the Czech gasoline retail industry. Section 3 presents the data, discusses the empirical strategy, and defines the variables. Section 4 reports the results of the regression analysis. Section 5 presents various robustness checks. Section 6 concludes. The theoretical model that motivates the research is in Appendix A.",7
18.0,1.0,"Journal of Industry, Competition and Trade",09 March 2017,https://link.springer.com/article/10.1007/s10842-017-0247-2,"Incentives and Impacts of Vertical Coordination in a Food Production-Marketing Chain: A Non-cooperative Multi-Stage, Multi-Player Analysis",March 2018,Jebaraj Asirvatham,Sanjib Bhuyan,,Unknown,Unknown,Unknown,Unknown,,
18.0,1.0,"Journal of Industry, Competition and Trade",22 May 2017,https://link.springer.com/article/10.1007/s10842-017-0253-4,"A Note on Vertical Differentiation of Durable Goods: Sellers, Renters and Moral Hazard",March 2018,George Geronikolaou,,,Male,Unknown,Unknown,Male,"Moral hazard in rental markets has been well acknowledged. In a vertical differentiation duopoly framework this paper shows that moral hazard affects strategic firm behavior and may benefit renters by raising the strategic effect of leasing low durability goods. In a typical leasing oligopoly such as the car rental industry, the profit enhancing effect of neglect implies that low budget car renters do not have an incentive to carefully screen their customers or inspect the returned cars. However, I show that when there is no moral hazard, the distinction between sellers and renters is not substantial in terms of durability levels, profits and consumer welfare. The literature on durable goods starts with Swan (1970) who shows that a firm’s equilibrium durability choice is independent of industry structure. Under constant returns to scale, efficient durability is such that the discounted production cost is minimized and is not influenced by the firm’s production level. Bulow (1986) shows that Swan’s theorem holds only for rental markets due to the sellers’ dynamic consistency concerns. Sellers cannot commit to prevent the decrease in the value of the stock of already sold goods, caused by the new production and new price at each subsequent time period (Coase, 1972). Sellers’ dynamic consistency problem is easier to understand under the standard assumption that there is a secondhand market where buyers can resell the units they bought at the prevailing price (Bulow, 1982). Buyers anticipate the possibility of resale, and adjust their demand accordingly. Goering (1992) examines Cournot competition between renters and shows that the optimal durability is still equal to the monopolist renter’s durability and thus, independent of market structure and production level. Saggi and Vettas (2000) show that in durable goods Cournot oligopolies in which firms sell and lease at the same time, high-cost firms lease more than low-cost firms. The literature on moral hazard problems is quite lengthy. However, this paper is mostly related to Goering (1997) who introduces theoretically the possibility of moral hazard in monopoly rental markets where he demonstrates that it may induce a monopoly renter to produce lower durability goods than a seller. Empirically, Schneider (2010) documents the effects of moral hazard in the New York taxi-leasing industry. In this paper competition between durable goods firms (either sellers or renters) is modeled by means of a dynamic two-period vertical differentiation Bertrand game, based on the famous model of Gabszewicz and Thisse (1979) as presented by Tirole (1988). The seller’s dynamic consistency concern that exists in the monopoly case or the Cournot competition is also present in Bertrand competition. Sellers will compete for their second period prices ignoring the reduction in the value that their competition will cause to the already sold units. This stems from the fact that the value of the stock of previously sold goods depends on each period’s new production and price. Assuming that a secondhand market exists, first period buyers will anticipate the second period’s price and will adjust their willingness to pay accordingly. The model assumes that renters face a moral hazard problem due to the possible neglect of rented units by the consumers. The introduction of moral hazard does not affect durability choices because the maximal differentiation principle will apply anyway, implying that one of the firms chooses the lowest possible durability and the other the highest. Firms will react to the possible neglect of their goods by raising rental prices to compensate for expected damages on the rented units. However, moral hazard induces a strategic advantage for the low durability renter by increasing its profits. In the absence of moral hazard, each renter’s profits are exactly equal to the corresponding seller’s profits, although rental prices are, as expected, lower than selling prices. Without moral hazard consumer surplus is also identical in the two games.",
18.0,1.0,"Journal of Industry, Competition and Trade",18 April 2017,https://link.springer.com/article/10.1007/s10842-017-0252-5,Contract Enforcement and Trade,March 2018,Azmat Gani,,,Male,Unknown,Unknown,Male,"This paper examines the effect of contract enforcement on trade in a large sample of developing countries. Available statistics reveal that several countries around the world have been expanding their trade reach with the aim of greater participation and integration in the global trading environment. For example, at the inception of General Agreement on Tariff and Trade (GATT) in 1948, there were 23 founding members and as of 30 November 2015, there were 162 members of the World Trade Organisation. In terms of growth in trade, merchandise exports grew by 6% annually in the past 50 years and the total trade in 2000 was 22 times the level of 1950 (World Trade Organisation, WTO, www.wto.org/english/thewto-e/whatis-e/brief-e/inbro1.r.htm). One aspect of global trade that is likely to influence the trade integration process is the pace of enforcement of contracts as it is now well known from the institutional economics perspective that market based economic activity cannot succeed unless appropriate institutions that support this are in place (Rodrik 2007). At the same time, it is the quality of institutions (law and order; property rights; contracts; independence of the courts; low corruption and cronyism; and traditions of civic responsibility) that are equally fundamental to the effective functioning of markets (Williamson, 1975 and Williamson 2002; and North 1990, 2005). For countries to fully integrate in the world economy and to benefit from outward oriented trade strategies, the functioning and quality of institutions are important as reliable institutions are found to play an important role in shaping international trade between countries (Ranjan and Lee 2007; De Groot et al., 2004 and Gani and Scrimgeour 2016). Undeveloped and inefficient institutional structure such as poor enforcement mechanisms cannot facilitate productive cooperation (Olson 1996) and can be an obstacle to trade. It is known that poor institutional quality particularly in the low-income countries contributed to lower trade volumes (Francois and Manchin, 2013). Poor enforcement of law can constitute additional costs to trade (Anderson and van Winccoop 2004) and imperfect enforcement of contracts reduces the volume of trade (Ranjan and Lee 2007). On the contrary, sound contract enforcement and an effective legal system can enhance the export activities of firms (Yue, Qu and Zhang, 2010). For enforcements to be effective, the role and the efficiency of the wider judicial system, including the courts, is also fundamentally important. For example, according to the Doing Business Report 2014 (www.doingbusiness.org), the efficiency of the courts has a direct effect on contract enforcements with great variations noted around the world (Fig. 1). Figure 1 depicts the trend in time taken to enforce a contract in the low, middle and high-income countries for the period 2003–12. It is obvious from Fig. 1 that in 2013, in the high-income OECD countries, it took 500 days to enforce a contract whereas in the low and middle-income countries; it took around 600 to 700 days to enforce a contract. This divergence in the time taken to enforce a contract can have regressive effects on trade between different countries. The range in terms of time taken to enforce a contract reveals large gaps. The Doing Business Report 2014 notes that of the 189 countries surveyed in 2013, contract enforcement can take less than 10 months in New Zealand and Norway but about four years in Bangladesh. Time required enforcing a contract. Source of data for Fig. 1: The World Bank (2014) The little variation in contract enforcement overtime as revealed in Figure 1 also indicates that low and middle income countries slower pace of reforms that can make it easier to enforce contract as opposed the countries in the high-income category. One of the policy implications for the countries in the low and middle-income category is to engage in re-organizing their judicial systems through the introduction of specialised commercial courts, regulation of attorney fees, adoption of automated systems and streaming judiciary administrative procedures. The costs of contract enforcement can also matter for trade among other things. Figure 2 depicts the pattern of contract enforcement costs across different regions of the world. According to Fig. 2 there are wide variations in the costs of contract enforcement across the world. For example, the cost of enforcement ranges from 21% of the value of the claim in the high-income OECD economies to just over 51% in Sub-Saharan Africa (Fig. 2). Much of the cost is attributable to attorney fees to try cases and enforce judgements. Cost of contract enforcement in 2013. Source of data for Fig. 2: The World Bank (2014) Studies comprehensively investigating the direct effects of enforcement on trade in the developing countries with an empirical focus are sparse. Given the importance of contract enforceability in business transactions and in the process of trade integration, an issue that deserves much attention is whether or not it directly facilitates more trade and remains an important empirical question. With this view, the purpose of this paper is to examine if contract enforcements matter for trade. Augmented equations of exports and imports are estimated that incorporates cross-country annual data for a large sample of developing countries. In testing this effect, the empirical methodology incorporates three different measures capturing contract enforcement. These are: the time required to enforce a contract (days); the costs to enforce a contract (including court costs, enforcement costs and attorney fees); and the number of procedures required enforcing a contract. The study uses the panel corrected standard errors (using covariance matrix) method of estimation. This paper’s contribution to the trade and institutional economics literature is unique as it attempts to use three new numerical measures of contract enforcement and test their effect on trade. This issue is worth investigating in as the findings of this study can give new direction in terms of institutional policy reforms that can facilitate more trade for the developing economies. This paper makes a new contribution to the study on the effects of contract enforcement on trade across a large sample of countries and complements past important theoretical studies such as Anderson and van Winccoop (2004); Ranjan and Lee (2007); Anderson (2009) and Moenius and Berkowitz (2011). The paper is organized as follows. The next section presents a literature review and the conceptual framework. Section three presents the empirical model and discusses the estimation method and findings. Section four concludes.",
18.0,2.0,"Journal of Industry, Competition and Trade",09 June 2017,https://link.springer.com/article/10.1007/s10842-017-0254-3,The Turnover of Market Leaders in Growing and Declining Industries: Evidence from Japan,June 2018,Yuji Honjo,Noriyuki Doi,Yasushi Kudo,Male,Male,Male,Male,"Many, but not all, managers are concerned about their firms’ ranking at the top of the markets in which they operate (e.g., Geroski and Toker 1996). Some managers make decisions in order to perform well relative to their competitors, while paying attention to their market shares, rather than profits. This is partly because profits are difficult to forecast or because a focus on profits may lead to a short-term orientation at the expense of long-term considerations (e.g., Armstrong and Collopy 1996). By gaining higher market share, firms can exploit market power and have competitive advantages in the industry. Hence, sustaining a leadership position is considered to be one of the key managerial objectives for market leaders. If a market leader holds a competitive advantage, the ranking of market shares will be stable in the industry. Conversely, if a competitor against a market leader creates a breakthrough product, the ranking of market shares will be vulnerable in the industry. Therefore, we can say that the ranking of market shares reflects the degree of competition in the industry. In this respect, a change in the ranking of market shares not only attracts managers, but also provides useful information on the dynamics of the competitive process for policy makers. From the perspective of competition policy, much attention has been paid to how to examine the factors affecting competition in industries. To identify the degree of competition, scholars have proposed some indices for market mobility.Footnote 1 Traditionally, the n-firm concentration ratio and the Hirschman–Herfindahl index (HHI) have been regarded as measures of market mobility. However, these indices ultimately tend to be static and ignore the dynamics of the industry because they simply provide a snapshot of market share distribution. More specifically, market mobility may appear high, even though the concentration ratio is high. Indeed, the market shares of oligopolistic firms, which compete with each other fiercely, can change, even in highly concentrated industries. Therefore, further research is needed to explore how to measure market mobility and to identify the factors affecting the dynamics of the competitive process at the industry level. This article explores the turnover of market leaders in the manufacturing and information and communications (ICT) industries in Japan. We propose indices for market mobility by focusing on the turnover of market leaders and examine how the likelihood of the turnover of market leaders differs across industries. We provide evidence that market leaders are more likely to be replaced by competitors in growing and declining industries, relative to industries where the growth is more stable. Moreover, the results reveal that the turnover of market leaders is more likely to occur in research and development (R&D)-intensive industries. Furthermore, the interaction effects of industry growth and concentration indicate that the turnover of market leaders is more likely to occur in declining industries with high concentration. The remainder of the article is organized as follows. The following section discusses how to measure market mobility and reviews the literature on this topic. Section 3 introduces the method used in this article and Section 4 describes the data and variables. The estimation results are presented in Section 5. Finally, the findings of this article are concluded.",
18.0,2.0,"Journal of Industry, Competition and Trade",23 June 2017,https://link.springer.com/article/10.1007/s10842-017-0255-2,Did the Demand for Crestor Shrink when Lipitor’s Patent Expired?,June 2018,David Zimmer,,,Male,Unknown,Unknown,Male,"Crestor is a cholesterol-lowering drug belonging to the larger class of statin medications. Introduced in 2003 by AstraZeneca, Crestor quickly grew in popularity, reaching global sales of $6.6 billion in 2011.Footnote 1 At that time, with patent protection set to last until 2016, Crestor appeared positioned to maintain its status as a top seller for at least the next half decade. Yet Crestor’s market success faced a threat, albeit an anticipated one, in November, 2011, when the patent of Crestor’s main competitor, Lipitor, expired. With name-brand statins costing approximately $160 per month, the loss of Lipitor’s patent protection was projected to see the introduction of generic versions priced at nearly $30 per month.Footnote 2 Cam Patterson, chief cardiologist at University of North Carolina-Chapel Hill, predicted in an interview with USA Today, ""The market for Crestor will go close to zero."" Concerns about Crestor’s market position were amplified by a widely-publicized medical study released in 2011 indicating that Crestor and Lipitor are equally effective at reducing “bad” low-density lipoprotein (LDL) cholesterol and raising “good” high-density lipoprotein (HDL) cholesterol (Nichols et al. 2011). The same study also attests to the comparable safety of the two drugs. For those reasons, many commentators predicted the inevitable brand erosion of name-brand statins like Crestor (Kidd 2006). Yet, contrary to expectations, and also contrary to previous research on the effects of expiring patents (Emerton 2006; Puig-Junoy 2007; DeRuiter and Holston 2012),Footnote 3 Crestor’s demand does not seem to have collapsed following the expiration of Lipitor’s patent. Using the reported number of Crestor prescriptions in the Medical Expenditure Panel Survey, and adjusting for person-level sample weights in each year, Fig. 1 shows the approximate total number of Crestor prescriptions, by year, in the U.S., with the triangles indicating years following the expiration of Lipitor’s patent. Although Crestor prescriptions show a slight dip in 2012 and 2013, the figure does not point to any large collapse in the market for Crestor. Corroborating the numbers in the figure, a report by the Wall Street Journal found that, in 2013, two years after the expiration of Lipitor’s patent, Medicare Part D spent 2.22 billion dollars, alone, on Crestor. That dollar amount represented approximately 2.1% of Medicare Part D’s total drug spending during that year. In fact, Crestor was Medicare’s third most costly drug that year, topped only by Nexium (heartburn) and Advair (asthma).Footnote 4 Consequently, Crestor appears to have weathered the competitive threat of inexpensive, generic Lipitor, and, in fact, has by some measures flourished. Crestor Prescriptions, by year. (Triangles indicate years following the expiration of Lipitor’s patent) This paper uses micro-level data from the Medical Expenditure Panel Survey to investigate the demand for Crestor at the individual level. The main empirical question is this: Following the expiration of Lipitor’s patent, did patients predisposed toward high cholesterol reduce their usage of Crestor? In seeking to answer that question, this paper employs both event study and difference-in-difference methods. The event study approach provides information on shifts in the overall market for Crestor, while the difference-in-difference method informs upon whether subjects who already used Crestor changed their consumption patterns following the expiration of Lipitor’s patent. This paper produces several findings. Among subjects ever diagnosed with high cholesterol, the expiration of Lipitor’s patent does not appear to have significantly affected the overall market for Crestor. However, patients enrolled in private insurance do appear to have reduced their Crestor usage by about 13%. Medicaid patients who used Crestor prior to the change in Lipitor’s patent status also appear to have reduced their Crestor usage by a relatively sizable amount. Finally, the expiration of Lipitor’s patent appears to have resulted in an 18% increase in the strength of a typical Crestor pill, which might be interpreted as a de facto price decrease for Crestor. From a public policy perspective, these findings indicate that Medicare drug plans, by failing to encourage patients to switch from Crestor to cheaper generic alternatives, have missed opportunities to cut total drug spending. Such cost-cutting measures likely will take on added urgency due to the development of injectable cholesterol-lowering medications known as PCSK9 inhibitors. Entering the market in 2016 under the brand names Praluent and Repatha, this new class of drugs, aimed at patients whose cholesterol levels do not respond to standard statins, will have an initial wholesale cost of $1200 per month, significantly more expensive than even name-brand statins.Footnote 5 That widely-reported price already has generated discussions about the drug’s potential impact on publicly-funded insurance programs.",1
18.0,2.0,"Journal of Industry, Competition and Trade",24 July 2017,https://link.springer.com/article/10.1007/s10842-017-0256-1,Exchange Rate Pass-Through and the Role of Market Shares,June 2018,Michael Malenbaum,,,Male,Unknown,Unknown,Male,"The primary objective of this work is to determine the relationship between exchange rate pass-through and trade partners’ shares of the United States’ import market. The reasons for understanding pass-through to import prices relate to the connection between import prices and the overall price level of the US as a whole, as well as the role of the Federal Reserve to adjust monetary policy accordingly. Since import prices play a role in an open economy’s overall price level, the degree to which exchange rate fluctuations are passed on to prices can directly impact the inflation rate of an importing country. On the other hand, since monetary policy is often linked with expected inflation, understanding and anticipating changes in pass-through rates can allow for more effective policy. High pass-through to import prices could possibly result in currency devaluations improving the trade balance, as higher prices of imports lead to increased demand for domestic goods. If a foreign country controls a larger share of the import market for a good, then in theory firms in that country have greater ability to respond through pricing methods, and in turn have greater effect on the overall import market. Alternatively, an exporter with a smaller share has less freedom in terms of response. By analyzing the relationship between an exporter’s market share of a good and the pass-through for that good, we can gain a better understanding for which industries and which exporters drive these relationships. I motivate this analysis with a simple, static model of two foreign countries exporting a single good to a host country. Such a model shows how the countries respond to changes in exchange rates and how this behavior differs depending on the size of each country’s share of the host country’s import market for the good. I find that the general relationship between pass-through and market share is a skewed U-shape, with pass-through being greatest when shares are very large or very small. This model predicts the country holding the larger share will have the lower pass-through rate of the two competitors. Empirical tests of the model are based on quarterly observations of US imports at the ten-digit Harmonized System level, as well as bilateral exchange rate and price data from 233 exporters from 1990 through 2005. Using such highly disaggregated data, I find several results on pass-through rates across market shares. First, exporters with market shares at the extreme high and low ends tend to have higher pass-through rates, though this effect is more dramatic with low shares. Second, specifically focusing on the trade partner with the largest share of the market for a commodity, I find that such exporters have significantly lower pass-through rates than their competitors. Lastly, the effect of large market shares in particular varies depending on the type of imported good, as well as the size and direction of an exchange rate fluctuation. This paper ties into a vast literature on exchange rate pass-through, both theoretical and emprirical. The most fundamental theoretical explanations for incomplete pass-through to import prices rely on imperfect competition and the markup and marginal cost structures of exporting firms. If the import market for a good were perfectly competitive, then markups would be zero and pass-through would be complete (pass-through = 1). Complete pass-through should also occur under the assumptions of constant markups to marginal costs and production with constant returns to scale. Markets with imperfect competition tend to violate these assumptions, particularly the notion of a constant markup. Even if returns to scale are constant, when foreign firms increase markups following an appreciation of the home country’s currency, the ensuing reduction in import prices is smaller in magnitude than the percent appreciation of the currency (pass-through is incomplete). Interactions between production function types (increasing or decreasing returns to scale) and markups can vary the degree to which exchange rate shocks impact the price of imports. For instance, a foreign exporter with decreasing returns to scale (increasing marginal costs) would further reduce pass-through with increased markups.Footnote 1
 Many of these theoretical results relate to the seminal model of Dornbusch (1987). While also considering the overall integration of the world trade market for a good and the substitutability of domestic and foreign goods, Dornbusch uses a model of oligopoly to show that pass-through is greater when marginal costs are close to prices (small markups) and the foreign exporter controls a larger share of the import market. At the other extreme, a foreign exporter with only a small share of an import market is predicted to have a lower pass-through (assuming equal markups), thus obtaining increased profits from its small market share. However, the assumption of equal markups is problematic. In a similar study to this paper, Feenstra et al. (1996) show a general theoretical relationship between market share and pass-through within a specific industry. Their models show an increasing relationship (independent of assumptions on demand) between the variables with pass-through approaching one as market share approaches 100%. When smaller market shares are considered, assumptions about the nature of the demand function are necessary and the question of whether pass-through increases or decreases with share depends on firm interactions. Here, I expound on these findings and show how pass-through and market shares relate across all imported goods. The basic theoretical model in this paper derives from Atkeson and Burstein (2008) use of imperfect competition to explain pricing to market. Their model relies on strategic interactions between firms and shows the importance of the distribution of market shares within an industry in explaining why PPP does not hold. Specifically, Atkeson and Burstein allow for better performing firms to have larger market shares within their industry. Due to the nature of substitution both across and within industries, such firms have larger markups and lower pass-through rates.Footnote 2
 As one of the key questions involving exchange rate pass-through relates to the fall in pass-through to US import prices in the 1990s, many works seek to develop theoretical models to explain low pass-through rates. Such studies focus on the persistence of cost changes and frequency of price adjustments,Footnote 3 as well as the role of the currency used for pricing goods.Footnote 4 The role of non-traded goods is also a factor in creating lower than expected pass-through ratesFootnote 5 as consumers’ ability to substitute towards non-traded goods can impact the export decisions of trade partners. My contribution to this section of the literature is to show how market shares, particularly that of the largest trade partner, can play a role in creating lower pass-through rates. The empirical literature on pass-through focuses on a wide variety of topics. Some studies aim to simply estimate pass-through in the import and export markets for individual countries, or to make comparisons of imports or exports for multiple countries.Footnote 6 Another section of the literature on empirical pass-through serves to test the relationship between pass-through and monetary policy, as well as other pricing behaviors. While theory shows that pass-through rate changes can cause variation in an economy’s inflation rate, it is also possible that the opposite can be true where pass-through is influenced by inflationary policies.Footnote 7 Exploring the role of market shares can assist in showing and explaining this phenomenon. In addition to examining overall pass-through to US import prices and the role of market shares, this paper takes into account country of origin and specific commodity to determine the differences across host countries and good types. Specifically, the breadth of this paper will span a larger number of countries and more highly disaggregated goods than other works in the literature. Most papers that measure and analyze exchange rate pass-through and its effects use goods disaggregated at the Harmonized Tariff Schedule (HTS) six- or eight-digit level, or use Standard Industrial Classification (SIC) codes which are less disaggregated than HTS.Footnote 8 Additionally, most studies limit the analysis to interactions with major trade partners such as Canada, Mexico, China, Japan and the dominant EU economies. The breadth of the data in this study is unique and allows for more pass-through calculations for more goods and more exporters than other similar comparisons of pass-through and market share. However, such data is only available by exporter rather than at a firm level. All exporters in a given country are assumed to act as a single monopolist rather than individual firms. This is potentially problematic as pricing decisions (and therefore pass-through) are clearly made at the firm level. Auer and Schoenle (2016) use BLS pricing data to estimate firm shares of ten-digit goods. They find an average of 1.92 exporting firms per exporter of each ten-digit good in a month, with over sixty percent of countries having a single exporting firm and less than two percent having more than six firms exporting a ten-digit commodity. This suggests that while exporter shares do not exactly match firm shares, general comparisons can be made. I further address this issue in the Appendix by considering the number of shipments of each good. While the exact calculations of firm’s market shares are not possible, shipment data suggests that such shares are smaller when more countries are involved in trade. The lack of firm data does remain an issue to consider in future work.Footnote 9
 The main contribution of this work is that it considers all exporters of goods to the US between 1990 and 2005 and focuses on imported goods at the most disaggregated level. The level of detail in this paper allows for the examination of relationships within the broader categories of goods used in most studies. By examining various relationships between pass-through and market share at such a highly disaggregated level for a wider selection of exporting countries, I generate a more detailed analysis of how US import prices respond to exchange rate shocks.",1
18.0,2.0,"Journal of Industry, Competition and Trade",05 September 2017,https://link.springer.com/article/10.1007/s10842-017-0260-5,"The Effects of Competition, Liquidity and Exports on Markups: Evidence from the UK Food and Beverages Sector",June 2018,Chrysovalantis Amountzias,,,Unknown,Unknown,Unknown,Unknown,,
18.0,2.0,"Journal of Industry, Competition and Trade",30 September 2017,https://link.springer.com/article/10.1007/s10842-017-0261-4,The Impact of Structural Reforms on Telecommunications Performance,June 2018,Christos Agiakloglou,Michael Polemis,,Male,Male,Unknown,Male,"Telecommunications industry has undergone profound structural changes regarding its market structure. For most OECD countries the industry was vertically integrated and state-owned whereas over the last decades the market has been liberalized giving the opportunity for other private companies to enter the market and provide Telecommunications services. Over the last two decades, several interesting studies, such as Ros (1999), Laffont and Tirole (2000), Boylaud and Nikoletti (2001), Wallsten (2001), Gual and Thrillas (2004), Estache et al. (2006), Kim et al. (2011), Paleologos and Polemis (2013), Lestage et al. (2013) and Hausman and Ros (2013), Agiakloglou and Bloutsos (2011), Agiakloglou and Gkouvakis (2015), Agiakloglou and Yiannelis (2005); Agiakloglou and Karkalakos (2009) have tried to assess to what extent competition, regulatory and privatization affect the performance of the Telecommunications Industry. The objective of most of these studies was to detect the main drivers of Telecommunications performance either at macro or at micro economic level, taking into account occasionally indicators that express structural reforms. Hence, in contract to what has been done empirically so far, this study tries to capture the dynamic effects of these structural reforms variable along with some other macroeconomic and financial variables. The purpose of this study is to fill the research gaps by combining certain (structural) determinants from a macro and micro economic perspective. For this reason, we formulate a number of research questions including inter alia the following: How do regulatory reforms affect the overall performance of the telecommunications sector? How does competition stimulate industry output? In what way privatization determines the level of investments of the sector? Does regulation have a stronger effect on performance when it’s implemented with other reforms such as competition and/or privatization? Lastly, what policy implications could be drawn in order to enhance the performance of the telecommunications industry? This study contributes the literature in many ways. Firstly, unlike previous studies (see for example Ros 1999; Wallsten 2001, 2004; Li and Lyons 2012), devoted on this topic we try to assess the linkage and the possible spillover effects between regulation, competition and privatisation and the level of telecommunications performance by using superior measures of the effectiveness of regulation and competition (Fiorio and Florio 2013; Pompei 2013). For this reason, we use the most up to date regulation and competition indices provided by the OECD. Secondly, this is the first study that we use the regulation components of the FRASER Index of Economic Freedom to examine the impact of credit (financial), labour and business regulation, on telecommunications performance in the 30 OECD sample countries. The use of the FRASER index, allows greater insight into this issue and this is one of the novelties of this paper. It is noteworthy that FRASER index has been used in similar empirical studies in order to quantify the effects (see for example Psillaki and Mamatzakis 2017; Polemis and Stengos 2017; Polemis 2016; Mamatzakis et al. 2015) of credit and labour regulation on a specific sector of economic activity. Thirdly, it uses an updated data set covering the most recent period where regulation and competition policies are high in the political agenda of many OECD countries. To the best of our knowledge no other researcher has conducted similar estimations with the precise countries and data period. The paper is organized as follows. Section 2 presents the data set and the variables used in the relevant econometric methodology, while Section 3 reports and analyzes the empirical results. Finally, the concluding remarks as well as some policy implications are reported on Section 4.",4
18.0,2.0,"Journal of Industry, Competition and Trade",23 October 2017,https://link.springer.com/article/10.1007/s10842-017-0263-2,Can Banning Spatial Price Discrimination Improve Social Welfare?,June 2018,Ziying Yang,Félix Muñoz-García,,Unknown,Male,Unknown,Male,"In some industries, such as cement and ready-mixed concrete, spatial price discrimination is possible because firms are geographically differentiated and transportation is costly (Vogel 2011; Miller and Osborne 2014). For example, spatial price discrimination has a long history in the cement industry, where producers privately negotiate contracts with their customers (Miller and Osborne 2014).Footnote 1 While such spatial price discrimination yields larger profit, its welfare effects have long been the subject of debate. Despite being forbidden in many countries, like European Union under the Treaty on the Functioning of the European Union (2007) and China under the Antimonopoly Law (2007),Footnote 2 many analysts argue that banning spatial price discrimination may harm social welfare; see Greenhut and Ohta (1972) and Holahan (1975). Most previous studies show that price discrimination produces an unambiguous welfare improvement, but this paper demonstrates that a welfare reduction can emerge under relatively general conditions. We analyze a monopolist’s location decision and compare the resulting output and social welfare under two pricing regimes: spatial price discrimination and mill pricing (no discrimination).Footnote 3 Previous studies considered two simplifying assumptions: (1) firm’s location was given; and (2) consumers are uniformly distributed. While some studies relaxed assumption (1) by allowing for firm’s location to be endogenous, they assumed that location costs were constant, i.e., suggesting that the firm incurs the same location cost regardless of its distance from the city center.Footnote 4 We separately relax these assumptions, considering a model of endogenous firm location (relaxing 1); in which consumers are not necessarily uniformly distributed (relaxing 2); and whereby location costs are not necessarily constant. Such a general model allows us to show that output and welfare predictions are critically affected by the assumptions often considered by the previous literature. As Cheung and Wang (1995) and Hwang and Mai (1990), we solve a two-stage sequential-move model of location and pricing. In particular, the firm chooses its location in the first stage, and prices are chosen in the second stage. We separately identify equilibrium behavior under spatial price discrimination and mill pricing, and provide Monte Carlo simulations for those expressions without explicit solutions. Our results find that, when location costs are constant, the firm locates at the city center both under mill and discriminatory pricing since most customers concentrate at the city center.Footnote 5 However, when the location costs are non-constant (as in most industries), we find that optimal location differs across pricing regimes. Under mill pricing, the firm locates closer to the city center than under spatial price discrimination when transportation rates are low; otherwise, the optimal location under mill pricing is further from the city center. Spatial price discrimination, hence, yields unambiguously a larger market radius, higher profits, and a larger output. Welfare under this pricing regime, however, depends on the transportation cost per unit of distance. For low transportation costs, welfare under mill pricing is higher than under spatial price discrimination; while for high transportation costs the opposite result applies. Therefore, when transportation costs are relatively low (e.g., roads and railroads are in good condition, or transportation firms facing cheap oil prices), spatial price discrimination is actually welfare reducing. In these contexts, regulations that ban spatial price discrimination become welfare improving, while laws that allow or prevent this type of discrimination under all conditions can entail welfare losses. Location costs play a crucial role in firm’s location.Footnote 6 The monopoly spatial price discrimination literature assumes a constant location cost over the market space.Footnote 7 However, location costs, such as rental costs and land prices, differ by location (Hinloopen and Martin 2017). For instance, a one-mile increase in the distance from the city center decreases house prices in Chicago by 8%, McMillen (2003); and, similarly, a 1% increase in the distance from the city center decreases rentals (land prices) in Shanghai (New York Metropolitan area) by 0.14% (0.95%, respectively), see Wang et al. (2016) and Haughwout et al. (2008).Footnote 8 Importantly, our results show that, relaxing the assumption of constant location costs changes firm’s equilibrium location. Specifically, the firm faces a trade-off since locating closer to the city center helps it serve a larger number of customers but entails a higher location cost. Our above findings show how this trade-off affects firm’s location and, as a consequence, equilibrium output and welfare. Our results can thus be used at urban policies that seek to attract more firms to the city center (e.g., inner cities), as our findings help identify under which cases these policies can be beneficial. Our paper is related to the literature on monopoly spatial price discrimination. Using a model with uniformly distributed consumers and linear demand, Greenhut and Ohta (1972) and Holahan (1975) argue that, when the market area is variable, spatial price discrimination results in firms producing larger output, serving larger market areas, and generating larger social welfare than under mill pricing. Beckmann (1976) relaxes the assumption of uniform population density but assumes an exogenous market area.Footnote 9 He shows that spatial price discrimination yields lower welfare levels than mill pricing; a result that holds for all customer distributions. Another common assumption in the previous literature is that the monopolist’s location is given and coincides across different pricing policies. Allowing the firm to strategically choose its location based on the pricing regime, however, affects output and welfare, as shown in Beckmann and Thisse (1987), Hwang and Mai (1990), and Tan (2001). Cheung and Wang (1995) extend the analysis to non-uniform demands and show that, when the monopolist serves a fixed market area, spatial price discrimination results in the same total output, higher profit, lower consumer surplus and lower total welfare than mill pricing. They also demonstrate that when location is chosen endogenously, output falls, and consumer surplus and total welfare may rise or fall. However, the above studies assume a fixed market. Since market areas served vary with each pricing regime (Greenhut and Ohta 1972; Holahan 1975; Ohta and Wako 1988), we incorporate the location decision into models of monopolist’s spatial price discrimination with endogenous market areas. This general model allows us to identify novel settings under which spatial price discrimination is welfare reducing, thus supporting the arguments of regulators proposing to ban such a pricing practice at least under certain conditions. This paper, hence, contributes to the monopoly spatial price discrimination literature in two ways. First, although several studies analyze output and welfare effects of spatial price discrimination, few of them simultaneously consider non-uniform population density, endogenous market boundaries, and endogenous plant location. Our setting hence is closer to real market conditions. Second, to our knowledge, this is the first study considering a non-constant location cost in the analysis of monopolist’s spatial price discrimination. While most studies assume that location costs are constant (i.e., firm incurs the same costs, regardless of its distance from the city center), we allow them to decrease as the firm locates further away from the city center, and show how output and welfare change. The next section describes the model of our analysis. Section 3 analyzes the pricing decisions in the second stage. The location decisions in the first stage and equilibrium results are presented in Section 4. Section 5 concludes.",
18.0,2.0,"Journal of Industry, Competition and Trade",18 October 2017,https://link.springer.com/article/10.1007/s10842-017-0264-1,"Strategic Compatibility Choice, Network Alliance, and Welfare",June 2018,Tsuyoshi Toshimitsu,,,Male,Unknown,Unknown,Male,"In network industries, e.g., airlines, railways, telecommunications, application software, operating systems, and Internet services, we can observe not only network externalities but also compatibility and standardization of products and services. In particular, compatibility is a characteristic of products and services that interact with other products and services to enhance performance for users. Thus, the problems of compatibility and standardization are important for firms (providers), consumers (users), and the policy maker. However, the choice of compatibility between products and services tends to be made by providers rather than by users, unless an intervention by the policy maker occurs. Since the publication of the seminal paper by Katz and Shapiro (1985), many researchers have examined social and private incentives to achieve product compatibility, which refers to the trade-off between compatibility and standardization (or between incompatibility and perfect compatibility) in the presence of a network externality.Footnote 1
 We observe that there are several levels (i.e., imperfect, partial, and perfect) of compatibility between products and services in network industries. For example, estimating network effects and compatibility in the Polish mobile market, Grajek (2010) finds that there are strong network effects and that the estimated level of compatibility is very low despite full interconnection of the mobile telephone network. Furthermore, Gandal (1995) empirically analyzes complementary network externalities in personal computer software markets because users need to exchange data files between spreadsheets and database management systems. As an example, he shows a statistical analysis package such as TSP, which is fully compatible with Lotus files, but not with Dbase files. Taking the framework of Economides (1996), we develop a simple model of one-way compatibility choice under differentiated Cournot duopoly with network externalities. Using the model, we consider how the level of a network externality and product substitutability affect the compatibility choice. Chen and Chen (2011), whose work is closely related to ours, analyze compatibility choice under a horizontally differentiated duopoly with network externalities. However, based on their specific assumption, they consider only the case of a strategic substitute relationship, and they conclude that a firm’s optimal choice is an incompatible product in the market, whereas socially optimal compatibility involves establishing the perfectly compatible standard. In such a case, a social dilemma arises.Footnote 2 In the current paper, we relax their assumption and demonstrate that if the level of a network externality is larger than that of product substitutability, then there are multiple equilibria involving imperfect and perfect compatibility. Thus, a social dilemma need not always arise. Furthermore, we consider a network alliance between firms as a collusive behavior. We demonstrate that the stable network alliance is socially optimal where firms provide perfectly compatible products.",8
18.0,3.0,"Journal of Industry, Competition and Trade",10 August 2017,https://link.springer.com/article/10.1007/s10842-017-0257-0,Forecasting European high-growth Firms - A Random Forest Approach,September 2018,Jurij Weinblat,,,Male,Unknown,Unknown,Male,"High-growth firms, which are also known as “gazelles” (Lopez-Garcia and Puente 2012, p. 1029), are an intensively researched topic which is closely observed by policymakers (Daunfeldt and Halvarsson 2015).Footnote 1 There are several explanations for this considerable research interest. From the perspective of various firms, growth is a crucial strategic priority and is often seen as an indicator of corporate success and market acceptance (Shin et al. 2005, p.6; Barringer et al. 2005, p. 665). Especially for new firms, rapid growth is essential for survival (Coad 2007b, p. 51). Concerning their impact on job creation, it is frequently mentioned that HGFs create a substantial number of long-term jobs (Coad 2007a, p. 81; Acs and Mueller 2008, p. 86; Coad et al. 2014b, p. 92; Lopez-Garcia and Puente 2012, p. 1030).Footnote 2 The hired people are oftentimes long-term unemployed or immigrants so that HGFs help these people to get a foothold in the job market (Coad et al. 2014b, p. 293). It is impressive that approximately three percent of all firms are responsible for the majority of private sector’s revenue growth (Acs et al. 2008, p. 2). Oftentimes, this growth is sustainable since a considerable share of HGFs manages to stay a HGF in the following period (Acs et al. 2008, p. 8). For private investors, HGFs are also an attractive investment opportunity: especially big firms are more likely to continue to grow after such a period than the remaining firms and therefore, continue to be a promising investment (Acs et al. 2008, p.8, p. 18, p. 27, p. 46). Another motivation to study HGFs is put forward by Schreyer (2000) and also Acs et al. (2008) who regard these firms’ potential to advance national economies. Especially in some European countries, unemployment rates are relatively high which is due to a lacking ability of the economies to adapt to ongoing changes. The authors argue that although governments can create a favorable environment, it is up to private companies to carry out the required implementations. HGFs are believed to be especially capable of adapting to change, are willing to take hazards, and show higher-than-average research and development (R&D) expenses to finance important innovations. Birch and Medoff (1994, p. 163) have also stressed the HGFs’ innovative capacity. Companies like Apple and Cisco are frequently mentioned examples for such HGFs (Barringer et al. 2005, p. 664). Especially technology based HGFs are known to have positive spill-over effects and to have a higher propensity to invest in R&D (Schreyer 2000, p. 1; Fotopoulos and Louri 2004, p. 163). Consequently, HGFs foster an increase in productivity and competition. There is evidence that this competition creates more jobs than it destroys (Acs et al. 2008, p. 11 and p. 19). To reduce unemployment and because of other previously mentioned reasons both the European Commission and the OECD have taken measures to foster HGFs (European Commission 2010, p. 14; Organisation for Economic Co-operation and Development 2010; Coad et al. 2014b, p. 93, Schreyer 2000, p. 6). A mechanism to anticipate future HGFs would allow to well-directedly support HGFs without wasting taxpayers’ money and increasing inflation (Birch 1981, p. 4). Current HGF related initiatives invest money in start-ups without knowing if they will ever become HGFs which is criticized by Acs et al. (2008, p. 7). However, Birch (1981, p. 8), Schreyer (2000, p. 29), Coad et al. (2014a, p. 91), and Acs et al. (2008, p.45) point out that a priori, future HGFs are impossible to anticipate because of their high heterogeneity and their nonuniform growth development which hampers the identification of common characteristics. Coad (2007b, p. 1 and p. 56) even believes that “Firm growth is characterized by a predominant stochastic element, making it difficult to predict” and that it is an “idiosyncratic and fundamentally random process”. This is why Coad and also Acs et al. (2008, p. 40) believe that it is challenging to implement HGF related policies. In this context, this study aims to evaluate the capability of the random forest (RF) algorithm to predict future HGFs using publically available financial data. Therefore, we follow the appeal of Coad (2007b, p. 1) to apply novel statistical techniques in the area of HGFs. To provide a realistic impression, the out-of-sample prediction quality is evaluated on a more recent data set. Moreover, since the RF’s byproducts allow to analyze the data’s underlying patterns, the second contribution is to present and discuss these findings. For instance, an analysis of variable importance rankings can foster the identification of the previously mentioned common characteristics or patterns. According to Coad (2007b, p. 58), there was only a little progress in identifying the determinants of firm growth, making this analysis a valuable contribution. The analysis is based on nine countries, covering eleven years (2004–2014) and 179970 unique firms. Therefore, the results are robust and enable cross-national comparisons. In contrast to studies like (Schreyer 2000), the data originates from the same source so that differences cannot be attributed to different data collection and processing methods.Footnote 3 As it will become obvious in the literature review, previous empirical analysis either regard the influence of single variables on (high) firm growth or perform regression and panel data estimations. Although these studies were able to deliver various interesting insights into the determinants of HGFs, none of them evaluates whether these insights enable the prediction of future firm growth based on new data. Our last contribution will be an analysis of the so-called “survivorship bias” (cf. Coad et al. 2014a, p. 96). Based on our data, such bias cannot be confirmed. Hence, this study is supposed to introduce the predictive paradigm to the research area of HGFs. This paradigm is already common in other financial data applications. For instance, in the tradition of Altman (1968) and Ohlson (1980), scientists try to predict future corporate defaults using statistical techniques like the multiple discriminant analysis and the logistic regression. In the recent past, data mining approaches like support vector machines (Härdle W et al. 2005), artificial neural networks (ANNs) (Cross and Rarnchandani 1995) and RFs (Kartasheva and Traskin 2011; Behr and Weinblat 2017) are applied as well, usually outperforming the previously mentioned techniques. Another application of forecasting is the corporate financial performance prediction for instance in Lam (2004) using ANNs. In this study, ANNs enable to derive investment decisions which outperform the average market return. The remaining article is structured as follows. In Section 2 we present important HGF related findings based on descriptive and regression studies. In Section 3 we introduce our data source, the structure of our train and test data and our used growth indicator. Section 4 describes the RF algorithm, how its prediction performance can be quantified, and the proceeding of our main analysis. The selected prediction variables following this proceeding are presented and described in Section 5 while our results can be found in Section 6. A summary and directions for further research are given in Section 7.",13
18.0,3.0,"Journal of Industry, Competition and Trade",31 August 2017,https://link.springer.com/article/10.1007/s10842-017-0258-z,The Cournot-Ricardo Solution under Domestic Free Movement of Labour,September 2018,Alexandra M. Espinosa,,,Female,Unknown,Unknown,Female,"The Ricardo-Mill theory of Comparative Advantage is a very powerful tool to describe the international distribution of production, and an elegant argument supporting free trade. Nevertheless, the competitive equilibrium does not have a known dynamic given the “general price uncertainty” resulting from the time-consuming nature of the productive process: when the productive process is planned, industries do not know the price that will prevail, whilst production is not available in world markets (Ruffin 1974). Consequently, the Comparative Advantage theory cannot explain how economies are driven out of the autarkical equilibrium to the free trade competitive equilibrium (Dixit and Norman 1980). The Cournot-Ricardo monopolistic competition model is introduced in the international trade analysis with the aim of studying inter-industry trade (Song and Sohn 2012). This model emerges as an interesting proposal to solve this “general price uncertainty”, since the relative factor price is known at the Cournot equilibrium, hence the comparative advantage is well-defined at this price. However, this paper shows that the stability of the Cournot-Ricardo solution requires strong conditions relative to the labour markets: workers cannot move to new jobs, or industries do not react to such a labour movements. The first assumption is an unrealistic and unacceptable case since it violates the international labour rules; and, the second is irrational, given the strategic behaviour of industries. Hence, if workers have incentives to leave industries without a comparative advantage and seek new jobs in industries with a comparative advantage, these inter-industry movements should reduce the size of industries without a comparative advantage. Then, the free movement of labour seems to lead economies to the competitive equilibrium. However, in general, it is not true: the assumptions relative to the inter-industry movement of labour determine important properties of the Cournot-Ricardo model, such as the convergence to the competitive equilibrium and specialisation. This paper is organised as follows: Section 2 reviews the general theoretical framework and properties of the Competitive and Cournot solutions; Section 3 analyses the convergence in prices and specialisation under the intra-industrial free movement of labour. Finally, Section 4 exposes the conclusions obtained from the previous section.",
18.0,3.0,"Journal of Industry, Competition and Trade",21 September 2017,https://link.springer.com/article/10.1007/s10842-017-0259-y,Hidden Costs of Offshore Outsourcing: an Analysis of Offshoring Decisions,September 2018,Deeparghya Mukherjee,,,Unknown,Unknown,Unknown,Unknown,,
18.0,3.0,"Journal of Industry, Competition and Trade",04 October 2017,https://link.springer.com/article/10.1007/s10842-017-0262-3,Endogenous Market Structures in the Presence of a Socially Responsible Firm,September 2018,Yasuhiko Nakamura,,,Male,Unknown,Unknown,Male,"This study explores the endogenous selection of strategic contracts by each firm’s owner in an asymmetric duopoly with substitutable goods. the duopoly comprises a typical managerial firm with sales delegation, à la Fershtman and Judd (1987), Sklivas (1987), and Vickers (1985), and a CSR firm with a linear combination of social welfare and quantity as its managerial delegation contract. there, we consider the effect of introducing the CSR firm into an equilibrium market structure, after the owners of the two firms simultaneously select their strategic contracts. the purpose of this study is to ctheck the robustness of the equilibrium market structures obtained in a duopoly composed of two firms with sales delegation in a symmetric managerial duopoly. In an oligopolistic market, firms make several decisions (e.g., horizontal and vertical mergers, collusion, setting the firm’s capacity and R&D levels), but do not set long-term price or quantity levels in the market. In fact, in the real-world economy, firms frequently face an economic situation in which they select a price contract or quantity contract as part of a long-term decision. As such, endogenous choices of strategic contracts in oligopolistic markets have received increasing attention in the literature on industrial organization, ever since the seminal works of Singh and Vives (1984) and Klemperer and Meyer (1986).Footnote 1
 Subsequently, Tanaka (2001a) extended the fundamental model to a general oligopolistic market with more than two firms, and Tanaka (2001b) considered a similar problem in a duopolistic market with vertical product differentiation. Moreover, Lambertini and Schultz (2003) and Reisinger and Ressner (2009) investigated the endogenous selection of strategic contracts in a market with tacit collusion and with two kinds of demand uncertainty, respectively.Footnote 2 More recently, Nakamura (2015a) explored the endogenous choice of strategic contracts when two firms with sales delegation face asymmetric demand functions, à la Choi and Lu (2012). Chirco and Scrimitore (2013) investigated a differentiated duopoly, with and without separation between ownership and management, in the fashion of Fershtman and Judd (1987), Sklivas (1987), and Vickers (1985). they endogenized firms’ choices of the strategy variable (price or quantity) in a product market with network externalities, à la Katz and Shapiro (1985) and Hoernig (2012), in which the surplus obtained by a firm’s client increases directly with the number of other clients of the firm.Footnote 3
 Moreover, in addition to improving the utility of shareholders by maximizing profit, firms in modern economic environments focus on activities related to corporative social responsibility (CSR), such as consumer services, environmental conservation, regional contributions, and so on. there are two main theoretical approacthes in the field of industrial organization:Footnote 4
 the change in the objective functions of firms to include consumer surplus and/or social welfare, along with CSR activities. the managerial delegation approach, in which firms’ owners provide managers with incentivized managerial contracts, in an oligopolistic market with separation between ownership and management. these two approacthes have been developed simultaneously. In the first approach, the objective function of a CSR firm is defined as a weighted average of its profit and its welfare/consumer surplus.Footnote 5 the first approach includes a number of prominent studies. First, Ghosh and Mitra (2014) compared Bertrand and Cournot competition in a symmetric differentiated oligopoly with CSR firms. Matsumura and Ogawa (2014) considered the decision-making of CSR firms that set their quantity, which implies that the competition mode is determined endogenously. they used the observable delay game, following Hamilton and Slutsky (1990), in a similar setting to that of Ghosh and Mitra (2014). Subsequently, in the context of a vertical oligopoly, Goering (2012) defined the objective functions of a socially concerned downstream retailer and an up-stream manufacturer as a linear combination of profit and consumer surplus.Footnote 6 More specifically, Goering (2012) explored the optimal degree of upstream firms’ concern over CSR, and its influence, in a vertically related market wthere the products are imperfect substitutes.Footnote 7
 In contrast to the first approach, studies belonging to the second approach focus on the strategic utilization within each firm, with separation between ownership and management. Kopel and Brand (2012) investigated a model in which the delegation parameter of a CSR firm is determined endogenously. In this case, the parameter is equal to the weight of the firm’s quantity in a linear combination of social welfare and quantity as its managerial delegation contract. In particular, Kopel and Brand (2012) considered a typical managerial firm with a sales delegation contract, à la Fershtman and Judd (1987), Sklivas (1987), and Vickers (1985), that competes with a CSR firm in a homogeneous goods quantity-setting market.Footnote 8 Most recently, Hino and Zennyo (2017) investigated endogenous decision-making on the level of CSR in a managerial delegation game to reveal how firms’ CSR strategies may affect the outcomes of quantity competition with homogeneous goods.Footnote 9 This study falls within the second approach. More specifically, we investigate the endogenous selection of strategic contracts in a duopolistic market with a typical managerial firm with sales delegation and a CSR firm, from a long-term perspective. there, we explore an endogenous selection game on the strategic contracts, wthere a typical managerial firm with sales delegation competes with a CSR firm, following the analyzes presented in Kopel and Brand (2012). Furthermore, we examine the equilibrium selection between the p-q game and the q-p game based on the notion of risk domination in Harsanyi and Selten (1988) by deriving a unique mixed-strategy equilibrium. there, we show that the p-q game risk-dominates the q-p game for all parameters in this model. However, from the viewpoint of social welfare, the lowest social welfare is achieved in the p-q game, which is a robust equilibrium market structure under the pure strategic contract class. Thus, in a duopoly comprising a typical managerial firm with sales delegation and a CSR firm whose delegation contract is partly based on social welfare, the socially preferable incentive cannot coincide with the private incentive if both firms simultaneously and endogenously select their strategic contracts. therefore, policymakers may need to prescribe a law regulating the free selection of strategic contracts by firms’ owners, with respect to social welfare, in an oligopolistic market with a managerial firm with sales delegation and a CSR firm. The remainder of this paper is organized as follows. In Section 2, we formulate a differentiated goods duopolistic model with the endogenous selection of strategic contracts by the owners of the typical managerial firm with sales delegation and the CSR firm with a linear combination of social welfare and quantity. In Section 3, we explain the game-theoretical model with multiple stages. In the first stage, the owners of both firms select their strategic contracts simultaneously. In the second stage, the firms’ owners choose the delegation parameters. then, in the third stage, the managers engage in market competition on the managerial contracts provided by their owners. Subsequently, we use backward induction to derive the market outcomes, including the payoffs of both firms in the four games, which are classified based on the strategic contracts chosen by the firms’ owners. In Section 4, we compare the market outcomes, including the delegation parameters, quantities, prices, and payoffs of the owners of sales delegation firm 0 and CSR firm 1, between the duopoly wthere both firms have sales delegation and the duopoly with CSR. In Section 5, we induce the equilibrium market structure (s) As a result of the selection of strategic contracts. In addition, we provide the ranking order of the delegation parameters, quantities, prices, and the payoffs of the owners of firms 0 and 1 in the four games in the duopoly comprising firms 0 and 1 with sales delegation, in order to describe the equilibrium market structures under the pure strategic contract class after the owners of the firms make their selections. Furthermore, we derive a unique mixed-strategy equilibrium and select the equilibrium between the two asymmetric equilibrium market structures under the pure strategic contract class, based on the notion of risk domination in Harsanyi and Selten (1988). Further, in Section 6, we consider the ranking order of social welfare in each of the four games, and compare the private incentives on firms’ free selection of strategic contracts with the social incentive of policymakers and authorities, from the viewpoint of social welfare ranking. In addition, we compare the consumer surplus, producer surplus, and social welfare between the duopoly wthere both firms have sales delegation and the duopoly with the CSR firm. then, we show that the existence of the CSR firm, whose manager considers social welfare, changes the result on the equilibrium market structure(s) under the pure strategic contract class, after the strategic contracts of the owners of firms 0 and 1 are strictly changed. Section 7 concludes the paper. In the Appendix :, we present the market outcomes, except for each firm’s delegation parameters and the payoffs of the owners of both firms in the four games. the Appendix : also provides the calculations for the ranking orders of the market outcomes among the four games, as well as direct proof that the p-q game risk-dominates the q-p game.",5
18.0,3.0,"Journal of Industry, Competition and Trade",13 November 2017,https://link.springer.com/article/10.1007/s10842-017-0265-0,Intangibles Trade and MNEs: Supply-Chain Trade in R&D Services and Innovative Subsidiaries,September 2018,Francisco Moris,,,Male,Unknown,Unknown,Male,"Production operations by multinational enterprises (MNEs) and their suppliers are increasingly fragmented across stages and geographic locations. Production fragmentation, also called vertical specialization, is a form of division of labor that occurs when countries, enterprises, or even units within firms specialize in particular stages of the supply or production chain. Within MNEs and foreign direct investment (FDI) activities, vertical specialization results in vertical FDI (VFDI) where affiliates specialize in intermediate inputs, such as manufactured components, business services, or production tasks. Fragmentation results in trade in intermediate inputs –also called supply-chain trade, vertical specialization trade, or input trade– within production networks known as global value chains (GVCs) (Baldwin 2006; Baldwin and Taglioni 2011; Grossman and Rossi-Hansberg 2008; Hanson et al. 2005;). Further, the geographic dispersion of value added activities within MNEs is reaching higher valued stages in the supply chain such as R&D and design (Mudambi 2008; Schmeisser 2013). At the macroeconomic level, these trends suggest that trade associated with supply chains comprises not only trade in manufactured components but also trade in business services, including trade in intangibles (knowledge-based services) explored in this paper.Footnote 1 Trade in business services has been studied at the macro level in the offshoring and ‘trade in tasks’ literature (Lanz et al. 2011; Grossman and Rossi-Hansberg 2008) and in outsourcing and input-output studies (Yuskavage et al. 2009).Footnote 2
 This paper focuses on the relationship of ‘FDI in R&D’, a form of vertical specialization in R&D tasks within MNEs,Footnote 3 and intangibles trade in the form of R&D services. This question has been little studied, in no small part due to data limitations on international transactions in intangibles, especially at the bilateral level.Footnote 4 Yet, understanding the structure and evolution of these transactions may be useful for FDI and trade policies aimed at increasing participation in, and benefits from, GVCs by moving to R&D and other high value added tasks (IMF 2015). The empirical work in this paper uses a gravity-trade model to relate aggregate bilateral U.S. exports and imports of R&D services simultaneously to outward and inward MNE activity, or bilateral FDI, as economic mass variables. The econometric strategy accounts for zero trade observations, addressing possible selection and consistency issues of traditional gravity trade specifications, and explores extensive vs. intensive margin in intangibles trade. The results are partially consistent with hypothesized complementarity of trade in R&D services and the operations of MNE subsidiaries.",2
18.0,3.0,"Journal of Industry, Competition and Trade",25 January 2018,https://link.springer.com/article/10.1007/s10842-017-0268-x,Sequential Mergers and Antitrust Authority’s Decisions in Stackelberg Markets,September 2018,Mariana Cunha,Hélder Vasconcelos,,Female,Unknown,Unknown,Female,"The large body of previous literature on the effects of horizontal mergers has argued that Antitrust Authorities should pay particular attention to the balance between anticompetitive price (market power) effects and pro-competitive merger related efficiency improvements (see e.g. Williamson (1968) and Farrell and Shapiro (1990)).Footnote 1 The European Commission (EC), in practice, has so far never used efficiency gains arguments to clear a merger. When the merging parties use the “efficiency defence argument” reporting that the merger would generate cost reductions, this claim usually has been dismissed by the EC. The EC uses the efficiency offence argument arguing that although the merger would benefit the consumers in the short-run, in the long-run rival firms have incentives to exit the industry and then the merging firm would become a monopolist, thereby harming consumers’ welfare. This efficiency offence argument has received some attention by economists, providing an informal discussion of efficiency offence arguments in EC practices, such as Padilla (2002). The efficiency offence argument has also been formally analyzed on a static and a dynamic framework (Motta 2004; Motta and Vasconcelos 2005). However, to the best of our knowledge, scarce attention has been devoted to the study of efficiency defence arguments, in contexts where merging parties have asymmetric strategic power. In this paper, we contribute to close this gap in the literature by studying an endogenous merger formation game wherein: (i) merging parties compete à la Stackelberg; (ii) all firms are ex-ante cost-symmetric, but mergers may give rise to endogenous efficiency gains and, therefore, cost asymmetries between the remaining firms in the industry; and (iii) every merger must be submitted for approval to an Antitrust Authority (AA). In particular, we consider two possible types of AA: a myopic AA, that evaluates a merger proposal without anticipating that the corresponding merger might trigger other subsequent mergers, and a forward looking AA, which is able to anticipate the ultimate market structure a merger will lead to if approved. Although in reality there are merger waves (or sequential mergers), usually the AAs rarely adopt forward-looking decisions when analyzing a merger case, since it is hard to predict the future behavior of the firms. Also AAs might make mistakes in predicting that following a merger, outsiders might leave. However, the economic literature (eg. Motta and Vasconcelos (2005) and Nocke and Whinston (2010)) has emphasized the need for those AAs to predict which is the ultimate market structure, after the first merger takes place. Recently, the Centre on Regulation in Europe (CERRE) published a dossier to the European Commission (EC) where it includes some recommendations on the future regulatory policy in network industries (CERRE 2014). This report highlights that the EC and national competition authorities should pay particular attention to the dynamic issues when investigating mergers such as, in electronic communications and media markets. It concludes that the merger policy is currently not very good at assessing the dynamic effects of mergers, given its static focus on prices. In this sense our paper is a theoretical contribution that suggests that when predicting the possible impact of the merger, possible reactions by the outsiders (defensive mergers) should be properly taken into account. More particularly, before concluding that a merger will create such a more efficient merged entity that rivals would not be able to compete with it, AAs should consider whether, in the industry at hand, there exists room for further mergers allowing outsiders to attain similar efficiency levels, and/or whether the outsiders might be able to enhance efficiency through internal growth. Within this theoretical structure, we find that, when evaluating a two-firm merger proposal, both myopic and forward-looking AAs adopt similar decisions if the proposed merger would not trigger the exit of outsider firms in case it was approved (and no further mergers take place). Nevertheless, their decisions are shown to be in sharp contrast when evaluating exit-inducing merger proposals, i.e, in the region where efficiency gains and the fixed costs are sufficiently high such that the merger would trigger the exit of outsider firms. In particular, under some circumstances, while the myopic AA blocks the merger under an efficiency offence argument, the forward looking AA approves the very same merger proposal, since it correctly anticipates that this merger will be followed by a subsequent defensive merger involving the outsider firms of the first merger. This will lead to a duopoly situation wherein even though firms have asymmetric strategic power, they end up being equally sized and equally efficient, to the benefit of consumers. This paper is mainly related to three strands in the extant literature. Firstly, it is related to the literature on endogenous horizontal mergers, since we explicitly model the merger formation process. Important references in this literature are Kamien and Zang (1990), Gowrisankaran (1999), Faulí-Oller (2000), Horn and Persson (2001a, 2001b), Motta and Vasconcelos (2005), Fumagalli and Vasconcelos (2008), Fumagalli and Nilssen (2008), Banal-Estanol et al. (2008), Vasconcelos (2010) and Nocke and Whinston (2010), to name a few.Footnote 2 Secondly, our paper is also related to the previous literature that incorporates an active AA into the merger formation game. Few studies have introduced the AA as an active player, such as, Motta and Vasconcelos (2005), Fumagalli and Nilssen (2008), Fumagalli and Vasconcelos (2008), Vasconcelos (2010) and Nocke and Whinston (2010). Thirdly, this paper is also related to the branch of the literature that deals with the economic analysis of merger control by taking into account the efficiency defence argument. The efficiency defence argument refers to the case where the AA approves the merger if the efficiencies caused by the merger more than compensate for the induced increase of market power. Some papers include the AA’s efficiency defence argument when evaluating a merger and some also analyze the role of structural remedies introduced by the AA after the merger takes place, such as, Röller et al. (2000), Motta and Vasconcelos (2005), Fumagalli and Nilssen (2008), Fumagalli and Vasconcelos (2008), Banal-Estanol et al. (2008), Vasconcelos (2010) and Nocke and Whinston (2010).Footnote 3 Our paper is closely related to Cunha and Vasconcelos (2015)’s paper who studied the effects of merger’s efficiency gains in a Stackelberg market but also to Motta and Vasconcelos (2005) ’s paper, which constitutes a key contribution as it endogenized the active role played by the AA in merger control, which was mostly disregarded in the previous literature. Cunha and Vasconcelos (2015) show that efficiency gains can make mergers profitable as well as be welfare enhancing. Motta and Vasconcelos (2005) show that if the AA does not anticipate subsequent merging, such a myopic AA could actually make wrong decisions. However, if the AA correctly anticipates that the merger is followed by other mergers, no efficiency offence argument is justified. Like Motta and Vasconcelos (2005), we also consider that the AA maximizes consumer welfare and, therefore, the AA approves both mergers if consumer surplus increases (i.e. if prices decrease).Footnote 4 There are two major differences between Motta and Vasconcelos (2005)’s framework and the setting used in this paper. First, Motta and Vasconcelos (2005) assume that the mergers occur under symmetric Cournot competition. Hence, in this paper we try to complement their results by assuming a scenario with firms having different degrees of strategic power (some behave as leaders and others as followers) at the pre-merger equilibrium industry structure and, therefore, it is assumed that different types of mergers may occur in an industry characterized by Stackelberg competition.Footnote 5 This assumption implies that, in the setting proposed in the current paper, when the efficiency gains are very small (or even when there are no efficiency gains) a merger between two firms will always be proposed because it is profitable, which is not the case under Cournot. When there is no strategic power advantage for any firm, we obtain the well known Salant et al. (1983) merger’s paradox: when costs are linear, a merger between two firms with the same strategic power that creates a firm of the same type is always unprofitable for the merging firms, unless more than 80% of the firms in the industry merge or there are sufficiently high fixed costs.Footnote 6 By considering this extended setting, we are able to characterize firms’ and AA’s incentives in some real world industries not encompassed by Motta and Vasconcelos (2005)’s framework. Also, the specific merger partners (and their respective strategic power) involved in the first merger have a decisive impact on the type of subsequent defensive merger that may take place between the outsiders of the (first) merger. Further, we find that in an asymmetric strategic power industry, the AA will be more severe when it is deciding to accept a merger in this type of industry, since the interval of efficiency gain levels where mergers are usually accepted is more restricted/smaller under Stackelberg than under Cournot. Put it another way, the AA blocks mergers in a Stackelberg setting for parameter values under which a merger would not be blocked in a Cournot environment. Second, Motta and Vasconcelos (2005) consider, under the forward looking AA, that after the defensive merger occurs, the firms of the first and the second merger are allowed to seek a merger to a monopoly. In this paper, we rule out merger to monopoly since we want to analyze the competitive effects of merger proposals in which both at the status quo industry structure and in the merger induced industry structure firms do have asymmetric strategic power. Although this paper encompasses a theoretical exercise, it is also motivated by the profitability of real-world mergers involving firms with asymmetric strategic power. A case in point is the DRAM (Dynamic Random Access Memory) industry, where the leading manufacturers announce their production plans in advance and manufacturers, which enter the market later, respond by adjusting their quantity of DRAM produced. In addition, in this specific industry, the last decades have witnessed a wave of mergers.Footnote 7 Another example is Microsoft’s dominance in software markets. In this case, although Microsoft usually makes decisions first, other smaller companies typically react to Microsoft’s actions when making their own decisions. Obviously, these subsequent followers’ actions, in turn, affect Microsoft (see e.g. Graham (2013)). In both examples, it seems reasonable and plausible to analyze both firms and AA decisions when firms have asymmetric strategic power. The remainder of the paper is organized as follows. Section 2 introduces the baseline assumptions of the model. Section 3 presents the results before the merger. Section 4 analyses the post-merger industry structure under two different scenarios regarding the behaviour of the AA (myopic and forward looking), for the case in which the merger involves two leader firms. Section 5 presents the results obtained for alternative types of mergers. Section 6 analyses the results and discusses the merger policy implications. Finally, Section 7 offers some concluding comments.",2
18.0,3.0,"Journal of Industry, Competition and Trade",26 February 2018,https://link.springer.com/article/10.1007/s10842-018-0271-x,Trade and Productivity in a Transition Economy: the Role of Industry and Export Destination,September 2018,Carlo Reggiani,Yevgeniya Shevtsova,,Male,Female,Unknown,Mix,,
18.0,4.0,"Journal of Industry, Competition and Trade",14 March 2018,https://link.springer.com/article/10.1007/s10842-018-0273-8,The Determinants of Plant Exit: the Evolution of the U.S. Refining Industry,December 2018,David W. Meyer,Christopher T. Taylor,,Male,Male,Unknown,Male,"The petroleum refining industry has undergone significant changes since the late nineteenth century as new technologies have altered how petroleum products are manufactured, transported, and consumed. Refineries began as relatively simple plants that distilled crude oil into different products including kerosene for lighting. With the growth of internal combustion engines, gasoline became a higher-valued product. As gasoline consumption grew, refineries added new technology to “crack” crude oil to increase the percentage of crude oil that could be refined into gasoline. Over time, higher performing engines required fuels that met more stringent specifications, such as higher octane. Government regulations also began to influence the products that refineries produced, such as Clean Air Act regulations phasing out lead and later regulations requiring reductions in sulfur in final product. These changes in the demand and regulation often led refineries to add additional equipment.Footnote 1 At the same time, technology to move crude oil and petroleum products also improved as crude, and then product pipelines lowered shipping costs. As the market for petroleum products has changed, the optimal number, type, and location of refineries has changed. These changes may lead a refinery to exit, or may lead a refinery to expand. There have also been many mergers that have changed concentration in the refining industry and may have affected refinery exit and capacity decisions.Footnote 2 In this paper, we analyze what factors make it more likely that a refinery survives in these changing market conditions. Several authors have previously analyzed factors that influence plant exit, mostly in other industries during periods of consolidation and exit. This paper contributes to that literature by utilizing a much longer data set that tracks annual changes in refinery capacity during periods of both capacity expansion and exit. We analyze multiple factors that may affect refinery exit and expansion including market concentration. Refinery exit and the lack of refinery entry have been posited as explanations for the periodic increases in gasoline prices. There is also some suggestion that market concentration may affect refinery expansion and exit as well. Many industry observers have pointed to two industry facts: (1) A large number of refineries have closed since the 1980s; (2) No new refinery has been built since 1976.Footnote 3 While the number of refineries has been decreasing since 1940, the focus on closures and lack of new construction misses the main source of current refinery capacity, the expansion of existing refineries. The relationship between concentration and plant exit and expansion is important to antitrust analysis. In our empirical section, we find that larger refineries are less likely to close and that refineries owned by a multi-plant firm are more likely to close. If a multi-plant firm closes a refinery, it is likely to close its smaller refineries. Ultimately, we find refinery exit and expansion is determined by industry capacity utilization, the size of the refinery and whether the owner of the refinery owns other refineries. In contrast to previous literature, we find weak evidence that refineries owned by firms with higher market shares are less likely to close. There is no suggestion in our results that concentration increases the likelihood of refinery closure. In specifications with more control variables, this relationship is statistically insignificant. We ultimately find that industry capacity utilization, not surprisingly, is overwhelming the most important explanatory variable for both refinery exit and expansion. In the remainder of the introduction, we give a brief overview of how refineries operate and a brief review of related literature. Section II describes the data set and discusses factors that could influence refinery exit and expansion decisions. Section III presents the empirical methodology and results. Section IV offers some concluding observations. Crude oil is a mixture of many different hydrocarbons. Refineries are complex manufacturing facilities that separate and recombine those hydrocarbons into various refined products. The main products produced today are gasoline, distillate (mainly diesel), and jet fuel. In the past, fuel oil and kerosene were also significant products, but over time, production of these products has decreased significantly. A typical refinery consists of various processing units. Crude oil is initially processed by the crude distillation unit, which separates the crude oil into various groups of hydrocarbons based on their boiling points. These separate groups are then processed further in one or more downstream units. These units include vacuum distillation, fluid catalytic cracking, delayed coker, hydrotreater, catalytic reformer, and alkylazation. Since the 1930s, there have been many changes in the petroleum refining industry: in the production and distribution of crude oil and the distribution and marketing of refined products. For example, refiners developed new technologies to increase the portion of crude oil that could be refined into higher value products, especially for more difficult to refine types of crude oil.Footnote 4 Refined products markets also evolved as advances in engine technology and changes in environmental regulations altered the specifications for finished petroleum products.Footnote 5 As a result, refiners that continued to manufacture fuels often needed to upgrade their refineries to meet these new specifications. Changes in transportation infrastructure also have influenced where refiners choose to operate. For example, crude oil pipelines became viable before refined product pipelines, so that in some locations it was more efficient to build refineries near the source of finished product demand and ship the crude oil there, rather than refine the crude oil near where it was produced or imported and ship the finished product there. While we do not have good data on many of these factors we are able to make inferences based on refinery capacity data. A number of previous studies have looked at how plant and firm characteristics influence the probability that a plant will close.Footnote 6 There are a number of empirical papers that examine factors on the likelihood that a manufacturing or processing plant will close. These studies either review a broad range of industries using data from a survey of manufacturing plants or they concentrate on an industry. Both of these types of studies inform our empirical specification. First, we review the cross industry studies. Dunne et al. (1989) use the U.S. Census of Manufacturers at the four-digit level to look at growth and exit rates, and find that size, owning multiple plants, and age all affect the probability of closure for the years 1963–1982. Disney et al. (2003) use the UK Census of Production to look at how size, age, and owning multiple plants affect plant survival with data from 1986 to 1991. Bernard and Jensen (2007) use the US Census of Manufacturers, from 1987 to 1997, to look at the effect of owning multiple plants, whether the firm is a multinational, whether the plant has been sold in the last five years, along with the effect of plant level controls including plant employment, age, capital intensity, factor productivity, and whether it is a multi-product plant. They also use measures based on input costs. Kneller et al. (2012) use data from the Japanese Census of Manufacturers and the Basic Survey of Japanese Business Structure and Activities, for 1994 through 2005, to look at the impact of whether a plant is owned by a multinational firm, and also control for the number of employees, capital per worker, factor productivity, input costs, entry and exit rates. All of these studies examine a cross section of industries for a 10 to 20 year period. There are a number of studies examining plant exit in specific industries. Baden-Fuller (1989) uses profitability, diversification, closure experience, share information, and the number of employees to explain exits in the U.K. Steel Castings industry. He examines exit from this declining industry from 1975 through 1983. He finds that multi-plant diversified firms are the most likely to close a plant. Lieberman (1990) uses data on 30 different types of chemical plants to look at the impact of size, owning multiple plants, diversification, economies of scope, and capacity utilization. Lieberman uses data from roughly 1960 through 1980. He finds that small plants and plants of multi-plant firms are more likely to exit. He also finds that multi-plant firms with higher market shares are more likely to close a plant. Deily (1991) looks at data on integrated steel companies during a period of consolidation between 1977 and 1987. She analyzed the impact of plant and firm size, geographic location, plant technology, and customer market segments on which plats exit. She finds that small plants are the most likely to close. Muth et al. (2002) examine data on meat slaughter plants and find that smaller, older and higher costs plants are more likely to close. This study was conducted using data from 1996 through 2000, a period when new regulations would change the cost of production. All of these studies examine plant closing during a relative short period, usually a decade or less during which the industry in question was consolidating. There are three papers examining refinery closures. Chen (2002) examines the probability of survival of U.S. petroleum refineries from 1981 to 1986, a period of many refinery closures due to the removal of price controls and allocations of crude oil. He uses duration analyses, both parametric and non-parametric duration models, to estimate which factors affect the probability that a refinery existing in 1980 is still operating in 1986. He finds plant size, age, complexity, and whether the refinery is part of a multi-plant firm affects the survival probabilities. Chen (2003) examines the same issue with a similar data set but uses probit analyses. Once again examining yearly data from 1981 to 1985, he estimates the relationship of surviving each year as a function of the size, age, complexity, location and multi-plant nature of each refinery. He also uses an ordered probit to examine which refineries exit, which refineries remain open but stay the same size, and those that remain open and grow. He finds that larger and older refineries are most likely to survive. It is important to note that regulatory changes in the early 1980’s, including the deregulation of crude oil, and the subsequent restructuring, may make this time period unique. Jiang (2012) examines refinery closures and sales between 1982 and 2007. Using duration analysis, she examines when refineries either shut down or change hands. Refineries are more likely to survive with their original owners if they are older or larger but less likely if the owners is a major vertically integrated firm or if the refinery is more complex. Jiang also uses a multinomial logit model to analyze the same choice, open, close, or sell. She finds that the larger, older or more technically sophisticated the refinery, the more likely it is to stay open or change ownership. While some of the data on relevant characteristics used in these previous studies that examine exit is not available for our entire data set, we have many of the variables that these studies found had an impact on that probability. For example, several papers have found that smaller plants and single-firm plants are more likely to exit, but after controlling for size, some of these papers find that plants owned by multi-plant firms were more likely to close than those owned by a single plant firm. Other variables that that these papers include are the age of the plant (older plants are less likely to close) and measures of changes in capacity. One of these papers also found that a plant was more likely to close in years with lower capacity utilization, and that firms with higher market shares were more likely to close a plant.",
18.0,4.0,"Journal of Industry, Competition and Trade",12 January 2018,https://link.springer.com/article/10.1007/s10842-017-0266-z,Capital Structure and Mergers: Retrospective Evidence from a Natural Experiment,December 2018,Sumit K. Majumdar,Rabih Moussawi,Ulku Yaylacicegi,Male,Male,Unknown,Male,"In the literature, the link between types of financing and firm strategic behavior is crucial. The relationship between a firm’s capital structure and strategy is acknowledged as key (Brown et al. 2009), and finance and strategic behavior questions are interrelated (Balakrishnan and Fox 1993). Debt is an important type of funds source (Corbett and Jenkinson 1997), capital structure is measured as the ratio of debt to total capital (Zingales 1998),Footnote 1 and the defining feature of two components in a firm’s capital structure, debt and equity, are the differential rights of providers (La Porta et al. 1998). Financial structure matters strategically (Myers 1977; Parsons and Titman 2008), since due to agency, signaling and information asymmetry issues (Ross 1977; Myers and Majluf 1984) there is heterogeneity in firms’ financing decisions (Denis and Mihov 2003). The issues of whether to have debt, how much, and what happens are important (Grinblatt and Titman 2001). Relative debt levels impact firms’ behavior. The findings in the leverage and strategy literature indicate that increased debt in firms softens aggressive strategic behavior. Titman (1984) evaluates liquidation decisions; Lambrecht (2001) evaluates entry and exit decisions; Phillips (1995) evaluates output and pricing decisions; Chevalier (1995) evaluates strategic responses of firms, while Zingales (1998) highlights the links between capital structure, firm performance and survival; David et al. (2008) evaluate the impact of debt on long-term oriented R&D activities; Anderson and Makhija (1999) evaluate the relationship between debt and corporate growth opportunities in Japan, and Chirinko and Elston (2006) carry out similar analysis for Germany. Simultaneously, a large literature discusses why firms merge. Reasons posited for mergers are to gain efficiencies (Farrell and Shapiro 1990), obtain reputation advantages (Dranove and Shanley 1995), reduce risk (Amihud and Lev 1981), diversify (Levy and Sarnat 1970), enjoy spillovers (Tremblay and Tremblay 1988), reconfigure resources (Steiner 1975), and redeploy capabilities (Capron and Mitchell 1998). Conversely, negative motives, such as hubris (Roll 1986), also drive mergers. Mergers determine the extent of competition in a market, and create substantial variations in industry structure (Steiner 1975) via the consolidations of firms. The historical evidence shows that concentration-enhancing structural variations permit firms to gain market power (Stigler 1964), to permit a quiet life (Hicks 1935), to grow the firm (Mueller 1969), and to permit rent-extraction (Marris 1964). In the finance literature, given a takeover or merger decision, a corpus of work (Bessler et al. 2011) evaluates the financial structure of such a deal. Merger transactions account for a large proportion of global gross domestic product. In the United States between 15,000 and 20,000 mergers occurred in the 2000s, and the role of debt in influencing economic activities is profound. There is a knowledge gap, as no evidence exists on how firm’s leverage influence takeover or merger decisions. A speculation is that, because of a limited liability effect, taken-over or merging firms with high leverage will compete aggressively (Socorro 2007). There is exploration of the relationship between leverage and merger timing (Morellec and Zhdanov 2005), but the evidence on how leverage affects firms’ merger decisions is non-existent. The study evaluates the relationship between firms’ leverage and mergers. The mergers assessed are all of those occurring among the population of local exchange firms in the United States telecommunications industry in the last two decades. Based on mergers data, the sector provides a natural experiment setting for retrospectively evaluating how leverage had impacted firms’ merger propensities. In infrastructure-based sectors, changes in firms’ strategic behavior have raised concerns that high debt levels could be leading to severe firms’ financial distress (Bortolotti et al. 2011). For telecommunications firms, the funding of assets such as spectrum and new networks would cost very large sums of money. Conversely, limits on abilities to raise prices, because of intense competition or effective regulation, would compromise the interest-paying capacities of such firms if they were to be highly indebted. Thus, strategies likely to compromise debt servicing would be considered risky, and risky strategic behavior of relatively greater-leveraged telecommunications firms would be constrained. Based on recent capital structure research (Majumdar 2016), we evaluate the relationship between firms’ leverage and mergers of local exchange firms in the United States telecommunications industry. Past mergers that have been approved are natural experiments, so that pre- and post-merger assessments can be carried out, permitting an evaluation of competition policy decisions. If, after evaluation of an allowed merger, subsequent outcomes, measured via analysis of firms’ behavior, are below expectations, then results indicate that competition agencies may not have got economic assumptions right (Carlton 2009). The use of historical panel data, from 1988 to 2001, of almost all the local exchange carriers in the United States, containing pre and post-merger data for firms, for two uniquely-different institutional periods, enables tracking of dynamic merger history for each carrier (Majumdar et al. 2012). Table 1 (extracted from Majumdar et al. 2014), lists ownership status and merger activity of local exchange telecommunications companies before 1996. Table 2 lists post-1996 merger events. Two issues can be investigated by retrospective merger assessments. First, whether specific merger decisions were right or wrong can be assessed. Second, the detailed evaluation of a stream of mergers permits an understanding of the outcomes of competition and merger policies. Retrospective assessments of consummated mergers have been reviewed by Hunter et al. (2008), Kwoka Jr (2013) and Pautler (2003). These historical assessments generate performance metrics useful for competition policy development (Kovacic 2006). Retrospective merger appraisals permit the accumulation of knowledge about various behavioral, structural and competitive conditions in different industries. By engaging in retrospective analyses, it is possible to highlight conditions under which merger outcomes are positive or negative. If these conditions can be established, then conclusions can be generalized to develop heuristics that provide policy insights in evaluating mergers based on expected outcomes in terms of price, and impact on other economic parameters.",3
18.0,4.0,"Journal of Industry, Competition and Trade",18 January 2018,https://link.springer.com/article/10.1007/s10842-017-0267-y,Quality Differentiation Under Mixed Competition in Hospital Markets,December 2018,Modhurima Dey Amin,Syed Badruddoza,Robert Rosenman,Unknown,Male,Male,Male,"Although not-for-profit hospitals (NFP) still have the largest share of the US market for hospital services, for-profit (FP) hospitals now account for more than 21% of the market, gaining about 1% per year in the 5 years up to 2012 (David 2009; Lee and Rosenman 2013; Henderson 2009; Selvam 2012). In 2015, 1034 of 4862 community hospitals in the US were investor-owned (AHA 2015). When government hospitals are excluded, the FP share of private hospitals climbs to over 26%. This trend towards the privatization of hospital services in investor hands is being seen in Europe as well. FP hospital beds in eight European countries grew from about 15.68% in 2005 to 18.42% in 2013 (Jeurissen et al. 2016). In France 37% of all hospitals are FP, as are 40% in Spain and 18% in Germany (Chevalier and Levitan 2009). Figure 1 shows that the trend towards FP hospitals has been steady since well before 2000. Health care market in US and Europe. Note: US FP includes the share of for-profit community hospitals in total number of community hospitals in the United States. Europe FP includes the share of for-profit hospitals in the European Union. Source: AHA (2015) for US, WHO (2016) for European Union The early literature on competition between FP and NFP hospitals revolved around Lakdawalla and Philipson (2006), who called NFP hospitals “profit deviating”. A primary conclusion of their work is that FP firms cannot compete if there are sufficient NFP preferences among potential entrepreneurs. Hence, a ready explanation for the growth of FP hospitals is that NFP preferences, as a share of market need, has fallen. However, more recent work has looked for other explanations of FP hospital growth, including the changing payment mechanism to prospective payment (Lee and Rosenman 2013), financial advantages deriving from vertical integration of physician-owned FP hospitals (Araújo et al. 2014), or that FP growth is more nimble, hence better able to respond to the increase in hospital demand over the past few decades (Bays 1983). In this paper, we use Montefiori’s (2005) model of quality competing hospitals to analyze mixed competition in the hospital industry, and provide a foundation that provides an alternative explanation for the changes in market share that are being observed. We are able to identify specific aspects of hospital operation related to fixed costs and the marginal cost of quality that help explain the growth of FP share. At the same time, our model is consistent with the Lakdawalla and Philipson, and we are able to quantify, in terms of fundraising relative to fixed cost, just what is meant by “sufficient” NFP preferences that would leave FP hospitals unable to compete in a market. Market shares suggested by our model are close to what is observed in present European and US health care markets. In addition, we show that the trend towards FP hospitals has implications for the quality of hospital services overall. In the next section, we present our model of mixed competition, and derive equilibrium market shares and qualities. Section 3 discusses the role of fundraising for determining the NFP share of the market, while section 4 offers discussion and conclusions. Several appendices provide additional insights and enrichments.",2
18.0,4.0,"Journal of Industry, Competition and Trade",16 February 2018,https://link.springer.com/article/10.1007/s10842-018-0269-4,License and Entry Strategies for an Outside Innovator Under Duopoly with Combination of Royalty and Fixed Fee,December 2018,Masahiko Hattori,Yasuhito Tanaka,,Male,Male,Unknown,Male,"We consider a choice of options for an innovating firm to enter the market with or without licensing its new cost-reducing technology to the incumbent firm using a combination of a royalty per output and a fixed license fee, or to license its technology without entry also using a combination of a royalty per output and a fixed license fee. In Proposition 4 of Kamien and Tauman (1986), assuming linear demand and cost functions and fixed license fee, it was argued that in an oligopoly when the number of firms is small (or large), entry with license strategy by the innovating firm, which is a strategy to enter the market and at the same time license its cost-reducing technology to an incumbent firm, is more profitable than license without entry strategy, which is a strategy to license its technology to an incumbent firm without entering the market. We think that their definition of license fee in the case where the innovating firm licenses its technology to an incumbent firm and does not enter the market is not appropriate. Interpreting their analysis in a duopoly model, they defined the license fee by the difference between the profit of an incumbent firm in that case and its monopoly profit before entry and license by the innovating firm. However, we can think that if the negotiation between the innovating firm and an incumbent firm about the license fee breaks down, the innovating firm can enter the market without license to an incumbent firm. If the innovating firm does not enter the market nor license, its profit is zero. But, if it enters the market, its profit is positive. Therefore, such a threat is credible, and hence an incumbent firm must pay the difference between its profit in the license without entry case and its profit in the entry without license case as a license fee. In Hattori and Tanaka (2018), using an alternative definition of a license fee taking the above point into account, the following results about duopoly with a linear demand function and only a fixed license fee have been shown. 
 Linear cost functions (constant marginal costs): If the incumbent firm does not drop out when the innovating firm enters the market without license, license without entry strategy is optimal for the innovating firm. This result is converse to that in Kamien and Tauman (1986). If the incumbent firm drops out when the innovating firm enters the market without license, both license without entry strategy and entry without license strategy are optimal.Footnote 1 Quadratic cost functions: If the magnitude of the innovation is large (cost of the new technology is sufficiently low), license without entry strategy is optimal for the innovating firm, and if the magnitude of the innovation is small, entry with license strategy is optimal. In this paper we consider a more general situation of duopoly with an innovating firm and an incumbent firm, in which the innovating firm imposes a combination of a royalty per output and a fixed license fee to the incumbent firm. We analyse a case of general demand and cost functions as well as a case of general demand and concave cost functions and a case of general demand and strictly convex cost functions. We will show the following results. When the innovating firm licenses its technology to the incumbent firm without entry, the optimal royalty rate per output for the innovating firm is zero. When the innovating firm enters the market and at the same time licenses its technology to the incumbent firm, there exists a positive optimal royalty rate per output. Entry without license strategy is not optimal for the innovator. (Lemma 3) If the innovating firm enters the market and at the same time licenses its technology to the incumbent firm, and the cost functions of the firms are concave, the optimal royalty rate per output for the innovating firm is one such that the output of the incumbent firm is zero. The fixed license fee is negative. Boh license without entry strategy and entry with license strategy are optimal for the innovator. However, if the license fee is determined according to the rule in Kamien and Tauman (1986), only the entry with license strategy is optimal because the license fee when the innovator licenses its technology to the incumbent firm and does not enter the market according to their definition is smaller than that according to our definition. If the innovating firm enters the market and at the same time licenses its technology to the incumbent firm, and the cost functions of the firms are strictly convex, the optimal royalty rate per output for the innovating firm is positive but smaller than one such that the output of the incumbent firm is zero. The equilibrium output of the innovating firm is larger than that of the incumbent firm. Entry with license strategy is optimal for the innovator. In this case the fixed license fee may be positive or negative. Please see an example in Section 5. In the next section we review some related studies. In Section 3 we describe the model of this paper. In Section 4 we present the main results, and in Section 5 we study a case of linear demand and quadratic cost functions as an example of the strictly convex function case.",1
18.0,4.0,"Journal of Industry, Competition and Trade",24 February 2018,https://link.springer.com/article/10.1007/s10842-018-0270-y,"Tariffs, Efficiency Wages and Unemployment",December 2018,Rajit Biswas,Kumar Shubham,,Unknown,Male,Unknown,Male,"In the recent years, there has been a growing pessimism against free trade throughout the globe. Along with this phenomenon a move to protectionism is being envisaged in many parts of the world. Madi (2017) points out that throughout the year 2016, a large number of countries have used protectionist policies to expand their domestic production. The Economist (2016) points out that “Donald Trump has described his foreign-policy priorities in only the vaguest terms. But he has made very clear that he believes his years in business have equipped him to negotiate better, smarter and tougher deals for America, whether by threatening to slap tariffs on foreign imports..”. Dutta et al. (2009) discusses how globalization is perceived to be a potential cause for job losses.Footnote 1 The present model attempts to analyse how effective protectionist policies can be at the first place to increase employment.Footnote 2 Tariff protection which is still quite prevalent todayFootnote 3 is generally believed to expand the domestic import competing sector and crowd out cheaper imports. Evidently, in presence of unemployed resources in the economy (say labour), expansion of domestic production would lead to higher employment. However, in the present model we show that for a small open economy that engages in intra-industry trade in a differentiated good, tariffs instead of protecting the domestic sector may cause it to contract and exacerbate the employment situation. We build a model closely on Matusz (1996). A model of monopolistic competition is embedded into the unemployment model of Shapiro and Stiglitz (1984).Footnote 4 A single consumer good is produced using a variety of intermediary inputs. Production of each of these inputs is subject to scale economies and markets are monopolistically competitive. Monitoring work effect is imperfect and unemployment becomes a workers discipling device. That is, in order to prevent workers from shirking firms have to pay a wage higher than the market clearing wage thereby causing unemployment. The country is assumed to be a small country and thus treats the number of varieties and the prices of the imported varieties as exogenously given.Footnote 5 Imposition of tariff on the imported brands would have two distinct effects. Tariffs increase the price of the imported brands thereby making the consumption basket dearer, this tends to reduce the effective real wage workers receive. Falling real wages would lower the opportunity cost of unemployment and unemployment would tend to rise by this mechanism. However, there also exists a second effect. Protection of a sector with scale economies would tend to expand it and thereby increase employment. The stronger is the scale economy, the more pronounced will be this effect.Footnote 6 A lower elasticity of demand would make this effect more dominant as that would imply higher supernormal profits. As consumers would demand more of the domestic brands, since the foreign brands are costlier due to the imposed tariff, entering the domestic industry becomes profitable. If the first effect dominates the second effect of imposing tariffs, then indeed tariff protection may increase unemployment as the no-shirking constraint would get more binding. This is indeed the case, when elasticity of demand is higher. This paper is also related to the issue of tariff protection and its effect on import competing sector. Chakraborty (2001) shows that capital inflow into a tariff protected sector of a small open economy can conditionally cause a simultaneous expansion of import competing sector and cheaper imports.Footnote 7Biswas (2015) builds a model with two sectors. One of these sectors produce a differentiated good and another sector produces a public good through voluntary contribution. It is shown that income effect generated by the imposition of the tariff can increase consumption of the public good thereby causing the public good producing sector to expand. This may actually contract the import competing sector leading to a situation analogous to that of Metzler Paradox. In the present model also a similar result occurs but through a completely different channel. An imposition of tariff causes the consumers to demand more of the home varieties, which tends to make entry profitable for the firms. However, if elasticity of demand is high then real wages may actually go down. Firms may thus in the equilibrium end up hiring less labours causing the import competing sector to contract and thus protectionism may fail. A related series of contributions have tried to explain the link between international trade and unemployment. Hoon (1991) incorporates the unemployment model of Shapiro and Stiglitz (1984) into a Heckscher Ohlin model of trade.Footnote 8 The effect of trade on unemployment depends on the relative factor abundance of the trading nation. The labour abundant country experiences a lower unemployment rate in the post trade situation compared to its autarky state. This is due to the expansion of the labour intensive sector in the post trade situation compared to autarky. However unemployment increases for the capital abundant country, as the labour intensive sector becomes the import competing sector and thus shrinks compared to autarky. Hoon (2001) develops a dynamic Ricardian model of the world economy exhibiting unemployment due to labour shirking. International trade increases the stake in job holding, enhances the real earnings of the labourers and in equilibrium lowers unemployment. Economic shocks in one country affects the other country by shifting the terms of trade. This is true unless one of the countries is so large that it faces the same terms of trade in autarky as in the post trade situation. In Matusz (1996) a single consumer good is produced using a variety of intermediary inputs. Production of each of these inputs is subject to scale economies and markets are monopolistically competitive. The labour market is characterised by efficiency wages as in Shapiro and Stiglitz (1984). Trade increases the varieties of intermediary inputs available through imports and thus causes an expansion of the final good produced. The rise in the value of total output gets translated into a higher wage bill for the workers. At constant employment this would mean higher wages. The increased wage relaxes the efficiency wage constraint and causes an unambiguous rise in employment. The gains from trade results due to a greater division of labour, which in turn is due to the increase in the number of intermediary inputs. The resulting productivity increases the real wages and hence employment. Dutta et al. (2009) find empirical evidence that protectionism and unemployment are positively related. This paper relates to that of Dutta et al. (2009) by suggesting a possible channel through which this may occur (high elasticity of substitution). Section 2 develops the basic model, and Section 3 discusses the comparative static effects of change in tariff rates and provides some intuition for the results derived. Finally, Section 4 concludes the model.",2
18.0,4.0,"Journal of Industry, Competition and Trade",06 March 2018,https://link.springer.com/article/10.1007/s10842-018-0272-9,Systemic Cooperative Actions among Competitors: the Case of a Furniture Cluster in Brazil,December 2018,Miguel Afonso Sellitto,Juliane Luchese,,Male,Female,Unknown,Mix,,
18.0,4.0,"Journal of Industry, Competition and Trade",21 March 2018,https://link.springer.com/article/10.1007/s10842-018-0275-6,Price-setting Behavior and Competition in Developing Countries: an Analysis of Retail Outlets in Lesotho,December 2018,Mamello A. Nchake,Lawrence Edwards,Asha Sundaram,Unknown,Male,Female,Mix,,
19.0,1.0,"Journal of Industry, Competition and Trade",15 March 2018,https://link.springer.com/article/10.1007/s10842-018-0274-7,Game of Regional Environmental Policy: Europe and US,March 2019,Elias Asproudis,Nadeem Khan,Nada Korac-Kakabadse,Male,Male,Female,Mix,,
19.0,1.0,"Journal of Industry, Competition and Trade",20 April 2018,https://link.springer.com/article/10.1007/s10842-018-0276-5,On Mergers in a Stackelberg Market with Asymmetric Convex Costs,March 2019,Marc Escrihuela-Villar,,,Male,Unknown,Unknown,Male,"In a symmetric linear Cournot oligopoly setting with homogenous goods, Salant et al. (1983) showed that horizontal mergers are generally not profitable since the minimum profitable merger involves at least 80% of the firms in the industry. Unprofitability comes from the fact that non-merging firms react to the merger by increasing their output. Mergers, therefore, create an incentive to free ride as outsiders often benefit from the merger more than participants. This well-known result has been sometimes called the “merger paradox”. Many papers have subsequently tried to solve this paradox by changing some of the original assumptions. For instance, Perry and Porter (1985) study the profitability of horizontal mergers when the merged entity generates cost savings through the sharing of a tangible asset owned by merging firms or Faulí-Oller (1997) that shows that merger profitability also depends on the degree of concavity of demand. Some other papers have also tackled the issue considering a different timing. For instance, in the Stackelberg model with linear demand and symmetric cost functions, Daughety (1990) showed that the merger of two followers resulting in a leader firm is potentially profitable, and Huck et al. (2001) showed that mergers between a leader and a follower are unambiguously profitable. Other examples are Heywood and McGinty (2007a, 2008) that with convex costs obtain profitable mergers between leaders and followers and Escrihuela-Villar and Faulí-Oller (2008) that, in an asymmetric and linear cost function setting, show that a merger between a leader and several followers is always profitable regardless of the degree of cost asymmetry. On the other hand, Gelves (2010) shows that in a linear asymmetric model a two-firm horizontal merger between an inefficient leader and an efficient follower is always profitable. In some cases, thus, the leadership assumption has been sufficient to solve the merger paradox. More recently, Cunha and Vasconcelos (2015) show that if mergers give rise to efficiency gains, the free-riding problem is eliminated, and mergers are not only profitable but also welfare enhancing even with linear costs. To the best of our knowledge, however, the present paper combines for the first time the assumption of Stackelberg leadership with that of convex costs from Perry and Porter (1985) but in an asymmetric context where a leader chooses output before a group of (follower) firms that may be less efficient than the leader. We extend the analysis by Heywood and McGinty (2007a, 2008) to the case where costs are asymmetric and Gelves (2010) when asymmetry between leaders and followers is reversed.Footnote 1 This analysis proves useful to distinguish an effect that is exacerbated when introducing such a strategic timing. It is well known that the cost reduction associated when combining two asymmetric convex cost structures increases if the cost advantage is larger (as pointed out by McGinty 2007). Therefore, a leader-follower merger is always profitable regardless of the cost asymmetry since the merger permits participants not only to combine their capital as well as efficiently reallocate outputs but also to transfer output from a high-cost follower firm to a low-cost leader firm. In addition, and most importantly, we show that the free-riding effect (the profit gain from merging may be lower than that from being excluded) may reappear under cost convexity and asymmetry, in situations where it would be absent with symmetric convex costs, because the total output of the merged firm may decrease with the cost asymmetry increasing thereby the profit gain from an excluded follower. This stands in contrast to Heywood and McGinty (2008) where if the global number of followers is large enough, each follower earns more by merging with a leader than by staying as a follower. Our result thus reintroduces the free-riding issue of mergers in a Stackelberg model with convex costs that is already present in the literature with linear costs (Huck et al. 2001) or with symmetric convex costs without leadership (Perry and Porter 1985 or Heywood and McGinty 2007b). We also obtain that mergers between followers become profitable only when followers are inefficient enough compared to the leader. The intuition is as follows. On the one hand, merging followers reduce their output and may efficiently divide the new entity capital among its plants (formerly, firms) in such a way that the larger the inefficiency of the followers, the larger is also the cost saving originated by the merger through this optimal reallocation of output between the merging plants. On the other hand, we have two additional effects derived from this merger, (i) non-merging followers react to the merger expanding their production, and (ii) the leader also increases its output when two followers merge. However, the output expansion of all the non-participants (non-merging followers and the leader) is smaller if the followers are more inefficient. Intuitively, the negative slope of the aggregate reaction function of the followers decreases with their inefficiency and, as a consequence, the output produced by the leader after the merger of two followers is an increasing and concave function of the inefficiency of the followers. Therefore, when the followers are inefficient enough, the optimal reallocation of output between the merging plants compensates the output expansion of non-participants, rendering mergers profitable. Our analysis allows us to obtain that mergers of firms (namely, followers) with the same technology may be profitable in a setting where firms choose output and, therefore, a merger of two followers may be profitable regardless of the number of firms in the industry. Here, the incentive to free ride is always present since even though merging firms’ profits increase with the merger, firms would rather wait for their rivals to merge and thereby taking advantage of the higher price induced by the reduction in output due to the merger. We also study the welfare effects of the mergers considered. In this regard, it is well known from Farrell and Shapiro (1990) that, with simultaneous quantity competition, only mergers creating synergies may raise welfare. We show that mergers between followers always increase price since the effect on the price of the efficient reallocation of outputs (derived from the merger) is more than compensated by the effort of merging firms to cut production in order to reduce competition.Footnote 2 On the other hand, and interestingly enough, when the leader absorbs an inefficient follower market price only increases if the follower is sufficiently inefficient, or if the number of followers is low enough. There are two different forces at work that explain this result. First, non-merging followers react to the merger by expanding their production. Second, as long as we assume that when the leader merges with a follower the new firm will stay a leader, the merger between the leader and one former follower leads to a reduction in the number of followers that, all else being equal, drives production down. In addition, the leader includes now a relatively inefficient production plant that further cuts its production when the merged (former) follower is more inefficient. As a consequence, total output decreases after the merger whenever these output-reducing effects dominate the effect from the non-merging followers. This is true if either the number of output-expanding non-merging followers is low enough or the merged follower is inefficient enough. This result thus indicates, contrary to Gelves (2010) where mergers between an inefficient leader and an efficient follower always increase welfare, that cost asymmetries between leader and followers should be considered in order to scrutinize mergers. Summarizing, the main contribution of the present paper is twofold. First, we show that in an asymmetric Stackelberg model, even though mergers are (generally) profitable when costs are convex, the cost asymmetry reintroduces the free-riding problem. The point is that small inefficient firms might prefer to wait for their rivals to merge in order not to be forced to drastically cut production compared to the pre-merger allocation. Second, it is also shown that despite the effect of the decreasing returns to scale exploitation associated with the merger when firms have convex costs, the market price may be larger after the merger because (highly) inefficient firms drastically cut production in order to optimally reallocate outputs inside the merged firm. Consequently, the policy implications arising from the present paper are basically that, unless the cost structure of firms implies a significant profit-enhancing reallocation of outputs after the merger, we should expect mergers to occur between firms with different strategic market power. In such cases, then, antitrust authorities may be extremely wary as, in this case, welfare is certainly to be reduced. Especially because, due to the free-riding incentives, these mergers are more likely to occur when the gains stemming from the cost advantage of allocating production changes across plants are small. Although we have focused on the asymmetric Stackelberg model from a theoretical viewpoint, the present paper is also motivated by real mergers. Heywood and McGinty (2008) provide many examples of industries with dominant firms and much smaller rivals as the Standard Oil trust and the sugar trust in the USA or the IMS Health Inc. in the UK. More concretely, the dominant market shares of the Standard Oil trust and the sugar trust were maintained through the purchase of much smaller rivals. For instance, in the sugar industry, the American Sugar Refining Company was a dominant firm with a substantial market share in the first half of the 20th century. During this period, the capital stock of this firm was importantly increased since it merged with other four companies, and two other smaller firms, the California Sugar Company and the Baltimore Sugar Company, were brought under control. However, during the 1960s, the Court prohibited the takeover of even very small firms if the acquirer was a dominant firm probably expecting mergers to have adverse effects on welfare. Another interesting example is the semiconductor industry such as the DRAM (Dynamic Random Access Memory) industry, where often the leading manufacturer announces their production plans in advance. For instance, Toshiba became the leader in producing DRAM in 1985 and the manufacturers that enter the market late correspond by adjusting their quantity of DRAM produced (see Cho et al. 1998). Gugler and Siebert (2007) provide important evidence of mergers in the semiconductor industry in Japan during the period from 1989 to 1999. On the other hand, mergers between small firms in concentrated markets are not unfrequent either. Muris (1980) provides an example from the American brewing industry where from 1947 to 1976, the number of plants in the industry decreased from 465 to 94 and the number of firms from 404 to 49. Many of the mergers involved firms which were not industry leaders and had, even after the merger, market shares smaller than the larger firms in the industry. Additionally, Muris argued that despite the substantial potential for cost efficiencies, particularly in mergers not involving firms with significant market shares, the Department of Justice attacked almost every brewing merger fearing the effect of the merger on market power. In several cases, the firms were able to present evidence of these efficiencies during the litigation. The rest of the paper is structured as follows. In Section 2, we present the model. In Section 3, we analyze firms’ incentives to merge, the incentives to free ride on the merger, and the welfare impact of mergers. We conclude in Section 4. All proofs and some calculations of the model are grouped together in the Appendix.",1
19.0,1.0,"Journal of Industry, Competition and Trade",21 June 2018,https://link.springer.com/article/10.1007/s10842-018-0277-4,Financial Constraints: State Aid to the Rescue? Empirical Evidence from Belgian Firm-Level Data,March 2019,Ilona Sergant,Patrick Van Cayseele,,Female,Male,Unknown,Mix,,
19.0,1.0,"Journal of Industry, Competition and Trade",12 May 2018,https://link.springer.com/article/10.1007/s10842-018-0278-3,Testing the Quiet Life Hypothesis in the African Banking Industry,March 2019,Simplice A. Asongu,Nicholas M. Odhiambo,,Unknown,Male,Unknown,Male,"There are three main motivations for the positioning of this study: (i) surplus liquidity issues in African financial institutions and limited financial access to households and corporations (Saxegaard 2006; Fouda 2009; Asongu 2014, p.70); (ii) recent claims that banks in Africa, instead of enhancing financial access, have been enjoying a “quiet life” (Asongu et al. 2016a; Boateng et al. 2018) and (iii) gaps in the literature because the existing bulk of studies on “quiet life” in the banking industry has failed to engage the African continent. The Quiet Life Hypothesis (QLH) is a postulation that large financial institutions would invest less in enhancing financial access through the pursuit of intermediation efficiency. According to the hypothesis, instead of using their favourable market position to increase the quantity of loans and/or decrease the price of loans, such financial institutions tend to exploit such market advantages from their large size to improve their gains or enjoy a “quiet life” (Coccorese and Pellecchia 2010). The literature accords with the perspective that relative to large banks, small banks are associated with lower interest margins (see Beck and Hesse 2006; Ahokpossi 2013). For instance: the size of a bank substantially influences interest spread/variations in the banking sector (Beck and Hesse 2006); big banks are related to a higher cost of loans (see Ngigi 2013a, b) and in sub-Saharan Africa (SSA), competition-friendly policies reduce the price of loans because they enhance interbank competition (Ahokpossi 2013). From a theoretical perspective, however, large banks with substantial market influence are expected to be linked to lower interest margins owing to internal and external economies of scale. Unfortunately, big banks have been associated with financial allocation inefficiency because they contribute to reduce financial access (Mitchell and Onvural 1996). Three main narratives have been provided to elucidate this paradox in the recent financial development literature: (1) Large banks could be employing credit information agencies (such as private credit bureaus and public credit registries) to boost their profit margins (Brown and Zehnder 2010; Asongu et al. 2016b). (2) Large financial institutions are also associated with diseconomies of scale which engender management, organisational and coordination inefficiencies (Mester 1992; Clark 1996; Karray and Chichti 2013). (3) Big banks could be more focused on enjoying a ‘quiet life’ than on leveraging on their positions to boost financial intermediation efficiency (Mitchell and Onvural 1996; Boateng et al. 2018). The positioning of the study falls within the framework of the third dimension. Hence, by investigating the QLH, we seek to clarify whether big banks are reducing financial access by increasing interest margins (price of loans) and reducing credit availability (quantity of loans). In the light of the above, the positioning of the inquiry also complements a recent strand of African financial literature that is based on claims that big banks are associated with less financial access (Triki and Gajigo 2014; Barth et al. 2009; Tchamyou and Asongu 2017).Footnote 1 The complementary character of this study is based on the fact that claims from the underlying literature are founded on policy inferences of indirect nature. This is essentially because specific “quiet life” indicators are not directly engaged. We directly assess how banks with strong influence in the banking industry affect financial access in order to bridge the identified gap. Noticeably from existing literature on the QLH summarised in Table 1, the African continent has not been given the scholarly attention it deserves, despite being the region with comparatively more issues of financial access (Triki and Gajigo 2014). In essence, with the exception of Ariss (2010), who has included a few African countries, the majority of studies have failed to engage Africa. In order to assess the QLH in the African banking industry, two main hypotheses are investigated: H1: The Lerner index reduces financial access. H2: The negative effect of the Lerner index on financial access is higher in the above-median Lerner index sub-sample. In order for the hypotheses to be confirmed, we expect the Lerner index to increase loan price and reduce loan quantity. Using Two Stage Least Squares, we assess the effect of the Lerner index on financial access proxied by loan price and loan quantity. The empirical evidence is based on a panel of 162 banks from 42 countries for the period 2001–2011. The findings support the QLH, although quiet life is driven by the below-median Lerner index sub-sample. Hence, Hypothesis 1 is valid while Hypothesis 2 is rejected. The rest of the study is structured as follows. Section 2 discusses the data and methodology. Section 3 covers the empirical results while Section 4 presents concluding implications and future research directions.",13
19.0,1.0,"Journal of Industry, Competition and Trade",25 May 2018,https://link.springer.com/article/10.1007/s10842-018-0279-2,Bank Competition in Kenya,March 2019,Idi Jackson Mdoe,Jacob O. Omolo,Nelson H. Wawire,Unknown,Male,Male,Male,"Competition among commercial banks is critical in enhancing intermediation efficiency. In the long run, competition corrects the negative feature of intermediation inefficiency that manifests in the form of exceptional bank profitability driven by high interest rates and wide interest rate spreads (Flamini et al. 2009). Inherently, therefore, competition among commercial banks determines the level of entrepreneurial activities, access to finance, allocation of capital, development of the productive sector, level of economic growth and banking sector stability (Chronopoulos et al. 2015). For these reasons the competitive environment in the banking sector receives both national and international attention. Theoretically economists posit that in the long run, competition should be able to equalize returns to all economic activities through a dynamic process. Therefore, existence of exceptional profits above or below the competitive norm is a purely short run affair, which is simply a transitory condition showing the direction that resources should take for efficient allocation (Chronopoulos et al. 2015). From a theoretical perspective, therefore, there should be a tendency for excessively high profits to fall and excessively low profits to rise toward a competitive norm (Pakes 1987; Mueller 1977). Applying the theoretical proposition to commercial banking, then the underpinning argument is that exceptional bank profitability driven by wide interest rate spreads manifested in terms of high lending rates and low deposit rates is a short run affair. Such a phenomenon would be corrected by competition in the long run (Chronopoulos et al. 2015). Globally, banks in Africa have been found to be more profitable though the continent continues to experience low levels of financial intermediation (Flamini et al. 2009). This situation holds in all respects whether by country, country income group or individual banks. This paradox of more profits and less banking is a pointer to issues with competition and intermediation efficiency in Africa. A closer examination of banking in Africa reveals that the low levels of banking are not proportionately distributed. There exists a wide disparity in terms of banking in Africa. There are a few African nations with vibrant banking. For instance, the level of financial intermediation in South Africa is nearly twice that of Uganda, Tanzania and Rwanda (Sanya and Gaertner 2012). In addition, less than one third of the population in Tanzania, Uganda and Rwanda have access to finance compared to two thirds in Kenya and South Africa. Since the low levels are an average, the disparities mean that in some African nations banking is almost non existent. The cross cutting issue irrespective of the level is the paradox of exceptional profits amidst low levels of financial intermediation. Within Africa South of the Sahara (SSA)Footnote 1, South Africa’s banking sector is dominant followed by that of Kenya (Central Bank of Kenya 2015). Though playing second fiddle to South Africa, the share of East Africa’s banking in SSA has been growing with that of Kenya exceeding the SSA average between 2011 and 2014 (Central Bank of Kenya 2015). Therefore, in addressing the state of banking in SSA the status of banking in Kenya cannot be ignored. The banking sector in Kenya comprises of the Central Bank of Kenya (CBK), as the regulator, 43 commercial banks, one mortgage finance company, eight representative offices of foreign banks, nine microfinance banks, two credit reference bureaus, 13 money remittance providers and 87 foreign exchange bureaus (Central Bank of Kenya 2015). In terms of commercial banks, Kenya had three government owned banks between 2000 and 2014 (Central Bank of Kenya 2001, 2015). Domestic privately owned banks were 38 in 2005 and 27 between 2010 and 2014 (Central Bank of Kenya 2006, 2015). Private foreign banks were 11 in 2005 and 13 between 2010 and 2014 (Central Bank of Kenya 2006, 2015). This shows that the Kenyan banking sector is dominated by domestic privately owned banks in terms of numbers. In addition, it implies that bank competition can take the dimension of ownership other than the usual rivalry expected between individual banks. In terms of bank size, the CBK has categorized the banks into three categories: large, medium and small banks using a composite market share index (CMSI). The index consists of deposits, net assets and advances (Central Bank of Kenya 2011). A bank with a CMSI greater than five per percent is considered large, that with a CMSI between one per percent and five per percent is medium and those with a CMSI of less than one per percent are regarded as small. Based on this classification, there were six large banks, 15 medium sized banks and 23 small banks between 2010 and 2014 (Central Bank of Kenya 2015). The evolution of bank market share based on the CMSI index among these three categories for the period 2010 to 2014 is shown in Figure 1.
 Market share by bank size Figure 1 shows that large sized banks consistently had a large market share between 2010 and 2014. However, the share gradually decreased from 56.1 per percent in 2006 to 49.9 per percent in 2014. The contraction in the market share for the large banks is associated with an expansion in the market share for the medium sized banks. The market share for the medium sized banks gradually rose from 34.5 per percent in 2006 to 41.7 per percent in 2014. Therefore, although the large banks dominate commercial banking in Kenya, competition across the sizes is apparent. The fact that the medium sized banks have managed to wrestle a market share of about seven per percent from the other tiers means that competition among the commercial banks in Kenya is intensifying. Figure 1 further shows that the market share of small sized banks marginally declined from 9.4 per percent in 2010 to 8.4 per percent in 2014. This implies that though the small banks are the majority in terms of numbers in the banking sector, they may not be contributing much to the intensity of competition. As observed earlier, competition among commercial banks determines the efficiency of the intermediation process. Competition for deposits and lending leads to increased deposit rates and low lending rates and therefore, increased intermediation efficiency which is evidenced by low interest rate spreads and profitability consistent with the competitive norm (Berger et al. 2009). The prevailing levels of bank competition in Kenya shaped interest rate spreads and profitability as illustrated in Fig. 2.
 Trend in Bank profitability and Interest rate spread Figure 2 shows that interest rate spread was 14.24 per percent in 2000 and 9.18 per percent in 2014. The spread sharply declined between 2002 and 2005 due to improvement in macroeconomic management occasioned by regime change in 2002. Between 2010 and 2011, the spread increased considerably due to the tough monetary policy stance adopted during the currency crisis of 2010 (Central Bank of Kenya 2011). After 2011, the spread declined gradually and assumed a long run trend. The spread remained relatively stable but high compared to monetary instruments signals such as the central bank rate during periods of stable macroeconomic conditions such as 2005 and 2010. The fact that the interest rate spread, the measure of intermediation efficiency, is larger than the central bank rate and persistently so even in periods of stable macroeconomic stability means that Kenyan commercial banks are inefficient. Indeed, wide interest rate spreads are a cause of concern since such wide rates are symptomatic with systemic problems such as bank unsoundness and a lack of adequate competition (Randall 1998). Figure 2 further shows that commercial banks profitability and interest rate spread are highly correlated during periods of macroeconomic stability and tough monetary policy stance. The relative stable interest rate spread between 2005 and 2009 was, for example, associated with consistent increase in bank profitability. However, the overshoot in interest rate spread between 2010 and 2011 was associated with a jump in profitability. Therefore, persistence and overshoot of interest rate spreads is associated with continued rise in bank profitability. After the shock in interest rate spreads in 2010, bank profitability rose to even exceptional levels, underscoring the importance of high lending rates and low deposit rates in driving bank profitability in Kenya. The close association between wide interest rate spreads and commercial banks profitability means that high cost of credit causes high profitability in the Kenyan banking sector. The trends illustrated in Fig. 2 clearly show that commercial banking in Kenya has wide spreads and exceptional profitability. Therefore, commercial banking in Kenya is bedeviled by the negative feature of intermediation inefficiency that manifests in the form of exceptional bank profitability driven by high interest rates and wide interest rate spreads. Further, the trends confirm the problem of banking in Africa: low levels of financial intermediation with high profitability (Flamini et al. 2009). As per economic theory this negative feature should be corrected by competition (Chronopoulos et al. 2015). Though competition dealing with this negative phenomenon is apparent, its level is unknown. The knowledge of the level would be significant in informing policy and appropriate interventions. This study, therefore, sought to ascertain the level of bank competition among commercial banks in Kenya over the period 2001 to 2014.",2
19.0,1.0,"Journal of Industry, Competition and Trade",26 May 2018,https://link.springer.com/article/10.1007/s10842-018-0280-9,Market Power Effects of the Livestock Mandatory Reporting Act in the U.S. Meat Industry: a Stochastic Frontier Approach Under Uncertainty,March 2019,Dimitrios Panagiotou,,,Male,Unknown,Unknown,Male,"In 1999, the U.S. Congress passed the Livestock Mandatory Reporting (LMR) Act. On September 30, 2015, the Act was reauthorized for an additional five years until 2020. With the LMR program already being in effect for more than fifteen years, a number of questions arise regarding its effectiveness.Footnote 1 The U.S. Congress has a persistent interest in concentration and market power within the livestock and meat markets. High level of concentration in the U.S. meat packing industry and the impact of oligopsonistic power on livestock prices have been a major policy concern for many years. The main objective of the LMR Act was (and still is) to encourage competitive behavior in the marketplace for livestock and livestock products by providing more information to market participants. More specifically, the Act requires large U.S. meatpacking firms to report, twice a day, summary information on all cash and noncash transactions. Among other things, packers file electronically detailed quantity and price information on cattle, hogs, lambs and livestock products to the Agricultural Marketing Service (AMS) of the United States Department of Agriculture (USDA).Footnote 2 The reported information is then aggregated and published in the Mandatory Livestock and Meat Market News Reports. Aggregation is viewed as necessary in order not to encourage anti–competitive or collusive behavior by meatpacking firms, since packers might employ the increased amount of reported information on price and quantities in order to further enhance their market power or sustain collusion when procuring livestock.Footnote 3 The market effects of the LMR Act have been a largely debated public policy issue over the last years. The literature has relied mainly on theoretical works to study the effectiveness of the mandatory reporting program and has produced controversial results (Koontz and Ward 2011; Mathews et al. 2015). Some studies have suggested that increasing the information and therefore the transparency on all cash and non cash transactions, reduces uncertainty and promotes competition in the livestock markets. Azzam (2003) studied the market effects of increased transparency in the U.S. livestock sector. According to the author, transparency is taken to be the degree to which uncertainty about average livestock and meat prices is reduced as more information becomes available under mandatory reporting. Azzam’s findings indicated that in a theoretical framework where packers and cattle feeders are risk averse, reduction in uncertainty promotes competition and results in higher livestock prices. Azzam and Salvador (2004) developed a model of risk-averse Cournot firms to evaluate the change in meat-packer’s market power due to the LMR Act in five different regional markets. Their study concluded that mandatory price reporting was not collusive in one of the five regional markets under examination and the rest of them were inconclusive. In the most recent theoretical work, Boyer and Brorsen (2013) used an auction-based model to study the effects of the LMR Act. Their study suggests, among other things, that if packers’ price uncertainty is reduced, livestock feeders benefit from an increase in competition between the meatpacking firms. On the other hand, a number of studies have concluded that reporting too much information about rival pricing could facilitate coordination and foster collusive behavior among packers. Wachenheim and DeVuyst (2001) discuss how characteristics of the livestock sector increase the likelihood for collusion among packers under more transparent price reporting. More specifically, the authors argue that the LMR Act would enhance the probability for tacit collusion, increasing this way the oligopsony power exerted by packers in the livestock industry. Njoroge (2003) showed that the LMR program may enable meatpacking firms to update prior asymmetric conjectures, thus leading to a convergence of posterior conjectures. The study concluded that the Act might promote collusive behavior among packers. In a primary empirical work on the effects of the Act on oligopsonistic power exertion in the cattle market, Cai et al. (2011) used a model that allowed for switching between cooperative and non-cooperative conduct among beef packers. Their results suggest that packers’ market power increased after the implementation of the Act. More specifically, economic profits due to oligopsonistic power were risen from $0.88 per head to $2.59 per head, for the period before (1992–1999) and after the Act (2001–2010), respectively. However, the authors point out that there were other changes taking place in the market that period, such as increased market concentration, that make it difficult to attribute changes solely to the Act. The aforementioned studies raise relevant questions, mainly on a theoretical level, as to what degree mandatory price reporting has promoted competition in the U.S. meatpacking industry or facilitated coordination and increased market power exerted by meatpacking firms at the expense of feeders. The present study intends to provide empirical evidence on the market effects of the Act. In doing so, it develops a theoretical framework while combining elements from the studies of Azzam (2003), Njoroge et al. (2007) and Kumbhakar et al. (2012). In the first study, Azzam (2003) examined the effects of the LMR Act within the framework of a vertical marketing chain linking expected utility maximizing packers downstream and livestock feeders upstream. Large dominant packers exert market power when procuring livestock. A conjectural variation parameter was used in order to nest various market structures.Footnote 4 In order to account for conduct between packers, the present work employs the conjectural variation approach as well. In the second study, Njoroge et al. (2007) used the model by Green and Porter (1984) of trigger price strategies between risk–neutral firms and allowed for aversion toward risk. The authors assumed that meat-packers have formed an imperfect cartel. By introducing risk–averse packers, their work accounted for the counteractive collusive and risk effects of the LMR Act on a theoretical level. As the authors point out, an increase in the transparency would increase the effectiveness of trigger price strategies employed by the members of the cartel and would make it easier to detect defective behavior. The result would be a reduction in the quantity of livestock slaughter. This outcome the authors call it the collusive effect of the Act. On the other hand, the same transparency increase in the livestock market would reduce packers’ uncertainty and would have as a result an increase in the amount of livestock slaughter. This outcome the authors call it the (lower) risk effect of the Act. This article also assumes risk averse packers and takes into account explicitly the (lower) risk and strategic effects of increased transparency due to the LMR program. The expression strategic effect is used in this study instead of the expression collusive effect used by Njoroge et al. (2007) since we do not assume that packers have formed an imperfect cartel. In a manner similar to Wachenheim and DeVuyst (2001), this work assumes that increasing the amount of reported information about rival pricing could facilitate coordination among meatpacking firms and increase packers’ market power when procuring livestock. In the last study, Kumbhakar et al. (2012) drew on the stochastic frontier methodology from the efficiency literature (Coelli et al. 2005; Kumbhakar and Lovell 2003) and developed a stochastic frontier (SFA) estimator of market power. The authors used their estimator in order to measure the degree of market power in an output market. This methodology has been applied to the U.S. food industry by Lopez et al. (2018), to the U.S. cattle industry by Panagiotou and Stavrakoudis (2017) and to the Brazilian milk market by Scalco et al. (2017). One of the big advantages of the SFA estimation approach is that it bypasses the estimation of demand and conduct needed in new empirical industrial organization models to measure the gap between price and marginal cost of production (Lopez et al. 2018). This work employs the SFA estimator in order to measure market power exerted by meat-packers when purchasing livestock, employing this way the stochastic frontier approach of market power estimation in an input market. The present paper develops a theoretical model that takes into account the counteractive risk and strategic effects of increased transparency generated by the Act.Footnote 5 The model is then employed in order to empirically estimate the degree of market power exerted by meat-packers when procuring livestock. Market power estimates are acquired with the use of the recently developed SFA estimation technique. The estimated values of the degree of market power, before and after implementation of the LMR Act, will provide evidence on the market effects of the Act. If the Act has generated a pro–competitive impact in the livestock sector, a decrease in the degree of market power is to be expected, suggesting this way that the risk effect has dominated the strategic effect of the Act. On the other hand, if the Act has promoted anti–competitive behavior (facilitated coordination) among meat-packers, one would expect an increase in the value of the degree of market power exercised in the livestock sector, suggesting this way that the strategic effect has dominated the risk effect of the Act. The present study relates to a certain degree with the the most recent work by Panagiotou and Stavrakoudis (2017). In their study, the authors derived a stochastic production frontier estimator of market power in order to empirically measure the degree of oligopsony power in the U.S. cattle industry. The empirical results are obtained with the use of the physical quantities of the factors of production. In this work, the empirical results are obtained with the employment of a stochastic cost frontier estimator of market power and with the employment of the prices of the factors of production. Additionally, the present study assumes that packers are risk averse and models for uncertainty in the market whereas the study by Panagiotou and Stavrakoudis assumes that beef-packers are risk neutral. Lastly, this manuscript presents results for both the cattle/beef and the hog/pork packing industries whereas the study by Panagiotou and Stavrakoudis considers only data from the cattle/beef sector. Both studies, the present article and Panagiotou and Stavrakoudis (2017), find evidence of statistically significant market power in the meat-packing sector(s). The main contribution of this work is that it develops a model and empirically tests and identifies changes in market power in the US cattle and hog sectors, due to the implementation of the mandatory reporting program. Changes in market power are attributed in the strategic and the risk effects generated by the introduction of the LMR Act. To the best of our knowledge, there is no published work that accounts for uncertainty in the stochastic frontier methodology of market power estimation. The present work is structured as follows: Section 2 contains the theoretical framework and Section 3 the empirical model. Data are presented in Section 4. Results and discussion are in Section 5. Section 6 offers conclusions.",3
19.0,1.0,"Journal of Industry, Competition and Trade",26 May 2018,https://link.springer.com/article/10.1007/s10842-018-0281-8,Industrial and Innovation Policies in the Mexican Biotechnology Sector,March 2019,Federico Stezano,,,Male,Unknown,Unknown,Male,"This article is guided by the following research question: what are the possibilities of an industrial ascent of the Mexican biopharmaceutical sector based on creative imitation? In this context, the empirical goal of this study is to identify, typify and catalogue the modes of insertion configuring technological trajectories within the pharmaceutical industry in Mexico by taking into account: (i) their science and technology (S&T) base; (ii) the technological capabilities of firms in the sector, (iii) the institutional responses to global regulatory trends at the sector level, and (iv) the general national production development vision supporting the sector’s development path. Thus, this study seeks to explain the potential for knowledge-intensive production activities to modify the production structure and allow for production specialization based on increasing activities that provide higher productivity and more added value in Mexico. This entails the emergence of new areas in the sector with the role of creating new technologies and performing cross-sectional dissemination of biotechnological solutions in the value chain associated with human health. An explanation of these multi-dimensional processes is based on an explanatory framework that combines two analytical approaches. A theoretical branch emphasizes the analysis of the technical and productive factors of innovation from macro-models articulated in the concepts of technological regimes, paradigms, dynamics and trajectories. On the other hand, a vision of institutional regimes highlights the relevance of historical sociopolitical and cultural factors that enable certain models and styles of innovation at the national level. The concepts of regime at the institutional and technological level seek to adopt a causal explanation guided by the search for patterns that characterize the establishment of paths and inertias and, at the same time, define the environment and the conditions under which development processes can be established. From a conception of development as a process of structural change of social and economic institutions (Portes 2015). In this way, the explanatory framework of this work combines general models that explain the relations between State, economy and society. Where the concept of regime accounts for regularities and patterns of mediations between scientific, economic, political, productive, technical and social orders (Lesemann 2007). As explanatory categories, technological regimes allow for the differentiation of trajectories guided by technological paradigms and dominant designs (Cimoli and Dosi 1995: 245). Defining the notion of technological paradigm is the starting point of a comprehensive analysis of technological trajectories. The concept of paradigm underscores three central ideas about technology by providing: (i) a definition of technology and an insight into how changes in a technology reflect specific forms of the knowledge base of a particular activity; (ii) a specific heuristic and certain views on how to do things and improve them collaboratively, and (iii) models of artifacts and systems that change and improve with time given certain technical and economic circumstances (Cimoli and Dosi 1995: 245–246). The idea of regimes makes an ideal theoretical framework to analyze innovation forms and processes of technological change -or inertia-. The array of concepts and theories comprising the notion of technological regimes and their manifestation as technological trajectories broaden the possible explanations for change and stability of processes by considering the dynamics behind sectoral technological transformations. Technological trajectories synthesize the patterns that determine the specific heuristics (problem resolution) of each technological paradigm. This conceptualization assumes that the development paths shown by technological trajectories determine the potential orientation of those heuristics (Dosi 1982: 152). From a perspective of institutional regimes, the perspective of varieties of capitalism emphasizes the role of the institutional conditions that favor certain national innovation styles. From the concept of institutional comparative advantages, this approach suggests that the institutional structure of a political economy generates certain conditions for companies to undertake certain activities to produce certain types of products. This vision emphasizes the factors that give advantages in the profiles of productive specialization and innovation, linked to the regimes of regulation, the organization of economic actors, the structures of the State, the environment of public policies and institutions as types of social arrangements and as interactions of the political sphere with society (Hall and Soskice 2001). This article analyzes the possibilities of an industrial ascent of the Mexican biopharmaceutical sector based on creative imitation. In the pharmaceutical and/or biotechnological sector, creative imitation refers to firm strategies focused on competition mechanisms via imitation and development of biosimilar and generic pharmaceutical products after brand medication patents have expired (Cefis et al. 2006: 165). The emergence of various national endogenous technological change initiatives (e.g., creative imitation processes) is associated with late industrialization and favorable or unfavorable circumstances for developing countries to achieve a dynamic insertion into the technological paradigms of emerging sectors. These contents of the work are organized as follows. The first section analyzes the biopharmaceutical-related S&T knowledge base in Mexico by especially highlighting the innovation/imitation strategies used by Mexican firms in the sector to achieve a place in development and manufacturing activities in the biopharmaceutical industry; the lack of strong links between the production sector and the national research infrastructure is also analyzed. The second section discusses the technological capabilities of firms by addressing the considerable difficulties they face in capitalizing knowledge produced during the different industrial stages of biological extractive development and to generate new technological learning within the sector, except in some exceptional cases. The third sections deal with the national institutional capacities and the positions that firms in the sector and government regulatory organisms have taken in view of the increasing international regulatory barriers in regard to intellectual property, as well as the most important strategies around venture capital and government purchasing as incentives to national development. Finally, the conclusions section makes a cross-sectional analysis of the extent to which the dimensions discussed previously are based on a national strategy for scientific and production development guided by an intentional agenda.",3
19.0,1.0,"Journal of Industry, Competition and Trade",28 May 2018,https://link.springer.com/article/10.1007/s10842-018-0282-7,Platform Competition with Intra-Group Externalities,March 2019,Barna Bakó,Dániel Fátay,,Male,Male,Unknown,Male,"According to Rochet and Tirole (2003) many markets with network externalities are two-sided markets. In general, these markets are characterized with two distinct sides that benefit from being able to interact with each other through a common platform. Good examples abound from credit cards, computer operating systems and video game consoles to job recruitment agencies and dating sites. The core concept behind the model of two-sided markets is that the utility obtained by each side of the market is crucially affected by the size of the other side of the market. Credit card holders, for example, gain positive network effect if their card is widely accepted and merchants that accept the card are affected positively if the number of card holders increase. Although the topic of two-sided markets is well researched (see e.g. Rochet and Tirole 2003; Armstrong and Wright 2006; Armstrong 2006; Weyl 2010; Hagiu and Halaburda 2014; Vasconcelos 2015) to the best of our knowledge no attention has been paid to the asymmetric case of such markets. A good example for an asymmetric two-sided market would be the social media (e.g. Facebook, WhatsApp, Snapchat, Twitter, etc). While it is reasonable to assume that the number of users of a social media crucially affects the utility gained by the advertisers, the complementary assumption related to the network effect caused by the advertisers is perhaps secondary. Users most likely join the platform in order to interact with each other rather than to interact with the advertisers. If this is the case, such markets must be modeled with this asymmetric network effect in mind since the original symmetric two-sided models can be misleading and might lead to inaccurate conclusions. In this article we analyze asymmetric two-sided markets. Two types of agents are assumed to interact with each other and we assume that agents of one type derive utility from inter-group interactions, while agents of the other type benefit from intra-group rather than from inter-group interactions as it is assumed in the standard symmetric two-sided market model. First, we consider a monopoly platform, then we analyze competing platforms, both with single-homing and multi-homing abilities.",1
19.0,1.0,"Journal of Industry, Competition and Trade",11 June 2018,https://link.springer.com/article/10.1007/s10842-018-0283-6,Bank Competition and Access to Finance: Evidence from African Countries,March 2019,Misraku Molla Ayalew,Zhang Xianzhi,,Unknown,,Unknown,Mix,,
19.0,2.0,"Journal of Industry, Competition and Trade",14 December 2018,https://link.springer.com/article/10.1007/s10842-018-0287-2,Revisiting the Causal Effects of Exporting on Productivity: Does Price Heterogeneity Matter?,June 2019,Tewodros Ayenew Wassie,,,Unknown,Unknown,Unknown,Unknown,,
19.0,2.0,"Journal of Industry, Competition and Trade",12 December 2018,https://link.springer.com/article/10.1007/s10842-018-0288-1,Explaining the Current Innovative R&D Outsourcing to Developing Countries,June 2019,Zachary Cohle,,,Male,Unknown,Unknown,Male,"Innovative research and development, or R&D for the creation of a new product, has largely been kept in the developed world. In 2016, 16% of R&D carried out by majority owned foreign affiliates of US multinational firms was in developing countries (US BEA 2018). While two of the largest attractions for R&D offshoring in the developing world, India and China, largely remain sites for adaptive research, or research for the purpose of adapting an existing product for sale in the host country, a few firms in the forefront of technology in their respective industries have started locating more advanced types of research in these regions (Lundin and Serger 2007). For example, survey evidence from Sun et al. (2006) shows a majority of foreign R&D labs in Shanghai engage in adaptive research and development; however, GE is among the few multinational firms in the city conducting innovative R&D. Despite the low cost of capable labor in developing countries, firm have been hesitant to outsource innovative R&D to these regions, where intellectual property rights (IPR) protection is weak. Using labor costs, IPR-protection, and the threat of imitation from a competing firm, I explain the limited amount of multinational firm innovative R&D investment in the developing world. Using a North-South model, I examine a single firm, the Northern firm, and the firm’s decision to locate innovative R&D in either the North or the South in the context of a number of different competitive environments. The Northern firm has a fixed number of research tasks that must be completed in order to develop a new, unique product. Researchers in the South are exactly as capable as researchers in the North; however, Southern researchers earn a significantly lower wage. I use a partial equilibrium model in which the Northern firm first chooses research locations to carry out its fixed amount of necessary research. A competing firm, the Southern firm, has the chance to absorb some Southern researchers in order to emulate the Northern firm’s product. After the fixed cost of entry has been paid, the Northern firm chooses production decisions and either acts as a monopolist or competes against the Southern firm. In explaining the small amount of offshoring of innovative research to the developing world, this model distinguishes itself from past literature concerning IPR-protection through its treatment of innovative R&D as a fixed cost of entry. Similar to Melitz (2003), I model R&D as a necessary fixed cost of entry; however, the way in which the firm pays the fixed cost has real ramifications on production profits. Following Lai et al. (2009), I include the notion of information leakages when outsourcing R&D. I use a probabilistic view of information leakage related to the intensity of the research done in the South. My model uses the notion of Southern researchers starting their own or defecting to a competing firm as the channel of imitation. Researchers hired in the South, unlike their Northern counterparts, can leave to either start their own firm or join a competing firm. Furthermore, the probability of Southern researchers leaving as a team increases as the Northern firm hires more Southern labor. The probability of the Southern firm successfully copying the product and entering the market is modeled as a Tullock contest. In a Tullock contest, each player puts forth a certain amount of effort in order to attempt to win the contest. I introduce a proxy for player effort: the number of researchers employed by the Northern firm in each country. My primary findings are as followed. First, a firm’s research needs determine its location decisions. Firms in low-tech industries, or firms that require less total R&D, locate in the North while firms in high-tech industries, or firms with large research needs, locate entirely in the South. Intuitively, the firms with a large need for research and development have a large fixed cost in order to enter the market. These firms are more willing to risk their product being imitated in order to reduce the fixed cost of entry by hiring lower wage researchers. Firms with intermediate research need locate in both countries. A main result of the model is the ambiguous effect of IPR-protection on R&D location decisions. Low-tech firms that require little research respond to a weakening of Southern IPR-protection by locating less research in the South. The increase in the probability of imitation caused by the IPR-protection reform induces the Northern firm to avoid the risk of imitation by locating more research in the North. On the other hand, high-tech firms respond to a weakening of IPR-protection by shifting more research to the South. A firm with high research needs, or a large fixed cost of entry, reacts to the decrease in expected revenue by further decreasing expected revenue in favor of decreasing the fixed cost of entry. This reduction of fixed cost minimizes the loss in expected profit. The next finding relates possible operating profit and research locations. A large difference between monopoly and duopoly profit induces the Northern firm to locate more research tasks in the North. Imitation leads to a decrease in operating profit due to increased competition. When the decrease is large, the Northern firm finds it more profitable to protect their patent than to cut costs in the R&D phase. Finally, holding the penalty of imitation constant, a large wage gap between the North and South encourages Southern research; however, the large wage gap might also imply a large penalty of imitation. This paper is organized as follows. Section 2 summarizes related literature. Section 3 presents the assumptions, functional forms of the model, and the partial equilibrium solutions. Section 4 presents the results of the model. Section 5 concludes the paper.",6
19.0,2.0,"Journal of Industry, Competition and Trade",11 October 2018,https://link.springer.com/article/10.1007/s10842-018-0286-3,Combining the Endogenous Choice of the Timing of Setting the Levels of Strategic Contracts and Their Contents in a Managerial Mixed Duopoly,June 2019,Yasuhiko Nakamura,,,Male,Unknown,Unknown,Male,"Following Hamilton and Slutsky (1990), we investigate an endogenous timing game called the observable delay game for a managerial mixed duopoly composed of one public firm with a welfare-maximizing owner and one private firm with a profit-maximizing owner. The public and private firms set the level and the content of their respective strategic contracts. In both cases, the timing of these events is endogenized, as in Sun (2013) and Din and Sun (2016). That is, the equilibrium market structure is considered in a private duopoly composed of private firms only, as well as in a mixed duopoly composed of a public firm and a private firm. In the latter case, we focus on the situation in which the owners of both firms offer their managers sales delegation managerial contracts, following Fershtman and Judd (1987), Sklivas (1987), and Vickers (1985) (FJSV delegation). Given this setting, we compare the equilibrium and socially preferable market structures in a managerial mixed duopoly from the viewpoint of social welfare. Then, we derive the implications for policies that regulate when the firms’ owners set the content and level of their respective strategic contracts. Prior studies on oligopolistic markets have explored the selection of strategic contracts by firms as long-term decisions, including those on horizontal and vertical mergers, collusion, capacity, R&D levels, and so on. The seminal studies of Singh and Vives (1984) and Klemperer and Meyer (1986) provide fundamental models of firms’ endogenous choices of strategic contracts in an oligopolistic market without separation between ownership and management.Footnote 1 Since these works, many theoretical studies have focused on endogenous selection in a private oligopoly composed of profit-maximizing private firms.Footnote 2 These studies have examined the endogenous selection of firms’ strategic contracts in the context of private oligopolies composed of profit-maximizing private firms. However, they all face a similar problem, namely that many markets also include public and semi-public enterprises. Matsumura and Ogawa (2012) were the first to consider a model of strategic contracts for public and private firms in a mixed oligopoly using the approach of Singh and Vives (1984) and Klemperer and Meyer (1986).Footnote 3 Many researchers in this field have attempted to solve the endogenous selection of strategic contracts in a managerial oligopoly characterized by a separation between ownership and management in each firm. In particular, many of these studies examine the management structure of such firms using the FJSV delegation approach.Footnote 4 Moreover, Chirco et al. (2014) study the endogenous determination of strategic contracts by the owners of a public and a private firm in a managerial mixed duopoly. Here, the owners also select an entrepreneurial structure or a managerial structure (i.e., whether or not to hire managers to whom FJSV delegation contracts are provided). Subsequently, Nakamura (2015a) introduced a new type of managerial delegation contract for the public firm into the endogenous selection problem of the public and private firms’ owners. This new contract is a weighted sum of social welfare and the difference between the consumer surplus and the producer surplus. In the observable delay game of Hamilton and Slutsky (1990) for a mixed oligopoly, the seminal study of Pal (1998) considers the endogenous order of moves in the timing choice of quantities in a homogeneous goods market.Footnote 5 Then, Matsumura and Ogawa (2014) explore the importance of payoff (a)symmetry in an endogenous timing game, where the firms’ objective functions are equal to the weighted sum of social welfare and their respective profits as their (corporate) social responsibility. Recently, studies in this field have begun examining the endogenous timing problem of setting strategic contract levels in an oligopolistic market, focusing on the separation between ownership and management. For example, Nakamura (2018a) investigates an endogenous timing game in a managerial private duopolistic market with FJSV delegation, with two possibilities: \(\left (1\right )\) the strategic contracts of the two firms are different; and (2) the two firms’ products are substitutes/complements. Taking into account the importance of \(\left (1 \right )\) the endogenous timing problem of strategic contract levels for firms’ owners, and \(\left (2 \right )\) the endogenous determination of the contract content, Sun (2013) unifies these factors in a product-differentiated private duopoly model. The results show that the unique equilibrium outcome is simultaneous quantity competition if the goods are substitutes, and simultaneous price competition if the goods are complements. Furthermore, in the context of a mixed duopoly and the same game as that explored by Sun (2013), Din and Sun (2016) show that simultaneous price competition is the unique equilibrium market structure, regardless of whether the goods are substitutes or complements. This study determines the equilibrium market structures in a managerial mixed duopoly composed of one public firm with a welfare-maximizing owner and one private firm with a profit-maximizing owner. To do so, we consider a model that separates ownership and management, in addition to the above factors.Footnote 6 More precisely, the owners of both firms announce the level and content of their strategic contracts in the pre-play stage in an observable delay game, à la Hamilton and Slutsky (1990). This occurs before determining the managers’ incentive parameters and the start of the market competition in a managerial mixed duopoly.Footnote 7 In this study, we first consider a game that endogenizes when the firms choose to set their strategic contract level, with the content being fixed: \(\left (1 \right )\) the q–q game, where the strategic contracts of both firms are quantity contracts; \(\left (2 \right )\) the p–p game, where both strategic contracts are price contracts; \(\left (3 \right )\) the p–q game, where the strategic contract of the public firm is a price contract, and that of the private firm is a quantity contract; and \(\left (4 \right )\) the q–p game, where the public firm chooses a quantity contract, and the private firm chooses a price contract.Footnote 8 Nakamura and Inoue (2007) derive the equilibrium market structures when the goods are substitutes in the q–q game, finding two market structures: \(\left (1 \right )\) the public firm is the leader and the private firm is the follower; and \(\left (2 \right )\) the public firm is the follower and the private firm is the leader. In this study, we find that the q–q game can become the equilibrium market structure when the goods are complements. In addition, the highest social welfare in the game is achieved in the equilibrium market structure where the manager of the public firm is the leader and the manager of the private firm is the follower, regardless of whether the goods are substitutes or complements. Then, for the p–p game, Nakamura and Inoue (2009) show that the market structure in which the managers of both firms set their respective prices in the later period simultaneously is a unique equilibrium market structure when the goods are substitutes. We confirm that this result holds for both substitute and complementary goods. Moreover, for the p–p game, we find that the unique equilibrium market structure does not yield the highest social welfare, regardless of whether the goods are substitutes or complements. We also derive the equilibrium market structure when the firms’ choices of when to set their strategic contract levels in an asymmetric game affect their strategic contracts. First, in the p–q game, we show there is no equilibrium market structure in pure strategies, because the owner of the public firm wishes to set the level of his strategic contract sequentially, while the owner of the private firm wishes to do so simultaneously. In the q–p game, we find that the market structure where the manager of the public firm is the follower and the manager of the private firm is the leader can become a unique equilibrium market structure, regardless of whether the goods are substitutes or complements. In this case, the highest social welfare can be achieved in the unique equilibrium market structure. Next, we explore the equilibrium market structures when the contents of the firms’ strategic contracts are endogenized and the level timing is fixed: \(\left (1 \right )\) the SSmm case, where the managers of the firms set the levels of their strategic contracts simultaneously; \(\left (2 \right )\) the LFmm case, where the manager of the public firm is the leader and the manager of the private firm is the follower when setting the strategic contract levels; and \(\left (3 \right )\) the FLmm case, where the manager of the public firm is the follower and the manager of the private firm is the leader when setting the strategic contract levels. In the SSmm case, Matsumura and Ogawa (2012) and Din and Sun (2016) show that in a mixed duopoly, the p–p game can become the equilibrium market structure uniquely in an entrepreneurial situation, where the owners make all managerial decisions. However, we find no equilibrium market structure under the pure strategic contract class in the managerial case. In addition, in the entrepreneurial case, the highest social welfare is achieved in the p–p game, which is the unique equilibrium market structure. In our case, the highest social welfare is achieved in the p–p game, but this is not an equilibrium market structure. Thus, in the SSmm case, providing the manager in either type of firm with an FJSV delegation contract changes the need for a policy to regulate the free selection of the contents of strategic contracts, based on individuals’ incentives, according to their payoffs in a mixed duopolistic market. Furthermore, we find that in a managerial mixed duopoly, the p–q game and the p–p game can become equilibrium market structures in the LFmm case. Furthermore, the q–p game and the p–p game can become equilibrium market structures in the FLmm case. These two results hold when the timing of setting the levels of the strategic contracts by both firms is asymmetric. Finally, we compare the equilibrium market structures with the socially preferable market structures from the viewpoint of social welfare in a game that endogenizes when firms set the level and the content of their strategic contracts. This approach follows that of Sun (2013) and Din and Sun (2016), who investigate an entrepreneurial private duopoly and an entrepreneurial mixed duopoly, respectively. We compare the equilibrium and socially preferable market structures from the viewpoint of social welfare in an observable delay game. Here, the owners of both firms set the level and content of their strategic contracts in the pre-play stage, before determining the specific levels of their strategic variables in the market (Hamilton and Slutsky 1990). We show that the q–p game in the FLmm case can become both a unique equilibrium and a socially preferable market structure from the viewpoint of social welfare. Consequently, it is not always necessary for an authority to regulate when owners can set the level and content of their strategic contracts in public and private firms in a managerial mixed duopoly with FJSV delegation. The remainder of this paper is organized as follows. In Section 2, we formulate a differentiated-goods mixed duopolistic model, in which the owners of the public and the private firms choose when to set the level and content of their strategic contracts. In Section 3, we consider a game in which the content of the contracts is fixed, and owners choose when to set the strategic contract level endogenously in both firms. Here, there are four subgames, classified by the contents of the strategic contracts: the q–q game, p–p game, p–q game, and q–p game. Subsequently, we derive the equilibrium market structure(s) under the pure strategic contract class by comparing the payoffs of the owners in the four games. Then, we compare these with the socially preferable market structures.Footnote 9 In Section 4, we conduct similar analyses to those in Section 3 for a managerial mixed duopoly with FJSV delegation. Here, we examine a game in which the contents of the strategic contracts of both firms are determined endogenously, while the choice of when to set their levels is fixed. Once again, we compare the equilibrium and socially preferable market structures. In Section 5, we explore the full observable delay game for a managerial mixed duopoly with FJSV delegation. In this case, both the levels and contents of the contracts are determined endogenously by the owners of the firms. Lastly, Section 6 concludes the paper.Footnote 10",3
19.0,2.0,"Journal of Industry, Competition and Trade",03 January 2019,https://link.springer.com/article/10.1007/s10842-018-0289-0,On Cooperation Through Alliances and Mergers,June 2019,Manel Antelo,David Peón,,Male,Male,Unknown,Male,"The debate about alliances and mergers as strategic substitutes in searching for new opportunities to grow is gaining momentum in recent years because of the growing volume of these operations worldwide and across industries, as well as because of its academic interest. Through alliances, firms collaborate in search of mutual profits, but remain competitors in the product market, while through mergers and acquisitions (M&As) resources of involved firms are put under common ownership. Though often different in instances such as size, riskiness, and time duration, their key difference is ownership. Hence, since firms may choose between the two strategies to improve their performance, the analysis of the pros and cons of selecting one alternative or another becomes relevant. Neither theoretical models nor empirical results are clear-cut in that sense. Theories include the resource-dependence theory and transaction costs—to analyze which strategy induces more cost-benefit advantages—and industrial organization theory—which suggests that alliances are more likely to occur in concentrated industries because a collusive behavior is easier to be established with the fewer competing firms. For instance, several articles (e.g., Yin and Shanley 2008; Das 2011; Atallah 2015) cite the three-firm Cournot oligopoly case with linear demand and constant marginal costs where an alliance between two firms is always better than a merger as the way to reduce their cost (Sawler 2005). These alliances are unequivocally the best strategy due to the fact that they avoid the problem of transferring market share to the firm that remains outside the agreement. However, a more comprehensive assessment of the superiority of one type of agreement or another from the standpoint of firms, both those involved in the agreement and those remaining outside, consumers, and the society as a whole needs the consideration of a more general setup than one with three firms and two of them engaged in an agreement to saving costs. In fact, in an n-firm industry, where a subset of m firms may choose to collaborate to get access to a cost-saving opportunity, either through an alliance or through a merger, the analysis becomes richer and more variable results hold depending on the efficiency level of firms and cost cuts available by cooperation. Alliances are preferred to mergers in cost-efficient industries, the larger the cost reduction available by collaborating, and the more competitors in the industry, whereas mergers only become more probable with a higher number of collaborating firms. These results are also discussed in terms of consumer surplus and aggregate welfare to show that consumers always prefer alliances, while the only implemented mergers that are socially desirable overall are those achieved in efficient industries when the number of merged entities is relatively low. Finally, since a key prediction of our model—that alliances are preferred the more competitors in the industry—contradicts the basic tenets of industrial organization theory, we end up our analysis with an interpretation of this result: for insiders, controlling the number of collaborating firms is the device they use to control for the degree of market competition. Beyond that, we provide a discussion of two assumptions that might explain the paradox. One is assuming that alliances and mergers offer similar cost reduction possibilities, when perhaps alliances can achieve larger cost cuts in concentrated industries. The second is the assumption in our model that entrepreneurs manage their own companies, whereas introducing strategic delegation and managerial incentives might induce alternative results. The rest of the paper is organized as follows. In the next section, we revise the state of the arts regarding the choice between alliances and mergers. In Section 3, we present the model and obtain the main results. Section 4 is devoted to the analysis in terms of social welfare. Section 5 concludes the paper.",1
19.0,2.0,"Journal of Industry, Competition and Trade",02 August 2018,https://link.springer.com/article/10.1007/s10842-018-0285-4,The Construction Industry and (Dis)Economies of Scope: Empirical Research in the Hokkaido Procurement Auction,June 2019,Koki Arai,Emi Morimoto,,Male,Female,Unknown,Mix,,
19.0,2.0,"Journal of Industry, Competition and Trade",03 August 2018,https://link.springer.com/article/10.1007/s10842-018-0284-5,Contestability in the Digital Music Player Market,June 2019,Wei Dai,Kam Yu,,,Male,Unknown,Mix,,
19.0,2.0,"Journal of Industry, Competition and Trade",30 January 2019,https://link.springer.com/article/10.1007/s10842-019-00292-6,Strategic Emission Fees: Using Green Technology to Deter Entry,June 2019,Ana Espínola-Arredondo,Felix Munoz-Garcia,Boying Liu,Female,Male,Unknown,Mix,,
19.0,3.0,"Journal of Industry, Competition and Trade",04 July 2019,https://link.springer.com/article/10.1007/s10842-019-00309-0,Sweetening the Pill: a Theory of Waiting to Merge,September 2019,Eileen Fumagalli,Tore Nilssen,,Female,Male,Unknown,Mix,,
19.0,3.0,"Journal of Industry, Competition and Trade",09 January 2019,https://link.springer.com/article/10.1007/s10842-018-0290-7,State Aid and Competition: Application of a Social Welfare Criterion to State Aid,September 2019,Koert van Buiren,Daan in ‘t Veld,Janneke van der Voort,Male,Male,Female,Mix,,
19.0,3.0,"Journal of Industry, Competition and Trade",09 March 2019,https://link.springer.com/article/10.1007/s10842-019-00293-5,Pricing Decisions and Competitive Conduct Across Manufacturing Sectors: Evidence from 19 European Union Manufacturing Industries,September 2019,Chrysovalantis Amountzias,,,Unknown,Unknown,Unknown,Unknown,,
19.0,3.0,"Journal of Industry, Competition and Trade",06 March 2019,https://link.springer.com/article/10.1007/s10842-019-00295-3,Trade Openness and Domestic Market Share,September 2019,Aya Elewa,,,Female,Unknown,Unknown,Female,"Over the last two decades, theoretical works studied how trade liberalization affects the market structure through its impact on firms’ behavior. The seminal model of Melitz (2003) shows that trade openness leads to the exit of the least productive firms as they could not afford the competition faced from foreign firms (Bernard et al. 1995). Due to the existence of fixed and sunk costs of exporting, only the most productive firms could afford these costs and start to export. Thus, trade liberalization increases the average productivity available in the market. Recently, the emergence of micro-data sets encourages researchers to evaluate the impact of trade openness on firms’ behavior following periods of trade liberalization. Therefore, the analysis of trade openness has shifted from countries and sectors to firms and products. This paper focuses on the evaluation of the impact of trade reforms adopted in 2004 on the domestic market structure in Egypt. Doing so, the paper studies how market share of the manufacturing firms varies after 2004 wave of trade reforms. The analysis of the Egyptian market is quite interesting since Egypt has witnessed major reforms concerning both trade and competition policies during the 1990s. In order to improve the business environment after adopting the privatization process, the Egyptian government has adopted policies of liberalization since the early 1990s during the Economic Reform and Structural Adjustment Program (ERSAP). The maximum tariff rate has fallen from 110% at the end of 1980s to reach 40% by the end of 1990s. In 2004, the Egyptian market becomes more liberalized thanks to a new phase of trade reforms that reduces both tariff and non-tariff barriers. Following these reforms, the nominal and the effective protection rates in the manufacturing sector fall from 21.3 to 12.1% and from 23.3 to 14% respectively. On the other hand, concerning the competition policy, and thanks to the Egyptian European Partnership, the government has considered its competition law to be more effective to be able to join the free-trade area with the European Union (EU). Moreover, there were great demands to ensure an effective competition policy following periods of great privatization. This paper studies the implications of heterogeneous-firm trade models by examining how the market structure in Egypt was affected by the evolution of trade costs. A key contribution of this analysis is the linkage between Egypt domestic firm-level data from the World Bank Enterprise Survey and product-level tariff data from the UNCTAD and WTO databases. Trying to assess the impact of trade openness on the domestic market share of the Egyptian firms and hence their revenue, this paper’s contribution is twofold: First, it tries to fill the gap in the literature concerning the impact of trade on domestic market outcomes (domestic sales and market share). Second, it is the first attempt to study how the decline in trade costs changes the Egyptian market structure. The potential link between trade openness and level of competition in the domestic market is very important to evaluate in order to assess the interaction between trade and competition policies and conclude whether they are seen as complements or substitutes. Trade openness affects firms’ behavior, which in his turn changes the market structure. Following Melitz (2003) in this part, as the less productive firms exit the market after the decline in trade costs, his model predicts that the market share of the domestic firms will fall following periods of trade liberalization for all surviving firms. Following periods of tariffs cut, the number of firms selling in the domestic market increases, and so does the total number of varieties available to domestic buyers. Therefore, trade liberalization leads to pro-competitive effects due to the increase in the number of sellers and varieties. Trade liberalization policies and competition policy are not dissociated; there are many theoretical works that conclude that trade liberalization may facilitate the collusion between foreign and domestic firms as the punishment after the decrease in trade costs is more severe.Footnote 1 Indeed, there was evidence of international cartels formed after periods of openness between home and foreign firms. The paper is organized as follows: Section 2 reviews the literature on trade and competition. Section 3 shows the theoretical background to our empirical part. Section 4 presents some stylized facts. Section 5 shows the methodology and the data used. Finally, Section 6 concludes.",
19.0,3.0,"Journal of Industry, Competition and Trade",29 March 2019,https://link.springer.com/article/10.1007/s10842-019-00299-z,"Business Hours, Store Quality, and Social Welfare",September 2019,Mai Yamada,,,Female,Unknown,Unknown,Female,"In the retail sector, the restriction of business hours is an important issue for both retail organizations and consumers. In some European countries and Australia, the regulation of trading during public holidays and weekends is a controversial topic. In Japan, the government introduced liberalization in 2000 to develop the economy and improve the lives of citizens. Many Japanese retailers extended their business hours. In 2014, about 86% of convenience stores remained open 24 hours a day. About 50% of general merchandise stores trade during late hours.Footnote 1 However, local governments have claimed that business hours in the retail sector should be regulated to protect landscapes. How does regulation affect competition among stores in the retail sector? Which is better for society, regulation or liberalization? Empirically, early studies show that liberalization increases sales in large retail stores (Morrison and Newman 1983) and raises prices charged by large retail stores (Tanguay et al. 1995). Some studies show that liberalization leads to lower prices in the retail sector (Kay and Morris 1987; Reddy 2012). A study on American “Blue Laws” finds that the restriction depresses retail prices (Burda and Weil 2005). On the other hand, a recent study on the restriction on Sunday trading in Europe shows that the restriction does not significantly affect retail prices (Genakos and Danchev 2015). A study on time allocation for consumers’ shopping time shows that the liberalization increases their shopping time (Jacobsen and Kooreman 2005). Theoretically, recent studies, which endogenously determine business hours, find that liberalization leads to increased prices (Inderst and Irmen 2005).Footnote 2 Studies that extended Inderst and Irmen’s (2005) model show that liberalization enhances social welfare (Shy and Stenbacka 2008; Wenzel 2011; Flores and Wenzel 2016). Existing literature has overlooked retailers’ investment in store quality (e.g., product or service quality). The investment in store quality plays an important role in the competitiveness of the retail industry. Recently, many Japanese retailers have increased quality investments to attract more demand. For instance, SEVEN&i HOLDINGS invests about 3.5 billion US dollars in store quality by February 2018 and plans to invest about 7.8 billion US dollars in store quality by February 2019.Footnote 3 Therefore, it is worth to consider retailers’ investment in store quality and to examine the interaction between quality choice and the choice of business hours. Also, the store quality aspect of our paper might provide further justification for the liberalization of business hours. Our model is an extended version of the Hotelling model with two dimensions (location and time) such as Inderst and Irmen (2005). To examine retail strategies related to store quality and business hours, we introduce quality investments into Inderst and Irmen (2005)’s setups. We consider two different cost regimes: the cost of improving quality is a fixed cost and independent of the choice of business hours; quality investments are more costly for extended business hours. The first regime is suitable when retailers invest in product quality, such as private label products. The second regime captures additional investment costs for customer and security service during late hours. Considering these two cost regimes, we investigate how the interaction between quality choice and the choice of business hours changes depending on the cost regime. We also consider that there are two types of consumers. One type is flexible with respect to time and always purchases a retail product, the other type is non-flexible with respect to time and only purchases when a retailer is open at the preferred shopping time—therefore, extended business hours exhibit a market expansion effect.Footnote 4 We assume that the mass of the first type is greater than that of the second type. This captures the empirical fact that most consumers can always shop. The game runs as follows. In the first stage, retailers decide their business hours and store quality. In the second stage, retailers compete in prices. We find that in each cost regime liberalization yields an equilibrium with maximal differentiation in business hours. That is, one retailer opens for longer and another opens for shorter period of time in equilibrium. We also find that under liberalization a retailer with longer (shorter) business hours charges higher (lower) price in both cost regimes. The effect on quality choice changes across the two cost regimes. In the first regime, a retailer with longer business hours chooses a higher quality. This reverses in the second regime. This study also offers a comparison with regulated business hours and finds that such relaxation raises social welfare because of increased store quality and demand. This contributes to the issue of regulating business hours in the retail sector. However, in extensions of the basic model, where we consider that most consumers have shopping time constraints, or a retailer with longer business hours sells only to consumers with shopping time constrained, or retailers invest in both product and service quality, we find that the regulation of business hours might be welfare enhancing. This implies that the decision to regulate business hours in the retail industry depends on the mass of no time-constrained consumers and on the behavior of retailers. The remainder of this paper is organized as follows. Section 2 presents the model, which is solved in Section 3. Section 4 shows the impact of regulation on social welfare. Section 5 discusses extensions of the model, and Section 6 concludes the paper.",1
19.0,3.0,"Journal of Industry, Competition and Trade",15 May 2019,https://link.springer.com/article/10.1007/s10842-019-00302-7,Cross-country Knowledge Spillovers and Innovations in Less Developed Countries in the Context of the Schumpeterian Growth Model,September 2019,Sergey Kondyan,Karine Yenokyan,,Male,Female,Unknown,Mix,,
19.0,3.0,"Journal of Industry, Competition and Trade",17 April 2019,https://link.springer.com/article/10.1007/s10842-019-00303-6,One Bad Turn Deserves Another: How Terrorism Sustains the Addiction to Capital Flight in Africa,September 2019,Simplice A. Asongu,Rexon T. Nting,Evans S. Osabuohien,Unknown,Unknown,Unknown,Unknown,,
19.0,4.0,"Journal of Industry, Competition and Trade",05 April 2019,https://link.springer.com/article/10.1007/s10842-019-00301-8,Platform Competition and Endogenous Switching Costs,December 2019,Mark J. Tremblay,,,Male,Unknown,Unknown,Male,"Many platforms are updated over time with new generations. For example, the iPhone is now in its “Xth” generation while the video game industry began its ninth generation with the recent release of the Nintendo Switch. Other platform devices like personal computers and eReaders are also updated regularly. By offering a new generation, the content, software, app, and game developers create new content of higher quality while the platform providers make additional sales to their existing customer base. For consumers that own the previous generation, the new generation often provides more than new content and updated technologies. Platform sellers often develop a new generation so that user profiles, preferences, and previous content are carried over to the new generation; that is, platform generations are backward compatible. For example, content purchased on iTunes is stored for consumers to use on any Apple device over many generations of a device; the same is true for software on personal computers, ebooks for eReaders, content preference on Netflix, and radio stations on Pandora.Footnote 1 Similarly, video game consoles are often backward compatible and this technology has been attributed to the success of several video game platforms over the last two decades.Footnote 2 The consumer carryover generated from previous content acts much like a switching cost since customers face an opportunity cost, in the form of lost content and lost preference investment, from switching platforms. I find that the endogenous switching costs developed by intra-platform technologies result in first-period subsidized content provision, instead of first-period consumer price discounting. This contradicts the standard result found in models with exogenously given switching costs where the first-period price to consumers is reduced and is followed by a second-period markup: Klemperer (1987a, 1987b, 1987c) for traditional markets with Klemperer (1995) as an overview, Farrell and Klemperer (2007) for network markets, and Lam (2017) for two-sided markets. The reason for offering a bargain to first-period consumers through more content, instead of offering a lower price, is that more content providers generate greater consumer lock-in on both the extensive (more consumers) and the intensive (stronger carryover per consumer) margins; however, a subsidy to consumers only generates lock-in at the extensive margin. Thus, more first-period content both locks-in more consumers and generates a greater second-period consumer markup, while a discounted first-period price to consumers only locks-in more consumers. As a result, a platform prefers to offer content providers (instead of consumers) a reduced first-period price. To further highlight the impact of endogenous switching costs in two-sided markets, a numerical example using data from the fifth and sixth generations of the video game market is provided. I show that reasonable parameter values satisfy the equilibrium conditions. More specifically, the exercise suggests that the strength of the consumer carryover is strictly greater than zero for the video game market. In addition, when the strength of the consumer carryover ranges between a third and a half (so that games from the previous generation provide a half to a third of the utility of new games), then the expected value that a consumer has for a purchased video game ranges from $33 to $143 greater than the price of the game. While the measurement of such a valuation is difficult for a consumer (let alone a practitioner), this range appears reasonable. There is a large contemporary literature on platform competition: Rochet and Tirole (2003), Caillaud and Jullien (2003), Armstrong (2006), Hagiu (2006), Ambrus and Argenziano (2009), and Jullien (2011) and (White and Weyl 2016), all of which consider static competition. Little research has been done on competition across platform generations. The main contributions to this literature have been empirical. Iansiti and Zhu (2012) and Lee (2013) investigate entry in the video game console industry, and Kim et al. (2017) investigate entry in the daily deal promotions market. The theoretical literature of dynamic competition and compatibility in markets with network externalities has largely considered single-sided networks, and this prevents the consideration of endogenously developed switching costs through multi-sided pricing strategies. For example, Cabral (2011) considers dynamic single-sided network competition and does not consider switching costs; Chen et al. (2009) consider network pricing and compatibility decisions when networks compete in a single-sided market without switching costs; and Hałaburda et al. (2016) develop a model with network effects where the platform that “won” in the previous period is focal in the current period. That is, consumers observe which platform was available in the previous period and form favorable beliefs about that platform in the current period. This essentially acts as an exogenously given switching cost that makes it more difficult for the non-focal platform to convince consumers to join their platform even if it is of higher quality.Footnote 3 One paper that extends several of the classic switching cost models to two-sided markets is Lam (2017). She takes the horizontal platform differentiation approach (pioneered by Armstrong 2006) to model platform competition with an exogenously given switching cost on each side of the market. The switching cost is homogenous for all consumers and homogenous for all content providers. In terms of prices, Lam extends the switching cost pricing results to platforms where a bargain is offered in the first-period while a markup is extracted in the second period. While these platform prices contain network externality components consistent with Armstrong (2006), the effect of switching costs on these prices is generally consistent with the traditional switching cost literature. The approach considered in this paper differs from Lam (2017) in two important ways. First, the switching costs that consumers face depend on the amount of content consumed in the first period. This results in endogenously determined switching costs that depend on platform first-period pricing strategies. Another important difference is that this paper considers the case where entry by platform sellers is sequential. This is important for considering markets where sequential entry, or sequential intra-platform technology development, exists.Footnote 4 More importantly, the horizontally differentiated platform model considered by Lam does not allow for the single platform case in the first period. To incorporate these distinctions, a modeling structure of consumer heterogeneity for content is developed. This naturally mirrors the behavior of consumers in the markets that this paper aims to consider.Footnote 5 I find that the results on pricing, content procurement, and consumer switching differ considerably from Lam. This contrast suggests that the structure and origin of the switching costs is important in markets where network externalities exist. Lastly, this paper also makes a contribution to the existing literature on exogenously given switching costs (see Farrell and Shapiro 1988; Klemperer 1995; Padilla 1995, or Farrell and Klemperer (2007) for an overview) by highlighting how an incumbent’s ability to invest in switching costs will impact pricing and competition. More specifically, a common result with exogenous switching costs is that an incumbent uses switching costs to create a competitive advantage over a potential entrant (see Klemperer1987b).Footnote 6 However, I find that the incumbent uses the endogenously determined switching costs to soften platform competition. In other words, I find that endogenous switching costs generate the “fat-cat” effect, from Fudenberg and Tirole (1984), where the incumbent invests in greater switching costs in the first period (by offering a reduced price to content providers, which generates greater consumer carryover), to soften competition with entrant in the second period.Footnote 7",3
19.0,4.0,"Journal of Industry, Competition and Trade",25 February 2019,https://link.springer.com/article/10.1007/s10842-019-00294-4,Impact of Vertical Integration on Market Power in Indian Manufacturing Sector During the Post-Reform Period,December 2019,Rakesh Basant,Pulak Mishra,,Male,Unknown,Unknown,Male,"Competitive pressures unleashed by economic reforms in India seem to have resulted in an increase in importance of business strategies like outsourcing manufacturing jobs (Basant and Mishra 2016). Manufacturing outsourcing can potentially permit rationalization of production wherein firms can exploit economies of scale and scope in specific segments along with outsourcing activities in which they are not cost-competitive. In this sense, outsourcing has a very important strategic role in situations where firms compete with one another on production costs. The movement towards greater outsourcing of manufacturing at a reasonably high rate after initiation of reforms and associated decline in degrees of vertical integration for most industries (Basant and Mishra 2016) reflects that the strategy of vertical disintegration is emerging as an alternative to in-house production. Outsourcing markets seem to be maturing, but given that vertical integration can potentially reduce production and other transaction costs and/or uncertainties in output and input markets, understanding the impact of such policy shift on market power of firms and the emerging implications for competition policy is very important. Vertical integration can not only enhance efficiencies by reducing production and transaction costs, it can potentially also reduce uncertainties in output and input markets. Given this logic a decline in its degree would reduce firms’ competitiveness and market power.Footnote 1 Conversely, high degrees of vertical integration in an industry also create entry barriers as integration may be necessary for successful entry by a new firm which is likely to be costly. A decline in vertical integration, therefore, is likely to facilitate entry and enhance market competition. Similarly, market foreclosure following vertical integration seems to have important implications in competition policy analysis. This is particularly so when integration results in exit from upstream markets and increases costs of production of the downstream firms. It can also facilitate the dominant firms to exercise market power. Thus, there is a possibility of increase in market concentration and loss of consumer welfare following vertical integration. While competition in upstream markets may decline, firms in downstream markets may experience increase in costs of production and hence prices. However, the welfare loss due to higher prices may be offset by cost advantage of the dominant firms. Given all these possibilities, it would be useful to examine how such “vertical disintegration” has affacted market power of firms in different industries of Indian manufacturing sector and what are the implications of such strategic changes for competition policy. The present paper explores these issues. Using panel data consisting 49 majors manufacturing industries for the period 2003–04 to 2010–11 and applying the system GMM approach to estimate of dynamic panel data models, the paper finds that vertical integration has no impact on average firms’ market power in an industry. Instead, it is influenced by market size, and selling and technology-related efforts. While selling intensity causes positive impact on market power, the impact of market size and technology intensity is found to be negative. Notably, like vertical integration, market concentration, import–export ratio, and capital intensity have no influence on market power. The paper has six sections. The next section invokes the structure–conduct–performance (SCP) paradigm to develop conceptual relationships and identify the impact of different variables (including vertical integration) on market power. A functional model used for econometric investigation is then specified. The econometric techniques and data sources are discussed in the third section, whereas the fourth section presents and analyzes the econometric findings. The major findings and their policy implications are highlighted in the last section.",
19.0,4.0,"Journal of Industry, Competition and Trade",01 April 2019,https://link.springer.com/article/10.1007/s10842-019-00297-1,Mergers and Wages in Digital Networks: a Public Interest Perspective,December 2019,Sumit K. Majumdar,Rabih Moussawi,Ulku Yaylacicegi,Male,Male,Unknown,Male,"Mergers are important phenomena that raise public interest concerns because of associated human costs (Bruner 2005). When evaluating competition policy topics, such as mergers, the United States Department of Justice (DOJ) and similar bodies around the world focus on consumer issues. This is because of the impact on consumers’ welfare, since a combined entity can have a large market share and can dictate prices. Focusing on consumers, neglecting other stakeholders, such as firms’ employees’ concerns, is unfortunately common in assessing firms’ merger outcomes. In merger assessment, primary questions relate to if mergers promote or retard competition, via their impact on prices, competitive behavior, and entry (Andrade et al. 2001; Baker 1997; Kovacic 2001). Jobs and wages define key parameters by which the livelihoods of people are measured. Merger outcome questions also need to be asked with respect to variables such as jobs, wages, and technical progress (Katz and Shelanski 2007; Porter 2001). It is important that evidence on how mergers impact firms’ employees also be generated.Footnote 1 On the nature of the relationship of mergers and wages, there are no clear empirical conclusions. Over a dozen retrospective studies have generated mixed results. Negative mergers and wage outcomes have been established by Brown and Medoff (1988), Lichtenberg and Siegel (1990), and Gokhale et al. (1995) and partially by McGuckin and Nguyen (2001), while Davis and Wilson (2003) have found a small positive effect of mergers on wages. Beckman and Forbes (2004), Conyon et al. (2004), Huttenen (2007), Kubo and Saito (2012), Peoples (1989), and Siegel et al. (2008) have found a positive impact, while Majumdar et al. (2010) have evaluated merger waves and established a positive impact in respect of first mergers but a negative impact in second mergers on wages; Nguyen and Ollinger (2009) have found both negative and positive impact of mergers in different time periods. Absence of an empirical regularity on the issue of mergers and wages is puzzling. A possible resolution to this conundrum is to incorporate institutional context specifics in assessing phenomenon and anchoring analysis in relevant literatures.Footnote 2 Yet, we also know very little about how mergers occurring across specific institutional regimes affect labor market outcomes.Footnote 3 Firms’ decisions are influenced by regulatory changes (Nelson 2007) and institutional incentives (Parente and Prescott 2002). Merger-impact assessments can be made contingent on such regulatory and institutional specificities. Thus, occurrence of negative versus positive merger and wage outcomes could be explained as occurring due to institutional variations driven by varying public interests.Footnote 4 Such contingencies would affect post-merger wage outcomes across differing contexts.Footnote 5",4
19.0,4.0,"Journal of Industry, Competition and Trade",04 May 2019,https://link.springer.com/article/10.1007/s10842-019-00306-3,The Effect of Awareness and Observability on the Non-contractible Investment of a Regulated Natural Monopoly,December 2019,Ismail Saglam,,,Male,Unknown,Unknown,Male,"A pioneering work of Tirole (1986) showed that the non-contractible investment of a firm is lower when it is (ex-post) observable than when it is not. This finding was obtained in a two-period procurement model where a single project is produced and sold by a single firm to a single sponsor. In the first period of this model, the firm invests in reducing the costs of the project, while the sponsor is only aware of the investment possibility of the firm. At the beginning of the second period, the sponsor learns its private value for the project while the firm privately learns the costs it will face if it realizes the project. Then takes place a non-cooperative bargaining where the firm and the sponsor determine whether to trade and the price contingent on trade. According to Tirole (1986), the result of underinvestment arises due to “the information effect” of observability, since the firm would be able to influence not only its cost distribution but also the sponsor’s beliefs about it. As the sponsor’s price under observability decreases with the sponsor’s beliefs about the firm’s investment, more optimistic beliefs make the sponsor less agreeable in the bargaining process in the second period, leading the firm to reduce its investment below the level it would choose under unobservability. One may here ask whether or not Tirole’s (1986) result is sensitive to his modeling assumption that both the firm and the sponsor have some private information about the project and can thus make a non-cooperative bargaining for trade. To answer this question, we will study in this paper whether a regulator’s ex-ante awareness of and ex-post ability to observe can jointly affect the non-contractible investment activities of a regulated firm in a principal-agent model where “only” the agent, i.e., the investing firm, holds some private information about the regulated environment. While our research question is novel to the best of our knowledge, investment of a firm in a principal-agent framework has been extensively studied in the regulation literature, where the closest works to our study are Baron and Besanko (1984) and Laffont and Tirole (1993). Both of these works consider the case of unobservable and non-contractible investment as well as the case of observable and contractible investment. However, neither of them studies the case of observable and non-contractible investment, which as mentioned by Laffont and Tirole (1986, p. 88) may arise as a third possibility when, “The regulator might observe investment but not be able to provide evidence that is accurate enough for a court in charge of enforcing the regulatory contract.” Our paper will attempt to consider this unexplored case together with the earlier studied case of unobservable and non-contractible investment so as to identify the effect of observability on non-contractible investment in a principal-agent model with “one-sided” informational asymmetry. Here, we should note that our paper is also closely related to a literature that examines investment unobservability as a factor reducing the hold-up problem where two parties refrain from efficiently cooperating (see, for example, Gul2001; Sloof et al. 2007; Lau Lau:2008; and Hermalin and Katz 2009, among others). In this literature, it is usually the buyer that invests prior to the transaction stage and the asymmetric information is one-sided. Our paper shows that a general result of this literature, linking observability to lower investment, holds as well in a regulatory framework of Baron and Myerson (1982). For tractability of our results, we will consider a simpler model than the models considered by Baron and Besanko (1984) and Laffont and Tirole (1993). Basically, we will integrate investment with Baron and Myerson’s (B-M) (1982) well-known model that optimally regulates—through an incentive-compatible policy—a monopolist with unknown production costs.Footnote 1 In more detail, we will consider prior to the production stage in the B-M model an investment stage in which the monopolist has access to an investment (or research and development) technology determined by a fixed parameter γ ∈ (0, 1) and a choice variable ρ ∈ [0, 1). This technology will reduce the monopolist’s private marginal cost, say 𝜃, to γ𝜃 with probability ρ. The parameter γ will be called the improvement due to (successful) investment. On the other hand, the variable ρ will be determined by the level of investment, and will be called the probability of success or the level of investment interchangeably. We will close the model by defining a cost function for investment. For the model we have described above, we will assume that the regulator can not contract on investment, implying that the value of the parameter ρ will be freely determined by the monopolist. However, as in the B-M model without investment, the regulator will be able to contract on the price and output of the product. Regarding the regulator’s knowledge about investment, we will consider two possibilities: The first one is that the regulator is ex-ante aware of the investment technology accessed by the monopolist and also ex-post able to observe the realized investment (say through mandated reporting and auditing). That is, the regulator learns about the investment technology (γ, ρ) and the actual value of the parameter γ before investment takes place, and observes the actual value of the parameter ρ after investment takes place.Footnote 2 The second possibility is that the regulator is never aware of the investment technology (γ, ρ) or the possibility of investment and never able to observe γ or ρ. Thus, the regulator acts like she is in the standard B-M model without investment. Dealing with both possibilities in our paper, we show that the optimal level of investment is, in general, lower when the regulator is ex-ante aware of and ex-post able to observe investment than when the regulator is never aware of and never able to observe investment. This result, being in line with an earlier finding of Tirole (1986), points to the regulated firm’s prevention of ratcheting, whereby a monopolistic firm—that demonstrates through its investment that it has lower costs—is required to produce at lower costs. Also, irrespective of the regulator’s awareness and observability, we find that the optimal level of investment is always higher when the monopolist is productively less efficient, provided that investment always increases productive efficiency. This is because of the fact that the marginal effect of investment on the profits (informational rents) of the monopolist becomes higher when the monopolist has a lower marginal cost. We also find that the producer welfare and the social surplus is always ex-ante higher when the regulator is unaware of its investment activities than when she is aware. Moreover, our computations show that depending on the specifications of our model the unawareness of the regulator may positively affect the expected consumer and social welfares, as well. The rest of our paper is organized as follows. Section 2 presents our model and Section 3 presents our results. Finally, Section 4 contains some concluding remarks.",2
19.0,4.0,"Journal of Industry, Competition and Trade",29 June 2019,https://link.springer.com/article/10.1007/s10842-019-00311-6,On the Rationality of Bundled Rebate Program in Modem Chip Industry: an Analysis on Qualcomm’s Case,December 2019,Youqiong Ai,Thomas Y. Lu,,Unknown,Male,Unknown,Male,"Bundled rebate and loyalty discount are two traditional incentives to sustain the customer relationship between a supplier and a manufacturer. In the presence of bundled rebate, the manufacturer buying products and/or other services altogether can receive a fixed amount of rebate from the supplier in return. As a result, this rebate can constantly and exclusively tempt the manufacturer into buying products or other services together from that specific supplier. Loyalty discount, similar to bundled rebate, is another incentive for exclusive procurement. In practice, bundled rebate and loyalty discount sometimes are combined into a total fixed number in a contract for easy enforcement. However, a monopolist who continuously provides such traditional incentives to manufacturers may violate antitrust law by exploiting its monopolistic position and excluding competitors or potential entrants. For instance, in early 2017, Qualcomm, one of the leading modem chip suppliers, was accused by FTC and Apple Inc., one smartphone manufacturer and one of Qualcomm’s modem chip buyers, that its bundled rebate and loyalty discount program should violate Sherman Act Section Two.Footnote 1 Specifically, the way Qualcomm delivered the program was unique—it bundled the selling of physical modem chips with the licensing of involved standard essential patents (SEPs). That is, if Apple desired to buy Qualcomm’s chips, it had to acquire SEP licenses at a certain royalty rate with the chips altogether.Footnote 2 Qualcomm would refund Apple a lump sum of money in return for Apple’s commitment. Therefore, Apple asserted that it was induced to purchase modem chips from Qualcomm continuously and exclusively.Footnote 3 This article focuses on analyzing reasons underlying Qualcomm’s behavior in the real world. Why does Qualcomm insist on delivering the bundled rebate and loyalty discount program for Apple Inc., if they are likely to be illegal under antitrust law? To answer this question, this article is organized as follows. Section 2 reviews related literature in legal and business areas. Section 3 describes the legal disputes and the modem chip industry status quo that FTC and Apple Inc. have talked about in their complaints. Section 4 addresses the case law of antitrust regime, which lays the foundation of our model analysis in Section 5. We attempt to derive business incentives for Qualcomm to insist on implementing the bundled rebate and loyalty discount program regardless of legal risks. In detail, this article analyzes three different scenarios: the single-stage exhaustive contract setting, the single-stage non-exhaustive contract setting, and the two-stage exhaustive contract setting. We examine how patent licensing and quality improvement might affect Qualcomm’s bundling rebate decisions. Section 6 summarizes some implications as to why Qualcomm insists on implementing its bundled rebate and loyalty discount program. We justify that the key business reason is that Qualcomm would like to prevent itself from future fierce competition with potential competitors who improve their product quality significantly. Finally, Section 7 concludes this article.",2
19.0,4.0,"Journal of Industry, Competition and Trade",04 July 2019,https://link.springer.com/article/10.1007/s10842-019-00307-2,"Efficiency, Productivity, and Congestion Performance: Analysis of the Automotive Cluster in Mexico",December 2019,Alfonso Mendoza-Velázquez,Francisco Benita,,Male,Male,Unknown,Male,"The automotive industry in Mexico has experienced an increasingly relevant role in the manufacturing sector, not only for its proximity with the USA but also because its low costs and high productivity levels (Contreras et al. 2012). This industry became an export platform after the North America Free Trade Agreement (NAFTA) in 1994 and continues to be an important cluster in the new renewed United States-Mexico-Canada Agreement (USMCA) by the end of 2018. Eight out of the top ten auto companies own plants in Mexico (Chrysler, Ford, General Motors, Honda, Mazda, Nissan, Toyota, and Volkswagen) and, according to the data of the Ministry of Economy (SE, as per the Spanish acronym) (SE 2016), this sector has consolidated itself as one of the most important in the Mexican economy. It contributes as much as 3% of the total gross domestic product (GDP) and 18% of the manufacturing GDP. Moreover, in 2016, the sector accounted for 30% (18.5% in 2006) of the total foreign direct investment in manufacturing and 18% (7.8% in 2006) of total foreign direct investment. However, the automotive cluster in Mexico is one of the most vulnerable to external shocks as it was demonstrated during the global financial crisis 2007–2008. The study by Sanchez-Ramirez et al. (2011) documents how the strong agglomeration of plants in the northern and center regions resulted in industrial weakness. In part because of the export-oriented profile of Mexican production sites, which derived in a gap in the local supply chains and in labor, once the demand of the original equipment manufacturers decreased due to the global economic crisis. Some automotive industries in Mexico, nonetheless, have shown a fast recovery from the crisis, and nowadays, the Mexican automotive industry is one of the world’s most competitive (SE 2016). The automotive cluster is also high-tech and innovation-driven, as well as one of the most productive clusters in Mexico. Previous work has focused on studying the new mechanisms developed by local firms to participate in the supplier network (Contreras et al. 2012); the changes in demand for automobiles (Medina-Alvarez 2015) or the spatial shifts in the distribution of various sectors of the automotive industry (Wójtowicz 2019). Yet, changes in productivity and efficiency of the automotive cluster in Mexico have been less investigated. Gaining understanding of how productivity and efficiency have been affected in recent years, including the experience of the global financial crisis, is of great interest to policy-makers because the competitiveness of the automotive firms may be achieved by effective decision-making and high levels of productivity. This is of special relevance in the wake of a new trade agreement with the USA and possibly with Canada through the recent USMCA renegotiations. An evaluation of the scale of the automotive cluster in Mexico is also needed as well as an exploration of potential deviations from efficiency, such as congestion. Congestion is a form of inefficiency where the excess inputs may lead to reductions of output. It is a condition in which negative marginal returns are possible. Färe and Svenson (1980) and Färe and Grosskopf (1983) first defined and proposed methods to identify and measure input congestion. This deviation from efficiency may result when production processes in a given industry are not flexible enough to adjust to external shocks or new economic conditions and inputs cannot be easily disposed. The new agitated world trade environment increases the uncertainty and could pressure firms to make adjustments to productions processes such as modifying the shares of inputs. Nevertheless, these adjustments are not often readily made. Some inputs, such as labor, are not easily disposed due to the highly qualified nature of labor or the strength of unions in the automotive cluster. The technical and productive efficiency of industries and the possibility of congestion have strong implications in terms of profit maximization (Lovold 2013), financial viability (Tone and Sahoo 2004), and economic growth (Delgado et al. 2016). By employing the cluster definitions set out by Delgado et al. (2016), we first examine productivity efficiency via data envelopment analysis (DEA) and then analyze productivity patterns via Malmquist index. Of particular interest is the identification of efficiency scores and the resilience of the automotive cluster to the crisis. Second, implementing the approach by Cooper et al. (2001), we identify whether a given region or automotive subcluster presents congestion, its input source (labor, capital, or consumption) and its extent. The rest of this paper is organized as follows. After the introduction, Section 2 introduces related studies of efficiency and congestion in the automotive industry, highlighting the case of Mexico. Section 3 describes the proposed methodology. The empirical results appear in Section 4 followed by a conclusion of the study in Section 5.",3
19.0,4.0,"Journal of Industry, Competition and Trade",02 January 2019,https://link.springer.com/article/10.1007/s10842-018-0291-6,Endogenous Choice of the Timing of Setting Incentive Parameters and the Strategic Contracts in a Managerial Mixed Duopoly with a Welfare-Based Delegation Contract and a Sales Delegation Contract,December 2019,Yasuhiko Nakamura,,,Male,Unknown,Unknown,Male,"This study revisits the endogenous timing game, which is called the observable delay game in the fashion of Hamilton and Slutsky (1990), in a managerial mixed duopoly composed of one public firm with a welfare-maximizing owner and one private firm with a profit-maximizing owner with a welfare-based delegation à la Nakamura (2015) and a sales delegation à la Fershtman and Judd (1987), Sklivas (1987), and Vickers (1985) (an FJSV delegation herein). In this study, we focus on the situation in which the owner of the public firm provides a managerial contract equal to the weighted sum of welfare and the difference between the consumer surplus and producer surplus with respect to the welfare-based incentive parameter to his manager, while the owner of the private firm provides a managerial contract equal to the weighted sum of his profit and his sales revenue with respect to the FJSV incentive parameter to his manager. More precisely, in the observable game in which both the timing of setting the welfare-based incentive parameter of the public firm and the FJSV incentive parameter of the private firm and the contents of their strategic contracts are endogenously determined by their owners, we seek the equilibrium market structures and derive policy implications by clarifying the relationship between the equilibrium market structures and socially preferable market structures from the viewpoint of social welfare. The main purpose of this study is to disclose the relationship between the equilibrium market structures and socially preferable market structures from the viewpoint of social welfare along with the change in the managerial delegation contract adopted within the public firm from the FJSV delegation to the welfare-based delegation à la Nakamura (2015) in a managerial mixed duopoly. The literature on the organizational structures within enterprises has explored the situation in which their owners provide their managers with managerial delegation contracts. The most famous works are Fershtman and Judd (1987), Sklivas (1987), and Vickers (1985). These three papers introduced managerial contracts equal to the weighted sum of each firm’s profit and its sales revenue with respect to the so-called FJSV incentive parameter. Existing research in this field has applied the FJSV managerial delegation to several economic situations following Fershtman and Judd (1987), Sklivas (1987), and Vickers (1985).Footnote 1 In a managerial mixed oligopoly composed of public firms with welfare-maximizing owners and private firms with profit-maximizing owners, Barros (1995) and White (2001) first investigated the effect of FJSV delegation contracts on market outcomes. Moreover, Nishimori and Ogawa (2005) considered the relation between the length of incentive contracts and market behavior in a managerial mixed duopoly, using the FJSV delegation approach in the fashion of Bárcena-Ruiz and Paz Espinoza (1999). In the context of a mixed oligopoly, to confirm the reasonability of the assumption of the order of the moves of both the public firm and the private firm, Pal (1998) analyzed the observable game à la Hamilton and Slutsky (1990) in a quantity-setting market with homogeneous goods composed of a welfare-maximizing public firm and multiple profit-maximizing private firms, and Bárcena-Ruiz (2007) discussed a similar endogenous timing game to that in Pal (1998) in a price-setting mixed duopoly with differentiated goods.Footnote 2 Furthermore, Bárcena-Ruiz and Garzón (2010), Matsumura and Ogawa (2010), and Méndez-Naya (2015) investigated an endogenous timing game à la Hamilton and Slutsky (1990) in a mixed oligopoly with a partly privatized semi-public firm, which was introduced in Matsumura (1998).Footnote 3 In a managerial mixed duopoly, by taking into account the endogenous determination of the strategic variable adopted within both the public firm and the private firm and their internal organizational structures (i.e., the FJSV delegation) simultaneously, in the differentiated goods mixed duopoly, Nakamura and Inoue (2007) analyzed whether the owners of both the public firm and the private firm prefer when to decide their quantities, while Nakamura and Inoue (2009) considered the same analysis as that in Nakamura and Inoue (2007) in the context of price competition with differentiated goods. Bárcena-Ruiz (2013) explored the determination under which the owners of both the public firm and the private firm prefer when to provide their FJSV delegation to their respective managers in the context of price competition with differentiated goods, using the observable delay game à la Hamilton and Slutsky (1990). Taking into account the separation between ownership and management in the FJSV delegation approach and the endogenous timing game on the strategic variables of firms simultaneously, Sun (2013) introduced a theoretical model not only of the endogenous role distribution (leader, follower, and simultaneous move) but also of the endogenous choice for the types of strategic contracts (price and quantity) in the context of an entrepreneurial private duopoly composed of private firms without the separation between ownership and management. Din and Sun (2016) extended the model in Sun (2013) that unifies the endogenous choice of the timing of the levels of the strategic contracts with the competition version from a private duopoly model composed of entrepreneurial private firms to a mixed duopoly model with differentiated goods, which is composed of an entrepreneurial public firm and an entrepreneurial private firm. Subsequently, Nakamura (2018b) further extended the model in Din and Sun (2016) by considering the situation in which FJSV managerial contracts are employed within both the public firm and the private firm. More precisely, in a managerial private duopoly with an FJSV delegation, Nakamura (2018b) proposed a model in which the owners of the two managerial private firms simultaneously announce the timing of setting their FJSV incentive parameters and the contents of their strategic contracts (their prices or quantities) in the observable delay game à la Hamilton and Slutsky (1990).Footnote 4 Furthermore, in the context of a managerial mixed duopoly composed of a public firm and a private firm with an FJSV delegation, Nakamura (2018c) and 2019 investigated the model with the observable delay game à la Hamilton and Slutsky (1990) in which the timing of setting the FJSV incentive parameters/contents of their strategic contracts and the timing of the levels of their strategic contracts/contents of their strategic contracts, respectively, are endogenously determined by their owners. Nakamura (2018c) showed that the market structure in which the manager of the public firm with a quantity contract is the follower and the manager of the private firm with a price contract is the leader can become the unique equilibrium market structure in the unified game between the timing of setting the levels of strategic contracts and their contents and that such a unique equilibrium market structure can become the socially preferable market structure from the viewpoint of social welfare in a managerial mixed duopoly with an FJSV delegation. On the contrary, Nakamura (2019) showed that two equilibrium market structures are possible in this game: (1) the market structure in which the owner of the public firm is the follower with a quantity contract and the owner of the private firm is the leader with a price contract and (2) the market structure in which the owners of both firms use their price contracts and simultaneously set their incentive parameters in the late period and the highest social welfare can be achieved with the first of these equilibrium market structures. Thus, in a managerial mixed duopoly, the difference in the timings of setting the FJSV incentive parameters of both the public firm and the private firm and the levels of their strategic contracts yields different equilibrium market structures and different policy implications with respect to social welfare. In this study, we pay attention to how the change in managerial delegation contracts employed within the public firm from its FJSV delegation contract to its welfare-based delegation influences the equilibrium market structures and policy implications with respect to social welfare in the game in which the timing of setting the welfare-based incentive parameter and FJSV incentive parameter of the private firm and the contents of their strategic contracts are endogenously determined by their owners. Before considering the game in which the endogenous determination of the timing of setting the welfare-based incentive parameter of the public firm and the FJSV incentive parameter of the private firm is unified with the endogenous determination of the contents of their strategic contracts in a managerial mixed duopoly with a welfare-based delegation and an FJSV delegation, this study investigates the game in which one of the above two factors is fixed. First, we explore the equilibrium market structures in the game in which the timing of setting the welfare-based incentive parameter of the public firm and the FJSV incentive parameter of the private firm is endogenously determined by their owners when the contents of their strategic contracts are fixed: (1) the q-q game in which the owners of both the public firm and the private firm have quantity contracts; (2) the p-p game in which the owners of both the public and the private firms have their price contracts; (3) the p-q game in which the owner of the public firm has his price contract, while the owner of the private firm has his quantity contract; and (4) the q-p game in which the owner of the public firm has his quantity contract, while the owner of the private firm has his price contract. In such a game, we show that in the three types of games, namely the q-q game, p-p game, and p-q game, the equilibrium market structure(s) can become the socially preferable market structure(s) from the viewpoint of social welfare for any degree of product homogeneity. In these three types of market structures, it is not as necessary for the relevant authority including the government to regulate the free determination of the timing of setting the welfare-based incentive parameter of the public firm and the FJSV incentive parameter of the private firm on the basis of their individual incentives. However, in the q-p game, we find that it is necessary for the relevant authority to regulate the free determination of the incentive parameters on the basis of the individual incentives of the owners of both the public firm and the private firm, since social welfare does not become the highest in the following two equilibrium market structures: (1) the market structure in which the owner of the public firm is the leader, while the owner of the private firm is the follower in the determination of the incentive parameters; (2) the market structure in which the simultaneous determination of the incentive parameters occurs in the late period. Second, we consider the equilibrium market structures in the game in which only the contents of the strategic contracts of both the public firm and the private firm are endogenously determined by their owners when the timing of setting the welfare-based incentive parameter and FJSV incentive parameter of the private firm is fixed: (1) the SSw case in which the owners of both the public firm and the private firm simultaneously determine the welfare-based incentive parameter and FJSV incentive parameter, respectively; (2) the LFw case in which the owner of the public firm is the leader, while the owner of the private firm is the follower in the determination of the incentive parameters; and (3) the FLw case in which the owner of the public firm is the follower, while the owner of the private firm is the leader in the determination of the incentive parameters. In the SSw case, as shown in Nakamura (2015), no equilibrium market structure exists under the pure strategic contract, and there exists a unique mixed strategy equilibrium market structure with the property such that the probability of choosing the quantity contract by the owner of the private firm is higher than that by the owner of the public firm. In the LFw case, each firm’s owner is indifferent between taking his quantity and price contracts when the strategic contract of each rival firm is fixed; hence, all four games become equilibrium market structures. Finally, in the FLw case, given that it is a dominant strategy for the owner of the public firm to take his quantity contract, two types of market structures, namely the q-p game and q-q game, can become not only equilibrium market structures but also socially preferable market structures. However, we pay attention to the fact that such a reasonable result holds at the expense of the relatively low payoff of the owner of the private firm. Lastly, in the observable delay game in which both the timing of setting the welfare-based incentive parameter of the public firm and the FJSV incentive parameter of the private firm and the contents of their strategic contracts are endogenously determined by their owners in a managerial mixed duopoly with a welfare-based delegation and an FJSV delegation, we find that two types of market structures, namely the q-q game in the LFw case and the q-p game in the FLw case, can become equilibrium market structures. In addition, the q-q game in the LFw case—as one of the equilibrium market structures—can become the socially preferable market structure. In this sense, in the environment in which both the welfare-based incentive parameter of the public firm and the FJSV incentive parameter of the private firm and the contents of their strategic contracts are endogenously determined by their owners in a managerial mixed duopoly with a welfare-based delegation and an FJSV delegation, it is not as necessary for the relevant authority including the government to regulate the free determination of both the timing of setting the welfare-based incentive parameter of the public firm and the FJSV incentive parameter of the private firm and the contents of their strategic contracts. On the contrary, if the q-p game in the FLw case as another equilibrium occurs, we focus on the fact that the payoff of the owner of the public firm, which is equal to social welfare, and the payoff of the owner of the private firm, which is equal to its profit, stay low in such a market structure.Footnote 5 The remainder of this paper is organized as follows. In Section 2, we formulate a differentiated goods mixed duopolistic model in which not only the timing of setting the welfare-based incentive parameter and FJSV incentive parameter of the private firm but also the contents of their strategic contracts are endogenously determined by their owners in a managerial mixed duopoly with a welfare-based delegation and an FJSV delegation. In Section 3, we consider the game in which only the timing of setting the welfare-based incentive parameter and FJSV incentive parameter of the private firm is endogenously determined by their owners, which is classified into four games on the basis of the contents of their strategic contracts, namely the q-q game, p-p game, p-q game, and q-p game. Subsequently, in these four games, we derive the equilibrium market outcomes under the pure strategic contract class and compare the socially preferable market structures from the viewpoint of social welfare with them.Footnote 6 In Section 4, in a managerial mixed duopoly with a welfare-based delegation and an FJSV delegation, we conduct similar analyses to those in Section 3 in the game in which only the contents of the strategic contracts of both the public firm and the private firm are endogenously determined by their owners provided that the timing of setting the welfare-based incentive parameter of the public firm and the FJSV incentive parameter of the private firm is fixed. Then, in such a game, we derive the equilibrium market structures and compare the socially preferable market structures from the viewpoint of social welfare with them. In Section 5, in a managerial mixed duopoly with a welfare-based delegation and an FJSV delegation, we explore the observable delay game in which both the timing of setting the welfare-based incentive parameter of the public firm and the FJSV incentive parameter of the private firm and the contents of their strategic contracts are endogenously determined by their owners. In Section 6, we extend the analyses of the situation in which the technologies of both the public firm and the private firm are represented as cost functions with their constant marginal costs with respect to their quantities, which was presented until the previous section, into those when their technologies are represented as quadratic cost functions with respect to their quantities. Section 7 concludes with several remarks. In the Appendix, we present the market outcomes except for the welfare-based incentive parameter of the public firm and the FJSV incentive parameter in the four games.",2
20.0,1.0,"Journal of Industry, Competition and Trade",22 July 2019,https://link.springer.com/article/10.1007/s10842-019-00312-5,Times are a Changin’? The Emergence of New Firms and Rank Reshuffling,March 2020,Stefan Schneck,,,Male,Unknown,Unknown,Male,"Entrepreneurship and the emergence of new firms are considered to be responsible for growth, productivity-enhancing processes, and the rejuvenation of economies. Indeed, young, innovative, and ambitious firms impose relentless competitive pressure, causing some firms to prosper, while others contract or cease to exist. This perfectly illustrates the steady process of creative destruction (Schumpeter 1934, also see the introductory quote) in which new firms, markets, products, or organizational structures challenge the established ones. It is common sense that entry, exit, growth, and decline of firms are inevitable in healthy markets. Empirical evidence about the link between entry, firm survival, and exit of firms is well established (e.g., Dunne et al. 1988; Boeri and Cramer 1992; Geroski 1995; Agarwal and Gort 1996). In fact, the relationship between entry and exit is well described in Geroski (1995, p. 435), who concluded that “[t]he most palpable consequence of entry is exit, and industries that exhibit high entry rates often also exhibit a high degree of churn at the bottom of the size distribution.” With respect to young firm survival, almost half of all firms of a particular start-up cohort do not survive the first five years. The literature on firm growth has a long tradition of analyzing the relation between growth and firm size (Gibrat 1931; Birch 1979; Sutton 1997; Caves 1998; Coad 2009). Although small and young firms are similar to a certain degree, they are conceptually very different. Hence, more recent studies about firm growth started to differentiate between firm age and firm size effects. With the Census Bureau’s Business Dynamics Statistics and Longitudinal Business Database, Haltiwanger et al. (2013) found no systematic relationship between firm size and growth when firm age is controlled for. In fact, young firms, rather than small firms, are found to be a major source of job creation in the USA. The importance of young firms in the job creation process was corroborated with Irish survey data, the Annual Employment Survey (Lawless 2014). Studies on the growth of young firms suggest the prevalence of an up-or-out pattern among young firms (Haltiwanger et al. 2013; Pugsley et al. 2017), which describes that young low-growth firms are more likely to exit the market, while survivors tend to grow quickly. The young high-growth firms also received special interest in Decker et al. (2016), who examined the skewness of the distribution of employment growth rates. The authors observed a decline in high-growth firms over time, which was explained by decreasing shares of young firms and a falling propensity of young firms to be a high-growth firm. So far, firm growth was frequently addressed by studying the percentage change of firm size or firm-specific growth rates over time, respectively. A higher growth rate, however, need not necessarily imply that a firm grows faster in absolute values. Specifically, when two competitors of different sizes increase sales by 1,000 Euro, then the smaller firm grows at a higher rate than the larger one. In this case, the higher growth rate of the smaller firm does not imply that the smaller firm became larger in absolute values than its competitor. The smaller firm hence did not manage to ascend within the firm size distribution (FSD). We therefore augment the analysis of firm growth by application of an alternative measure and address firm growth by studying mobility along the FSD. We hence widen the firm growth literature by analyzing whether higher growth rates also translate into larger absolute firm size. With administrative census data from Germany, covering the entire set of firms, which are obliged to submit a tax preregistration form, we determine the position of a firm within the industry-specific FSD by its corresponding percentile. We then address the process of firm growth through the examination of changes in the relative standing or changes in the position of the FSD, respectively. Mobility along the FSD is measured by changes in percentile rank positions within a four-year time horizon. Our results corroborate prior results that rank persistence is highest among the largest firms (see Geroski and Toker 1996; Baldwin 1998; Sutton2007; Kato and Honjo 2009, for studies on market leadership). A special focus is on the emergence of young firms and their growth patterns. In this regard, we show that young firms are more likely to ascend when compared with incumbents. The higher growth rates of young firms (cf. Haltiwanger et al. 2013; Lawless 2014) thus also imply that smaller firms grow larger than the incumbents. Over time, we observe a negative trend in rank mobility, which is also observable among young firms. This corroborates the recent concerns about a disappearance of high-growth firms (Decker et al. 2016). We furthermore estimate recentered influence function regressions (Firpo et al. 2009) to deduce the effect of young firms on rank variation after controlling for investments as well as for sector- and time-specific factors. The results reveal that new firms cause a significant degree of mobility along the FSD. Our empirical analysis thus clearly shows that young firms are a major source of competitive dynamics. Young firms enter and grow, while mature firms decline.",1
20.0,1.0,"Journal of Industry, Competition and Trade",24 April 2019,https://link.springer.com/article/10.1007/s10842-019-00304-5,The Russian Telecommunications Experience: a Positive Outcome of the Competitive Order in the Industry,March 2020,Dmitrii Trubnikov,,,Male,Unknown,Unknown,Male,"The telecommunications industry has been considered as an example of a natural monopoly over the major part of the twentieth century. Even when the pro-market ideas penetrated industrial policy during the last decades of the century, the understanding that not all layers of the industry are able to have a competitive form governed the “liberalization” process and was expressed in a new regulatory environment, a new role of the state in the industry’s development, and different methods of promotion of rivalry through regulatory tools. At the same time, the biggest telecommunications market of Europe, the Russian Federation, since the collapse of the Soviet Union, has demonstrated comparatively low level of concentration in many of its parts without any attempts to promote competition at all. The industry in Russia has been a place for the introduction of a number of innovative solutions by local and regional market actors despite weak state institutions, a high level of corruption, and an industrial policy that has been hostile for independent innovative activity. Russian telecommunications have showed one of the best figures of development of fiber-optic networks in the world in spite of the absence of essential government support of its construction. Joseph Stiglitz (1999) even notices that Russian telecommunications pose “quandaries for traditional economic theories.” However, it is not entirely clear whether some features of the Russian market distinguish it from the other examples that have been explained by the economic mainstream, or the mainstream theories have been based on fragile assumptions, that, in turn, had been the result of the previous ways of the industry development under the close supervision of the states all across the world. At the same time, if we look at the phenomenon from positions of the Austrian school, we will see that the case supports the theoretical propositions about competitive order and dynamism of the market process. The Russian experience, where the industry to a large extent was left to itself for several years in the beginning of the reform, demonstrates how market forces were able to govern the development of the field without close supervision of the state, and that makes the case particularly interesting for analysis. The article begins with a review of the contrast between the “competitive order” paradigm and the actual “ordered competition” regime adopted by industrial policy around the world. This part also highlights the cross-countries differences with a particular attention to the fact that some territories that are among the world leaders of the telecommunications network development have not relied in this development on state aid and regulation, and introduces the Russian telecommunications industry as a remarkable example of this kind. Section 3 is dedicated to the initial stages of the market reforms in the industry in Russia and explanation of the peculiarities of privatization of telecommunications in the country that allow to claim that the process in Russia was much closer to the Austrian view at “spontaneous privatization” than the European “state-led privatization” approach. The fourth section analyses the evolution of the order of the telecommunications industry in Russia. This section is constructed around the timeline of the industry development linked to the milestones of the transformation of the former Soviet monopoly and provides the main argumentation of the research. The empirical examples of this part explain how and why the decentralized industrial structure and independent entrepreneurship are able to satisfy actual social needs, while interventions in the market process tilt the industry towards concentration with negative consequences for its development.",8
20.0,1.0,"Journal of Industry, Competition and Trade",30 April 2019,https://link.springer.com/article/10.1007/s10842-019-00300-9,Organic Mergers and Acquisitions,March 2020,Ana Espínola-Arredondo,Felix Munoz-Garcia,Ae Rin Jung,Female,Male,,Mix,,
20.0,1.0,"Journal of Industry, Competition and Trade",28 June 2019,https://link.springer.com/article/10.1007/s10842-019-00310-7,The Importance of Industry to Strategic Entrepreneurship: Evidence from the Kauffman Firm Survey,March 2020,Christopher J. Boudreaux,,,Male,Unknown,Unknown,Male,"One of the most well-known examples of the importance of industry to firm strategy is captured in the five forces model, which describes how firms can exhibit superior performance due to their choice of industry (Ketels 2006; Porter 1979). Porter (1979) bases the strength of the industry according to five characteristics: threat of new entrants, bargaining power of suppliers, bargaining power of customers, threat of substitute products or services, and rivalry among existing competitors. Yet, despite this well-known model, scholarly studies often ignore the importance of the industry and instead opt to control for industry differences rather than highlight their importance.Footnote 1 In this stream, industries are often classified according to a few similar characteristics and dimensions but doing so forces the ensuing analysis to be selective to a few industries (Peneder 2003). Although this approach is logical when industries are of secondary importance, we argue that the literature has overlooked their importance in strategic entrepreneurship.Footnote 2 By ignoring the importance of the industry in analyses, important industry-level questions will continue to be ignored. The purpose of this study is to examine empirically how different industry sectors affect entrepreneurs’ performance according to several metrics—profit, sales revenues, firm survival rates, and competitive advantages. This is important because certain policies designed to stimulate entrepreneurship in some industries have been shown to be less effective in other industries (Gohmann et al. 2008). By examining differences in entrepreneurial outcomes across industry sectors, we intend to acquire a deeper understanding of the ways industry structure affects strategic entrepreneurship. Uncovering differences among industries generates novel and interesting questions related to entrepreneurship via agency theory, institutional theory, sociology, or political economy, among others. Our study utilizes a rich source of data, the Kauffman Firm Survey (KFS), which follows thousands of nascent and small businesses in the USA from 2004 to 2011. It includes a detailed source of information on geographical location, profitability, sales revenues, exit rates, sources of competitive advantage, credit risk, and firm and owner characteristics, among others. Most importantly, the KFS contains detailed industry information, which allows us to examine how the choice of industry affects entrepreneurial performance using three key indicators: firm survival, profitability, sales revenues, and sources of competitive advantage. We uncover several important findings in our study. We find that the agricultural and forestry industry is relatively stable with a low rate of firm exit. Firms in the utility industry and public administration industry also face low rates of exit. This is unsurprising since utilities are heavily regulated by the government and do not face the same competitive forces that other industries may encounter. We also find that firms in service industries—particularly the Professional, Scientific, and Technical service industry—are, on average, more profitable, have higher sales, survive longer, and the owners are more likely to perceive that they have a competitive advantage. In contrast, we find that the manufacturing and retail trade industries have lower profits and firms in retail industries face lower rates of survival. Our findings, thus, illustrate the importance of industry to strategic entrepreneurship. Porter’s (1979) five forces model indicates that some firms are more profitable than others merely because they are positioned in superior industries. That is, some firms will be more profitable than others due to the different factors associated with that industry. These factors include the threat of new entrants, the bargaining power of suppliers, the bargaining power of customers, the threat of substitute products or services, and rivalry among existing competitors. In all factors, competitiveness is key (Aiginger 2006) since a firm can become more profitable and experience better prospects for survival if it reduces its competition and increases its bargaining strength. Thus, we use this framework as a rationale to facilitate our understanding of industry-based differences. To our knowledge, no study has conducted a comparative analysis of business industries, though some research has been conducted on entrepreneurship by comparing particular industries. We highlight these studies below. Because some studies have examined how entrepreneurship varies by industry sector, it is important to mention these studies to situate our research in the literature. Scholars have found that there is more product innovation in manufacturing, knowledge-intensive services, and financial services industries compared to the construction, wholesale and transport, retail services, and hotel and catering services (De Jong and Vermeulen 2006). Another study used the 1984 Survey of Income and Program Participation to examine self-employment decisions across industry sectors and discovered major financial barriers to self-employment in manufacturing and wholesaling (Bates 1995). In another study, researchers examined how entrepreneurship and economic freedom varies within the service industry and found that economic freedom leads to growth in the number of firms and the level of employment in business and personal services but reduces growth and employment in health, social, and legal service industries (Gohmann et al. 2008). Sandberg and Hofer (1988) expand on the traditional venture capitalist model, based on the personality traits and strategies of the entrepreneur, by including a consideration of the industry. They find that industries matter to a much greater extent than the personality of the entrepreneur. Chatman and Jehn (1994) find that industry membership accounts for a larger variance than the individual firm in organizational culture and conclude that “future research should take industry contexts into account to fully explain the evolution and maintenance of organizational cultures.” Based on these studies, we conclude that industry analysis is very important, and a more comprehensive examination of the ways industries affect entrepreneurship is needed. Industry structure, competition, institutions, and culture are all very important because of their interactive effect on entrepreneurship. Institutions and culture are important because they help define the rules (North 1991; Williamson 2000) of the industry. Some industries (e.g., agriculture and utilities) may be more politically connected, which, in turn, affects entrepreneurial outcomes. McDougall et al. (1992) found that industry specific factors are very important when assessing the success of new ventures. Specifically, they found that some new venture strategies were not only very effective in some industry settings but also ineffective in other settings. Dean and Meyer (1996) find that dynamic industries—those that experience high rates of growth—experience higher rates of new venture formation. They also find that entry barriers greatly inhibit the formation of new ventures. Entry barriers, thus, help reinforce a culture of unproductive entrepreneurship (Baumol 1990). The industry setting also influences strategic entrepreneurship. McDougall et al. (1994) find that new ventures have high sales growth when entering high growth industries and engaging in a broad breadth strategy. All of these factors help explain how strategy and industry structure affect new venture internationalization through a complex and interactive relationship (Fernhaber et al. 2007). In addition, findings from several studies (Shane 2008; Hurst and Pugsley 2011, 2017) indicate that all entrepreneurs are not created equal and, thus, some industries have more small business owners who are less interested in growth and innovation and are more interested in non-pecuniary factors (e.g., flexibility and autonomy). Based on this review, how competitive and profitable some industries are or whether entrepreneurs desire to expand their businesses largely depends on the choice of industry. Thus, the choice of industry becomes very important for analysis. Despite these findings, prior research has not comprehensively examined the ways industries affect entrepreneurial outcomes. We fill this void by performing and empirical analysis of entrepreneurial outcomes using the Kauffman Firm Survey (KFS) data in the USA.",12
20.0,1.0,"Journal of Industry, Competition and Trade",06 July 2019,https://link.springer.com/article/10.1007/s10842-019-00308-1,"Market Structure, Entry Barriers, and Firms’ R&D Intensity: Panel Data Evidence from Electronics Goods Sector in India",March 2020,Richa Shukla,,,Female,Unknown,Unknown,Female,"In this study, we analyse the role of different elements of market structure in relation to firm-level R&D. Elements of the market structure included in this study are size distribution of firms, number of competitors, and height of entry barriers (Comanor 1967; Shepherd 1972; Kamien and Schwartz 1982; Vossen 1999). Since the early 1960s, there has been much theoretical and empirical discussion of the impact of market structure on firm spending for research and development (see, for instance, Mansfield (1963), Scherer (1965), Lall (1983), Kumar (1987), and Geroski (1990), among others, for more details). There has, however, been no consensus on the relationship between them. While most of this literature has been concerned only with the firm size and concentration ratios, accounting for entry barriers is relevant because potential competition from new entrants would also contribute towards creating pressure of competition within an industry (Comanor 1967). In the wake of liberalisation, the Indian Economy experienced major structural changes in its industrial policy. With the gradual easing of bureaucratic norms and regulations and prospect of a large market base, potential new entrants were striving to make their marks and arguably pushed the existing domestic as well as foreign incumbents operating in India to strategise their positions. While the Indian firms faced stiff global competition from their multinational counterparts, some of the positive externalities include access to foreign technology, collaboration with foreign firms, and the use of specialised services from abroad through outsourcing. Particularly during the second phase of economic reforms in India (post-2000) guided by the dominant presence of a knowledge economy ably supported by the information technology (IT) sector and information technology enabled services (ITES), there were eventual shakeouts in the electronics manufacturing sector. While there has been a modest increase in the number of electronic firms from 143 to 245 between 2000 and 2010, the sector has witnessed a steep increase in the number of firms exiting their field of operation (only 88 firms reported sales figures in 2015) (see CMIE Prowess Database). In fact, the emergence of a significant middle-income class and revolution in the telecommunications sector played a major role in boosting the electronics sector which culminated into an inherent dynamism both in terms of continuous upgradation of products and processes. Therefore, it goes without saying that the competition for market share (both domestic as well as the exports market) among the existing firms changed into different dimensions over these years. With fast changing dynamics in the structure of the industry and the rising challenges from the Information Technology Agreement (ITA) of transforming electronics production from “high-volume, low-cost” to “low-volume, high-value”, policies to upgrade electronics manufacturing industry placed considerable importance on technological improvements in products and processes through incentivising research-oriented activities. The case for promoting India as a manufacturing destination is also getting stronger with time due to burgeoning local demand and increasing maturity of the Indian market. This is also possibly an outcome of the increased R&D initiatives of electronics firms operating in the consumer electronics and communication and broadcasting equipment industry group, among others. The current focus is to rejuvenate India’s hardware manufacturing along with wireless, consumer electronics, aerospace and defence, medical devices, and security solutions (Frost and Sullivan Report 2014). The government’s National Policy on Electronics is an important step on this path. Of late, the Indian electronics sector sustained the increasing demand through imports of critical intermediate inputs as well as the final goods.Footnote 1 In order to cater to the love for qualitative variety as well as growing demand, not only it is important to address the supply side bottlenecks (if any), more importantly, it is the technological upgradation towards more user-friendly features that evolved as the major deciding factor apart from aggressive marketing and advertisement strategies that had been observed both in the white goods industry and telecom equipment sector. Given a liberal policy environment, it seems to be of relevance to look at the possible determining factors of in-house R&D of firms operating in a high-technology-intensive sector such as electronics. Against this backdrop, the objective of this study is to examine the impact of market structure on firm-level R&D activity of electronic firms in India. The dataset comprises information of 353 firms in an unbalanced panel for the time period corresponding to the second decade of the economic reforms, 2000–2015. The rest of the paper is organised as follows. The “Literature Overview and the Empirical Hypotheses” section presents an overview of literature and formulates the empirical hypotheses. The “Data and Variables” section describes the data and variables. “The Econometric Method” and “Empirical Results” sections explain the estimation methodology and discusses the empirical results, respectively. Lastly, the “Summary” section concludes the paper.",6
20.0,1.0,"Journal of Industry, Competition and Trade",27 August 2019,https://link.springer.com/article/10.1007/s10842-019-00316-1,Shopping Hours and Entry - an Empirical Analysis of Aldi’s Opening Hours,March 2020,Samuel de Haas,Daniel Herold,Jan T. Schäfer,Male,Male,Male,Male,"In mid 2015, Aldi, Germany’s biggest discounter,Footnote 1 started to extend the opening times of some of its stores from 8 to 9 p.m.. This article empirically examines the drivers of the decision to open stores longer. For this purpose, we collected data on the opening hours of all German retail grocery stores as well as the distance between them. By controlling for socio-demographic variables such as income and population density, we study the strategic effects driving the decision of Aldi to extend shopping time of a given store until 9 p.m.. The goal of our study is to examine how the choice to open a given Aldi outlet longer than 8 p.m. is affected by the opening hours of nearby stores run by competitors as well as by nearby Aldi outlets. A quasi-natural experiment in the industry allows us to isolate these strategic responses of a given Aldi store because until mid-2015 basically all Aldi outlets were closing at or before 8 p.m.Footnote 2 This schedule was a world-wide policy: By the time we collected the data for this study, for instance, US shops were also closing at 8 p.m.Footnote 3 Although speculative, we assert that this change in policy is due to a turnover in Aldi’s leadership structure.Footnote 4 Despite being unable to pin down the exact reasons for these developments, Aldi de facto refrained from extending shopping hours after 8 p.m. for a long period of time after legal changes in 2006 and 2007 allowed the extension of shopping hours. All of Aldi’s main competitors indeed extended opening hours after these changes in regulations came
into force (see Section 4.2). We thus assume that around 2015 there was an exogenous event that triggered Aldi’s strategic expansion of opening hours. In 2015, four grocery retail groups controlled roughly 67 % of the German market: Edeka (25.3 %), Rewe (15 %), Schwarz (Lidl and others) (14.7 %), and Aldi (11.9 %). There were 6 smaller players with 1–5 % market share whereas there is a fringe of 13.7 % that comprises very small suppliers.Footnote 5 Since at least 2007, most federal states of Germany allow retail grocery stores to open longer than 8 p.m. on workdays.Footnote 6 To examine the drivers of Aldi’s decision on whether to extend the shopping hours of a given store, we interpret this decision as entry into a new market, namely, the market of retail grocery shopping after 8 p.m. This interpretation allows us to apply a straightforward Logit regression in order to analyze entry decisions based on, e.g., Berry (1992) and Toivanen and Waterson (2005) (see Section 3). To the best of our knowledge, we are the first to adopt this approach to examine shopping hours. Moreover, studies thoroughly examining the latter topic empirically are quite scarce (see Section 2). Our main findings are, first, that it seems that firm learning influences Aldi’s decision to expand shopping hours of its outlets. In our sample, the probability that a given Aldi outlet extends shopping hours past 8 p.m. decreases with the number of outlets run by Aldi’s close competitors closing at or before 8 p.m.. However, the number of competitor’s outlets that are located close to a given outlet of Aldi and that allow for shopping past 8 p.m. does not significantly influence Aldi’s decision about whether to extend shopping hours of that outlet. This observation suggests that Aldi learns from its closest competitors in which areas not to open later than 8 p.m. Second, we find that it seems that consumer learning occurs. The probability that a given Aldi outlet is open until 9 p.m. significantly increases in the number of nearby Aldi outlets that are also open until 9 p.m. Controlling for population density and purchasing power, this result thus provides evidence that consumers
learn in which areas shopping at Aldi is possible until 9 p.m., which makes it profitable for other Aldi outlets located close to these areas to also extend shopping. The findings about consumer learning can be interpreted from the viewpoint of evolutionary game theory as proposed by Kosfeld (2002). In those areas where coordination between consumers and discounters was successful, extending shopping hours of an additional Aldi store is more likely to be profitable. This pattern may also be explained by market expansion, where consumers demand increases when shops they are loyal to expand their shopping hours (Yamada (2019), Flores and Wenzel (2016)). Moreover, one can interpret the aforementioned firm learning in a similar fashion. In areas where the population of consumers focused on discounters have not (yet) coordinated on longer shopping hours, Aldi refrains from opening longer than 8 p.m.. These may be those areas where close competitors also close their outlets at or before 8 p.m.. The article is structured as follows. In Section 2, we outline the determinants of shopping hours as well as the related literature. In Section 3, the model upon which our empirical approach is based will be explained. Some facts about the German retail grocery industry are outlined in Section 4. In Section 5, we present our empirical results as well as descriptive statistics. Section 6 concludes and robustness checks are stated in the Appendix.",
20.0,1.0,"Journal of Industry, Competition and Trade",20 February 2019,https://link.springer.com/article/10.1007/s10842-019-00296-2,Regional Inequality: An Analysis under an Extended Core-Peripheral Model,March 2020,Marcus Gumpert,,,Male,Unknown,Unknown,Male,"The central problem of underdeveloped regions is that transfers are made between regions without increasing productivity to the same extent. Higher regional incomes and only moderately rising productivity reduce competitiveness. In the papers of Gumpert and Krugman, two spatial models were analyzed. In a ‘classical’ core peripheral model, new parameters such as elasticities, fixed costs, variable costs, spatial considerations through company distribution and number of companies lead to an increase in the development of the advanced region (Brezis et al., 1993; Gumpert, 2013; Gumpert, 2019a; Krugman, 1991; Krugman and Venables, 1990; Krugman and Venables, 1995). This can be seen in individual regions such as Italy (Desmet, 2002; Desmet and Ortín, 2007, p. 5). The Heckscher-Ohlin theorem behaves contrary to this. In this model, capital transfers between regions and capital mobility lead to the underdeveloped region approaching and developing towards the advanced region (Gumpert, 2016). The following paper will combine both contrary models. Consequently, an ‘extended’ core peripheral model has been developed, which is more robust and realistic. These basic parameters come from Desmet and Ortín (Desmet, 2002; Desmet and Ortín, 2007). A classic example is the European Union. There are regions in the European Union with different levels of development. The Western and Central regions (Denmark, Germany, and France) of the European Union are advanced, whereas the Eastern regions (Poland and the Czech Republic) lag behind (Eurostat 2018, p. 3). The second column of Table 1 is only suitable to a limited extent for the analysis of regional development behavior because other indicators, such as factor mobility, factor endowment, benefit, externality, technology, and learning effect, must be considered. The third column, namely “Gross domestic product per capita,” serves as an analytical basis due to the lack of factor endowment and factor mobility (Eurostat 2018, p. 3). In the last column, the individual nations are compared with an average country (European Union). A large gap between Western/Central and Eastern Europe can be clearly observed. The European Union pursues the primary objective of harmonizing the economic conditions of the individual member states. The European Union’s cohesion policy provides for advanced regions to support poorer regions. The financial transfers are intended to harmonize all wage and living conditions in the European Union. Wage subsidization leads to the approximation of financial conditions between regions (Barca 2009, p. 4). Table 1 shows the regional underdevelopment. The European Union’s agricultural policy provides information on the development of regions (Busch 2004/2005, p. 9; Busch 2005, p. 136; Federal Statistical Office 2004, p. 53; German Central Bank 2004, p. 7; IWH 2004, p. 174; Ludwig 2004, p. 322). Subsidizing the incomes of the economically lagging regions causes wages in the agricultural sector to increase, and the workers to remain in this sector. This phenomenon shows the negative effect of financial transfers in connection with regional development (Padoa Schiopa and Basile 2002; Desmet and Ortín 2007, p. 2). The article of ‘Gumpert (2019a)’ analyses regional underdevelopment using a Krugman core peripheral model. Aspects of Venables were also considered. Additional influencing factors are fixed costs, variable costs, transport costs, a partial mobility of the factor labor (industrial labor), monopolistic competition, substitution elasticity or internal aspects (number of companies and their spatial distribution influenced by transport costs). The model only promotes the advanced region (Brezis et al., 1993; Gumpert, 2013; Gumpert, 2019a; Krugman, 1991; Krugman and Venables, 1990; Krugman and Venables, 1995). If, in the European Union, the economic increases in ‘Gross domestic product’ and ‘Gross domestic product per capita’ are considered to be in the advanced regions, we see a steady and sustainable increase. The time series from 2013 to 2016 confirm these statements (Eurostat, 2015, pp. 3; Eurostat, 2016, pp. 3; Eurostat, 2017, pp. 3; Eurostat, 2018, pp. 3). However, it can be seen that in the European Union the economic relations between the advanced and the undeveloped region are stagnating at a fixed level (analogous to Table 1) and that substantial capital transfers are being made (Eurostat, 2015, pp. 3; Eurostat, 2016, pp. 3; Eurostat, 2017, pp. 3; Eurostat, 2018, pp. 3). The article of ‘Gumpert (2016)’ demonstrates the balancing function of capital transfers, capital mobility and returns (Gumpert, 2016). The statements from the Heckscher-Ohlin theorem lead to an alignment of the benefits between the two regions. Through the new aspects from the core peripheral model, the advanced region intensively increases the utility. However, the fixed balance of the returns leads to the undeveloped region developing indirectly. This constitutes a second internal rational dependency between the regions. The underdeveloped region uses its capital to develop itself further. In the article of ‘Gumpert (2016)’, this puts the advanced region at a disadvantage. With the introduction of the core peripheral model, the advanced region has a way of counteracting the disadvantage of capital transfers (Gumpert, 2019a; Krugman, 1991; Krugman and Venables, 1990; Krugman and Venables, 1995). Costs are optimized, product variety is increased and technological growth for spillover effects is increased. This overcomes the weaknesses of the Heckscher-Ohlin framework. ‘Gumpert (2019a)’ promotes only the advanced region through the exclusive consideration of the core peripheral model (without capital transfers and returns). The Heckscher-Ohlin theorem serves as the basis, which is combined with the core peripheral model. The assumptions of the Heckscher-Ohlin theorem such as capital transfers, returns or industrial capital are adopted. Furthermore, the basic assumptions of the core peripheral model are integrated. These include combination wages, substitution elasticity, marginal costs, fixed costs, variable costs, transport costs, and the number of companies. The central innovation of the model is how the individual assumptions from the Heckscher-Ohlin theorem and core peripheral model interact with each other as well as influence each other (Brezis et al., 1993; Desmet, 2002; Desmet and Ortín, 2007; Gumpert, 2016; Gumpert, 2019a; Krugman, 1991). In the first period, the two sectors are formed in the regions. In the second period, a new technology is available. The industrial region is characterized by high wages, high productivity, and transfer payments. The agricultural region is characterized by low wages, lack of productivity, and the transfer payments received from the advanced region. The financial transfers are certainly in place. The higher the financial transfers, the lower the change in the underdeveloped region to adopt the new technology. The reason for this phenomenon is the uncertainty as to whether the new region can be attracted (Desmet and Ortín 2007; Gumpert 2016; Krugman 1991; Gumpert, 2019a; Gumpert, 2019b, p. 779; Wolff, 2013, pp. 13). The motivations for this following analysis are: Padoa Schiopa and Basile (2002), for example, have observed the inequality between regions as a result of the behavior of national trade unions, which always advocate wage equality between regions within countries. In principle, the East accepts higher wages to improve living conditions. Due to the lack of an increase in productivity, this behavior leads to underdevelopment. To answer this phenomenon, the author mixes the models according to Heckscher-Ohlin and Krugman and develops a novel combination model (Brezis et al., 1993; Desmet and Ortín, 2007; Gumpert, 2019a, p. 779; Gumpert, 2019b, p. 3; Krugman, 1991; Padoa Schioppa and Basile, 2002). Conscious model theoretical analysis is to be carried out. Authors such as Daniele, Felice, Malanima, and Ostuni have presented the phenomenon empirically. A sustainable model theoretical explanation is still lacking. The following paper is intended to contribute here (Daniele et al. 2018; Felice 2018a; Felice 2018b; Gumpert, 2019a, p. 779). The Ricardian model provides a factor analysis for work. This factor is rigid and not mobile. The model also provides perfect competition. The Heckscher-Ohlin theorem defines a completely mobile second input factor, capital, in addition to the rigid labor factor. The factor capital is regionally and sectorally mobile. Finally, the core peripheral model provides the necessary flexibility in the labor factor and allows for market modifications (Brezis et al., 1993; Desmet, 2002; Desmet and Ortín, 2007; Krugman, 1991). The core peripheral model has one factor, namely, labor, but an analysis of a higher degree of mobility of the input factors by a second factor (capital) should be considered. Due to the second input factor, namely, capital, the following modifications must be made to the core periphery model: enlargement by the factor capital, expansion of the production function of the agricultural sector, introduction of a standard unit in the industrial sector, capital- and labor-intensive productions, and specialization patterns due to the learning advantage or productivity increase (Brezis et al. 1993; Brezis and Tsiddon 1998, p. 263; Cobb and Douglas 1928; Desmet 2002; Desmet and Ortín 2007; Ehrenfeld 2004, p. 2; Fonseca 2017, p. 21; Krugman 1991; Ohlin 1933; Pindyck and Rubinfeld 2003; Samuelson and Nordhaus 2005). With the introduction of heterogeneous spatial space by the core peripheral model, the factor capital takes on a new significance by influencing the regional distribution/number of companies (Krugman, 1991). Two market forms are combined. The monopolistic competition of the core peripheral model is combined with the complete competition of the Heckscher-Ohlin theorem in the agricultural sector. In addition, the second factor of capital is introduced in both the sectors. In the ’extended’ core peripheral model, the rising and constant returns to scale are introduced across the two sectors and influenced by a second factor (Daniele et. al., 2018, p. 648; Gumpert, 2019a, p. 780; Krugman, 1991, p. 14; Martin and Sunley, 2017). ‘Gumpert (2019b)’ uses a growth theoretical model framework, according to Solow and Ramsey. New aspects are technological progress, the effects of growth theory or the saving of part of the household income. These assumptions are extensions of the Heckscher-Ohlin theorem and have no influence on this paper.",1
20.0,1.0,"Journal of Industry, Competition and Trade",03 December 2019,https://link.springer.com/article/10.1007/s10842-019-00314-3,Correction to: Regional Inequality: An Analysis under an Extended Core-Peripheral Model,March 2020,Marcus Gumpert,,,Male,Unknown,Unknown,Male,,
20.0,2.0,"Journal of Industry, Competition and Trade",06 January 2020,https://link.springer.com/article/10.1007/s10842-019-00322-3,Rebirth of Industrial Policy and an Agenda for the Twenty-First Century,June 2020,Karl Aiginger,Dani Rodrik,,Male,Male,Unknown,Male,"After a period of decline in interest and premature predictions of demise, industrial policy is back on the scene. A variety of trends have contributed to the renewed interest. In the developing world, there has been a pushback against the market-fundamentalist approach, typically associated with the Washington Consensus. Even when growth rates have been high, economies in Sub-Saharan Africa and Latin America have experienced unsatisfactory rates of productive transformation and shortfalls in generating quality jobs in manufacturing or modern services. This has created a demand for proactive government policies to diversify and upgrade economies beyond simply freeing up markets. In the advanced economies, generalized labor market malaise and the lingering effects of the financial crisis have produced similar effects. Low growth dynamics occurred especially in the euro zone, as countries with trade and budget double deficits with a common currency struggled to come out of the crisis. The continuing decline in the employment shares of manufacturing in the USA and Western European countries and the increasing competitive threat posed by China on world markets have pushed in the same direction.Footnote 1 Interest in industrial policy is being further stimulated by disruptive technological change—from automatization to digitalization, industry 4.0, and the Internet of things. Behind many of these trends looms the imposing figure of China. China’s economic growth has slowed down, but even at these more moderate rates, the country is poised to become soon the largest economy in the world. The country’s rapid export-oriented industrialization and impressive manufacturing sector have played a critical role in this achievement. In the USA, China has rapidly become a bogey man. American businesses complain about inadequate market access and unfair trade practices in China. Labor advocates worry about the large footprint of Chinese exports in communities that are experiencing difficulties producing sufficient numbers of good jobs. The US national security establishment meanwhile is increasingly concerned about technology transfer to a strategic and geopolitical rival and loss of US technological edge. All these have combined to yield both a hard line against China and a desire for more robust industrial policies at home. Remarkably, industrial policy is now a favored theme at both ends of the political spectrum, from progressives such as Senator Elizabeth Warren to conservatives such as Senator Marco Rubio.Footnote 2 This is a trend that is paralleled to some extent in other nations. In Germany, for example, there have been calls for more activist industrial policies both from left leaning economists like Peter Bofinger and from the conservative minister for industry Peter Altmaier. France and Germany tried to reestablish their cooperation in the EU by publishing a “Manifesto” on industrial policy.Footnote 3 The debate in Europe so far has had less of a hard edge against China. The growing Chinese presence in Europe, and especially Chinese acquisitions of European firms, has led to calls for a review of competition rules. In Europe, as well as in the USA, applying “national security clauses” to prevent Chinese giants from buying firms is on the agenda. When mergers of European firms are screened by the European competition authority, “competition with Chinese mega-firms” sheltered in their own country is deployed frequently as an argument for allowing such mergers to go ahead.Footnote 4 On the other hand, the EU enjoys an overall trade surplus—with very different national experiences within and outside the common currency area. With the greater salience of industrial policy objectives, there is a brewing tension between these objectives and competition policy goals. For developing nations, meanwhile, China is both a threat and an example to emulate. On the one hand, Chinese success in manufacturing has made it more difficult for many middle-income countries to compete on world markets and has contributed to premature deindustrialization.Footnote 5 On the other hand, Chinese industrial strategies are yet another powerful example of how concerted government action can stimulate rapid economic diversification and structural change. And as Chinese labor costs continue to rise, there is potentially a role for low-income, low-cost countries to fill the gap on world markets left by receding Chinese export presence. A question of great interest is whether Africa will be able to become a supplier of manufacturing goods, with manufacturing playing a key role for “rising Africa.” This continent has never had a proper industrialization experience, and many observers hope this is the time for a great leap forward based on industrial growth and exports. Is there a strategy that could produce rapid industrialization, despite forces militating in a different direction such as rich natural resources endowments, political conflicts, climate change, and bad governance? For other, middle-income developing nations, the question is the role that a more modern version of industrial policy, emphasizing productive services in addition to manufacturing, can play in overcoming premature deindustrialization, middle-income traps, and failure to transition to more fully diversified economies (Table 1).Footnote 6 Finally, an increased focus on societal and environmental goals is necessarily raising questions about industrial policy as it shapes the structure of economic activity more generally. In general, manufacturing has been a “dirty” sector with high carbon emissions. It is also a sector subject to strong business fluctuations, leading to short- and medium-term unemployments. On the other hand, in many countries, manufacturing is associated with good jobs and a strong middle class. Many technological solutions for cleaner production also have their origins in manufacturing, and the interface between manufacturing and services can often lead to highly paid and relatively stable employment. One can imagine the greening of industrial policyFootnote 7 or new forms of industrial policy steered by employment concerns.Footnote 8 The “green new deal,” which has adherents on both sides of the Atlantic Ocean (and is high on the agenda of Ursula Von der Leyen, the new president of the European Commission), is an attempt to combine these two objectives under one large rubric. It is hard to know where these trends will lead. It is possible that a renewed emphasis on industrial policy, reinforced by the spread and growth of ethnonationalist populism, will replicate and magnify the worst mistakes of interventionism and statism from the past. This would take the form of defensive and purely protectionist strategies aimed at propping up ailing firms and national champions, while creating beggar-thy-neighbor harms on other nations. Or we could see the rise of new, more nimble forms of collaboration between the government and the private sector that draw on the lessons of the past and reorients them towards new challenges. Whatever the future direction, we can probably safely say that the renewed interest in industrial policy is not a short-term phenomenon. Industrial policy will be with us in the years ahead. The question before us, therefore, is what shape industrial policy should take in this period of disruptive political and technological change. How can policy makers craft an industrial policy that is future- and welfare-oriented, which not only mitigates market failure, but also addresses society’s most important social and environmental challenges, without stroking national chauvinism. Four of the transformations that are needed are clear from the outset. First, industrial policy can no longer be about industry or manufacturing per se. Employment de-industrialization is virtually inevitable in middle-income and advanced economies alike. As the world economy turns increasingly towards services, it is clear that we will need a conception of industrial policy that addresses the need to nurture and develop modern economic activities more broadly, including but not limited to manufacturing. The appellation “industrial policy” may be even misleading insofar as it clouds this broader mission. Other alternatives such as “productive development policies,” “structural transformation policies,” or “innovation policies” do exist. We have stuck with the traditional terminology here, even though these other labels may be more appropriate for what we have in mind. Second, the industrial policy of the future is unlikely to look like the economist’s traditional conception of it: top-down policymaking, targeting pre-selected sectors, and employing a standard list of subsidies and incentives. This kind of industrial policy may have been common in certain countries—Japan, South Korea, Taiwan, and some European countries—and has produced some success, but increasingly, the emphasis is different. The contemporary conception and practice of industrial policy is much less about top-down incentives and much more about establishing a sustained collaboration between the public and private sectors around issues of productivity and social goals. This kind of dialog eschews an ex ante selection of activities to promote or policy instruments to utilize. It focuses instead on engineering an appropriate institutional setting within which the collaboration can best bear fruit. Government policies, as well as firm strategies, are the outcome of this process. These policies and strategies are viewed as provisional at the outset, to be continuously monitored and revised in light of outcomes. Third, industrial policy can no longer be an isolated policy, developed on its own and competing with competition, regional, and other growth policies (Aiginger 2014). As we mentioned above in the context of Europe, the goals of competition policy and industrial policy are often in tension or viewed as such. Competition policy targets mainly consumer welfare, while industrial policy is concerned with productive, dynamic industries. In the long run, the two goals ought to be consistent, but in the short run, maximizing consumer benefits may lead to different priorities than productive diversification and dynamism. Similarly, there has often been not only considerable overlap but often also a conflict between regional policies and industrial policy without an explicit division of labor or coherent coordination. To what extent, for example, should industrial policy target communities and areas left behind and take the form of “place-based” policies? And to the extent that they do, what are the respective roles of propping up declining, traditional industries versus encouraging new industries? Such questions will have to be confronted more systematically. Fourth, support of structural change and productivity growth can no longer serve as a policy goal without any consideration of the direction of technological change.Footnote 9 In industrialized countries, the current bias of technical progress towards labor saving must be questioned, as it is neither natural nor conducive to a shift to lower, greener, and healthier growth. Steering technological change in a direction that is friendlier to environment and labor must be a key element of new industrial policies. In emerging economies, the question is whether industrial policy should copy leading economies or instead look for approaches better suited to the own countries’ stages of development, as well as focus on new priorities such as supporting vulnerable groups, gender equality, reduced fossil energy use or the development of green technologies for new types of agriculture, housing, and transport.Footnote 10",110
20.0,2.0,"Journal of Industry, Competition and Trade",03 January 2020,https://link.springer.com/article/10.1007/s10842-019-00323-2,The New Empirics of Industrial Policy,June 2020,Nathaniel Lane,,,Male,Unknown,Unknown,Male,"Industrial policies are everywhere. From Germany’s Industrie 4.0 to Strategic Priorities of Digital Bangladesh, national industrial strategies are omnipresent across the world. Though for decades industrial policies have been central to debates about the role of the state in economic development, the empirical literature on these policies has remained underdeveloped. Until recently, econometric evaluations of these interventions were exceedingly rare.Footnote 1 This paper considers the new empirical research examining industrial policy. By using contemporary econometric methods and utilizing natural experiments, I show these studies have been swiftly expanding what we know—and updating what we thought we knew—about these policies. To be clear, by industrial policy, I mean intentional political action meant to shift the industrial structure of an economy. Often policymakers hope this shift will be more favorable for growth, relative to what would have happened had the economy evolved according to its static comparative advantage (Chang 2003; Noland and Pack 2003; Lane 2019). Of course, there are many iterations of this definition, but most embed a causal argument: the idea that there is a better outcome that would not have occurred in the absence of the intervention. While it seems this would be ripe territory for causal inference, this has not been the case until recently. The goal of this paper is to assess the emerging body of work on industrial interventions and to speak to the potential of evaluating these policies more broadly. Doing so entails looking backward. I do so not only because economists have long debated the historical importance of these policies.Footnote 2 Instead, new studies of industrial policy have illustrated the value of using rich retrospective cases, new data, and institutional details to improve our understanding of these interventions. Moreover, by looking at the past body of empirical research, we can refine our understanding of these controversial policies. By critically examining this work, I hope to point out misconceptions that have persisted—and how contemporary econometric methods can and do address these deficiencies. In light of early industrial policy studies, we often hear the refrain: “The evidence is mixed.” An implication of this review is that we should hope for more mixed evidence. In evaluating new empirical work on industrial policy, and earlier high-quality case studies, my argument is that the evidence surrounding industrial policy will likely be nuanced and complicate the conventional wisdom. Precisely because industrial policy is complex and multidimensional, deployed across different economies and with different objectives, useful evidence will often be, in a sense, mixed. Justifications for industrial policies introduce their own complications. Benefits and costs may be hard to fully capture in straightforward empirical exercises, much less distill into a single discrete punchline. Interventions may rely on hopes of long-run—or dynamic—benefits (promoting infant industries, accelerating technological change, encouraging agglomeration). These benefits often justify the short-run—or static—costs of interventions (Greenwald and Stiglitz 2006). More philosophically, the ambitious and abstract objectives of planners complicate our quantitative machinery. Generally speaking, either side of the cost-benefit ledger is difficult to fully capture with our current toolset.Footnote 3 That said, past empirical evidence is not in fact mixed. It is often vacuous. Section 2 argues that aspects of earlier cross-country and industry-level regression studies have, indeed, created conceptual confusion in how we empirically think about industrial interventions. I use this section (Sect. 2) to review the shortcomings of this literature, juxtaposing prior studies against new evidence from modern empirical analysis. First, I focus on conceptual confusion surrounding early evidence, namely, issues in interpreting regression studies and issues related to the endogeneity of policy. Second, I show first-generation aggregate studies do not adequately articulate, contextualize, or even clearly measure many interventions. Third, early work has been mostly critical of the extent to which industrial interventions targeted spillovers—a principal motive for industrial interventions. In light of recent evidence, I argue that these tests may be incomplete, and may not adequately speak to the role of spillovers in industrial policymaking. Nonetheless, empirical evaluation of industrial policy is notoriously challenging. Not only is randomization unlikely, but also, by construction, industrial policies are meant to promote special industries, products, and places. These endogenous interventions seem awkward in the world of randomized policy evaluations. I argue that these issues are not insurmountable. While many studies of industrial policy argue counterfactual analysis of industrial policy is impossible, Sect. 3 argues otherwise. Here, I discuss how the language of contemporary causal methods can accommodate the context of these interventions. I illustrate this by considering related work on place-based policy, which is actively confronting issues of endogenous policy and selection in policy evaluation (Neumark and Simpson 2015). Recent studies of place-based industrial policies in the UK (Criscuolo et al. 2019) and across the EU (Becker et al. 2010; Bernini and Pellegrini 2011; Cerqua and Pellegrini 2014) have used localized random variation to estimate the impact of targeted policy. A related wave of recent studies on industrial R&D incentives, similarly, shows the promise of using rankings, thresholds, and similar discontinuities for causal estimation (Dechezleprêtre et al. 2016; Howell 2017). Section 3 also argues that within-country studies of industrial interventions can answer valuable questions about national policies, even when they do not aggregate impacts. I argue that, much like microeconometric studies of trade policy and natural experiments in macroeconomics, more microeconometric work can deliver valuable insights into the proposed mechanisms and workings of policies. With little systematic empirical evidence as to the workings of industrial policy, this work is valuable. The possibilities of microeconometric studies are detailed in Sect. 4. This final section shows how new case studies are confronting these issues through better research design, especially by combining natural experiments and new within-country data. Merging newly digitized panel data with quasi-experimental design allows Harris et al. (2015), Giorcelli (2019), Hanlon (2018), Juhasz (2018), Lane (2019), and Mitrunen (2019) to trace the medium- and long-run consequences of policy on industrial development. Relatedly, Aghion et al. (2015); Martin et al. (2017); Rotemberg (2017); and Criscuolo et al. (2019) estimate the impact of contemporary interventions using careful within-country policy variation with rich microdata. With rich network data, Blonigen (2016), Lane (2019), Liu (2018), and Rotemberg (2017) consider the transmission of policy through linkages. Hanlon (2018) and Mitrunen (2019) show the potential of investigating other types of externalities: learning-by-doing and human capital spillovers from interventions. While it is hard to evaluate the aggregate implications of these interventions, new studies of industrial policies are already providing new insights.Footnote 4 Relatedly, quantitative work by Liu (2018) illustrates new avenues of evaluating the aggregate general equilibrium consequences of sectoral targeting. Before I launch into this study, I want to make some things clear. First, when I discuss industrial policy, I am mainly talking about infant industry policies aimed at promoting the development of new economic activity. However, when necessary, I discuss policies aimed at aiding lagging industries. Although this discussion centers on industries and firms, many of these statements will likely apply to geographies as well—as in the case of place-based policy. Second, throughout this study, I am mostly considering the case of industrial promotion in a developing country setting. However, especially in the case of sunset and terminal policies, this work also applies to mature, high-income countries. Third, I largely discuss reduced-form studies: approaches where economists are trying to recover statistical relationships between variables, often using quasi-experimental variation to identify causal relationships between an outcome and an explanatory variable. I do not focus, however, on structural econometric studies—studies that estimate parameters directly using theoretical models. Nevertheless, I discuss valuable structural work from the field of industrial organization. Broadly, the contours of my argument map to such structural work, and both flavors of empirical work should be seen as complementary. Finally, this review does not advocate industrial policy and targeted interventions—it is a review advocating better evidence. By interrogating earlier critical work on industrial policy, I am not arguing for a favorable interpretation of interventions. Instead, I am arguing for more precise studies to improve our understanding of these policies. This study is organized as follows: Before considering new empirical tools and studies of industrial policy, Sect. 2 interrogates earlier studies of industrial policies. Section 3 clarifies some of the residual issues from past empirical work, specifying the possibility of microeconometric evaluation of industrial policy. I do so by focusing on contributions from place-based policy evaluation. Finally, Sect. 4 reviews new empirical research on industrial policy, describing the array of historic case studies tackling industrial policy issues. I argue this literature is rapidly updating our understanding of these policies. Section 5 closes this study, and describes both takeaways and shortcomings of the current literature. As well, I use this section to discuss future directions of research.",18
20.0,2.0,"Journal of Industry, Competition and Trade",03 January 2020,https://link.springer.com/article/10.1007/s10842-019-00324-1,Network Failure and the Evolution of the US Innovation System,June 2020,Fred Block,Matthew R. Keller,Marian Negoita,Male,Male,Male,Male,"Bator’s (1958) canonical article on “The Anatomy of Market Failures” focuses its analysis on those failures that occur even when one assumes that market actors have perfect information. Since Bator’s article, however, economists have examined market failures that result from the reality that information is not perfect and is, in fact, often expensive and time consuming to obtain. Scholarship on transaction costs, search costs, information asymmetries, and signaling are all focused on this issue.Footnote 3 However, the great advantage of the concept of network failure is that it highlights the reality that recent changes in the organization of the economy and of the innovation process dramatically increase the importance of effective coordination within networks. Historically, many of the problems now described as network failure were managed through proximity. At least since Marshall (1890); see also Piore and Sabel 1984; Porter 1998; Belussi and Caldari 2009), economists have recognized a strong tendency for economic activity to be clustered in certain locations—industrial districts where multiple firms are involved in the various stages of a production process. Usually, an industrial district includes multiple competing firms that are producing final products as well as smaller, subcontracting firms with expertise in one particular stage of the production process. Whether we are talking about the cutlery industry in Sheffield, the garment district in New York City, Hollywood, or Silicon Valley, the basic elements are the same. The obvious advantages for any particular firm of locating in such a district are the ability to recruit employees, including managers, with the appropriate set of skills and to coordinate more easily with both upstream and downstream firms that would either purchase one’s output or provide needed inputs. Moreover, the existence of multiple firms at each stage of the production process helps each individual firm to cope with uncertainties and disruptions in the production process. In the case where one’s preferred subcontractor suddenly disappears as with the untimely death of an owner-manager, the firm could quickly shift to another subcontractor. Similarly, when a firm faced unexpectedly strong demand for its final product, it could enlist the help of multiple subcontracting firms. Finally, location within an industrial district can be an important source of information for shaping a firm’s competitive strategy since news of a competitors’ shift in strategy or adoption of a new technology is likely to spread quickly. Almost all of these advantages of location in an industrial district can be framed in terms of the avoidance of network failure. Location in the district makes it easier to connect with the partners one needs and significantly increases the probability that those partners will have the competencies that they claim. Even the informal gossip about a competitors’ strategy is useful in making sure that a firm is being responsive to where the particular market is headed. And, of course, since people within the industrial district know that they are likely to be doing business with each other on an ongoing basis, this significantly discourages opportunism. A participant in the network who gains a reputation for being unreliable faces a high likelihood of going out of business. In short, there was no need for a distinct concept of network failure because the industrial district idea explained the same phenomenon. However, the rise of the large, vertically integrated corporation in the late 19th and early twentieth century ultimately led to the decline of many industrial districts (Chandler 1990). The automobile industry, for example, got its start in cities such as Detroit and Turin that were classic industrial districts. However, as the industry consolidated around a handful of major firms that took control of most stages of the production process, factories could be located virtually anywhere and employment in the original industrial district declined precipitously. This dispersion of production made sense from a managerial point of view because of the power and strategic position acquired by unionized workers concentrated in that original industrial district. But the critical point is that the hierarchy of the multi-divisional firm substitutes for dependence on network partners and seemingly eliminates the advantages of locating in an industrial district.Footnote 4 In reality, however, the large multi-divisional firm has informational problems of its own. Its ability to produce optimal outcomes is diminished by principal agent problems and the difficulty of information flowing across different organizational divisions.Footnote 5 In the last three decades of the twentieth century, several trends revealed the weaknesses of vertically integrated firms. First, consumer demand began to shift away from standardized products, so that firms were under pressure to deliver a broader range of constantly changing products. Second, new technologies, including computerization, made both production processes and products substantially more complicated. With shorter production runs and more complicated products, there were obvious advantages to increasing the use of subcontracting firms that were able to acquire very specific forms of expertise. This was the context in which US automobile firms began to copy the system developed by Toyota where parts suppliers were located in close proximity to the firm’s final production line (Womack et al. 1990). These trends gave new vitality to some of the industrial districts that had survived the era of vertical integration. It has also produced a number of brand new industrial districts such as bio-medicine clusters in San Francisco and San Diego and firms focusing on instrumentation in Santa Barbara (Kenney and Mowery 2014) There has also been an emergence of mini-industrial districts that have grown up around some of the dispersed factories that produce automobiles and other complex manufactured goods as US companies have adopted Japanese just-in-time production processes. However, globalization means that these twenty-first century clusters and mini-clusters are inevitably different from the industrial districts that Alfred Marshall knew. Nineteenth century districts could be almost entirely self-contained; all they needed from the rest of the world were raw materials and an interest in purchasing their products. Now, however, firms rely on scientists and technologists who are spread out across the world and there are likely to be some production tasks and coding tasks that are outsourced to workers in China and India. Moreover, even relatively self-sufficient clusters have to monitor what their foreign competitors are doing.Footnote 6 In light of the complexity that twenty-first century clusters cannot be fully self-sufficient, it follows that they can benefit from some governance structures to help firms strategize. Since new technologies are constantly requiring new competencies, part of the role of governance structures is to make sure that network partners and employees are obtaining the required skills. And, in fact, research on the most successful twenty-first century industrial districts show that they have developed bridging organizations that bring together network participants, including government and higher education institutions, to strategize about what kinds of investments and what new initiatives might be useful to strengthen the networks for the future (Kenney and Mowery 2014). In sum, the concept of network failure becomes essential because of the way that twenty-first century industrial clusters differ from those of the nineteenth century. Informal ties and the flow of gossip are not sufficient to solve the coordination problems that network participants face given technological complexity and their location in a highly competitive global economy. It follows that studying the governance structures within districts and the role of public agencies in supporting and coordinating with those governance structures is important for understanding why some clusters emerge and are successful while others either fail to emerge or are unable to sustain themselves.",3
20.0,2.0,"Journal of Industry, Competition and Trade",04 February 2020,https://link.springer.com/article/10.1007/s10842-019-00325-0,The Failure of French Industrial Policy,June 2020,Pierre-André Buigues,Elie Cohen,,Unknown,Male,Unknown,Male,"The question of deindustrialization and the means of reversing it is a staggering issue in the French economic debate. Each major factory shutdown brings to the heart of the debate the question of the French industrial decline, of its causes, and the policies to implement for the revival of the industry for a country the size of France. Deindustrialization has long been considered as a fact of development, the more the economies grow and become more sophisticated, the more they consume services, while industrial activities migrate to emerging countries as part of a well-understood international division of labor. France’s attachment to an industry-based specialization and active state policy in the sector has long been considered an archaism in the era of fabless-fab, extensive value chains, and growing importance of services in the industry itself. The paradox is that it is at the moment when, thanks to the decennial crisis that we have just experienced, industrial policy finds a new legitimacy that the French industry has finally evaded. There is indeed a triple French enigma of industrial collapse. It intervenes in the homeland of industrial policy. It intervenes in a country that invests as much as Germany in this activity but with poor results, which then raises the question of a possible bad investment. It continues even as, in the wake of European integration, France began to favor horizontal policies of a competitive environment. Why then this constancy in failure? To this triple enigma of the accelerated deindustrialization of France in relation to its neighbors is added the more general question of the effects of globalization on the acceleration of this process. France has long pursued an autonomous industrial policy to rebuild its economy after the Second World War, develop its productive apparatus, and weigh on its specialization. It did so, successfully, until the adoption of the single market and registration in the perspective of the euro. European integration, the ever closer union, the development of regulatory authorities for competition, and state aids led France to dismantle its public intervention apparatus. The introduction of the euro has also deprived France of its power of devaluation to correct relative competitiveness losses. Thus, we have a pure case of a voluntarist country subjected to the test of a globalization intermediated by the European Union whose long-term effects on the industrial activity can be judged. In this contribution, we will proceed in four stages. In the first development, we will pose the diagnosis of deindustrialization. Since the Gallois Report (2012), the agreement has been made on the diagnosis: France is the worst dropout in Europe, it is measured in terms of value added, jobs, and export market shares. The trend is continuous despite variations in economic conditions and policies. In the second step, we will discuss the successes of the French industrial policy of the origins and the reasons for the strategic reorientation, the dismantling of the tools, and the new orientations. For a long time, France has been a model and its industrial Colbertism has been at the origin of great success in advanced technological sectors such as nuclear energy, civil and military aeronautics, telecommunications, space, and high-speed train. These policies were abandoned in the 1980s. Thirdly, we will try to give an account of the reasons for the French industrial failure in the context of the acceleration of globalization and European integration. It is by re-articulating macroeconomic policies and sectoral policies that one can understand the policies actually conducted and analyze their results. Finally, in the fourth step, we present an evaluation of the French industrial policy in the context of the renewal of the theoretical and political context that is less hostile to sectoral industrial policies. We present also some hypotheses about the future of the French industrial policy. In a previous article in this review, Elie Cohen (2007) presented the tools of industrial policy and their implementation first in a national framework and then in a framework constrained by European integration. The perspective of this article is different, it tries to account for the ultimate failure of industrial policy, if we judge by the French industrial collapse, and tries to identify the causes in the articulation between macro and micropolicies and in the articulation between the national level of decision and European level.",2
20.0,2.0,"Journal of Industry, Competition and Trade",03 June 2020,https://link.springer.com/article/10.1007/s10842-019-00332-1,Coping with Societal Challenges: Lessons for Innovation Policy Governance,June 2020,Jan Fagerberg,Gernot Hutschenreiter,,Male,Male,Unknown,Male,"Humankind is faced with a number of grand societal challenges that policy makers need to respond to. Many of these, such as the climate challenge, have their origins in the interaction between man and nature. Continuing on the same path as hitherto is not viable as it may threaten the very foundations of economies, food and water supply, health and quality of life worldwide.Footnote 1 Changing course in a more sustainable direction is demanding, however, as it will require extensive changes—i.e., innovation in a broad sense—in a whole range of sectors, activities and ways of life. Moreover, these changes must be consistent, i.e., support rather than counteract each other. This poses huge challenges for policy makers. In the next section, we discuss, based on theory and available evidence, the implications for governance of innovation policy,Footnote 2 understood here as policies influencing a country’s innovation performance. Based on a systemic understanding of innovation and the factors influencing it, the paper particularly highlights the need for effective coordination of policies influencing innovation and changes in innovation policy governance that make this possible. To throw further light on how this may be done in practice, Sect. 3 of the paper considers three cases of national innovation policy practice, drawing on insights from the OECD’s country reviews of innovation policy as well as other sources. The countries considered, Finland, the Netherlands and Sweden, are among the most innovative countries worldwide as conventionally defined. Moreover, policy makers in these countries have, over many years, used innovation policy strategically to promote economic development, although in different ways, and engaged actively in policy learning to improve the effectiveness of policy. Their experiences may therefore have wider relevance. The final section discusses the lessons for national innovation policy governance.",11
20.0,2.0,"Journal of Industry, Competition and Trade",07 January 2020,https://link.springer.com/article/10.1007/s10842-019-00327-y,State Capacity and the Role of Industrial Policy in Automobile Industry: a Comparative Analysis of Turkey and South Korea,June 2020,Murat A. Yülek,Kwon Hyung Lee,Donghyun Park,Male,,Unknown,Mix,,
20.0,2.0,"Journal of Industry, Competition and Trade",27 January 2020,https://link.springer.com/article/10.1007/s10842-020-00333-5,Correction to: State Capacity and the Role of Industrial Policy in Automobile Industry: a Comparative Analysis of Turkey and South Korea,June 2020,Murat A. Yülek,Kwon Hyung Lee,Donghyun Park,Male,,Unknown,Mix,,
20.0,2.0,"Journal of Industry, Competition and Trade",19 February 2020,https://link.springer.com/article/10.1007/s10842-019-00331-2,"Can Sub-Saharan Africa Be a Manufacturing Destination? Labor Costs, Price Levels, and the Role of Industrial Policy",June 2020,Alan Gelb,Vijaya Ramachandran,Kyle Navis,Male,Female,,Mix,,
20.0,2.0,"Journal of Industry, Competition and Trade",12 February 2020,https://link.springer.com/article/10.1007/s10842-019-00330-3,"Structural Change, Industrial Upgrading, and Middle-Income Trap",June 2020,Justin Yifu Lin,Yong Wang,,Male,,Unknown,Mix,,
20.0,2.0,"Journal of Industry, Competition and Trade",03 January 2020,https://link.springer.com/article/10.1007/s10842-019-00328-x,Smart Development Banks,June 2020,Eduardo Fernández-Arias,Ricardo Hausmann,Ugo Panizza,Male,Male,Male,Male,"Structural change towards high-productivity activities is the main driver of economic growth. This paper studies how state-owned development financial institutions, development banks for short, can be rethought and redesigned to better help the adoption of productive development policies fostering structural change. The ups and downs of development banks over time illustrate well the need for rethinking their role to make them an effective tool for economic development. In the 30 years that followed the end of World War II, development banks were regarded as the centerpiece of a development strategy. By the 1970s, the public sector owned two-thirds of the assets of the largest banks in developing economies, and more than one-third of the assets of the largest banks in advanced economies (Inter-American Development Bank 2005).Footnote 1 Nevertheless, they were regarded as a mixed blessing. Their leading role back then was associated with key structural changes and also, too many times, with “white elephants,” questionable lending practices, and runaway losses. In the 1980s, critics started to sound louder. The generalized economic crises that followed the oil shocks of the 1973 and 1979, as well as the 1982 sudden stop in capital inflows to developing economies, led to a sea change in the consensus view on the role of the state in economic development as part of the so-called Washington Consensus. The perception that government failures are more costly than market failures brought many economists and policymakers to the conclusion that public intervention, and state-ownership of banks in particular, stunted, rather than promoted, financial and economic development.Footnote 2 This change in the view on the role of the state in the economy, together with the fact that all advanced economies and most emerging and developing countries had by then built large and vibrant private financial sectors, led to several waves of bank privatization which greatly reduced the presence of the state in the financial system (it is estimated that 250 financial institutions were privatized between 1987 and 2003).Footnote 3 However, the subsequent exhaustion and failure of the Washington Consensus as a development strategy led to the concern that the backslash against development banks may have thrown the baby with the bathwater. With the eruption of the global financial crisis in 2008, there has been an expansion of the role of state-owned banks to counteract the contraction of the private system (World Bank 2013, Griffith-Jones and Ocampo 2018), sowing the seeds for their resurgence. The current lack of clarity concerning the role of development banks lends high priority to rethinking their role and redesigning their operation to avoid the vices of the past. The resurgence of the debate around a new generation of development banks to advance productive development policies jibes well with recent research on the critical role of public-private collaboration in this regard (Fernandez-Arias et al. 2016). The reality is that development banks do many things, pursuing many objectives not always with clear purpose. A survey of 90 national development banks in 60 developing and transition economies (de Luna-Martínez and Vicente, 2012) found that 53% of the institutions covered by the survey have a specific mandate. These specific mandates target the following market niches: agriculture (13% of surveyed institutions); small and medium enterprises (12%); international trade (9%); housing (6%); industry and other sectors (6%); infrastructure (4%); and local governments (3%). The remaining 47% of surveyed institutions have a general mandate, such as promoting economic development.Footnote 4 However, while only 12% of surveyed institutions have a specific target about small and medium enterprises (SMEs), 92% responded that they target SMEs. In fact, 60% responded that they target large corporations, 55% responded that they target individuals and households (versus 6% of institutions with a narrow housing finance mandate), and 54% responded that they target other state-owned enterprises. With respect to economic sectors, 86% of the surveyed institutions lend to the service sector, 84% to industry and manufacturing, 83% to agriculture, 74% to construction, 66% to energy, and 65% to infrastructure. These data suggest that even institutions with a narrow mandate seem to target different types of borrowers and economic sectors in an ad hoc fashion, without a clear rationale. Development banks appear ripe for a reform agenda focused on how to fulfill their strategic objective of economic development. Subsidized lending to SMEs may be futile or counterproductive on productivity grounds unless such lending targets young firms that bring innovation and have high-productivity potential (see IDB 2014). There may be good social or political economy reasons, such as cushioning unemployment or fighting inequality, for lending to traditional agriculture or providing housing credit, and some of these interventions may be well-justified by market failures. But providing financial assistance to these activities can, at best, only have limited effect on the major obstacles to structural transformation and the emergence of new highly productive sectors. In this paper, we will focus our attention on the activities of development banks that are designed to have a direct effect on increasing productivity, especially on those that build productive capacities and stimulate positive structural change. Following the United Nations (2009), we define development banks as government-owned financial institutions that have the objective of fostering economic or social development by financing activities with high social returns.Footnote 5 As mentioned, we concentrate on activities with a productivity-enhancing objective. Best practices based on this vision of development finance suggest that development banks need to target well-identified market failures, addressing them through financial support at suitably easy terms while making sure that they do not distort markets by unfairly competing with efficient private banks. While these best practices are well rooted in economic theory, their implementation leads in most cases to mixed and lackluster performance. This paper analyzes what is going wrong. Specifically, it argues that the requirement that development banks only address well-specified market failures implicitly makes the unwarranted assumption that the bank’s management (or the bank’s principal, i.e., the government) has a good understanding of the existing market failures and knows what is the best way to address them through lending (or other appropriate financial instruments such as guarantees).Footnote 6 In fact, policymakers cannot directly observe and ascertain the market failures that development banks are supposed to address and may easily give the wrong marching orders. The successful implementation of the development bank paradigm requires deep knowledge of market failures especially because economic development requires structural transformation and, in turn, structural transformation requires the creation of new activities which may be impeded by non-observable market failures. How does the bank’s decision makers know what activities should be promoted; how do they learn about the obstacles to the creation of new activities? How do policymakers obtain this information? How does the development bank ensure that projects that commercial lenders choose to reject are worth the risk because of a high social return? How do they know how to calibrate better-than-market inducements, enough to bring in all of the repressed high social return activities that the commercial system leaves aside but making sure that excessively cheap terms do not result in giveaways and wasteful projects? In other words, how does one build a mechanism that enables learning about market failures? On the bright side, banks have a unique vantage point for observing not only market failures but also government failures, and in this way uncovering the obstacles to firm creation and firm growth. Development banks are institutions that lend themselves to public-private collaboration. They are special because they can learn by lending to firms, and this learning by lending creates complementarities that are important for a development bank as an instrument of economic development. In this paper, we make the case for a new role of development banks that exploits these complementarities between financial assistance and the design of productive development policies. Specifically, we propose that development banks be deployed as an instrument of economic intelligence and play an active role in the design, as well as implementation, of productive development policies.Footnote 7 Deeper policy involvement would make development banks more accountable and facilitate the evaluation of their performance on substantive grounds, as opposed to bureaucratic lending targets. This new approach also has implications for the organization of development banks concerning the trade-off between first-tier and second-tier schemes. Since first-tier banks are in direct contact with clients, they may be better positioned to perform this new role compared with second-tier banks. In what follows, the paper reviews the traditional modus operandi of development banks and elaborates on the new role proposed, discussing some key issues concerning how to set up development banks to be successful and an agenda for institutional reforms of development banks. The analysis is buttressed with the experience of a number of development banks captured in a survey conducted among eight institutions (seven Latin American institutions and KfW in Germany).Footnote 8",12
20.0,2.0,"Journal of Industry, Competition and Trade",26 December 2019,https://link.springer.com/article/10.1007/s10842-019-00329-w,Challenge-Driven Innovation Policy: Towards a New Policy Toolkit,June 2020,Mariana Mazzucato,Rainer Kattel,Josh Ryan-Collins,Female,Male,Male,Mix,,
20.0,3.0,"Journal of Industry, Competition and Trade",21 November 2019,https://link.springer.com/article/10.1007/s10842-019-00317-0,Subsidy Entrepreneurs: an Inquiry into Firms Seeking Public Grants,September 2020,Anders Gustafsson,Patrik Gustavsson Tingvall,Daniel Halvarsson,Male,Male,Male,Male,"The importance of innovation as a driver of economic growth has made innovation policy one of the most discussed economic and political topics (Becker 2015). In recent years, it has become common for governments to provide various selective policy instruments directed to firms with the intention to stimulate innovation, R&D, and growth. One example is direct cash transfers in the form of grants. These grants are often, but not always, directed to small- and medium-sized enterprises (SMEs) due to their lack of credit and high-growth potential. Hence, a shortage of credits along with the positive spillover effects that arise from growth and innovation suggests that governments have a role to play in fostering innovation and firm growth. With a multitude of governmental subsidies available to firms, this type of grants nowadays represents an integral component of the financial ladder for many SMEs. Given the extent of direct support programs, it has become increasingly important to analyze and understand the efficiency, and the type of incentives they create for firms. If the objectives of public agents who seek appropriate firms and projects to fund are at odds with the incentives faced by firms, such mismatch can lead to less qualified firms seeking and receiving the grants. Incentive structures are central to our understanding of economic policy, yet little attention has been directed towards the selection process that underlies the decision by entrepreneurs to allocate resources for the purpose of seeking grants. According to Aerts et al. (2006), the decision to seek and participate in publicly supported grant programs is typically modeled ad hoc to conform with the often limited data that is available.Footnote 1 To the extent selection is considered, the selection process has often been subordinated to the effects of the grant. The purpose of this paper is to analyze the selection process of firms that apply for, and eventually receive, one or many government grants. To the best of our knowledge, this is the first paper that distinguishes single- from multiple-supported firms. The analysis is based on comprehensive data over the public grants that were distributed to firms by the three largest distributing agencies in Sweden over the period 1997 to 2013. Data on grants contains information on the type of grant, amount received, and the time at which it was handed out. What we do not have information on, however, is which firms that applied for a grant but were denied it. In total, there were more than fifteen thousand firms that receives at least one grant out of which about 20 percent received more than one grant. To theorize about selection, we present a simple and stylized model over the decision by entrepreneurs to allocate resources to seeking grants. It takes the form of a contest model (c.f. Tullock 1980; Stein 2002), where entrepreneurs face the decision of allocating their effort between grant seeking and market production. The source of heterogeneity is given by the entrepreneurs’ innate productivity that is used to leverage market production. The idea is that an entrepreneur, by seeking the grant, forgoes the profit earned in production for the expected profit from winning the contest, and hence receiving the grant. In equilibrium, entrepreneurs with sufficiently high productivity abstain from grant seeking altogether and use all their effort to production. For contesting entrepreneurs, on the other hand, the amount of effort expended to acquire the grant is inversely related to the level of productivity. For the lowest productive entrepreneurs, most if not all effort is allocated to seeking the grant. By implication, these kinds of subsidy entrepreneurs are also more likely to receive the grant. And without additional assumptions about the effect of the grant, low-productivity entrepreneurs are likewise more probable to receive additional grants. To examine the theoretical predictions of the contest model, we focus the empirical analysis on how single- and multiple-supported firms deviate from non-supported firms with respect to labor productivity, but also other firm-level characteristics, i.a. the firm’s age and size, wages, and skill intensity. Importantly, this analysis is made possible by the merging of register-based data on firms from Statistics Sweden (SCB) with the grant data that has been made available to us from The Swedish Agency for Growth Policy Analysis (Growth Analysis). Using Swedish data, it is our contention that Sweden constitutes a particularly relevant case for studying the economic implications of selective industrial policy and potential strategic behavior for the following reasons. Sweden is regarded as one of the most innovative countries in the world, but it is home to a complex system of public innovation programs with many small- and medium-sized agencies funding similar projects (OECD 2016). The existence of overlapping agencies and programs may enhance the formation of firms specializing in seeking grants. Furthermore, Sweden is a country with low, but not non-existent, levels of corruption, which facilitates in isolating the firm effect from other political incentives that might surround grants (Dahlberg and Johansson 2002; Svaleryd and Vlachos 2009). Recent research on grants has examined other countries, e.g., China, where corruption is more widespread and thus confounds the firm-level analysis (Du and Mickiewicz 2016; Cheng et al. 2019). To estimate the model, we apply a set of logistic and count data models to capture various aspects of the selection process that characterize single and multiple-supported firms. Specifically, we estimate three sets of models: the first is a logistic model of the probability of receiving a grant. The results suggest that subsidized firms have, on average, lower productivity and higher skill intensity than non-supported firms. These characteristics are further strengthened when distinguishing single-supported firms from multiple-supported firms, in line with the model of grant-seeking entrepreneurs. Similar results are found when we estimate the difference between non-, single-, and multiple-supported firms with a ordinal logit model. To complement these models, we also consider a count model over the number of received grants (1st, 2nd, and 3rd, ...) and obtain similar results while also finding that multiple-subsidized firms have higher wages than other firms. While the evidence is not conclusive, the results support the notion that a comprehensive system of available grants opens up for the possibility of low-productivity firms to specialize in grant seeking rather than market production as a viable strategy for profit maximization.",25
20.0,3.0,"Journal of Industry, Competition and Trade",11 December 2019,https://link.springer.com/article/10.1007/s10842-019-00321-4,Subsidy Incidence in the Presence of Bertrand Suppliers of Complementary Inputs: A U.S. Agricultural Example,September 2020,Abby Kelly,Kalyn T. Coatney,Keith H. Coble,Female,Female,Male,Mix,,
20.0,3.0,"Journal of Industry, Competition and Trade",29 April 2019,https://link.springer.com/article/10.1007/s10842-019-00305-4,Competition and Profitability in the Chinese Banking Industry: New Evidence from Different Ownership Types,September 2020,Yong Tan,,,,Unknown,Unknown,Mix,,
20.0,3.0,"Journal of Industry, Competition and Trade",07 August 2019,https://link.springer.com/article/10.1007/s10842-019-00313-4,The Determinants of Firm’s Innovation in Africa,September 2020,Misraku Molla Ayalew,Zhang Xianzhi,Demis Hailegebreal Hailu,Unknown,,Male,Mix,,
20.0,3.0,"Journal of Industry, Competition and Trade",21 November 2019,https://link.springer.com/article/10.1007/s10842-019-00319-y,A Stochastic Frontier Analysis Approach for Estimating Market Power in the Major US Meat Export Markets,September 2020,Dimitrios Panagiotou,Athanassios Stavrakoudis,,Male,Male,Unknown,Male,"In January of 2018, the US government announced a 25% tariff on steel imports and a 10% tariff on aluminum imports from China. Later that year, pork and beef producers in the USA were hit with a retaliatory 25% tariff on their China bound exports. More specifically, the tariff on pork exports was implemented in April of 2018 and the tariff on beef exports was implemented in June of 2018. In addition, Mexico, Canada, and the European Union have threatened to add their own tariffs on US meat products. China, Mexico, and Canada are among the top destinations for the US meat exports. The aforementioned countries, along with Japan and South Korea, account for more than 80% of the US meat exports, in terms of volume and value (U.S. Meat Export Federation 2017). Given the fact that the USA is among the world’s largest pork and beef exporters, the competitive conditions in the major US meat export markets are of significant importance. USA is the world’s largest pork exporter with a global market share approaching 30% (United States Department of Agriculture – Economic Research Service 2017). One in every 3.4 pounds of pork traded in the world will originate from the USA (U.S. Meat Export Federation 2017). Pork exports account for more than 20% of domestic US pork production. Concurrently, USA is the world’s fourth largest beef exporter with a global market share close to 12% (ERS-USDA, 2017). Beef exports represent more than 10% of domestic US beef production. The aforementioned facts constitute the USA as one of the most important players in the global meat market. In the last 30 years, US pork exports have grown from 86 million pounds carcass weight equivalent in 1986 to 4.858 billion pounds in 2014, an increase of 5649%. During the same time period, the value of pork and pork byproduct exports has increased from $1.97 per hog slaughtered to $62.45 per head slaughtered. As a consequence, the total income of all US pork producers has been improved by $9 billion over the last 30 years due to the increase in net exports. For the year 2016, USA exported 2.31 billion metric tones (MT = 2204.6 lbs) of pork and pork variety meat, exhibiting an increase of 8% in volume (2.31 million mt) and 7% in value ($5.94 billion) compared with the previous year (U.S. Meat Export Federation 2017). The top markets for the US pork exports in terms of value and volume are Japan (destination for about one-third of US exports), Mexico, Canada, South Korea, and China. These markets account for almost 90% of the US pork exports. Combined, the USA, the European Union, Canada, and Brazil account for nearly 92% of world pork exports. US beef shipments to foreign countries have grown more than 80% in the last 30 years, while domestic beef consumption has increased only by 14%. According to Panagiotou (2008), a 1% increase in beef exports leads to a 1.6% increase in fed cattle price. With beef exports at 12% and at a base cattle price of $85/cwt, this translates into about a $20/cwt added value. For the year 2016, USA exported 1.18 billion MT of beef and beef variety meat. Annual total beef shipments were valued at $6.34 billion, up 0.6% from 2015. From January through July of 2017, exports have increased 11% in volume (711,364 mt) and 15% in value ($3.97 billion), compared with the first 7 months of 2016 (United States Department of Agriculture – Foreign Agricultural Service 2017). On a volume and value basis, the top export markets for US beef are Japan, Canada, Mexico, and Hong Kong, accounting for more than 80% of the US beef exports (U.S. Meat Export Federation 2017). Despite the importance of US beef and pork exports, domestically and globally, the literature has not paid enough attention on the competitive conditions in each one of the major US beef and pork export markets. There are studies in the relevant literature (Arnade et al. 1998; Miljkovic et al. 2003) that measure the degree of market power in the US meat exports but at aggregate level, both for the meat product (beef and pork together) as well as for the destination of exports (all export markets together). The only exception are US beef and pork exports to Japan. Japan has been the most important export market for both US beef and pork products. The 1995–1998 depreciation in the Japanese yen by 39% reduced US slaughter steer and hog prices by $1.29 per cwt and $0.99 per cwt, respectively, while the 1994–1998 reduction in tariffs by 14% increased slaughter steer and hog prices by $0.49 per cwt and $0.33 per cwt, respectively (Miljkovic et al. 2002). Although having a significant market share in the Japanese beef market, USA does not seem to exercise significant market power (Reed and Saghaian 2004; Reed and Iswariyardi 2001). On the other hand, USA appears to have market power in the Japanese pork market (Felt et al. 2011). US NAFTA partners are also important markets for the US beef and pork exports (USDA, 2017). Empirical findings indicate that increases in meat expenditures in Canada and Mexico are expected to significantly raise the demand for US meats affecting this way exporters’ welfare (Henneberry and Mutondo 2009). One of the studies on pork trade calculates the effect of imports and exports on the price of hogs (Plain 2014). The author used a demand elasticity of − 0.3, and assumed a 1% increase (decrease) in net exports. The result would be 3.33% rise (fall) in hog prices. Apart from the significant global market share of the US beef and pork exports, US meat exporters have an additional advantage due to the superior quality of their products. The combination of genetic improvement, the additional days of feeding, and the grain fed US animals as opposed to grass fed livestock from most of the other major exporting countries are some of the factors that contribute to the higher quality of the US meat products. Thus, both US beef and pork have quality advantages that can set the demand curve faced by US meat exporters even more inelastic. The latter, along with the fact that USA is one of the most dominant players in meat exports worldwide, might lead to market power exertion by the US exporters of beef and pork.Footnote 1 Against this background, the objective of this study is to estimate the degree of market power in each one of the major US meat export markets with the employment of the recently developed stochastic frontier (SF) estimation technique by Khumbhakar, Baardsen and Lien (2012).Footnote 2 In their original work, Kumbhakar et al. (2012) draw on the stochastic frontier methodology from the efficiency literature and propose a new method of market power estimation. The SF method treats mark-ups as deviations from an optimal marginal cost pricing frontier. This methodology has been applied to the US food industry by Lopez et al. (2018), to the US cattle industry by Panagiotou and Stavrakoudis (2017), and to the Brazilian milk market by Scalco et al. (2017). Furthermore, there are two very recent studies that have utilized the stochastic frontier estimator of market power in the US meat packing industry. The first study, under the title “A stochastic frontier estimator of the aggregate degree of market power exerted by the U.S. meat packing industry” by Panagiotou and Stavrakoudis (2018), employed a stochastic frontier estimator in order to measure the market power exerted by the US meat packers (beef and pork meat in aggregate). The period of estimation was 1970–2011. The estimated degree of market power was 3.74%. The second study, under the title “Market Power Effects of the Livestock Mandatory Reporting Act in the U.S. Meat Industry: A Stochastic Frontier Approach under Uncertainty” by Panagiotou (2019), estimated the degree of market power in the US beef and pork packing industries, for the period before (1970–2001), and after (2002–2010) the implementation of the Livestock Mandatory Reporting Act. The empirical findings reveal that the average degree of market power exerted in the US beef packing was 5.268% for the period 1970–2001 and 3.829% for the time period 2002–2010. For the same time periods, the market power exerted by the US pork packing industry was 4.317% and 3.530%, respectively. One of the big advantages of the SF estimation approach is that it bypasses the estimation of demand and conduct needed in new empirical industrial organization (NEIO) models in order to measure the gap between price and marginal cost of production (Lopez et al. 2018). In the present study, where data for estimating demand for US meat exports by foreign countries would be hard to collect, the SF estimation technique is the most indicative in order to obtain market power estimates in each one of the meat export markets under examination. The present study contributes to the literature from at least two viewpoints. First, it measures market power in each one of the most significant US beef and pork export markets. Despite the fact that the USA is a major player in the global meat market, there are no prior studies that have attempted to do so. Secondly, for the estimation of market power in an export market, it employs the recently developed SF methodology which enables the researcher to estimate markups without having to estimate demand and conjectural variations elasticity, as is the case in the majority of the empirical studies in the relevant literature (NEIO). Furthermore, in contrast to traditional stochastic frontier analysis, the present study allows for the estimation of export market- and time-specific Lerner indices. To the best of our knowledge, there has been no published work on the estimation of market power on all the major US meat export markets.Footnote 3 Section 2 presents the stochastic frontier estimator of the degree of market power. Section 3 presents the data and the empirical results and Section 4 the results and discussion. Section 5 offers conclusions.",3
20.0,3.0,"Journal of Industry, Competition and Trade",05 November 2019,https://link.springer.com/article/10.1007/s10842-019-00320-5,Effects of Integration with a Consumer-Friendly Firm in a Cournot Duopoly,September 2020,Mariel Leal,Arturo García,Sang-Ho Lee,Female,Male,Male,Mix,,
20.0,3.0,"Journal of Industry, Competition and Trade",07 August 2019,https://link.springer.com/article/10.1007/s10842-019-00315-2,"Market Structure, Competition, and Optimal Privatization: a Linear Supply Function Approach",September 2020,Keita Yamane,,,Male,Unknown,Unknown,Male,"Does a privatization policy improve social welfare? This is a fundamental question when considering privatization programs, and it is a controversial subject among policymakers and watchers.Footnote 1 In the field of economics, theorists have often discussed this problem using mixed oligopoly market models in which public firms maximize the social welfare, whereas private firms maximize their enterprise profits. De Fraja and Delbono (1989), who conduct one of the main studies to consider the problem, show that an increase in the number of private firms, representing intensification of competition, causes the optimal degree of privatization (ODP) to shift to perfect privatization.Footnote 2 The authors justify privatizing public firms. Vickers and Yarrow (1988, p.52)Footnote 3 consider which objective the managers of a public firm faced by a number of profit-maximizing competitors should be tasked with. The authors find that if the number of firms is large enough, it may be better for the public firm to have profit maximization, rather than welfare maximization, as its objective. However, some cases show that privatization programs have not been successful.Footnote 4 Gradually, theorists have become skeptical about the incumbent result. Matsumura and Okamura (2015; hereafter, MO) object to utilizing the classical method to confirm whether privatization improves social welfare. The authors claim that the traditional definition of intensification of competition is “increasing the number of firms,” which is misleading. To be accurate, MO note that, when the number of firms (n) expands, the industry supply curve shifts out if each marginal cost is increasing, and hence the industry structure changes so that the “n-increasing approach” cannot evaluate the intensification of competition correctly. MO claim that n should be fixed within the analysis. MO alternatively adopt the payoff interdependence approach, which redefines intensifying competition as the transition from the quantity competition to price competition between firms. We sum their work within a duopoly as follows: MO assume that both a public firm and a private firm compete à la De Fraja and Delbono (1989), but their profit functions are described as mi = πi − απj, i,j = 0,1. Here, parameter α ∈ [0,1] implies the intensification of competition, and MO investigate how ODP is affected by α. Interestingly, the authors show that, contrary to the result from traditional analyses, ODP shifts to perfect nationalization. Thus, MO show that privatization can be detrimental to social welfare. This study adopts the linear supply function (LSF) approach, which is another method to evaluate the intensification of competition in an output market.Footnote 5 LSF competition is described as follows: Each firm has a supply function qi = si + tp; namely, production is described as a linear function of price. Each firm determines the intercept si. The standard Cournot model describes the case of t = 0, and this is proved in Menezes and Quiggin (2012). This applies to the case of increasing marginal costs. In sum, the critical difference between the Cournot and the LSF model appears in the interval of \(t\in (0,\infty )\). Delbono and Lambertini (2016) investigate the relationships among the Cournot, Bertrand, and LSF equilibria in a private oligopoly. In addition, Yamane (2018) studies linear supply function competition in a mixed duopoly to investigate product differentiation but posits the degree of privatization given. This study reproduces the above-mentioned analyses following MO to confirm the robustness of their main results. Additionally, this study reexamines the traditional “n-increasing approach,” although we recognize the validity of MO’s discussion. Our main results are as follows. First, if we fix n following MO, we find that fierce competition brings ODP close to perfect nationalization. Next, if we adopt the traditional approach, we find that fierce competition brings ODP close to perfect privatization; thus, we reach the same results as MO. Although privatization of public firms has been promoted globally, our study and other recent studies imply the need for sober and deliberate policymaking. The rest of the paper is organized as follows. Section 2 presents the model. Sections 3 and 4 analyze each stage of the game. Section 5 concludes the study. In the Appendix, the case of the different slope of linear supply functions is demonstrated.",
20.0,4.0,"Journal of Industry, Competition and Trade",15 July 2020,https://link.springer.com/article/10.1007/s10842-020-00344-2,Coordinated Effects of Corporate Social Responsibility,December 2020,Mariana Cunha,Filipa Mota,,Female,Female,Unknown,Female,"Over the past decades, firms have been voluntarily adopting social and environmental concerns in their business operations and in their interactions with stakeholders (European Commission 2011). Corporate social responsibility (henceforth CSR) has become a major concern for a large number of firms in several industries, working as a source of market competitiveness. According to the KPMG Survey of Corporate Responsibility Reporting (2017), more than 75% of the world’s 250 largest firms now include some “non-financial” information in their annual reports, since they believe CSR data is relevant to their investors, and this trend continues to grow (KPMG 2017). In the 2011 Communication on Corporate Social Responsibility, the European Commission defined CSR as “the responsibility of enterprises toward their impact on society” (EC 2011, p. 6). Scholars have been devoting their attention to this topic as well (e.g., Baron (2001), Goering (2007), Bénabou and Tirole (2010), Lambertini and Tampieri (2010), Kopel and Brand (2012), Fanti and Buccella (2017a), Fanti and Buccella (2017b), Fanti and Buccella (2017c), and Fanti and Buccella (2018), among others). Pressures to engage in CSR arise from different stakeholders (customers, employees, governments, and society as a whole), as noted by Baron (2001) and McWilliams and Siegel (2001). Baron (2001) explains that even if firms are completely selfish, they may strategically engage in social actions to avoid bad propaganda or, putting it differently, to be entitled to some kind of endorsement. Indeed, firms may be willing to mix corporate do-gooding with profit maximization, so as to respond to such demands. Following a moral or altruistic behavior instead, Bénabou and Tirole (2010) explain that firms are willing to sacrifice profits in the social interest. Nevertheless, these authors add to their reasoning that firms often believe that by voluntarily taking actions in the name of CSR, they may be rewarded in the marketplace by increasing demand and, therefore, profits; or they may achieve a positive image among regulators and the public opinion. The latter may be strategically used to avoid strict supervision in the future (Garriga and Melé 2004; Bénabou and Tirole 2010).Footnote 1 According to some authors, CSR may also be used as a mechanism to deter entry, since promoting investments on the behalf of environmental or social causes would increase rivals’ costs (Baron 2001; Garriga and Melé 2004; Bénabou and Tirole 2010; Fanti and Buccella 2017b). Additionally, firms may engage in CSR because it may serve as a commitment device for their strategic decisions in oligopolistic markets (Planer-Friedrich and Sahm 2019) and may help promote a coordinated behavior in the market by means of decreasing market competition (Tzavara 2008; Lambertini and Tampieri 2012). CSR has been covered in the literature in two major perspectives. One perspective, related to the demand side, considers CSR as a form of vertical differentiation, which is valued by consumers (e.g., Bagnoli and Watts (2003), Alves and Santos-Pinto (2008), Baron (2009), García-Gallego and Georgantzís (2009), Manasakis et al. (2013), and Manasakis et al. (2014)). A second perspective, related to the supply side, relies on the assumption that CSR is incorporated in firms’ objective function along with their individual profit (e.g., Goering (2007), Goering (2012), Goering (2014), Lambertini and Tampieri (2012), Lambertini and Tampieri (2015), Lambertini et al. (2016), Fanti and Buccella (2017a), Fanti and Buccella (2017b), and Fanti and Buccella (2017c), among others). All of these contributions consider that CSR is exogenously given.Footnote 2 In this paper, we follow the second perspective. In our model, the level of CSR is defined as a positive weight on consumer surplus in firm’s objective function. Our aim is to study how this type of objective function affects firms’ ability to coordinate their decisions. Additionally, we are also concerned about assessing whether collusion with CSR firms may be welfare-enhancing to consumers following existing contributions in the literature. It is generally considered in the literature that collusion is detrimental to consumers (Farrell and Shapiro 1990). This results from the standard conclusion that firms restrict output while colluding. Since we model CSR by attaching a positive component to consumer surplus in firms’ objective functions, we expect CSR to increase output and, therefore, consumer surplus. Given this, we set out to investigate whether the result of output restriction under collusion holds in the presence of socially responsible firms, which will determine if collusion is harmful to consumers or not.Footnote 3 To the best of our knowledge, there are only two papers that study the coordinated effects of CSR, those of Tzavara (2008) and Lambertini and Tampieri (2012). Tzavara (2008) studies whether CSR promotes a collusive behavior among firms, considering a duopoly with homogeneous products and quantity competition. In her model, CSR is incorporated in the demand function, being price-augmenting for the consumers and entailing a cost for the firms. Lambertini and Tampieri (2012) consider a model where firms have CSR, produce homogeneous goods, and compete in quantities, as in Tzavara (2008). In their model, CSR is also incorporated as a weight that firms assign to consumer surplus in their objective functions. Both contributions find that CSR makes collusion harder to sustain. Our paper contributes to this literature being closely related to Lambertini and Tampieri (2012)’s paper as regards the modelling of CSR. However, our setting is more general as we consider product differentiation à la Singh and Vives (1984), which captures the case of homogeneous goods as a particular one. Additionally, as in Lambertini and Tampieri (2012), firms are cost-symmetric; however, in our setting, firms may have asymmetric levels of CSR, which are exogenously given. Our contribution also relates to the literature that studies collusion with product differentiation. Several papers in the literature have studied the effects of product differentiation on firms’ ability to collude, for instance Deneckere (1983), Deneckere (1984), and Ross (1992) and Rothschild (1992). These contributions have focused, mainly, on the nature of the competitive market, and on how the type of competition makes collusion easier or more difficult to sustain. The effect of horizontal differentiation in collusion sustainability is ambiguous (Ivaldi et al. 2003). On the one side, it reduces the short-term gains from undercutting rivals, since it makes it more difficult to attract customers who value a specific variety of the good. On the other side, it limits the severity of punishments. Deneckere (1983) and Deneckere (1984) find that the stability of collusion for substitute goods is monotonically decreasing with product homogeneity. Ross (1992, p. 7) finds a negative monotonic relationship between homogeneity and cartel stability; i.e., the more homogeneous the products are, the less likely the cartel is to be stable. In addition, Ross (1992) shows that cartels of very homogeneous products are more stable than cartels of heterogeneous products. We obtain the latter result when both firms have the same level of corporate social responsibility. The key findings of the paper are as follows. If firms have the same level of CSR (symmetric case), attaching a positive weight to consumer surplus hinders collusion. With symmetric CSR, firms’ payoffs increase under competition, collusion, and deviation. Although CSR increases the difference between the collusive and Cournot payoffs, it also increases the difference between deviation and collusive payoffs. Since the second difference is higher than the first one, firms’ incentives to deviate from the agreement are higher, making collusion less sustainable. This result is close to the ones obtained by Lambertini and Tampieri (2012) and Tzavara (2008). Nevertheless, product differentiation plays a crucial role. When firms are socially responsible, collusion sustainability increases in the degree of substitutability if the level of CSR is sufficiently high. Indeed, for a sufficiently high level of CSR, our findings confirm Rothschild (1992)’s: a high degree of substitutability fosters collusion in quantities, whereas a high degree of complementarity makes it more difficult to sustain.Footnote 4 We obtain the latter result for any level of CSR when both firms have the same level of CSR. If firms are asymmetric regarding the levels of CSR (asymmetric case), conclusions about collusion sustainability may depend on the level of product differentiation, on the level of CSR, and on to which firm belongs the binding critical discount factor (above which collusion is possible). When products are complements, collusion is easier to sustain the higher is the degree of differentiation. This result contrasts the one obtained in the symmetric case. Moreover, the higher the level of CSR, the more difficult it is to sustain collusion among the two firms. As products become more substitutes, conclusions regarding collusion sustainability are not straightforward. In fact, collusion is more sustainable for a sufficiently low level of CSR or some particular combinations of the level of CSR and the degree of product differentiation. Interestingly, under collusion, welfare may actually improve when compared with the competitive scenario when products are sufficiently differentiated or when the level of social responsibility is sufficiently high. Therefore, we believe our paper also contributes to the discussion of whether some cartel agreements may be exempted from cartel law if they promote sustainable gains as a public interest purpose.Footnote 5 Nevertheless, we strongly advise competition authorities to be careful when investigating the strategies followed by these types of firms. The remainder of the paper is organized as follows. Sections 2 and 3 present the baseline assumptions of the model. In Section 4, we analyze the results of collusion 2 with CSR in both cases (symmetric and asymmetric CSR levels) and in Section 5 we discuss their implications in terms of consumers’ welfare. Finally, Section 6 offers some concluding comments with a brief discussion of the main results.",4
20.0,4.0,"Journal of Industry, Competition and Trade",05 May 2020,https://link.springer.com/article/10.1007/s10842-020-00340-6,An Analysis of Fuel Smuggling in the Middle East as a Single Multinational Market,December 2020,Ali Dadpay,,,Male,Unknown,Unknown,Male,"The present study utilizes a multinational mixed oligopoly model to analyze the trends of fuel smuggling in the Middle East. It considers the market for the smuggled fuel as a single regional market shaped by the policies of different governments. It contributes to our understanding of strategic interactions between the government and their impact on a market that they do not recognize. Despite the significance of fuel and oil smuggling in the Middle East, no one has studied in a trade context. The present study demonstrates that the asymmetric cost structure and the different approaches to pricing can decide the direction and the volume of fuel smuggling in the region. It adds to the existing literature by considering a model of three countries with asymmetric cost structure, where the consumers’ surplus is divided between three countries. It demonstrates that although governments might not interact directly with each other in this market, their pricing policies decide the volume of smuggling activities. We find out that the best way to eliminate fuel smuggling in the region is strategic pricing based on interactions within a single multinational market. Today, fuel smuggling has become a major source of income for terrorist organizations. Financial Action Task Force (FATF) report (FATF 2015) on financing the Islamic State of Iraq and Levant (ISIL) highlights the need to understand the dynamism behind oil and fuel trafficking in the region. It reports that oil smuggling in the region has been steadily rising since 2012. Turkish authorities seized as much as 20 million liters of oil and oil products in seven Turkish provinces bordering Iraq and Syria in 2014 alone. In total, Turkish law enforcement agencies confiscated 79,238,759 l of petroleum products and oil in 2014 with an estimated value of hundreds of million dollars. In countries such as Iran and Iraq with vast resources of crude oil, governments subsidize fuel and other oil-related products heavily to ensure that their constituents have access to cheap fuel products, to which the public feels entitled. However, governments differ in their pricing and subsidization policies. The present article demonstrates how this difference creates the incentives for smuggling and shapes the fuel smuggling in the region. One cannot estimate the total volume of smuggled petroleum and other products. However, the seized cargos of fuel are large. In November 2006, New York Times reported that Iraqi officials estimated that smuggling networks re-export 10 to 30% of $4 billion to $5 billion of the imported fuel to the neighboring countries. Wahab (2006) offers a summary of fuel smuggling schemes in the case of Iraq. He estimates that a smuggler bringing fuel in a 9000-gal truck from a neighboring country could make as much as $7450 in net profit. Iraqi officials estimate that fuel smuggling cost Iraq economy $2.5 to $4 billion in 2005. According to Reuters, in August 2007, Iranian patrol boats seized a foreign-registered ship with a cargo of 500,000 l of fuel. In the same month, Iranian Police discovered that criminal gangs in Khuzestan, a province in southwest rich with oilfields, had constructed a 2.5-mile-long underground pipeline to smuggle petroleum through the port of Mahshahr on the Persian Gulf coast. Smuggled fuel had become a major source of energy in the region. The governments’ efforts and agreements to stall fuel smuggling have been futile.Footnote 1 Since its introduction by Merril and Schneider (1966) mixed oligopoly has emerged as an analytical tool to study policymaking in international trade and multinational markets. A mixed oligopoly framework includes welfare-maximizing public firms and private profit-maximizing businesses. Thus, it offers a platform to study interactions between governments and private businesses. Recent years have witnessed an increase in the number of authors who utilize this analysis to study the interactions between governments and profit-maximizing private firms both in domestic markets (Harris and Wiens 1980, Sertel 1988, Cremer et al. 1989, 1991, DeFraja and Delbono 1989, 1990; Fershtman 1990, Nilssen and Sorgard 2002, Fjell and Pal 1996) and multinational markets (Pal and White 1998, Fjell and Heywood 2002, Pal and White 2003, Dadpay and Heywood 2006, Dadpay 2010). Multinational mixed oligopoly analysis studies interactions between public and private firms of different nationalities. These studies either use a single multinational market set up (Dadpay and Heywood 2006) where consumers from different countries share consumers’ surplus or an intra-industry trade approach (Pal and White 2003) where local markets do not form a single market and consumers demand functions could differ. The existing literature has established the role of policies such as privatization and subsidization as trade policies. Dadpay and Heywood (2006), Matsumura et al. (2009), Ino and Matsumura (2010), and Wang and Chen (2011) demonstrate that governments’ policies have trade implementations in integrated regional markets. Dapday (2014), Haruna and Goel (2015), Lee and Tomaru (2017), Gil-Moltó et al. (2019), and Xing et al. (2019) study the role of subsidization and its impact on privatization, research, and development (R&D) activities, and environmental policy. This paper takes those studies further to show that subsidization can create a secondary market by providing incentives for activities such as fuel smuggling. The rest of the article is organized to discuss the model and then presents the analysis and conclusion. The second section sets up the model and presents the equilibrium values. The third section offers the properties of equilibrium values and the comparison of the results. The fourth section summarizes the policy implications, such as pricing policies, subsidization, and combating smuggling. The fifth summarizes the findings and highlights the conclusion.",2
20.0,4.0,"Journal of Industry, Competition and Trade",05 February 2020,https://link.springer.com/article/10.1007/s10842-019-00318-z,Determinants of Market Power in the Peruvian Regulated Microfinance Sector,December 2020,Giovanna Aguilar,Jhonatan Portilla,,Female,Unknown,Unknown,Female,"Microfinance’s remarkable expansion over the last three decades has demonstrated its ability to offer financial services (mainly credits) to segments of the population that find themselves in situations of poverty and vulnerability, thus allowing that these individuals access the formal financial system (Reed 2015). This expansion has been characterized by the greater market orientation of and greater competition between microfinance institutions (MFIs) (Assefa et al. 2013; Hermes and Hudon 2018; Hermes and Lensink 2007; Mader and Morvant-Roux 2019; Sabin 2015). In this context, increasing academic interest in studying competition in the microfinance industry has resulted in the development of a broad range of literature on the subject. Via different indicators, Kar (2016) and Kar and Swain (2018a) evaluate the level of competition within microfinance markets in various countries. The papers of Assefa et al. (2013), Kar and Swain (2014, 2018b), and Olivares-Polanco (2005) analyze competition’s effect on MFIs’ social and financial performance. McIntosh et al. (2005) as well as McIntosh and Wydick (2005) demonstrate how increased competition generates clients’ over-indebtedness and reduces the chances that MFIs will cross-subsidize between more and less profitable clients. In addition, Baquero et al. (2018) have studied competition’s effect on interest rates. Despite the extensive literature on competition in the microfinance market, less interest has been observed in studying the market power’s determinants in the microfinance sector. Market power’s existence in an industry restricts competition and causes welfare losses as a result of the allocative (price increase) and productive inefficiency (increase in costs) it produces as well as the disincentives for investment and innovation it generates (Motta 2004). These consequences can be very damaging in the microfinance sector because they reduce poverty-stricken clients’ access to financing via higher interest rates and products that are not suited to their needs. One way to assess a market’s competition level is by analyzing the market power exercised by the firms, as greater market power is a sign of less competition. Assefa et al. (2013) analyze competition’s effect on MFIs’ performance on a global scale, estimating their market power. Halouani and Boujelbène (2015) use market power estimates to assess competition’s effect on African MFIs’ social efficiency and profitability. Mayorca and Aguilar (2016) offer an analysis of competition’s effect on the portfolio quality of Peruvian MFIs using market power as a competition measure, while Mia (2018) analyzes competition in Bangladesh’s microfinance via market power estimation. However, none of these studies assess the market power determinants in the microfinance industry. Some papers analyze the financial margin determinants in microfinance (Cuéllar-Fernández et al. 2016; Fuentes-Dávila 2016), which is a concept related to market power but different from it.Footnote 1 Therefore, there exists the need that new studies fill the knowledge gap regarding the factors that explain market power in the microfinance sector. The identification of these factors is very useful for competition policymakers in that it provides them with information on the relevant variables that can be managed to reduce or control market power. In this way, restrictions on competition are prevented, alongside the consequent reduction in microcredit prices and the increased investment and innovation within the industry. Koetter et al. (2012) demonstrate that when firms are not fully efficient, market power’s conventional measure—that is, the Lerner index—is biased and does not adequately measure firms’ market power. In view of this, the authors propose an alternative market power measure known as the Lerner index adjusted for efficiency, which—considering the inefficiency with which firms operate—provides a more accurate measure of their market power. Previous literature in the microfinance sector reveal that MFIs are not completely efficient (Guitiérrez-Nieto et al. 2007; Hermes et al. 2011). Therefore, estimating their market power requires that their levels of inefficiency be considered, while having a more adequate measure of MFIs’ market power makes the analysis of their determinants more robust. The objective of this study is to analyze the evolution and determinants of market power in Peru’s regulated microfinance sector,Footnote 2 for which we estimate a conventional Lerner index (LICON) and an efficiency-adjusted Lerner index (LIADJ) as measurements of market power using information from a panel of MFIs from the period of January 2003 to June 2016. The analysis of market power and its determinants in the Peruvian regulated microfinance sector is relevant for two reasons. Firstly, this sector’s development and maturity, which were achieved after more than 30 years of operation, have made it one of the most emblematic in the world and thus the Global Microscope named Peru the most favorable environment for the development of microfinance and financial inclusion for eight consecutive years (2008–2015) (Economist Intelligence Unit 2016). As a result, the Peruvian microfinance sector is included in the sample of microfinance markets of impressive development and is analyzed in relevant studies on competition in microfinance (Baquero et al. 2018; Kar 2016; Kar and Swain 2018a, b; Mersland and Strøm 2012). Secondly, the consolidation of Peru’s regulated microfinance sector—driven by the macroeconomic stability of nearly the entire 2000s and by changes in the regulatory framework (introduced to promote competition in the sector)—has revealed an interesting dynamic characterized via mergers, takeovers, and changes in business structure that have raised the level of the microcredit market’s concentration. These features render the Peruvian microfinance market a natural laboratory for assessing the relationship between changes in microfinance entities’ market power and market structure. Our study makes two contributions to the literature. Firstly, it offers stylized facts about market power and its determinants, specifically in the context of a mature and highly expanding microfinance market. Secondly, it applies a novel method for measuring market power in the microfinance sector that considers MFIs’ efficiency. We find evidence that indicates that the LIADJ is significantly greater than the LICON, which confirms that failing to account for the inefficiency with which the MFIs operate leads to an underestimation of their market power. Both indices follow a decreasing trend between 2003 and 2014, which indicates that the market power in the Peruvian regulated microfinance sector significantly decreased for more than a decade. However, the dynamics the market structure followed as well as the intensified competition led to the reversal downtrend in market power that significantly increased as of 2015. Regarding market power determinants, we find strong evidence that the large entities as well as those with lower default risk and higher efficiency have greater market power. This last result evidences the fulfillment of the efficient structure (ES) hypothesis. Likewise, the processes of mergers, takeovers, and changes in the business structure of some MFIs as well as a less elastic demand for microcredits have contributed to increased market power in the sector. We additionally find that MFIs with lower market share, entities that operate in localized areas, exhibit greater market power. On the one hand, we determine that greater market concentration results in greater market power, but only when we use market power adjusted for efficiency. On the other hand, only with conventional market power, the relationship with commercial banks and an expansive economic cycle contributes toward increasing the Peruvian regulated microfinance sector’s market power. The rest of this article is organized as follows. Section 2 presents the conceptual framework that describes market power and identifies its main determinants. Section 3 describes the Preruvian regulated microfinance sector’s main characteristics. Section 4 presents the empirical strategy. Section 5 describes the data employed in the empirical analysis. Section 6 analyzes the empirical findings, and Section 7 presents the conclusions.",4
20.0,4.0,"Journal of Industry, Competition and Trade",25 March 2020,https://link.springer.com/article/10.1007/s10842-020-00337-1,Diversity and Quantity Choice in a Horizontally Differentiated Duopoly,December 2020,Xiaokuai Shao,,,Unknown,Unknown,Unknown,Unknown,,
20.0,4.0,"Journal of Industry, Competition and Trade",11 March 2020,https://link.springer.com/article/10.1007/s10842-020-00334-4,Entry of Innovator and License in Oligopoly,December 2020,Masahiko Hattori,Yasuhito Tanaka,,Male,Male,Unknown,Male,"In Proposition 4 of Kamien and Tauman (1986), it was argued that in an oligopoly when the number of firms is small (or very large), strategy to enter the market and at the same time license the cost-reducing technology to the incumbent firm (license with entry strategy) is more profitable than strategy to license its technology to the incumbent firm without entering the market (license without entry strategy) for the innovating firm. However, their result depends on their definition of license fee. They defined the license fee in the case of licenses without entry by the difference between the profit of an incumbent firm in that case and its profit before it buys a license without entry of the innovating firm. However, it is inappropriate from the game theoretic view point. If an incumbent firm does not buy a license, the innovating firm may punish the incumbent firm by entering the market. The innovating firm can use such a threat if and only if it is a credible threat. In a duopoly case with one incumbent firm, when the innovating firm does not enter nor sell a license, its profit is zero; on the other hand, when it enters the market without license, its profit is positive. Therefore, threat of entry without license is credible under duopoly, and then even if the innovating firm does not enter the market, the incumbent firm must pay the difference between its profit when it uses the new technology and its profit when the innovating firm enters without license as a license fee. For example, Hattori and Tanaka (2018) presented analyses of license and entry choice by an innovating firm in a duopoly. However, in an oligopoly with more than one incumbent firm, the credibility of threat of entry is a more subtle problem. In this paper, we examine definitions of license fees under oligopoly with three firms, one outside innovating firm and two incumbent firms, considering a two-step auction in the case of licenses without entry. Also we suppose that the innovating firm uses a combination of royalty per output and a fixed license fee. A two-step auction, for example, in the case of a license to one incumbent firm without entry is as follows.
 The first step. The innovating firm sells a license to one firm at auction without its entry conditional on that the bidding price must not be smaller than the minimum bidding price, which is equal to the willingness to pay for the incumbent firms described below, and the innovating firm imposes a predetermined (positive or negative) royalty per output on the licensee. A firm with the maximum bidding price gets a license. If both firms make bids at the same price, one firm is chosen at random. If no firm makes a bid, then the auction proceeds to the next step. The second step. The innovating firm sells a license to one firm at auction with its entry. At the first step of the auction, each incumbent firm has a willingness to pay the following license fee;  the difference between its profit when only this firm uses the new technology without entry of the innovating firm and its profit when only the rival firm buys the license with entry of the innovating firm. In the first step, each incumbent firm has an incentive to make a bid when the other firm does not make a bid. On the other hand, it does not have an incentive to make a bid when the other firm makes a bid. The decision of the innovator not to enter the market in the first step is commitment if the incumbent firms accept the offer. We need the minimum bidding price because if there is no minimum price, when one of the incumbent firms makes a bid which is slightly but strictly smaller than this price, the other firm does not have an incentive to outperform this bidding. Threat by such a two-step auction is credible if the total payoff of the innovating firm when it enters the market with a license to one firm is larger than its total payoff when it licenses to one firm without entering the market. A two-step auction in the case of licenses to two incumbent firms without entry is similar,Footnote 1 and at the first step of the auction, the incumbent firm has a willingness to pay the following license fee;  the difference between its profit when both firms use the new technology without entry of the innovating firm and its profit when only the rival firm buys the license with entry of the innovating firm. In the first step, each incumbent firm has an incentive to make a bid even if the other firm makes a bid because if it does not make a bid, the auction proceeds to the next step. In the next section, we present some literature review. In Section 3, the model of this paper is described. In Section 4, we consider various equilibria of the oligopoly. In Section 5, we present an analysis of a royalty and a fixed license fee under the license with entry strategy by the innovator. In Section 6, we consider a two-step auction and present an analysis of a royalty and a fixed license fee under the license without entry strategy. In Sections 5 and 6, the following results about the optimal royalty rate for the innovator are shown (see Proposition 6.1).Footnote 2 Entry with license to one firm case The optimal royalty rate may be positive or negative. Entry with licenses to two firms case If the outputs of the firms are strategic complements, the optimal royalty rate is positive. If the outputs of the firms are strategic substitutes, it may be positive or negative. License to one firm without entry case not using two-step auction If the outputs of the firms are strategic substitutes, the optimal royalty rate is negative. If the outputs of the firms are strategic complements, it may be positive or negative. License to one firm without entry case using two-step auction If the outputs of the firms are strategic substitutes, the optimal royalty rate is negative. If the outputs of the firms are strategic complements, it is positive. Licenses to two firms without entry cases using or not using two-step auction The optimal royalty rate is positive. In Section 6, also we examine the credibility of two-step auction and show the following results (see Proposition 6.2).
 If the cost function of the new technology is linear, the profit of the innovating firm when it enters the market with a license to one firm and its profit when it licenses to one firm without entering the market are equal, that is, entry with license to one firm case and license to one firm without entry case are equivalent. If the cost function of the new technology is strictly convex, two-step auction is credible. If the cost function of the new technology is strictly concave, two-step auction is not credible. In Section 7, we present an example of linear demand and quadratic cost functions. In this example, two-step auction is credible. We will show that when the cost of the new technology is low, license to two firms without entry strategy is optimal; on the other hand, when it is not low, entry with licenses to two firms strategy is optimal.",
20.0,4.0,"Journal of Industry, Competition and Trade",24 March 2020,https://link.springer.com/article/10.1007/s10842-020-00336-2,Downstream Information Leaking and Information Sharing Between Partially Informed Retailers,December 2020,Wei-Shiun Chang,Daniel A. Sanchez-Loor,,Unknown,Male,Unknown,Male,"Considerable work in supply chain and operations management has recognized the potential benefits of sharing information among competitors (hereafter referred in feminine). This is a mutual and voluntary sharing among competing companies at the same echelon defined as horizontal information sharing. In the service industry, competing airlines build alliances to improve their operational performance by sharing capacity and information about demand. These practices lead to a better performance at alliance level; for instance, Star Alliance and SkyTeam Alliance have grown in revenue at an average annual rate of 5.05% since 2015 (Flight Airline Business 2019). In the manufacture of energy-saving lighting, Phillips and LED Effect (LEI) were competitors who cooperated to the development of LED devices in 2006 by agreeing to share confidential business information and proprietary technologies. This partnership allowed them to increase their presence in the market and surpass their competitor, Color Kinetics.Footnote 1 However, when competitors purchase from the same upstream party, this upstream party (hereafter referred in masculine) has the potential incentives to share information from one downstream party to the other in order to increase his benefits. This practice is defined as information leaking and it is also visible in real business practice. For instance, the Israeli company, Bruno, distributed electronic components and represented US company, Vicor, to the Israeli manufacturers of the electronic industry for more than two decades. In 2011, Vicor decided to include another distributor, Migvan, to his network in Israel. Bruno sued Vicor in 2015 at the US District Court of Massachusetts because of sharing strategic information of Bruno’s operations with Migvan. This information included prices, sales, engineering, design, and the list of customers that allowed Migvan to snatch old and potential customers from Bruno.Footnote 2 Although the previous scenarios’ outcome is the transfer of information among competitors, there are strategic concerns that affect profit allocation among these parties. Horizontal information sharing is a mutual exchange, whereas information leaking is filtering information unidirectionally in the best interest of the upstream party. In this research, we focus on analyzing the impact of horizontal information sharing and information leaking on the performance of the supply chain, i.e., the profits of the upstream party (manufacturer) and downstream parties (retailers). Previous work has extensively explored horizontal information sharing between retailers and vertical information between parties at different echelons in supply chain, e.g., manufacturer and retailer, supplier, and manufacturer. The large amount of contributions in information sharing leads us to concentrate on the work that studies information leaking from an upstream party to a downstream one. The results of influential studies in this stream of research agree that manufacturers always leak information voluntarily by informing some of the retailers (Anand and Goyal 2009; Kong et al. 2013) or indirectly through his pricing decisions (Li 2002; Li and Zhang 2008). We find a case of how a manufacturer uses information of downstream parties to price goods in his best intertest. In the construction industry, Firestone was the leading manufacturer of roofing products in the USA with two main distributors in Philadelphia area by 2010: Marjam, and Allied. In 2012, Marjam brought Firestone to court because of selling identical products at lower prices to direct competitors including promotion discounts, rebates, special financing, and more convenient payment terms. Presumably, Firestone’s motivation was to reduce the market participation of Marjam to the point of terminating her distribution agreement in December 2011 and benefit Allied, which remains as the only significant distributor of Firestone in the area. This claim of discriminatory pricing was granted to the plaintiff by the court of New Jersey.Footnote 3 Previous work has built their analytical models with information asymmetries between retailers. They establish an incumbent retailer and entrant retailer, where the former has accurate knowledge of the upcoming condition of demand (Wang et al. 2018), or at least a signal about an uncertain demand (Anand and Goyal 2009). Jain and Sohoni (2015) consider the limitations of this assumption and allows the entrant retailer (second-mover in their original work) to have the possibility of having better information about demand. Following this direction, we argue that it is improbable for one retailer to determine the other retailer’s information position about demand when both retailers enter a new market or start selling a new product whose demand is uncertain. To address this gap, this study investigates the retailers’ decision of horizontal information sharing and manufacturer’s decision of information leaking when retailers cannot determine their own information position with respect to others’. The present study is organized as follows. Section 2 presents a literature review of the previous work including information leaking in supply chain. Section 3 develops the analytical model with three scenarios: no information sharing no information leaking, horizontal information sharing, and information leaking. Section 4 uses a numerical example to point out the insights of the model. Section 5 brings up a discussion about our findings and contribution to literature. Section 6 concludes the study.",2
20.0,4.0,"Journal of Industry, Competition and Trade",28 June 2020,https://link.springer.com/article/10.1007/s10842-020-00343-3,Social Responsibility in a Bilateral Monopoly with Downstream Convex Technology,December 2020,Luciano Fanti,Domenico Buccella,,Male,Male,Unknown,Male,"During the last decades, the adoption of corporate social responsibility (CSR) activities has become a global business practice. In 2002, KPMG surveyed the top 100 companies in 45 countries, disclosing that 23 percent of them declared the accomplishment of CSR activities in their financial reports; those figures increase to 73 percent in 2015. Moreover, in the same time period, the Global Fortune Index (which includes the world’s 250 largest companies) has more than doubled those figures, from 45 to 92 percent (KPMG 2005, 2015). The booming expansion of CSR has raised questions among scholars and policy makers, thus spurring the debate on the motives pushing companies to engage in socially concerned activities. Interestingly, however, in some vertically related industries, an asymmetric attitude toward CSR has been observed among upstream and downstream firms. For instance, on November 2017, leading carmakers including Volkswagen and Toyota pledged to sustain socially responsible standards in their purchases of minerals for an expected boom in electric vehicle production. However, talks with major cobalt producers (including Glencore, one of the largest globally diversified natural resources company), which are barely engaged in CSR in activities, ended without a deal on this issue (Reuters, 2017). In this paper, we start from the basic model of duopolistic Cournot competition, in which it is easy to show that firms—which maximize short-run profits—always reduce their profits by introducing social concerns in their objectives, for instance, under the form of an “interest” for the welfare of consumers, and we pose the following research question: how do firms’ attitudes toward CSR activities depend on the feature of production function in a vertically related industry? Our reference point is the contribution of Brand and Grothe (2015), which analyzes the choice of CSR engagement in the upstream and downstream firms in a standard, linear bilateral monopoly. Those authors, as the majority of the literature on CSR, assume constant returns to input (i.e., a one-on-one relationship between input and output). They find that CSR may emerge only if the upstream firm is the Stackelberg leader in the choice of the CSR levels, and the weight given to the consumer surplus by the downstream firm is precisely one-third and half of that given by the upstream firm. Given the specificity of the predictions of Brand and Grothe (2015), we question if the alteration of the assumption with regard to the technology in place in the supply chain will modify such results. Thus, in our framework, the constant return to input assumption is relaxed and substituted by a decreasing return to input, while the rest of the Brand and Grothe’s (2015) model is kept unaltered. In detail, we assume increasing marginal costs in line with the short-run context of any Cournot model: indeed, according to the first principles of economics, in the short run, some factors are fixed with remaining factors subject to diminishing returns, so the short-run marginal cost increases in output. With regard to the labor costs, typical arguments for the existence of rising marginal costs are, for instance, the additional costs of overtime work and the higher cost of bringing into use older equipment to meet the additional demand.Footnote 1 The main findings of the paper are as follows. First, in a vertical industry in which the upstream firm has linear technology with constant returns while the downstream firm shows decreasing returns to input, firm owners may earn higher profits at equilibrium, adopting CSR behaviors. Second, only the downstream firm finds it optimal to be of CSR type and strongly engaged in the welfare of consumers, thus reversing the standard result obtained by Brand and Grothe (2015) in a standard bilateral monopoly with overall linear technology. Nonetheless, the profit-seeking upstream firm benefits from the consumer-friendly CSR of its downstream firm, leading to a Pareto-superior outcome. In the next section, we present a review of the related literature. Then, in Section 3, we introduce the basic ingredients of the model with unions and the cooperative choices of CSR activities. Then, Section 4 presents the equilibrium outcomes of the model without CSR, compares the outcomes of the models, and derives the main results. The last section sums up our findings, offering some policy and empirical insights.",5
20.0,4.0,"Journal of Industry, Competition and Trade",31 July 2020,https://link.springer.com/article/10.1007/s10842-020-00345-1,Publisher Correction: Social Responsibility in a Bilateral Monopoly with Downstream Convex Technology,December 2020,Luciano Fanti,Domenico Buccella,,Male,Male,Unknown,Male,,
21.0,1.0,"Journal of Industry, Competition and Trade",19 September 2020,https://link.springer.com/article/10.1007/s10842-020-00348-y,A Sectoral Approach to the Politics of State Aid in the European Union: an Analysis of the European Automotive Industry,March 2021,Marco Schito,,,Male,Unknown,Unknown,Male,"Government support to business through selective subsidisation is historically common practice. It allows governments to encourage economic activity in a region, slow the rate of decline of an industry, maintain the incomes of producers, correct market failures, or enhance employment (OECD 2001, p. 7). In the European Union (EU), subsidy spending is commonly known as state aid, the control of which is pivotal to the correct functioning of the Single Market. For this reason, past studies have explored different facets of state aid politics to understand why some countries support business more than others, or why under certain circumstances state aid is warranted. These studies usually analyse spending as a whole, without differentiating between the different sectors of the economy. However, a disaggregated view of the state and the economy that looks at its individual sectors may be necessary to better understand state-society relations (see Atkinson and Coleman 1989) and to contribute to the improvement of state aid rules. Scholars that attempt sectoral analyses often look at specific aid measures that may not necessarily be representative neither of the industry as a whole, nor of the trend over time. For instance, in the airline industry, Chari (2004) focuses on aid to Irish and Spanish airlines Aer Lingus and Iberia, whereas Featherstone and Papadimitriou (2007) follow the restructuring of Greek flagship Olympian Airways. In the automotive industry, Germano (2009) retraces the relationship between the car maker Fiat and the Italian government, which enjoyed a privileged relationship, while Dunnett (1980) and Wilks (1988) explore the effect of government policy on the British automotive industry. A large-N analysis, instead, offers the ability to better generalise the findings and therefore improve the external validity of the analysis. Thus, the main goal of this article is to provide a quantitative analysis of the political determinants of state aid at the sectoral level. In particular, the article analyses subsidies to the automotive industry (or MVI, motor vehicle industry). This sector is one of the biggest and most important industries in Europe. According to the European Automobile Manufacturers Association (ACEA), in 2016, two and a half million people were employed in the manufacturing of motor vehicles in the EU-28, accounting for 8.3% of EU employment in the manufacturing sector; exports accounted for almost €140bn; €54bn was invested in innovation; and fiscal income from motor vehicles in Western European countries was over €400bn (ACEA 2019a). Hence, for governments in several EU member states, the MVI constitutes a sector in which they may have important political and economic stakes. My argument is that there are two mechanisms through which political considerations may come into play in a government’s decision to allocate subsidies. First, aid may be a function of policy-makers’ objectives. Governments give state aid because they are concerned about attaining certain ‘policy goals’ or objectives, though they are increasingly constrained in their room of manoeuvre by the European Commission (Hofmann 2016, pp. 3–4). Secondly, they many want to target those constituencies that maximise the governing party’s electoral fortunes (Rickard 2018). Thus, effective supply of aid allocations depends on how the political-institutional environment affects the ability of governments to deliver targeted benefits, and creates incentives to incumbents for political survival through its electoral institutions. The argument is tested by means of regression analysis based on an original dataset of over 120 aid measures to the MVI in 16 EU member states between 1992 and 2011. The findings show that, of the two mechanisms, electoral competition seems to be the more relevant one: variables associated with electoral competition are more consistently found to be statistically significant. Aid allocations seem seldom to be determined by a government’s preferences over its policy objectives. Electoral competition, instead, suggests that electoral rules such as the cultivation of a personal reputation by distribution of targeted benefits to a constituency may help legislators in their chances of being re-elected. The contribution of this study, then, is two-fold. Firstly, the article provides an account of state aid politics applied at the sectoral level based on two possible mechanisms: attainment of policy goals and electoral competition. Secondly, the article goes beyond the qualitative literature on sectoral studies by offering a quantitative assessment of the politics of state aid to the MVI. The article is organised as follows. Section 2 reviews the literature on the politics of state aid. Section 3 describes the automotive industry and its characteristics. Section 4 builds on the previous two sections to advance three hypotheses of state aid politics applied to the MVI. Section 5 provides the data and operationalisation of the variables, while Section 6 presents the statistical model and the empirical results. Section 7 concludes with some important takeaways of the study, as well as its limitations.",1
21.0,1.0,"Journal of Industry, Competition and Trade",11 April 2020,https://link.springer.com/article/10.1007/s10842-020-00335-3,Strategic CSR in Asymmetric Cournot Duopoly,March 2021,Lisa Planer-Friedrich,Marco Sahm,,Female,Male,Unknown,Mix,,
21.0,1.0,"Journal of Industry, Competition and Trade",22 April 2020,https://link.springer.com/article/10.1007/s10842-020-00339-z,Environmental Technological Choice in a Cournot-Bertrand Model,March 2021,Elias Asproudis,Eleftherios Filippiadis,,Male,Male,Unknown,Male,"There has been a rising interest in the IO literature in types of competition where the same competing firms choose, within a specific market, different strategic variables. A firm’s choice of strategic variable is not solely determined by market attributes, but it also depends on the characteristics of the individual production processes. Kreps and Scheinkman (1983) have shown that when production precedes demand realization a firm chooses quantity as its strategic variable (i.e., the firm is a Cournot competitor). On the other hand, when production schedules can be easily changed, a firm chooses price as its strategic instrument (i.e., the firm is a Bertrand competitor). Therefore, it is conceivable that firms operating in the same market but characterized by significantly different production processes might choose different strategic instruments. Empirical observations confirm the existence of this type of oligopolies. Tremblay and Tremblay (2011) mention the small car industry example where Honda and Subaru dealers decide upon quantities while Scion and Saturn dealers decide upon prices, whereas Sato (1996) is discussing the case of the Japanese domestic market of electronics where Matsushita and Sanyo are acting as Cournot and Bertrand rivals, respectively. Oligopolies of this type have been theoretically explored in Singh and Vives (1984)Footnote 1 where the Cournot-Bertrand duopoly is analyzed and compared against pure Cournot and Bertrand models under the assumptions of constant marginal costs, zero fixed costs, and no capacity limitations. These authors conclude that each firm’s dominant strategy is to compete à la Cournot. However, as pointed out in Tremblay and Tremblay (2011), this conclusion rests on the assumption of zero fixed cost and the choice of the strategic instrument might change should this assumption change. This study explores the effect product differentiation has on the optimal decision-making under Cournot-Bertrand competition and argues that the equilibrium is stable for a sufficient degree of product differentiation and that the Cournot-Bertrand outcomes can be optimal. A more recent study (Tremblay and Tremblay 2017) investigates the effect an excise tax has on prices in pure Cournot, Bertrand, and Cournot-Bertrand models, fully describing the conditions under which firms can undershift or overshift the tax onto the consumers. Furthermore, Naimzada and Tramontana (2012) focus on the dynamic case of the Cournot- Bertrand duopoly while Manasakis and Vlassis (2014) present a case of upstream-downstream pair-wise firms where downstream firms compete in Cournot, Bertrand, and/or Cournot-Bertrand fashion. Similarly, Rozanova (2017) studies equilibrium wholesale prices in vertically related firms with Cournot-Bertrand competition in the final product market. It concludes that “at the downstream level the Bertrand-type competitor has a cost advantage over the Cournot-type firm.” In earlier studies, Matsumoto and Onozaki (2005) and Yousefi and Szidarovszky (2005) modeled the complex dynamics of mixed duopolies with nonlinear demands. Wang and Ma (2013) consider a Cournot-Bertrand model with bounded rationality expectations and explore equilibria and local stability under limited information. Also, Ma and Pu (2013) explore the complex characteristics of a mixed Cournot-Bertrand model using nonlinear dynamics theory. Matsumoto and Szidarovszky (2010) investigate the continuous dynamics of mixed Cournot-Bertrand competition without time delays, and with fixed and continuously distributed time lags. They argue that fixed time lags have a larger destabilizing effect on the dynamics than continuously distributed time lags. Matsumoto and Szidarovszky (2011) focus on N-firm Cournot-Bertrand competition and conclude that “...[i]f the firms can precommit to quantity or price strategy, the dominant strategy depends on the average quality ratio of the goods produced by the quantity-adjusting firms and the goods produced by the price-adjusting firms. ” Szidarovszky and Molnár (1992) focus on the general oligopoly Cournot-Bertrand model with nonlinear complementarity problem and the existence and uniqueness of the Nash equilibrium. Chang et al. (2015) examine the case of the Cournot-Bertrand model under the existence of patent licensing and differentiated duopoly. Tremblay and Tremblay (2019) offer a comprehensive review of the related literature and examines the alternative market conditions under which the Cournot-Bertrand model can emerge. It also discusses the welfare ranking of Cournot-Bertrand oligopoly compared to pure Cournot and pure Bertrand oligopolies. The authors propose the application of the Cournot-Bertrand model in areas of economics such as international economics, industrial organization, labor, and public economics. While the specific characteristics of the Cournot-Bertrand model have been analyzed in the literature, there is still little research done on how firms, engaging in this type of competition, respond to environmental policies. This paper investigates the choice of abatement technology in a static Cournot-Bertrand duopoly and its effect on quantities, prices, profits, and emissions. We argue that, for a reasonably wide range of demand and cost parameters, the Cournot firm will choose a “greener” technology compared to its Bertrand rival. At the same time, it will produce more, charge less, and yield higher profits compared to the Bertrand firm. This is because investing in abatement technology effectively lowers the per unit of production effluent tax for the firm making it more aggressive in the product market competition. Furthermore, starting from the same level of anti-pollution technology, an identical improvement in the abatement technology increases the supply of the Cournot firm by more than the increase in the supply of its Bertrand rival, hence making the Cournot firm relatively more aggressive than the Bertrand firm. Moreover, we show that when a range of abatement technologies is available to the firms, the total output in the market will increase while total emissions decrease, thus increasing consumer welfare. This result is also confirmed in pure Cournot and pure Bertrand oligopolies. Finally, we show that firms choose a greener technology when engaged in quantity competition (i.e., pure Cournot) than in price competition (i.e., pure Bertrand). In Section 2, we develop the Cournot-Bertrand model in the presence of emission taxes and abatement technology choice, and we derive the relevant results. In Section 3, we conduct the same analysis for the pure Cournot and pure Bertrand oligopolies and we extend our findings on the connection between abatement technology choice and the type of competition. In addition, we provide some numerical results on welfare comparisons between the different types of oligopolies. Finally, Section 4 concludes.",4
21.0,1.0,"Journal of Industry, Competition and Trade",25 April 2020,https://link.springer.com/article/10.1007/s10842-020-00338-0,Armington Elasticity and Development,March 2021,Purba Mukerji,John Struthers,,Unknown,Male,Unknown,Male,"Table 1 presents the source of AE estimates along with the sample of countries and years on which each estimate is based. In addition, there is a column with the share of patent applications filed by the countries in the sample as a percentage of world totals to measure technological development. The aim of Table 1 is to show a comprehensive list of AE estimates in the literature, and it demonstrates standard patterns: AE estimates are higher for disaggregated data, for longer term data, and for cross section data (e.g., McDaniel and Balistreri (2002), Ruhl (2003)). In this work, however, we would like to draw attention to two new characteristics of the estimates that will clarify the contribution we seek to make to the literature. First, we separate AE estimates based on whether they measured substitutability between domestic versus imported products or only among imported products. Viewed in this light, the table reveals a new pattern. We see that this separation makes it clear that imported products are easier to substitute for one another, compared with their substitutability with the domestic variety. This is evidenced by the AE estimates being on average larger when measuring substitutability among only imported products. This has been noted by Feenstra et al. (2012) whose estimates are also part of Table 1. However the reasons for this explored by Feenstra et al. (2012) are not intrinsic product characteristics, instead they consider imperfect substitutability based on factors such as, political processes/foreign ownership which make consumer perception of products become more or less dependent on the product’s country of origin and. For example, foreign ownership might lead to more openness and rising AE. Conversely, unionization might lead to falling AE due to political movements that encourage people to buy domestic, for example, in an attempt to protect domestic jobs (Blonigen and Wilson 1999). The contribution of our paper is to explore technological development creating real differences between domestic and imported product characteristics and thus affecting substitutability. To measure technology on Table 1, we add a column of patent applications as a percentage of total world patent applications to measure countries’ technological development. However, it is difficult to discern any broad patterns from the addition of the patent data. This is not surprising since the estimates of AE available in the literature are influenced greatly by the trade policy. For example, a small change in prices can bring about a large trade response due to bilateral, regional, or multilateral trade liberalization. Thus the countries included in the estimation will influences the AE estimate due to trade policies that were directed towards these countries. In addition, particular industries analyzed may have characteristics e.g., trade restrictions, consumer perceptions based on unionization, political processes, etc. that influence the AE estimated. Furthermore, as noted above, the characteristics of the data such as aggregation level, time period covered, and cross section/time series nature also impact the AE estimate. Our contribution in this paper is to model how the process of development, particularly the availability of technology will shape the AE between the domestic and imported goods. One of the important questions this will help answer is how economic fundamentals of each economy might explain why AE estimates of domestic versus imported goods is so much lower than that among imported goods alone. This important aspect has so far been neglected by the literature.",1
21.0,1.0,"Journal of Industry, Competition and Trade",20 May 2020,https://link.springer.com/article/10.1007/s10842-020-00341-5,Impact of Technical Progress on the Relationship Between Competition and Investment,March 2021,François Jeanjean,,,Male,Unknown,Unknown,Male,"The relationship between competition and investment is a matter of longstanding debate in industrial organization. However, no clear overall conclusions have been reached thus far. Theoretically, Schmutzler (2013) showed that the relationship can go in any direction. These different outcomes depend on the characteristics of the industry in question. Many parameters may matter: market structure, the type of competition, consumer demand, cost patterns, and technical progress. To the best of my knowledge, the specific influence of technical progress on this relation has not been thoroughly studied, despite its essential role in dynamic efficiencies and economic growth. This paper attempts to fill this gap and focuses on the impact of technical progress on the relationship between competition and investment. In the paper, technical progress is understood as the ease to innovate, which is specific to each technology. This specificity of technical progress for each technology has been highlighted by Koh and Magee who have noted a fairly steady rate of technical progress for more than a century in different technologies. This annual rate of technical progress is much higher for information technologies (over 20%) than for energy technologies (approximately 6%) (Koh and Magee (2006); Koh and Magee (2008)). In both cases, the authors find an almost constant rate of technological change that does not vary beyond relatively narrow limits (< 5% for information technologies and < 2.5% for energy). Thus, the technical progress rate is relatively steady for each technology. An industry is based on a mixture of different technologies; therefore, it is reasonable to assume, as long as the technology mix of the industry does not change too much, that technical progress also does not change significantly at the industry level. This paper shows that these different paces of innovation have a major impact on the relationship between competition and investment and, therefore, on the relationship between competition and consumer surplus or between competition and welfare. Innovation may be either cost-reducing (process innovation) or quality-improving (product innovation). Competition can be measured by either the number of competitors or the degree of horizontal product substitutability. Innovation is made possible through investment. There are several types of cost-reducing or product quality-enhancing investments: spending on R&D, spending on a cheaper new generation of supply materials (to benefit from R&D of the supplier), spending on process improvement, and so on. Intuitively, one can reason as follows: innovative industries are more adept at innovating than others. They innovate at lower cost. They therefore benefit from a higher potential for technical progress. However, there could be a difference between potential technical progress and effective technical progress (the extension of the technological frontier). This difference occurs when the margin is insufficient to sustain the investment required by technical progress. In this case, an increase in competitive pressure further reduces the margin and thereby reduces investment. Otherwise, an increase in competitive pressure, as expected, increases investment. Consequently, the investment is maximized at the level of competition above which potential technical progress is no longer achieved. Higher potential technical progress requires more investment for its transformation into actual technical progress and, therefore, the level of competition that maximizes investment decreases. Some observations seem to corroborate this line of reasoning: for example, the merger between two mobile telecommunication operators Hutchison and Orange in Austria in 2013. This merger had different impacts on voice and data traffic. It decreased voice traffic (minutes of communication) and increased data traffic (megabytes). This is meaningful because voice and data technologies do not undergo innovation at the same pace. Voice traffic increased on average by 3.2% per year before the merger (2009–2013) and 0.3% after (2013–2017). Data traffic increased on average by 63% per year before the merger and 70% after.Footnote 1 In other words, the merger had a positive impact on the use of data technology, which displays a high innovation pace, and a negative impact on the use of voice technology, which displays a much lower innovation pace. The same event, namely, the merger from 4 to 3 mobile operators, which reduced competition in the same manner for voice and data technologies, led to different outcomes based on their technical progress rate. Although it is not possible to distinguish between voice and data investment, traffic growth requires investment, and we can reasonably assume that an acceleration of traffic growth entails an increase in investment, whereas a slowdown entails a decrease in investment. This suggests that the degree of competition (the number of operators) that maximizes investment is lower for data than for voice technologies. Data technology which displays a higher innovation pace than voice technology maximizes investment under lower competitive pressure. In this paper, using an oligopoly model, I show that an increase in technical progress, by increasing the size of innovation, tends to decrease the degree of competition that maximizes investment at the industry level. These features are illustrated by different versions of the model in which the measure of competition is the number of firms or the degree of horizontal substitutability. As a result, industries experiencing low technical progress are more likely to exhibit an increasing relationship between competition and investment, whereas industries experiencing higher technical progress are more likely to exhibit an inverted U-shaped or decreasing relationship. The higher the technical progress is, the lower the number of competitors or the degree of horizontal substitutability corresponding to the maximum investment. More precisely, this paper shows that on the one hand, in a symmetric market, a higher degree of technical progress reduces the number of firms for which investment at the industry level is maximized; on the other hand, in an asymmetric market, technical progress reduces the degree of substitutability for which the level of investment is maximal at the industry level. Moreover, technical progress spurs an innovation race among firms, which tends to amplify competitive pressure. Innovation shifts the technological frontier and increases the efficiency gap between leaders and laggards, reallocating output from less efficient firms to more efficient ones. According to Boone (2008), this is a general feature of more intense competition. Technical progress is thus a dynamic amplifier of competition. Since a rise in technical progress increases competition, it is not surprising that other types of competition, particularly static forms of competition, such as the number of firms or the degree of horizontal substitutability, have to decrease to maintain the optimal level of competition that maximizes investment. To illustrate the results, this paper provides parametric examples using demand functions in the manner of Shubik and Levitan (1980) or Singh and Vives (1984). The remainder of the paper is organized as follows: Section 2 is a literature review. Section 3, based on a model derived from Aghion et al. (2014), explains why the level of innovation tends to decrease the level of competition that maximizes innovation. Section 4, using an oligopoly model of competition, shows that the level of competition that maximizes investment decreases with technological opportunity, i.e., a lower cost of innovation. In symmetric markets, competition is measured by the number of competitors, while in asymmetric markets, competition is represented by the degree of horizontal substitutability. In both cases, the size of innovation, or the level of technical progress, reduces the degree of competition that maximizes investment. Section 5 concludes the paper.",3
21.0,1.0,"Journal of Industry, Competition and Trade",14 June 2020,https://link.springer.com/article/10.1007/s10842-020-00342-4,Determinants of the (Slow) Development of Effect-Based Competition Enforcement: Testing the Impact of Judicial Review on the Choice of Legal Standards by Competition Authorities,March 2021,Yannis Katsoulacos,Svetlana Avdasheva,Svetlana Golovanova,Male,Female,Female,Mix,,
21.0,1.0,"Journal of Industry, Competition and Trade",27 August 2020,https://link.springer.com/article/10.1007/s10842-020-00347-z,Access Prices Indexed to Geographical Coverage of Innovative Telecom Services,March 2021,David Henriques,,,Male,Unknown,Unknown,Male,"Motivation A key concern for Europe and the USA is the timely rollout of innovative high-speed broadband services. The European Commission (2016) has set a target for all European homes to have access to a download speed of at least 100 Mbps by 2025, while the Federal Communications Commission (2016) has set a goal for all US Americans to have access to affordable, high-quality broadband. These high-speed services have the potential to offer considerable benefits to businesses to remain or become more competitive, allow consumers to benefit from advanced online services that improve their quality of life, and induce significant growth across major economic sectors (Czernich et al. 2011). Fibre optics is one of the fastest technologies for content transmission (both downloading and uploading), allowing for significantly faster and wider transmission of information than current copper-based networks. However, the private sector has been reluctant to invest in a large-scale deployment of Next Generation Access Networks (NGA), namely fiber-based networks.Footnote 1 Insofar as the fiber rollout cost increases substantially when population density falls, this has led to concerns on the ability of firms to extend geographical coverage outside major urban areas. One reason for under-investment in NGA coverage relates to the inability of firms to capture the full social benefit from that investment. Another potential reason for under-investment is the lack of access to finance. In the introduction phase of innovative services requiring significant investment in geographical coverage such as high-speed broadband, regulators are likely to face a trade-off between static (price) and dynamic (coverage) efficiency. I question how such a trade-off can be softened. I investigate the impact of different access price controls on the firms’ choices of geographical coverage of innovative services, and on downstream prices. The aim of this paper is to seek access price control rules that encourage further coverage without increasing downstream prices relative to a standard fixed price control approach. Related Literature This paper draws from the strand of literature on the interplay between access price regulation and private investment, especially on geographical deployment of new networks. Faulhaber and Hogendorn (2000) and Foros and Kind (2003) and Valletti et al. (2002) are important contributions to the research on geographical deployment of broadband networks. These articles studied the effects of universal service and uniform retail pricing obligations on coverage. However, they did not address the impact of access price regulation. Hori and Mizuno (2009) compared service-based and facility-based competition in terms of a firm’s incentive to invest in network infrastructure under uncertainty. Brito et al. (2010) showed that two-part access tariffs might enable a regulator to incentivize an operator to invest on NGA. However, neither of the two addresses investment in geographical coverage. Lestage and Flacher (2009) pioneered the research of the impact of access regulation on geographical coverage within the context of competition for rolling out new telecommunications infrastructures. They proposed a model for the decision about “if” and “ where” to deploy a new infrastructure, and showed that access regulation reduces the area of facility-based competition and extends the area where no firm is willing to invest. However, they did not consider access price rules as a function of investment levels.Footnote 2 Only exceptions such as Hurkens and Jeon (2008), Klumpp and Su (2010), Nitsche and Wiethaus L (2011), and Henriques (2011) and Sauer (2012) have considered the idea of access prices as a function of strategic variables, e.g., retail prices, quantities, or geographical coverage, as a means to improve welfare outcomes. Henriques (2011) and Sauer (2012) are the closest research works to this paper studying access prices for NGA as linear functions of geographical coverage. Both papers showed that such access prices incentivize further coverage from firms when compared with a fixed access price. However, these papers rely on specific assumptions, e.g., Hotelling model and quadratic cost of coverage. They do not show whether the Ramsey outcome or the first-best coverage level could be achieved under more general sets of assumptions. Other forms of access price, e.g., dependent on how much entrants invest, or the timing of investment, were studied by Cave and Vogelsang (2003) and Cave (2006) with the concept of “ladder of investment,” Gans (2001), and Hoernig and Vareda (2010). More recent papers that studied the impact of access regulation on investment are the following. Flacher and Jennequin (2014) compared different regulatory regimes in terms of geographic coverage and welfare levels. They showed that coverage and number of users as well as social welfare will be highest with direct regulation of both infrastructure deployment and access price. Bourreau et al. (2015) proposed access regulations tailored to each geographical area depending on the degree of infrastructure competition. They showed that geographically differentiated access prices can enhance welfare and promote investment compared with a uniform access price. Description of the Paper I compare the outcomes of a standard model obtained under a fixed access price and an access price as a function of NGA coverage (indexation, for short) in terms of retail prices, NGA coverage, and social welfare levels. The indexation approach corresponds to a regulator setting out a menu of options in which the regulated firm faces a choice of access price-coverage regulatory contracts. In theory, a regulator could set directly the price and investment in coverage that maximizes social welfare. However, in practice, regulators may not have the powers to set such investment levels for a firm, and firms face financial constraints which may be difficult to observe and verify by a regulator. Setting out a menu of options for the regulated firms to choose from, rather than imposing price and coverage levels directly, can avoid regulatory risks, e.g., forcing the firm to make an investment that it cannot afford, as well as incentivize the firm to invest up to the maximum amount that it can achieve. A distinctive feature of the access price indexation is to reward a regulated firm depending on the NGA coverage achieved. The firm is rewarded for covering a marginal area with NGA by increasing the access price in all (i.e., marginal and inframarginal) covered areas. Thus, the indexation grants an increasing competitive advantage at the downstream level as the regulated firm covers further areas. A key factor influencing firms’ incentives to invest and provide NGA services in an area is the incremental net revenues they can earn over and above providing their existing copper-based services in that area. Mechanisms which increase the incremental net revenues from NGA deployment can therefore have a positive effect on NGA coverage. Under a fixed access price and assuming copper-based services provided in a competitive basis at zero economic profit, the incremental net revenue of covering an additional area with NGA is the profit from that area only. However, under the indexation approach, the incremental net revenue of covering an additional area with NGA is the profit from that area plus the incremental profit from all inframarginal areas already covered with NGA. Thus, to achieve the same level of geographical coverage, the firm will require a lower access price under indexation than with a fixed access price. This paper extends both Henriques (2011) and Sauer (2012) by considering a more general set of properties for welfare, revenue, and cost of coverage, as well as non-linear access prices. The main contribution of this paper is to show that, under a standard set of assumptions, setting an access price as a function of NGA coverage can improve economic efficiency beyond what is feasible with a fixed access price. The indexation dominates a fixed access pricing rule in terms of retail price efficiency (i.e., the number of consumers served with a fiber connection), investment efficiency (i.e., total NGA coverage), and social welfare. Moreover, I address how a regulator can set the access price indexation optimally (based on the coverage cost plus an incentive), rather than assuming linearity as in Henriques (2011) and Sauer (2012). I show that the access price indexation can be used to achieve approximately the Ramsey outcome, or the first-best coverage level. I abstract from other potential policies designed to promote coverage (e.g., subsidies) treating them as independent of price controls. The rest of the paper is organized as follows. Section 2 sets up a service-based competition model. Section 3 defines the first- and the second-best, as well as the free market (monopoly) solution as benchmarks. Section 4 sets out the analysis under a standard fixed access price approach. Section 5 repeats the analysis with the access price indexation and compares it against the fixed access price approach and benchmarks previously considered. Section 6 discusses further features of access price indexation and the robustness of the results. Section 7 concludes the paper. Proofs can be found in the Appendix.",
21.0,2.0,"Journal of Industry, Competition and Trade",05 January 2021,https://link.springer.com/article/10.1007/s10842-020-00351-3,Flexible Ubers and Fixed Taxis: the Effect of Fuel Prices on Car Services,June 2021,Thomas J. Weinandy,Michael J. Ryan,,Male,Male,Unknown,Male,"This paper is the first to empirically compare the impact of fuel price on ridership of taxicabs and transportation network companies (TNCs) like Uber and Lyft. The market for single-rider transportation has experienced a dramatic transformation during the past decade (Bagchi 2018). The business model of the iconic yellow taxicab is threatened by the emergence of TNCs. Traditional taxis operate according to a regulated fixed-supply, fixed-price model while TNCs like Uber and Lyft have flexible supply and flexible pricing. We focus on the TNC-taxi relationship in New York City (NYC), the largest city in the USA. This is an ideal location due to the early entrance of Uber as well as the sheer size of the market for transportation. One growing component to the city’s travel mix is car services. To better understand this evolving market, we must first understand how the decisions of transportation providers are influenced by factors like fuel prices. Drivers for taxicabs and TNCs both have to pay for their own gasoline which is not factored into their compensation. This, along with insurance, vehicle repairs, and depreciation, can lead to substantial costs for professional drivers. This cost for full-time Uber drivers is estimated nationally at $3.76–$6.46 per hour of work (Hall and Krueger 2018, p. 726), while taxi drivers in NYC commonly lease a vehicle for 12-h shifts that range from $9.58 to $11.83 per hour, plus gas (Farber 2015, p. 1993). These input costs are substantial for drivers and should be negatively associated with the number of car service trips. There are, however, alternative conceptual explanations as to why higher fuel prices may be associated with more car service trips. This theoretical ambiguity requires an empirical estimation to understand whether fuel price has a positive or negative effect on ridership and with what magnitude. Since fuel prices are measured daily, it is possible to study how this factor of production impacts the quantity of rides under the two systems. We know of no other research that compares how TNCs and taxis behave differently in response to changing fuel prices. This paper specifically looks at the impact fuel prices have on taxicabs and TNCs in New York City from the beginning of 2015 through the end of 2018. We consider the daily quantity of rides under each car service system after controlling for conventional predictors. The static model is estimated using ordinary least squares (OLS) regression and seemingly unrelated regression (SUR). For robustness, we consider alternative measures with a variable for economic activity as well as a lagged dependent variable. This paper broadly finds fuel prices to have a negative and significant impact on the number of trips from TNCs with a cumulative marginal effect ranging from 0.367% and 0.486%. This means that in NYC alone, when looking at mean values, a 1-day 1% increase in fuel price is associated with 1266 to 1677 fewer TNC trips that day. Conversely, however, an equal increase in fuel prices has a positive and statistically significant impact on the number of taxi rides. The same rise in fuel prices will increase the number of taxi trips by 0.033% to 0.088%, or 125 to 333 trips. This discrepancy is likely attributed to the highly regulated nature of the New York City taxicab that hinders it from adjusting to exogenous changes in fuel price.",3
21.0,2.0,"Journal of Industry, Competition and Trade",11 March 2021,https://link.springer.com/article/10.1007/s10842-021-00359-3,Correction to: Flexible Ubers and Fixed Taxis: the Effect of Fuel Prices on Car Services,June 2021,Thomas J. Weinandy,Michael J. Ryan,,Male,Male,Unknown,Male,,
21.0,2.0,"Journal of Industry, Competition and Trade",30 September 2020,https://link.springer.com/article/10.1007/s10842-020-00349-x,"The Impact of Foreign Technology and Embodied R&D on Productivity in Internationally Oriented and High-Technology Industries in Egypt, 2006–2009",June 2021,Shimaa Elkomy,Hilary Ingham,Robert Read,Unknown,Female,Male,Mix,,
21.0,2.0,"Journal of Industry, Competition and Trade",05 November 2020,https://link.springer.com/article/10.1007/s10842-020-00350-4,Contracting in a Market with Differential Information,June 2021,Marta Rocha,Thomas Greve,,Female,Male,Unknown,Mix,,
21.0,2.0,"Journal of Industry, Competition and Trade",06 January 2021,https://link.springer.com/article/10.1007/s10842-020-00352-2,Do Mature Firms Gain Higher Economic Value from R&D Investment?,June 2021,Evans Opoku-Mensah,Yuming Yin,Bismark Addai,Unknown,Unknown,Unknown,Unknown,,
21.0,2.0,"Journal of Industry, Competition and Trade",25 February 2021,https://link.springer.com/article/10.1007/s10842-021-00357-5,R&D Investments in Markets with Network Effects,June 2021,Małgorzata Knauff,Adam Karbowski,,Female,Male,Unknown,Mix,,
21.0,2.0,"Journal of Industry, Competition and Trade",18 March 2021,https://link.springer.com/article/10.1007/s10842-021-00354-8,Effects of the European Monetary Union on High-Technology Exports,June 2021,Timo Tohmo,Kari Heimonen,Mika Nieminen,Male,Female,Male,Mix,,
21.0,2.0,"Journal of Industry, Competition and Trade",26 March 2021,https://link.springer.com/article/10.1007/s10842-021-00355-7,The Size of Strategic Alliances and the Role Played by Managers,June 2021,Manel Antelo,David Peón,,Male,Male,Unknown,Male,"Urged by increasing market competition and globalization, firms are forced to grow larger and improve their capabilities, in order to achieve economies of scale and access to new markets. They can do this through organic growth and new project ventures, but the process is slower than participating in different forms of corporate transactions with other firms, such as mergers and acquisitions (M&A), joint ventures, and alliances. In particular, through alliances, two or more firms agree to share resources in search of mutual profits or cost reductions, but they remain competitors in the product or services market and can independently adopt decisions there. Alternatively, firm complexity, high transaction costs, or the need for control may favor the pooling of all resources under common ownership by two or more merged firms or through the acquisition of one or more firms by another firm. Strategic alliances, a powerful mechanism to combine competition and cooperation (Kang and Sakai 2001), have been a common strategy for business growth for the last three decades, including in areas such as R&D, production, and marketing. For example, multicarrier alliances in the airline industry allow firms to take advantage of the network effects made possible by a global system of hubs that any single firm would find financially prohibitive to build on its own. Similarly, joint research in certain base technologies allows firms in the automotive industry to take advantage of economies of scale unavailable to any single partner. A recent survey (KPMG 2018) of 50 alliance experts in 13 different industries—including manufacturing, automotive, pharmaceuticals, and fast-moving consumer goods—shows that strategic alliances are becoming a fundamental part of corporate strategy as a means of keeping abreast of disruptive technologies, with, specifically, 58% of respondents indicating that their own industries will be entirely reshaped by new business combinations in the form of strategic alliances. Most research articles on strategic alliances are empirical in nature and focused on analyzing large companies in, among others, the airline sector (Fu et al. 2011), the car industry (Zeng et al. 2013), pharmaceuticals (Dong and Yang 2015), and biotech (Zidorn and Wagner 2013). Nonetheless, what happens with the creation of alliances when prospective members are not necessarily large firms, but firms of any size? Indeed, many scholars (e.g., Gundolf et al. 2018) observe a dearth of knowledge of small business alliances. In this article, we analyze a market with n companies where firm size, rather than being fixed, can be calibrated by the number of active firms in the market. In parallel, research on strategic alliances has overlooked the role of managers, both in the firms involved in the alliance and those outside of it. Entrepreneurship literature has focused on firms as governed by their owners and behaving, thus, as profit-maximizing entities (Berglann et al. 2011). However, recent evidence suggests that this is not always the case: up to 40% of founders in the USA and Europe rely on hired CEOs at the time of founding (see, e.g., McKenzie and Woodruff 2016) and a significant share of the remaining 60% of founders hire a professional manager by the time of a major financing event or initial public offering (IPO) (see, e.g., Wasserman 2003). This opens the door to investigating the extent to which ownership and control, when separate as compared to when they coincide (managerial and entrepreneurial firms, respectively), influence incentives to create a strategic alliance. While managerial contracts as used for a growth strategy have been extensively studied, most articles are empirical and do not address two main concerns. First, what role does strategic managerial delegation play in defining the company’s strategic alliances? Second, can the creation of strategic alliances be rationalized in industries with any number of firms? This latter concern arises because strategic alliances are considered to be frequent in scenarios of high technological uncertainty (Yin and Shanley 2008) and, since collusive behavior is easier, in concentrated industries consisting of a small number of firms and where competition is low (Dyer et al. 2004). In this paper, we seek a theoretical interpretation for those concerns, based on the managerial delegation literature. Comparing entrepreneurial versus professional management is a frequent academic debate in areas such as the impact of hiring managers in family businesses (e.g., Dekker et al. 2015) and the analysis of professional management performance in small and medium enterprises (SMEs) (e.g., Lumpkin et al. 2011). Specifically oriented to the analysis of strategic alliances by SMEs, several authors have highlighted the positive impact of appropriate governance mechanisms (Hoffmann and Schlosser 2001), particularly at the alliance building stage (Swoboda et al. 2011). The importance of managerial delegation is clear in the M&A literature: theoretical models by Ziss (2001) and Straume (2006) have shown that managerial delegation increases the probability of implementing a merger. Nonetheless, when applied to the formation of alliances, most models have obviated the impact of managerial delegation (e.g., Toshimitsu 2018; Antelo and Peón 2019). We contribute with a theoretical model underpinned by a key hypothesis regarding whether managerial firms have a rationale to incur in more (or larger) alliances than entrepreneurial firms. We analyze the benefits to firm owners of hiring professional managers to develop alliances with competitors. We model entrepreneurial firms as firms managed by their owners, and managerial firms as firms in which ownership and management are separated. The delegation literature analyzes the strategic value of publicly observable managerial incentive contracts based, for instance, on a convex combination of profits and revenues. On that basis, if managerial delegation is found to promote more (or larger) alliances between firms more than non-delegation, then entrepreneurs would do better to hire managers and implement the appropriate incentive scheme that maximizes the pursued combination of sales and profits. Our findings show that alliance formation critically depends on a firm’s government structure in terms of entrepreneurial management or professional management. Specifically, alliances are more likely when firms are governed by managers than when they are governed by their owners. Nonetheless, the socially optimal alliance—which is shown to include all firms in the industry—is not achieved by either entrepreneurial firms or managerial firms. Therefore, a desirable industrial policy should encourage cooperation between companies in stages prior to the production phase (when there is Cournot competition). The rest of the paper is organized as follows. In Section 2, we present the model. In Sections 3 and 4, we summarize the results for entrepreneurial firms and managerial firms, respectively. Section 5 provides the welfare analysis. Finally, Section 6 discusses the results of the model in relation to the empirical evidence and concludes with some remarks. All results are proved in the Appendix.",2
21.0,3.0,"Journal of Industry, Competition and Trade",04 March 2021,https://link.springer.com/article/10.1007/s10842-021-00356-6,How Do Firms Respond to Reduced Labor Costs? Evidence from the 2007 Swedish Payroll Tax Reform,September 2021,Sven-Olov Daunfeldt,Anton Gidehag,Niklas Rudholm,Unknown,Male,Male,Male,"Unemployment rates and the number of individuals in neither employment, nor education nor training, are high in many European countries—particularly among first-generation immigrants and young adults with low educational attainment (Papademetriou et al. 2010; Bruno et al. 2014). This development is especially troublesome considering the rising unemployment following the outbreak of the COVID-19 pandemic (Fana et al., 2020). Long periods of unemployment may depreciate individuals’ human capital and can be used as a negative sorting criterion when employers recruit personnel (Lockwood 1991). Long unemployment periods may thus cause persistent high unemployment rates among these groups (Phelps 1972; Heckman & Borjas 1980; Arulampalam 2001), with high economic and social costs as a result. In highly unionized economies—such as the Scandinavian welfare states—policymakers have limited influence over minimum wages because they are set in negotiations between employer organizations and trade unions. Policymakers tend, under such circumstances, to rely on job subsidies aimed at groups of job seekers having difficulties in entering the labor market (Martin and Grubb 2001). However, these policies have been criticized because they typically are time-limited and can crowd-out regular jobs (Martin and Grubb 2001; Kluve 2006; Nekby 2008). An alternative way for policymakers to reduce firms’ labor costs is to implement payroll tax cuts, but the efficiency of such reforms has been questioned because insiders may use their bargaining power to increase their wages at the expense of outsiders’ possibility to become hired (Holmlund 1983; Gruber 1997). We investigate the effects of a payroll tax cut of 11.1 percentage points for employees aged 19–25 that was implemented by the Swedish government on July 1, 2007. An important and generally overlooked aspect of the reform was that the payroll tax cut covered all young workers, not only those who were recruited after the reform. Firms that initially had many young employees were thus able to reduce their labor costs substantially due to the payroll tax cut, which means that firms received different doses, or treatment intensities, of the reform based on their number of young employees when the payroll tax cut was implemented. We utilize this firm-level variation in treatment intensity to investigate the effects of the payroll tax reform on the number of employees and total wages of incumbent workers. Previous studies that have analyzed the labor market effects of the Swedish payroll tax reform in 2007 are inconclusive. Egebark and Kaunitz (2013, 2014) and Skedinger (2014), compared the outcomes for young individuals who were targeted by the Swedish payroll tax cut with the outcomes for slightly older individuals who were not subject to reduced payroll tax. Using this methodology, Egebark and Kaunitz (2013) found that 6–10,000 jobs were created within the targeted age group, suggesting that the payroll tax reform had a fairly small effect on employment and was costly in terms of foregone tax revenues. They found, on the other hand, no indications that the lack of major employment effects could be explained by significant wage spillovers to incumbent workers (Egebark and Kaunitz; 2013, 2017). However, the fact that the payroll tax cut gave rise to both a substitution effect and a scale effect is ignored when investigating the effects of the reform on individuals just below and above the age threshold. The substitution effect encourages firms to shift towards a more youth labor-intensive production, while the scale effect incentivizes them to expand their production and therefore to increase the usage of other input factors as well. This finding implies that firms might also have spent some of their labor cost savings on recruiting nontargeted individuals, e.g., older and more experienced individuals. The total employment effect can thus differ from the effects previously found for the targeted group of young employees versus slightly older, noneligible employees. Egebark and Kaunitz (2017) and Saez et al. (2019a) are two recent studies that have acknowledged the link between firms’ labor cost savings and the number of young employees at the time of the reform implementation. However, both studies used relative treatment intensity measures, while we rely on a treatment intensity measured in absolute terms. We believe this distinction to be important because firms’ labor cost savings do not strictly increase with relative treatment intensity measures. For example, if using a relative measure, an employer with three out of four employees below the age of 26 will be defined as being more exposed to the reform than a firm with 20 young employees out of a total of 50 employees even though the latter firm experiences a substantially larger labor cost reduction in monetary terms following the payroll tax cut. We argue that the largest effect of the reform is likely to be for those firms that receive labor cost savings covering a large part, or even the whole cost, of any additional employees. We thus use the labor cost saving per firm at the time of the payroll tax cut as our treatment intensity measure. We construct five equally sized quantiles across the distribution of firms’ labor cost savings to investigate if the effect of the reform depends on the treatment intensity dose. A potential concern with our approach is that the size of labor cost savings and firm size are positively correlated, which induces the risk of differences in firm size biasing the estimate of the employment effect because large firms tend to grow more in absolute terms than small firms (Henrekson and Johansson 2010). To handle this potential source of bias, we rely on a firm-level difference-in-difference-in-differences (DDD) model. In contrast to ordinary difference-in-difference (DiD) estimation, the DDD model eliminates any underlying bias caused by differential trends in absolute employment growth between the treatment and control groups. Our study contributes to a small but growing literature that takes into account firms’ labor cost savings of payroll tax reforms. Cottet (2020), for example, investigated a payroll tax cut for minimum wage workers in France, finding that firms with many minimum wage workers primarily increased their number of employees with higher wages. Ku et al. (2020) analyzed the employment effects when geographically based payroll taxes in Norway were suddenly abolished and found a significant reduction in local employment where firms received a payroll tax hike. When investigating a regional payroll tax reform in Finland, Benzarti and Haju (2020) found that firms who received a payroll tax cut became more resilient towards recessions compared to similar firms that were located in regions that did not receive any payroll tax cut. Overall, these studies seem to imply that employment effects of payroll tax reforms are stronger if they are targeted towards firms rather than individuals (see also Saez et al., 2019a, 2019b; Cottet, 2020). We find that 80% of all treated firms saved less than 60,000 SEK annually ($6,480)Footnote 1, suggesting that most firms experienced fairly modest decreases in their labor costs following the Swedish youth payroll tax cut in 2007. This finding might explain why most previous studies have found relatively small employment effects from the payroll tax reform. We do, however, observe a large variation in labor cost savings across firms, and we find that employers who received a large treatment intensity dose increased their number of employees significantly more than employers who received a low treatment intensity dose. More specifically, we find that the average firm within the >0–20 % treatment intensity interval of the labor cost savings distribution recruited an additional 0.13 employees following the youth payroll tax cut. The corresponding figures for firms within the >60–80 % and >80–100 % treatment intensity ranges amount to 0.38 and 0.90 employees, respectively. We also find that the payroll tax cut mainly is associated with an increased number of employees within the targeted age group (19-25 years of age). However, we find some indications that employers also increased their recruitment of older individuals, implying that the immediate labor cost savings created by the reform also had a positive yet small employment effect outside the targeted age group. We conclude that the employment effect of the 2007 Swedish payroll tax reduction is strongly contingent on the size of firms’ labor cost savings, and it is therefore primarily determined by the prereform age composition of firms’ personnel. In total, we estimate that the reform created 18,100 new jobs. We also find indications that the number of work hours increased among incumbent employees who are working at firms with small labor cost savings, while we find the opposite results for those working at firms that received large labor cost savings. Our interpretation is that nontargeted incumbents’ work tasks at firms receiving a high treatment intensity dose partly have been overtaken by those younger employees that were targeted by the reform. The outline of this paper is as follows. The next section describes the 2007 Swedish payroll tax reform and provides main findings from previous evaluations. Section 3 includes a description of our data, and our treatment intensity measure, and presents descriptive statistics, while our empirical methodology is explained in Section 4. The empirical findings for how the reform affected firm-level employment and wages are presented in Section 5. Lastly, Section 6 summarizes our results and concludes the paper.",2
21.0,3.0,"Journal of Industry, Competition and Trade",31 March 2021,https://link.springer.com/article/10.1007/s10842-021-00358-4,"R&D Characteristics, Innovation Spillover, and Technology-Driven Business Cycles",September 2021,Uluc Aysun,Zeynep Yom,,Unknown,Female,Unknown,Female,"The past five decades of evidence has revealed that research and development (R&D) plays a critical role in productivity growth and the overall growth of economies (c.f. Griliches 1973). This inference, now a stylized fact, originating mostly in the growth literature, has also influenced research on short-term macroeconomic dynamics as studies have analyzed the fluctuations of R&D, and the implications for productivity, along the business cycle. The findings for the cyclicality of R&D in this literature are inconclusive. While some studies (Aghion and Saint-Paul 1998; Aghion et al. 2012) find that R&D is countercyclical, others (Himmelberg and Petersen 1994; Hall and Lerner 2010) find otherwise. These studies are also different in terms of the main factor that generates R&D cyclicality. Regardless of these differences, the direction of casuality in all these studies is from the stage of the business cycle to R&D spending. In this paper, we approach the subject from the opposite direction and investigate how R&D activity affects business cycles generated by technology shocks. In particular, we determine the characteristics of R&D processes for which technology shocks have the biggest impact on economic output and labor markets. In so doing, we focus on the diffusion and adoption of innovation (the output of the R&D process) across firms, the market power of firms engaging in R&D activity, and R&D adjustment costs as the four key determinants of technology shock propagation. We incorporate these four characteristics and various other features of R&D inferred from microdata into a general equilibrium model. The model is a two-tier, vertically related, industrial system consisting of innovators and intermediate good producers in which innovation not only passes-through within an industry but also across industries. The inter-industry transfer of technology occurs through both embodied and disembodied technologies. The innovators sell input goods to intermediate goods producers. These input goods embody the improvement in technology that is a product of the innovators’ R&D activity. At the same time, intermediate good producers directly adopt the disembodied technologies from innovators. These adopted technologies complement the intermediate goods producers’ existing R&D process and allows them to increase their own efficiency in producing the input good. This internal production is larger than the external purchases of input goods. To visualize our model, imagine a producer, say Apple, hires engineers and scientists to develop software and conduct R&D type activities while at the same time outsourcing some of the software development to technology companies such as Infosys. The downstream spillover of innovation (from Infosys to Apple) then can work through Apples’s purchases of the new software or by Apple directly adopting innovations from Infosys (for example, the ability to input data into a hand-held device when a retailer sells a product). The question we are interested in here is how a company such as Apple reacts to an increase in the rate of successful innovations by a company such as Infosys? Does it adopt the new technologies or does it outsource a larger fraction of software development to the now more efficient technology producer, Infosys? More central for our paper, how do these decisions and inter-industry linkages affect the response of overall economic activity to technology shocks? Examining the effects of a technology shock that originates in the innovators’ production process, we find a larger output response, yet a decline in overall R&D activity when, at steady state, innovations are transferred more rapidly from innovators to intermediate goods producers. The reason is that intermediate goods producers substitute externally purchased input goods with internal goods as they become more efficient at input production. Since internal production constitutes the largest share, this increase in efficiency generates a larger positive response of intermediate and final goods. The decrease in the price of innovators’ output due to lower demand from intermediate goods producers decreases the returns to and the level of R&D by innovators. Also, higher technology adoption by intermediate goods producers curbs their need for internal R&D and thus overall R&D activity declines. These results are reversed when inter-industry innovation spillover is weaker. There are several inferences here. First, the main channel through which technology shocks propagate is through technology adoption (disembodied technology) and not through inputs that embody the new technologies. Second, to the extent that business cycles are driven by technology shocks, higher spillover across industries can increase the amplitude of business cycles (boosting expansions and increasing the severity of recessions). Third, R&D becomes countercyclical as the rate of spillover across industries increases. A positive technology shock that increases output, therefore, can restrain the ability to create new technologies if the technology shock spreads very rapidly. Finally, the positive technology shock also prompts labor to migrate away from innovative activities to intermediate and final goods production. One feature of R&D that has been put under great scrutiny is the level of competition amongst innovators. Studies, some of which we discuss below, have attempted to determine how R&D spending and rate of innovations depend on innovators’ market power. As a second exercise we, therefore, investigate this feature of R&D. Increasing the market power of innovators produces results that are similar to those obtained by increasing the rate of spillover. When innovators are less competitive, they restrict the production of the input good and charge a higher price relative to the baseline scenario with more competition. This results in a lower level of R&D by innovators and innovation spillover to intermediate good producers. Although this increases intermediate good producers’ R&D, labor demand, and input production, the weaker spillover and lower labor efficiency mitigate the positive output response. Similar to simulations under high innovation spillover, the economy becomes less volatile under a monopoly but it also engages in less innovative activities and the labor force shifts away from innovators to intermediate goods producers. We incorporate two other realistic features of R&D to gain further insights from our model. First, we assume that firms incur costs when changing the level of R&D. We then test how the economy responds to a technology shock when these costs are low. Although there is a disagreement in the literature (see below) about the size of these costs (especially in relation to physical capital adjustment costs), according to firm-level observations, they are nontrivial. Second, we assume that intermediate goods producers incur costs when adopting new technologies from innovators. By contrast, they pay no cost when adopting in-house innovations. Our findings indicate that if firms pay a lower cost to adjusting R&D, the amplitude of overall R&D spending and output increases. Output is also more responsive to shocks when adoption costs are lower. The increase in overall R&D activity, however, is more subdued relative to the baseline case since intermediate goods firms, in response to higher labor efficiency, lower their demand for input goods from innovators. They instead produce these goods internally. The lower demand for input goods decreases innovators’ labor demand and R&D spending. These results imply that if innovation is successfully transferred between industries either, due to a more rapid spillover rate or due to lower adoption and adjustment costs, technology shocks generate a larger positive response of output yet a smaller positive response of R&D activity. We find that the above characteristics of R&D are most impactful for technology shocks that originate in the innovation industry as opposed to those that originate in the intermediate goods industry. Using these shocks we also conduct a welfare analysis. This analysis shows that welfare costs are higher in an economy that has lower innovation spillover, higher adjustment and adoption costs, and less competition in the innovation industry relative to that under the benchmark calibration. In this exercise, we keep the steady-state growth rate of the economy constant. When we allow the balanced growth rate of economy to change with R&D intensity, we observe a trade-off between welfare costs and economic growth. The additional welfare costs due to higher R&D activity, however, are small compared to the gains in economic growth. In the high-growth-high-R&D economy, for example, while the households are willing to give up 2.2% more of their annual consumption to avoid volatility (relative to the baseline case), their consumption grows 3% more than it does along the baseline balanced growth path on a quarterly basis. Our methodology is similar in spirit to those that identify the cyclicality of R&D and productivity along the business cycle and explain the productivity slow-down following the 2008 crisis (e.g., Fernal 2015; Queralto 2019; Christiano et al. 2016; Bianchi et al. 2019; Anzoategui et al. 2019). Some components of the R&D process in our model, for example, follows the structure in Bianchi et al. (2019) and the basic dynamic stochastic general equilibrium (DSGE) framework is similar to Anzoategui et al. (2019).Footnote 1,Footnote 2 Yet our approach is fundamentally different in several ways. First, as mentioned above, we investigate the effects of R&D and R&D spillover on the business cycle, in contrast to the studies above that take the opposite direction. We should mention here that our paper is not the only one that has taken this direction. Earlier studies such as Comin and Gertler (2006) and Kung and Schmid (2015) have analyzed the effects of R&D and innovation on the persistence of business cycles and growth of economies. These papers, however, are very few in number and they are different in scope and methodology compared to our analysis. Second, we deviate from the studies mentioned above by incorporating vertically related industries into our model. This allows us to capture the business cycle effects of innovation spillover across industries. Third, our model represents a real economy without the nominal rigidities in a standard New-Keynesian framework, a framework that is used by most of the studies mentioned above. The model also includes endogenous growth which allows to incorporate growth-enhancing characteristics of R&D and innovation. To the best of our knowledge, there have only been few attempts at merging endogenous growth with a DSGE framework (e.g., Bilbiie et al., 2008, 2012, 2014). The relationship between endogenous growth and R&D in our model allows us to determine the volatility implications of R&D-driven growth. We find that higher growth due to higher R&D is associated with higher economic volatility. While this finding goes against the common negative relationship in international data (e.g., Ramey and Ramey 1995; Aghion et al. (2005a, 2005b), we find that the welfare costs of the higher economic volatility are very small compared to the gains from higher growth.Footnote 3 The more central contribution of our modeling approach is that it allows us to reconcile two seemingly detached features of R&D. R&D is strongly related to business cycles yet it is a relatively smooth form of expenditure (especially compared to investment). We show that it is not the overall level of R&D activity but the cross-industry spillover of R&D-driven innovations that drives business cycles. Our paper is mostly motivated by evidence for higher rate of innovation spillover that has emerged in the past two decades. Studies such as Azoulay (2004), Cassiman and Veugelers (2006), Chesbrough (2003), Knott (2017), and Higon (2016) find/show a positive trend in the outsourcing of R&D (also referred to as open innovation). While the scope and the quantitative findings of these studies are different, they unequivocally point to an increasing rate of innovation spillover and the adoption of external technologies.Footnote 4 In order to draw general macroeconomic inferences from our model, we assume symmetry across firms. We should note, however, that the degree of R&D spillover can vary across firms. In Aldieri et al. (2018) for example, the degree of R&D spillover through knowledge absorption depends on how close firms are to the technology frontier. Similarly, Orlando (2004) finds evidence that the degree of spillover could be related to the firms’ geographic location and industry. The findings in this literature also show that knowledge spillover can have positive effects on firm productivity (Aldieri et al. 2020; Audretsch and Belitski 2020) and that amongst different types of innovations, product innovation and R&D innovation have the most positive effect on spillover (e.g., Zhao et al. 2019). Micro-evidence also reveals several other characteristics of R&D. Studies such as Foster and Grim (2010) and Foster et al. (2016) for example show, using US data, that R&D is mostly conducted by large firms that have sizeable production processes in addition to R&D type activities. This is the reason both types of firms in our model, intermediate goods producers and innovators, do both R&D and production at the same time and they have market power. We should however mention that there are opposing views on how market power affects R&D and innovation.Footnote 5 In our analysis, we address these different views by investigating how our results depend on market power. R&D adjustment costs play a critical role in our model as they directly determine how smooth R&D is. While there is a general agreement that adjusting R&D is costly, it is less clear how big these costs are, especially with respect to physical capital adjustment costs. On the one hand, studies such as Brown and Petersen (2011), Hall et al. (2016), and Aysun and Kabukcuoglu (2019) favor high adjustment costs as they argue that high fixed costs (setting up a lab for example) and knowledge input is insensitive to short-term fluctuations and thus R&D expenditures are smoothed across the business cycle. On the other hand, studies such as Saint-Paul (1993), Comin and Gertler (2006), Rafferty and Funk (2008) find that R&D is more volatile implying that adjustment costs may be low. Some of the explanations for this result are that since R&D conducting firms are dependent on external finance and R&D is a risky activity, firms face more difficulty in funding R&D and they are more likely to shed these risky activities during economic downturns.Footnote 6 The application and evidence for technology adoption costs mostly come from the international trade literature. Bustos (2011), Yeaple (2005), and Bresnahan et al. (2002), for example, argue/find that there are fixed costs to adopting external technologies such as costs of IT and general employee training and organizational restructuring. It is, therefore, critical to address these issues related to R&D. This is what we do in Section 3. In so doing, we use different calibrations to determine how our results depend on the level of adjustment and adoption costs.",2
21.0,3.0,"Journal of Industry, Competition and Trade",19 April 2021,https://link.springer.com/article/10.1007/s10842-021-00361-9,The Dynamics of Firm Growth in Sub-Saharan Africa: Evidence from Ethiopian Manufacturing Sector 1996–2017,September 2021,Kahsay Gerezihar Tsaedu,Zhihong Chen,,Unknown,Unknown,Unknown,Unknown,,
21.0,3.0,"Journal of Industry, Competition and Trade",20 April 2021,https://link.springer.com/article/10.1007/s10842-021-00360-w,List Price Collusion,September 2021,Willem H. Boshoff,Johannes Paha,,Male,Male,Unknown,Male,"Many firms set prices using a two-stage process: firms first set list prices and then negotiate discounts with (some) buyers in a subsequent stage. Two-stage price setting may render collusion more difficult: for example, the efficacy of colluding on list prices is not evident if the conspirators offer non-coordinated discounts off the list price. This article investigates the conditions under which agreements on list prices can result in higher transaction prices for customers not purchasing at the list price, even if there are no additional agreements on limiting discounts. A prominent recent example of list price collusion relates to a cartel among six producers of trucks in the EU, who had exchanged information about the gross list price of trucks, informed each other of their planned gross price increases, and agreed upon harmonizing the list prices over the period 1997 to 2011.Footnote 1 In 2016/2017, the European Commission imposed its hitherto largest fine, i.e., 3.8 bn EUR, on the cartel. In the USA, list price collusion received attention as early as the 1970s, with Hay and Kelly (1974) presenting a range of examples, suggesting that list price collusion was a prevalent phenomenon at the time of their study. Our article adds to the case study literature on collusion (for example, Grout and Sonderegger 2005; Harrington 2006; Herold and Paha 2018) by presenting evidence of list price collusion. We review economic features of cases decided by competition authorities and courts both in Europe and the USA to emphasize the relevance of list price collusion and to highlight that this practice deserves greater attention in the economics literature.Footnote 2 To characterize agreements on list prices, we distinguish between full collusion, which involves coordination across both stages of price formation (i.e., the explicit fixing of both list prices and discounts), and pure list price collusion, where the firms only agree on list prices (i.e., the coordination is limited to the first stage of pricing). Agreements on list prices pose a challenge to assessing their economic effects. In both U.S. and European cases, the conspirators have defended their conduct arguing that a conspiracy on list prices, which does not involve agreements on a maximum admissible level of rebates, needs not be effective because any list price increase would have been offset by higher rebates. For example, in the context of the European thread cartel, where the firms had conspired on list prices but also on maximum admissible rebates, one company contended that “list prices have more of a political importance than a competitive one.” Another firm held that “the list price increase did not mean that the actual net prices achieved in the relevant market also rose” and that “[c]ustomers are almost never charged the list prices.”Footnote 3 These challenges matter for practice. Though price fixing is considered anticompetitive by object in many jurisdictions, the circumstances under which agreements on list prices influence the market is important to competition practice, for example, in the context of follow-on damages claims. In damages cases, buyers must demonstrate a causal link between the infringement by producers and the associated harm to buyers. The claimants of damages often find it easier to sue if they can already build on a theory of harm established by a competition authority. Yet, in both the trucks and thread cartel cases, the European Commission remained vague when it came to presenting a theory of harm.Footnote 4 In the trucks case, it argued that the “exchanges, at least, put the [firms] in a position to take account of the information exchanged for their internal planning process and the planning of future gross price increases for the coming calendar year. Furthermore, the information may have influenced the price positioning of some of the [firms’] new products.”Footnote 5 Similarly, by “exchanging EEA-wide applicable gross price lists, [the firms would have] been in a better position to understand from the price increase information […] each other’s European price strategy, than they would have been solely on the basis of the market intelligence at their disposal.” The European Commission concluded that by “exchanging current gross prices and gross price lists, combined with other information gathered through market intelligence, the [firms] were better able to calculate their competitors’ approximate current net prices”.Footnote 6 Similarly, in the industrial thread case, the European Commission asserted vaguely that “increasing list prices automatically had an influence on the level of the actual prices. Even if there was no general fixed amount of rebates, the list prices had a target function and served as a starting point for discussion, as well as an indicator from which a percentage discount could be deducted. Consequently, they necessarily had at least a potential and even a likely influence on actual prices.”Footnote 7 The article does not provide new regression results or a formal model. Its purpose is to contextualize the practice of list price collusion by providing a structured summary of the circumstances and cases that support various theories of harm related to list price agreements. We also place the topic in the context of the related literature in empirical, experimental, and theoretical economics (e.g., Harrington 2011), as well as marketing, and behavioral sciences. The information gleaned from the cases and the literature suggests that list price collusion may be effective, especially in the presence of behavioral effects and asymmetric information. The article may therefore also be informative to researchers in the emerging field of behavioral industrial organization (see Grubb and Tremblay 2015 as well as HeidhuesKöszegi 2018 for an overview) about market conduct that is worthwhile being studied in greater detail. The article identifies key gaps in the literature to assist in the development of improved models of list price collusion as are currently being devised, for example, by Harrington (2020) or Paha (2020a, b). A similar methodological approach as ours, which relies on putting theory in the context of evidence, was taken, for example, by Baker and Salop (2015) in their study of the relationship between antitrust and inequality. By focusing on behavioral effects, our analysis serves the function outlined by Reeves and Stucke (2011), helping to explain “how actual, real world evidence that contradicts (or is unexplainable under) a neoclassical economic theory may nevertheless be insightful in understanding whether conduct is pro- or anticompetitive.” The article is structured as follows. Part 2 presents cases that document the dispute whether list price collusion can raise transaction prices at all if it does not involve additional agreements on eliminating discounts. Part 3 introduces evidence of list price collusion that involved additional agreements on eliminating discounts. The main insights are presented in Part 4 where we study the conditions under which list price collusion can result in higher transaction prices for customers not purchasing at the list price, even if there are no additional agreements on limiting discounts. We show that higher list prices lead to higher transaction prices, by serving as starting points for the negotiations between sellers and buyers. Part 5 concludes.",8
21.0,3.0,"Journal of Industry, Competition and Trade",24 April 2021,https://link.springer.com/article/10.1007/s10842-021-00363-7,Note on Excess Capacity in a Monopoly Market with Network Externalities,September 2021,Tsuyoshi Toshimitsu,,,Male,Unknown,Unknown,Male,"Theoretical and empirical studies of the relationship between market structure and excess capacity are important in the fields of industrial organization and competition policy. It is well known that maintaining excess capacity plays an essential role as a strategic device in an oligopoly market. In particular, it has been found that firms maintain excess capacity to make their rivals reduce output levels or to deter market entry. Thus, excess capacity exists in a pure oligopoly market where profit-maximizing firms compete with each other (emphasis added).Footnote 1 If so, can excess capacity arise in a pure monopoly market where there are no competing firms and no entries? The answer is that, in standard industries, it cannot. The purpose of this paper is to examine whether excess capacity results hold in the case of a monopoly market associated with network externalities, i.e., a network product and service market, such as electricity, railway, telecommunications, cable TV, and others. Using a capacity-then-production choice model, we consider how network externalities and the timing of consumer expectations affect the capacity-scale decision by a monopoly. In particular, we focus on the following points: players in the games are both owners of a monopoly (private firm) and consumers, and thus, the timing of consumer expectations of network sizes plays an essential role.Footnote 2 In a capacity-then-production choice model, forming expectations either before or after the capacity-scale decision affects the decisions of the monopoly. Furthermore, if a pure monopoly market implies that there are no competing firms and no entries, in other words, there is only one supplier (provider) in the market, we would examine the case of a public firm owned by the government deciding both the production quantity and capacity scale to maximize social welfare. In particular, the research question is “does the public firm hold excess capacity?” The following papers consider the relationship between the timing of consumer expectations and firms’ investment decisions. Boivin and Vencatachellum (2002) examined how network externalities affect cost-reducing R&D investments in a homogeneous duopoly. It is assumed in their model that consumers form their expectations before the R&D investments. Naskar and Pal (2020) considered process (cost-reducing) R&D investments in horizontally differentiated Cournot and Bertrand duopolies and compared the Cournot and Bertrand equilibria. In their model, they assumed that consumers form their expectations after the R&D investments. In our model, in which a supplier provides a network product, as mentioned below, we examine two cases of the timing of consumer expectations, i.e., before and after the capacity-scale decision, and compare their results. We demonstrate that whether excess capacity arises in a monopoly market depends on the timing of consumer expectations. Then we investigate the case of a public firm and find that excess capacity does not arise in the first-best policy, irrespective of the timing of consumer expectations. However, this result depends on the specification of the utility function associated with network externalities.",
21.0,3.0,"Journal of Industry, Competition and Trade",24 April 2021,https://link.springer.com/article/10.1007/s10842-021-00353-9,Technology Spillovers Through Exports: Empirical Evidence for the Chinese Case,September 2021,João Gabriel Pio,Eduardo Gonçalves,Claúdio R. F. Vasconcelos,,Male,Unknown,Mix,,
21.0,3.0,"Journal of Industry, Competition and Trade",06 May 2021,https://link.springer.com/article/10.1007/s10842-021-00364-6,The Nonlinear Relationship Between Firm Size and Growth in the Automotive Industry,September 2021,Claudiu Tiberiu Albulescu,Matei Tămășilă,Ilie Mihai Tăucean,Male,Male,Male,Male,"The relationship between firm size and growth is explained by Gibrat’s (1931) theory and the so-called law of proportionate effect, which shows that in the short run, the firms’ growth rate is independent of their size. The subsequent theories and empirical studies posit, however, that small firms record different growth patterns compared with large companies (for a survey of these theories, please refer to Coad 2009). Early studies (e.g. Hart 1962; Singh and Whittington 1975; Hart and Oulton 1996), conducted on the United Kingdom (UK) manufacturing sector, show that large firms grow fast because the survival does not represent their main objective. Thus, large firms might accept a trade-off between growth and profit and look for a decentralized structure that generate an increase of investment’s level and employees’ number. In addition, these firms are “managerially dominated” (Singh 1975) and, in contrast to the small, owner-controlled firms, they are willing to grow for strategic reasons. Therefore, early empirical works conducted on a cross-sectional basis underline the positive relationship between firm size and growth. A concurrent strand of the literature sustains on contrary that small firms are forced to grow faster compared with their larger counterparts. In this line, the theoretical framework by Jovanovic (1982), called the “passive learning” model, shows that the small firms’ growth rate is constrained by their productivity level. Given the fact that they compete with large companies, small firms expand rapidly and there is no contradiction between their growth and profitability level, on contrary. Therefore, firms’ profit sustains their growth. In addition, under the “active learning” model of Pakes and Ericson (1998), small firms boost their productivity by investing in research and development (R&D) activities. Moreover, the growth of small firms is supported by policy interventions, which is not the case for large firms. The paper by Hall (1987) represents one of the first empirical works that rejects Gibrat’s (1931) law for small firms, but not for large firms. This result is confirmed by Evans (1987a) and Evans (1987b), stating that in the case of the United States (US) manufacturing firms, the size matters for firm growth, but this relationship is nonlinear. The empirical studies approach the relationship between firm size and firm growth in two concurrent ways. A first strand of the literature analyses is the nexus between size and growth, considering the growth level. In this line, Yasuda (2005) document a negative impact of firm size on growth in the case of Japanese manufacturing firms, providing thus evidence in favour of Gibrat’s (1931) law. This result is confirmed by Das (1995) for a set of Indian companies from the computer hardware industry. On contrary, using an unbalanced panel data approach, Yadav et al. (2020) reject Gibrat’s law for a large set of Asian companies. A second strand investigates the relationship between firm size and the volatility of their growth ratios (e.g. De Fabritiis et al. 2003; Maria Moreno et al. 2014; Calvino et al. 2018), and generally shows that the relationship between growth volatility and firm size is negative. This means that large companies record smaller fluctuations in their growth level. For example, Calvino et al. (2018) underline the existence of a common mechanism that explains the connection between firm size and growth, whereas Fariñas and Moreno (2000), Pfaffermayr (2007) and Zou (2019) show that the growth of firms is positively influenced by their age. Nevertheless, the relationship between firm size and growth is specific to each industry. Furthermore, this relationship is nonlinear, and its intensity might depend on the growth level of firms (Capasso and Cefis 2012). Therefore, our paper contributes to the existing literature in several ways. First, we posit that the impact of size on firm growth is not only different between small and large firms, but it is also asymmetric, being influenced by firms’ growth level. More precisely, we show that size is less important for firms that grow faster. The strategic management decisions (i.e. in terms of capital structure) and firms’ performances are essential in this case; regardless, we refer to small or large firms. To this end, we implement the fixed effect quantile panel data approach by Canay (2011), in order to show the varying effects of size on firm growth. Although quantile approaches were previously used to test the link between firm size and exports (e.g., Hernández 2020), this is the first paper considering the nonlinear relationship and the particularities of companies within a panel framework, resorting thus to a fixed effect estimator in quantiles. Canay’s (2011) approach has several advantages over the similar methodologies proposed by Koenker (2004), Lamarche (2010), Galvao (2011) or Rosen (2012). It allows for the parameter identification when the temporal dimension of the panel is fixed, whereas the fixed effects are considered as local shift variables. In addition, Canay’s (2011) approach relies on a two‐step estimator which is relatively simple to compute.Footnote 1 Second, we estimate the firm growth as the growth rate of tangible assets. That is, we use the perpetual inventory method (PIM) to compute the capital stock and to assess the firm’s capital dynamics. We consider that the investment dynamics is the primary measure of firm growth, which boost in a second phase the dynamics of employees and total assets. For robustness purpose, in line with most previous papers, we use the sales as a proxy for the firm growth level, whereas the number of employees is used as a proxy for firm size. Third, we focus on a specific industry and on companies located in the Timis region of Romania. More precisely, we consider the case of the automotive industry (“Manufacture of motor vehicles, trailers and semi-trailers”—NACE code 29), which is very dynamic and represents the engine of the economic activity in this region. Therefore, we conduct a panel data analysis for 19 firms for the period 2006 to 2015, using AMADEUS statistics. Focusing on a narrow industry is essential to obtain a correct picture of the relationship between firm size and growth (Hall 1987). Furthermore, the focus on the automotive industry from the Timis region represents an interesting case study at least for two reasons. On the one hand, the automotive industry represents the most developed and dynamic industry within the region. Therefore, the interest of authorities in understanding what drives the firm growth within this sector is high. On the other hand, the automotive industry records noteworthy changes all over the world, which requires adaptation and optimal investment strategies. Therefore, more insights about the relationship between firm size and growth has important implications for international investors acting in the automotive sector. Fourth, we search for the role of agglomeration effects in influencing the growth—size nexus. That is, as a robustness check, we retained in a second step in our sample only the companies located in Timisoara—the main city within the region, which is in the same time the third largest city in Romania. Fifth, we isolate the effect of firm size on growth, considering a set of control variables. Firms’ age represents a common control variable in similar analyses, but this information is not available in the database we use. This is also the case of firm exports (see, for example Battaglia et al. 2018; Hernández 2020). Therefore, in line with other studies, we control for the effect of R&D activities. As Coad and Rao (2008), Goedhuys et al. (2016), Corsi et al. (2019) and Yuan and Nishant (2019) state, innovation is essential for firm growth. We also look to the role of firms’ financial performances in sustaining their growth. Carpenter and Petersen (2002) underline that firm growth is conditioned by financial constraints, especially in the case of small businesses. In addition, profitability is considered the basis of investment and influences its structure (Almeida et al. 2011; Datta and Agarwal 2014; Albulescu 2020). That is, the profitability is even more important for firm growth in the case of financially constrained firms (Farla 2014; Mata 1993; Vermoesen et al. 2013). At the same time, liquidity sustains the investment especially during and after financial crisis episodes (Albulescu et al. 2018). However, as Baum et al. (2008) show, the role of liquidity is controversial in sustaining firm growth if precautionary reasons encourage cash holdings. Finally, in line with corporate governance literature, we want to know if the asymmetric response of firm growth to their size is influenced by the chief executive officer’s (CEO) gender and by the nationality of the CEO. It is well known that women CEOs ensure a higher equilibrium in the decision-making process, women being more averse to risk-taking decisions (Marques 2015). At the same time, according to the organization theory, the CEO’s experience and independence in making decision influences firm performances and consequently their growth level (Donaldson and Davis 1991; Jiraporn et al. 2018). The outline of our research is as follows. In Sect. 2, we describe the automotive industry from the Timis region (Romania), and we discuss the research hypotheses. Section 3 presents the data, general statistics and Canay’s (2011) methodological approach. Sections 4 and 5 show the main empirical findings and the robustness results, respectively. The last section concludes and debate on the results’ implications for the management decision.",3
21.0,4.0,"Journal of Industry, Competition and Trade",27 April 2021,https://link.springer.com/article/10.1007/s10842-021-00362-8,Why Abandon the Paradise? Stations’ Incentives to Reduce Gasoline Prices at First,December 2021,Thomas Wein,,,Male,Unknown,Unknown,Male,"The price development at German filling stations is characterized by a high degree of price fluctuations. There are strong ups and downs of prices within 1 day. For example, the development of prices in Lueneburg can be traced using data from the Bundeskartellamt’s Market Transparency Office. Figure 1 shows the price reports for premium gas (E5) from four selected petrol stations active in the Lueneburg town area as they were issued on 31 March 2019. The numbers represent the prices set by service stations 1, 4, 5, and 6 on that day, based on the price announcements made by the respective service stations to the Market Transparency Office (Appendix Table 19). In the figure, it is easy to see that, especially in the period between 6 a.m. and 6 p.m., prices are repeatedly raised, only to respond again with price concessions within a short time thereafter. The question remains as to why suppliers who have worked their way up to a higher price level are prepared to leave the high level. In particular, if the development repeats itself within a day and over the days, why don’t suppliers learn from it and stay at high prices? Why do they voluntarily give up the price paradise?
 Prices in Lueneburg—4 stations, 03/31/2019, Premium Gas E5. 1, Shell, Universitaetsalle; 4, Aral, Dahlenburger Landstraße; 5, LTG, Dahlenburger Landstraße; 6, Esso, Bleckeder Landstraße The theoretical background for price cycles is fundamentally based on the work of Maskin and Tirole (1988). Two suppliers competing exclusively on price set their prices alternately. Only the price of the current period is relevant (Markov-strategies). If prices are set for a certain period in line with marginal costs, a war of attrition develops. One company hopes that the other loses his nerve, relents, and is the first to raise prices again. After one company increases the price (jump), the other follows with his price increase, but remains slightly below the first company’s price. All the demand goes to the cheaper supplier. The too expensive supplier reacts by slightly undercutting its competitors. The now too expensive supplier also responds with price undercutting. At the end of the mutual undercutting phase, both suppliers have returned to their marginal costs. Then, a war of attrition, jump, and undercutting will start anew again. Noel (2008) extended this approach to three companies fighting price wars with each other. Once again, there are attrition wars, price jumps, and mutual undercutting. There are new possibilities that the subsequent price increases will be delayed (delayed starts) or even cancelled due to a lack of imitators (false starts). Stochastic price movements of input prices can influence the manifestations of cycles. Edgeworth cycles have been empirically proven in many industrialized countries; especially the most recent work on the individual countries is presented below. Australia has recently demonstrated cycles, although, in one federal state, the rule is that petrol station prices must be kept constant for 24 h (Byrne and De Roos 2019; De Roos and Katayama 2013; Wang 2009a, b; Wills-Johnson and Bloch 2010). At Canadian petrol stations, there are many confirmatory indications found by evaluating long-term data at the local level (groundbreaking Noel 2007a, b; Atkinson 2009; Atkinson et al. 2014; Byrne et al. 2015). In Germany, data from the Market Transparency Office have been used in recent years to find corresponding cycles based on daily average price data at defined hours (Eibelshäuser and Wilhelm 2017; Haucap et al. 2017a; Siekmann 2017). In two Scandinavian countries, Norway and Sweden, the results for local petrol markets also point to the existence of Edgeworth cycles (Foros and Steen 2013; Nguyen and Steen 2018). The USA has the longest tradition of empirical testing for the existence of Edgeworth cycles, with confirming results available from the past decade (Doyle et al. 2010; Lewis 2012; Lewis and Noel 2011; Zimmerman et al. 2013). The well-confirmed Edgeworth cycles explain price reductions as reactions to price undercutting by one or two competitors, but they cannot explain why petrol stations reduce prices when their competitors charge almost the same prices. It has been known for some time that powerful petrol stations are raising prices more and are unwilling to lower prices later (Borenstein and Shepard 2002; Deltas 2008). Sharply rising petrol prices can especially be observed when crude oil prices or wholesale prices go up; however, declining purchase prices are only slowly passed on to end customers. Prices rise like a rocket but fall like a feather. This “rocket-feather-relationship” was first documented by Bacon (1991), and later confirmed by Galeotti et al. (2003), and again by Verlinda (2008). Bremmer and Kesselring (2016) have recently added to this by checking whether falling cost prices during the global economic crisis in the thirties of the last century led to a contrary trend (known as “balloons and rocks”). Price cuts are thus a delayed response to falling input prices. Since input price fluctuations play a very small role in the intraday cycles under consideration, this explanatory approach is unlikely to be relevant for this paper. One would tend to expect that rising search costs among petrol consumers would make it more difficult to compare prices at petrol stations and that stations could charge excessive prices. The easier prices can be compared, the more stable the prices will remain. Thus, there will be fewer price reductions (Chandra and Tappata 2011). Byrne and De Roos (2017) show that in times of increasing price differentials, information media with price information from petrol stations are used more frequently in corresponding websites. Haucap et al. (2017a, b) interpret the developments in German petrol price cycles as an indication of easier search activities by German final customers through information apps that provide current price data on the basis of the Market Transparency Unit (MTU). In summary, simplified search activities would increase price volatility and thus make price reductions more likely. Since search activities will hardly change within 1 day, this approach cannot be tested in this paper. Recently, Byrne and De Roos (2019) turned its attention to the question of how the uniform behavior of petrol station owners arises. It is therefore not the question of whether the petrol price development follows due to tacit collusion or Edgeworth cycles, but how novel price cycles are initiated. For this, they use price data from more than 600 petrol stations over a 14-year period. Due to the West Australian price rule that applies throughout this period, all petrol stations must announce the daily petrol prices on the previous day and are bound to this price for 24 h. Due to the unusually long data set, more than 1.5 million price data are available. Supply shocks—such as natural disasters, or market entry in the petrol station market—also occurred during this time. As a result, the authors can describe relatively precisely how a change from one cycle form to another occurred. Neukirch and Wein (2019) also use local data from medium-sized cities and large German metropolises to classify brand-specific price markups in the German Edgeworth cycles, which are run several times a day using the Lerner index. The entirety of their cycles is not the object of investigation in either approach. Instead, the dynamics within the cycle (Neukirch and Wein 2019) or between the cycles (Byrne and De Roos 2019) are the focus. Applying general microeconomic considerations, a petrol station is even more likely to reduce its price if the revenue gain from falling prices outweighs the revenue losses caused by the price reductions. Falling prices could therefore be associated with the hope of attracting additional demand. Since many petrol stations offer additional services such as shops, ATMs, toilets, car washes, bistros, baking stations, or vacuum cleaners, they have a great interest in encouraging as many customers as possible to refuel at their petrol station. Lowering the price could be a suitable measure. The longer a petrol station is open, the more likely it will sell more products, and prices will lower. Petrol stations that are further away from motorway entrances, do not offer services on main roads (federal roads), or are located along typical commuter routes with price-sensitive end customers, are more likely to reduce prices than others. Since many petrol stations sell fuel in the name and on the account of their major, they receive a fixed fee per liter of fuel. This means that there is no loss of turnover due to price reductions. These petrol stations are all the more interested in turnover from services, which is promoted by price reductions rather than by adhering to high prices. The trend to lure customers to petrol stations by lowering prices is intensifying. Since the large majors often have card customers whose bills are paid by third parties such as their employers, customers are less willing to look for lower prices than customers at independent petrol stations. Increasing volume through price lowering is likely to be less relevant for self-service stations or for petrol stations with associated car repair shops: the former because fixed personnel costs have to be distributed less, and the latter because the petrol station is perhaps only a source of additional profits. Petrol stations that are within sight of each other react immediately to price reductions of the other. Petrol station–specific factors such as location, service, or brand can also influence their willingness to reduce prices. As in many other countries, excessively high gasoline prices are repeatedly the subject of political debate, as was the case in Germany at the beginning of the 2010s. As early as the end of the 2000s, the Federal Cartel Office had conducted detailed surveys of gasoline prices in four metropolitan regions and found indications of at least parallel behavior; for example, there were different prices according to weekdays or at the start of vacations. In the early 2010s, there were even calls for government intervention in the gasoline price mechanism, such as a gasoline price brake, due to generally high gasoline prices. Politically, it was then decided to set up a Market Transparency Unit for fuels, to which all gas stations have had to report their price changes within 5 min since the end of 2013. The transparency unit in turn passes these on to consumer information services, via whose websites, apps, or navigation devices consumers can find out about low-price suppliers. Not only consumers but also suppliers are more likely to be able to find out about relevant prices, making parallel behavior easier (Haucap et al. 2017a, b and Dewenter et al. 2017). This paper examines why a service station is the first to lower prices after a period of rising prices, within the intraday German Edgeworth cycles. Edgeworth cycle theory would require price undercutting by a competitor. Petrol stations with market power would be less forced to lower prices than powerless ones. More interest in selling additional services, the location of the petrol station, and existing brand loyalty may also be reasons to be the first to give up the high-price paradise. The second chapter describes the service station market in Lüneburg and compares it with the national market. The third chapter shows which price data are available from the MTU and how a panel data set can be created from them, based on the (price) data of the 26 gas stations recorded for each price reduction round. Descriptive statistics are provided within Section 4. Section 5 describes the estimated results of multivariate fixed effect logit estimates of why a single service station lowers their price and the others do not. Robustness tests are presented in Section 6. Summarized results and conclusions can be found in the seventh section.",
21.0,4.0,"Journal of Industry, Competition and Trade",23 June 2021,https://link.springer.com/article/10.1007/s10842-021-00365-5,Endogenous Timing of R&D Decisions and Privatization Policy with Research Spillovers,December 2021,Sang-Ho Lee,Timur K. Muminov,,Male,Male,Unknown,Male,"Many studies on oligopolistic competition analyzed the Cournot model while some other studies analyzed the Stackelberg model, in which the role of each firm is given exogenously. However, it is more reasonable to assume that firms choose not only what actions to take but also when to take them. It implies that endogenous timing on the firm’s movement is important because an alternative ordering of moves often gives rise to different results. Previous literature of an endogenous timing game has heavily used an observable delay game since Hamilton and Slutsky (1990) who showed that in private duopoly, profit-maximizing firms decide simultaneously when competing in quantities and sequentially when competing in prices. Pal (1998) also examined a mixed duopoly where a profit-maximizing private firm competes with a welfare-maximizing public firm, and showed that the results are reversed and both firms decide sequentially when competing in quantities and simultaneously when competing in prices. Furthermore, it is more important to investigate whether the public firm in mixed duopoly becomes the leader or the follower. Under private leadership, the public firm plays a complementary role as a potential competitor against private firm and the private firm mostly supplies the products. Under public leadership, however, the public firm cannot play such a role and the private leadership is better than the public leadership from the normative viewpoint.Footnote 1 Besides understanding these conflicting results in production market competition, as innovations have intensified R&D competition among firms, governments have recognized the importance of R&D policies and emphasized the facilitation of innovation in society. For example, EU institutions have reaffirmed the commitment to R&D policies and, consequently, the budgets of the research Framework Programs (FPs) have grown from EUR 3.3 billion in the first FP, launched in 1984, to EUR 80 billion of Horizon 2020.Footnote 2 The policy concerns over innovation suggest the academic need for further examinations such as which role should be allowed to the public institutions and organizations for R&D decisions and how the government regulates the R&D investment in the privatization of the public firms. In the last generation, there have been considerable theoretical works on R&D and policy implications for innovation under imperfect competition along with different structures of ownership. In the literature of mixed oligopolies where a welfare-maximizing public firm competes against profit-maximizing private firm, the works by Delbono and Denicolo (1993), Nett (1994), Ishibashi and Matsumura (2006), and Heywood and Ye (2009) have motivated the analysis of simultaneous or sequential R&D investments. However, these works have neither examined the role of R&D spillovers nor endogenous choices of R&D decisions. Due to its cost-reducing features associated with the existence of R&D spillovers (knowledge sharing) and its implications on innovation and competition activities, the works on R&D spillovers are recently gaining importance and have become highly popular.Footnote 3 There have been also considerable researches devoted to investigate main determinants which lead firms to internalize R&D performances and spillovers. For instance, Gil-Molto et al. (Gil-Molto et al. 2011, 2020), Kesavayuth and Zikos (2013), Lee and Tomaru (2017), Lee et al. (2017), and Haruna and Goel (2017, 2018) investigated the role of R&D policies in mixed oligopolies where firms compete in R&D investments and examined the relationship between R&D activity and public policy. However, previous analyses have heavily investigated the fixed timing of firms’ decision on R&D where mostly simultaneous-move game in R&D investment is exogenously given. In fact, firms may choose their R&D level sequentially or simultaneously given conditions for knowledge sharing in a certain marketplace. We incorporate this important aspect into the model with an endogenous timing game and analyze the strategic movement of R&D investment. That is, we raise an important question how the rate of spillovers affects the endogenous choices of R&D levels (not only how much to undertake but when to take them) under different market structures such as private or mixed markets.Footnote 4 This paper investigates an endogenous timing game on strategic timing choice of cost-reducing R&D investment with R&D spillovers in private and mixed duopolies, respectively. We then examine an observable delay game with a two-period where firms first determine their cost-reducing R&D investments either simultaneously or sequentially given the rate of spillovers, and then play Cournot output competition. Following Amir et al. (2000), we consider a Cournot duopoly in output competition but allow for an endogenous timing in R&D investments. This structural enhancement of the model allows us to anticipate when the firms are likely to play either a leader or a follower in making their R&D decisions. We highlight that the rate of spillovers is crucial in determining equilibrium of endogenous R&D choices in both private and mixed duopolies while welfare consequences are in contrast between the two markets, depending on the timing of R&D choices and R&D spillovers. Therefore, in the process of privatization policy, not only the rate of spillovers, which is affected by the intellectual property right, but also the leadership position of the privatized firm in R&D decisions are important factors in determining welfare consequences. Our main findings are as follows: First, a leader’s R&D and output are higher than those of a follower for any rate of spillover under the sequential-move game in a private market while public firm’s R&D and output are higher than those of the private firm for any market structure in a mixed duopoly. Hence, the presence of public firm enhances not only total R&D expenditures but also total market outputs. This also implies that the R&D decisions by the public firm in a mixed duopoly might be over-investment from the viewpoint of social welfare. This finding is consistent with the results in Ishibashi and Matsumura (2006) who examined patent race in a mixed duopoly and showed that the R&D expenditure of the public firm is too large while that of the private firm is too small, due to the strategic substitutability between the two firms’ R&D decisions. Second, in a private duopoly, a simultaneous-move is equilibrium if the spillovers rate is low while a sequential-move is otherwise. This implies that the simultaneous-move game in R&D decisions is plausible in the case of no spillovers, but if there exist R&D spillovers, it might be problematic. We also show that a sequential-move in R&D choices yields a higher total R&D investments and total market outputs. Thus, a higher rate of spillovers can change the equilibrium of an endogenous R&D timing game to a sequential-move game and enhance the welfare. This result complements previous findings in Hamilton and Slutsky (1990) who showed that the equilibrium of an endogenous timing game is that both firms choose outputs simultaneously (in a specific case with the same R&D investments and no spillovers). However, when the spillovers rate is high, both firms prefer a sequential-move in R&D choices even though they prefer a simultaneous-move in output choices. This result also complements previous findings in Amir et al. (2000) Third, in a mixed duopoly, a simultaneous-move game cannot be equilibrium. Thus, in the existence of public firm, the sequential game in R&D decisions is more plausible irrespective of the rate of spillovers. We also show that private leadership in an equilibrium of an endogenous R&D choices yields a higher total R&D investments and total market outputs if the spillovers rate is either low or high, which enhances the welfare. Further, public leadership is robust and becomes the only equilibrium if the spillovers rate is intermediate and its welfare is always higher than that under the other two cases. This result is in contrast to the previous studies in Pal (1998), Tomaru and Kiyono (2010), and Matsumura and Ogawa (2010, 2017) who showed that private leadership is more robust in a mixed market with quantity competition. Our findings highlight the key role of R&D spillovers which can change the equilibrium outcome between private and public leadership of the endogenous R&D timing game in a mixed market. Finally, the implementation of privatization policy by government may transform public leader to a private leader which in turn decreases the social welfare for any rate of spillovers. This is because privatization policy decreases total industry R&D investments and outputs for any rate of spillovers. Our analysis reveals that the rate of spillovers does not affect welfare consequences under privatization policy. This is consistent with the results in Ishibashi and Matsumura (2006) and Gil-Molto et al. (2011), who showed that privatization is not desirable, regardless of whether the government provides R&D subsidies to private and public firms. The remainder of the paper is structured as follows. In Section 2, we present a basic duopoly model of R&D investment with spillovers. In Sections 3 and 4, we analyze an endogenous R&D timing game in private and mixed duopolies, respectively. We then discuss the welfare effect of privatization policy in Section 5. Finally, Section 6 concludes the paper.",3
21.0,4.0,"Journal of Industry, Competition and Trade",13 July 2021,https://link.springer.com/article/10.1007/s10842-021-00366-4,The Chicken or the Egg: Causality Between Trade and Innovation,December 2021,Daniel K. N. Johnson,Phoenix Van Wagoner,,Male,,Unknown,Mix,,
21.0,4.0,"Journal of Industry, Competition and Trade",28 July 2021,https://link.springer.com/article/10.1007/s10842-021-00368-2,"Strategic Interactions, Bargaining Power and Stability of Joint Venture in an Emerging Nation",December 2021,Rituparna Kaushik,Sourabh Bikas Paul,,Unknown,Unknown,Unknown,Unknown,,
21.0,4.0,"Journal of Industry, Competition and Trade",28 July 2021,https://link.springer.com/article/10.1007/s10842-021-00367-3,Servitization of Global Manufacturing Business,December 2021,Jieun Lee,Hyung-Deok Shin,Saehwa Hong,Unknown,Unknown,Unknown,Unknown,,
21.0,4.0,"Journal of Industry, Competition and Trade",31 July 2021,https://link.springer.com/article/10.1007/s10842-021-00369-1,"Competition, External Economies of Scale, and Unionized Wage",December 2021,Debasmita Basak,Arijit Mukherjee,,Unknown,Unknown,Unknown,Unknown,,
21.0,4.0,"Journal of Industry, Competition and Trade",25 September 2021,https://link.springer.com/article/10.1007/s10842-021-00372-6,The Characteristics of Low Bid Price Survey Standards and Their Impact,December 2021,Koki Arai,,,Male,Unknown,Unknown,Male,"The lower bound in public procurement poses a problem similar to unemployment. In a capitalist economy, unemployment is the situation of those who are willing to work but are not working. Unemployment is caused by a variety of factors, including seasonal, temporary, and frictional unemployment. From a theoretical point of view, when the minimum wage is higher than the equilibrium wage for some reason, the supply of labor increases and the demand decreases, resulting in a surplus, which can lead to unemployment. This minimum wage can be considered the so-called lower bound price (Fig. 1). Minimum wage and labor market. Note: Panel a shows a free labor market in which wages are adjusted to balance labor demand and labor supply. Panel b shows the effect of binding minimum wage. Since the minimum wage is the lower bound of the price, it leads to a surplus. That is, the labor supply quantity exceeds the labor demand. Consequently, unemployment has risen (Clemens 2021) This study empirically examines the effect of this lower bound as a distortion of the public procurement market. In a competitive market, the lower bound price is generally defined as the minimum price that a buyer should pay for goods (Fig. 2). This minimum price regulation can cause persistent oversupply, which leads to four different inefficiencies. First, this causes inefficiently low quantities. It raises the price of goods for demanders, reducing the quantity demanded and leading to deadweight. Second, it leads to inefficient allocation of sales opportunities among sellers. People who are willing to sell goods at the lowest price may not always be the ones who sell them. Third, there is a waste of resources. For example, under minimum wage laws, workers spend money and effort to find jobs. Fourth, it is inefficiently high-quality. Even if the buyer prefers low quality at a low price, the seller offers high-quality goods at a high price. Then, there is a temptation to break the law by selling at a price lower than the legal price. This fact is illustrated in the following diagram, according to the basic economics textbook (Mankiw 2019). Low-price standard and construction market. Note: Panel a shows a free public procurement market where the bid rate is adjusted so that the construction demand is balanced with the construction supply. Panel b shows the impact of a binding low-price standard. The low-price standard is a lower bound on the price, leading to an excess supply. That is, the construction supply quantity exceeds the construction demand quantity. As a result, there is an abundance of construction work However, it is important to note that although the low bid price survey standard acts like a lower limit, it is not a literal lower limit, because it is set randomly and the cost of being even slightly below it is high. Whether such a minimum price for public procurement causes an oversupply situation, and if so, what effect it has, is an important question for the authorities that ensure the proper execution of public procurement. It is essential to examine not only the theoretical situation but also the quantitative support for it. The Law concerning the Promotion of Proper Bidding and Contracting for Public Works (Law No. 127 of 2000, Japan) clearly states that the prevention of dumping orders should be a basic issue in proper bidding and contracting for public works. The “Guidelines for Measures to Ensure Appropriate Bidding and Contracting for Public Works” (approved by the Cabinet on September 30, 2014) states that the base price for low bid price investigations is reviewed from time to time from the preventing dumping orders’ perspective. The base price for the low bid price survey has been raised successively and is currently 0.75 0.92% of the predetermined price of the project. Concerning the base price for the low bid price survey, the 2008 revision had little effect on bidding and winning prices, and the 2009 and 2011 revisions showed a positive trend in actual winning prices, but the effect was not significant (Morimoto and Arai 2013). However, it has been pointed out that the problem with the current predetermined price system and pricing structure is that bids cannot be awarded unless they are within the upper and lower limits set by the client (the predetermined price and the low bid price survey standard price), which leads to the problem of bids being guided within the upper and lower limits (Kinoshita 2017). In addition, it has been confirmed that bidders formulate their bidding prices by estimating the ordering authority’s cost (Seki et al. 2019). Using public procurement data on general civil engineering works from the Regional Development Bureau of the Ministry of Land, Infrastructure, and Transport, this study empirically examines the competition distortion in the public procurement market because the low bid price survey standard is effectively recognized as the lower limit of public procurement. The originality of this study and its contribution to industrial research is that it is a steady study that empirically supports theoretical predictions based on the actual situation of public procurement. The fact that unemployment-like situations have arisen, which has not been pointed out in many cases, is important and should be studied. At first glance, the problem caused by this lower limit on public procurement prices is not readily apparent. The clarification of the actual situation and the consideration of countermeasures are expected to widely promote the usefulness and necessity of industrial research. This paper is organized as follows. Section 2 provides an overview of previous studies. There have been many studies on price regulation in public procurement. While theoretical and empirical studies of price regulation have progressed, there have been several empirical studies on the impact of the content of the regulation, and this study belongs to that lineage. This section explains that this research fills the gap between theoretical research and the clarification of real-world movements that have not been addressed in previous studies. Section 3 identifies the empirical questions to be clarified. Section 4 provides an overview of the Japanese system, the data used in this study, and the model used in this paper. In Sect. 5, the estimation results and their implications are presented. Section 6 provides the conclusion.",
22.0,1.0,"Journal of Industry, Competition and Trade",27 October 2021,https://link.springer.com/article/10.1007/s10842-021-00373-5,Exit Decisions in the Canadian Grain Elevator Industry,March 2022,Sichao Jiang,James Nolan,Wesley W. Wilson,Unknown,Male,Male,Male,"Grain elevators have long been a visible and important component in rural communities. They not only provide employment opportunities and invest in the local areas, they are also the central local gathering point for agricultural products and link the local markets to destinations. Elevators not only receive grain, they also store, blend, and/or treat grains, ultimately loading the stored grain for shipment to terminals and processing plants. In Canada, since the first Prairie elevator was built in 1881 in Gretna, Manitoba, there has been enormous investment in rural elevators to accommodate the long-term growth of the Prairie grain industry.Footnote 1 Over the last few decades, the industry has transitioned as older (mostly built of wood) and smaller elevators have given way to more modern (mostly built of concrete) larger elevators. In this paper, we examine this transition by not only developing and estimating a model of exit that captures traditionally used determinants such as scale, multi-plant firms, plant vintage, but also developing and including a measure of vertical linkages as well as local measures of demand, supply, and spatial competition. We develop a panel dataset of Western Canadian elevators in operation during 1999–2016 time period. These data provide a comprehensive unbalanced panel that allow patterns of exit to be described and allow the estimation of a unique model of exit to be estimated. We first estimate a model motivated by the industrial organization literature on exit. The model includes variables such as capacity, multi-plant ownership, and whether or not an elevator was a recent entrant to the market to capture elevator vintage. We then develop and include in the model measures of the vertical relationship between the elevators and the transportation markets as well as a set of variables to reflect the spatial setting of the elevator. These latter include local measures such as demand, supply, and spatial competition. The results provide strong evidence consistent with the literature that capacity and time of entry (i.e., more recent, newer technology) have negative effects on exit. We also find that vertical relationships as well as spatial measures of demand, supply, and spatial competition have expected and strong effects on the probability that an elevator in the sample exited the market. The current industry in Canada consists of four types of elevators. These are primary, forwarding, process, and terminal elevators. Primary elevators receive grain directly from producers for storage and forwarding. Process elevators receive and store grain for direct manufacture or processing into other grain products. Terminal elevators receive grain after official inspection and weighing, cleaning and storing grain before moving it along the supply chain; and transfer elevators transfer grain that has been officially inspected and weighed at another elevator. Transfer elevators can also receive, clean, and store domestic or foreign grain.Footnote 2 Primary elevators still dominate the grain elevator industry in Canada. In 1999, there were 976 primary elevators, and a total of 57 other types of elevators. The number of primary elevators generally decreases throughout the range of the data (1999–2016). Yet since 2004, total capacity of primary grain elevators has increased in most Canadian provinces. For example, Alberta has seen total primary elevator capacity increases from 1,685,250 to 1,834,160 tonnes within the time frame of 1999 to 2016. British Columbia is the only province where inland elevator capacity fell, from 46,030 in 1999 to 41,130 tonnes in 2016.Footnote 3 Overall, the industry now has fewer but larger elevators, while these remain mostly primary elevators. Concurrently, the number of process and terminal elevators have increased while their average capacity has dropped. And since 2013, no transfer elevators have been operational in this market. We focus the analysis on primary elevators, given their dominance in the industry. There is considerable research on industrial entry and exit.Footnote 4 Generally, this literature finds that inefficient firms/plants tend to exit the market either due to the lack of scale economies or due to inherent inefficiencies.Footnote 5 Other research points to strategic motivations for exit, e.g., Ghemawat and Nalebuff (1985), Ghemawat and Nalebuff (1990), and others. In addition, recent research provides evidence that firm characteristics at the time of entry have an important effect on exit (Dunne et al. (2005)), while other research theoretically points to the role of multiplant ownership, e.g., Reynolds (1988) and Ghemawat and Nalebuff (1990) and empirically (e.g., Audretsch and Mahmood (1995), Mata et al. (1995), and Miller and Wilson (2018)).Footnote 6 Previous research has shown that the effects of scale can have a positive effect on the likelihood of exit. That is, in declining demand markets. Ghemawat and Nalebuff (1985) show theoretically that a small single plant firm can profitably “hang on” longer than a large firm, with the result that the larger firm exits first. In a subsequent paper, Ghemawat and Nalebuff (1990) allow partial capacity adjustments, but similarly find that large firms reduce capacity before small firms and then both small and large firms reduce capacity until their plants are equally sized, subsequently reducing capacity at the same rate. When firms operate multiple plants, Whinston (1988) find that the large plant can improve a multi-plant firm’s strategic position in the survival game, with the result that this firm will not necessarily be the first to exit or cut capacity. Fudenberg and Tirole (1986) analyze a model in which two firms possess asymmetric information about each other’s fixed costs, but hold symmetric expectations. They identify a unique subgame perfect equilibrium where high-cost firms exit earlier than low-cost firms. We conclude that overall, the implications of plant capacity on exit decisions are mixed. That is, small and/or inefficient firms can be “shaken” out earlier, but in declining markets it may be that small firms “stakeout” the market with the result that larger firms exit first (Lieberman (1990)) and Blonigen et al. (2013). In this paper, we control for what have become standard exit related variables such as capacity, multi-plant ownership, and whether the plant (individual elevator) is a recent entrant (to capture vintage effects). But given the nature of the industry, we also introduce industry specific variables that may also have an effect on elevator exit. Since elevators are part of an extensive grain supply chain in Canada, their individual relationships with the grain transportation market can also influence their long term viability. In this sense, rail transportation in particular represents a vertical linkage connecting individual grain elevators to final markets. Plants/elevators supported by well developed transportation infrastructure would seem less likely to exit the market. Some elevators now also have considerable capacity to load hopper cars, which means they can ship large quantities, leading to lower negotiated freight rates than elevators with smaller capacities. We capture this effect with a rail carload capacity variable and find that it has a significant negative effect on the probability of a given elevator exiting the market. In addition, we also introduce a set of variables to account for differences in local demand and supply conditions, as well as spatial competition from other proximate elevators. The latter measure is a measure of capacity of other proximate elevators (calculated using weights inversely related to distance to the neighboring elevators). There is a limited amount of research that applies to vertical relations in firms’ exit decisions. As an example, Chen (2002) use a duration model to find that vertical integration reduces the likelihood of survival for US petroleum plants. de Figueiredo and Silverman (2012) examine exit rates in the US laser printer and manufacturing industry, finding that the density of a vertically related population has an adverse effect on exit rate. In our market, a clear vertical linkage exists between grain elevators and rail transportation. While some elevators can load only a few cars at a time, others can load dozens of rail cars in short order. Railroads will typically offer rate discounts for multiple rail car shipments over smaller rail car movements, a situation that places elevators having high car loading capacity with a substantial competitive advantage.Footnote 7 Due to this, car loading capacity is our measure of vertical linkage. In the case of grain elevators, Sarmiento and Wilson (2005) show that large elevators have a greater tendency to adopt a shuttle train technology than smaller ones, while the size of a rival has a negative impact on adoption decisions. They also find shuttle train technologies tend to be adopted in regions with high production and less competition. The remainder of this paper is organized as follows: Section 2 contains some general background of the grain elevation industry in Canada and provides a review of related academic literature; Section 3 describes the data on Western Canadian grain elevators, providing more details about firm entry and exit during the study period; Section 4 presents the results of various econometric specifications and then discusses our findings; Section 5 concludes.",
22.0,1.0,"Journal of Industry, Competition and Trade",18 January 2022,https://link.springer.com/article/10.1007/s10842-022-00379-7,"The Dynamics of Bank Concentration, Competition and Efficiency in the East African Community",March 2022,Moses Nyangu,Nyankomo Marwa,Latacz-Lohmann Uwe,Male,Unknown,Unknown,Male,"A heated debate globally has risen over the years on the implications of increased market power in banks and its effect on bank efficiency and overall bank performance. Various studies have established that competition failureFootnote 1 in banks can lead to high prices for financial products and increased limitations to access finance especially for small and emerging firms (Anzoategui et al., 2010). Other studies have found that lack of competition can hinder the entry of new firms and lead to slower growth on emerging firms and also delayed exit by older firms in the sector (Beck et al. 2008). In addition, empirical evidence suggests that market power leads to high bank concentration which can hinder the level of bank efficiency (Turk-Ariss 2010; Schaeck and Cihák 2014). The level of bank concentration in Africa and in particular the East African Community (EAC) has persistently remained high suggesting an evidence of competition failure (Christensen 2014; Oduor et al. 2017). Furthermore, the EAC banking sector is characterized by high bank charges, high lending rates, high non-performing loans, and low deposit rates which raises concerns over the efficiency of the financial sector (Davoodi et al. 2013; World Bank 2018). The situation seems to persist despite EAC being actively involved with financial liberalization, deregulation, and bank restructuring processes to lay the foundation of achieving an integrated regional financial sector (EAC 2019). The incomplete market structure can thus pose a challenge to policy makers with regard to managing the levels of bank efficiency and general bank performance which is extremely crucial especially for the developing economies like EAC. Empirical evidence on the link between bank concentration, competition, and efficiency remain complex and ambiguous (Demirgüç-Kunt and Levine 2000; Ferreira 2013; Otero et al. 2020). The relationship may be either positive or negative depending on banking sector market characteristics like availability of information and the level of competition (Goddard et al. 2007; Molyneux 2009; Casu and Girardone 2009; González et al. 2019; Asongu et al., (2020). A study by Ferreira (2013) and Otero et al. (2020) establishes that bank market power leads to more inefficiency because concentrated banks face less competition to obtain more outputs with less inputs. Conversely, other studies have examined whether bank efficiency affects bank concentration (Allen and Engert 2007; Williams 2012). Despite the existing theoretical prediction and empirical evidence globally, there is a paucity of such studies in Africa (Alhassan and Ohene-Asare 2016; Moyo 2018; Asongu and Odhiambo 2019). Within the EAC, there is no empirical evidence, and this is the first study to comprehensively and systematically address the linkages between bank concentration, competition, and different types of efficiency in the EAC banking sector. This paper contributes to the literature in several ways: firstly, the paper simultaneously incorporates both market-level (concentration) and bank-level (competition) measures to establish whether bank concentration and competition can be used as a proxy. This action is critical as it sheds more light on the mixed and inconclusive findings from existing studies which use different measures of concentration and competition leading to contrasting findings (Claessens and Laeven 2004; Bikker et al. 2015). Secondly, the paper develops theoretical arguments to explain how bank concentration and competition differs across the five different types of bank efficiency unlike previous studies which have examined bank efficiency in a more generic manner (Asongu et al. 2020; Mansour and Moussawi 2020; Otero et al. 2020). This is because bank concentration and competition may have different effects on different forms of efficiency. Bank efficiency is decomposed into (1) technical efficiency, how efficiently inputs resources are transformed into outputs; (2) pure technical efficiency, managerial ability of bank managers; (3) scale efficiency, a bank’s optimal scale of operation; (4) cost efficiency, extent of cost minimization; and (5) profit efficiency, extent of profit maximization (Maudos et al., 2002; Coelli 2016). This is overly critical as there exist a very few studies to the best of our knowledge that have examined the different effects of bank concentration and competition on the bank efficiency. Furthermore, the available studies lack the rigor and detailed accounts to explain the different effects of bank concentration and competition on the different types of bank efficiency. Lastly, given that EAC is at the forefront of realizing regional financial integration and currently in the process of creating a common EAC monetary union, several lessons may be drawn from the behavior of EAC bank market structure with respect to efficiency. This is because banks are predominantly the leading institutions within the EAC financial system, and they are the main providers of private sector credit to the economy. Therefore, any inefficiencies and shocks within the sector might pose serious dire consequence to the entire economic bloc. The findings reveal that bank concentration has positive significant effect on technical, pure technical, and profit efficiency, thus supporting the concentration-efficiency hypothesis that efficiency is positively influenced by bank structure. The findings also reveal that bank concentration has a negative significant effect on scale and cost efficiency, thus supporting the quiet life hypothesis. This implies that concentrated banks are cost inefficient and do not capitalize on economies of scale to increase profitability but instead choose to have an easy life (quiet life) by charging high prices to make more profits (Berger and Hannan 1998; Mirzaei et al. 2013). Furthermore, greater competition is found to foster technical, scale, cost, and profit inefficiency, thus augmenting concentration to be a source of efficiency. In sum, the results indicate that bank concentration may have a positive or negative effect depending on the particular type of efficiency being explored. The rest of the paper is organized as followed: Section 2 reviews theoretical and empirical studies on bank concentration, competition, and efficiency; Section 3 sets out model specification and measurement of key variables and explains the data; Section 4 presents the results of the empirical analysis; finally, Section 5 concludes and develops policy implications.",
22.0,1.0,"Journal of Industry, Competition and Trade",10 January 2022,https://link.springer.com/article/10.1007/s10842-021-00378-0,The Impact of the Concession of 14 Regional Greek Airports on Passenger Traffic,March 2022,Svetoslav Danchev,Nikos Paratsiokas,Nikolaos Vettas,Male,Male,Male,Male,"Private sector involvement in the development and management of aviation infrastructure has increased over the past decades through privatization schemes and long-term concession contracts. In Europe, approximately 75 percent of passenger trips take place through fully or partly privatized airports (ACI 2016). The transfer of activity from the public to the private sector is considered to facilitate investment and support traffic growth. This is particularly significant for the economic and regional development of countries, like Greece, that rely strongly on international arrivals of tourists by air. There are 44 civil airports in Greece (Fig. 1), out of which 15 are categorized as international, 25 as national, and the remaining 4 as municipal. The largest hub is the Athens International Airport “Eleftherios Venizelos,” which was built with a public–private partnership and is currently operated by a company with shareholders from the public and private sector. The remaining international and national airports were operated by the Hellenic Civil Aviation Authority prior to the start of the privatization program. Map of Greek airports In the context of recent economic adjustment programs, of central interest in policy in Europe in the midst of the Eurozone crisis, an extensive and ambitious privatization program was implemented in Greece.Footnote 1 The objectives of the program were to reduce inefficiencies and financial risks associated with the management of public companies, generate public revenue to reduce public debt and hence improve its sustainability, and spur new investment to boost productivity and economic growth. To implement this objective, the Greek government established the Hellenic Republic Asset Development Fund (HRADF) in 2011, with the mission to transfer real estate, shares in public companies, and concession rights for transport and other infrastructure to strategic private investors. The program included the concession of 14 regional airports for a period of 40 years. Three of the 14 regional airports included in the concession agreement are on the mainland, including the second largest airport in the country in Thessaloniki. The remaining 11 privatized airports are located on Greek islands. Four of the airports belong to the category of national airports, and the remaining 10 airports are international. Despite their status as international airports, only one airport (Thessaloniki) has more than one runway and terminal, while in nine of the 14 airports, the length of the runway does not exceed 2.5 km (Table 1). The procedure for the privatization of the regional airports was initiated in 2013 with a call for interest issued by the Hellenic Republic Asset Development Fund. The concession was awarded on November 25, 2014, to Fraport Greece, a consortium of companies consisting of the Frankfurt airport operator Fraport AG and Slentel Ltd, a Greek-Cypriot company. Following a period of 2.5 years to complete legal and administrative procedures related to the concession, the rights to upgrade, maintain, manage, and operate the 14 regional airports were transferred to Fraport Greece for 40 years, starting from April 2017, without conferring full ownership rights of the airport assets.Footnote 2 The concession agreement included an upfront payment of €1.23 billion and an annual fee of €22.9 million during the concession period. Following the concession of the 14 airports to Fraport Greece, 24 regional airports have remained under the management of the Hellenic Civil Aviation Authority. The concession agreement triggered an investment program for terminal and runway reconstructions with a total budget of €440 million. The investment program aimed to significantly increase the capacity of the airports (Table 2) and improve their service level over the medium term. The development works included the construction of five new passenger terminals, expansion of 6 existing terminals, and significant upgrade of the remaining three terminals, raising the total terminal size by about 100,000 m2 to a combined total of about 300,000 m2 (50%). As a result of the expansion, the number of check-in counters was increased from 213 to 297 (+ 23%), the number of security-check lanes from 44 to 84 (+ 47%), the number of departure gates from 103 to 147 (+ 30%), and the number of aircraft parking stands from 115 to 150 (+ 23%). In addition, the investment program included refurbishment works on all 15 runways, 14 fire stations, and airport apron areas. The construction works began shortly after the commencement of the concession and were completed in January 2021, 3 months ahead of schedule. The airports continued to service passenger traffic throughout the reconstruction period. Apart from the investment program, the airport operator provided incentives to airline operators, aiming at attracting international services and, thus, increasing traffic even during the investment implementation period. This paper examines whether the concession of the regional airports with the implementation of the company’s business plan produced an impact on passenger traffic. For that purpose, we employ an econometric analysis of passenger traffic before and after the concession to infer the operational effects of the change in the management model of these airports. The paper is organized as follows: Section 2 provides a discussion of the literature related to the objectives and outcomes of airport privatization. Section 3 describes the model and the methodology used in this paper. Section 4 presents the results from the main model, while Section 5 presents results from robustness checks. The paper concludes with a discussion of the results and some policy issues.",1
22.0,1.0,"Journal of Industry, Competition and Trade",13 October 2021,https://link.springer.com/article/10.1007/s10842-021-00370-8,Objectives and the Optimal Structure of Competition Authorities Revisited,March 2022,Yannis Katsoulacos,Vasiliki Bageri,,Male,Female,Unknown,Mix,,
22.0,1.0,"Journal of Industry, Competition and Trade",29 September 2021,https://link.springer.com/article/10.1007/s10842-021-00371-7,Pollution Abatement and Production Outsourcing in India,March 2022,Saibal Kar,Sarmistha Banerjee,,Unknown,Unknown,Unknown,Unknown,,
22.0,1.0,"Journal of Industry, Competition and Trade",16 January 2022,https://link.springer.com/article/10.1007/s10842-021-00375-3,Pricing Strategies and Partial Privatization Policy Based on Complementary Competitive Market,March 2022,Akio Kawasaki,,,Male,Unknown,Unknown,Male,"We often witnessprivatization of public firms, like the privatization of the transportation industry in Asia and Europe. In Kumamoto, Japan, the local government privatized their bus services in 2009. Osaka City, Japan, privatized its subway and bus services in 2018. These examples depict monopolistic and complementary competitive markets. For example, in a complementary competitive market, passengers use bus services from a bus stop near their home to go to the railway station where they switch to private train services.Footnote 1 In reality, two pricing strategies exist across various industries: discriminatory and uniform pricing. For example, the Japanese transportation industry adopted uniform pricing. The Japan Railway Company sets the common-cost-based fare for various cities for monotonic and complementary routes. On the other hand, in the airline industry, discriminatory pricing seems to be adopted because airfare differs among routes that have similar conditions.Footnote 2 In addition to the pricing strategies mentioned above, we should focus on the privatization of the transportation industry. For example, in Japan, airport privatization is now progressing, and airports can select their own pricing strategies.Footnote 3 As mentioned earlier, we observe that public or privatized firms adopt uniform pricing. Despite this observation, no study has discussed whether partial privatization with uniform pricing is socially preferable. Under uniform pricing, there are restrictions on the determination of prices. Given these restrictions, what are the mechanisms that make partial privatization more desirable under uniform pricing? Aguirre (2011) and Adachi and Matsushima (2014) investigated the pricing strategy in a pure duopolistic multi-market. However, they did not consider a mixed duopoly market and its relation to privatization policies. The only exception to this pattern is Kawasaki (2020a). However, Kawasaki (2020a) only considers substitute markets, and does not discuss complementary markets. Thus, assuming an asymmetric mixed duopoly market of complementary competitive services, we investigate the optimal degree of privatization under each pricing strategy in this paper, and discuss which pricing strategy is socially preferable. Next, we examine how technology affects the degree of privatization by considering both constant and decreasing returns of scale technology. The most representative study of partial privatization was conducted by Matsumura (1998). However, as Matsumura (1998) assumes the general cost function, he does not discuss how differences in technology affect the optimal degree of privatization. Since this study uses the specific cost function, it succeeds in discussing how the difference affects the optimal degree of privatization. The main results obtained in this study are as follows. Under both the discriminatory and the uniform pricing strategies, partial privatization is socially preferable. When discriminatory pricing is adopted, the relationship between the degree of complementarity and the optimal degree of privatization is a monotone increasing shape for the inefficiently decreasing returns to scale. For an efficient or a constant return to scale, its relationship is an inverse U-shape. When uniform pricing is adopted, the monotone relationship (inverse U-shaped relationship) holds for the decreasing return to scale (constant return to scale). Additionally, independent of the technology, when the degree of complementarity is small, uniform pricing is socially preferable; when the degree is large, discriminatory pricing is socially preferable. By choosing uniform pricing, the privatized firm commits to setting a low price in its monopolistic market, which increases social welfare when the degree of complementarity remains small. The remainder of this paper is organized as follows. Section 2 reviews the literature on privatization and price discrimination. The model employed in this study is presented in Section 3. Sections 4 and 5 derive the optimal degree of privatization under both discriminatory and uniform pricing strategies, respectively. In Section 6, we first compare the equilibrium prices in both cases and then compare the optimal degree of privatization in both cases using a simulation analysis. Finally, we compare the social welfare of each pricing strategy and elucidate which pricing is socially preferable. Section 7 discusses the two extended models.Footnote 4 In Section 7.1, we assume a foreign private firm and examine the privatization policy and pricing strategy. In Section 7.2, we introduce the heterogeneity of market size and discuss how its heterogeneity affects the socially preferable pricing strategy. Section 8 offers concluding remarks and suggestions for future research. This study does not include proofs for all propositions and lemmas because the calculation results are messy. We can send these proofs upon request. Regarding the results of the simulation analysis, we can send the Mathematica files upon request.",1
22.0,1.0,"Journal of Industry, Competition and Trade",01 November 2021,https://link.springer.com/article/10.1007/s10842-021-00374-4,"Long-Term Daily Equity Returns Across Sectors of the Oil and Gas Industry, 2000–2019",March 2022,Scott Alan Carson,,,Male,Unknown,Unknown,Male,"Throughout the second half of the twentieth century, large state-owned oil and gas companies influenced oil prices, output, and production quotas. While the fracking revolution has transformed the industry, state-owned oil companies continue to dominate production. State-owned oil companies operate as government extensions, and investment decisions are made less with the objective to increase shareholder wealth than to support domestic consumption and governments’ strategic objectives. State-owned oil and gas companies, subsequently, do not share the same objectives, incentives, or responses to market variation as privately held oil companies. With recent innovations in the oil industry, the primary source of international oil production is shifting from the Middle East to North America and Russia. In 2019, 15% of world production came from the USA, 13% from Russia, 12% from Saudi Arabia, 6% from Iraq, and 5% from Canada (EIA 2020). The historic international dominance by large state-owned oil producers have ceded greater influence to the private sector, and recent technological developments have turned more oil and gas production decisions over to privately held firms, such as ExxonMobil, BP, and Royal Dutch Shell, who make investment decisions primarily over economic factors with the intent to maximize shareholder wealth. Subsequently, in the short run, the role and performance of privately held US oil and gas companies have become more prominent. Evaluating industry equity returns in the changing international oil and gas industry is necessary because relationships are constantly changing. Furthermore, the oil and gas industry is not homogeneous but is segregated along production and service lines. The industry is reasonably classified into five sectors. Exploration and production firms are upstream producers that discover and extract oil and its by-products. Equipment and service firms are complementary to exploration and production and take a larger role in resource extraction, such as hydraulic fracturing. Physically closer to oil and gas recovery, exploration and production and equipment and service firm returns are more likely to vary with the price of crude oil. Integrated firms were once classified as the super majors, and their contemporary operations extend into every stage of oil and gas production. Transportation and pipeline firms are mid-stream producers that transport oil and its by-products from upstream producers to downstream refiners and marketers. Refiners and marketers are downstream producers that process and market oil, its by-products, and derivatives. These sectors change, and the classification used here partitions the industry into manageable sectors within the oil and gas industry (Mohanty and Nandha 2011). Participants in well-developed international financial markets, in turn, are sufficiently informed to price returns and risk into different sectors of production. The oil and gas industry was also transformed as a result of hydraulic fracturing (fracking) and unconventional recovery techniques. Fracking is the practice among upstream exploration and production and equipment and service firms of forcing liquids, typically water combined with other materials, into a wellbore under high pressure, which creates deep-rock fractures that allow more hydro-carbons to be released from a well, increasing well productivity. While the process of hydraulic fracturing and unconventional recovery has been developed over decades, most of the effects within the industry became prominent between 2013 and 2016. However, firm returns illustrate no structural breaks that would indicate the fracking revolution affects the results in this study. Fracking now dominates US oil and gas production, making up around two-thirds of natural gas and one-half of oil production (EIA 2016, Today in Energy). This study considers three questions regarding the US oil and gas industry. First, how do firm excess returns vary with the Standard & Poors 500 across different sectors of the oil and gas industry? Each segment of oil and gas production has positive and significant return variation with equity market risk. Exploration and production and refining and marketing have the greatest equity market risk, while large well-capitalized integrated and transportation and pipeline firms vary less with equity market returns. Second, how do firm excess returns in different sectors vary with respect to Brent oil excess returns, an alternative to holding the raw commodity oil? Across the five sectors, producer returns are positively related to excess oil returns, and firms in closest proximity to oil extraction have greater oil returns than downstream producers. The further producers are removed from oil and gas extraction, the more their returns are affected by equity rather than oil return variation. Across sectors, firm returns are not systematically related to natural gas excess returns. Third, how do firm returns in different sectors respond to size, book-to-market, profitability, and investment strategies? Across oil sectors, small-minus-big, high-minus-low, and profitability are positively related to individual firm returns, while results are mixed and insignificant for investment strategy and momentum.",1
22.0,2.0,"Journal of Industry, Competition and Trade",25 April 2022,https://link.springer.com/article/10.1007/s10842-022-00384-w,Green Alliances: Are They Beneficial when Regulated Firms are Asymmetric?,June 2022,John C. Strandholm,Ana Espinola-Arredondo,Felix Munoz-Garcia,Male,Female,Male,Mix,,
22.0,2.0,"Journal of Industry, Competition and Trade",11 January 2022,https://link.springer.com/article/10.1007/s10842-021-00376-2,"On Industrialization, Human Resources Training, and Policy Coordination",June 2022,Saul Mendoza-Palacios,Julen Berasaluce,Alfonso Mercado,Male,Male,Male,Male,"The mechanisms through which industrial policy work remain a controversial topic. Still, a series of works point out the importance of the manufacturing sector in the industrialization process and this sector’s relationship with economic growth (e.g., Szirmai and Verspagen 2015; Cantore et al. 2017). Hausmann and Rodrik (2006) argue that forming adequate industrial policy is a process through which the public and private sectors predict possible blockages in economic activities and jointly propose solutions for these blockages. Thus, governments require public-private institutional arrangements to obtain information on profitable economic activities and useful intervention instruments. We will refer to industrial policy as a strategic effort of the State in coordination with private initiative to promote technological development and the growth of one or more sectors of the economy. This effort attempts to alter the production structure of the economy to promote better prospects for economic development. Murphy et al. (1989) propose that the simultaneous industrialization of many sectors of an economy can be profitable for them all, through an increase in aggregate demand, the so-called the big push model.Footnote 1 In this work, we present a continuous-time dynamic model using a general equilibrium approach based on Murphy et al. (1989). We explore the idea that successful industrialization does not only depend on the implementation of a set of public policies, but also on their coordination; that is, the coordination of public policies is a key factor for an economy to industrialize. In our model, each family chooses its consumption from a continuum of goods and chooses whether to invest in education or not. Firms, on their part, choose the technology they use, which can be either traditional or modern. Both of these types of firms use only labor as input. While traditional technology has constant returns, modern technology is assumed to receive increasing returns after covering its fixed costs. At each instant of time, the markets for goods and labor are at equilibrium. The choices of job skills obtained and technology utilized are made under bounded rationality modeled by an evolutionary dynamic. Thus, under favorable conditions, aggregate demand externalities emerge and, consequently, a successful industrialization process emerges. However, if conditions are not favorable, the economy may get stuck in a poverty trap. The contribution of this paper lies in modeling the skills and technology choices under bounded rationality through replicator dynamics, and using comparative statics in steady states through which we obtain tenable deductions of how public policies affect technology transition dynamics, and hence industrialization. We analyze three public policy domains: innovation policies; policies of human resources training, including wages and employment; and push policies. In our proposal, the big push model is a consequence of push policies, and their coordination may result in them becoming “Smaller.” Cimoli et al. (2009) and Cimoli and Dosi (2017) present a generalized classification of the policy domains and their influence on the variables and processes on which they act. Within industrial policy, we can find education and training policy, scientific policy, the creation of national champions, state-owned companies, price regulation, tariffs, labor markets, etc. Although we do not cover the entire range of possible industrial policies, the idea of coordinating several public policy dimensions is present in this model. For Dosi and Nelson (1994), an industrialization process is the result of a combination of factors, such as the industrial structure, competence, and the technology utilized by firms. This has been observed in cases at which some economic sectors achieve national leadership. Mowery and Nelson (1999) propose that these factors should not be analyzed individually. Therefore, we highlight the role of the agencies that coordinate policies, incentives, and simultaneous investments within industrializing processes, as has been described by many authors (e.g., Krugman1992; Basu 2003; Allen 2011). In our multisectoral market economy, each kind of good is produced by a unique economic sector, and each sector consists of two possible types of firms, either traditional or modern. In turn, the preferences and decisions of families are modeled with a representative consumer. Their production and consumption decisions are the result of profit/utility maximization, setting prices that ensure market clearance. Our model uses one production factor, labor. We consider that the technology selection by firms and the education/qualification decisions made by workers follow a bounded rationality decision process. This allows us to analyze technology transition dynamics, and how different public policies may affect them. In the next section, we discuss the related literature. In Section 3, we describe the economy and characterize its equilibrium. Section 4 incorporates evolutionary dynamics to study the evolution of the industrialization process and training issues. In Section 5, we analyze the stability of steady states and define the industrialization frontier. Section 6 examines the three public policy domains and their coordination. Final remarks are presented in Section 7. Two appendices are presented at the end of the document showing (a) stability analysis and (b) comparative statics.",
22.0,2.0,"Journal of Industry, Competition and Trade",26 January 2022,https://link.springer.com/article/10.1007/s10842-021-00377-1,Old Wine in New Bottles: Patenting Propensity,June 2022,Di Fan,Long Zhao,,Female,,Unknown,Mix,,
22.0,2.0,"Journal of Industry, Competition and Trade",10 March 2022,https://link.springer.com/article/10.1007/s10842-022-00381-z,"Taxation, Network Externalities, Consumer Suffering, and Profit-Raising Entry: A Cautionary Note",June 2022,Qidi Zhang,Leonard F. S. Wang,,Unknown,Male,Unknown,Male,"Greater competition is usually believed to benefit consumers and improve social welfare. However, as argued in the literature, greater competition, either due to cost reductions (Lahiri and Ono, 1988) or entry of a firm (Mukherjee et al., 2009), may reduce social welfare. More surprisingly, Dinda and Mukherjee (2014) showed that the entry of inefficient firms may even hurt consumers with the consideration of strategic unit taxation, while that of efficient firm’s benefits consumers as believed. Will greater competition always lead to a lower profit?Footnote 1 In a Stackelberg model of final goods market, Mukherjee and Zhao (2017) found that the entry always increases output of the cost-efficient incumbent and increases both industry output and profit of the cost-efficient incumbent. However, the entry always reduces the profits of the cost-inefficient incumbents. Fanti and Buccella (2017) investigated the possibility of profit-raising entry in network industries where firms follow corporate social responsibility (CSR) behaviors, showing the interaction between the network size and CSR features. In particular, for high levels of the network effect, an incumbent’s profit-raising entry effect occurs. Mukherjee (2019) showed that entry in the final goods market with product differentiation increases profits of the incumbent final good producers if there is free entry in the input market and the final goods are sufficiently differentiated. This paper has twofold under a unit tax/subsidy: (1) investigates the relationship between competition and welfare and (2) studies the profit-raising entry and consumer welfare suffering in the presence of network externalities. We find that the entry of firms improves social welfare, while the entry of inefficient firms hurts consumer surplus with network externalities. It confirms the result of undesirable competition found by Dinda and Mukherjee (2014) and Wang et al. (2019a, b) in an asymmetric Cournot oligopoly with network externality. However, the entry of efficient firm raises industry profit if the degree of network externality is relatively high. The main reason is that consumers with higher network externality have higher willingness to pay. The entry of efficient firms raise industry profit is mainly due to output-expansion effect under unit taxation/subsidy and network externalities that dominates the competition effect if the degree of network externality is relatively high. In the real world of the Internet industry, for example, there are well-known cartels in Japan's electronics industry. It involved some dynamic random access memory manufacturers including Samsung, Mitsubishi, and Toshiba. The memory chip makers share secret information to control dynamic random access memory prices and supply to PC and server makers. This paper is organized as follows. Basic modeling is provided in Sect. 2. Section 3 presents the analysis of welfare comparison of entry firms in the presence of network externalities. Section 4 provides conclusions.",
22.0,2.0,"Journal of Industry, Competition and Trade",07 April 2022,https://link.springer.com/article/10.1007/s10842-022-00382-y,Knowledge Spillovers and Productivity Growth: Role of Absorptive Capacity in the Indian Manufacturing Sector,June 2022,Ipsita Roy,Sourabh Bikas Paul,,Unknown,Unknown,Unknown,Unknown,,
22.0,2.0,"Journal of Industry, Competition and Trade",18 April 2022,https://link.springer.com/article/10.1007/s10842-022-00380-0,Do Competition Improve Persistence in Innovation Effort? Sectoral Patterns and Evidence from India,June 2022,Rituparna Kaushik,Sourabh Bikas Paul,,Unknown,Unknown,Unknown,Unknown,,
22.0,2.0,"Journal of Industry, Competition and Trade",16 May 2022,https://link.springer.com/article/10.1007/s10842-022-00385-9,Prevalence and Persistence of High-Growth Entrepreneurship: Which Institutions Matter Most?,June 2022,Eva Christine Erhardt,,,Female,Unknown,Unknown,Female,"High-growth firms are a popular target of public policy (Autio and Rannikko 2016; Grover et al. 2019; OECD 2013) following evidence that only a small number of fast growing firms creates the majority of job and output growth (Birch and Medoff 1994; Bravo-Biosca et al. 2016; Henrekson and Johansson 2010; Storey 1994). At the same time, high-growth is hard to predict (Coad and Srhoj 2019). Contradicting views widely held, high-growers are not predominantly small start-ups in high-tech industries (Daunfeldt et al. 2015) but can be larger and established firms (Henrekson and Sanandaji 2014; Weinblat 2017), originating from a variety of industries and operating across a range of locations (Coad et al. 2014; Henrekson and Johansson 2010). Rather than trying to directly support future winners within this heterogeneous group of firms, it might therefore be more promising to improve the external environment necessary for high-growth entrepreneurship to unfold. This approach builds on institutional theory, which views institutions as rules of the game for interaction influencing transaction and production cost and hence the profitability of engaging in entrepreneurial activity (North 1991, 1994). It specifically follows the central proposition by Baumol (1996) that institutions incentivize the allocation of entrepreneurial efforts towards productive, growth-oriented activities — depicted as high-growth entrepreneurship in this study — rather than unproductive, rent-seeking purposes. Extant empirical evidence indeed largely supports that institutions matter for start-ups and small businesses, especially in emerging countries with less-developed institutions (Aidis et al. 2008; Bjørnskov and Foss 2016; Bruton et al. 2010; Manolova et al. 2008; Tonoyan et al. 2010). Insights on young and small firms, however, are only useful to a limited extent in explaining the enabling environment for high-growth entrepreneurship. As argued above, not all high-growth firms start out small and young. Moreover, many new entrants have no intention to grow (Hurst and Pugsley 2011; Sanandaji and Leeson 2013; Shane 2009) representing ‘necessity-push’ firms created for lack of alternative ways of earning a living (Welter and Smallbone 2011) rather than growth-oriented, productive ventures. To gain a deeper understanding of the link between institutions and high-growth entrepreneurship, I thus investigate two closely related research questions: (a) which institutions affect the prevalence of high-growth firms and (b) which institutions affect the persistence of high-growth firms? Building on the classification of institutions by Williamson (2000), I distinguish between informal institutions (measured by corruption, crime, and mal-functioning courts), formal institutions (measured by licensing and permits, customs and trade regulation, labour regulation, tax regulation, and tax rate), and institutional governance (measured by access to finance, skilled labour, land, transportation infrastructure, and electricity). I test the hypotheses derived from the theoretical framework based on a sample of 239,911 firm observations in the emerging economy of Bulgaria. The dataset is constructed from administrative sources collected in Amadeus as well as perceptions of institutional constraints from the Business Environment and Enterprise Performance Surveys (BEEPS). It covers the period 2001–2010 and offers rich information on firms from the smaller end of the size distribution. Measuring growth by the absolute number of jobs created, I employ probit and linear fixed effect models to estimate whether institutional constraints matter for the prevalence and persistence of high-growth entrepreneurship. In doing so, this study contributes to both the literature on institutions and high-growth firms in several ways. Most importantly, this is the first test of whether the same institutional constraints affecting the likelihood of becoming a high-growth firm also influence the growth performance after the high-growth period. Both time perspectives, before and after high-growth, warrant closer inspection, because many high-growth firms are unable to continue to grow (Coad and Holzl 2009; Daunfeldt and Halvarsson 2015; Erhardt 2021; Moschella et al. 2018). Thus, by analysing whether and which institutions contribute to an environment where growth spurts do not remain an episode but the beginning of a sustained growth process, this study gains relevance for policymakers willing to support high firm growth. Moreover, firms change over the course of the high-growth period. They do become not only larger, but also more experienced and acquire a record of accomplishment. The effect of institutions on firm growth, in turn, could differ along with these changes. Regulatory burden, for example, may discourage smaller and younger firms from pursuing high-growth ambitions but might support further expansion after high growth by acting as entry barrier to new competitors. Policies that exclusively focus on institutions encouraging the emergence of high-growth firms and disregard further growth might consequently lead to unintended effects. As a further contribution to the literature, this study operationalizes productive entrepreneurship by having actually experienced high-growth and accounts for the heterogeneity of high-growth firms. One approach in previous studies is to focus on whether institutions drive or hinder entrepreneurs’ growth aspirations (Autio and Acs 2010; Bowen and Clercq 2008; Estrin et al. 2013; Stenholm et al. 2013). However, growth aspirations are not necessarily reflected in actual growth (Wiklund and Shepherd 2003). This is well illustrated for Bulgaria, where high-growth aspirations are found to be among the lowest of all countries surveyed by the Global Entrepreneurship Monitor, whereas the share of actual high-growth-firms is among the highest in Europe based on administrative data (Eurostat 2018). Hence, the approach used in this study is to investigate the influence of institutions on actual high-growers defined as the top 1% of micro-, small-, and medium-sized enterprises in terms of absolute growth in employment over a 3-year period. Next to measuring actual high-growth and including firms of all sizes, this definition also requires a minimum increase of 19 employees for qualifying as high-growth firm compared to 0.73–4.4 employeesFootnote 1 in previous studies on actual high-growth (Cuaresma et al. 2014; Krasniqi and Desai 2016; Lee 2014). Given that the attention to high-growth firms by both academia and policymakers originates from their contribution to job creation (Coad et al. 2014), insights for the specific set of high-growth firms used in this study are considered a particularly important extension to the literature. In what follows, the next section sets out the theoretical foundations for linking institutions to entrepreneurship and develops hypotheses for the influence of institutional constraints on the prevalence and persistence of high-growth. Then, I provide details on the data used and the research methodology before presenting the results of the analysis. I conclude with a discussion of findings, limitations of the analysis, and possible future research avenues.",
22.0,3.0,"Journal of Industry, Competition and Trade",18 June 2022,https://link.springer.com/article/10.1007/s10842-022-00386-8,Does the Nature of Goods Affect Bilateral Exchange of Technology and Location Choice in Stable Networks?,December 2022,Luca Correani,Fabio Di Dio,Patrizio Morganti,Male,Male,Male,Male,"The creation of a network among firms is usually aimed to provide several benefits, such as increasing their bargaining power, easing access to credit, sharing administrative and staff training costs, creating a common brand, internationalising the production, participating in public tenders, increasing the number of customers, innovating products and processes, and sharing services, know-how, and technology. Nonetheless, the relationship between the nature of the goods produced by firms and their spatial dispersion within an already formed and stable network is unclear. Motivated by empirical evidence for a sample of Italian firms differentiated with the nature of goods and services produced and the distance among firms, we extend the spatial Cournot markets model by Pal (1998) by including firm incentives to form cooperative links in order to share R&D cost-reducing investments. Specifically, we assume that firms can share their knowledge by forming a cooperative link before deciding over their own location; then, they compete à la Cournot. Such a game has been broadly used in the literature studying the formation of collaborative networks among firms (see for example Goyal and Moraga-Gonzàlez 2001; Goyal and Joshi 2003, 2006; Correani et al. 2014). Following Pal’s model, only including strategic location and quantity, we introduce two new relevant variables, namely link formation and R&D investment. In this way, our model takes the form of a complex three-stage optimization process augmented to introduce exchange of technology and strategic location. In the first stage firms decide whether to form a collaborative link, in the second one they choose their own locations, and in the final stage firms invest in cost-reducing technology and, simultaneously, compete à la Cournot. The growing interest for these issues basically reflects the policy relevance of the following questions: how networks among firms are able to channel R&D investments towards improvements in productivity and social welfare? Pal (1998) analyses the circular city model where two firms set the location in the first period and compete à la Cournot in the second period. The author shows that, in sharp contrast to the results obtained in a linear city model, firms locate equidistantly on the circle. Subsequently, Shimizu (2002) extends the Pal’s location-quantity model using the inverse demand function of Deneckere (1983) to take into account the degree of differentiation between the products. Using this inverse demand function, he shows that the maximum dispersion of firms holds only if goods are substitutes. On the contrary, when firms produce complements, they will agglomerate. Along this line of research, we thus extend the Pal’s model introducing technological spillovers and R&D investments. Our key findings are the following. First, the nature of goods produced affects the distance between firms belonging to the same networks; namely, the distance between firms is greater if they produce substitute goods whereas we obtain agglomeration (low distance between cooperating firms) when firms produce complementary or independent goods. Agglomeration is a consequence of strategic R&D investment which is absent in the models of Shimizu (2002) and Pal (1998). In our model, R&D effort is affected by location even when firms are monopolist. As a result, they will tend to agglomerate since the smaller the distance from the rival firm the higher the positive effect (externalities) from R&D cooperation. Second, we show that the cooperative link is stable regardless of the type of goods that are produced and the location choice. This result is supported by some empirical evidence for Italian firms. Specifically, we take a detailed list of firm network contracts ranging from 2010 to 2021 from the Italian Chambers of Commerce. The dataset provides a detailed description of 7171 network contracts with a total of 40,647 companies involved. For each network, the following variables are available: the number of firms involved, a detailed description of the motivations that lead firms to cooperate, the spatial location of each firm, and the industrial sector to which it belongs (Ateco Code). This information allows us to produce accurate classifications of firm networks according to the nature of the goods and services produced by the participating firms, the object of the agreement, and the number of firms involved. Besides, we selected all networks consisting of two firms aiming at technological innovation and exchange of know-how in order to make enterprises more efficient and competitive. We then categorised the selected networks according to the nature of the goods/services produced by the firms (complementary, substitutes, or independent) and, for each network, we work out the distance between the two participating firms. After this selection, we obtained a sample of 262 two-firm networks for complementary goods/services, 286 for substitute goods/services, and 275 for independent goods/services. This means that networks are formed independently of the nature of goods produced by firms, in a way consistent with the first theoretical finding of the paper. Also, by correlating the average distance between firms and the type of goods produced, we observe that networks of firms producing complementary or independent goods are more concentrated, showing a significantly lower average distance between them (see Fig. 1). In other terms, the nature of goods produced is shown to affect the distance between firms belonging to the same networks. Average distance between firms in two-firm networks by type of goods produced (2010–2021). Italian chambers of commerce. Data are availabe at https://www.registroimprese.it/inbalance Average distance between firms in two-firm networks by type of goods produced per year (2011–2021). Italian Chambers of Commerce. The first two-firm networks were formed in 2011 Figure 2 displays the same finding from a different (inter-temporal) angle. Specifically, it shows the time series of the average distance for the three different types of two-firm networks considered in our study. From Fig. 2, it comes out that networks of firms producing substitute goods draw over time a general tendency towards an increase in the average distance between firms. In other words, it emerges that the average distance between companies in the same network tends to be greater in the cases in which participating firms produce substitute goods/services, thus providing further evidence about the role of the nature of goods produced on distance between firms in forming links. All in all, both the figures provide evidence that the nature of goods produced affects the distance between firms of the same networks and this distance tends to be greater when firms produce substitute goods. This is consistent with the second theoretical finding of this paper. The rest of the paper is organised as follows. Section 2 discusses the review of the literature on R&D networks. Section 3 presents the theoretical model. Section 4 shows the main results. Section 5 concludes.",
22.0,3.0,"Journal of Industry, Competition and Trade",20 June 2022,https://link.springer.com/article/10.1007/s10842-022-00388-6,Innovations as a Response to Shadow Economy: Evidence from Privately Held Firms,December 2022,Omar Farooq,Khondker Aktaruzzaman,Fatima Zahra Bendriouch,Male,Unknown,Female,Mix,,
22.0,3.0,"Journal of Industry, Competition and Trade",28 June 2022,https://link.springer.com/article/10.1007/s10842-022-00387-7,Contract Incompleteness and the Boundaries of the Firm in Times of COVID-19,December 2022,Marta Bernasconi,Sara Galetti,Piergiovanna Natale,Female,Female,Female,Female,"Over the last few decades, the global economy has undergone two major changes that have reshaped production and trade. One pertains to the increasingly integrated nature of world markets, fuelled by trade liberalisation, regional integration agreements, falling transportation costs, and rapid technological advances (Baldwin and Venables 2013; Antras and de Gortari 2020). The second concerns the disintegration of production processes and the strategic dispersion of different value-added activities in ‘global value chains’ (Antras 2020; Kaplinsky 2020), also called ‘global supply chains’ (Baldwin 2012; Hernandez et al. 2014), or ‘global production sharing’ (Ng and Yeats 1999; Yeats 2001). These labels suggest that production processes embody value-added from multiple countries, with each country specialising in a particular production task rather than manufacturing final goods from conception to delivery. Firms increasingly participate in global value chains (GVCs), integrating backward as buyers of intermediate inputs or forward as suppliers of intermediate inputs, or both (Antras 2003; Antras and Chor 2013). The combination of world markets integration and production processes disintegration has reshaped the firm’s boundaries, producing various configurations in which some production tasks are internalised and others are externalised in the domestic country or abroad (Feenstra and Hanson 1996; Feenstra 1998). Defined as the global economy’s backbone and central nervous system, GVCs were regarded as unstoppable (Kano et al. 2020) until very recently, when they slowed down—if not completely stopped—because of COVID-19. Javorcik (2020) argued that the pandemic posed an existential threat to GVCs. In the past, health-related crises and supply chain disruptions occurred because of SARS, Ebola, and the swine flu epidemic, with adverse effects on the global economy and trade. However, the socio-economic impact of COVID-19 is expected to be more severe, comparable with that of the Great Depression of 1929, the Second World War, and the Great Recession of 2008–2009 (Kowalski 2020). Participation in GVCs greatly increases countries’ and firms’ exposure to the epidemic shock as it entails that a disruption in any upstream stage ripples down, investing downward stages. Likewise, any adverse shock affecting downward stages transmits upwards, causing disruptions in markets that would otherwise be unaffected by the shock. The COVID-19 pandemic, causing upstream and downstream disruptions, poses new challenges for firms stretching their boundaries across countries (Baldwin et al. 2020). A shock of this magnitude is expected to create a discontinuous shift in the preferences and expectations of consumers, firms, and organisations. It is likely to produce significant and widespread effects in the short, medium, and long run. Following Antras (2020), we believe that the impact of COVID-19 on GVCs can be fully assessed only at the firm level, investigating the firm’s boundaries. This is because participation in GVCs amounts to a joint ownership and location decision (Antras and Helpman 2004). For simplicity, consider a stylised framework in which the production of a final good requires intermediate inputs. In this context, the final good producer takes two crucial decisions over sourcing. The final good producer has to decide whether to make the components itself or buy them from an independent input supplier (ownership decision); conversely, it has to decide whether to employ domestic inputs or foreign inputs (location decision). In this framework, studying the firm’s boundaries means addressing sourcing issues at the crossroad between ownership and location considerations. Previously, sourcing was a local phenomenon; the firm’s boundaries could be fully explained in terms of the ownership decision, the choice being restricted to make-or-buy. Nowadays, sourcing has become a global phenomenon; therefore, the firm’s boundaries should be addressed considering ownership and location decisions jointly, the choice involving the make-or-buy, and the domestic-or-foreign alternatives. In this paper, we empirically study the firm’s boundaries in times of COVID-19. For the present research, we provide new empirical evidence on a large stratified sample of Italian manufacturing firms headquartered in Lombardy, one of the most developed regions in Europe and, concurrently, one of the first regions severely affected by the COVID-19 pandemic. Particularly, our evidence draws on survey interviews conducted between April and July 2020 of a sample of 212 Italian firms headquartered in the region and stratified by size, manufacturing activity, and province. Considering the incomplete contracts theory/international economics perspective, we study the sampled firms’ boundaries in times of COVID-19, discussing the extent to which input specificity and productivity affect ownership and location decisions. This allows us to portray sourcing strategies at the onset of the pandemic. Moreover, we investigate the sampled firm’s plans to permanently rethink their ownership and location decisions because of the pandemic. This allows us to capture the expected medium- and long-run effects of COVID-19 on sourcing. Based on survey data, our sample’s ownership decision involves relying on independent input suppliers the most, engaging in outsourcing more than insourcing. Regarding location, Lombardy firms employ domestic inputs the most, engaging in domestic sourcing more than foreign sourcing. Our descriptive statistics and econometric analysis suggest that the ownership decision is driven by input specificity, whereas the location decision mainly depends on productivity. Our results are consistent with our conceptual framework: in a context of contract incompleteness, the more important the specific inputs, the more likely the insourcing relative to outsourcing; moreover, the more productive the firm, the more appealing the foreign sourcing than domestic sourcing. Our results are robust to alternative productivity and input specificity measures and various controls at the firm, industry, and province levels. Moreover, they survive in a wide range of econometric models—including probit, bivariate probit, and multivariate probit—and survey estimation methods. Interestingly, our descriptive statistics reveal that the pandemic has adversely affected business for 89% of the sampled firms, irrespective of their geographical location, manufacturing activity, and size. These firms assign an important role to their supply chain in mitigating the impact of COVID-19. Moreover, the firm’s boundaries show a great deal of inertia; just a handful of firms plan to change their ownership and location decisions permanently because of the pandemic. Then, they plan to switch from insourcing to outsourcing and from foreign to domestic sourcing. This suggests that value chains will survive the COVID-19–induced permanent changes; however, we expect them to be less global in the future. The rest of the paper is organised as follows. Section 2 introduces our conceptual framework. Section 3 provides background information about Lombardy. Section 4 describes data, empirical methodology, and results. Section 5 summarises our main findings, derives policy implications, and suggests future lines of research.",1
22.0,3.0,"Journal of Industry, Competition and Trade",04 July 2022,https://link.springer.com/article/10.1007/s10842-022-00389-5,Licensing Innovation in Mixed Multinational Markets with Stackelberg Leadership,December 2022,Ali Dadpay,Faraz Farhidi,J. Alejandro Gelves,Male,Unknown,Unknown,Male,"Should a leading domestic business license its cost-saving innovation to a foreign firm? This study is an effort to find the answer to this question. Recent years have witnessed a remarkable increase in the applications of mixed oligopoly theory, developed initially by Merrill and Schneider (1966), to study and to analyze interactions between firms of different structures in domestic and multinational markets. Among the most recent articles on global mixed oligopoly markets, one can mention Wang and Tomaru (2015), Xu and Lee (2015), Chen (2017a, b), Han et al. (2017), Wang and Zeng (2019), and Dadpay et al. (2019). The present extends the existing literature by analyzing the case for licensing in an international market in the presence of a Stackelberg innovator who must decide to approve the innovation to firms of different nationalities. In doing so, it provides a theoretical framework to study emerging global manufacturing, telecommunication, banking, and aviation trends. In addition, this article considers the differences between drastic and non-drastic innovation to view a multinational model to study licensing. An innovator can push its rivals out of the market if it offers a powerful innovation because of significant cost differentials. The only way for the competition to survive is to purchase a license for the new drastic innovation. Otherwise, the rival firms cannot compete with the innovator. We utilize mixed oligopoly theory to explain the interactions between private and partially public firms regarding licensing. In doing so, we are inspired by the commercial aviation industry and its markets worldwide, where many partially private airlines interact with private ones in different markets. Commercial aviation has prompted several researchers to use the mixed oligopoly model to study the interactions between public and private firms when they offer their services to customers of different nationalities. Simultaneous liberalization of the commercial aviation industry in Europe prompted Dadpay and Heywood (2006) to investigate privatization in multinational markets using a mixed oligopoly framework. Later Dadpay (2014) studies the role of subsidization in multinational markets as a trading instrument using the example of airlines in the Persian Gulf region. One cannot help noticing an increasing number of airlines seeking to operate in markets where private or partially private airlines have been working for decades. As the aviation industry evolves, airlines differentiate their cost structures. Some, such as Emirates and Qatar Airways, owned partially by the public entities, offer luxurious air travel services in the same markets where low-cost carriers operate. We ask ourselves what the most optimal licensing procedure is in such markets? Thus, we stand at the intersection of mixed oligopoly studies and the existing literature on licensing. We hope to further investigate by reviewing the case where a domestic firm is a leader in the market. Licensing innovation often enables innovators to generate revenues. It also means that their competitors compete more efficiently. Eswaran (1994) argues that licensing can create collaboration where firms’ products are imperfect substitutes. Rockett (1990) explains that firms choose their competition through licensing. An innovator can ensure its dominance in the marketplace if it licenses its innovation only to weak competitors. Anecdotally this argument holds that public firms have the rights and licenses to operate or utilize the products. They can use licensing to stay dominant in the market. The licensing pattern varies according to market structure and the innovator’s cost structure. Filippini (2005) investigates the optimal linear licensing policy using a Stackelberg quantity competition model in a domestic market. He concludes that when the innovator is an insider, the optimal licensing contract is a royalty if the patentee wants to maximize profit. Ye (2012) compares licensing through either a fixed fee or a royalty with a public innovator and a foreign firm in the domestic market. Expanding the literature on licensing to study the impact of network and technology, Zhang et al. (2018) suggest that royalty licensing is optimal with common network effects, while high network effects, the market size, and the licensee’s cost structure become the determinant factors. Chen (2017b) analyzes the optimal licensing strategy when a licensor firm competes with potential licensee firms. He suggests that fixed fees will be the best licensing policy if endogenous entry is possible in the industry. Zhang et al. (2018) and Chen (2017b) are only two examples of investigations focusing on finding the optimal licensing policy under different structures. The existing literature on mixed oligopoly treats a foreign firm’s entry into the market as a significant event. It is substantial enough to alter market equilibrium and influence existing firms’ strategies and pricing behavior. Fjell and Pal (1996) show that when a state-owned public firm competes with foreign private and domestic firms, the equilibrium price falls. Fjell and Heywood (2002) demonstrate that the welfare-maximizing Stackelberg leader alters its pricing facing foreign competition. They also show for the first time that the consequences of privatization in this market depend on the relative size of domestic firms. Matsumura (2003) proves that the state-owned public firm should assume leadership when foreign firms enter the domestic market. Chao and Yu (2006) study tariff policy in a mixed oligopoly market and conclude that the optimal tariff increases when a foreign firm enters the market. It is time to look if an innovator’s licensing policy changes when facing a foreign competitor. Given the increasing popularity of the mixed oligopoly analytical framework to study firms’ strategies, some have already used it to investigate licensing. It must be noted that many emerging economies and economies in transition have provided ample examples of the cases where a state-owned public firm or a mixed-ownership firm has to decide about licensing. The researchers’ increasing use of the mixed oligopoly framework to study these economies has made it the standard analytical tool for such studies. Motivated by the examples from Japan’s economy, Matsumura (1998) assumes that an ownership firm considers both profit and social welfare. Using this approach, Gelves and Heywood (2016) investigate how a disadvantaged mixed-ownership innovator decides to license its patented innovation. They show that such an innovator often licenses through a fixed fee alone. Heywood and Wang (2017) study the effect of an R&D rivalry under spatial price discrimination to compare alternative timing. Finally, Heywood et al. (2019) extend this model to include a more efficient foreign rival showing that ad valorem fees dominate fixed and royalties. The present study uses a three-stage game between two firms, one domestic with mixed ownership and the other a profit-maximizing foreign private firm, to investigate the licensing behavior where a mixed-ownership innovator licenses a foreign firm to compete in the domestic market. This setup covers the decision to license, the terms of licensing, and then compete in the market between a foreign private firm and a partially domestic firm. Thus, it departs from the existing literature by considering a Stackelberg model. It must be noted that in many global air transport hubs such as Doha, Dubai, and Singapore, the flag carriers have the majority share of the air travel market across different routes. The remaining airlines of different nationalities compete in the residual market, paying fees to have the necessary permits. The rest of the paper is organized into five sections. The second section reviews the model setup based on a no-licensing benchmark. The model analysis follows this in the third section and discusses our findings in the fourth section. Finally, the fifth and the last section summarizes the conclusions of this study while suggesting new ways of furthering the study of licensing in the mixed oligopoly markets.",
22.0,3.0,"Journal of Industry, Competition and Trade",26 August 2022,https://link.springer.com/article/10.1007/s10842-022-00390-y,Market Regulation and Innovation: Direct and Indirect Effects,December 2022,Aurelien Quignon,,,Male,Unknown,Unknown,Male,"The relationship between innovation and productivity growth in the endogenous growth literature and among policy makers is at the heart of the debates (e.g., Grossman and Helpman 1991, Romer 1990, and Aghion and Howitt 1992).Footnote 1 This broad consensus on the contribution of innovation contrasts with the mixed evidence of the effects of competition on innovation. This paper empirically considers the effectiveness of competition on innovation, differentiating between domestic and foreign competition. We look at how various kinds of competition impact directly innovation intensity, which is relevant for prioritizing reforms (Tables 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11). How competition impacts innovation is of long-standing theoretical interest. In theory, the impact of competition-enhancing product market regulation on innovation is based on competing theories advanced by Schumpeter (1934) and Arrow (1962).Footnote 2 Schumpeter (1934) suggested that rising market competition discourages innovation (i.e., ""Schumpeterian effect"") by lowering expected Research and Development (R&D) investment payoffs (e.g., Dasgupta and Stiglitz 1980, Dixit and Stiglitz 1977, and Romer 1990). By contrast, Arrow (1962) argued that competition improves the incentive to innovate through an escape effect, hence raising innovation rents (e.g., Gilbert and Newbery 1982 and Reinganum 1983). Endogenous growth theory has introduced a model in which the Schumpeterian and escape effects interact with innovation intensity via an inverted U-shape (Aghion and Howitt 1998). Thus, depending on the market structure (i.e., the technological gap between firms) and the initial level of competition, competition-enhancing policies may have opposing impacts on innovation intensity at the country level. In this paper, we evaluate the effects of domestic and foreign product market competition regulation on R&D intensity and patenting, as well as how they directly or indirectly promote innovation, using data from 25 OECD countries from 1995 to 2015.Footnote 3 We used aggregate as well as sub-indicators on factors reflecting rules and bureaucratic procedures that impede entrance and trade barriers that diminish competition to quantify domestic and international product market regulation.
 Our findings imply that reducing regulation while enhancing domestic product market competitiveness is related to higher R&D intensity and patenting. Furthermore, raising the level of foreign competition increases the number of patents while having ambiguous impacts on the intensity of R&D in our baseline specification. Using the sub-indicators of domestic and foreign competition, the effects can be partially explained by market competition policies that reduce barriers to new entrants and administrative costs, whereas non-tariff barriers, rather than tariffs, had the effects according to our innovation measures. Finally, the effect of domestic and foreign competition can be nonlinear and depends on country’s characteristics like the level of development or exposure to trade. We explore these interactions and find evidence of nonlinearities. The effects of domestic regulation are more favorable for R&D expenditures in countries in which the level of development and trade openness are stronger. In contrast, deregulation fostering foreign competition harms patenting intensity, which is strongest for more developed countries and where the level of trade exposure is higher. The main challenge to our identification strategy is the possible reverse causality between innovation and competition reforms as well as the existence of omitted variables. We address these issues in several ways. First, to address endogeneity issues we use aggregate measures of competition regulation in European and non-European countries as an instrument for regulation in a particular country. Our conclusions are robust to the instrumental variable (IV) specification with larger point estimates than Ordinary Least Squares (OLS) estimates. Second, the estimates are stable to the inclusion of lagged competition regulation indicators that reduce potential reserve causality between competition and innovation intensity. Finally, our results are robust to alternative specifications, controlling for confounding factors such as import intensities and foreign R&D and measuring product market regulation through OECD’s indicators. Domestic and foreign competition might have a different magnitude in enhancing innovation. Related literature does not compare the effect of the source of competition reforms. In addition to challenging the ambiguous empirical findings on the relationship between innovation and regulation, this paper goes even further in empirical identification. Instead of findings based only on regression identification and reduced-form,Footnote 4 we use causal structure methodology that allows discovering endogenously causal relations and ordering determinants of innovation. Differentiating between domestic and foreign competition regulations (i.e., the extent to which regulation directly promotes innovation) may reconcile contradictory findings and the significance of underlying processes. We investigate causal relationships to determine whether sources of competition rules are direct drivers of innovation intensity. We rely on a Directed Acyclic Graph (DAG) technique based on a search algorithm (Pearl 1995). According to the DAG, the sole direct driver of innovation intensity is domestic regulation that improves product market competitiveness, whereas international regulation has an indirect influence on R&D intensity and patenting at the country level. Furthermore, the magnitude of the causal effect of product market regulation is quite close to the point estimate obtained by IV specification. These findings point out mechanisms in the innovation–competition relationship, which have important policy implications. The remainder of the paper is organized as follows. Section 2 presents the related literature and states empirical hypotheses. Section 3 presents the main variables, data sample and discusses our identification strategy. Section 4 discusses our results and robustness tests. Section 5 concludes and discusses the policy implications of our results.",
22.0,3.0,"Journal of Industry, Competition and Trade",10 November 2022,https://link.springer.com/article/10.1007/s10842-022-00391-x,Global R&D Location Strategy of Multinational Enterprises: an Agent-Based Simulation Modeling Approach,December 2022,Haruo H. Horaguchi,Toichiro Susumago,,Male,Unknown,Unknown,Male,"The strategy of locating research and development (R&D) activities in the global market is an important issue in international business (Coronado et al. 2008; Cuervo-Cazurra et al. 2017). A multinational enterprise (MNE) looks for the best place to secure knowledge bases in the global market (Blanc-Brude et al. 2014; Buckley and Ghauri 2004). For multinational enterprises (MNEs), location strategies are crucial for achieving this objective. Most MNEs establish research projects in countries that have world-class universities as research centers and forge alliances with knowledge workers and highly innovative start-ups (Piperopoulos et al. 2018). Porter (1990) summarizes that strategy, structure, rivalry, factor conditions, related and supporting industries, and demand conditions as the reasons for firms to select specific locations. The location strategy of MNEs is discussed to explain agglomeration in empirical studies (Rugman 2000; Myles Shaver and Flyer 2000; Cantwell 2009) in which various elements of natural, human, and knowledge resources are included to explain the phenomenon of clustering (Sebestyén and Varga 2019). We argue that the discussion on MNEs’ R&D location strategy has been somewhat confusing. The cause of this confusion is that the location strategy theory has been discussed in terms of natural endowment, management resources of MNEs, and the strategic positioning of MNEs in the market (Goerzen et al. 2013; McCann and Mudambi 2005). Location strategies have been discussed based on the coexistence of internal and external factors for MNEs. This coexistence causes some confusion because the location theory was not wholly captured from the perspective of theoretical confinements. In empirical studies on location strategies, relevant variables were included as long as they were observable. Explanations are provided when plausible variables are found to be statistically significant (Caves 1982; Dunning 1980, 1988, 1993). The deductive theoretical approach is not a major thrust area in location strategy research and has not been sufficiently examined (Nielsen et al. 2017). In a scientific analytical approach, it is fundamental that researchers focus on certain factors and disregard others. The model should control and extract essential factors from various influences while focusing on theoretical factors. However, in international business research, only a few approaches focus on an essential factor in a scientific manner. In this study, we single out the strategic location effect as an essential factor in a deductive theoretical approach to inquire location strategy. Using the deductive approach of agent-based simulation (ABS), we focus only on strategic location effects, assuming that the influence of internal management resources held by MNEs is constant (Penrose 1959; Teece et al. 1997). There are two types of simulation models used in economics. The first incorporates conditions close to reality into the model and confirms the changes caused by the changes in the parameters. These simulation models are useful when physical conditions, such as weather and aerodynamics, are stable. In economics, similar ideas are applied to macroeconomic interstate trade. The second is to loosen some of the assumptions in the theoretical model and reach conclusions in more complex situations. Simulation models in microeconomics are examples of such simulation models. This is similar to the simulation model of the infectious disease virus transmission process. With these micro-approaches, the significance of adding real-life conditions is limited. There are an infinite number of “real-world” examples, and we cannot trace them all. In the competition between firms in microeconomics, there are various conditions such as price, quantity, location, investment strategy, human resources, finance, division of labor, and logistics. If these variables are incorporated so that the simulation model is closer to reality, it becomes impossible to find a solution. In such cases, the solution is either equilibrium or imbalance, and only ABS can find the result of market competition. Of course, we do not deny that management resources such as brand equity and technology can broaden the location selection criteria of MNEs (Porter 1998). However, we want to improve the theory of location strategy scientifically by extracting the effect of location choices. In our study, MNEs’ external factors such as factor conditions, related and supporting industries, and demand conditions in the host countries are considered equal. The reason for such sophistication is that many MNEs relocate their R&D subsidiaries overseas over the long term (Buckley and Mucchielli 1997; Pennings and Sleuwaegen 2000). Withdrawal of investment from foreign markets has also been observed in many countries and industries (Horaguchi 1993; McDermott 2010). If factor conditions, related and supporting industries, and demand conditions are the reasons for choosing the R&D location, then MNEs do not shift the locations unless resources are exhausted, supporting industries are extinguished, or demand conditions are rapidly declining. It is common for MNEs to repeat location changes and withdraw foreign direct investment (FDI)(Vernon 1966; Mesquita 2016). A new theoretical approach is necessary to address this gap in exploring the key characteristics of the relocation strategy of MNEs in global markets (Kim and Aguilera 2016). We propose the following research questions: What kind of competition pattern is found when it is assumed that MNEs will compete only on the strategy of selecting R&D locations to use the available knowledge resources and move the R&D locations multiple times? What kind of R&D location strategy can we find, given that all MNEs compete for absorbing the knowledge input based on market proximity? What tendencies can be observed in the selection of multinational corporations’ R&D locations if we assume that MNEs’ internal resources are equal to the pure location choice effect? Given that the preconditions of MNEs such as economies of scale by oligopolistic large enterprises are controlled completely and MNEs compete only by location selection of R&D, what kinds of trends can we find in location strategy? In the ABS modeling, can we observe agents that adopt a niche market strategy or blue ocean strategy? If so, how long will the agent adopt one of these strategies? This location strategy perspective is relevant to the positioning strategy (Porter 1980; Mintzberg and Lampel 1999; McGrath 2013) as well as the blue ocean strategy (Kim and Mauborgne 2005) by MNEs because the concept of a niche market is prevalent among business people and in the strategic management literature (Porter 1985; Barney 2001). ABS modeling has the advantage of incorporating time as one dimension (Gómez-Cruz et al. 2017). Thus, we observe the dynamic interactions among agents in the market.",
22.0,3.0,"Journal of Industry, Competition and Trade",11 November 2022,https://link.springer.com/article/10.1007/s10842-022-00392-w,Price-Rising Competition: a Higher Market Price When a Monopoly Faces a Small Entrant,December 2022,Jing Shao,Huanhuan Chen,Jinke Li,,Unknown,Unknown,Mix,,
22.0,3.0,"Journal of Industry, Competition and Trade",22 November 2022,https://link.springer.com/article/10.1007/s10842-022-00394-8,Endogenous Determination of Strategies in a Kantian Duopoly,December 2022,Yasuhiko Nakamura,,,Male,Unknown,Unknown,Male,"This study revisits the endogenous selection problem of each firm’s strategy (price or quantity) in an oligopolistic market. We focus on a duopoly wherein both firms behave as Kantians in all competition structures, similar to Roemer (2010) and Roemer (2015). Unlike purely self-interested firm behaviors, altruistic behaviors among Kantian firms were formalized in Laffont (1975), questioning the validity of the Nashian assumption in predicting agents’ behavior. However, the model presented in Laffont (1975) assumed identical agents, and Roemer (2010) and Roemer (2015) proposed a more general model with heterogeneous Kantians. Kantian cooperation—developed by Roemer (2010) and applied in Roemer (2015) and Roemer (2010)—provided a comprehensive approach to maximizing the sum of profits. In the approach by Roemer (2010) and Roemer (2015), a Kantian firm would care solely about its own profit by making its selfish and decentralized form of cooperation based on Kantian optimization. In the context of oligopoly theory, a Kantian firm would increase its effort if and only if its own profit would increase when all existing firms exert higher efforts. Remarkably, in this cooperative formulation, each firm is solely concerned with maximizing its own profit. Hence, Kantian cooperation is also selfish and decentralized like the noncooperative equilibrium. Furthermore, Ghosh and Van Long (2015), Grafton et al. (2017), Roemer (2010), and Eichner and Pethig (2020) applied the Kantian approach introduced in Roemer (2010) and Roemer (2015) in various contexts, such as, environmental problems, public and private good provision, income taxation, and tax competition, respectively. Most recently, Nakamura (2022d) explored a scenario wherein each firm endogenously selected either a Kantian or Nashian action principle in a duopoly market. Existing studies have explored the significance of Kantian cooperation, such as à la Laffont (1975) and Roemer (2010). Essentially, each firm’s Kantian cooperation has empirical basis as it explains widespread price markups caused by entry barriers (e.g., patents, licensing, policy aspects, and so on). More concretely, in Slade (1986) and Slade (1990), the situation wherein a firm expects the same rate of change in its price as that of its rival firms were referred to as “Kantian conjecture price-matching.”Footnote 1 Additionally, as indicated in Donduran and Ünveren (2021), each firm’s Kantian optimization can become a typical example of “all hanging together,” without behaving individually and separately. Hence, we can adequately believe that firms hope to cooperate with each other and resist excessive competition based on the somewhat moral motivation in some corresponding oligopolistic industries. The moral philosophy of each firm’s Kantian behavior is also emphasized by Grafton et al. (2017) in the climate change mitigation context.Footnote 2 Furthermore, in the business ethics context, recent studies by Bowie (2017), White (2011), and Heath (2014) thoroughly discuss Kantian firms. This study focuses on the endogenous selection problem for each firm’s strategy. Singh and Vives (1984) first discussed this problem in the modern game theory context. In a Nashian differentiated duopoly, Singh and Vives (1984) demonstrated that firms prefer the quantity (price) strategy, considering that their goods are substitutes (complements).Footnote 3 Subsequently, Tanaka (2001a), Tanaka (2001b), and Tasnádi (2006) confirmed the robustness of the results discussed above in Singh and Vives (1984) in several economic environments.Footnote 4 More recently, Ghosh and Mitra (2014), Kopel (2015), Liu et al. (2015), Matsumura and Ogawa (2016), and Fanti and Buccella (2018) investigated the endogenous decision of each firm’s strategy à la Singh and Vives (1984) in an oligopolistic market with CSR firms.Footnote 5 However, in all the previous studies, every firm was assumed to behaves as Nashian in the market. Therefore, this study should be considered the first step in the endogenous determination problem for each firm’s strategy in the setting wherein each firm behaves as a Kantian. In a Kantian duopoly with substitutes, we demonstrate that Bertrand competition can become the equilibrium market structure (EMS) for any degree of homogeneity between goods produced by both firms. Cournot competition can also become the equilibrium market structure if each firm’s marginal cost is high relative to degree of homogeneity. Moreover, this result is strikingly different from that in a Nashian duopoly if goods are substitutes, which is obtained in Singh and Vives (1984). Conversely, in a Kantian duopoly with complements, we demonstrate that if each firm’s marginal cost is high relative to the degree of homogeneity between goods produced by each firm, two asymmetric market structures relative to its strategy can become the EMS. Conversely, Cournot competition can uniquely become the EMS otherwise. Additionally, the result in a Kantian duopoly with complements is also strikingly different from that in a Nashian duopoly with complements, similar to the case of substitutes. Additionally, in this paper, we tackle the problem of whether the EMS(s) can coincide with socially preferable market structure(s) from the perspective of social welfare or not when the goods are substitutes and when goods are complements. In a Kantian duopoly with substitutes, an area of the degree of homogeneity between the goods produced by each firm and its marginal cost exists in that the EMS(s) can coincide with the socially preferable market structure(s) if its marginal cost is sufficiently high relative to degree of homogeneity. Conversely, in a Kantian duopoly with complements, a similar larger area of the degree of homogeneity and its marginal cost exists unless its marginal cost is sufficiently high relative to degree of homogeneity. Consequently, in a Kantian duopoly, the free selection of each firm’s strategy should be permitted when the goods are complements rather than when the goods are substitutes. The remainder of this paper is organized as follows. In Section 2, we formulate the basic model. In Section 3, we derive the equilibrium market structures and describe the welfare implications of the structures both when goods are substitutes and complements. Section 4 concludes this paper. In the A, we present the process of deriving the equilibrium market outcomes and concrete values in each competition structure.",3
22.0,3.0,"Journal of Industry, Competition and Trade",25 November 2022,https://link.springer.com/article/10.1007/s10842-022-00393-9,The Welfare Impact of New Firm Acquisitions,December 2022,Luis Gautier,Mahelet G. Fikru,,Male,Unknown,Unknown,Male,"In the past two decades, several horizontal merger and acquisition (M&A) deals which involve the purchase of new businesses by relatively larger firms have taken place. For example, in 2016, Hormel Foods Corporation, a multi-plant food processor, announced its acquisition of Justin’s LLC, a start-up snack food producer. Another example is large high tech firms that have frequently acquired start-up businesses (Bryan and Hovenkamp 2020). While this has raised concerns over the elimination of competition and market power in certain industries, there are not many studies that model the welfare impacts of the acquisition of new or start-up firms. It is not clear under what conditions such acquisitions improve or reduce economic welfare and which sectors are likely to harness welfare gains or losses, if any. It is also not entirely clear how and whether merger control policies ought to be used to regulate firms engaged in such deals. Previous studies have used different methodologies and frameworks with varying assumptions on market and technology parameters to examine the welfare impact of plant-ownership structures, including M&As, yielding different results and implications. This provides an excellent benchmark through which the impact of start-up acquisitions could be evaluated. In this paper we provide a comprehensive review of studies on the welfare impact of M&A deals and propose an extension, not yet adopted in the literature, to re-examine the merger-welfare relationship when new firms are acquired. While other studies look at new firm entry after acquisitions or merger induced firm entries (e.g., Davidson and Mukherjee 2007), we look at entry of new firms followed by the acquisition of some or all. Thus, the unique aspect of our model is that it captures the acquisition of new firms that enter a market. Our framework allows us to address the following research question in Cournot markets with the entry of new firms: Under what conditions does the acquisition of new firms by an incumbent multi-plant firm enhance welfare? Overall, our results suggest that the profitable acquisition of new firms is not necessarily harmful for welfare as long as (1) the number of new firm entry is within a given range (i.e., not too many and not too few), (2) sufficient oligopolistic interdependence is present (output response from firms not involved in the acquisition deal or outsider firms), and (3) there are cost symmetries. The key factor that makes the privately beneficial acquisition of new firms welfare enhancing is the profit opportunity for outsider firms and oligopolistic interdependence, given the restriction on the number of new firm entry. Our findings imply that, under the given conditions, such acquisition deals may not necessarily need to trigger a scrutiny from merger control policies. Our model also highlights the importance for merger control policies to pay attention to the specific number of new firms that enter a given market when there are no cost synergies. In Section 2 we present a review of the literature on the welfare impacts of M&As, including the relatively more recent literature of new firm or start-up acquisitions. In Section 3 we present the model, assumptions, and derive conditions under which the profitable acquisition of new firms affects economic welfare. We also present a discussion of results and implications for policy. Section 4 presents concluding remarks.",
