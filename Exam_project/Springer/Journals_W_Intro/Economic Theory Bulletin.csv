Volume,Issue,Journal Name,Published Date,Link,Title,Journal Year,Author 1,Author 2,Author 3,Gender_Author 1,Gender_Author 2,Gender_Author 3,Article_Gender,Intro,Citations
1.0,1.0,Economic Theory Bulletin,28 May 2013,https://link.springer.com/article/10.1007/s40505-013-0014-4,Editorial,May 2013,David K. Levine,Nicholas C. Yannelis,,Male,Male,Unknown,Male,,
1.0,1.0,Economic Theory Bulletin,04 April 2013,https://link.springer.com/article/10.1007/s40505-013-0010-8,Incentive compatibility of rational expectations equilibrium in large economies: a counterexample,May 2013,Yeneng Sun,Lei Wu,Nicholas C. Yannelis,Unknown,,Male,Mix,,
1.0,1.0,Economic Theory Bulletin,05 April 2013,https://link.springer.com/article/10.1007/s40505-013-0013-5,Using oriented volume to prove Sperner’s lemma,May 2013,Yakar Kannai,,,Male,Unknown,Unknown,Male,"Sperner’s (1928) well-known lemma is used to prove the Brouwer fixed point theorem (and is actually equivalent to it), and has been used frequently, along with various generalizations, to establish fundamental results in game theory and in economics (see e.g. in Kannai 1992; McLennan and Tourky 2008; Scarf 1982; Shapley and Vohra 1991 and in the references quoted there). Motivated by the wish to provide a proof “sufficiently short or intuitively appealing to be attractive in the context of texts on mathematical economics”, a proof which can be “reasonably be assumed to be part of the prior knowledge of students studying mathematical economics, at least at the advanced level” was supplied in McLennan and Tourky (2008).Footnote 1 The proof of Sperner’s lemma provided in Kannai (1992) is based (via Kannai 1981) on an argument involving volume (as in McLennan and Tourky 2008), but involves “advanced calculus”, unfortunately not too familiar to the present generation of students studying mathematical economics. In the present note we provide an elementary proof of Sperner’s lemma, inspired both by McLennan and Tourky (2008) and the method of Kannai (1992) and Kannai (1981). This proof uses the concept of oriented volumeFootnote 2 rather than the volume itself, but requires no extra parameter for homotopy. Observe that we actually prove a stronger form of Sperner’s lemma (the oriented version), due to Brown and Cairns (1961), see Sect. 4. Sperner’s lemma is stated and proved in Sect. 2, where the necessary concepts are recalled for convenience of the reader. (For completeness we follow McLennan and Tourky (2008) and define affine dependence, simplices, and triangulations.) The main technical tool is the Main Lemma, establishing equality (2) of the oriented volume of the image of a simplex with the sum of the oriented volumes of images of the simplices in a triangulation of the simplex under a Sperner labeling. In Sect. 3, a proof along similar lines is provided for generalizations of Sperner’s lemma, such as the Sperner–Shapley’s lemma, [this generalization is useful, e.g., in proving Scarf’s theorem on non-emptyness of the core of a balanced game, see Shapley (1973) and also Kannai (1992)], and for more general forms (used for example in Section 7 of Scarf 1982). In addition, the Main Lemma is generalized to a certain class of pseudomanifolds with boundaries. In Sect. 4, we comment on relations between arguments and results described in this note and well-known ideas. As stated earlier, the prerequisites needed for understanding Sect. 2 are minimal. In Sect. 3, we use freely standard topological concepts and terminology, such as may be found, e.g., in Seifert and Threlfall (1980) or Spanier (1966). I am very much indebted to Prof. H. E. Scarf for several very useful comments.",2
1.0,1.0,Economic Theory Bulletin,11 April 2013,https://link.springer.com/article/10.1007/s40505-013-0011-7,On the existence of coalition-proof Bertrand equilibrium,May 2013,R. R. Routledge,,,Unknown,Unknown,Unknown,Unknown,,
1.0,1.0,Economic Theory Bulletin,01 April 2013,https://link.springer.com/article/10.1007/s40505-013-0009-1,Eliciting beliefs by paying in chance,May 2013,Alvaro Sandroni,Eran Shmaya,,Male,Male,Unknown,Male,"Several mechanisms, often called proper scoring rules, incentivize an expert to honestly report his subjective probabilities. However, these mechanisms often assume that the expert is risk neutral or that the expert’s preferences over risk are known. Recently, Karni (2009) showed a novel mechanism that induces truth reporting even if the expert’s preferences over risk are not known. Lambert (2011) characterizes the mechanisms that induce truthful-revelation with unknown preferences. In this paper, we describe a very simple principle that can also be used to dispose the assumption that the expert’s preferences are known when beliefs are elicited. There are two monetary rewards. The expert receives the greater reward with odds proportional to a proper scoring rule. Payments based on this principle delivers incentives for an expert to truthfully reveal what he knows, even if his attitudes toward risk are unknown. We present two examples to illustrate the use of this principle. In the first example, we consider a traditional proper scoring rules (the Brier Score). In the second example, we consider Prelec (2004) “Truth Serum” which elicits honest opinions in the absence of any data. In both cases, the original mechanism is based on known preferences. We show how to transform these mechanisms, with the principle mentioned above, so that the assumption of risk-neutrality (or known attitudes towards risk) are disposed. While we provide no general results, we hope that these two examples illustrate the basic principle clearly.",5
1.0,1.0,Economic Theory Bulletin,25 March 2013,https://link.springer.com/article/10.1007/s40505-013-0006-4,Revealed cardinal preference,May 2013,József Sákovics,,,Male,Unknown,Unknown,Male,"Assume that there are two discrete goods, A and B, and two observations: when the price vector is \((p_{A}^{1}=1,p_{B}^{1}=3)\), the consumer chooses B, when the price vector is \((p_{A}^{2}=1,p_{B}^{2}=2)\) she chooses A. Intuitively, this does not seem to be rational behavior: a decrease in the price of B has made the consumer switch away from it. However, according to the accepted theory of revealed preference (for a synopsis, see Varian 2006), these choices are consistent with the consumer maximizing a(n ordinal) utility function subject to a budget constraint: any utility function that assigns a higher value to B than to A is acceptable.Footnote 1 How come? The reason is implicit in the definition of the hypothesis we are testing. As each observation corresponds to a different decision, even if the preferences are assumed constant, the budgets are allowed to vary. Consequently, there seem to be “ too many” degrees of freedom: as we cannot reject the possibility that in the second experiment the consumer had a budget less than 2, the second observation is effectively discarded. To resolve this problem, I suggest that we should discard the notion that the consumer is budget constrained, instead. To replace the budget constraint—following Marshall (1890)—assume that the consumer is endowed with a marginal utility for money, \(\lambda .\) Now both observations count and we have two inequalities that need to be satisfied for the data to be consistent with our new definition of rationality: Substituting in It is immediate that, despite having an additional constraint, consistency can be assured: as long as \(\lambda _{2}\ge 2\lambda _{1},\) there exist (cardinal) utility levels such that both inequalities are satisfied.Footnote 2 That is, if (and only if) we cannot reject the possibility that the consumer values money at least twice as much in the second experiment, the data continue to be reconciled with the—modified—theory. So far it seems that the two modeling assumptions are operationally equivalent. Not quite so! Unlike budgets, the marginal utility of money is not mercurial: barring significant shocks to lifetime(!) wealth occurring between the experiments, \(\lambda \)—understood as the value of an extra dollar to the consumer in the rest of her life—should be (at least, approximately) constant across the observations. Taking this on board, our consistency conditions become which obviously cannot be satisifed for any \(\lambda >0.\)
 Consequently, appealing to the “stickiness” of marginal utility of money, we can refine GARP, so that the result of the test agrees with our intuition. At the same time, we have surreptitiously introduced a “partial equilibrium” model of consumer choice as the paradigm of rationality. In the next section, we show that the example generalizes.",5
1.0,1.0,Economic Theory Bulletin,30 March 2013,https://link.springer.com/article/10.1007/s40505-013-0008-2,On seller estimates and buyer returns,May 2013,Alex Gershkov,Flavio Toxvaerd,,Male,Male,Unknown,Male,"Asymmetry of information is pervasive in markets for financial assets. Sellers of assets such as shares of newly floated companies as well as objects of fine art may have better information about true values than potential buyers, and have an inherent interest in distorting sales prices upwards. This fact raises the concern that buyers may be lead to overpay for assets and let themselves be fooled by information supplied by the seller. The empirical evidence seems inconclusive. Bradshaw et al. (2003) confidently assert that “[the] evidence [...] suggests that investors are systematically fooled by analyst hype”. If such conclusions are taken at face value, we are facing a potentially huge problem of market inefficiency which casts a shadow on the investment advice provided by sellers of assets. It is therefore of great importance to study the robustness and interpretations of studies suggestive of such sell-side manipulation and buyer gullibility. In recent empirical research, Mei and Moses (2005) describe and study a natural experiment that occurred in the market for fine art. Prior to 1973, buyers of art at auction houses such as Sotheby’s and Christie’s largely relied on own information and research when valuing pieces put up for sale. After 1973, both auction houses publicly announced valuations of all items offered for sale. This situation provides an ideal context within which to test the effects that announced seller valuations have on prices of assets. Their main findings can be summarized as follows: (i) Auctioneer price estimates are biased, (ii) Bidders tend to pay more for objects with high auctioneer price estimates and (iii) The introduction of auctioneer price estimates caused long-term under performance of auctioned objects. The authors take these findings to suggest that buyers of art are credulous and that auction houses exploit this fact to further their own interests. In this paper, we revisit these findings by providing a simple formal model of the aforementioned natural experiment, in which all bidders are fully rational. Within this model, we show that it is consistent with equilibrium behavior for bidders to bid more aggressively for items with higher announced valuations and that the shift from a regime without public valuations to one with such valuations can lead to a decrease in long-term returns for bidders. Mei and Moses’ (2005) finding (i), i.e. that auctioneer estimates are biased (significantly so, although the bias is quite small), should be contrasted to previous studies that fail to find the existence of bias, such as Keane and Runkle (1988). McAndrew et al. (2012) argue that the bias found in previous studies stems from the exclusion in the data of assets that do not reach the reserve price (and are thus not traded). They show that once all auctioned objects are considered (sold and unsold alike), there is no evidence of bias. In a related paper, Sproule and Valsan (2006) consider a hedonic model of art auctions and find that it has no better predictive power than those of estimates provided by sellers of the assets. In itself, estimation bias is not of interest in the current context unless bidders are found to react to announced price estimates. In other words, if bidders were oblivious to announced price estimates, such estimates would be inconsequential. This motivates Mei and Moses’ (2005) analysis of bidder reactions to public price estimates. They find that bidders tend to pay more for items with higher announced auctioneer price estimates. What should or can one conclude based on such an observation? Clearly, were it indeed the case that auction houses and sellers of assets were manipulating information and exploiting gullible bidders by providing them with biased price estimates, such a finding would be expected. Unfortunately, concluding that bidders are gullible would be premature, since such a pattern in price reactions is equally consistent with a more benign state of affairs, namely that sellers truthfully reveal the information they possess and that bidders in turn rationally bid more aggressively for higher value items. This difficulty leads to the natural experiment provided by the introduction of public price estimates in 1973. The approach adopted by Mei and Moses (2005) is to consider what effects the regime change had on bidder returns. If the introduction of price estimates changed bidder returns to the worse, they argue, this would constitute prima facie evidence that bidders are being misled by the manipulated information provided by auction houses. Specifically, their analysis is as follows. They consider a large data set of prices of items for which three consecutive sales have been recorded. This allows us to determine the effects (if any) that the introduction of price estimates had on returns to a particular item over different holding periods (i.e. the adjusted change in price from the date at which the item was acquired until the date at which it was resold). Figure 1 shows their setup schematically. For some part of the data set (scenario A), the first sale occurred prior to 1973 while the next two sales occurred after 1973. The remaining part of the data set (scenario B) consists of items which had two recorded sales prior to 1973 and one recorded sale after. The two scenarios under the two regimes The strategy of their analysis is as follows. If, as the authors conjecture, the introduction of price estimates creates an upward pressure on prices, only items sold in the second regime (i.e. post price estimate introduction) would be thus influenced. In turn, this would mean that the return in holding period 1 (from \(t=1\) to \(t=2\)) in scenario A would be larger than the return in holding period 1 in scenario B. Similarly, the return in holding period 2 (from \(t=2\) to \(t=3\)) in scenario A should be lower than the return in holding period 2 in scenario B. Below, we shall argue that both findings (ii) and (iii) in Mei and Moses (2005) are consistent with fully rational behavior and furthermore that both observations are essentially reflections of the same mechanisms at work. As a consequence, their result (i) also becomes irrelevant. Specifically, our setup is as follows. We consider two different regimes, consistent with the situations prevailing before and after the introduction of auctioneer valuations. In the first regime, bidders receive private signals before participating in a standard English auction. No further information is disclosed before bidding takes place. In the second regime, everything is as in the first regime, with the difference that before bidding takes place, the auctioneer publicly announces all bidders’ signals. We then go on to study two different scenarios, like scenarios A and B in Mei and Moses’ (2005) study. We show that in equilibrium, the return in holding period 1 in scenario A is larger than the return in holding period 1 in scenario B. Similarly, we show that the return in holding period 2 in scenario A is lower than the return in holding period 2 in scenario B. In short, we show that the decrease in long-term return on assets during holding periods that straddle the introduction of publicly announced auctioneer valuations are due to the fact that more information is released, which in turn prompts bidders to rationally bid more aggressively than they otherwise would have.",2
1.0,1.0,Economic Theory Bulletin,25 March 2013,https://link.springer.com/article/10.1007/s40505-013-0007-3,Making efficient public good decisions using an augmented Ausubel auction,May 2013,Matt Van Essen,,,Male,Unknown,Unknown,Male,"After almost 50 years of research on incentive design, it remains unclear whether a practical institution can be designed to overcome free-riding incentives in a public good environment. While this problem is easier if agents reveal their preferences to a decision maker, agents’ interests are not typically aligned with those of the decision maker. As a result, agents may misrepresent their preferences. In this paper, we look to recent contributions in dynamic private good auctions and experimental economics to give us insight into a new, and hopefully improved, way of overcoming the “preference revelation” problem in a public good setting. Early work in this area came from Vickrey (1961) in a private good setting. He proposed an auction which efficiently allocates multiple units of a homogeneous good by encouraging revelation of preferences as a dominant strategy. His mechanism was later generalized by Clarke (1971) and Groves (1973) to accommodate public goods. Loeb (1977) shows the Vickrey auction can also be re-defined to make efficient public good decisions. These mechanisms are known as VCG mechanisms and have generated a large literature.Footnote 1 Despite the theoretical interest in VCG mechanisms, Rothkopf (2007), and others, have argued they are not practical due to lack of privacy preservation. Intuitively, an auction is privacy preserving for a bidder if, when the auction ends, the seller cannot construct a complete demand schedule for that bidder. A second price sealed bid auction, for example, is not privacy preserving since at the end of the auction a seller knows all the valuations. This feature encourages practices like ‘shill’ bidding and may dissuade bidders from participating. Privacy preservation is also a concern in public good settings, where consumers prefer the government not know their true valuations. A potential solution to this critique is to use a dynamic auction to make allocation decisions. A Japanese auction, for example, is outcome equivalent to the second price sealed bid auction, but preserves the privacy of the winning bidder. In this auction, an auctioneer slowly raises the price and bidders signal each round whether they want to continue and drop out if the price becomes too high. The last bidder still in the auction wins and pays the price the second to last bidder dropped out at. However, unlike the second price auction, the winner never reveals his maximum willingness to pay. Thus, in a dynamic setting the auction can stop before bidders can reveal their whole valuation schedule. Ausubel (2004) introduced a dynamic auction that retains the nice revelation properties of the private good multi-unit Vickrey auction, is outcome equivalent to the Vickrey auction, and preserves the privacy of some of the bidders.Footnote 2 In addition, this auction has been more “behaviorally” successful than its sealed bid counterpart when tested in the laboratory. Kagel and Levin (2001) find that bidders in the private good Ausubel auction do, in general, bid truthfully when compared with bidders in uniform price sealed bid auctions. In a follow up paper, Kagel and Levin (2001) compare the private good, multi-unit Vickrey auction against the private good Ausubel auction with different information feedback treatments finding the Ausubel auction outperforms the Vickrey auction.Footnote 3 The authors credit these results to the relative transparency of Ausubel’s auction. We define and study the public good Ausubel auction. The intuition for the transition is simple. In the private good Ausubel setting, all bidders take the auctioneer’s price as given and respond with (potentially) different quantity bids.Footnote 4 In a public good setting, bidders face a uniform quantity of the public good, by definition, but have (potentially) different marginal valuations for each unit. Thus, it is natural to re-define the private good Ausubel auction by using an ascending “quantity” auction instead of an ascending “price” auction. In this new mechanism, the auctioneer starts by calling out a low quantity (instead of a price) and individuals respond by submitting value bids (instead of quantity bids). If the bids exceed the marginal cost (i.e., supply for that unit), the auction continues and the auctioneer increases the quantity. This process continues until the sum of the bids no longer exceeds the marginal cost—i.e., until there is no longer excess inverse demand for the public good. Truth telling is made incentive compatible by adopting a variation of Ausubel’s “clinching rule” to determine the individuals’ taxes. The resulting auction is the ascending quantity Ausubel auction (AQ-AA) and it has a number of nice features. We show the AQ-AA is privacy preserving, that truthful revelation of bidders’ valuations is supported as an equilibrium in a variety of strategic environments, and that auction is outcome equivalent to the public good Vickrey auction. However, not all of the properties of the AQ-AA are ideal in a public good setting. We conclude the paper by discussing two shortcomings of the AQ-AA that do not appear in the private good Ausubel auction and introduce a dynamic auction with similar strategic properties that corrects these problems.",1
1.0,1.0,Economic Theory Bulletin,11 April 2013,https://link.springer.com/article/10.1007/s40505-013-0004-6,The (im)possibility of collective risk measurement: Arrovian aggregation of variational preferences,May 2013,Frederik S. Herzberg,,,Male,Unknown,Unknown,Male,"Consider a committee that has to compare several risky positions on a financial market. One obvious example from the recent past would be a panel of various supervisory authorities and public financial institutions, assessing various government bonds by means of several continuous convex risk measures. We ask the question whether it is possible to find a mechanism for merging, in a rational and systematic manner, the resulting differing risk assessments into a single risk assessment, one financial position at a time. It will turn out that for finite electorates, this is not the case; hence, a panel as in the above example should agree on a single risk measure from the outset. In the case of infinite electorates, however, we shall see that rational and systematic aggregation rules for preferences representing convex risk measures do exist; this observation entails a microfoundation for macroeconomic models with, for example, Hansen’s and Sargent’s (2001) multiplier preferences. What is needed to arrive at these results is a theory of collective decision making with respect to (continuous) convex risk measures. The main clue will be to identify (negated) continuous convex risk measures with their decision-theoretic counterparts, viz. variational preferences, (via their maxmin-expected-utility-plus-penalty representation) and to apply recent results from abstract aggregation theory. Convex risk measures can be represented as negated maxmin expected utility functions with additive convex lower semi-continuous penalty (Föllmer and Schied 2002, 2004), which in turn are in a one-to-one correspondence with the set of so-called variational preference relations (Maccheroni et al. 2006). Given such an individual decision-theoretic foundation for convex risk measures, it is only natural to study the aggregation problem for convex risk measures as an aggregation problem for variational preference relations. The original, Arrovian preference aggregation theory [originating with Arrow’s (1963) famous impossibility theorem; for concise proofs, cf. Fishburn (1970) and Yu (2012)] does not provide suitable methods to study the aggregation of variational preferences. Even the assumptions in the rich literature on Arrovian social choice on economic domains—cf. e.g. Maskin (1976, 1979), Kalai et al. (1979) or Moulin (1980) for important early contributions as well as Le Breton and Weymark (2002, 2010) and Bossert and Weymark (2006) for more recent work and surveys—are too restrictive for the purposes of the present paper. [For instance, many contributions in this body of literature require the alternatives to form a non-negative orthant and the population to be finite; the only theorem in this literature that might be considered a special case of our results in this paper is the analogue of Arrow’s impossibility theorem for expected-utility preferences which Le Breton proved in his habilitation thesis Le Breton (1986), cf. also Le Breton and Weymark (2010).] That said, there is also a (“non-Arrovian”) literature on the aggregation of (generalisations of) expected-utility preferences. This body of literature originated with Harsanyi’s (1955) paper on the aggregation of von Neumann and Morgenstern (1944) expected-utility preferences and has seen numerous contributions by diverse other authors. For example, the Paretian aggregation of subjective expected-utility preferences has been studied (motivated by a Bayesian view of probabilities) by, e.g. Hylland and Zeckhauser (1979), Seidenfeld et al. (1989), and Mongin (1995). Gilboa et al. (2004) even generalise Harsanyi’s (1955) and Mongin’s (1995) characterisations (of social welfare functions as convex combinations of individual utility functions) to a setting where both the utility functions and the probability measures are subjective. Furthermore, Mongin (1998) investigated the aggregation of state-dependent expected-utility preferences, while the aggregation of an even richer class of preference orderings [that includes the Gilboa and Schmeidler (1989) maxmin expected-utility preferences] has been studied quite recently by Gajdos et al. (2008). For all its merits, this body of literature generally does not impose Arrow’s (1963) axiom of independence of irrelevant alternatives (let alone systematicity) and, therefore, should not be considered a branch of Arrovian aggregation theory; in addition, the contributions in this literature typically only consider the case of finitely many individuals. In contrast, the present paper does assume the systematicity axiom (a stronger sibling of the independence axiom), thus placing itself more firmly within the Arrovian current of aggregation theory, and studies the case of infinite electorates as well. The scope of Arrovian aggregation theory has developed considerably during the past decade. It now encompasses aggregation problems of very general form, including even the aggregation of general logical propositions. This area, known as judgment aggregation theory or abstract aggregation theory, has seen seminal contributions by List and Pettit (2002), Dietrich and Mongin (2007), Nehring and Puppe (2007), Dokow and Holzman (2010), Dietrich and List (2007, 2008, 2010); for a survey, see List and Puppe (2009). A very recent development in this area is the investigation of the aggregation of more general propositional attitudes which allows for a unified treatment of both judgment aggregation and probabilistic opinion pooling (cf. McConway (1981) for a seminal contribution to the latter area), cf. Dietrich and List (2010). One of the recent and less well-known generalisations of classical (Arrovian) preference aggregation theory within judgment aggregation theory is concerned with the aggregation of relational structures (model aggregation). This approach can best be seen as a continuation of Lauwers and Van Liedekerke’s far-sighted paper Lauwers and Van Liedekerke (1995) and was elaborated systematically recently by Herzberg and Eckert (2012a, b).Footnote 1 It is a rather natural methodological choice to employ model aggregation theory in our analysis of variational preference aggregation, on account of the intrinsic emphasis which model aggregation theory lays on semantics (in comparison with most of the judgment aggregation literature) and also because of its historical roots in preference aggregation theory through the work of Lauwers and Van Liedekerke (1995). In the present paper, the methodology of model aggregation theory will enable us to prove variational analogues of two of the most important (im)possibility theorems of Arrovian social choice theory—those of Arrow and Fishburn—, and to propose a potential analogue of Campbell’s theorem in a generalised variational setting. Moreover, it may well be possible to apply the same proof methodology to obtain similar results for multiple priors preferences (which can be represented by coherent risk measures) and perhaps ultimately even for dynamic variational or multiple priors preferences. The paper is structured as follows: Sect. 2 reviews the axioms and the representation theorem of variational preferences and relates them to convex risk measures. Section 3 proposes a formal framework for an Arrovian aggregation theory of variational preferences, within which Sect. 4 formulates the main (im)possibility results of this paper. Section 5 then describes briefly the ideas behind the proof methodology (model aggregation theory), while Sect. 6 discusses possible extensions and future research. In an Appendix, we also apply Dietrich and List (2010) account of majority voting to the problem of variational preference aggregation. The fruit is a possibility theorem, but at the cost of considerable and—at least at first sight—rather unnatural restrictions on the domain of the variational preference aggregator.",4
1.0,1.0,Economic Theory Bulletin,27 March 2013,https://link.springer.com/article/10.1007/s40505-013-0001-9,First-price auctions on general preference domains: axiomatic characterizations,May 2013,Tsuyoshi Adachi,Takumi Kongo,,Male,Male,Unknown,Male,"In this study, an auction is theoretically studied under a standard setting, an allocation problem of an indivisible item among multiple agents, each of which is interested in obtaining the item by paying some amount of money.Footnote 1 The value of an item being sold differs from agent to agent so that the amount of money they are willing to pay for obtaining the item also differs from agent to agent. By considering every agent’s preference on the pair of the item and payment, an auction format decides (1) whether the agent obtains the item and (2) the amount of money each agent pays.Footnote 2
 Second-price auctions (Vickrey 1961, generally referred to as Vickrey auctions) and first-price auctions are two well-known auction formats. In both formats, the agent who represents the highest willingness to pay obtains the item (when multiple agents represent the equally highest willingness to pay, a prearranged tie-breaking system is applied to choose one of them); agents who do not obtain the item pay nothing. The difference between the two famous auction formats lies in the payment by the agent who wins the auction. According to the second-price rule, the winner pays the amount of money equal to the second highest willingness to pay among agents, while in first-price auctions, the highest willingness to pay, that is, one’s own. This slight difference causes considerable distinctions between properties of the two formats. Among them, one of the most important properties of second-price auctions is strategy-proofness, which requires that each agent’s stating his true preferences does not worsen his welfare. By focusing on strategy-proofness, second-price auctions are axiomatically characterized in various ways (Holmstrom 1979; Chew and Serizawa 2007; Saitoh and Serizawa 2008; Sakai 2008; Sakai 2013; Adachi 2012; Ashlagi and Serizawa 2012). Meanwhile, although their payment rules are simple, first-price auctions have not been well-investigated from an axiomatic point of view. First-price auctions apparently fail to be strategy-proof. Even though his willingness to pay is the highest, an agent representing his true preference obtains essentially nothing, because the agent obtains the item by paying exactly the same amount of money as the value of the item, which is equivalent to obtaining nothing without paying. Thus, ordinarily, every agent is inclined to understate his valuation of the item in first-price auctions. This type of strategic behavior stems from the fact that the winner’s payment amount is determined by the winner’s willingness to pay. This self-deterministic payment property in first-price auctions is compatible with non-bossiness (Satterthwaite and Sonnenschein 1981), which is another important property related to agents’ strategic behavior.Footnote 3 Non-bossiness requires that an agent stating a false preference has no influence on others unless it influences the agent. Essentially, first-price auctions have this property.Footnote 4 Obviously, in first-price auctions, the winner is not able to change the outcome for other agents while maintaining himself as a winner. Any agent other than the winner does not change the payment of others unless he becomes a winner; however, in this case, the outcome for the agent has also been changed. In contrast, second-price auctions lack non-bossiness because the payment amount for the winner relies on others’ willingness to pay. An agent other than the winner is able to change the winner’s payment while keeping the outcome for himself unchanged by increasing his willingness to pay not more than the winner’s one but more than the second highest one. Therefore, a clear distinction between second- and first-price auctions is captured by the difference between strategy-proofness and non-bossiness—two major axioms concerning agents’ strategic behavior. In this paper, we present axiomatic characterizations of first-price auctions by focusing on non-bossiness. Together with non-bossiness, other axioms needed for the characterizations are classified into three types: efficiency, equity, and participation-constraint-related axioms. These three types of axioms are basic and important to our results, which suggest that first-price auctions are consequent auction formats when we pay attention to non-bossiness. In particular, our results show that first-price auctions are characterized by (i) strong non-bossiness in welfare, Pareto efficiency, equal welfare to equals, and individual rationality, (ii) non-bossiness in welfare, Pareto efficiency, anonymity in welfare, and individual rationality, (iii) non-bossiness in welfare, envy-freeness (Foley 1967), and individual rationality, and (iv) non-bossiness in welfare, Pareto efficiency, and individual rationality on some restricted domains. Pareto efficiency is a usual requirement in economics. Individual rationality ensures agents’ voluntary participation in the auction. Each of the properties, anonymity in welfare, envy freeness, and equal welfare to equals, requires a type of impartial treatment among agents. Thus, (i) is a parallel result to (ii), which strengthens a non-bossy axiom instead of weakening an equity axiom, while (iv) specifies the domains on which we can drop an equity axiom from the set of axioms in (ii). Also, our results are obtained in a general setting for agents preferences. For agents’ preferences, we assume only three basic properties: money monotonicity (less payment is preferable), weak item monotonicity (the auctioned item has non-negative value), and finiteness (the value of the auctioned item is not infinite). We also assume that the domain of agents preferences is not empty (avoid triviality) and is rich (with no spaces between). Our characterizations of first-price auctions on these general-preference domains are in line with recent studies of characterizations of second-price auctions on general-preference domains, such as Saitoh and Serizawa (2008), Sakai (2008); Sakai (2013), and Adachi (2012). Importantly, our conditions on preference domains are the most general ones. The rest of the paper is organized as follows. In Sect. 2, we present our model. In Sect. 3, axioms characterizing first-price auctions are introduced. In Sect. 4, four axiomatic characterizations of first-price auctions are discussed.",3
1.0,2.0,Economic Theory Bulletin,27 March 2013,https://link.springer.com/article/10.1007/s40505-013-0002-8,Compactness in the choice and game theories: a characterization of rationality,November 2013,Athanasios Andrikopoulos,,,Male,Unknown,Unknown,Male,"The concept of compactness is an extension of the benefits of finitenessFootnote 1 to infinite sets.Footnote 2 Most properties of compact sets in economic theory are analogous to the properties of finite sets which are quite trivial. For example, the existence theorems of maximal elements are useful and important tools to prove the existence of non-empty choice sets or equilibrium existence theorems of mathematical economies and generalized games in different underline spaces.Footnote 3 Therefore, we are often interested in conditions under which we can be sure that a preference achieves a maximal element on the feasible set.Footnote 4 If the feasible set is finite, a sufficient condition for the existence for such a maximal element is the preference to be acyclic. However, the same statement remains true if finiteness is replaced by compactness and the preference is upper semicontinuous.Footnote 5
 A classical result of Sloss (1971), Brown (1973) and others states that any upper semicontinuous acyclic binary relation defined on a compact set has a maximal element. A converse result of Sloss and Brown is that of (Gutiérrez (2009), Theorem 2.1), which says that: if the compactness from the feasible set is violated, then there exists a preference (here preference means asymmetric and negative transitive binary relation) such that for every feasible element there is one that is better according to this preference. That is, the feasible set has no maximal element with respect to this preference. Since asymmetry and negative transitivity imply acyclicity, the aforementioned results of Sloss, Brown and Gutiérrez, provide a characterization of compactness as follows: the feasible set is compact if and only if there is a maximal element for any upper semicontinuous acyclic binary relation. This characterization requires the binary relation to be acyclic. However, in collective choice problems (ranking of social preferences, voting in committees, etc.), cyclicity is a plausible assumption as, for example, the Condorcet Paradox shows. For this reason, a more general framework is needed to characterize compactness. The classical rationality conditions in choice theory formalize the thesis that to choose rationally is to choose in such a way that no other choice would have been better, or preferable. That is, each individual makes choices by selecting, from each feasible set of alternatives, those which maximize his own preference relation. On the other hand, one of the most common assumptions made in game theory is that rationality implies that every player maximizes his own payoff. In a stricter sense, it implies that every player always maximizes his utility, thus being able to perfectly calculate the probabilistic result of every action. In any case, the choice set, from a given potential set, is the set of maximal elements under a dominance relation. But, the set of maximal elements is often empty. In this case, it is important to specify criteria that will provide reasonable sets of alternatives as solutions. In the choice and game theories, a number of theories, called general solution theories, have been proposed to take over the role of maximality in the absence of maximal elements. One of the most important general solution concepts is the Schwartz set. An equivalent notion to the Schwartz set in game theory is that of the admissible set (see Kalai and Schmeidler 1977). The admissible set concept can be applied to a host of game-theoretic situations, ranging from non-cooperative games, where a coalition consists of an individual player, to fully cooperative games, where any coalition can be allowed. On the other hand, to face the problem of characterization of the existence of non-empty choice sets, the standard approach is to assume upper semicontinuous preferences. A number of more general concepts of continuity have been introduced in the literature in connection with the problem of the existence of maximal elements. Alcantud (2002) defines the notion of upper tc-semicontinuity which is extended by Andrikopoulos (2007) to the notion of generalized upper tc-semicontinuity. In this study, we characterize the compactness of the feasible set in a general framework, where “preference”  means arbitrary binary relation. We prove that the feasible set is compact if and only if every generalized upper tc-semicontinuous preference has non-empty Schwartz (admissible) set.",1
1.0,2.0,Economic Theory Bulletin,27 March 2013,https://link.springer.com/article/10.1007/s40505-013-0003-7,A note on values for Markovian coalition processes,November 2013,Ulrich Faigle,Michel Grabisch,,Male,Male,Unknown,Male,"The Shapley value is a well-known allocation scheme for both TU- and NTU-games with numerous applications. It is defined as the average marginal contribution of a player, taken over all possible ways to form the grand coalition \(N\) when one starts from the empty coalition and adds players one by one. In real situations, however, there is no a priori reason for a process of cooperation to end with the grand coalition, nor are all ways of forming the grand coalition necessarily feasible. This explains why the Shapley value can produce counterintuitive results in some cases, as pointed out by, e.g., (Roth 1980; Shafer 1980; Scafuri and Yannelis 1984). Guided by these considerations, the authors have proposed an allocation scheme for a general model of coalition formation (Faigle and Grabisch 2012) where the evolution of the coalition of active players is ruled by a Markov chain. The classical Shapley value appears then as the particular case where the only transitions possible consist of the addition of a single player to the present coalition and all these transitions are equiprobable. The aim of this note is to develop some explanations in the even more general context of time discrete stochastic processes that are not necessarily Markovian, exhibit new properties of the model and correct some inaccuracies in the original paper (Faigle and Grabisch 2012). In particular, we give a new version of the axiomatization. We restrict our exposition to the minimum, and refer the reader to the original paper for examples and further details on the Markovian model.",2
1.0,2.0,Economic Theory Bulletin,30 March 2013,https://link.springer.com/article/10.1007/s40505-013-0005-5,The impossibility of social evaluations of infinite streams with strict inequality aversion,November 2013,José Carlos R. Alcantud,,,Male,Unknown,Unknown,Male,"This paper is primarily concerned with the problem of aggregating infinite utility streams and the possible adoption of distributive equity principles. We prove that there is a fundamental incompatibility between salient postulates of strict inequality aversion like the Strong Equity Principle (Bossert et al. 2007), the Pigou–Dalton Transfer principle (Sakai 2006; Bossert et al. 2007), the Lorenz Domination principle (Hara et al. 2008), or Altruistic Equity (Hara et al. 2006; Sakamoto 2012), and the Basu–Mitra approach that uses social welfare functions (SWFs) and renounces continuity. If we abandon the use of utilities, we complement Sakai (2006) and Hara et al. (2008) to conclude that those postulates are incompatible with semicontinuous preferences too. As Sakai (2006) has put it, there are two ethical considerations that capture the concept of intergenerational equity: inequality aversion and equality in evaluating allocations. The latter is in the utilitarian tradition à-la-Sidgwick and Diamond, and requires that the welfare orderings should not be biased against any generation. In formal terms, it appeals to anonymity axioms that impose the impartial treatment of all generations. The former has received much attention in recent years. The aforementioned distributional axioms have been introduced in the literature on intergenerational justice to explore the implications of such ethical standpoint; thus, they have the common spirit of expressing a strict preference for distributions of utilities among generations that reduce inequality in various forms. Irrespective of the egalitarian position that is adopted, the essential shortfall of the approach by numerical evaluations or SWFs in this context has been brought to the fore by a number of contributions. Either, if one requests anonymity-type properties (Basu and Mitra 2003; Crespo et al. 2009), the very mild Hammond Equity for the Future (Banerjee 2006), or variations of other consequentialist principles of aversion to inequality (Alcantud 2010, 2012; Sakamoto 2012), relaxed—but not universally acceptable—versions of the Pareto principle like strong Pareto, weak dominance, or weak Pareto, lead to incompatibility under different specifications of the domain of utility sequences. Here we go further and prove that assuming only the uncontroversial monotonicity for nearly unrestricted sets of admissible utilities, SWFs must contradict the ethos of the Pigou–Dalton transfer principle at the level of a especially plausible generalization named Altruistic Equity. Other distributional axioms implying Pigou–Dalton under monotonicity, like the Strong Equity Principle or the Lorenz domination principle, turn out to be incompatible with the Basu–Mitra approach. To illustrate further the difficulty of implementing strict aversion to inequality, we prove that acyclic evaluations which are semicontinuous with respect to the sup topology cannot verify Altruistic Equity. This is a variant of previous results in Hara et al. (2008). This paper is organized as follows. Section 2 introduces the setting and axioms. Section 3 proves our main result. Section 4 concludes and briefly reports on related literature, including our impossibility result for acyclic relations.",9
1.0,2.0,Economic Theory Bulletin,13 April 2013,https://link.springer.com/article/10.1007/s40505-013-0012-6,Alternative proofs of Arrow’s general possibility theorem,November 2013,Susumu Cato,,,Male,Unknown,Unknown,Male,"Immediately after the publication of Social Choice and Individual Values (Arrow 1951), Inada (1954) provided alternative proofs of three results in the book, including for Arrow’s general possibility theorem. Later, Blau (1957) pointed out that the original version of the theorem is incorrectly stated; his observation also applies to Inada’s proof. In response to Blau (1957), Arrow (1963) provided a restatement of the general possibility theorem and its proof. Since then, most authors have followed the revised version, which is included in the second edition of Arrow’s book. As Blau (1957) and Arrow (1963) reformulated the set of axioms on which Inada’s proof was based, Inada’s proof has not received much attention in the context of Arrovian social choice theory. The present article aims to rehabilitate Inada’s proof of Arrow’s general possibility theorem. In line with Inada (1954), we provide two simple proofs of the second version of the general possibility theorem. These proofs have some notable features compared with the existing ones. The standard approach to prove Arrow’s theorem was developed by Arrow (1963) and Sen (1970, 1979).Footnote 1 Most proofs of the theorem are constructed along the same lines (Fishburn 1970; Blau 1972; Sen 1986, 1995; Denicolò 1996, 2001; Suzumura 2000). In such proofs, the so-called field expansion lemma is established as the first step: it says that if a group of individuals has decisive power over some pairs of alternatives, then it has decisive power over all pairs. Thus, this lemma shows that the decisiveness structure is invariant across all pairs under Arrow’s axioms.Footnote 2 As the next step, the group-contraction lemma is proved using the field expansion lemma: for any decisive group with more than one individual, there exists some smaller decisive group within it. The theorem immediately follows from this lemma. In Contrast to the standard proof, Inada and we do not construct the field expansion lemma as an auxiliary step. Instead, we employ the concept of a minimal (almost) decisive set to construct a group-contraction procedure as the first step: we prove that a minimal (almost) decisive set is a singleton for all pairs. Next, we show that the minimal (almost) decisive set is invariant across all pairs. Finally, we explain the relationship between our proofs and Inada’s. Inada used the concept of a decisive set, whereas we apply the concept of an almost decisive set in our first proof. This difference is because of the difference between the original axioms and those of the 1963 theorem. In our second proof, we reconstruct the argument to apply standard decisiveness. It is one of the simplest proofs of Arrow’s theorem.",2
1.0,2.0,Economic Theory Bulletin,31 August 2013,https://link.springer.com/article/10.1007/s40505-013-0015-3,An interpretation of Ellsberg’s Paradox based on information and incompleteness,November 2013,Luciano I. De Castro,Nicholas C. Yannelis,,Male,Male,Unknown,Male,"Much has been written about the Ellsberg (1961)’s Paradox, including a special symposium on its 50 years; see Ellsberg (2011). Therefore, the following description is already familiar for many readers. Consider an urn with three balls, one of which is red, and the other two are either black or yellow, but the exact composition is unknown (see Fig. 1). An Ellsberg urn with three balls We will draw a ball from this urn and we offer two different pair of bets for an individual to choose. In the first pair, the choice between the actFootnote 1
\(f_{1}\) that pays \(\$1\) if the red ball is drawn and zero otherwise and the act \(f_{2}\) that pays \(\$1\) if the ball is black and zero otherwise is offered. For convenience, we normalize \(u(1)=1\) and \(u(0)=0\). In the second pair, the choice is between an act \(f_{3}\) that pays \(\$1\) if the ball is either red or yellow and zero otherwise and the act \(f_{4}\) that pays \(\$1\) if the ball is either black or yellow and zero otherwise. To summarize, \(f_{i}\) is given, for \(i=1,\ldots ,4\) as follows: Most individuals will exhibit preferences as: \(f_{1}\succ f_{2}\) and \(f_{4} \succ f_{3}\).Footnote 2 This is called the Ellsberg Paradox because there is no expected utility that can rationalize this choice, since the first preference would imply \(\pi (\{R\}) > \pi (\{B\}\), while the second, that is, \(\pi (\{B\}) > \pi (\{Y\})\) and these implications contradict each other. Now, let us formulate this example in the asymmetric information terminology. Let \(\Omega =\{R, B, Y\}\) denote the state space; each \(\omega \) corresponds to the color of a ball (red, black, yellow) to be extracted from an urn. For simplicity, let us assume that the utility index of the individual is \(u(x)=x\). The agent’s information about the state of the nature is described by the algebra generated by the following partition: \(\mathcal F = \{ \{R\}, \{B, Y\} \}\), and his belief \(\mu : \mathcal F \rightarrow [0,1]\) is given by \(\mu (\{R\}) = \frac{1}{3}\) and \(\mu (\{B,Y\}) = \frac{2}{3}\). Therefore, the acts \(f_{1}=1_{\{R\}}\) and \(f_{4}=1_{\{B,Y\}}\) are measurable, while the acts \(f_{2}=1_{\{B\}}\) and \(f_{3}=1_{\{R, Y\}}\) are not. Thus, while \(U(f_{1})=\int u(f_{1}) \mathrm{\ d} \mu = \mu ( \{R\})= \frac{1}{3}\) and \(U(f_{4})=\int u(f_{4}) \mathrm{\ d} \mu =\mu ( \{B,Y\})= \frac{2}{3}\), the integrals \(U(f_{2})=\int u(f_{2}) \mathrm{\ d} \mu \) and \(U(f_{3})=\int u(f_{3}) \mathrm{\ d} \mu \) are not defined! Therefore, in this standard preference, the individual is unable to compare act \(f_{1}\) with \(f_{2}\) (and \(f_{4}\) with \(f_{3}\)). In other words, this preference is incomplete, that is, it does not obey the completeness axiom, which requires that either \(f_{1} \succcurlyeq f_{2}\) or \(f_{2} \succcurlyeq f_{1}\) for every pair of acts \(f_{1}\) and \(f_{2}\). However, in the above example, we forced the individual to make a choice. This means that the individual has to find a way to complete her preferences.
",10
1.0,2.0,Economic Theory Bulletin,09 July 2013,https://link.springer.com/article/10.1007/s40505-013-0016-2,A one-shot proof of Arrow’s theorem and the Gibbard–Satterthwaite theorem,November 2013,Ning Neil Yu,,,,Unknown,Unknown,Mix,,
1.0,2.0,Economic Theory Bulletin,29 September 2013,https://link.springer.com/article/10.1007/s40505-013-0017-1,A characterization of maximin,November 2013,Kristof Bosmans,Erwin Ooghe,,Male,Male,Unknown,Male,"Maximin and leximin epitomize the extremely egalitarian position in comparisons of social welfare. Both criteria support complete equality, except if this makes everyone worse off.Footnote 1 Maximin focuses solely on the lowest utility. Leximin extends maximin lexicographically by focusing on the second lowest utility if the lowest utilities tie, on the third lowest utility if the second lowest utilities also tie, and so on. The two criteria have been put forward and studied as formalizations of (a utility-based version of) Rawls ’ (1971) well-known difference principle.Footnote 2
 The axiomatic social choice literature has traditionally given less attention to maximin than to leximin.Footnote 3 In this note, we provide a characterization of maximin in the spirit of Hammond ’s (1976) classic characterization of leximin. Hammond shows that leximin is the only criterion satisfying anonymity, strong Pareto and Hammond equity. Hammond equity requires that a utility transfer from a better off individual to a worse off individual results in a social improvement, irrespective of how leaky the transfer is. The axiom is usually regarded as a demanding ethical requirement. However, (Hammond (1991), pp. 209–210), stresses that Hammond equity is demanding only if utility differences (as opposed to only utility levels) are interpersonally comparable. Indeed, otherwise utility leaks have no meaning. Our setting allows both the case of comparable and non-comparable utility differences. We, moreover, consider a new variation on Hammond equity. Weak Hammond equity is concerned only with alternatives in which there is a single worst off individual, while the remaining individuals are all equally well off. The axiom recommends transfers that diminish the gap between the worst off individual and the group of best off individuals. Such transfers, contrary to those recommended by Hammond equity, unambiguously diminish inequality in the overall population. We show that maximin is the only criterion satisfying anonymity, continuity, weak Pareto and weak Hammond equity. As a corollary, we obtain a natural counterpart of Hammond ’s (1976) result, viz., a characterization of maximin on the basis of anonymity, continuity, weak Pareto and the standard Hammond equity axiom.",12
1.0,2.0,Economic Theory Bulletin,26 September 2013,https://link.springer.com/article/10.1007/s40505-013-0018-0,Liapounoff’s vector measure theorem in Banach spaces and applications to general equilibrium theory,November 2013,Michael Greinecker,Konrad Podczeck,,Male,Male,Unknown,Male,"In various contexts, it was observed that measure spaces of uncountable Maharam type allow for useful constructions that are not available for the unit interval with Lebesgue measure; see, e.g., Scott (1967), Hoover and Keisler (1984), Rustichini and Yannelis (1991), Podczeck (2008), or Keisler (2009). Continuing this line, Khan and Sagara (2013) recently established a version of Liapounoff’s theorem for vector measures with values in a Banach space. The main result in Khan and Sagara (2013) says that if \((T,\varSigma ,\mu )\) is a totally finite measure space and \(G\) is a \(\mu \)-continuous countably additive vector measure defined on \(\varSigma \) with values in a Banach space \(X\), then the range of \(G\) is a convex and weakly compact set in \(X\) if \(\mu \) is Maharam-type-homogeneous with Maharam type strictly larger than the algebraic dimension of \(X\). In this note, we sharpen this result of Khan and Sagara (2013). In particular, we remove the hypothesis of Maharam-type-homogeneity, and, in the condition on the codomain of a vector measure, replace the algebraic dimension of a Banach space by the cardinal of some point-separating family of continuous linear functionals. The latter has drastic consequences; see the comments after Corollary 5 below. We provide two proofs of our main result. Our first proof is very short. It reveals that versions of Liapounoff’s theorem based on the Maharam classification of measure spaces are, in fact, a straightforward consequence of Knowles’ version of Liapounoff’s theorem in the weak topology (Knowles 1975), which we use in the form as stated in Diestel and Uhl (1977, Theorem IX.1.4). Our second proof is essentially measure-theoretic and works without the extreme point arguments on which the proof of Diestel and Uhl (1977, Theorem IX.1.4) is based. Instead, it makes use of an idea introduced by Maharam (1942) in the proof of her classification result for measure algebras. We illustrate the usefulness of our main result with three applications. First, we establish results on the convexity of the Aumann integral of a correspondence taking values in a Banach space, following the lines of the classical proof by Richter (1963) for the case of a finite-dimensional codomain. Second, we show that the result in Schmeidler (1972) on blocking power of small coalitions can be extended to infinite-dimensional commodity spaces, covering in particular models of commodity differentiation. Finally, we establish a result on core-Walras equivalence in coalitional exchange economies in the spirit of Vind (1964) when the commodity space is an order-continuous Banach lattice.",8
1.0,2.0,Economic Theory Bulletin,23 October 2013,https://link.springer.com/article/10.1007/s40505-013-0019-z,An outside-option-sensitive allocation rule for networks: the kappa-value,November 2013,Julia Belau,,,Female,Unknown,Unknown,Female,"In an economic or social situation where agents have to group in order to achieve common goals, how should we allocate the worth arising from the coalition formation among the agents? There are various frameworks and various allocation rules. This paper suggests an allocation rule for network structures which, in contrast to existing allocation rules, accounts for both outside options and the role of an agent within the network. We analyze situations where coalition formation is restricted by an undirected graph, that is, the economic or social structure is described by a network which captures the (bilateral) relations between agents and agents can only form a coalition if they are connected in such an interaction network via path (directly or indirectly). This approach was introduced by Myerson (1977) [for applications and further approaches on communication structures, see for example, van den Brink et al. (2007) or van den Brink et al. (2011)]. We use undirected networks to describe the relations between the agents while it would also be possible to use directed networks (i.e., interaction has a fixed direction) as analyzed by González-Arangüena et al. (2008). They use generalized characteristic functions as introduced by Nowak and Radzik (1994), that is, games where the worth of a coalition depends on the order in which agents enter the coalition. In our approach, interaction is not directed and the order of entry does not change the worth of the coalition. There are various examples in which an allocation rule should take into account outside options. As a simple example, consider a glove game, introduced by Shapley and Shubik (1969), with two right gloves and one left glove. A pair of gloves produces worth which has to be distributed among the agents holding the gloves. Due to the bargaining position (outside options) of the left glove holder, this agent should obtain a higher payoff than the others. This game has a nice economic interpretation and it is used to analyze simple markets (cf. Shapley and Shubik 1969). Tutic et al. (2011) show in their experimental work about social interchange that outside options significantly affect negotiations. This connection has also been mentioned by Maschler (1992) as “the need to let the players know what to expect from each coalition structure so that they can then make up their mind about the coalitions they want to join, and in what configuration” (p. 595). In a similar spirit, von Neumann and Morgenstern (1944) state that any formed coalition between individuals “only describes one particular consideration”. The result of negotiation between the individuals will be “decisively influenced by the other alliances which each one might alternatively have entered”. “Even if [...] one particular alliance is actually formed, the others are present in virtual existence: although they have not materialized, they have contributed essentially to shaping and determining the actual reality.” (p. 36) Furthermore, an allocation rule should take into account the specific position of agents within the network, that is, taking into account the path of information flow. As a simple example take the train connections between England, France and Germany. The Eurostar train connects London and Paris and the Thalys train connects Paris and Cologne while there is no direct train connection between England and Germany. Hence, as a transit country, France has to be passed for any kind of flow via trains between England and Germany (travel, trade,...). As further examples consider cost allocation among the nodes in energy networks or social networks used for job offers: nodes with a lot of links should be treated differently to nodes with just a few links. The literature suggests different allocation rules. The Shapley value (Shapley 1953) as well as the component-restricted Shapley valueFootnote 1 (Aumann and Drèze 1974) and, as another modification of the Shapley value, the Owen value (Owen 1977) do not take into account the network structure as they are designed for coalitional models without any interaction structure. Also more recent allocation rules that account for outside options, the Wiese value (Wiese 2007) and the \(\chi \)-value (Casajus 2009b), do not account for the inner interaction structure of a coalition. In order to account for the position within the network, this paper only analyzes allocation rules designed for networks (without further structure). These are the Position value (Meessen 1988; Borm et al. 1992), the graph-\(\chi \)-value (Casajus 2009a) and the Myerson value (Myerson 1977) or, as a generalization of the latter to a wider class of networks, the equal bargaining rule (Jackson and Wolinsky 1996).Footnote 2 The Position value never accounts for structures outside the own coalition, hence, is outside-option-insensitive while the graph-\(\chi \)-value generally does not take into account the network structure within a coalition for weighted voting games with minimal winning coalitions. The Myerson value, and hence the equal bargaining rule, even have both these drawbacks. Hence, there is a need for a new allocation rule. The contribution of this paper is the definition and characterization of a new allocation rule, the kappa-value, that is outside-option-sensitive and takes into account the position of an agent within the network. To the best of our knowledge, there exists no other allocation rule combining these properties. The kappa-value has a nice axiomatization, we only need already known and approved axioms or weakened versions of them (which combine the ideas of known and approved axioms). The kappa-value combines the advantages of the graph-\(\chi \)-value and the Position value while lacking their drawbacks and furthermore provides an elegant use of the quite intuitive concept of the Position value. We further show the independence of the characterizing axioms. To motivate the need for an allocation rule accounting for both outside options and the specific position of agents within the network, consider the following weighted voting game: we have four agents \(\{1,2,3,4\}\) holding weights \((w_1,w_2,w_3,w_4)=(39,30,25,6)\) and let the threshold be \(T=60\), that is, the worth of a coalition is 1 if the sum of weights of the coalitional agents is at least 60 and 0 otherwise. Hence, minimal winning coalitions are \(\{1,2\},\{1,3\}\) and \(\{2,3,4\}\). We consider minimal winning coalitions without organized opposition, that is, agents outside the winning coalition stay as singletons. The networks that could occur are shown in Fig. 1. Networks for minimal winning coalitions Table 1 reports the distribution of worth assigned by the Position value, denoted by \(\pi \), the graph-\(\chi \)-value, denoted by \(\chi ^\#\) and the new allocation rule suggested in this paper, the kappa-value, denoted by \(\kappa \).Footnote 3
 Consider the networks \(g^{3{-}2{-}4}\) and \(g^{2{-}3{-}4}\): the graph-\(\chi \)-value assigns the same payoff to agent \(2\) even though its position in the first case is stronger than in the second case while the Position value accounts for the different positions. On the other hand, the Position value does not take into account the existence of alternative winning coalitions, that is, outside options: consider the network \(g^{3{-}2{-}4}\) again and note that agents 3 and 4 obtain the same payoff even though 3 would have the outside option of a winning coalition with 1 while 4 has no outside option. The graph-\(\chi \)-value accounts for outside options and assigns a higher payoff to agent 3. The kappa-value takes into account both outside options and the position within the network: consider the coalition \(\{2,3,4\}\), agents 2 and 3 always obtain a higher payoff than 4, because they could also cooperate with 1 instead, while 4 has no outside option. Agents 2 and 3 are symmetric in terms of outside options but 2 obtains a higher payoff than 3 if the coalition is connected through 2, a lower payoff than 3 if the coalition is connected through 3 and the same payoff if the coalition is connected through 4. An agent obtains the highest payoff within the coalition if she has the strongest position. Note that not every outside option has the same value/impact: consider \(g^{1{-}2}\) and note that agents 1 and 2 have the same position in this network. Agent 1 obtains a higher payoff due to the fact that her outside option (building a coalition with 3) is valued higher/has a larger impact than the outside option of 2 (cooperating with \(\{3,4\}\)). This can be explained by the fact that in smaller coalitions, the worth has to be distributed among less agents. In contrast to defining a coalition as the group of agents that is connected via path, one could define a coalition by complete subnetworks, that is, as the group of agents that are directly connected to each other. The latter definition has the drawback of not taking into account different interaction paths within a coalition and the position of all agents within the coalition would be the same. This is why we use the more general definition of a coalition. But still it is notable that also in the case of equal positions, the kappa-value is not redundant; it differs from the graph-\(\chi \)-value as shown by \(g^{1{-}2},g^{1{-}3}\) and \(g^{2{-}3{-}4{-}2}\). The paper is structured as follows: we start with the framework and drawbacks of the existing allocation rules. Following the idea of combining the properties of the analyzed allocation rules, Sect. 3 will give an axiomatic characterization of the kappa-value and analyzes independence of the characterizing axioms. Section 4 concludes.",7
1.0,2.0,Economic Theory Bulletin,26 October 2013,https://link.springer.com/article/10.1007/s40505-013-0020-6,A concise axiomatization of a Shapley-type value for stochastic coalition processes,November 2013,Ulrich Faigle,Michel Grabisch,,Male,Male,Unknown,Male,"The Shapley value (Shapley 1953) is among the most popular solution concepts in cooperative game theory and has been applied numerously. Its basic idea: consider all possible orders for the players to enter the game and compute each player’s average marginal contribution over these orders. Therefore, the Shapley value can be seen as assuming particular way of cooperative dynamics: start from the empty coalition and add player after player until the grand coalition is reached. This simple view, however, is quite restrictive from the point of view of coalition formation. So it is not surprising that the Shapley value would give counterintuitive results in some situations (see, e.g., Roth 1980; Shafer 1980; Scafuri and Yannelis 1984). A much more general framework for a value, suited to coalition formation, has been developed by Faigle and Grabisch (2012). It takes into account that several players may enter at any step of the coalition formation process and also that some may leave the current coalition. Moreover, the process is not assumed to stop when the grand coalition is formed but may continue to evolve. Indeed, the evolution may be governed by a Markov chain or any kind of stochastic process. The authors have presented two values, called Shapley I and Shapley II, which define allocation schemes for this general situation. While both include the classical Shapley value as a particular case, a closer study of their properties suggests, however, that Shapley II seems to be more appropriate in practical settings. Faigle and Grabisch (2012) give an axiomatization of Shapley II (see a corrected version in Faigle and Grabisch 2013), with a very complex proof that is similar to the proof of Weber (1988) for the axiomatization of the classical Shapley value. The aim of this note is to provide a much more transparent proof exists for an only slightly weaker axiomatization. In addition, the logical independence of the axioms can be demonstrated. To achieve this, we replace the anonymity axiom (invariance of the value under permutations of the players) by the weaker symmetry axiom (symmetric players receive the same payoff) and base our present proof on the decomposition of a game as a sum of unanimity games (as it is done in, e.g., Faigle and Kern 1992; van den Brink 2001). The paper is organized as follows. Section 2 describes coalition formation processes and the allocation scheme (value) we suggest. Section 3 establishes the new axiomatization. Finally, we prove our axioms’ logical independence in Sect. 4. Throughout the paper, \(N\) denotes a finite set of \(n\) players. We often omit braces for singletons, writing, e.g., \(S\cup i\), \(S\setminus ij\) instead of \(S\cup \{i\}\) and \(S\setminus \{i,j\}\). Generally, we restrict our exposition to a minimum and refer the readers to Faigle and Grabisch (2012, 2013) for full details and more examples.",2
2.0,1.0,Economic Theory Bulletin,05 December 2013,https://link.springer.com/article/10.1007/s40505-013-0021-5,On the existence of essential and trembling-hand perfect equilibria in discontinuous games,April 2014,Vincenzo Scalzo,,,Male,Unknown,Unknown,Male,"In some recent papers, stability properties of Nash equilibria under perturbations on the payoffs and on the mixed-strategy profiles have been studied in classes of games where the payoffs are not necessarily continuous functions (henceforth discontinuous games). Carbonell-Nicolau (2010) and Scalzo (2013) identify classes of discontinuous games where, in the generic case, any pure-strategy Nash equilibrium is essential (see Wu and Jiang 1962). Regarding the mixed extension of a game, Carbonell-Nicolau (2011a); Carbonell-Nicolau (2011b) gave sufficient conditions for the existence of trembling-hand perfect (see Selten 1975) Nash equilibria and stable sets of equilibria (see Kohlberg and Mertens 1986; Al-Najjar 1995). In this paper, we present classes of discontinuous games, denoted by \(\mathfrak {g}^1\), \(\mathfrak {g}^2\) and \(\mathfrak {g}^3\), where, for each game in a dense subset, every mixed-strategy Nash equilibrium is essential. We prove that each essential mixed-strategy Nash equilibrium of any game in \(\mathfrak {g}^3\) is trembling-hand perfect and every stable set of equilibria contains only one element. The same property holds also in a subspace of \(\mathfrak {g}^2\), denoted by \(\mathfrak {g}^4\), when there are only two players. The paper is organized as follows: Section 2 introduces the setting. In Sect. 3, we present the spaces of games \(\mathfrak {g}^i\) with \(i=1, 2, 3\), and prove some of their properties. In particular, we show that \(\mathfrak {g}^3 \subset \mathfrak {g}^2 \subset \mathfrak {g}^1\) and, in each of such classes of games, there exists a dense subset where, for every game, any mixed-strategy Nash equilibrium is essential. Furthermore, for each game in \(\mathfrak {g}^{3}\) and in \(\mathfrak {g}^4\), we prove that any essential mixed-strategy Nash equilibrium is trembling-hand perfect. Examples show that \(\mathfrak {g}^1\), \(\mathfrak {g}^2\) and \(\mathfrak {g}^4\) are not included in the spaces of games considered in Corollary 1 by Carbonell-Nicolau (2010) and in Theorem 1 (and 4) by Carbonell-Nicolau (2011a). Finally (see Remark 7), we note that our result on the existence of essential and trembling-hand perfect equilibria in \(\mathfrak {g}^3\) is new even if \(\mathfrak {g}^3\) is included in the space of games considered in Theorem 1 by Carbonell-Nicolau (2011a).",4
2.0,1.0,Economic Theory Bulletin,12 December 2013,https://link.springer.com/article/10.1007/s40505-013-0022-4,An order-theoretic approach to dynamic programming: an exposition,April 2014,Takashi Kamihigashi,,,Male,Unknown,Unknown,Male,"Dynamic programming is one of the most important tools in modern economics, especially dynamic macroeconomics.Footnote 1 Recently, Kamihigashi (2013) obtained a simple yet useful result on the existence, uniqueness, and stability of a solution to the Bellman equation, i.e., a fixed point of the Bellman operator. In this note, we present the logic behind this result as well as explain why the order-theoretic approach used in Kamihigashi (2013) is useful but not sufficient to characterize the value function. To present our arguments in precise terms, we start by introducing some definitions and notations.",7
2.0,1.0,Economic Theory Bulletin,30 November 2013,https://link.springer.com/article/10.1007/s40505-013-0023-3,Information and evidence in bargaining,April 2014,Péter Eső,Chris Wallace,,Male,,Unknown,Mix,,
2.0,1.0,Economic Theory Bulletin,10 December 2013,https://link.springer.com/article/10.1007/s40505-013-0024-2,Stability analysis of Uzawa–Lucas endogenous growth model,April 2014,William A. Barnett,Taniya Ghosh,,Male,Unknown,Unknown,Male,"The Uzawa–Lucas model [(Uzawa (1965) and Lucas (1988)], upon which many others have been built, is among the most important endogenous growth models. The model has two sectors: the human capital production sector and the physical capital production sector, producing human capital and physical capital, respectively. Individuals have the same level of work qualification and expertise (\(H)\). They allocate some of their time toward producing final goods and dedicate the remaining time to training and studying. The social planner solution for the Uzawa–Lucas model is saddle path stable, but the representative agent’s equilibrium can be indeterminate, as shown by Benhabib and Perli (1994). As a result of the presence of externalities in human capital, the market solution is different from the social planner solution. The externality creates a distinction between return on capital, as perceived by the representative agent, to that perceived by a social planner. In this paper we provide a detailed bifurcation analysis of the model. Our task is to examine whether the dynamics of the model changes within the feasible parameter space of the model. A system undergoes a bifurcation, if a small smooth change in a parameter produces a sudden qualitative or topological change in the nature of singular points and trajectories of the system. The presence of bifurcation damages the inference robustness of the dynamics, when inferences are based on point estimates of the model. Hence, knowing the stability boundaries within the feasible region of the parameter space, especially near the point estimates, can lead to more robust dynamical inferences and more reliable policy conclusions. Using Mathematica, we locate transcritical and Hopf bifurcation boundaries in two-dimension and three-dimension diagrams. The numerical continuation package, Matcont, is used to analyze further the stability properties of the limit cycles generated by Hopf bifurcations and the presence of other kinds of bifurcations. We show the existence of Hopf, branch-point, limit-point-of-cycles, and period-doubling bifurcations within the feasible parameters set of the model’s parameter space. While these are all local bifurcations, presence of global bifurcation is also confirmed. There is some evidence of the possibility of chaotic dynamics through the detected series of period-doubling bifurcations, known to converge to chaos. Some of these results have not previously been demonstrated in the literature on endogenous growth models. 
Benhabib and Perli (1994) analyzed the stability property of the long-run equilibrium in the Lucas (1988) model. They have also detected a Hopf bifurcation in the Lucas (1988) model. Arnold (2000a; b) analyzed the stability of equilibrium in the Romer (1990) model. Arnold (2006) has done the same for the Jones (1995) model. Mondal (2008) examined the dynamics of the Grossman and Helpman (1991b) model of endogenous product cycles. The results derived in those papers provide important insights to researchers considering different policies. But, as in the Benhabib and Perli (1994) paper, a detailed bifurcation analysis has not been provided so far for many of these popular endogenous growth models. The current paper aims to fill this gap for the Uzawa–Lucas model. As pointed out by Banerjee et al. (2011): “Just as it is important to know for what parameter values a system is stable or unstable, it is equally important to know the nature of stability (e.g. monotonic convergence, damped single periodic convergence, or damped multi-periodic convergence) or instability (periodic, multi-periodic, or chaotic).” Barnett and his coauthors have made significant contribution in this area. Barnett and He (1999; 2002) examined the dynamics of the Bergstrom–Wymer continuous-time dynamic macroeconometric model of the UK economy. Both transcritical bifurcation boundaries and the Hopf bifurcation boundaries for the model were found. Barnett and He (2008) have found singularity bifurcation boundaries within the parameter space for the Leeper and Sims (1994) model. Barnett and Duzhak (2010) found Hopf and period-doubling bifurcations in a New Keynesian model. More recently, Banerjee et al. (2011) examined the possibility of cyclical behavior in the Marshallian macroeconomic model and Barnett and Eryilmaz (2013a; b) have found bifurcation in open economy models, while Barnett and Ghosh (2013) have found bifurcation boundaries within a variant of the Jones (1995) semi-endogenous growth model.",7
2.0,1.0,Economic Theory Bulletin,25 December 2013,https://link.springer.com/article/10.1007/s40505-013-0025-1,Meeting friends of friends and homophily: a complementarity,April 2014,Adrien Vigier,,,Male,Unknown,Unknown,Male,"Social networks underlie the diffusion of information and form a key component of trust and social capital. In this respect, understanding the structure and determinants of social networks is a major challenge for economists. The present paper aims to shed some light on these topics by exploring some effects of homophily (one’s preference for similarity to self) on social networks. I build in this paper on Vazquez (2003) and Jackson and Rogers (2007) insights on network formation, with a view to illustrate what appears like a natural form of complementarity between homophily and the dynamics of social network formation. I first postulate, following Jackson–Rogers–Vazquez, that social networks result from a combination of random and network-based (so-called friends of friends) meetings. Agents first meet a number of people at random, forming a link to each of them with some probability. They then go on to meet the friends of those they form a link with. If individuals are homophilous then friends of friends are likely to share tastes and hence also likely to form new friendships. Thus, in the context of homophily, the social network dynamics of meeting friends of friends acts as directed search. It is in this sense that homophily and the social network dynamics of meeting friends of friends naturally complement one another. I consider two distinct models of link creation: a homophilous model and a non-homophilous model. The homophilous model is based upon the idea that, in deciding whether or not to form ties with others, individuals consider certain characteristics, and that the same characteristics are used across pairs of individuals. This may be political opinions, taste for certain activities, or simply geographical proximity of two individuals. For our purposes, the important qualification is the following: proximity of tastes is transitive across pairs of nodes. By contrast the non-homophilous model is characterized by the property that the process of link formation is independent across pairs of nodes. I then go on to show that, in the context of meeting friends of friends, homophily generates networks which tend to (a) have more connections, (b) be more clustered, and (c) exhibit more unequal degree distributions. More connections (and greater clustering) arise because network-based meetings more often result in link formation. This exacerbates preferential attachment—whereby high degree nodes attract new links—and explains why homophily also causes more unequal distributions of links. These results have sharp welfare implications. By inducing more links, homophily generates higher average social welfare. However, if agents’ utility is concave in their number of links then, for a given average number of links formed, homophily in fact affects welfare negatively. Recent years have witnessed significant interest from economists in issues related to the interplay of social network structure and homophily. Bramoulle and RogersFootnote 1 (2010) for instance present a set of complementary views and results to those offered in this paper. They show among other things that, somewhat surprisingly, in multigroup settings network-based meetings tend to have a negative effect on the fraction of links eventually formed within one’s own group. The works of Currarini et al. (2009) and Golub and Jackson (2012) are also to a large extent related to this paper, albeit the focus of the first is on the relationship between group size and homophily rather than network structure stricto sensu, while the second investigates the effect of homophily on learning and diffusion in networks. To the best of my knowledge, this paper is the first to bring out and examine the complementarity between homophily and the social network dynamics of meeting friends of friends. The present paper is organized as follows. I present the formal model in Sect. 2. I develop the analysis and state the paper’s main results in Sect. 3. All proofs are relegated to the Appendix.",1
2.0,1.0,Economic Theory Bulletin,07 January 2014,https://link.springer.com/article/10.1007/s40505-013-0026-0,Noncompensatory consideration and compensatory choice: an application to Stackelberg competition,April 2014,Mauro Papi,,,Male,Unknown,Unknown,Male,"Standard models of choice assume that the decision-maker (DM) makes tradeoffs independently of the characteristics of the choice problem. Over the last two decades experimental evidence has challenged this paradigm: contrary to what standard models assume, the extent to which the DM is able to make tradeoffs crucially depends on the choice environment (e.g., number of alternatives, amount of time pressure, etc.). 
Payne et al. (1993) define a choice heuristic to be compensatory (resp., noncompensatory) whenever the DM makes (resp., does not make) tradeoffs between attributes. Experiments typically suggest that whenever the choice problem is relatively simple, DMs tend to follow decision strategies, such as compensatory ones, that are accurate, but require relatively high cognitive effort. On the contrary, whenever the choice problem gets complex, they sacrifice accuracy by relying on decision strategies, such as noncompensatory ones, that require relatively little cognitive effort.Footnote 1
 In this note I study a simple multi-attribute market model in which consumers simplify complex problems by discarding all alternatives that do not possess some salient attribute (noncompensatory phase) and then choose by maximizing an utility function among the alternatives that survive (compensatory phase), if any. Consistently with the experimental evidence, I assume that at simple problems consumers use a compensatory choice heuristic (i.e., utility maximization) straight away and identify the complexity of a choice problem with its cardinality. Firms compete à la Stackelberg by offering menus of multi-attribute alternatives and influencing the attribute that the consumer considers to be salient in the noncompensatory phase via marketing. I find that there is a tight link between the optimal menu design and marketing in equilibrium. If firms face technological constraints (i.e., only alternatives that possess up to a certain number of attributes can be offered), then in any equilibrium the leader uses product differentiation as an entry deterrence and marketing is irrelevant. On the contrary, in any equilibrium under fixed-capital constraints (i.e., only alternatives that possess certain specific attributes can be offered), both firms are active in the market and whenever the consumer goes through the noncompensatory phase marketing is not only relevant but also firm-specific, and firms offer menus accordingly. Finally, I briefly discuss the choice-theoretic properties of the consumer’s choice procedure and examine its relationships with other models. The paper is organized as follows: Sect. 2 defines the game; Sects. 3 and 4 propose the equilibrium analysis; Sect. 5 examines the consumer’s choice procedure in detail; Sect. 6 discusses the related literature, limitations, and extensions. Proofs are relegated in the Appendix.",6
2.0,1.0,Economic Theory Bulletin,22 January 2014,https://link.springer.com/article/10.1007/s40505-014-0029-5,Alfred Marshall’s cardinal theory of value: the strong law of demand,April 2014,Donald J. Brown,Caterina Calsamiglia,,Male,Female,Unknown,Mix,,
2.0,1.0,Economic Theory Bulletin,23 January 2014,https://link.springer.com/article/10.1007/s40505-014-0030-z,Optimal seedings in elimination tournaments revisited,April 2014,Matthias Kräkel,,,Male,Unknown,Unknown,Male,"There exist many situations from different fields that can be best described by a winner-take-all competition. For example, in sporting contests individual athletes or teams compete for a championship. In internal labor markets, employees participate in job-promotion tournaments for a vacant position at a higher tier of the corporate hierarchy. In addition, political contests, litigation contests, rent-seeking contests, R&D races, the race for technological or fashion leadership in certain markets, military conflicts, and song, beauty and cooking contests also have the typical characteristics of a winner-take-all competition. In these situations, the contestants do not necessarily compete against each other in a grand contest. Instead, they are often initially assigned to several sub-contests whose winners are allowed to continue in a higher order tournament, whereas the sub-contest losers are eliminated. There are several examples for such elimination tournaments:Footnote 1 Sporting contests are frequently divided into a group phase and a subsequent knock-out phase, where the group winners meet in the round of sixteen. Thereafter, the respective winners are matched in the quarter final and so on. At the end, the winner of the final receives the overall winner prize. Another example is given by job-promotion tournaments. Here, managers typically have to win subordinate tournaments (e.g., for becoming section or division head) before they get the opportunity to compete for a top position at their corporation’s headquarters (e.g., the CEO position). In this paper, I analyze how an organizer should optimally design the structure of such elimination tournaments. In particular, the organizer has to decide on the matching of different player types in the single sub-contests, which is called seeding (Groh et al. 2012). The answer to the question on what is the optimal seeding may crucially depend on the objective function of the tournament organizer. As a somehow natural objective function, the tournament organizer can be interested in maximizing players’ total expected effort for a given winner prize.Footnote 2 In the case of a sporting contest, the local organizer of the sports event may be free to choose the structure of the tournament, but the winner prize is determined by an exogenous sponsor or the respective sporting association. In that case, maximization of players’ total effort can be interpreted as maximizing the entertainment of the audience. In the case of a job-promotion tournament within internal labor markets, the firm owner may be primarily interested in maximizing workers’ overall effort for given wages being attached to jobs. The examples of sporting contests and job-promotion tournaments indicate a second possible objective of the tournament organizer, namely the maximization of the top players’ win probability.Footnote 3 A national sporting association can be very interested in this aim, if the winner of a national contest does not only obtain a winner prize but is also qualified for an international tournament. In a job-promotion tournament, the owner of a firm usually prefers the most able employee to climb the ladder to the top. Suppose that the design of the tournament which maximizes total expected effort, being thus optimal from an incentive perspective, is not optimal with respect to selecting high-ability individuals for top positions. In that case, the firm owner may be tempted to breach the rules of the tournament by declaring a more able employee the tournament winner although another employee has performed best. If the employees anticipate such opportunistic behavior of the firm owner, incentives from participating in a job-promotion tournament will be erased. Altogether, if the incentive aim and the selection aim lead to different solutions to the design problem, the organizer must credibly commit either to single out one of the two aims or to decide according to an optimal weighing of the two aims. I consider a four-player two-type elimination tournament and address both possible objective functions—maximization of total expected effort and maximization of the top players’ win probability. In this setting, there are two semifinals whose winners compete in the subsequent final for a winner-take-all prize, whereas the semifinal losers are eliminated and obtain nothing. Two players have a high type (i.e., a high valuation of winning) and two players have a low type (i.e., a low valuation of winning), which implies two possible seedings for the semifinals: The tournament organizer can either choose a homogeneous seeding or a heterogeneous one. In the former case (\(hom\)), the organizer matches the two high types in one semifinal and the two low types in the other semifinal. In the latter case (\(het\)), the organizer chooses two identical semifinals each between one high type and one low type. I use a Lazear–Rosen (1981) type of tournament for modeling the winner-take-all competition.Footnote 4 My results show that it can be optimal for the tournament organizer not to match low types (“underdogs”) and high types (“favorites”) together in the same semifinal, which is the typical procedure used in real sporting contests. On the contrary, the design \(hom\) can dominate the design \(het\) irrespective of whether the organizer wants to maximize total expected effort or the top players’ win probability. In that case, there is no trade-off between the two aims. The intuition for my finding is the following: design \(hom\) leads to balanced competition in both semifinals, which is beneficial for the organizer since players’ equilibrium efforts are higher the more balanced the competition.Footnote 5 Moreover, all semifinalists anticipate unbalanced competition in the final for sure, implying low effort costs in the final and, hence, a rather large expected utility from participating in the final. This second effect also boosts overall incentives in the semifinals. In addition, the two high-type or top players already know in the semifinal that, in case of winning, they will be matched with a weaker opponent in the final. Thus, their win probability in the final will be quite large, so that especially the high-type players have a very large incentive to win the semifinal. Note that the design \(hom\) has two drawbacks: First, since it is clear that one high-type and one low-type player will reach the final, total effort from the final will be rather small due to unbalanced competition. Second, the low-type players in the semifinal anticipate that they will have a rather low win probability in the final. However, if the incentive advantages from the two homogeneous semifinals dominate these incentive disadvantages from a surely heterogeneous final, design \(hom\) will be optimal for maximizing total expected effort. Design \(hom\) is also beneficial for maximizing the win probability of a high-type player: in contrast to \(het\), design \(hom\) guarantees that one high-type player reaches the final for sure. In the final, the high-type player has a quite large win probability since he competes against a low-type opponent. My finding sharply contrasts with the main result of Groh et al. (2012) who analyze the same design problem but use an all-pay auction with complete information instead of a Lazear–Rosen tournament [or difference-form contest-success function (csf)]. They show that design \(het\) is optimal for maximizing both total expected effort and the top players’ win probability. My contrary findings point out that the optimal design of elimination tournaments crucially depends on the underlying contest-success technology. Note that the all-pay auction with complete information can be seen as an extreme case of the Lazear–Rosen tournament. In fact, by assuming that the noise distribution is degenerate, the Lazear–Rosen tournament immediately turns into an all-pay auction. Suppose that the tournament organizer can choose between two different monitoring technologies. He may either choose a perfect monitoring technology leading to an all-pay auction and high monitoring costs, or a less precise monitoring technology implying a Lazear–Rosen tournament and lower monitoring costs. Under either contest type, the organizer has the advantage that one design is optimal in both dimensions—maximizing total expected effort (incentive dimension) and the top players’ win probability (selection dimension). However, I can show that for uniformly distributed noise the optimally designed all-pay auction (using design \(het\)) dominates any optimally designed Lazear–Rosen tournament (using design \(hom\)) in both the incentive and the selection dimensions. The optimal decision between an all-pay auction and a Lazear-Rosen tournament then crucially depends on the different monitoring costs of the two contests. Previous work on elimination tournaments typically builds on either the all-pay auction (e.g., Moldovanu and Sela 2006) or the Tullock csf (e.g., Rosen (1986), Gradstein and Konrad 1999, Amegashie 1996, 2000, Harbaugh and Klumpp 2005). So far, only two papers have addressed the problem of optimal seeding in elimination tournaments—Groh et al. (2012) and Höchtl et al. (2011). As has been stressed above, my paper is closest to the recent work by Groh et al. (2012), who also consider seedings of heterogeneous contestants in two semifinals. However, contrary to my paper, Groh et al. apply an all-pay auction with complete information, which leads to the converse outcome—\(het\) dominates \(hom\). Höchtl et al. (2011) use a Tullock contest with linear impact function, and assume costs to be linear and contestants having identical valuations of the winner prize.Footnote 6 They show that \(hom\) is better than \(het\) if the tournament organizer wants to maximize total expected effort, but \(het\) is better than \(hom\) for maximizing the top players’ win probability. Thus, given a Tullock csf, the incentive and selection aims lead to a strict trade-off, contrary to the Lazear–Rosen tournament and the all-pay auction.",11
2.0,1.0,Economic Theory Bulletin,05 March 2014,https://link.springer.com/article/10.1007/s40505-014-0031-y,Non-bossy single object auctions,April 2014,Debasis Mishra,Abdul Quadir,,Unknown,Male,Unknown,Male,"We study single object auctions in the standard private values model. We are interested in characterizing deterministic allocation rules which can be implemented in dominant strategies using suitable payments. We provide precise characterizations of such rules under an additional condition called non-bossiness. Non-bossiness specifies that keeping the valuations of other agents fixed, if agent \(i\) changes his valuation in such a manner such that his own allocation (i.e., whether he gets the object or not) does not change, then the allocation of no other agent should change. We show that implementability of a non-bossy allocation rule in dominant strategies is equivalent to that allocation rule being a strongly rationalizable allocation rule. Under an additional continuity like condition, this characterization can be strengthened as follows: an implementable non-bossy allocation rule is equivalent to a simple utility maximizer allocation rule. Simple utility maximizers transform the valuation of each agent to a real number using non-decreasing functions that we call simple utility functions. Then, it gives the object to an agent who has the highest non-negative simple utility (breaking ties in a consistent manner). If all the agents have negative simple utility, then the object is not allocated. The simple utility maximizers are a large class of allocation rules—it includes the efficient allocation rule, constrained efficient allocation rule with a reserve price, revenue-optimal allocation rule in Myerson (1981) that maximizes virtual utilities of agents. The primary objective of this paper is to characterize the set of implementable allocation rules in the single object private values model. While, Myerson (1981) provides a monotonicity condition that is necessary and sufficient, it is only an implicit characterization. We are interested in a functional form explicit characterization of implementable allocation rule. A benchmark result that answers such a question for the unrestricted domain is Roberts (1979). Consider a general mechanism design set up with private values and quasi-linear utility. Let \(A\) be a finite set of alternatives. Suppose \(|A| \ge 3\). The type of agent \(i\) is denoted as \(v_i \in \mathbb {R}^{|A|}\) and \(v_i(a)\) denotes the valuation of agent \(i\) for alternative \(a\). Roberts (1979) shows that if type space of every agent is \(\mathbb {R}^{|A|}\), then for every onto and implementable allocation rule \(f\), there exists \(\lambda _1,\ldots ,\lambda _n \ge 0\), not all of them equal to zero, and \(\kappa :A \rightarrow \mathbb {R}\) such that at every valuation profile \(v\), Such allocation rules are called affine maximizer allocation rules. The unrestricted type space plays a crucial role in Roberts’ theorem. It is well known that there are implementable allocation rules in restricted domains that are not affine maximizers. However, few concrete characterizations are known in any such restricted domain. There have been some extensions of Roberts‘ affine maximizer theorem. Mishra and Sen (2012) show that if the type space is a multidimensional open interval, an additional condition neutrality along with implementability implies affine maximization. Carbajal et al. (2013) provide an extension where they consider infinite set of alternatives but types are continuous functions on these alternatives (or satisfy some topological properties). Marchant and Mishra (2012) show that the set of implementable allocation rules expand if we just have two alternatives. Lavi et al. (2003) characterize almost affine maximizers (affine maximizers for large enough values) in specific combinatorial auction domains using various additional conditions. The single object auction model is a restricted domain since each agent only places a non-negative value on the alternative where he is allocated the object and places zero value on all the other alternatives. This is a severe restriction on the set of all possible types, and hence, all the earlier results do not have any implication on this model. As is well known, in a restricted domain, the possibility to manipulate is smaller for an agent, and hence, a larger set of allocation rules are implementable. Roberts’ theorem shows that if the domain is unrestricted, then every allocation rule maximizes an affine combination of valuations of agents. Our results show that in the single object auction model, we get some form of maximization but it is no longer an affine maximization. To our knowledge, this is one of the very few papers that has characterized non-affine maximizers. Because of this reason, our methodology of proof differs from proving the Roberts’ theorem. A work related to ours is Archer and Tardos (2002). They consider the single object auction model and show that if the object is always allocated then the only implementable allocation rules satisfying non-bossiness and three more additional conditions are min function allocation rules. Footnote 1 Min function allocation rules are simple utility maximizer allocation rules, but with some additional limiting and continuity properties. Though our characterization of simple utility maximizer is related to their result, it has several important differences. First, their result requires that we always sell the good. This rules out any allocation rule with a reserve price, such as Myerson’s revenue maximizing allocation rule. Further, our proof shows that allowing the object to be not sold adds several non-trivial complications in deriving our results. Second, they seem to require different types of range and tie-breaking conditions than our continuity requirement. On the other hand, our characterization of simple utility maximizer makes it explicit the way ties need to be broken. Finally, they have no analog of our other characterization. There have been many simplifications of the original proof of Roberts (Jehiel et al. 2008; Lavi 2007; Dobzinski and Nisan 2009; Vohra 2011; Mishra and Sen 2012). But none of these proofs show how Roberts’ theorem can be extended to a restricted domain like the single object auction model. Unlike most of the literature, our goal is not to characterize “affine maximizers”—indeed, all our characterizations capture a larger class of implementable allocation rules than affine maximizers. Instead of characterizing implementable allocation rules, one can characterize the set of dominant strategy mechanisms directly by imposing conditions on mechanisms rather than just on allocation rules. A contribution along this line is Ashlagi and Serizawa (2011). They show that any mechanism which always allocates the object, satisfies individual rationality, non-negativity of payments, anonymity in net utility, and dominant strategy incentive compatiblity must be the Vickrey auction. This result is further strengthened by Mukherjee (2013), who shows that any strategy-proof and anonymous (in net utility) mechanism which always allocates the object must use the efficient allocation rule. Further, Sakai (2012) characterizes the Vickrey auction with a reserve price using various axioms on the mechanism (this includes an axiom on the allocation rule which requires a weak version of efficiency). By placing minimal axioms on allocation rules, we are able to characterize a broader class of allocation rules than these papers.",10
2.0,1.0,Economic Theory Bulletin,18 January 2014,https://link.springer.com/article/10.1007/s40505-013-0027-z,"Comment on “Collateral premia and risk sharing under limited commitment” [Econ. Theory 46, 475–501 (2011)]",April 2014,Michael Zierhut,,,Male,Unknown,Unknown,Male,,
2.0,1.0,Economic Theory Bulletin,19 January 2014,https://link.springer.com/article/10.1007/s40505-013-0028-y,"Correction for “Collateral premia and risk sharing under limited commitment” [Econ. Theory 46, 475–501 (2011)]",April 2014,Weerachart Tee Kilenthong,,,Unknown,Unknown,Unknown,Unknown,,
2.0,2.0,Economic Theory Bulletin,28 March 2014,https://link.springer.com/article/10.1007/s40505-014-0032-x,Factor proportionality in multiple households closed CGE models: theory and illustrations,October 2014,Yves Balasko,Octavio Tourinho,,Male,Male,Unknown,Male,"The factor contents of different consumers’ consumption bundles computed from a country’s CGE model with multiple households are seen to be proportional or almost proportional in the case of four different countries, namely USA, Brazil, Spain and Ivory Coast. These countries have been chosen because of the existence for these countries of CGE models with multiple households (by opposition to a representative consumer) and good quality data. This study has been limited to these four countries because we thought that the implications for CGE modeling of our findings should not delay any further their publication, though further studies are obviously needed. The proportionality in factor contents in multiple households CGE models is likely to be the result of more or less implicit and seemingly innocuous simplifying assumptions made at various stages of the modeling process. Taken as a law, we show that factor proportionality is not innocuous at all. We start by showing that multiple households closed CGE models (i.e., without foreign and governmental sectors) are equivalent to pure exchange models where households (also known as the consumers in those models) have preferences for factors induced by their preferences for consumption goods in the CGE models. We then apply this equivalence to show that in exchange economies, factor proportionality for all endowment vectors for given preferences is equivalent to those preferences being identical and homothetic. Applied to our closed CGE models, households’ implicit preferences for factor contents induced by their preferences for consumption goods are therefore identical and homothetic. This identity of preferences for factors does not require that households’ preferences for consumption goods are identical and, in general, they are not in the multiple households CGE models that we have studied. Another consequence of factor proportionality for all endowment vectors is that factor and goods’ equilibrium prices are unique and depend only on total factor resources, not on the distribution of these factors between the households of a given country in the case of CGE models. Factor proportionality offers one a possible explanation of the mysterious rigidity and uniqueness of equilibrium prices of goods and factors observed in many CGE models. If factor proportionality is confirmed to be a property of the current versions of multiple households CGE models, further research will be needed to identify the implicit assumptions in CGE modeling at the root of that factor proportionality, assumptions that will have to be eliminated if one wants to get more relevant CGE models with multiple households. Computable general equilibrium or CGE models are numerical implementations of the general equilibrium models that are based on real world data. A huge literature has been devoted to the study of the general equilibrium model since its formulation by Walras (1874). The existence of equilibrium (Arrow and Debreu 1954; McKenzie 1954) and the efficiency of equilibrium allocations (Arrow 1951a) are the best known properties of that model. Just after them, the multiplicity of equilibria stands out for its combination of theoretical interest with importance in applications. This explains the search for economically relevant conditions that imply the uniqueness and stability of equilibrium. First results were obtained by Wald (1951). The search was pursued by Arrow, Hahn, Hurwicz, McKenzie and Uzawa among many others during the 1950s and 1960s. See the survey article by Negishi (1962) and the two chapters on uniqueness and tatonnement stability in Arrow and Hahn (1971) monumental book for an account of the results of that period. A new line of research was started in the wake of Debreu’s theory of regular economies (Debreu 1970) by Dierker (1972) and Kehoe (1980, 1982) who proved index theorems for exchange and production economies. Important by-products of those index theorems were more general sufficient conditions for the uniqueness of equilibrium in general equilibrium models, conditions that have been readily applied by Kehoe and Whalley (1985) and Kehoe (1985, 1991) to CGE models. Kehoe’s example of a production economy with multiple equilibria (Kehoe 1984) shows, however, that uniqueness is not satisfied in very general classes of general equilibrium models. In the less complex exchange model, it is very easy to create examples of economies with multiple equilibria provided preferences are not homothetic and identical. It suffices to select in any given fiber of the equilibrium manifold (Balasko 1975a) an equilibrium with a negative index number. In general, this requires little more than a large net trade vector. Then it follows from the index theorem for exchange economies that an economy that features an equilibrium with a negative index number has other equilibria. (See Balasko (2011) for more details.) All these results imply the existence of economies with multiple equilibria for some endowment vectors at least as a consequence of the non-linearities of the general forms of general equilibrium model. The absence of multiple equilibria in the many CGE models has been noticed by sufficiently many economists to become a phenomenon in need of an explanation given the widespread occurrence of multiple equilibria in general equilibrium models of exchange and production economies. This uniqueness of equilibrium is in fact a real problem only for CGE models with multiple households because equilibrium is obviously unique as soon as there is a representative household or, equivalently, a unique consumer. The rigorous study of the question of the number of equilibria in CGE models with multiple households requires first that these models are compared to the standard exchange and production general equilibrium models of economic theory. In fact, CGE models are different in several dimensions: (1) There are two kinds of goods (consumption goods and pure production factors, the latter being inputs to the production process without being arguments of consumers’ utility functions); (2) Production sets have a somewhat elaborated geometry due to the absence of joint production (of consumption goods), fixed coefficient technologies for consumption goods used as inputs and substitutability between factor inputs; (3) Consumers are endowed only in factors; (4) Existence of governmental and foreign sectors. The operation of these two open sectors creates major differences with the closed general equilibrium models of economic theory. The first thing to do is therefore to close the CGE models of real countries by deleting these two open sectors after having data adjusted for the economic impact of these two sectors. The resulting closed CGE models are then sufficiently close to the standard exchange and production models of general equilibrium theory for comparisons to become possible. Nevertheless, the remaining differences suffice to require a fresh study of any question that goes beyond the existence and efficiency of equilibria. In that direction, the special case of two goods, two factors and two consumers has already been considered by Vanek in a paper published in (1963). There, Vanek adheres to the standards of the time by limiting himself to the derivation of formulas expressing the local comparative statics of the equilibria of that model. For example, Vanek does not prove the existence of an equilibrium nor studies the number of equilibria. One goal of the current paper is to take up the theory of closed CGE models where Vanek left it by developing the theory for an arbitrary number of goods, factors and households along the lines of the global approach through the equilibrium manifold and the natural projection, an approach that is particularly fitted for the identification of economies with multiple equilibria as follows from Balasko (1975a, 2011). That undertaking will be facilitated by the equivalence between the pure Heckscher–Ohlin model and a suitably defined exchange model for the factors of that Heckscher–Ohlin model recently proved by Balasko (2013a). The Heckscher–Ohlin and closed CGE models differ only by their production sectors. In the Heckscher–Ohlin model, goods cannot be used as inputs while they can in closed CGE models and, when they are, they contribute to production according to the linear activity model. Our approach will therefore consist in extending the equivalence of Balasko (2013a) to the more general category of production sets considered in the closed CGE models. A few words of explanation about this equivalence between models is in order at this stage. The observation that the demand for consumption goods in both the Heckscher–Ohlin model and in closed CGE models induces an indirect demand for factors is not new. Rader (1972) and Kehoe (1991) in particular establish properties of the aggregate excess demand function for factors of a given economy viewed as a function of factor prices. As mentioned above, these properties are for a given economy, i.e., for given specifications of the fundamentals of an economy like initial endowments. This approach has enabled Kehoe to extend his earlier work on index numbers and on sufficient conditions for the uniqueness of equilibrium from general equilibrium models with production to CGE models. The global approach focuses on a collection of economies defined by a set of values of the fundamentals by opposition to a single economy. In the general equilibrium exchange model for example, the fundamentals are represented by the vector \(\omega \) defined by the consumers’ endowments as in Debreu (1970) and Balasko (1975a). The collection of economies \(\Omega \) is also known as the parameter space and is in general the full set of possible endowments. A “model” then consists of a parameter space and of an equilibrium concept. For example, the Edgeworth–Pareto–Bowley box \(\Omega \) plus its contract curve and its collection of budget lines is a “model” in the above sense for the two good, two consumer and fixed total resource case. A point \(\omega \) in the box \(\Omega \) represents the endowment vector for the two consumers. Properties of the economy \(\omega \) will deal for example with the number of the equilibria associated with that endowment vector \(\omega \). Typical properties of the Edgeworth–Pareto–Bowley box as a “model” are the pathconnectedness of the set of Pareto optima (a.k.a., the contract curve) or the pathconnectedness of the set of (regular) economies that have a unique equilibrium and the inclusion of the contract curve in that set. In the exchange model, an equilibrium is a pair \((p,\omega )\) where \(\omega \in \Omega \) is the endowment and the price vector \(p\) an equilibrium price vector associated with the endowment \(\omega \). With \(S\) denoting the set of all price vectors \(p \in S\), the equilibrium manifold \(E\) is then the subset of \(S \times \Omega \) that consists of all equilibria. A “model” therefore features its equilibrium manifold \(E\) and the “natural projection,” the map \(\pi {:\,}E \rightarrow \Omega \) that is the restriction to the equilibrium manifold of the projection map \(S \times \Omega \rightarrow \Omega \). The preimage \(\pi ^{-1}(\omega )\) is in bijection with the equilibrium price vectors associated with the economy defined by the endowments \(\omega \in \Omega \). The natural projection captures among other things all the information about the subsets of \(\Omega \) that consist of economies with a unique equilibrium and with multiple equilibria, respectively. An important contribution of the global approach in the general equilibrium model has been to highlight the impact of the quantities of net trade at equilibrium on the number of equilibria: in the exchange model (Balasko 1975a), in general equilibrium models with private ownership of production Balasko (2011) and in the Heckscher–Ohlin model (Balasko 2013a). Two “models” are equivalent if their natural projections are equivalent smooth mappings in the sense of Differential Topology. In other words, these maps coincide up to some diffeomorphisms of the domain and range. Equivalence is a powerful tool for extending properties related with the number of equilibria from one model, the exchange model in particular, to other general equilibrium models like the model with private ownership of production and the Heckscher–Ohlin model. In the current paper, closed CGE models are shown to be equivalent to suitably defined exchange models for factors.Footnote 1 It follows from that equivalence that all the properties of the exchange model, including those related with the sets of endowments with unique and multiple equilibria, carry over to closed CGE models. That result is new. Our initial goal was to apply the concept of model equivalence to several closed CGE models with multiple households to identify their sets of economies with multiple equilibria. We also wanted these models to be based on real data. We therefore chose four countries for which CGE models with multiple households and high-quality data were known to exist: USA, Brazil, Spain and Ivory Coast. After having unsuccessfully looked for economies with multiple equilibria, we started to look for reasons that might explain why economies with multiple equilibria were so elusive in those CGE models with multiple households. This led us to focus on the set of equilibrium allocations in the equivalent factor models and to observe, much to our surprise, that these equilibrium factor allocations (or, by equivalence, the factor content of the allocations in consumption goods at equilibrium) were collinear or almost collinear for all consumers in the models of the four countries. This property was all the more remarkable given that the equilibrium allocations in consumption goods in the same models were significantly non-collinear. Factor proportionality in itself is not new within the setup of the Heckscher–Ohlin model, a model that is rather close to the closed CGE models. For example, factor proportionality has been a staple of international trade theory since Vanek’s paper (1968) at least. Nevertheless and to the best of our knowledge, the proportionality of factor contents has not been documented for any CGE model so far. A property that is satisfied by only four countries is a long way from being a universal law. The fact that these four countries were chosen only for their economic differences combined with the quality of the data of their CGE models with multiple households suggests that the property of factor proportionality in those models may nevertheless be more general than one could expect from just these four examples. This possibility led us to explore the theoretical implications for a CGE model of having the factor content of its equilibrium allocations always proportional for all consumers. That property is extreme and cannot in anyway be considered as resulting from the four examples. The relevance of that property, however, would be strengthened if it is shown to imply other properties that have already been observed in multiple households CGE models. In this paper, we therefore start by showing that, in the simpler exchange model where individual equilibrium allocations are proportional for all possible endowments while preferences are fixed, those preferences are necessarily identical and homothetic. We then show that equilibrium is unique under those circumstances and depends only on the vector of total resources, not on the distribution of these resources among consumers. It then suffices to use the equivalence of the closed CGE model with the exchange model to see that the law of proportional factor contents in multiple households CGE models implies the uniqueness and rigidity of equilibrium prices of goods and factors. The widespread observation that equilibrium price vectors in multiple households CGE models are unique and rigid with respect to endowment redistribution is one more element in favor of the law of proportionality of factor contents. This paper is organized as follows. The theoretical version of a closed CGE model is defined in Sect. 2. The associated factor exchange model and its equivalence with a closed CGE model is proved in Sect. 3. The equivalence between proportionality of equilibrium allocations and the homotheticity and identity of individual preferences (in exchange economies) is proved in Sect. 4. The proportionality or almost proportionality of factor contents of equilibrium allocations is seen in Sect. 5 on data for the USA, Brazil, Spain and Ivory Coast. Concluding comments end this paper with Sect. 6.",4
2.0,2.0,Economic Theory Bulletin,12 June 2014,https://link.springer.com/article/10.1007/s40505-014-0044-6,Non-existence of weakly Pareto optimal allocations,October 2014,Foivos Xanthos,,,Male,Unknown,Unknown,Male,"A challenging problem in general equilibrium theory is to extend equilibrium results of finite many commodities to the infinite dimensional setting. Several authors (Aliprantis and Brown 1983; Aliprantis et al. 2004; Aliprantis and Tourky 2009; Angelopoulos and Koutsougeras 2014; Bewley 1972; He and Yannelis 2014; Mas-Colell 1986; Mas-Colell and Richard 1991; Podczeck 1996; Podczeck and Yannelis 2008; Yannelis and Prabhakar 1983; Yannelis 1985; Yannelis and Zame 1986) contributed to this problem and nowadays it is a well-known fact that such a generalization is possible, provided that additional assumptions are imposed to the economic model. In Aliprantis et al. (1987); Araujo (1985); Jones (1984); Yannelis (1991), the authors demonstrated the necessity of additional assumptions by constructing concrete economies with infinitely many commodities, that fail to have an equilibrium or a non-empty core. In particular in Yannelis (1991), Example 6.2, the author illustrated that to ensure the non- emptiness of the core, it is not sufficient to assume that consumers’ preferences have norm open lower sections. In Aliprantis et al. (1987) and Jones (1984), Example 8, are provided examples of economies in \(C[0,1]\), where consumers’ preferences are weakly continuous and the economy has an empty core. In Araujo (1985), the author showed that the same phenomenon occurs in \(\ell _\infty \). In this paper, we throw light to these results, by showing that the existence of a weakly Pareto optimal allocation in these economies, forces the commodity space to be finite dimensional. In fact, we show that this is true for a general class of commodity spaces with an order unit. This phenomenon occurs due to the possible lack of compact intervals in infinite dimensional commodity spaces. The existence of a Hausdorff linear topology under which the order intervals of the commodity space are compact is a standard assumption in economic models (see in Aliprantis and Tourky 2009; Podczeck and Yannelis 2008). In Sect. 2, we demonstrate that a large class of ordered vector spaces with the Riesz decomposition property, including the spaces \(C[0,1],C^{1}[0,1],c\), fails to have compact intervals under any Hausdorff linear topology. This fact, enables us to improve a characterization of the Riesz decomposition property, obtained in Aliprantis et al. (2000). In general, the Riesz decomposition property of an ordered vector space \(L\) cannot be characterized by the vector lattice property of the order dual \(L^\sim \) (see Wickstead 2014, Example 10). In Aliprantis et al. (2000), Corollary 3.5, the authors showed that this is possible, if \(L\) has an order unit, \(\sigma (L,L^\sim )\)-compact intervals and \(L^\sim \) separates the points of \(L\). In Theorem 2.5, we improve this result, by proving that in this case, \(L\) is a finite dimensional vector lattice. In Sect. 3, we study the existence of weakly Pareto optimal allocations in exchange economies. In our model, we assume that preferences are transitive, irreflexive, have non-empty, convex values and open lower sections with respect to some Hausdorff linear topology \(\tau \). Under these assumptions, any economy on \(L\) has an Edgeworth equilibrium, provided the set of allocations is \(\tau \)-compact (see Florenzano 2003, Proposition 5.2.2). In the case, where \(L=C[0,1]\) and \(\tau \) is the weak topology, we cannot always apply this result, since there are plenty of economies where the set of allocations is not weakly compact. It turns out that these economies fail to have a weakly Pareto optimal allocation. In particular, we show in Theorem 3.4, that for a general class of commodity spaces with an order unit, including any \(C(K)\) space (see Corollary 3.5), the existence of a weakly Pareto optimal allocation for any economy is equivalent to the finite dimensional nature of the commodity space. This result gives a characterization of infinite dimensional spaces in terms of general equilibrium theory. In paper Polyrakis (2008), in a similar fashion, a characterization of reflexive Banach spaces, based on the existence of the demand correspondences is given. In the case, where the commodity space is \(\ell _\infty \), it is well known that the set of allocations is \(w^*\)-compact, so if we consider preferences that have \(w^*\)-open lower sections, then any economy will have a weakly Pareto optimal allocation. Hence, a natural guess would be that in the case of \(C[0,1]\), the problem was the choice of the weak topology. As we show in Theorem 3.6, this is not the case, that is under any choice of Hausdorff linear topology \(\tau \), there exists an economy in \(C[0,1]\) with no weakly Pareto optimal allocations. This result, illustrates that when the commodity space fails to have compact intervals with respect to any Hausdorff linear topology, the validity of the Welfare theory in this model is questioned. To overcome this obstacle, we must impose additional conditions on the preferences. In the case, where the preferences are defined by utility functions, it is known that the compactness of the utility set can solve this problem (see Florenzano 2003, Remark 5.2.1 and Allouch and Florenzano 2004). To our knowledge, it is not known whether some additional condition can ensure the validity of the Welfare theory, in the general case where consumers’ preferences are not defined by utility functions. In this article, \(L\) will denote an ordered vector space. The positive cone \(L_+\) of \(L\) is assumed to be pointed (i.e. \(L_+ \cap (-L_+)=\{0\}\)), \(L_+\) defines a vector ordering on \(L\), by letting \(x \ge y\) whenever \(x-y\in L_+\). We say that \(L_+\) is generating if \(L=L_+-L_+\). The order interval \([x,y]\) is the set defined by \([x,y]=\{z \in L \,\, | \,\,x \le z \le y\}\). The space \(L\) has the Riesz decomposition property, if for each \(x,y,z \in L_+\) such that \(x \le y+z\) there exist \(x_1 \in [0,y]\) and \(x_2 \in [0,z]\) such that \(x=x_1+x_2\). If for every pair of finite non-empty subsets \(A\) and \(B\) of \(L\) satisfying \(A \le B\) there exists \(x \in L\) such that \(A \le x \le B\), we say that \(L\) has the interpolation property. It follows that the interpolation property and the Riesz decomposition property are equivalent (see Aliprantis and Tourky 2007, Theorem 1.54). If for every pair \(x,y \in L\) their infimum \(x \wedge y\) exists in \(L\), we say that \(L\) is a vector lattice or a Riesz space. We say that \(L\) is (\(\sigma \)-)monotone order complete if every increasing upper bounded (sequence) net of \(L\) has a supremum. If \(L\) is a vector lattice, this property is equivalent to the so-called (\(\sigma \)-) Dedekind complete property, that is every upper bounded (countable) subset of \(L\) has a supremum. We denote with \(L^*\), the algebraic dual of \(L\) and \(L^\sim \) the order dual of \(L\). A functional \(f \in L^*\) is said to be (strictly) positive, if \(f(x) \ge 0\) (\(f(x)>0\)) for any \(x\in L_+\setminus \{0\}\). If \(L\) has the Riesz decomposition property and \(L_+\) is generating, then the order dual \(L^\sim \) is a vector lattice (see Aliprantis and Tourky 2007, Theorem 1.61). We say that \(e \in L_+\) is an order unit of \(L\), if \(\bigcup _{n=1}^\infty [-ne,ne]=L\). An order unit \(e\), induces the following seminorm on \(L\), \(||x||_e=\inf \{\lambda >0 \,\, | \,\, x \in [-\lambda e,\lambda e]\}\) (see Aliprantis and Tourky (2007), Theorem 2.55). For the following, assume that \(L\) is equipped with a linear topology \(\tau \). We denote with \(L'\) the topological dual of \(L\) and we say that \(L\) has compact (closed) intervals, whenever \([0,x]\) is \(\tau \)-compact (\(\tau \)-closed), for any \(x \in L_+\). If \(L\) has compact intervals then any order interval is \(\tau \)-compact, since whenever \(x \le y\) we have that \([x,y]=x+[0,y-x]\). We recall here some well-known facts about Banach lattices and \(C(K)\) spaces. A Banach lattice \(L\) is a vector lattice, equipped with a complete norm such that \(|x| \le |y| \Rightarrow ||x|| \le ||y||\) for any \(x,y \in L\). If \(L\) is a Banach lattice, then \(L'=L^\sim \) (see Aliprantis and Border 2007, Theorem 9.11) and \(e\) is an order unit of \(L\) iff \(e\) is an interior point of \(L_+\) (see Aliprantis and Tourky 2007, Theorem 2.8). An AM-space with a unit, is a Banach lattice with an order unit \(e\) whose norm is given by \(||\cdot ||_e\). A Banach lattice is an AM-space with a unit if and only if is lattice isometric to \(C(K)\) for some compact Hausdorff space \(K\) (see Aliprantis and Burkinshaw 1985, Theorem 12.28). Assume for the following that \(K\) is a compact Hausdorff space. The vector lattice \(C(K)\) is (\(\sigma \)-) Dedekind complete iff \(K\) is (\(\sigma \)-) Stonian, that is the closure of every open ( \(F_\sigma \) ) set in \(K\) is open (see Meyer-Nieberg 1991, Proposition 2.1.4, 2.1.5). For unexplained mathematical terminology, we refer the reader to Aliprantis and Border (2007); Aliprantis and Burkinshaw (1985); Aliprantis and Tourky (2007).",4
2.0,2.0,Economic Theory Bulletin,30 May 2014,https://link.springer.com/article/10.1007/s40505-014-0040-x,Speculative trade under unawareness: the infinite case,October 2014,Martin Meier,Burkhard C. Schipper,,Male,Male,Unknown,Male,"Unawareness refers to the lack of conception rather than to the lack of information. It is natural to presume that asymmetric unawareness may lead to speculative trade. Indeed, Heifetz et al. (2013) present a simple example of speculation under unawareness in which there is common certainty of willingness to trade but agents have a strict preference to trade despite the existence of a common prior.Footnote 1 This is impossible in standard state-space structures with a common prior. In standard “no-speculative-trade” theorems, if there is common certainty of willingness to trade, then agents are necessarily indifferent to trade (Milgrom and Stokey 1982). Somewhat surprisingly, Heifetz et al. (2013) also prove a “no-speculative-trade” result according to which under a common prior there cannot be common certainty of strict preference to trade. This means that arbitrarily small transaction costs rule out speculation under asymmetric unawareness. The “no-speculative-trade” result in Heifetz et al. (2013) was stated for finite unawareness belief structures. In this note, we generalize the result to infinite unawareness belief structures. Such a generalization is relevant since the space of underlying uncertainties may be large. Especially if it is large, agents may be unaware of some of them. Moreover, the generalization serves as a robustness check for our “no-speculative-trade” result for finite unawareness belief structures. It shows that the result in Heifetz et al. (2013) is not an artifact of the finiteness assumption but holds more generally. The topological unawareness belief structure introduced in this paper to prove our result may be of independent interest for other applications. 
Board and Chung (2011) present a different model of unawareness, in which unawareness is about “objects” rather than events. Intuitively, we model an agent’s unawareness of events like “penicillium rubens has antibiotic properties” while in their model the agent’s corresponding unawareness would be about “penicillium rubens”. Board and Chung (2011) also prove a “no-speculative-trade” result for finite spaces. This suggests that the “no-speculative-trade” result in Heifetz et al. (2013) remains robust if unawareness of events is replaced by unawareness of objects. Further, Board and Chung (2011) study awareness of unawareness of objects. This allows them to show that the “no-speculative-trade” result obtains both under “living in denial” and “living under paranoia”, where former refers to the situation in which every agent is certain that there is nothing they are unaware of, while latter refers to the situation in which every agent is certain that there is something they are unaware of. Grant and Quiggin (2013) discuss the speculative trade example of Heifetz et al. (2006) in the context of awareness of unawareness. The authors argue that agents should induce from previous experiences of becoming aware and from differences in awareness across agents that they themselves could be unaware of something. This awareness of unawareness may be coupled with a version of a precautionary principle which may make them reluctant to engage in speculative trade. The paper is organized as follows. The next section introduces topological unawareness belief structures. The general “no-speculative-trade” theorem is stated in Sect. 3. Finally, Sect. 4 contains the proof of the theorem.",7
2.0,2.0,Economic Theory Bulletin,26 April 2014,https://link.springer.com/article/10.1007/s40505-014-0037-5,The logic of Knightian games,October 2014,Shiri Alon,Aviad  Heifetz,,Unknown,,Unknown,Mix,,
2.0,2.0,Economic Theory Bulletin,24 April 2014,https://link.springer.com/article/10.1007/s40505-014-0036-6,Mechanism design without monotone differences: an example featuring buyer habits,October 2014,Levent Ülkü,,,Male,Unknown,Unknown,Male,"Consider a seller interacting with a privately informed buyer whose values exhibit an intertemporal allocation externality in the form of habit persistence: current consumption generates disutility in the future. The existence of habit renders the agent’s value nonmonotone in type. I show that this nonmonotonicity leads, for a range of habit parameter values, to the optimality of a nonmonotone mechanism: as part of a revenue maximizing mechanism, the seller screens out low as well as high types, serving only to an interval of types inbetween. The distinguishing feature of the environment in this paper is that the monotone differences condition need not hold. This condition leads to the possibility of ordering outcomes from “small” to “large” in such a way that larger outcomes are valued more at the margin by larger types. As a result, implementability is characterized by monotonicity of allocation functions: larger types should receive larger outcomes. In the absence of monotone differences, however, monotone allocation functions need not be implementable and implementable allocation functions need not be monotone. Importantly an optimal mechanism may involve nonmonotonicity and this is exactly what I find in a simple parametrized example, where the monotone difference condition fails for a set of parameter values. I begin, in Sect. 2, by discussing two important background results on implementability from the literature. The first concerns a sufficient condition for implementability: if allocations can be ordered in such a way that an allocation function is monotone and the agent’s values satisfy monotone differences, then the allocation function at hand is implementable. The second result is a characterization of implementability adapted from Carbajal and Ely (2013, Theorem 1) which is obtained by “integrating out” incentive constraints via the envelope theorem. This characterization also points towards a simple condition under which individual rationality follows from implementation even when payoffs are nonmonotone in types. I note this in Lemma 1. In Sect. 3, I analyze the example featuring a privately informed buyer with habits. For a range of habit parameters, the classical approach of Myerson (1981) can be used to construct an optimal mechanism by solving a virtual problem and checking that the solution satisfies incentive constraints. In fact this is feasible even for some (but not all) parameters which render the buyer’s value nonmonotone in his type. For all sufficiently large parameters, however, the solution to the virtual problem is not implementable. In this case, I solve an optimal pricing problem which I show to be equivalent to the optimal mechanism design problem, and show that as part of an optimal mechanism the seller screens out high as well as low types. This phenomenon occurs if the habit parameter is sufficiently large, i.e., if future disutility from current consumption is sufficiently high. There are other economic environments where the monotone differences condition fails because the agent’s values are nonmonotone in his type. I construct one such environment in the concluding section, where the agent’s value for an object is his expectation of an unobservable state conditional on his type, which is an informative signal. It turns out that for a class of joint densities for the state and the signal, the resulting conditional expectation is a nonmonotone function of the signal. 
Berger et al. (2010) contains an example of a nonmonotone mechanism which is implementable. It has also been noted that a mechanism design problem may be solved by nonmonotone mechanisms. With single dimensional types and multidimensional outcomes, Matthews and Moore (1987) shows that a dimension of the outcome may be nonmonotone at a seller-optimum. Focusing on the class of differentiable mechanisms, García (2005) provides conditions under which the optimal mechanism is nonmonotone when the outcome space is multidimensional. The application in this paper shows that a nonmonotone optimum may exist even when both the type space and the outcome space are single dimensional.",1
2.0,2.0,Economic Theory Bulletin,22 April 2014,https://link.springer.com/article/10.1007/s40505-014-0034-8,From preferences to Leontief utility,October 2014,Mark Voorneveld,,,Male,Unknown,Unknown,Male,"Together with the Cobb–Douglas utility function, the Leontief utility function is among the most commonly used in economics. It illustrates the case where commodities are perfect complements. Wassily Leontief, Laureate of the Nobel Memorial Prize in Economic Sciences in 1973, introduced its functional form in the early 1930s for a production function rather than a utility function (Leontief 1941; Dorfman 2008). His idea was as follows. Suppose that producing an output requires fixed proportions of its \(n\) inputs. One unit of output requires a vector \((\alpha _1, \ldots , \alpha _n)\) of inputs, with all \(\alpha _i > 0\). Given input vector \(x \in \mathbb {R}^n_+\), how much output can you produce? Well, looking at input \(i\), at most \(x_i/\alpha _i\) units. What constrains you are inputs \(i\) where this ratio is smallest: the maximal output is \(\min \{x_1/\alpha _1, \ldots , x_n/\alpha _n\}\) units, which is of the form (1) with \(a_i = 1/\alpha _i\). This functional form also provides the underpinnings of a number of theoretical constructs in the literature on technological efficiency, like Debreu’s coefficient of resource utilization, the Solow residual, and total factor productivity (TFP); ten Raa (2008) gives a recent overview of these three concepts and their relations.
 Instead of assuming that a utility function of a specific form exists, this note takes things one step back and derives Leontief utility functions from first principles: what properties of an economic agent’s preferences
\(\succsim \)
assure that they can be represented by a Leontief utility function?
 The crucial axiom is meet preservation (emphatically not ‘meat’ preservation, no matter what my apparently carni-industrially inclined spelling checker insists). It is a standard property borrowed from the literature on partially ordered sets and lattices (Birkhoff 1967; Davey and Priestley 1990); see Sect. 2 for details. The main results are: Theorem 3.1(a) shows that upper semicontinuity and meet preservation imply that upper contour sets have the familiar ‘L-shaped’ or ‘kinked’ form typical of Leontief-like preferences; see Fig. 1. Theorem 3.1(b) then characterizes preferences representable by Leontief utility functions, allowing some coordinates to be redundant. The axioms are shown to be logically independent in Sect. 4. As opposed to existing characterizations (Miyagishima 2010; Ninjbat 2012), Theorem 3.1 does not take the parameters \(a_i\) of the Leontief utility function (1) as given and use them explicitly in the axioms. Rather, the parameters are derived as consequences of the axioms; see the discussion in Sect. 5. Related literature is discussed in the final Sect. 5, where I can more easily appeal to my earlier notation and axioms. Indifference curves of utility function \(u: \mathbb {R}^2_+ \rightarrow \mathbb {R}\) with \(u(x) = \min \{x_1, 2x_2\}\)
",4
2.0,2.0,Economic Theory Bulletin,01 July 2014,https://link.springer.com/article/10.1007/s40505-014-0047-3,A characterization of stochastic dominance efficiency,October 2014,Haris Aziz,,,Male,Unknown,Unknown,Male,"Pareto optimality has been termed the “single most important tool of normative economic analysis” Moulin (2003). In this paper, we consider stochastic dominance (\(\mathrm {SD}\))-efficiency that is arguably the canonical generalization of Pareto optimality in randomized settings (Abdulkadiroğlu and Sönmez 2003; Aziz et al. 2013a; Bogomolnaia and Moulin 2001; Carroll 2010; Katta and Sethuraman 2006; McLennan 2002; Manea 2008). \(\mathrm {SD}\)-efficiency is efficiency with respect to the well-established SD lottery extension that extends preferences over alternatives to preferences over lotteries over alternatives. The relation \(\mathrm {SD}\) is fundamental because one lottery stochastically dominates another one if and only if the former yields at least as much expected utility as the latter for any von-Neumann-Morgenstern utility representation consistent with the ordinal preferences (see e.g., Cho 2012). \(\mathrm {SD}\)-efficiency was first used by Bogomolnaia and Moulin (2001)Footnote 1 and has received considerable interest within the domain of the random assignment problem in which agents express preferences over objects and the outcome is an assignment that assigns an object to each agent (Abdulkadiroğlu and Sönmez 2003; Bogomolnaia and Moulin 2001; Katta and Sethuraman 2006; McLennan 2002; Manea 2008). The random assignment setting is a subdomain of the randomized voting setting (see e.g., Aziz et al. 2013b; Carroll 2010; Gibbard 1977) in which each discrete assignment can be considered as an alternative and each agent is indifferent among all the discrete assignments in which he gets the same object. Characterization of \(\mathrm {SD}\)-efficiency has been an active area of research within economic theory. Bogomolnaia and Moulin (2001) and Katta and Sethuraman (2006) showed that a random assignment is \(\mathrm {SD}\)-efficient if and only if a certain binary relation between objects is acyclic. Abdulkadiroğlu and Sönmez (2003) presented another interesting characterization of SD-efficient assignments based on a concept of domination defined over sets of assignments. McLennan (2002), Manea (2008) and Athanassoglou (2011) characterized \(\mathrm {SD}\)-efficient assignments as ex-ante welfare maximizing for some vNM utilities compatible with the ordinal preferences. Carroll (2010) generalized the result to the setting of randomized social choice. In this paper, we present a new characterization of \(\mathrm {SD}\)-efficiency. We characterize \(\mathrm {SD}\)-efficiency in the general randomized social choice setting as a property of the support of the outcomes. As a corollary, we show that \(\mathrm {SD}\)-efficiency only depends on the support of the lottery and not the actual probabilities. In the charaterization, we show a formal connection between the \(\mathrm {SD}\) lottery extension and the responsive set extension.",
2.0,2.0,Economic Theory Bulletin,23 May 2014,https://link.springer.com/article/10.1007/s40505-014-0045-5,A note on the welfare of the maximin rational expectations,October 2014,Zhiwei Liu,,,Unknown,Unknown,Unknown,Unknown,,
2.0,2.0,Economic Theory Bulletin,08 April 2014,https://link.springer.com/article/10.1007/s40505-014-0033-9,A characterization of maximin: corrigendum,October 2014,Kaname Miyagishima,Kristof Bosmans,Erwin Ooghe,Female,Male,Male,Mix,,
3.0,1.0,Economic Theory Bulletin,22 August 2014,https://link.springer.com/article/10.1007/s40505-014-0055-3,Implementation of reduced form mechanisms: a simple approach and a new characterization,April 2015,Sergiu Hart,Philip J. Reny,,Male,Male,Unknown,Male,,15
3.0,1.0,Economic Theory Bulletin,12 June 2014,https://link.springer.com/article/10.1007/s40505-014-0046-4,Axiomatization of the discrete Raiffa solution,April 2015,Walter Trockel,,,Male,Unknown,Unknown,Male,,7
3.0,1.0,Economic Theory Bulletin,04 September 2014,https://link.springer.com/article/10.1007/s40505-014-0056-2,Utilitarianism on infinite utility streams: summable differences and finite averages,April 2015,Adam Jonsson,Mark Voorneveld,,Male,Male,Unknown,Male,,4
3.0,1.0,Economic Theory Bulletin,19 November 2014,https://link.springer.com/article/10.1007/s40505-014-0064-2,A remark on the continuity of the Walras correspondence in pure exchange economies,April 2015,Ram Sewak Dubey,Francesco Ruscitti,,Male,Male,Unknown,Male,,
3.0,1.0,Economic Theory Bulletin,26 February 2015,https://link.springer.com/article/10.1007/s40505-015-0070-z,Two characterizations of the random arrival rule,April 2015,Yan-An Hwang,,,,Unknown,Unknown,Mix,,
3.0,1.0,Economic Theory Bulletin,15 February 2015,https://link.springer.com/article/10.1007/s40505-015-0069-5,Equilibrium selection through \(\mathbf {p}_{u}\)-dominance,April 2015,Andrea Gallice,,,Female,Unknown,Unknown,Female,,
3.0,1.0,Economic Theory Bulletin,03 August 2014,https://link.springer.com/article/10.1007/s40505-014-0049-1,Multiple equilibria in asymmetric first-price auctions,April 2015,Todd R. Kaplan,Shmuel Zamir,,Male,Male,Unknown,Male,,6
3.0,1.0,Economic Theory Bulletin,23 April 2014,https://link.springer.com/article/10.1007/s40505-014-0038-4,Quantal response equilibrium in a double auction,April 2015,Claudia Neri,,,Female,Unknown,Unknown,Female,,3
3.0,1.0,Economic Theory Bulletin,27 November 2014,https://link.springer.com/article/10.1007/s40505-014-0062-4,Evolutionary dynamics and dominated strategies,April 2015,Yannick Viossat,,,Male,Unknown,Unknown,Male,,6
3.0,2.0,Economic Theory Bulletin,14 July 2014,https://link.springer.com/article/10.1007/s40505-014-0048-2,On the characterization of preference continuity by chains of sets,October 2015,Carlos Alós-Ferrer,Klaus Ritzberger,,Male,Male,Unknown,Male,,
3.0,2.0,Economic Theory Bulletin,29 May 2015,https://link.springer.com/article/10.1007/s40505-015-0073-9,A multiperiod Drèze rule,October 2015,Egbert Dierker,,,Male,Unknown,Unknown,Male,,
3.0,2.0,Economic Theory Bulletin,10 April 2014,https://link.springer.com/article/10.1007/s40505-014-0035-7,A search model with match makers,October 2015,Shigeru Makioka,,,Male,Unknown,Unknown,Male,,
3.0,2.0,Economic Theory Bulletin,29 April 2014,https://link.springer.com/article/10.1007/s40505-014-0039-3,On social welfare functions on infinite utility streams satisfying Hammond Equity and Weak Pareto axioms: a complete characterization,October 2015,Ram Sewak Dubey,Tapan Mitra,,Male,Male,Unknown,Male,,5
3.0,2.0,Economic Theory Bulletin,09 May 2014,https://link.springer.com/article/10.1007/s40505-014-0041-9,On equilibrium payoffs in wage bargaining with discount rates varying in time,October 2015,Agnieszka Rusinowska,Ahmet Ozkardas,,Female,Male,Unknown,Mix,,
3.0,2.0,Economic Theory Bulletin,14 May 2014,https://link.springer.com/article/10.1007/s40505-014-0042-8,Proximate preferences and almost full revelation in the Crawford–Sobel game,October 2015,Murali Agastya,Parimal Kanti Bag,Indranil Chakraborty,Unknown,,Unknown,Mix,,
3.0,2.0,Economic Theory Bulletin,20 May 2014,https://link.springer.com/article/10.1007/s40505-014-0043-7,Equity risk premium and insecure property rights,October 2015,Konstantin Magin,,,Male,Unknown,Unknown,Male,,
3.0,2.0,Economic Theory Bulletin,26 July 2014,https://link.springer.com/article/10.1007/s40505-014-0051-7,Changes in probability distributions and the form of compensation contracts,October 2015,Pierre Chaigneau,,,Male,Unknown,Unknown,Male,,
3.0,2.0,Economic Theory Bulletin,24 July 2014,https://link.springer.com/article/10.1007/s40505-014-0052-6,The law of one price in a modified strategic market game,October 2015,Nicholas Ziros,,,Male,Unknown,Unknown,Male,,
3.0,2.0,Economic Theory Bulletin,29 July 2014,https://link.springer.com/article/10.1007/s40505-014-0053-5,Transitive preferences in multi-member households,October 2015,Bart Smeulders,Laurens Cherchye,Fabrice Talla Nobibon,Male,Male,Male,Male,,3
3.0,2.0,Economic Theory Bulletin,13 August 2014,https://link.springer.com/article/10.1007/s40505-014-0054-4,A convergent transfer scheme based on the complement-associated game,October 2015,Yan-An Hwang,,,,Unknown,Unknown,Mix,,
3.0,2.0,Economic Theory Bulletin,25 September 2014,https://link.springer.com/article/10.1007/s40505-014-0057-1,A note on consequentialism in a dynamic Savage framework: a comment on Ghirardato (2002),October 2015,Joachim Hubmer,Franz Ostrizek,,Male,Male,Unknown,Male,,1
3.0,2.0,Economic Theory Bulletin,16 September 2014,https://link.springer.com/article/10.1007/s40505-014-0058-0,Recursive extension of a multicommodity analysis,October 2015,Katsutoshi Wakai,,,Male,Unknown,Unknown,Male,,
3.0,2.0,Economic Theory Bulletin,07 October 2014,https://link.springer.com/article/10.1007/s40505-014-0059-z,Ordinal dominance and risk aversion,October 2015,Bulat Gafarov,Bruno Salcedo,,Male,Male,Unknown,Male,,
3.0,2.0,Economic Theory Bulletin,17 October 2014,https://link.springer.com/article/10.1007/s40505-014-0060-6,Transitive supermajority rule relations,October 2015,Riste Gjorgjiev,Dimitrios Xefteris,,Male,Male,Unknown,Male,,
3.0,2.0,Economic Theory Bulletin,18 October 2014,https://link.springer.com/article/10.1007/s40505-014-0061-5,Testing stochastic rationality and predicting stochastic demand: the case of two goods,October 2015,Stefan Hoderlein,Jörg Stoye,,Male,Male,Unknown,Male,,10
3.0,2.0,Economic Theory Bulletin,20 November 2014,https://link.springer.com/article/10.1007/s40505-014-0063-3,Monopoly price discrimination with constant elasticity demand,October 2015,Iñaki Aguirre,Simon G. Cowan,,Male,Male,Unknown,Male,,1
3.0,2.0,Economic Theory Bulletin,04 December 2014,https://link.springer.com/article/10.1007/s40505-014-0065-1,When is voting optimal?,October 2015,Ruth Ben-Yashar,Leif Danziger,,Female,Male,Unknown,Mix,,
3.0,2.0,Economic Theory Bulletin,01 August 2014,https://link.springer.com/article/10.1007/s40505-014-0050-8,Ex post self-implementation,October 2015,Hideki Mizukami,Takuma Wakayama,,Male,Male,Unknown,Male,,2
4.0,1.0,Economic Theory Bulletin,09 December 2015,https://link.springer.com/article/10.1007/s40505-015-0087-3,Equilibrium in discontinuous games without complete or transitive preferences,April 2016,Philip J. Reny,,,Male,Unknown,Unknown,Male,,10
4.0,1.0,Economic Theory Bulletin,21 January 2016,https://link.springer.com/article/10.1007/s40505-015-0091-7,On the existence of price equilibrium in economies with excess demand functions,April 2016,Guoqiang Tian,,,Unknown,Unknown,Unknown,Unknown,,
4.0,1.0,Economic Theory Bulletin,19 September 2015,https://link.springer.com/article/10.1007/s40505-015-0081-9,Coalitional extreme desirability in finitely additive exchange economies,April 2016,Francesca Centrone,Anna Martellotti,,Female,Female,Unknown,Female,,3
4.0,1.0,Economic Theory Bulletin,07 February 2015,https://link.springer.com/article/10.1007/s40505-015-0067-7,A coalitional production economy with infinitely many indivisible commodities,April 2016,Takashi Suzuki,,,Male,Unknown,Unknown,Male,,2
4.0,1.0,Economic Theory Bulletin,24 September 2015,https://link.springer.com/article/10.1007/s40505-015-0080-x,Strategic and stable pollution with finite set of economic agents and a finite set of consumption commodities: a Pareto comparison,April 2016,Avishay Aiche,Hovav Perets,Benyamin Shitovitz,Male,Unknown,Male,Male,,
4.0,1.0,Economic Theory Bulletin,15 July 2015,https://link.springer.com/article/10.1007/s40505-015-0076-6,Cheap talk with an informed receiver,April 2016,Junichiro Ishida,Takashi Shimizu,,Male,Male,Unknown,Male,,13
4.0,1.0,Economic Theory Bulletin,07 May 2015,https://link.springer.com/article/10.1007/s40505-015-0072-x,Bertrand versus Cournot with convex variable costs,April 2016,Flavio Delbono,Luca Lambertini,,Male,Male,Unknown,Male,,9
4.0,1.0,Economic Theory Bulletin,08 February 2016,https://link.springer.com/article/10.1007/s40505-016-0094-z,Equivalence between graph-based and sequence-based extensive form games,April 2016,J. Jude Kline,Shravan Luckraz,,Unknown,Unknown,Unknown,Unknown,,
4.0,1.0,Economic Theory Bulletin,12 December 2015,https://link.springer.com/article/10.1007/s40505-015-0090-8,Strict Nash equilibria in non-atomic games with strict single crossing in players (or types) and actions,April 2016,Ennio Bilancini,Leonardo Boncinelli,,Male,Male,Unknown,Male,,3
4.0,1.0,Economic Theory Bulletin,01 October 2015,https://link.springer.com/article/10.1007/s40505-015-0082-8,Learning from arbitrage,April 2016,Lionel de Boisdeffre,,,Male,Unknown,Unknown,Male,,2
4.0,1.0,Economic Theory Bulletin,12 February 2015,https://link.springer.com/article/10.1007/s40505-015-0066-8,Correction to “A Strategy-proofness Characterization of Majority Rule”,April 2016,Donald E. Campbell,Jerry S. Kelly,,Male,Male,Unknown,Male,,6
4.0,2.0,Economic Theory Bulletin,17 February 2015,https://link.springer.com/article/10.1007/s40505-015-0068-6,Competing over a finite number of locations,October 2016,Matías Núñez,Marco Scarsini,,Male,Male,Unknown,Male,,5
4.0,2.0,Economic Theory Bulletin,07 May 2015,https://link.springer.com/article/10.1007/s40505-015-0071-y,Balanced contributions and fairness in exchange economies,October 2016,Gustavo Gudiño,,,Male,Unknown,Unknown,Male,,
4.0,2.0,Economic Theory Bulletin,15 June 2015,https://link.springer.com/article/10.1007/s40505-015-0074-8,Stability in price competition revisited,October 2016,Marta Faias,Javier Hervés-Estévez,Emma Moreno-García,Female,,Female,Mix,,
4.0,2.0,Economic Theory Bulletin,07 July 2015,https://link.springer.com/article/10.1007/s40505-015-0075-7,A global game with heterogenous priors,October 2016,Wolfgang Kuhle,,,Male,Unknown,Unknown,Male,,3
4.0,2.0,Economic Theory Bulletin,28 July 2015,https://link.springer.com/article/10.1007/s40505-015-0077-5,Generalising Bertrand competition: a special case of the Hotelling model,October 2016,Manzur Rashid,,,Male,Unknown,Unknown,Male,"In the classic Bertrand duopoly, firms split the market equally if and only if they offer exactly the same price. If one firm offers a price arbitrarily less than its competitor, it is able to sell to all of the consumers. This leads to fierce competition and marginal cost pricing in equilibrium. That firms make no profit in equilibrium is called the Bertrand paradox: it seems strange that the model only requires one additional firm in the marketplace to go from the monopoly outcome to an outcome which simulates perfect competition. In this paper I provide a natural extension of the Bertrand model where firms split the market equally if their prices are sufficiently close to one another; there is a unique symmetric equilibrium where firms earn positive expected profits. There are a number of papers which consider circumstances under which the Bertrand paradox disappears and firms earn positive profits in equilibrium. Baye and Morgan (1999) show that if the monopoly profit function is unbounded there exist positive profit equilibria. Dastidar (1995) shows that if firms have identical and strictly convex cost functions, positive profit equilibria exist even when the monopoly profit function is bounded. Baye and Morgan (2002) show that this result no longer holds under the ‘winner-takes-all’ tie-breaking rule. Baye and Kovenock (2008) show that with concave costs and a symmetric sharing rule, equilibria may not exist in either pure or mixed strategies. In my model, the monopoly profit function is bounded, firms have identical and constant marginal costs and the results are invariant to the choice of sharing rule. The only departure from the classic model is that the firms now tie if their prices are sufficiently close. Another classic model of competition is due to Hotelling (1929) where firms initially choose their location and then compete on price. The equilibrium price distributions in my model are precisely the mixed strategies which would be chosen by firms in the price-setting stage of the Hotelling model for a restricted class of (non-uniform) distributions of consumers.Footnote 1
 Finally, my model has an extremely simple sequential search interpretation where two firms simultaneously choose a price. These two prices {\(p_{1}\), \(p_{2}\)} form a known discrete distribution from which consumers can take costly draws without replacement. In this respect, my model is closest to Stiglitz (1987) who models sequential search (both with and without replacement) from a known discrete distribution by consumers who differ in their search costs. However, he does not characterise the actual pricing strategies that firms use in equilibrium. Stahl (1989) does derive the equilibrium distribution of prices; however, in his model consumers do not know the realised distribution of prices, they only know the mixed strategies firms use in equilibrium.Footnote 2 Furthermore, his model requires some consumers to have no search costs; otherwise, the equilibrium involves only monopoly pricing. Ever since Diamond (1971) showed that even small search costs can lead to monopoly pricing, one of the key issues the literature has struggled with is explaining how price dispersion for homogeneous goods can be an equilibrium phenomenon. This is important since without price dispersion there is no need for consumers to search. A nice feature of Stahl’s (1989) model is that as search costs increase, the distribution of prices smoothly increases from competitive to monopoly pricing—thus providing a bridge between the Bertrand paradox (zero profits) and the Diamond paradox (monopoly pricing). There is a similar effect in my model. Finally, in the unique equilibrium of my model, firms use mixed strategies, thus this extremely simple model is able to explain price dispersion without having to assume any heterogeneity of firms, consumers or goods.Footnote 3
",
4.0,2.0,Economic Theory Bulletin,20 August 2015,https://link.springer.com/article/10.1007/s40505-015-0078-4,Virtue and vice with endogenous preferences,October 2016,Nicholas Chesterley,,,Male,Unknown,Unknown,Male,,1
4.0,2.0,Economic Theory Bulletin,08 January 2016,https://link.springer.com/article/10.1007/s40505-015-0079-3,"Noncooperative games, coupling constraints, and partial efficiency",October 2016,Sjur Didrik Flåm,,,Male,Unknown,Unknown,Male,,6
4.0,2.0,Economic Theory Bulletin,27 September 2015,https://link.springer.com/article/10.1007/s40505-015-0083-7,A reformulation-based smooth path-following method for computing Nash equilibria,October 2016,Yin Chen,Chuangyin Dang,,,Unknown,Unknown,Mix,,
4.0,2.0,Economic Theory Bulletin,20 October 2015,https://link.springer.com/article/10.1007/s40505-015-0084-6,Endogenous lifetime and economic growth: the roleof the tax rate,October 2016,Laurent Brembilla,,,Male,Unknown,Unknown,Male,,2
4.0,2.0,Economic Theory Bulletin,19 October 2015,https://link.springer.com/article/10.1007/s40505-015-0085-5,Equilibrium existence in group contests,October 2016,Philip Brookins,Dmitry Ryvkin,,Male,Male,Unknown,Male,,11
4.0,2.0,Economic Theory Bulletin,27 November 2015,https://link.springer.com/article/10.1007/s40505-015-0086-4,Competition with price similarities,October 2016,Benjamin Bachi,,,Male,Unknown,Unknown,Male,,3
4.0,2.0,Economic Theory Bulletin,18 December 2015,https://link.springer.com/article/10.1007/s40505-015-0088-2,A class of individual expenditure functions,October 2016,Martina Menon,Elisa Pagani,Federico Perali,Female,Female,Male,Mix,,
4.0,2.0,Economic Theory Bulletin,23 December 2015,https://link.springer.com/article/10.1007/s40505-015-0089-1,A generalization of the AL method for fair allocation of indivisible objects,October 2016,Haris Aziz,,,Male,Unknown,Unknown,Male,,2
4.0,2.0,Economic Theory Bulletin,04 February 2016,https://link.springer.com/article/10.1007/s40505-016-0092-1,"Optimal performance reward, tax compliance and enforcement",October 2016,Christos Kotsogiannis,Konstantinos Serfes,,Male,Male,Unknown,Male,,1
4.0,2.0,Economic Theory Bulletin,29 March 2016,https://link.springer.com/article/10.1007/s40505-016-0096-x,"An alternative proof of Hardy, Littlewood, and Pólya’s (1929) necessary condition for majorization",October 2016,Oscar Volij,,,Male,Unknown,Unknown,Male,,
4.0,2.0,Economic Theory Bulletin,20 April 2016,https://link.springer.com/article/10.1007/s40505-016-0097-9,Separation of several convex sets,October 2016,Farhad Hüsseinov,,,Male,Unknown,Unknown,Male,,
4.0,2.0,Economic Theory Bulletin,25 April 2016,https://link.springer.com/article/10.1007/s40505-016-0098-8,An extensive form-based proof of the existence of sequential equilibrium,October 2016,Subir K. Chakrabarti,Iryna Topolyan,,Male,Female,Unknown,Mix,,
4.0,2.0,Economic Theory Bulletin,14 July 2016,https://link.springer.com/article/10.1007/s40505-016-0103-2,Rational expectations equilibria: existence and representation,October 2016,Anuj Bhowmik,Jiling Cao,,Unknown,Unknown,Unknown,Unknown,,
5.0,1.0,Economic Theory Bulletin,01 August 2016,https://link.springer.com/article/10.1007/s40505-016-0104-1,On the convergence of logit-response to (strict) Nash equilibria,April 2017,Carlos Alós-Ferrer,Nick Netzer,,Male,Male,Unknown,Male,,9
5.0,1.0,Economic Theory Bulletin,16 September 2016,https://link.springer.com/article/10.1007/s40505-016-0107-y,A folk theorem with codes of conduct and communication,April 2017,Juan I. Block,David K. Levine,,Male,Male,Unknown,Male,"In many economic environments people develop social norms or conventions when they regularly play familiar (or similar classes of) games, specifying behavior and choices everyone is expected to conform to. These social norms naturally endow people with the ability to commit, and this in turn allows the possibility that certain behavior can be visible to other people due to costs of choosing alternatives outside the conventional norm (see, for example, Schelling 1960; Frank 1988). Such consensus on behavior gives rise to the emergence of cooperation even when these economic relationships are not sustained in the long run, and therefore, not susceptible to future incentives. In this paper, we examine such situations where players employ codes of conduct which are defined as a complete specification of how they play and their opponents should play. Players also receive private signals about what code of conduct their opponents may be using, while their own code of conduct enables them to respond to these signals. We focus on the limit case of perfectly informative signals because we are interested in applications such as games played through agents whose codes of conduct determine their compensation schemes (the contracts players sign with their agents are observable), if the agent is human, or are embedded in their programming, if automated. We show a folk theorem for finite normal form games using simple trigger codes of conduct and under two observability assumptions. First, we make the relatively standard assumption that all players can observe their opponents’ codes of conduct as in many models of conditional commitment devices (see, for example, Tennenholtz 2004; Kalai et al. 2010). We demonstrate that our codes of conduct generalize the commitment device space described by Kalai et al. (2010) and we discuss how codes of conduct can be applied to, but are not restricted to computer algorithms (program equilibrium as described in Tennenholtz (2004)). These program strategies are self-referential in the sense that they take as input the opponents’ programs; then they syntactically compare them with its own description and execute an output strategy depending whether they are equal or not. Our main result, however, is for settings in which not all players can observe opponents’ codes of conduct. In large communities, for example, a group of people can be excluded from monitoring or have limited ability to screen whether other people would behave within the current convention. In general, it may be reasonable to assume that people have good information about whether a few people with whom they closely interact use the same code of conduct that they do, but not so reasonable that they would have this information about everyone in the community. However, we allow the possibility that people can communicate via cheap talk what they have observed about others. Specifically, we extend the idea of self-referential games to assume that after observing private signals about rivals’ codes of conduct players are allowed to send public “cheap talk” messages. Communication is per se costless but within the self-referential framework we show that it becomes a “signaling” device since the code of conduct includes the cheap talk messages, thereby players may receive different private signals depending on different message strategies. Although players choose strategically what to communicate, we show that there is an equilibrium in which players will reveal their private information truthfully. As a result, our key finding is that with public communication it is sufficient to get a folk theorem that every player is observed by at least two other players. The key feature that distinguishes our paper from conditional commitment device models is that our commitment device (code of conduct) is a function of signals rather than the opponents’ devices. The two most closely related papers are Tennenholtz (2004) and Kalai et al. (2010) in which agents commit to a particular behavior in response to their opponents’ device. By contrast, in our model the commitment device affects the likelihood of signals on which the other players would base their behavior; it requires an indirect connection between commitment and observation, thereby relying on a weaker observability assumption and expanding the number of applications our model can be used for. Our model encompasses Tennenholtz’s model of conditional commitment devices where players play through computer programs and receive as input their opponents’ program. Unlike Tennenholtz, we fully describe the space of codes of conduct and our folk theorem reaches efficiency. Similar to Kalai et al. (2010), we characterize the space of codes of conduct avoiding typical circularity problems, but in contrast to their model, we allow for mixed strategies, do not require the use of jointly controlled lotteries, and consider normal form games with more than two players. In their models, every player condition her play on all the other players’ devices, and their equilibrium construction breaks down if this observability assumption is not satisfied. Unlike these papers, our main focus is on situations where players are able to observe some opponents’ code of conduct, and we propose a theoretical approach for incorporating public communication via cheap talk messages into conditional commitment device models. More recently, attention has been drawn to noisy environments; Block and Levine (2015) examine players that observe imperfectly informative signals about each others’ codes of conduct, as Levine and Pesendorfer (2007) do within a evolutionary framework. Block and Levine (2015) prove a folk theorem for repeated games with private monitoring. How the period at which players receive signals about others’ codes of conduct affects the equilibrium payoff set was explored by Block (2013). In a much less noisy environment, Bachi et al. (2014) study games in which deceptive players may betray their true intentions. They show a folk theorem for two-player normal form games if the cost of deception is sufficiently low. By contrast, in our model these kinds of costs are embedded in the likelihood of private signals but could be readily incorporated. Although a leading example to motivate commitment in this literature is the idea of a communication phase before the actual play of the underlying game, to the best of our knowledge this is the first paper that incorporates explicitly such a communication round.",
5.0,1.0,Economic Theory Bulletin,05 February 2016,https://link.springer.com/article/10.1007/s40505-016-0093-0,Contracts in informed-principal problems with moral hazard,April 2017,Nicholas Charles Bedard,,,Male,Unknown,Unknown,Male,,3
5.0,1.0,Economic Theory Bulletin,02 March 2016,https://link.springer.com/article/10.1007/s40505-016-0095-y,Strongly rational sets for normal-form games,April 2017,Gilles Grandjean,Ana Mauleon,Vincent Vannetelbosch,Male,Female,Male,Mix,,
5.0,1.0,Economic Theory Bulletin,07 May 2016,https://link.springer.com/article/10.1007/s40505-016-0099-7,Disclosure of endogenous information,April 2017,Matthew Gentzkow,Emir Kamenica,,Male,Male,Unknown,Male,,22
5.0,1.0,Economic Theory Bulletin,30 June 2016,https://link.springer.com/article/10.1007/s40505-016-0101-4,A comment on mixed oligopoly spatial model: the non-uniform consumer distribution,April 2017,Jie Shuai,,,,Unknown,Unknown,Mix,,
5.0,1.0,Economic Theory Bulletin,09 July 2016,https://link.springer.com/article/10.1007/s40505-016-0102-3,Edgeworth box economies with multiple equilibria,April 2017,Alexis Akira Toda,Kieran James Walsh,,Male,Male,Unknown,Male,,15
5.0,1.0,Economic Theory Bulletin,05 August 2016,https://link.springer.com/article/10.1007/s40505-016-0105-0,Contracts and domination in incomplete markets: what is a true core?,April 2017,Valeriy M. Marakulin,,,Male,Unknown,Unknown,Male,,1
5.0,1.0,Economic Theory Bulletin,06 September 2016,https://link.springer.com/article/10.1007/s40505-016-0106-z,Maximal elements of quasi upper semicontinuous preorders on compact spaces,April 2017,Gianni Bosi,Magalì E. Zuanon,,Male,Unknown,Unknown,Male,,7
5.0,1.0,Economic Theory Bulletin,26 May 2016,https://link.springer.com/article/10.1007/s40505-016-0100-5,A remark on discontinuous games with asymmetric information and ambiguity,April 2017,Wei He,Nicholas C. Yannelis,,,Male,Unknown,Mix,,
5.0,2.0,Economic Theory Bulletin,18 April 2017,https://link.springer.com/article/10.1007/s40505-017-0118-3,Externalities in economies with endogenous sharing rules,October 2017,Philippe Bich,Rida Laraki,,Male,Male,Unknown,Male,,1
5.0,2.0,Economic Theory Bulletin,18 October 2016,https://link.springer.com/article/10.1007/s40505-016-0108-x,Pre-auction or post-auction qualification?,October 2017,Philippe Gillen,Vitali Gretschko,Alexander Rasch,Male,Male,Male,Male,,4
5.0,2.0,Economic Theory Bulletin,13 October 2016,https://link.springer.com/article/10.1007/s40505-016-0109-9,Risky rents,October 2017,Jean-Daniel Guigou,Bruno Lovat,Nicolas Treich,Unknown,Male,Male,Male,,3
5.0,2.0,Economic Theory Bulletin,19 October 2016,https://link.springer.com/article/10.1007/s40505-016-0110-3,Dynamic programming and behavioral rules,October 2017,Dale O. Stahl,,,,Unknown,Unknown,Mix,,
5.0,2.0,Economic Theory Bulletin,29 December 2016,https://link.springer.com/article/10.1007/s40505-016-0111-2,Uniqueness of the weights in Harsanyi-type theorems,October 2017,Massimiliano Amarante,,,Male,Unknown,Unknown,Male,,
5.0,2.0,Economic Theory Bulletin,16 January 2017,https://link.springer.com/article/10.1007/s40505-016-0112-1,Existence and uniqueness of equilibrium in Lucas’ asset pricing model when utility is unbounded,October 2017,João Brogueira,Fabian Schütze,,,Male,Unknown,Mix,,
5.0,2.0,Economic Theory Bulletin,23 February 2017,https://link.springer.com/article/10.1007/s40505-017-0113-8,Partially dominant choice with transitive preferences,October 2017,Dan Qin,,,Male,Unknown,Unknown,Male,,4
5.0,2.0,Economic Theory Bulletin,28 February 2017,https://link.springer.com/article/10.1007/s40505-017-0114-7,"Information, ambiguity and price equilibrium",October 2017,R. R. Routledge,,,Unknown,Unknown,Unknown,Unknown,,
5.0,2.0,Economic Theory Bulletin,17 March 2017,https://link.springer.com/article/10.1007/s40505-017-0115-6,"Employment lotteries, endogenous firm formation and the aspiration core",October 2017,Camelia Bejan,Juan Camilo Gómez,,Female,Male,Unknown,Mix,,
5.0,2.0,Economic Theory Bulletin,05 April 2017,https://link.springer.com/article/10.1007/s40505-017-0116-5,"A theory of organized crime, corruption and economic growth",October 2017,Keith Blackburn,Kyriakos C. Neanidis,Maria Paola Rana,Male,Male,Female,Mix,,
5.0,2.0,Economic Theory Bulletin,28 March 2017,https://link.springer.com/article/10.1007/s40505-017-0117-4,Assignment games with externalities revisited,October 2017,Jens Gudmundsson,Helga Habis,,Male,Female,Unknown,Mix,,
5.0,2.0,Economic Theory Bulletin,19 April 2017,https://link.springer.com/article/10.1007/s40505-017-0119-2,Replica core limit theorem for economies with satiation,October 2017,Hiromi Murakami,Ken Urai,,,Male,Unknown,Mix,,
6.0,1.0,Economic Theory Bulletin,18 September 2017,https://link.springer.com/article/10.1007/s40505-017-0129-0,On the ultrafilter representation of coalitionally strategy-proof social choice functions,April 2018,Surekha Rao,Achille Basile,K. P. S. Bhaskara Rao,Female,Male,Unknown,Mix,,
6.0,1.0,Economic Theory Bulletin,09 May 2017,https://link.springer.com/article/10.1007/s40505-017-0120-9,An agency relationship under general conditions of uncertainty: a game theory application to the doctor–patient interaction,April 2018,Dionysius Glycopantis,Charitini Stavropoulou,,Male,Female,Unknown,Mix,,
6.0,1.0,Economic Theory Bulletin,25 April 2017,https://link.springer.com/article/10.1007/s40505-017-0121-8,Weak maximal elements and weak equilibria in ordinal games with applications to exchange economies,April 2018,Vincenzo Scalzo,,,Male,Unknown,Unknown,Male,,1
6.0,1.0,Economic Theory Bulletin,28 April 2017,https://link.springer.com/article/10.1007/s40505-017-0122-7,Allocation of an indivisible object on the full preference domain: axiomatic characterizations,April 2018,C. Gizem Korpeoglu,,,Unknown,Unknown,Unknown,Unknown,,
6.0,1.0,Economic Theory Bulletin,15 June 2017,https://link.springer.com/article/10.1007/s40505-017-0123-6,Implementation with socially responsible agents,April 2018,Makoto Hagiwara,Hirofumi Yamamura,Takehiko Yamato,,Male,Male,Mix,,
6.0,1.0,Economic Theory Bulletin,19 July 2017,https://link.springer.com/article/10.1007/s40505-017-0124-5,Disclosing information to a loss-averse audience,April 2018,Xingyi Liu,,,Unknown,Unknown,Unknown,Unknown,,
6.0,1.0,Economic Theory Bulletin,11 September 2017,https://link.springer.com/article/10.1007/s40505-017-0125-4,A theory of managerial compensation and taxation with endogenous risk,April 2018,C. Gizem Korpeoglu,Stephen E. Spear,,Unknown,Male,Unknown,Male,"Economists have always been of two minds when it comes to modeling uncertainty. The earliest approach, which is called the “state-of-nature” (or Savage) approach, models the probabilities of possible outcomes as fixed and independent of agents’ actions. In the traditional models, it is reasonable to assume that output shocks are exogenous and independent of agents’ actions as agents take the states of the world given. However, the state-of-nature approach may be inadequate when a model considers settings in which agents’ actions intrinsically affect the state of the economy and hence the well-being or distress of firms and households in the economy. A good recent example of how agents’ actions affects the state of the economy is how the seizing up of the mortgage-backed securities market ended up freezing the world financial markets in 2008. In principle, bundling mortgages from different areas and different income profiles made a perfect sense as a way of diversifying the risk of a borrower defaulting on the mortgage. Packaging these up as securities to sell to large numbers of investors also further diversified the default risk. One drawback of the process, however, was the decoupling of loan origination from risk bearing. In a number of un- or under-regulated real estate markets, far too many so-called “sub-prime loans” were made to borrowers who clearly could not afford to carry the mortgage. This also generated an increase in housing values, which led a number of homeowners to increase consumption. When the inevitable defaults started and the housing price bubble deflated, credit markets ended up in panic, because no one knew what the various mortgage-backed securities were actually worth. Securitization of loans indeed reduced an individual bank’s risk exposure, but the collective actions of all banks (or bank managers) engaging in securitization resulted in a spectacular failure. Motivated by examples like the 2008 crisis, we study how endogenous shocks driven by collective actions of managers impact social welfare. In particular, we ask the following research questions: (Q1) do markets deliver a socially optimal allocation in the presence of endogenous shocks? (Q2) if not, how can the social planner implement a socially optimal allocation? Because managers’ actions may be unobservable, we examine how endogenous shocks impact social welfare under information asymmetry. Specifically, we ask: (Q3) how can the social planner implement a second-best allocation? To address these questions, we construct an overlapping-generations model with two-period-lived agents in which young agents serve as line workers/lower level employees, whereas old agents serve as managers. This is because we observe a natural division of labor across the age spectrum. For most established companies, top-tier managers are middle aged or older. For example, 87% of S&P 100 companies have CEOs older than 50 years, and for S&P 500 companies, median age of CEOs is 56, and average age of CEOs is 55 (cf. Spencer Stuart). This is because management activities are qualitatively different from even the most technically demanding production activities that firm engage in. Managers fundamentally work to maximize the probability of favorable outcomes (e.g., innovating new products) and minimize the probability of adverse outcomes (improving quality and safety of current products) in their firms’ production activities. This task necessitates a degree of comprehension of the overall structure and function of the firm that even very well-educated line workers typically do not have. Obtaining this knowledge requires a combination of early on-the-job training at entry level activities, typically followed by the attainment of an advanced degree (generally an MBA), and then another stint on the managerial career ladder learning the idiosyncrasies of the firm’s overall performance. Because this all takes time to accomplish, we see a natural division of labor across the age spectrum: young agents serve as line workers/lower level employees, while old agents serve as risk managers. In return for their service, young and old agents earn wages. Moreover, agents hold ownership shares of firms, i.e., equities. Before answering the research questions (Q1)–(Q3) listed above, we first prove the existence of a competitive equilibrium allocation (Proposition 1). We then prove that competitive equilibrium allocation is suboptimal in the presence of endogenous shocks driven by collective actions of managers (Proposition 2). The source of inefficiency is the externalities in managers’ wages and in equity market. These externalities must be internalized to restore efficiency. We establish that to attain a socially optimal allocation, the social planner must impose wage taxes (or subsidies) on managers and equity taxes (Theorem 1). Our results provide an alternative explanation as to why managers are compensated and taxed differently than other workers. We then extend the model by incorporating unobservable actions for managers and show that a second-best allocation can be implemented if the social planner imposes equity taxes (Proposition 3). This paper is broadly related to three streams of the literature: the overlapping generations, managerial compensation, and managerial taxation literature. The overlapping-generations literature has long been concerned about the optimality of competitive equilibrium under different settings. For example, Cass (1972) and Gale (1973) provide ways to determine whether competitive equilibrium is Pareto optimal. Peled (1982) and Chattopadhyay and Gottardi (1999) prove the optimality of competitive equilibrium in a pure-exchange economy, where agents live two periods. Demange (2002) gives a comprehensive characterization of different optimality notions for competitive equilibrium. We contribute to this literature by incorporating endogenous shocks and characterizing the equilibrium under endogenous shocks. Other streams of related literature are managerial compensation and taxation literature. Since Jensen and Meckling (1976), the managerial compensation literature focuses on the agency problem—in particular, managers do not necessarily act in the best interest of shareholders, so shareholders offer contracts to incentivize managers to maximize shareholder value (see Murphy 1999 for a comprehensive survey). The managerial taxation literature usually assumes that managers’ effort is private information, so the social planner pays informational rent to managers to extract that information (see Mankiw et al. 2009; Diamond and Saez 2011 for surveys).Footnote 1 Both managerial compensation and taxation literature derive impactful results and provide useful insights by considering information asymmetries. We contribute to these streams of the literature by identifying an alternative reason why managers are compensated and taxed differently than other workers using a model without information asymmetries. The closest study to this paper is a recent paper by Magill et al. (2015). Magill et al. (2015) show that firms must act in the best interest of all stakeholders, i.e., firms’ consumers, workers, and shareholders instead of only shareholders. This is because the firm faces endogenous shocks influenced by its investments, and these shocks create externalities on consumers and workers of the firm. Because of these externalities, the competitive equilibrium is suboptimal. The competitive equilibrium becomes Pareto optimal, however, if the firm adopts the stakeholder criterion, which takes into account shareholders as well as consumers and workers. In the present paper, shareholders of firms are also consumers and workers of firms, and yet, the competitive equilibrium is suboptimal, because endogenous shocks driven by collective actions of managers create externalities in managers’ wages and in the equity market. While Magill et al. (2015) consider a simple economy with a single firm, we consider a general economy with many firms competing on the product and labor markets. While Magill et al. (2015) argue that taxes cannot be used to internalize the externalities, because the firm’s investments are unobservable, we show that if managers’ actions are unobservable, equity taxes can internalize the externalities in the equity market, and hence, imposition of equity taxes makes Pareto improvements. The remainder of this paper is organized as follows. In Sect. 2, we elaborate on model ingredients and define competitive equilibrium. In Sect. 3, we analyze the existence and optimality of competitive equilibrium, managers’ wages, and taxes, and extend the model by incorporating information asymmetry. In Sect. 4, we conclude with a brief discussion. We present all proofs in Appendix.",
6.0,1.0,Economic Theory Bulletin,05 September 2017,https://link.springer.com/article/10.1007/s40505-017-0126-3,Perfectionism and willpower,April 2018,Daniele Pennesi,,,Female,Unknown,Unknown,Female,,
6.0,1.0,Economic Theory Bulletin,05 September 2017,https://link.springer.com/article/10.1007/s40505-017-0127-2,A “three-sentence proof” of Hansson’s theorem,April 2018,Henrik Petri,,,Male,Unknown,Unknown,Male,"Two extensively studied binary relations in economics are the Pareto order and the lexicographic order. It is a well-known fact that the latter relation is an ordering extension of the former. For instance, in Petri and Voorneveld (2016), an essential ingredient is Lemma 3.1, which roughly speaking requires the order under consideration to be an extension of the Pareto order. The main message of this short note is that some fundamental order extension theorems can be reduced to this basic fact. An advantage of the approach is that it seems less abstract than conventional proofs and hence may offer a pedagogical advantage in terms of exposition. Mandler (2015) gives an elegant proof of Spzilrajn’s theorem (1930) that stresses the importance of the lexicographic approach in proving ordering extension theorems. He shows that criteria can be built out of the relation \(\succ \) on the domain X in such a way that if the criteria are ordered lexicographically the corresponding relation extends \(\succ \). At a technical level the proof presented here is quite similar. We use a result from Evren and Ok (2011), that uses criteria defined in a similar way as in Mandler (2015). However, in terms of exposition we argue that our proof is easier. Another difference compared to Mandler (2015) is that he gives a proof of Szpilrajn’s theorem (1930), whereas this note presents a proof of Hansson’s theorem (1968). Of course given a proof of one of them the other follows quite easily, but we believe that our proof of Hansson’s theorem is easier to digest. Colloquially the proof in this note reads: “Every preorder is essentially a Pareto order and the lexicographic order extends the Pareto order. Since the lexicographic order is complete every preorder has an ordering extension”. We thus argue that abstract extension theorems of orders can be embodied in this simple principle. The note is organized as follows. Section 2 contains notation and preliminaries. In Sect. 3, we present our proof of Hansson’s theorem. Section 4 concludes. We gather some standard results in set theory in Appendix A.",2
6.0,1.0,Economic Theory Bulletin,08 September 2017,https://link.springer.com/article/10.1007/s40505-017-0128-1,Stationary inflation and Pareto efficiency with incomplete markets and a large open economy,April 2018,Matthew Hoelle,,,Male,Unknown,Unknown,Male,,
6.0,2.0,Economic Theory Bulletin,16 March 2018,https://link.springer.com/article/10.1007/s40505-018-0137-8,Costly state verification and truthtelling: a note on the theory of debt contracts,October 2018,Josef Schosser,Jochen Wilhelm,,Male,Male,Unknown,Male,,
6.0,2.0,Economic Theory Bulletin,04 November 2017,https://link.springer.com/article/10.1007/s40505-017-0130-7,Anchoring on Utopia: a generalization of the Kalai–Smorodinsky solution,October 2018,Carlos Alós-Ferrer,Jaume García-Segarra,Miguel Ginés-Vilar,Male,Male,Male,Male,,8
6.0,2.0,Economic Theory Bulletin,17 November 2017,https://link.springer.com/article/10.1007/s40505-017-0131-6,Reducing the dimensionality of a selfishly optimal nonlinear income tax problem,October 2018,Craig Brett,John A. Weymark,,Male,Male,Unknown,Male,,1
6.0,2.0,Economic Theory Bulletin,03 February 2018,https://link.springer.com/article/10.1007/s40505-018-0135-x,Initial shares can cause Pareto improvements when markets are incomplete,October 2018,Egbert Dierker,,,Male,Unknown,Unknown,Male,"This paper focuses on a single firm with constant returns to scale in a setting with incomplete markets, more than two time periods and a single good per state. Two different types of firms, partnerships and corporations, are compared; see §31 and §32 of Magill and Quinzii (1996), henceforth referred to as MQ. In the case of a partnership, a group of consumers gets together to found a firm. Because of constant returns to scale, there are no incentives to exclude a consumer. The main difference between partnerships and corporations is that the former have no initial owners, whereas the latter are initially owned by consumers. When the firm is organized as a partnership, the output price equals the cost and no profits accrue. In the case of a corporation, initial shares are exogenously allocated before markets open. Shares are traded at all non-terminal nodes and profits can have any sign. In the particular case of finance economies with only two periods, the first-order condition for constrained efficiency requires marginal cost pricing and there is no need for initial shares. The paper addresses the following question: Shall the firm in the multi-period case always be organized as a partnership or can initial shares help to improve efficiency and welfare? This question is studied from a purely normative perspective in a particularly simple and transparent model. The paper abstracts from all kinds of real life complications. In particular, there are no liability and bankruptcy problems, no competition and no strategic interaction. The only assets are shares in the firm. Moreover, every consumer participates in the firm and takes part in the firm’s decision problem. The objective of a firm used in this paper can be described most easily in the case of a corporation. In this case, social welfare maximization takes into account how the original shares impact market outcomes. When the initial shares are sold below costs, the net sellers of initial shares subsidize the net buyers. When the shares are sold above costs, the redistribution of wealth is reversed. In the case of a partnership, all market transactions leave the distribution of wealth unaltered. Under the assumption that every consumer holds at least a tiny amount of initial shares, the welfare of the initial owners coincides with the welfare of the society. Otherwise, the group of initial owners could exploit the rest of the economy. A corporation chooses, as in any Cournot model, an output vector. All functions used to analyze the model depend directly or indirectly on the firm’s output so that the independent variable can be dropped in the present introductory explanation. Consumers anticipate the market clearing prices correctly and determine their optimal trades on all markets. In equilibrium, all markets clear. It is well known that even very weak welfare requirements can be out of reach because of second-order effects. Therefore, a first-order approach is adopted to select production plans that are candidates for social welfare maximization. More precisely, production plans are sorted out whenever first-order welfare improvements are possible.Footnote 1
 In line with the usual definition of state prices or stochastic discount factors, every utility function is normalized such that the marginal utility of good 0 equals 1 in equilibrium. The (indirect) social welfare function \(\mathcal W\) is the sum of all normalized indirect utility functions. The corporation chooses its production plan such that the first-order condition for welfare maximization is satisfied. For a more extensive explanation, see Sect. 2. In the case of a partnership, the basic principle is the same. However, the firm must take the pricing constraint into account. The partnership aims to satisfy the first-order condition for constrained welfare maximization. It is worth emphasizing that the degree of complexity of multi-period models of production economies with incomplete markets comes close to that of models of Cournot competition. 
Gabszewicz and Vial (1972) introduce a model that combines Cournot-Nash competition with Walrasian exchange of consumption goods under the assumption that markets are complete. The basic idea can be described as follows: The consumption goods are produced by firms who need non-marketable primary factors as inputs. Every firm chooses its production plan. The consumers possess preassigned shares of the firms, provide the primary factors in accordance with their shares, and receive their shares of the firms’ output. Thereafter, Walrasian exchange of the consumption goods takes place at market clearing prices. The main difference between Gabszewicz and Vial (1972) and the present paper is that they focus on oligopolistic competition with complete markets, whereas this paper focuses on market incompleteness without oligopolistic competition. Both papers have in common that they deal with preassigned, initial shares. First, the production plans are chosen. Thereafter, the output is distributed and the consumers obtain their intermediate endowments. Finally, Walrasian exchange takes place and the intermediate endowments are traded at their equilibrium prices. In multi-period models of corporations, the exchange occurs repeatedly. Both papers deal with the redistribution of initial wealth, however, from different perspectives. Gabszewicz and Vial focus on the profit motive of oligopolists, whereas this papers abstracts from that motive and uses the possibility to redistribute wealth to enhance efficiency and welfare. 
Guesnerie (1975) points out that a redistribution of wealth can be needed to achieve a Pareto improvement when one leaves the classical Arrow–Debreu framework. In his paper, the aggregate production set fails to be convex and marginal cost pricing becomes a necessary requirement for Pareto efficiency. Several marginal cost pricing equilibria exist, however, none of them is Pareto efficient given the distribution of the firms’ profits or losses. To obtain a Pareto-efficient marginal cost pricing equilibrium, the original distribution scheme needs to be changed. According to the fundamental theorems of welfare economics, no such problem arises in the convex case. In the context of a standard GEI model with numéraire assets and a finite set of commodities at each of \(S+1\) spot markets, the connection between endowment redistribution and Pareto improvements has been investigated by Mendolicchio and Pietra (2016). The main goal of this paper is to present an example of a partnership equilibrium that is Pareto dominated by a corporation equilibrium of the same economy with suitably chosen initial shares.",1
6.0,2.0,Economic Theory Bulletin,23 March 2018,https://link.springer.com/article/10.1007/s40505-018-0139-6,The maximin equilibrium and the PBE under ambiguity,October 2018,Dionysius Glycopantis,Nicholas C. Yannelis,,Male,Male,Unknown,Male,,3
6.0,2.0,Economic Theory Bulletin,21 March 2018,https://link.springer.com/article/10.1007/s40505-018-0138-7,Robust trading mechanisms with budget surplus and partial trade,October 2018,Jesse A. Schwartz,Quan Wen,,Male,Male,Unknown,Male,,2
6.0,2.0,Economic Theory Bulletin,16 March 2018,https://link.springer.com/article/10.1007/s40505-018-0136-9,Deterministic versus stochastic contracts in a dynamic principal-agent model,October 2018,Thomas Mettral,,,Male,Unknown,Unknown,Male,,
6.0,2.0,Economic Theory Bulletin,05 January 2018,https://link.springer.com/article/10.1007/s40505-017-0134-3,Egalitarianism with a dash of fair efficiency,October 2018,Martin Van der Linden,,,Male,Unknown,Unknown,Male,,2
6.0,2.0,Economic Theory Bulletin,18 December 2017,https://link.springer.com/article/10.1007/s40505-017-0133-4,A note on interval delegation,October 2018,Manuel Amador,Kyle Bagwell,Alex Frankel,Male,,Male,Mix,,
6.0,2.0,Economic Theory Bulletin,25 November 2017,https://link.springer.com/article/10.1007/s40505-017-0132-5,A probabilistic aggregation rule for large societies,October 2018,Youcef Askoura,Antoine Billot,,Male,Male,Unknown,Male,,1
7.0,1.0,Economic Theory Bulletin,10 July 2018,https://link.springer.com/article/10.1007/s40505-018-0151-x,Economic and financial modeling techniques in the frequency domain,May 2019,Bart Taub,,,Male,Unknown,Unknown,Male,"In this report, I describe some frequency domain modeling techniques using a continuous time approach, with a highly abbreviated version of the model in Taub (2018) to motivate the technical elements. The main tools are the Laplace and Fourier transforms and the continuous-time analogue of the Wiener–Hopf equation. These tools are described in sections 6.A (pp. 216–220), 7.1–7.2 (pp. 221–228), and 7.A (262–264) of Kailath et al. (2000). An additional reference is Hansen et al. (1991).",2
7.0,1.0,Economic Theory Bulletin,23 March 2018,https://link.springer.com/article/10.1007/s40505-018-0140-0,Imperfect monitoring is necessary for essentiality of money,May 2019,Hiroki Fukai,,,Male,Unknown,Unknown,Male,,
7.0,1.0,Economic Theory Bulletin,28 March 2018,https://link.springer.com/article/10.1007/s40505-018-0141-z,Optimality of the uniform rule under single-peaked preferences,May 2019,Ruben Juarez,Jung S. You,,Male,,Unknown,Mix,,
7.0,1.0,Economic Theory Bulletin,03 April 2018,https://link.springer.com/article/10.1007/s40505-018-0142-y,On a class of smooth preferences,May 2019,Andrea Attar,Thomas Mariotti,François Salanié,Female,Male,Male,Mix,,
7.0,1.0,Economic Theory Bulletin,04 May 2018,https://link.springer.com/article/10.1007/s40505-018-0143-x,Revisiting stability in one-to-one matching problems,May 2019,Wouter Vergote,,,Male,Unknown,Unknown,Male,,1
7.0,1.0,Economic Theory Bulletin,03 May 2018,https://link.springer.com/article/10.1007/s40505-018-0144-9,Reference-dependent mechanism design,May 2019,Roland Eisenhuth,,,Male,Unknown,Unknown,Male,,17
7.0,1.0,Economic Theory Bulletin,03 May 2018,https://link.springer.com/article/10.1007/s40505-018-0145-8,Equilibrium existence in global games with general payoff structures,May 2019,Eric J. Hoffmann,Tarun Sabarwal,,Male,Male,Unknown,Male,,4
7.0,1.0,Economic Theory Bulletin,24 May 2018,https://link.springer.com/article/10.1007/s40505-018-0146-7,Fixed-point approaches to the proof of the Bondareva–Shapley Theorem,May 2019,Jean Guillaume Forand,Metin Uyanık,,Male,Male,Unknown,Male,,1
7.0,1.0,Economic Theory Bulletin,24 May 2018,https://link.springer.com/article/10.1007/s40505-018-0147-6,Recursive maxmin preferences and rectangular priors: a simple proof,May 2019,Massimiliano Amarante,Marciano Siniscalchi,,Male,Male,Unknown,Male,,4
7.0,1.0,Economic Theory Bulletin,08 June 2018,https://link.springer.com/article/10.1007/s40505-018-0148-5,Characterizing inequality benchmark incomes,May 2019,Laurence S. J. Roope,,,Female,Unknown,Unknown,Female,"A number of studies have considered how incremental increases in income, at specific points in the income distribution, impact inequality. Lambert and Lanza (2006) established that, for all Lorenz-consistent inequality indices, a benchmark income or position exists, above which adding increments of income increases inequality, and below which it decreases inequality. They went on to derive, for a variety of ‘relative’ inequality indices, explicit results on where these critical points in an income distribution lie.Footnote 1 Benchmark incomes/positions have also been derived for some ‘absolute’ measures (Corvalan 2014).Footnote 2 These benchmark incomes can be interpreted as social reference levels for inequality, somewhat analogous to poverty lines, above which increases to income increase inequality, and below which they decrease inequality. Knowledge of the location of such a point in the income distribution could be used, for example, to predict the impact on inequality of a subsidy to income at a particular point in the distribution. This note provides a theoretical foundation which embeds the concept of a benchmark income/position within a social preference framework. We assume a social preference ordering over all possible income distributions and impose intuitive ethical principles on the preference ordering. This gives rise to the existence of a benchmark income/position below which adding incremental income is socially desirable, and above which it is undesirable. The assumptions which ensure the existence of benchmark incomes/positions are sufficiently mild to guarantee that they must exist for virtually all inequality measures that have been proposed in the literature. The exact value of a critical point in a given income distribution will depend on the additional social preferences embodied by a given inequality measure, beyond those imposed in our axiomatic framework. The rest of the paper is organized as follows. Some notation and the basic framework are provided in Sect. 2. Examples of specific benchmark incomes/positions implied by several well-known inequality measures are provided in Sect. 3. The paper’s central results are derived in Sect. 4. Some concluding remarks are offered in Sect. 5. All proofs are deferred to the Appendices.",3
7.0,1.0,Economic Theory Bulletin,06 June 2018,https://link.springer.com/article/10.1007/s40505-018-0149-4,Continuous utility on connected separable topological spaces,May 2019,Yann Rébillé,,,Male,Unknown,Unknown,Male,,6
7.0,1.0,Economic Theory Bulletin,20 June 2018,https://link.springer.com/article/10.1007/s40505-018-0150-y,Demand for public good as a correspondence of cost shares,May 2019,A. van den Nouweland,,,Unknown,Unknown,Unknown,Unknown,,
7.0,2.0,Economic Theory Bulletin,08 November 2018,https://link.springer.com/article/10.1007/s40505-018-0159-2,Dominance-solvable multicriteria games with incomplete preferences,December 2019,Georgios Gerasimou,,,Male,Unknown,Unknown,Male,"This paper studies dominance solvability in multicriteria games, i.e. games in which the players’ payoffs are generally multidimensional or vector-valued. Such higher payoff dimensionality may be relevant, for example, when modeling firms that compete in prices for profits as well as market share (Bade 2005; Mármol et al. 2017) or in quantities under demand uncertainty (Caraballo et al. 2015). It is also relevant in the analysis of commons exploitation when players have equity considerations in addition to a payoff capturing their personal gains (Lejano and Ingram 2012). Other potential domains of application of such games are multi-product auctions, multi-issue voting and bargaining among altruistic players. The paper’s main motivation for studying dominance solvability in the general class of multicriteria games comes from noting that, owing to the often severe multiplicity of generalized Nash equilibria in such games (Shapley 1959), there appears to be a need for solution concepts that offer plausible equilibrium refinements. Such refinements would allow for increased predictive sharpness and, possibly, descriptive relevance within the context of this modeling apparatus. Potentially, they may also help towards making multicriteria games more “friendly” in the economic analysis of strategic interaction. A reasonable starting point in this endeavour is to turn to the influential notion of sophisticated equilibrium that was introduced in Moulin (1979, 1986) for standard real-payoff games. In that context, dominance solvability can lead the analyst to discard equilibria in which some player employs a strategy that is iteratively weakly dominated. Similar to Moulin’s work, the goal of this paper is to provide a solution concept that builds on a notion of generalized weak dominance which, whenever applicable, eliminates generalized equilibria in which some player’s strategy is iteratively dominated. To this end, the most direct generalization of weakly dominated strategies in the class of multicriteria games is considered first, requiring one strategy to dominate another for some player if it results in a weakly greater vector payoff against all opponent profiles and strictly so against some such profile. A notion of iterative dominance solvability that builds on this definition is then introduced, extending Moulin’s (1979) notion to the present environment. The paper’s main result is that finite multicriteria games that are dominance solvable in this sense are necessarily generalized equilibria. As such, it includes the main result in Moulin (1979) as a special case where all players’ payoffs are real-valued. A less demanding solution concept of iterative dominance that is based on the more general notion of partially dominated strategies is introduced next. A strategy is said to be partially dominated by another for some player, if there is no opponent strategy profile at which the former does better (in the vector-dominance sense) and at the same time there is some such profile where the latter does better. This can be thought of as a “reason-based” decision rule (see also Gerasimou 2016 for a related choice-theoretic analysis) that a possibly bounded-rational player in such an environment might employ to make strategic choices. It is shown by example, however, that, when applicable, the solution concept associated with this notion of dominance may fail to select a set of generalized equilibria.",6
7.0,2.0,Economic Theory Bulletin,30 June 2018,https://link.springer.com/article/10.1007/s40505-018-0152-9,Discriminatory auctions with resale,December 2019,Isa Hafalir,Musab Kurnaz,,Female,Unknown,Unknown,Female,,4
7.0,2.0,Economic Theory Bulletin,31 August 2018,https://link.springer.com/article/10.1007/s40505-018-0153-8,"Perception, utility, and evolution",December 2019,José F. Tudón M.,,,Male,Unknown,Unknown,Male,,
7.0,2.0,Economic Theory Bulletin,04 September 2018,https://link.springer.com/article/10.1007/s40505-018-0154-7,Monotonicity and qualified majority rules,December 2019,Uuganbaatar Ninjbat,,,Unknown,Unknown,Unknown,Unknown,,
7.0,2.0,Economic Theory Bulletin,05 September 2018,https://link.springer.com/article/10.1007/s40505-018-0155-6,On the properties of the nucleolus of a veto game,December 2019,Eric Bahel,,,Male,Unknown,Unknown,Male,,1
7.0,2.0,Economic Theory Bulletin,18 September 2018,https://link.springer.com/article/10.1007/s40505-018-0156-5,Game-theoretic optimal portfolios in continuous time,December 2019,Alex Garivaltis,,,Male,Unknown,Unknown,Male,,5
7.0,2.0,Economic Theory Bulletin,20 October 2018,https://link.springer.com/article/10.1007/s40505-018-0157-4,Equilibria in games with weak payoff externalities,December 2019,Takuya Iimura,Toshimasa Maruta,Takahiro Watanabe,Male,Male,Male,Male,,3
7.0,2.0,Economic Theory Bulletin,24 October 2018,https://link.springer.com/article/10.1007/s40505-018-0158-3,Transfer paradox in a stable equilibrium,December 2019,Ram Sewak Dubey,Minwook Kang,,Male,Unknown,Unknown,Male,,1
7.0,2.0,Economic Theory Bulletin,27 November 2018,https://link.springer.com/article/10.1007/s40505-018-0160-9,Divide-and-choose with nonmonotonic preferences,December 2019,Laurence Kranich,,,Female,Unknown,Unknown,Female,,
7.0,2.0,Economic Theory Bulletin,31 December 2018,https://link.springer.com/article/10.1007/s40505-018-00161-1,Monotonicity in optimal mechanisms in general quasi-linear environments with a continuum of types,December 2019,Yu Chen,,,,Unknown,Unknown,Mix,,
8.0,1.0,Economic Theory Bulletin,09 February 2019,https://link.springer.com/article/10.1007/s40505-019-00163-7,Self-enforcing cooperation via strategic investment,April 2020,H. Moulin,A. Seth,B. Taub,Unknown,Unknown,Unknown,Unknown,,
8.0,1.0,Economic Theory Bulletin,03 May 2019,https://link.springer.com/article/10.1007/s40505-019-00170-8,Two-person Bargaining with Lexicographic Preferences,April 2020,D. Glycopantis,,,Unknown,Unknown,Unknown,Unknown,,
8.0,1.0,Economic Theory Bulletin,11 January 2019,https://link.springer.com/article/10.1007/s40505-019-00162-8,Measuring gender segregation,April 2020,Diego C. Botassio,Rodolfo Hoffmann,,Male,Male,Unknown,Male,,
8.0,1.0,Economic Theory Bulletin,01 March 2019,https://link.springer.com/article/10.1007/s40505-019-00164-6,Nash welfarism and the distributive implications of informational constraints,April 2020,Yves Sprumont,,,Male,Unknown,Unknown,Male,,1
8.0,1.0,Economic Theory Bulletin,05 March 2019,https://link.springer.com/article/10.1007/s40505-019-00165-5,Downside risk-neutral probabilities,April 2020,Pierre Chaigneau,Louis Eeckhoudt,,Male,Male,Unknown,Male,,1
8.0,1.0,Economic Theory Bulletin,25 March 2019,https://link.springer.com/article/10.1007/s40505-019-00166-4,Differentiability of the value function and Euler equation in non-concave discrete-time stochastic dynamic programming,April 2020,Juan Pablo Rincón-Zapatero,,,Male,Unknown,Unknown,Male,,
8.0,1.0,Economic Theory Bulletin,30 April 2019,https://link.springer.com/article/10.1007/s40505-019-00167-3,"Stackelberg versus Cournot duopoly with asymmetric costs: primary markups, entry deterrence, and a comparison of social welfare and industry profits",April 2020,Jan Zouhar,Martina Zouharova,,Male,Female,Unknown,Mix,,
8.0,1.0,Economic Theory Bulletin,04 May 2019,https://link.springer.com/article/10.1007/s40505-019-00168-2,Compatibility of egalitarian equivalence and envy-freeness in a continuum-agent economy,April 2020,Susumu Cato,,,Male,Unknown,Unknown,Male,,
8.0,1.0,Economic Theory Bulletin,25 April 2019,https://link.springer.com/article/10.1007/s40505-019-00169-1,Best-reply sets,April 2020,Jonathan Weinstein,,,Male,Unknown,Unknown,Male,,1
8.0,1.0,Economic Theory Bulletin,10 June 2019,https://link.springer.com/article/10.1007/s40505-019-00171-7,A generalization of Peleg’s representation theorem on constant-sum weighted majority games,April 2020,Takayuki Oishi,,,Male,Unknown,Unknown,Male,,
8.0,1.0,Economic Theory Bulletin,11 June 2019,https://link.springer.com/article/10.1007/s40505-019-00172-6,Consistent Pareto improvement over the student-optimal stable mechanism,April 2020,Battal Doğan,M. Bumin Yenmez,,Male,Unknown,Unknown,Male,"The tradeoff between efficiency and stability has been a central question in the context of assigning students to schools following the pioneering work of Abdulkadiroğlu and Sönmez (2003). A matching is (Pareto) efficient if there is no other matching in which at least one student is better off and no student is worse off. Efficiency is attained, for example, by a serial dictatorship mechanism (Svensson 1999) or Gale’s top trading cycles mechanism (Shapley and Scarf 1974). On the other hand, stability requires that the matching is individually rational and there is no student–school pair who prefer each other to their current matches. The deferred acceptance algorithm (DA) of Gale and Shapley (1962) produces a stable matching. Furthermore, no mechanism can be both efficient and stable (Roth 1982). Kesten (2010) addresses the tradeoff between efficiency and stability by introducing EADAM, the Pareto of which improves over DA by allowing violation of some student priorities when these violations do not hurt the students.Footnote 1 Another desirable property of a mechanism is consistency (Thomson 1990), which states that when a group of students leaves the market with their assigned seats and the mechanism is applied to the reduced market, the assignment for the remaining agents should not change. Consistency can be thought of as a robustness check when students can trade their assigned seats using the same mechanism. It is known that DA is not consistent (Toda 2006; Afacan and Dur 2017). Our first result shows that no mechanism which Pareto improves over DA is consistent (Theorem 1). Since EADAM Pareto improves over DA, an implication of our result is that EADAM is not consistent (Corollary 1).Footnote 2 Next, we provide a weaker consistency property. Given a matching, we say that a school is underdemanded at the given matching if no student strictly prefers it to his assigned school—underdemanded in the sense that no student prefers those schools to his assigned school. Using this concept, we introduce the following weak consistency property of a mechanism. Run a mechanism for a given market. Consider a subset of the students who are assigned by this mechanism to schools that are underdemanded at the DA outcome. This mechanism is weakly consistent (w.r.t. DA) if removing these students with their assigned seats and applying the mechanism to the reduced market do not change the assignments of the remaining students.Footnote 3 We take DA as a benchmark and look for Pareto improvements. Since any school that is underdemanded at DA remains underdemanded at any Pareto improvement, and any student who is assigned to an underdemanded school at DA remains assigned to the same school at any Pareto improvement (Tang and Yu 2014, Lemma 1), the requirement that we only remove a set of students, each of whom is assigned to a school that is underdemanded at DA, makes sense, as these schools remain underdemanded for any mechanism that we consider. In other words, the match between a student and an underdemanded school at DA is an irrelevant match, since the same match happens at any Pareto improvement over DA, and such a mechanism should operate independently from these irrelevant matches. Let us call a mechanism a weakly consistent Pareto improvement over DA, if it Pareto improves over DA and is weakly consistent w.r.t. DA. Our main finding is that EADAM is the unique weakly consistent Pareto improvement over DA (Theorem 2). The proof that any weakly consistent Pareto improvement must be EADAM follows from a simplified definition of EADAM proposed by Tang and Yu (2014). They show that EADAM can be produced as follows: Run DA once and identify underdemanded schools. Make the matches of underdemanded schools permanent and remove them from the market with the assigned students. Rerun this procedure until all students and schools are matched. Furthermore, Kesten (2010) proves that EADAM Pareto improves over DA. The more difficult part of the proof is showing that EADAM satisfies weak consistency w.r.t. DA. By the definition of EADAM, it is easy to see that if all students who are assigned to underdemanded schools at DA are removed with their assigned seats, then the matching for the remaining students does not change. However, it is not clear whether the assignments of the remaining students will change if some of the students, in particular only one, who are assigned to underdemanded schools at DA are removed with their assigned seats, which we establish in Appendix A. One implication of Theorem 2 is that DA is not weakly consistent w.r.t. itself. Recently, EADAM has received attention in the literature (Dur et al. 2019; Troyan et al. 2018; Tang and Zhang 2017; Ehlers and Morrill 2017). These papers weaken stability and provide a different justification of EADAM. Instead, we introduce weak consistency and characterize EADAM as the unique weakly consistent Pareto improvement over DA. 
Kesten (2010), Abdulkadiroğlu et al. (2009), and Alva and Manjunath (2019) show that there is no strategy-proof Pareto improvement over DA. We also study Pareto improvement over DA but instead of imposing strategy-proofness, we impose weak consistency and identify EADAM as the unique mechanism with these properties. Other related literature includes Toda (2006), who characterizes the core of matching markets using consistency. Ergin (2002) shows that DA is consistent if, and only if, the capacity-priority structure satisfies acyclicity.Footnote 4 In another recent paper, Afacan and Dur (2017) show that no stable mechanism is consistent.",3
8.0,1.0,Economic Theory Bulletin,22 July 2019,https://link.springer.com/article/10.1007/s40505-019-00173-5,A semi-uniform-price auction for multiple objects,April 2020,Peyman Khezr,Flavio M. Menezes,,Male,Male,Unknown,Male,,2
8.0,1.0,Economic Theory Bulletin,31 July 2019,https://link.springer.com/article/10.1007/s40505-019-00174-4,On the consumer problem under an informational externality,April 2020,Marc Santugini,,,Male,Unknown,Unknown,Male,,
8.0,1.0,Economic Theory Bulletin,03 August 2019,https://link.springer.com/article/10.1007/s40505-019-00175-3,On the uniqueness of Nash equilibrium in discontinuous ordinal and normal form games,April 2020,Vincenzo Scalzo,,,Male,Unknown,Unknown,Male,,2
8.0,2.0,Economic Theory Bulletin,04 January 2020,https://link.springer.com/article/10.1007/s40505-019-00181-5,The Gale–Nikaido–Debreu lemma with discontinuous excess demand,October 2020,Bernard Cornet,,,Male,Unknown,Unknown,Male,,3
8.0,2.0,Economic Theory Bulletin,10 September 2019,https://link.springer.com/article/10.1007/s40505-019-00176-2,Job search costs and incentives,October 2020,Andriy Zapechelnyuk,Ro’i Zultan,,Male,Unknown,Unknown,Male,,
8.0,2.0,Economic Theory Bulletin,14 September 2019,https://link.springer.com/article/10.1007/s40505-019-00177-1,On trade in bilateral oligopolies with altruistic and spiteful agents,October 2020,M. Lombardi,S. Tonin,,Unknown,Unknown,Unknown,Unknown,,
8.0,2.0,Economic Theory Bulletin,25 September 2019,https://link.springer.com/article/10.1007/s40505-019-00178-0,Belief-consistent Pareto dominance,October 2020,Xiangyu Qu,,,Unknown,Unknown,Unknown,Unknown,,
8.0,2.0,Economic Theory Bulletin,02 November 2019,https://link.springer.com/article/10.1007/s40505-019-00179-z,On Machina’s paradoxes and limited attention,October 2020,Anastasia Burkovskaya,,,Female,Unknown,Unknown,Female,,1
8.0,2.0,Economic Theory Bulletin,15 November 2019,https://link.springer.com/article/10.1007/s40505-019-00180-6,Hicksian complementarity and perturbed utility models,October 2020,Roy Allen,John Rehbeck,,Male,Male,Unknown,Male,,5
8.0,2.0,Economic Theory Bulletin,24 March 2020,https://link.springer.com/article/10.1007/s40505-020-00182-9,The extrinsic value of low-denomination money holdings,October 2020,Allan Hernandez-Chanto,,,Male,Unknown,Unknown,Male,,
8.0,2.0,Economic Theory Bulletin,04 June 2020,https://link.springer.com/article/10.1007/s40505-020-00183-8,Reduced normal forms are not extensive forms,October 2020,Carlos Alós-Ferrer,Klaus Ritzberger,,Male,Male,Unknown,Male,,
8.0,2.0,Economic Theory Bulletin,16 June 2020,https://link.springer.com/article/10.1007/s40505-020-00184-7,On group strategyproof and optimal object allocation,October 2020,Conan Mukherjee,,,Male,Unknown,Unknown,Male,,2
8.0,2.0,Economic Theory Bulletin,19 June 2020,https://link.springer.com/article/10.1007/s40505-020-00185-6,Deadlines in the market for lemons,October 2020,Heng Liu,,,,Unknown,Unknown,Mix,,
8.0,2.0,Economic Theory Bulletin,06 July 2020,https://link.springer.com/article/10.1007/s40505-020-00186-5,Finite expected multi-utility representation,October 2020,Dino Borie,,,Male,Unknown,Unknown,Male,,1
8.0,2.0,Economic Theory Bulletin,08 July 2020,https://link.springer.com/article/10.1007/s40505-020-00187-4,Continuity and robustness of Bayesian equilibria in Tullock contests,October 2020,Ezra Einy,Diego Moreno,Aner Sela,Male,Male,Male,Male,,
8.0,2.0,Economic Theory Bulletin,10 July 2020,https://link.springer.com/article/10.1007/s40505-020-00188-3,Optimal Gerrymandering in a competitive environment,October 2020,John N. Friedman,Richard Holden,,Male,Male,Unknown,Male,,5
8.0,2.0,Economic Theory Bulletin,15 July 2020,https://link.springer.com/article/10.1007/s40505-020-00189-2,Topologies for the continuous representability of every nontotal weakly continuous preorder,October 2020,Gianni Bosi,Magalì Zuanon,,Male,Unknown,Unknown,Male,,1
9.0,1.0,Economic Theory Bulletin,23 November 2020,https://link.springer.com/article/10.1007/s40505-020-00195-4,Fritz John’s equation in mechanism design,April 2021,Alfred Galichon,,,Male,Unknown,Unknown,Male,,1
9.0,1.0,Economic Theory Bulletin,18 January 2021,https://link.springer.com/article/10.1007/s40505-020-00197-2,A simple sufficient condition for a unique and student-efficient stable matching in the college admissions problem,April 2021,Philip J. Reny,,,Male,Unknown,Unknown,Male,,3
9.0,1.0,Economic Theory Bulletin,18 August 2020,https://link.springer.com/article/10.1007/s40505-020-00191-8,\(\lambda \) envy-free pricing for impure public good,April 2021,Takuya Obara,Shuichi Tsugawa,Shunsuke Managi,Male,Male,Male,Male,,
9.0,1.0,Economic Theory Bulletin,25 August 2020,https://link.springer.com/article/10.1007/s40505-020-00190-9,Weak transitivity and agenda control for extended stepladder tournaments,April 2021,Yongjie Yang,Dinko Dimitrov,,Unknown,Male,Unknown,Male,,1
9.0,1.0,Economic Theory Bulletin,27 August 2020,https://link.springer.com/article/10.1007/s40505-020-00192-7,Costly force relocation in the Colonel Blotto game,April 2021,Brian Roberson,Oz Shy,,Male,Male,Unknown,Male,,1
9.0,1.0,Economic Theory Bulletin,27 August 2020,https://link.springer.com/article/10.1007/s40505-020-00193-6,On the insufficiency of some conditions for minimal product differentiation,April 2021,Kali P. Rath,Gongyun Zhao,,Female,Unknown,Unknown,Female,,1
9.0,1.0,Economic Theory Bulletin,17 September 2020,https://link.springer.com/article/10.1007/s40505-020-00194-5,On atom-swarming and Luce’s theorem for probabilistic beliefs,April 2021,Andrew Mackenzie,,,Male,Unknown,Unknown,Male,,
9.0,1.0,Economic Theory Bulletin,13 November 2020,https://link.springer.com/article/10.1007/s40505-020-00196-3,Can price dispersion be supported solely by information frictions?,April 2021,José Tudón,,,Male,Unknown,Unknown,Male,,
9.0,1.0,Economic Theory Bulletin,31 January 2021,https://link.springer.com/article/10.1007/s40505-021-00200-4,Comparative risk apportionment,April 2021,Paan Jindapon,Liqun Liu,William S. Neilson,Unknown,Unknown,Male,Male,,1
9.0,1.0,Economic Theory Bulletin,07 February 2021,https://link.springer.com/article/10.1007/s40505-021-00199-8,On the continuity of the feasible set mapping in optimal transport,April 2021,Mario Ghossoub,David Saunders,,Male,Male,Unknown,Male,,3
9.0,1.0,Economic Theory Bulletin,09 February 2021,https://link.springer.com/article/10.1007/s40505-021-00201-3,"Informed principal, moral hazard, and limited liability",April 2021,Teddy Mekonnen,,,Male,Unknown,Unknown,Male,,4
9.0,1.0,Economic Theory Bulletin,11 February 2021,https://link.springer.com/article/10.1007/s40505-020-00198-1,Duopoly price competition with limited capacity,April 2021,A. Bërdëllima,,,Unknown,Unknown,Unknown,Unknown,,
9.0,2.0,Economic Theory Bulletin,06 July 2021,https://link.springer.com/article/10.1007/s40505-021-00205-z,Fine cartels,October 2021,David K. Levine,,,Male,Unknown,Unknown,Male,,
9.0,2.0,Economic Theory Bulletin,21 August 2021,https://link.springer.com/article/10.1007/s40505-021-00208-w,Afriat and arbitrage,October 2021,Alan Beggs,,,Male,Unknown,Unknown,Male,,2
9.0,2.0,Economic Theory Bulletin,10 April 2021,https://link.springer.com/article/10.1007/s40505-021-00202-2,Stationary equilibrium in stochastic dynamic models: Semi-Markov strategies,October 2021,Subir K. Chakrabarti,,,Male,Unknown,Unknown,Male,,
9.0,2.0,Economic Theory Bulletin,12 April 2021,https://link.springer.com/article/10.1007/s40505-021-00203-1,Demand functions and demand manifolds,October 2021,Alan Beggs,,,Male,Unknown,Unknown,Male,,1
9.0,2.0,Economic Theory Bulletin,06 May 2021,https://link.springer.com/article/10.1007/s40505-021-00204-0,Evolution of conventions in games between behavioural rules,October 2021,Abhimanyu Khan,,,Unknown,Unknown,Unknown,Unknown,,
9.0,2.0,Economic Theory Bulletin,19 August 2021,https://link.springer.com/article/10.1007/s40505-021-00207-x,Wealth and income inequality in a monetary economy,October 2021,Yoichi Gokan,Stephen J. Turnovsky,,Male,Male,Unknown,Male,,2
9.0,2.0,Economic Theory Bulletin,17 August 2021,https://link.springer.com/article/10.1007/s40505-021-00209-9,Social discount rate: spaces for agreement,October 2021,Takashi Hayashi,Michele Lombardi,,Male,Female,Unknown,Mix,,
9.0,2.0,Economic Theory Bulletin,03 September 2021,https://link.springer.com/article/10.1007/s40505-021-00210-2,Core equivalence in collective-choice bargaining under minimal assumptions,October 2021,Tomohiko Kawamori,,,Male,Unknown,Unknown,Male,,
9.0,2.0,Economic Theory Bulletin,04 September 2021,https://link.springer.com/article/10.1007/s40505-021-00211-1,Reduced-form mechanism design and ex post fairness constraints,October 2021,Erya Yang,,,Unknown,Unknown,Unknown,Unknown,,
9.0,2.0,Economic Theory Bulletin,12 November 2021,https://link.springer.com/article/10.1007/s40505-021-00213-z,Correction to: Reduced-form mechanism design and ex post fairness constraints,October 2021,Erya Yang,,,Unknown,Unknown,Unknown,Unknown,,
9.0,2.0,Economic Theory Bulletin,23 October 2021,https://link.springer.com/article/10.1007/s40505-021-00212-0,Designing income distributions with specified inequalities,October 2021,Satya R. Chakravarty,Palash Sarkar,,Male,Unknown,Unknown,Male,,1
10.0,1.0,Economic Theory Bulletin,26 April 2022,https://link.springer.com/article/10.1007/s40505-022-00223-5,Existence of alpha-core allocations in economies with non-ordered and discontinuous preferences,May 2022,Vincenzo Scalzo,,,Male,Unknown,Unknown,Male,,2
10.0,1.0,Economic Theory Bulletin,15 March 2022,https://link.springer.com/article/10.1007/s40505-022-00216-4,The risk-neutral non-additive probability with market frictions,May 2022,Alain Chateauneuf,Bernard Cornet,,Male,Male,Unknown,Male,,2
10.0,1.0,Economic Theory Bulletin,29 November 2021,https://link.springer.com/article/10.1007/s40505-021-00215-x,Equilibrium existence in two-player contests without absolute continuity of information,May 2022,Ori Haimanko,,,Male,Unknown,Unknown,Male,,2
10.0,1.0,Economic Theory Bulletin,11 January 2022,https://link.springer.com/article/10.1007/s40505-021-00214-y,Impact of Information Concerning the Popularity of Candidates on Loss-Averse Voters’ Abstention,May 2022,Kohei Daido,Tomoya Tajika,,Male,Male,Unknown,Male,,1
10.0,1.0,Economic Theory Bulletin,22 March 2022,https://link.springer.com/article/10.1007/s40505-022-00218-2,Inequality minimising subsidy and taxation,May 2022,Satya R. Chakravarty,Palash Sarkar,,Male,Unknown,Unknown,Male,,
10.0,1.0,Economic Theory Bulletin,24 March 2022,https://link.springer.com/article/10.1007/s40505-022-00219-1,On the approximate purification of mixed strategies in games with infinite action sets,May 2022,Yuhki Hosoya,Chaowen Yu,,Unknown,Unknown,Unknown,Unknown,,
10.0,1.0,Economic Theory Bulletin,29 March 2022,https://link.springer.com/article/10.1007/s40505-022-00217-3,The fractional multidimensional knapsack problem: solution and uniqueness,May 2022,John Y. Zhu,,,Male,Unknown,Unknown,Male,,
10.0,1.0,Economic Theory Bulletin,11 April 2022,https://link.springer.com/article/10.1007/s40505-022-00220-8,Monotone comparative statics in the Calvert–Wittman model,May 2022,Francisco Rodríguez,Eduardo Zambrano,,Male,Male,Unknown,Male,,
10.0,1.0,Economic Theory Bulletin,29 April 2022,https://link.springer.com/article/10.1007/s40505-022-00221-7,Auctions with resale and risk aversion,May 2022,Sanyyam Khurana,,,Unknown,Unknown,Unknown,Unknown,,
10.0,1.0,Economic Theory Bulletin,09 May 2022,https://link.springer.com/article/10.1007/s40505-022-00222-6,Agglomeration triggered by the number of regions: a NEG model with a quadratic subutility function,May 2022,Kensuke Ohtake,,,Male,Unknown,Unknown,Male,,
10.0,1.0,Economic Theory Bulletin,19 May 2022,https://link.springer.com/article/10.1007/s40505-022-00224-4,Optimal licensing contracts with a downstream oligopoly: insider versus outsider innovation,May 2022,Tsung-Sheng Tsai,Cheng-Tai Wu,,Unknown,Unknown,Unknown,Unknown,,
10.0,1.0,Economic Theory Bulletin,06 September 2021,https://link.springer.com/article/10.1007/s40505-021-00206-y,Mixed strategy implementation under ambiguity,May 2022,Zhiwei Liu,Nicholas C. Yannelis,,Unknown,Male,Unknown,Male,,
10.0,2.0,Economic Theory Bulletin,21 May 2022,https://link.springer.com/article/10.1007/s40505-022-00225-3,The dual of Bertrand with homogenous products is Cournot with perfect complements,October 2022,Paolo Bertoletti,,,Male,Unknown,Unknown,Male,,
10.0,2.0,Economic Theory Bulletin,11 July 2022,https://link.springer.com/article/10.1007/s40505-022-00226-2,The minimal Hilbert basis of the Hammond order cone,October 2022,Ramses H. Abul Naga,,,Unknown,Unknown,Unknown,Unknown,,
10.0,2.0,Economic Theory Bulletin,21 July 2022,https://link.springer.com/article/10.1007/s40505-022-00227-1,More ambiguity aversion or more risk aversion?,October 2022,Jiankang Zhang,,,Unknown,Unknown,Unknown,Unknown,,
10.0,2.0,Economic Theory Bulletin,22 July 2022,https://link.springer.com/article/10.1007/s40505-022-00228-0,Continuity and sensitivity analysis of parameterized Nash games,October 2022,Zachary Feinstein,,,Male,Unknown,Unknown,Male,,2
10.0,2.0,Economic Theory Bulletin,24 August 2022,https://link.springer.com/article/10.1007/s40505-022-00229-z,Substitution and size effect for factor demand revisited,October 2022,Johannes Bröcker,Till Requate,,Male,Male,Unknown,Male,,
10.0,2.0,Economic Theory Bulletin,28 July 2022,https://link.springer.com/article/10.1007/s40505-022-00231-5,Is it reasonable to legalize tea money?,October 2022,Hideki Sato,,,Male,Unknown,Unknown,Male,,
10.0,2.0,Economic Theory Bulletin,30 July 2022,https://link.springer.com/article/10.1007/s40505-022-00232-4,Local stability constraints,October 2022,Esteban Peralta,,,Male,Unknown,Unknown,Male,,
10.0,2.0,Economic Theory Bulletin,08 September 2022,https://link.springer.com/article/10.1007/s40505-022-00233-3,Risky human capital accumulation with endogenous skill premium,October 2022,Karol Mazur,,,Male,Unknown,Unknown,Male,,
10.0,2.0,Economic Theory Bulletin,20 August 2022,https://link.springer.com/article/10.1007/s40505-022-00234-2,Revisiting the convergence theorem for competitive bidding in common value auctions,October 2022,Seewoo Lee,Jeong-Yoo Kim,,Unknown,Unknown,Unknown,Unknown,,
10.0,2.0,Economic Theory Bulletin,29 August 2022,https://link.springer.com/article/10.1007/s40505-022-00235-1,First-mover advantage reversals under passive cross forward ownership in vertically related markets,October 2022,Emmanuel Petrakis,Panagiotis Skartados,,Male,Male,Unknown,Male,,
10.0,2.0,Economic Theory Bulletin,03 September 2022,https://link.springer.com/article/10.1007/s40505-022-00236-0,‘What is important is seldom urgent and what is urgent is seldom important’: a study of the strategic implications of the urgency effect in a competitive setting,October 2022,Mauro Papi,,,Male,Unknown,Unknown,Male,,1
10.0,2.0,Economic Theory Bulletin,08 September 2022,https://link.springer.com/article/10.1007/s40505-022-00237-z,Memory retrieval and harshness of conflict in the hawk–dove game,October 2022,Ennio Bilancini,Leonardo Boncinelli,Eugenio Vicario,Male,Male,Male,Male,,
11.0,1.0,Economic Theory Bulletin,09 March 2023,https://link.springer.com/article/10.1007/s40505-023-00242-w,Generalization of the social coalitional equilibrium structure,April 2023,Ken Urai,Hiromi Murakami,Weiye Chen,Male,,Unknown,Mix,,
11.0,1.0,Economic Theory Bulletin,28 October 2022,https://link.springer.com/article/10.1007/s40505-022-00239-x,Core and stable sets of exchange economies with externalities,April 2023,Maria Gabriella Graziano,Claudia Meo,Nicholas C. Yannelis,Female,Female,Male,Mix,,
11.0,1.0,Economic Theory Bulletin,15 September 2022,https://link.springer.com/article/10.1007/s40505-022-00230-6,Stable Markov perfect equilibria in the asymmetric differential-game duopoly with a renewable resource,April 2023,Yuankan Huang,Takehiro Inohara,,Unknown,Male,Unknown,Male,,
11.0,1.0,Economic Theory Bulletin,22 October 2022,https://link.springer.com/article/10.1007/s40505-022-00238-y,Symmetric games with only asymmetric equilibria: examples with continuous payoff functions,April 2023,Shiran Rachmilevitch,,,Female,Unknown,Unknown,Female,,
11.0,1.0,Economic Theory Bulletin,29 November 2022,https://link.springer.com/article/10.1007/s40505-022-00240-4,Does vertical integration increase product quality?,April 2023,Sanxi Li,Xinyu Li,Zhan Qu,Unknown,Unknown,Male,Male,,1
11.0,1.0,Economic Theory Bulletin,24 January 2023,https://link.springer.com/article/10.1007/s40505-022-00241-3,Losses from cross-holdings in a duopoly with convex cost and strategic input price determination,April 2023,Arijit Mukherjee,,,Unknown,Unknown,Unknown,Unknown,,
11.0,1.0,Economic Theory Bulletin,08 February 2023,https://link.springer.com/article/10.1007/s40505-023-00243-9,Multivariate MRS functions and smooth preferences,April 2023,Norman L. Kleinberg,Barry K. Ma,,Male,Male,Unknown,Male,,
11.0,1.0,Economic Theory Bulletin,26 March 2023,https://link.springer.com/article/10.1007/s40505-023-00244-8,Strong dictatorship via ratio-scale measurable utilities: a simpler proof,April 2023,Jacob M. Nebel,,,Male,Unknown,Unknown,Male,,
11.0,1.0,Economic Theory Bulletin,17 March 2023,https://link.springer.com/article/10.1007/s40505-023-00245-7,Endogenous gender-based discrimination in a model of simultaneous frictional labor and marriage markets,April 2023,Roberto Bonilla,Adrian Masters,,Male,Male,Unknown,Male,,
11.0,1.0,Economic Theory Bulletin,12 April 2023,https://link.springer.com/article/10.1007/s40505-023-00246-6,Strategy-proofness in linear production economies with homothetic or quasi-linear preferences,April 2023,Wataru Ishida,,,Male,Unknown,Unknown,Male,,
11.0,1.0,Economic Theory Bulletin,25 April 2023,https://link.springer.com/article/10.1007/s40505-023-00247-5,Strategy-proofness implies minimal participation under single-peakedness,April 2023,Michael Müller,Clemens Puppe,,Male,Male,Unknown,Male,,
11.0,1.0,Economic Theory Bulletin,26 April 2023,https://link.springer.com/article/10.1007/s40505-023-00248-4,Directional monotone comparative statics in function spaces,April 2023,Uttiya Paul,Tarun Sabarwal,,Unknown,Male,Unknown,Male,,
