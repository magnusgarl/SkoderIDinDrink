Volume,Issue,Journal Name,Published Date,Link,Title,Journal Year,Author 1,Author 2,Author 3,Gender_Author 1,Gender_Author 2,Gender_Author 3,Article_Gender,Intro,Citations
1.0,1.0,Journal of Spatial Econometrics,17 November 2020,https://link.springer.com/article/10.1007/s43071-020-00007-8,Do spatial interactions fuel the climate-conflict vicious cycle? The case of the African continent,December 2020,Federica Cappelli,Caterina Conigliani,Giorgia Sforna,Female,Female,Female,Female,"Armed conflicts wreak disorder on economies and have devastating effects on development. According to Gates et al. (2012), about a quarter of the population of the developing world lives in conflict and post-conflict countries. During last decades, African countries have especially experienced many conflicts and civil wars. In addition, the continent also suffers from the challenges of poverty, limited education and health systems, food insecurity and, last but not least, the negative impacts of severe changes in climate conditions. Although climate change is a global threat, developing countries (DCs) and especially the African ones suffer the most due to their greater vulnerability to climatic factors (Moore and Diaz 2015).
 For these reasons, the African continent has been continuously put under the lens of empirical investigation of the climate-conflict nexus. Changes in temperature and rainfall patterns are estimated to affect a large share of population, influencing their lives and creating further incentives for violent attacks and armed conflicts in the near future (Dell et al. 2014; Miguel et al. 2004). Although the recent comprehensive review by Koubi (2019) covers numerous academic studies exploring the climate-conflict link, there is still debate on whether a change in weather conditions systematically increases conflict risk. To this purpose, Mach et al. (2019), through an expert-based analysis, find that low socio-economic development and capabilities are judged to be drivers substantially more influential than changes in climate conditions, which in turn are estimated to increase the risk of conflicts in the future on account of the uncertainty they present.
 Nonetheless, Buhaug (2015) and Ide et al. (2014) note that socio-economic factors, including the demographic pressure, the quality of institutions and political exclusion of ethnic groups, are not only direct drivers of conflicts but substantially influence also the impact of weather conditions on conflicts. The economic structure of countries, their poor institutional capacity, unequal income distribution, the scarcity of financial resources to implement adaptation measures and the consequent low resilience to extreme events and disasters contribute to the complexity of mechanisms behind the vicious cycle of violence (Burke et al. 2015; Hsiang et al. 2011). This complexity is well explained by the comprehensive concept of social vulnerability to climate change (Otto et al. 2017). Moreover, the uncertainty on the direction and relative magnitude of linkages between changes in weather conditions and conflicts is found to strongly depend on the plethora of different approaches in empirical design related to data collection with heterogeneous temporal, geographic, and social scales and the quantitative methods implemented (Ide 2017; Salehyan 2014), leaving space for further development in research design. In this paper we propose a quantitative approach that aims contributing to the debate in two aspects. First, we apply a dynamic spatial panel econometric analysis based on a Durbin model, which allows simultaneous consideration of driving factors of the geographic unit under scrutiny and those of the surrounding areas. As emphasised in Ide (2017), statistical analysis using sub-national data rarely account for the fact that climate-related conflicts do not necessarily take place where the effects of climate change are most severe. By using an original panel dataset for the entire African continent at a sub-national scale for the time span 1990–2016, the dynamic Durbin model is applied to a cell-based geographic detail corresponding to a grid of 3402 units of observation of 1° × 1° (corresponding to an area around 110 × 110 km). By including a wide range of cell-based and country-based socio-economic and weather variables, we can control for the socio-economic vulnerability of local areas to different ranges of influence (Auffhammer et al. 2013; Busby et al. 2014; Devlin and Hendrix 2014; Maystadt et al. 2015), exploiting the powerful instrument of spatial econometric interaction modelling (Arbia and Patuelli 2016; LeSage and Pace 2009). Given the nature of the vicious cycle of violence that is persistent over time and space, the adoption of a dynamic Durbin model allows jointly taking into account the effect of contagion at a global scale occurring all over the continent. Second, instead of confining the analysis to the occurrence or not of violence, we account for the total number of events defined as an armed conflict, where an event is counted if the conflict causes at least one death. The empirical estimation must be interpreted as the effects of the explanatory variables not only on the probability of a cell to be violent or not (as in the case of binary information) but also on the relative strength of violence if several episodes occur in the same place over the same year. This allows partly solving the shortcoming related to differences in conflict coding systems as emphasised by Selby (2014). Given that conflict datasets vary in their typologies and classifications, as well as in thresholds used to mark conflict onset, by simply changing the statistical source empirical results might change. The remainder of the article is organised as follows. In Sect. 2 we review main analytical methods developed by the literature in order to select variables to be included in the database and to choose the appropriate econometric technique. In Sect. 3 we describe the econometric methodology and the dataset. In Sect. 4 we comment on main results, while in Sect. 5 we discuss concluding remarks and offer future research lines.",3
1.0,1.0,Journal of Spatial Econometrics,23 October 2020,https://link.springer.com/article/10.1007/s43071-020-00005-w,Network dependence in multi-indexed data on international trade flows,December 2020,Manfred M. Fischer,James P. LeSage,,Male,Male,Unknown,Male,"In recent years fixed effects model specifications have enjoyed great popularity in the panel gravity literature as a way to take into account the specific three-dimensional nature of international trade flow data sets.Footnote 1 These models, differing in the specification of the fixed effects, focus on unobserved heterogeneity, but ignore any potential cross-sectional dependence due to network interactions. Faced with this problem, we propose a panel gravity model that examines multiple network interaction structures, using Bayesian model probabilities to determine those most consistent with the sample data. This is accomplished with the use of computationally efficient Markov Chain Monte Carlo (MCMC) estimation methods that produce a Monte Carlo integration estimate of the log-marginal likelihood that can be used for model comparison. Empirical international trade modeling has focused on multilateral resistance terms based on Anderson and van Wincoop (2003, 2004), which Feenstra (2002, 2004) argued could be proxied by inclusion of origin- and destination-specific fixed effects parameters in the model specification. Ranjan and Tobias (2007) model the effects parameters as a (semi-parametric) function of an exogenous variable measuring bilateral trade resistance between origin-destination dyads. Koch and LeSage (2015) make a convincing argument that all of these models relax multilateral aspects of the dependence structure in favor of bilateral dependence, or a specification based on heterogeneity rather than simultaneous/multilateral dependence. They argue this is important given Behrens et al. (2012) demonstration that model specifications that control for regional heterogeneity do not necessarily capture the full structure of interdependence between trade flows implied by theory. Behrens et al. (2012) derive a dual version of the Anderson and van Wincoop (2003) model using a model based on quantity competition that also implies a simultaneous structure of interdependence between observed trade flows. Koch and LeSage (2015) show how linearizing the system of nonlinear multilateral resistance relationships around a free trade world leads to a structured random effects interdependence structure that can be used as a Bayesian prior to produce statistical estimates of the inward and outward multilateral resistance indices. They argue their statistical approach has advantages over the non-stochastic numerical approach used by Anderson and van Wincoop (2003) to solve for the multilateral resistance indices. In contrast to the empirical trade literature, the regional science literature regarding modeling of flows between regions has placed more emphasis on use of spatial autoregressive models that include spatial lags of flows from regions neighboring the origin and destination, an idea promoted by LeSage and Pace (2008), who devote an entire chapter to these models in their book (LeSage and Pace 2009, Chapter 8). This paper extends this type of spatial autoregressive models to a panel data model setting. The literature discussed above did not deal with panel data models where we have a series of flow matrices covering numerous time periods, but rather more conventional gravity models consisting of a single flow matrix. In a panel data model setting, distance as well as sociocultural factors (which we can view as generalized distance variables) are generally time invariant, so they are treated as fixed effects. Balazsi et al. (2018) explore econometric implications of using a host of alternative multidimensional fixed effects in panel gravity models, but assume trade flows to be independent. We apply two of the more widely used multidimensional fixed effects transformations from the empirical trade literature to a panel of \(N=70\) countries trade flows covering the \(T=38\) years from 1963 to 2000, in a model specification that allows for the presence of simultaneous cross-sectional dependence. One approach uses N origin and N destination country fixed effects plus T time-specific effects proposed by Mátyás (1997) as an extension of the conventional fixed effects panel data model (e.g., Baltagi 2005) to the multidimensional situation that arises in the case of gravity models. These models take an \(N^2 T \times 1\) vector of dependent variables reflecting the matrix of trade flows between the N countries (assuming flows between all countries) at each time period, resulting in a dummy matrix of fixed effects with column rank of \(2N + T-2\). The second approach makes use of fixed effects proposed by Cheng and Wall (2005) that introduce fixed effects for origin-destination dyads as well as time periods, resulting in a dummy matrix with column rank of \(N^2 + T -1\), frequently adopted in the empirical trade literature. Apart from accommodating heterogeneity in flows using fixed effects, the dependent variable vector of \(N^2 \times 1\) trade flows for each time period are assumed to be independent, so flows between countries that have a common currency, language, membership in trade organizations, border or colonial ties are no more likely than flows between countries having nothing in common. Cross-sectional dependence in flows suggests that flows between countries with sociocultural similarity are likely to exhibit dependence as opposed to independence. We set forth a model specification that allows for this type of dependence in flows across the \(N^2 T\) country-time dyads, along with computationally efficient MCMC estimation methods.Footnote 2 The nature of dependence that we model would be better labeled network dependence rather than spatial or cross-sectional dependence, because we introduce dependence between network nodes involving origin- and destination-dyads as well as covariance across these. We use the terms network and cross-sectional dependence interchangeably, but note that the network dependence specification introduced here reflects a special case of cross-sectional dependence that can arise in the case of origin-destination flows that has not received a great deal of attention in the literature. An innovative aspect of our MCMC estimation approach is use of Metropolis-Hastings guided samples from the joint posterior distribution of the dependence parameters to construct a Monte Carlo integration estimate of the log-marginal likelihood useful for model comparison. The MCMC estimation approach allows for estimation and posterior inference on a vector of dependence parameters that determines the relative importance of network dependence. In our case, we rely on Markov Chain Monte Carlo sampling to estimate the model parameters with the dependence parameters sampled using a Metropolis-Hastings procedure. Since this approach produces draws of the dependence parameters that are steered by Metropolis-Hastings accept/reject decisions to areas of high density of the joint posterior, we can produce an efficient Monte Carlo integration of the log-marginal likelihood.Footnote 3 Another methodological innovation is use of multiple network interaction structures constructed to reflect spatial proximity between countries, as well as numerous types of sociocultural proximity such as common currency, language, colonial ties, and so on. An equally weighted combination of these multiple weight matrices is used to form a single weight matrix. This approach allows us to treat sociocultural factors as sources of network dependence in the panel gravity model. The remainder of this paper is organized as follows. Section 2 outlines conventional panel gravity models as used in the empirical trade literature, along with a discussion of the two multidimensional fixed effects specifications that we explore.Footnote 4 Section 3 introduces network dependence in a conventional multidimensional fixed effects model specification, and describes the prior setup of the MCMC estimation approach. Section 4 sets forth computational challenges to estimation along with MCMC procedures to overcome these challenges. Section 5 applies our model to panel data on trade flows between 70 countries covering the 38 years from 1963 to 2000. In the application of the model we consider combinations of multiple sociocultural connectivity structures, that can be used in conjunction with log-marginal likelihood estimates to determine the relative importance of each type of connectivity. We find strong evidence of network dependence in trade flows pointing to network spillover effects, and suggesting that ignoring the presence of this type of cross-sectional dependence will result in biased estimates from conventional trade flow model specifications. Section 6 concludes the article and a technical appendix provides further details on the MCMC estimation approach.",3
1.0,1.0,Journal of Spatial Econometrics,30 July 2020,https://link.springer.com/article/10.1007/s43071-020-00003-y,Specification tests for spatial panel data models,December 2020,Anil K. Bera,Osman Doğan,Monalisa Sen,Male,Male,Female,Mix,,
1.0,1.0,Journal of Spatial Econometrics,26 June 2020,https://link.springer.com/article/10.1007/s43071-020-00002-z,Asymptotic properties of a spatial autoregressive stochastic frontier model,December 2020,Fei Jin,Lung-fei Lee,,,Unknown,Unknown,Mix,,
1.0,1.0,Journal of Spatial Econometrics,03 February 2020,https://link.springer.com/article/10.1007/s43071-020-0001-4,GMM identification and estimation of peer effects in a system of simultaneous equations,December 2020,Xiaodong Liu,,,Unknown,Unknown,Unknown,Unknown,,
2.0,1.0,Journal of Spatial Econometrics,02 November 2021,https://link.springer.com/article/10.1007/s43071-021-00017-0,Spatial autoregressive models for scan statistic,December 2021,Mohamed-Salem Ahmed,Lionel Cucala,Michaël Genin,Unknown,Male,Male,Male,"In many fields of science, cluster detection methods are useful tools for objectively identifying aggregations of events in time and/or space and for determining their statistical significance. See Lawson and Denison (2002) for a thorough review. Over the last few decades, several cluster detection methods have been developed. In particular, scan statistics are powerful methods to detect clusters in a one-dimensional or multidimensional space with a variable size scanning window and then test the clusters’ statistical significance (see Glaz et al. (2001, 2009) for a review). These methods are widely used in many fields such as epidemiology ( Luquero et al. 2011; Genin et al. 2020), genetics ( Ott and Hoh 2012) or economics ( Páez et al. 2002; Chasco et al. 2020). In the field of spatial econometrics, a particular case of scan statistics, namely two-dimensional scan statistics, are particularly relevant to identify geographical areas with abnormally high or low values of the dependent variable under study. Although the origins of two-dimensional scan statistics can be found in chapter 3 of Sir Ronald Fisher’s book ( Fisher 1959), the first mathematical formalizations were proposed by Naus ( Naus 1965). Arbia (1990) suggested to use scan statistics to study the spatial non-stationarity of the first and second moments of a random field. Moreover, Arbia (2014), stated that non-parametric techniques such as locally weighted regression (LWR, introduced by Cleveland and Devlin (1988)) can be seen as a scan method because they perform a regression around a point by exploiting the information carried out by the neighboring points. More recently, Lee et al. (2017) proposed a combination of scan statistics and geographically weighted regression techniques that can be considered as a special case of LWR (Brunsdon et al. 1996, 2007; Fotheringham et al. 1998, 2003). A special case of two-dimensional scan statistics, called spatial scan statistics, has been proposed by Kulldorff for spatial count data ( Kulldorff 1997). These methods use a circular scan window of variable size to identify, without pre-selection bias, spatial clusters and test their statistical significance. Following on from Kulldorff’s initial work, several researchers have adapted spatial scan statistics to continuous spatial data. Many of them use a parametric approach and specify the distribution of the data: exponential ( Huang et al. 2007), normal ( Kulldorff et al. 2009; Huang et al. 2009), Weibull ( Bhatt and Tiwari 2014), ... Others use a nonparametric approach based on moments ( Cucala 2014) or ranks ( Jung and Cho 2015). A common assumption in the literature of spatial scan statistics is that spatial data is composed of independent observations, for reasons of model simplicity. However, spatial data are usually characterized by the notion of spatial correlation, which makes the previous hypothesis too simplistic and inadequate. Particularly, it is reasonable to expect some positive correlation between nearby locations in epidemiological or environmental studies ( Cressie 1993). For instance, it is not surprising to say that the air quality in a given location depends on those measured in neighboring sites. Additionally, one can imagine that there is some pollution source which is behind the diffusion. Hence, the fact that spatial sites near this source are more polluted than those further away could be due solely to the effect of spatial correlation. Thus, in such situations, it is important that spatial scan statistics detect only the source of pollution and not a larger spatial cluster characterized by a strong positive spatial correlation. We note that this consists in identifying both first-order moments, i.e. the heterogeneity, and second-order moments, i.e. the spatial correlation structure, and this is subject to difficulties ( Ripley 1981). In the literature, a small number of studies ( Loh and Zhu 2007; Lin 2014; Lee et al. 2019) have focused on taking spatial correlation into account within spatial scan statistical methods and studying their behaviour in this situation. For instance, Loh and Zhu (2007) showed in theoretical as well as practical point of view that ignoring the spatial correlation leads to an increased rate of false positive: “the classical spatial scan statistic identifies too many clusters when overdispersion or spatial correlation is present”. Briefly, these works proposed modified spatial scan statistics allowing to integrate residual spatial correlation present in the data. Residual spatial correlation is principally due to spatial heterogeneity or omission of some spatial correlated latent variables that are related to the study but not included in the data (omission of some spatial correlated confounding factor). The reader may refer to Chapter 2 in (LeSage and Pace 2009) for more discussion about the different kinds of spatial dependence. However, these previous studies do not allow the spatial correlation to be taken into account when studying contagious phenomena, such as infectious diseases, which are usually characterized by a spatial correlation affecting the dependent variable of interest. In this paper, we focused on continuous spatial data in which the spatial correlation is integrated into the dependent variable using spatial autoregressive models (SAR). SAR models were introduced by Cliff and Ord (1973) and are usually used in the literature of spatial econometrics (see Sect. 2.1 in LeSage and Pace 2009). By combining Jung (2009)’s approach, expressing spatial scan statistics in terms of generalized linear models, with SAR models, we integrate the spatial correlation in the proposed SAR scan statistics through a known spatial weights matrix and an unknown scalar named the spatial autoregressive parameter. The latter allows to control the intensity of the spatial correlation while the spatial weights matrix allows to describe the spatial interactions between locations. We showed that the SAR scan statistic is equivalent to using a conventional spatial scan statistic after adjusting the initial dependent variable for spatial correlation. Firstly, we developed some estimation procedure to build the spatial autoregressive parameter based on a quasi-maximum likelihood (QML) method proposed by Lee (2004). Secondly, we used this QML estimator to construct some transformation of the initial dependent variable removing the effect of spatial correlation. Finally, as the new transformed dependent variable satisfies the independence assumption of classical spatial scan statistics, we suggest to use the Gaussian-based spatial scan statistic proposed by Kulldorff et al. (2009) in case of normally distributed initial data and the distribution-free scan statistic proposed by Cucala (2014) otherwise. The present article is organized as follows. Section 2 describes the methodology of the classical spatial scan statistic, the two proposed SAR models and presents an estimation procedure of the spatial autoregressive parameter. Section 3 presents both the design and the results of a simulation study. In Sect. 4 we apply the SAR scan statistics to economic data and the detection of clusters of high and low income in the city of Paris. Lastly, the results are discussed in Sect. 5.",1
2.0,1.0,Journal of Spatial Econometrics,11 October 2021,https://link.springer.com/article/10.1007/s43071-021-00016-1,Revisiting estimation methods for spatial econometric interaction models,December 2021,Lukas Dargel,,,Male,Unknown,Unknown,Male,"Spatial interaction models are a mathematical representation of interaction behavior between entities located at an origin and a destination. They are widely applied to explain and predict, for example, passenger-flows between airports, trade or migration flows between countries, and flows of customers from residential areas to stores. The most famous spatial interaction model is the gravity model, which is originally inspired by Newton’s law of universal gravitation. The gravity model states that the attraction between an origin and a destination increases as their masses increase and the distance between them decreases. Young (1924) was among the first to use a simple gravity model to explain migration flows of the agricultural population between farms. Since then, the gravity model has been continuously refined and has become one of the most popular econometric models used across industries and scientific disciplines. Initially, the success of the gravity model has been solely attributed to its excellent agreement with the data in empirical applications. However, by taking a macro perspective of interactions between cities or countries, it lacked a solid theoretical underpinning. Wilson (1967) addressed this problem by showing that the gravity equation can be derived from the behavior of individual actors. An overview of various ways to ground the gravity equation in economic theory is provided by Anderson (2011). The theoretical underpinning increased the recognition of the model in academic circles, but Curry (1972) raised another type of criticism when she showed that the distance parameter is not estimated consistently by ordinary least-squares (OLS) estimation. This would only be possible if the flows were independent, an assumption that is rather unrealistic as many flows start from the same origin or go to the same destination. Moreover, an increasing number of studies report significant spatial dependence in origin-destination (OD) flows (see for example Porojan 2001; Lee and Pace 2005; Chun et al. 2012; Kerkman et al. 2017; Margaretic et al. 2017). Ignoring spatial dependence in such cases would compromise the estimation of all parameters (Anselin 1988) and different strategies have emerged to address spatial correlation of OD flows (for a recent overview see Oshan 2020). LeSage and Pace (2008) account for spatial dependence in gravity type models using a spatial econometric approach. In general, spatial econometric models relax the independence assumption by allowing observations to influence their neighbors, where the neighborhood structure is defined by spatial weight matrices. These weight matrices typically reflect geographic proximity and allow to compute spatial lags that contain information on the average value of a variable in the neighborhood around a location. The spatial lag (LAG) model includes a lag of the dependent variable and using additional lags of the explanatory variables leads to the so-called spatial Durbin model (SDM). A great overview on different types of spatial econometric models is provided by Elhorst (2010). Apart from exceptional cases (see Lee 2002) the LAG and SDM model cannot be estimated consistently by OLS and much effort has been devoted to the development of alternative estimation procedures, such as MLE (Ord 1975; Anselin 1988), S2SLS estimation (Kelejian and Prucha 1998), or Bayesian MCMC (LeSage 1997). Due to the lack of an analytical solution for the MLE and Bayesian estimators, their computation can be very costly, and a large strand of the literature is devoted to improvements that bring down these estimation cost. Usually, the S2SLS is presented as a more efficient alternative, but this must be qualified for spatial interaction models whose double spatial index amplifies the computational challenges for two reasons: The number of OD pairs \(N = n^2\) grows quadratically with the number of origins and destinations, increasing problems related to the dimension of the data. The double index also complicates the definition of a geographical neighborhood, as a flow might be influenced by the neighbors of the origin, the destination, or both. To model this neighborhood structure LeSage and Pace (2008) use three spatial weight matrices, which augments the number of instruments used for the S2SLS estimator. This article presents computational techniques that allow to efficiently estimate the spatial econometric interaction model of LeSage and Pace (2008). While the expositions regarding the MLE and the Bayesian MCMC estimators constitute refinements of existing methods, the detailed implementation of the S2SLS estimator of this model is novel in the literature. The guiding principle of the improvements is a reformulation of the three estimation procedures in terms of low-dimensional moment matrices that need to be computed only once prior to the estimation. Consequently, the computation cost becomes, up to the calculation of these moments, independent of the sample size. In fact, this idea can be generalized to all spatial econometric models that use gaussian residuals, but it is especially efficient for spatial interaction models whose OD structure allows to represent the model in a matrix formulation. Using this matrix formulation, which was introduced by LeSage and Pace (2008), we obtain most elements of the required moments using \({\mathcal {O}}(\sqrt{N})\) instead \({\mathcal {O}}(N)\) computations. For the moment based MLE we derive a simple restructuring of the quadratic term in the likelihood function and a generalization of the mixed numerical analytical Hessian estimator (see LeSage and Pace 2009) to spatial models with multiple weight matrices. The improved Bayesian MCMC estimator is the one of LeSage and Pace (2009), with an adjusted sampling procedure that expresses all sampling steps in terms of low-dimensional moments. To improve the performance of the S2SLS estimator, we develop its matrix formulation and also address multicollinearity problems of the spatial instruments. One source of these problems is the OD structure of the data, while another one is related to the fact that the SDM model already includes spatial lags of the covariates. Hence, solutions to the second type of problem also apply outside the context of OD flows. Regarding the feasible parameter space, we develop a new method that allows to verify the coherence of the model and does not substantially increase the computational cost of the estimation. To facilitate the adoption of the model, all estimators presented in this article are implemented in the R package spflow.Footnote 1 These contributions should help to establish spatial econometric interaction models as a standard approach to modeling origin-destination flows. Failing to make this model operational implies that spatial dependence continues to be ignored in many studies, which may have severe consequences. Kerkman et al. (2017), for example, point out that omitted spatial autocorrelation might be a reason for the systematic overestimation of the effects of policy interventions in the public transport sector. Section 2 introduces the model and the matrix formulation. Section 3 discusses the issue of defining the feasible parameter space. Section 4 details the improved calculation procedures for the three estimators and Section 5 presents benchmarks of these methods. In Section 6, all estimators and the new parameter space solutions are illustrated based on the example of home-to-work commuting flows between the municipalities of Paris. The final section concludes.",
2.0,1.0,Journal of Spatial Econometrics,12 September 2021,https://link.springer.com/article/10.1007/s43071-021-00015-2,Fast estimation of matrix exponential spatial models,December 2021,Ye Yang,Osman Doğan,Süleyman Taşpınar,,Male,Male,Mix,,
2.0,1.0,Journal of Spatial Econometrics,20 August 2021,https://link.springer.com/article/10.1007/s43071-021-00014-3,Indirect effects and causal inference: reconsidering regression discontinuity,December 2021,Gary Cornwall,Beau Sauley,,Male,Male,Unknown,Male,"Regression discontinuity (RD) design has, over the previous two decades, become a mainstay of the empirical economics research toolbox (see Lee and Lemieux 2010 for a survey). Due to the difficulty, both in cost and ethical considerations, of randomized control trials (RCTs) economists have turned to this quasi-experimental design method to better understand the [causal] impacts of policy changes. First introduced by Thistlethwaite and Campbell (1960), RD has been used to identify the effect of passing school levies on new residential construction (Brasington 2017), school-board composition on student segregation (Macartney and Singleton 2017), implementation of gifted or high achieving classrooms on minority student achievement (Card and Giuliano 2016), traffic congestion following a cessation of public transit services (Anderson 2014), and class size on student achievement (Angrist and Lavy 1999), among many other topics. Peer effects, that is the impact changing one’s own characteristics has on neighboring outcomes, is quickly becoming a topic of great interest with respect to causal inference (Athey and Imbens 2017; Kolak and Anselin 2020). The importance of these indirect effects is made clear through violations of the no-interference assumption (see Imbens and Rubin 2015 for a discussion) which is critical to the potential outcome framework commonly used in economic literature. This paper reconsiders RD design when this assumption is not satisfied, yielding indirect effects in addition to the traditionally measured direct effects. RD exploits the common use of pre-specified treatment rules which are linked—through a threshold of eligibility—to some continuous measurement (running variable) in order to estimate the direct effect of treatment.Footnote 1 Since agents cannot precisely control, or manipulate, their relative position around the threshold they can be thought of as pseudo-randomized. This randomization produces—at least in theory—comparison groups which differ in expectation only with respect to the treatment effect (Rubin 1978). The RD framework has been shown to provide close approximations to RCT results in many cases (Cook and Wong 2008) and thus has become omnipresent in applied economics literature. Examples of continuous measurements used in determining eligibility for treatment include: vote share (Hainmueller and Kern 2008; Pettersson-Lidbom 2008; Eggers et al. 2015), test scores and academic ability (Thistlethwaite and Campbell 1960; Van der Klaauw 2002; Jacob and Lefgren 2004), and poverty rates (Ludwig and Miller 2007; Meng 2013), among others. While the RD framework has turned into a nearly ubiquitous structure from which to draw causal statements it is not without its weaknesses; particularly the cross-sectional dependence commonly found in spatial and network models. It is well known that, in the face of such cross-sectional dependence, parameter estimates are potentially both biased and inefficient (Anselin 1988; LeSage and Pace 2009; Pace et al. 2011). Additionally, it has been shown that common responses to this dependence, e.g. fixed effects and/or clustered standard errors, can exacerbate model misspecification issues including bias, efficiency, and spuriousness of results (Anselin and Arribas-Bel 2013). The primary issue with these types of models in an RD context is a clear violation of the no-interference assumption which underlies much of the potential outcome framework upon which RD is based. In this paper we extend the local-linear RD to a generalized network RD framework—one which nests both network and non-network base specifications as a special case—using a combination of Bayesian sampling methods, residualization, and numeric integration. Following LeSage and Pace (2017) we use a Monte Carlo study to show the resulting model specification produces estimates with lower bias and mean-square-error (MSE) relative to its peers, even in the nested, network free case. Moreover, the approach contained herein allows for a full examination of both partial and cross-partial derivatives common to both spatial and network models (LeSage and Pace 2009). These cross-partial derivatives, known as indirect effects, can be sizable depending on the strength of cross-sectional dependence. In a standard RD framework it is assumed that these cross-partial derivatives are equal to zero and that the total and direct effects of the treatment are equal. Put bluntly, this assumption prohibits the treatment from spilling over to other treated or non-treated units (see Kolak and Anselin 2020 for a discussion). While this may be a suitable assumption in some limited RCT settings—especially those with strict compliance protocols—in a quasi-experimental framework it is overly restrictive. Let us abstract away from the RD framework for a moment in an effort to build some intuition. Consider the following example: we have a class of students who are scheduled to take an exam. We would like to know what impact, if any a tutor would have on the students’ final scores. One way this can be done is to randomize which students get access to the treatment; the tutor in this example. As the students enter the classroom we might flip a fair coin and assign a tutor to all students who flip heads. For simplicity assume these tutors are homogeneous in their quality and that the treated students fully comply with the tutor and the tutor’s methods. After the exam we compare the scores of treated and non-treated students to estimate the average treatment effect (ATE). Is the ATE measuring only the effect of tutors on test scores? Given the information outlined above, the answer is no. Cross-sectional dependence is introduced through a number of channels, though the most obvious in retrospect is the students ability to cheat off of one another. An untreated student’s test score, in the presence of cheating, depends upon the test score of the treated and untreated students who sat next to him, a violation of the no-interference assumption. In addition to cheating, students may also form outside study groups comprised of both treated and untreated students. The interaction within these groups confers some of the benefits from the tutor on those that were not selected for treatment. The first channel is a relatively easy one to fix, we could just produce a different exam for every student and thus prevent them from cheating. Alternatively we could have students take the exam in isolation.Footnote 2 The second channel is a bit harder to deal with though it is not clear we would want to prevent it. Students studying is a good thing! How does our RCT example, flawed as it may be, shed light on the issue of cross-sectional dependence in quasi-experimental frameworks such as RD? The data we use in RDs are not collected in an RCT setting. As a result, we may not know which cross-sectional dependence inducing channels have been closed. For example, instead of assigning treatment through a random mechanism we could assign the services of a tutor based upon a student’s previous test score with some cutoff denoting eligibility. Any value drawn at or below the cutoff is treated while any above the cutoff is untreated. This is a classic RD setup in which we could examine, within a certain bandwidth, students around the cutoff and calculate a local average treatment effect (LATE). The assumption of course being that students one point below the cut-off are the same as those one point above the cut-off in all aspects other than the treatment. Without knowing if the aforementioned channels have been closed (e.g. Did the professor randomize exams?) we have left ourselves open to bias, inefficiency, and potential spurious results by assuming those channels had been closed. Moreover, as is often the case, we may be evaluating the impact of tutors specifically so that we can make a policy recommendation on public subsidy of tutors. If we do not fully account for the cross-sectional dependence we may overstate (or understate—depending on the direction of the indirect effects) the effectiveness of tutors on test scores, recommending a subsidy which is too large (or too small) and thus create inefficiencies in public financing. One can think of a number of situations in which we would expect cross-sectional dependence to exist in causal studies. First, consider the significant evidence pointing to strong cross-sectional dependence in housing markets (Kim and Goldsmith 2009; Bin et al. 2011; Mihaescu and vom Hofe 2012; Wong et al. 2013; Lazrak et al. 2014; vom Hofe et al. 2019) where prices are dependent not only upon the characteristics of one’s own home, but also the price and characteristics of neighboring homes. It follows then that any treatment which affects the price of homes would have an effect on surrounding (treated and untreated homes). Hidano et al. (2015) use an RD framework to examine how buyers in Tokyo evaluate seismic risk via the price premium on the property. They are able to show that properties in a low-risk zone are at a price premium relative to those that are outside of the low-risk zone. While their work acknowledges the presence of cross-sectional dependence, and utilizes a spatial hedonic model in the form of Kelejian and Prucha (1998, 1999) to support their main conclusions, they do not incorporate the dependence into the RD framework itself and admit “...accounting for such cross-sectional interactions in a quasi-experimental framework is challenging and an interesting topic for future research (p. 121)”. A similar example comes in the form of Moulton et al. (2016) which examines the benefits of targeted property tax relief measures in Virginia, using an RD framework, and finds that increased demand stemming from the measure lead to a 5% increase in home values. Again, acknowledging the possibility of these cross-sectional interactions, they employ a spatial fixed effects specification as a robustness check. Second, and perhaps more well known to most applied economists, is the use of RD to tease out measures of incumbency advantage. Several studies have shown that vote share in the current election is positively impacted by close wins, as measured by margin of victory, in previous elections (see Lee and Lemieux 2010; Chib and Greenberg 2014; Cattaneo et al. 2015 for example). Meanwhile, there is evidence that voting exhibits positive cross-sectional dependence and thus would be exposed to indirect effects (Kim et al. 2003; Cho and Rudolph 2008; Cutts and Webber 2010; Lacombe et al. 2014). We can think of several channels by which this cross-sectional dependence may manifest. First, while elections are district specific, the local media coverage area my overlap with multiple districts either in part or whole. Political advertisements would thus have an impact over multiple constituencies, even if those advertisements are for a particular candidate. Moreover, get out the vote initiatives by local political parties may cross district boundaries as they push for voter turnout in the area more generally rather than in a specific district. This is particularly relevant in situations where several tiers of government may be having simultaneous elections (e.g. House and Senate races). We find it interesting that use of RD in this context has become a bit controversial as researchers question if the basic assumptions of RD are being met in the aforementioned studies (see Caughey and Sekhon 2011; Eggers et al. 2015; De la Cuesta and Imai 2016 for a discussion). Yet, none of these criticisms take into account the potential for cross-sectional dependence which would violate the Stable Unit Treatment Value Assumption (Rosenbaum and Rubin 1983). By generalizing the RD framework we are able to overcome some of these limitations. We limit our generalization to the local-linear framework for two reasons. First, recent research has shown that RD models using higher-order polynomials (e.g. third or fourth degree) in the running variable produce poor results in practice with noisy point estimates and confidence intervals with ill defined coverage Gelman and Imbens (2018). Second, and perhaps more importantly, we find that interval construction in the local-linear method has a simple, clean form in a Bayesian context with bandwidth selection—though important for identification purposes—playing a marginal role. Since the distribution of the dependence parameter is of unknown form, we utilize numeric integration to include uncertainty about both initial parameters and the bandwidth in our estimate of the local average treatment effect (LATE). In each iteration we are recalculating the bandwidth based on our uncertainty about the residualization parameters. This creates a frontier of marginal observations which move in and out of the estimation sample throughout the algorithm. For computational efficiency we limit ourselves to bandwidth calculations as outlined by Imbens and Kalyanaraman (2012), although in our empirical example we relax this requirement and show bandwidth is not particularly relevant in that context. Finally, we illustrate this new model specification using the now canonical example of close elections in the U.S. House of Representatives (Lee 2008; Imbens and Kalyanaraman 2012; Calonico et al. 2014). We show that U.S. House districts are in fact spatially correlated and that this correlation impacts the estimates in a material way. Our results show that close wins in a district during time t leads to an increase in vote share at time \(t+1\) of approximately \(15\%\) with roughly \(9\%\) attributable to the direct effects of treatment on the treated, and approximately \(6\%\) the result of indirect effects. Original work by Lee (2008) and follow up work by Caughey and Sekhon (2011) yield estimates of a direct effect between \(7\%\) and \(9\%\) depending on the specification. Possible mechanisms which would produce the indirect effects include a shift in ad-buying resources, increased voter turnout following a nearby win, and voter migration. These dimensions are not captured in the data so channels by which the indirect effects manifest themselves are speculative. The remainder of this paper is organized as follows. Section 2 outlines the proposed model specification including interpretation of the resulting parameter(s). Section 3 includes a Monte Carlo study to examine the properties of the proposed specification. In Sect. 4 we contextualize the generalized RD framework using close elections in the U.S. House of Representatives. Finally, Sect. 5 concludes and offers avenues for additional research.",2
2.0,1.0,Journal of Spatial Econometrics,14 June 2021,https://link.springer.com/article/10.1007/s43071-021-00012-5,A hierarchical approach to scalable Gaussian process regression for spatial data,December 2021,Jacob Dearmon,Tony E. Smith,,Male,Male,Unknown,Male,"Large scale datasets such as County Assessor’s geodatabases offer novel opportunities to investigate spatial phenomena at much finer levels of resolution than in the past. Spatial spillovers, urban infill, renovation price effects and proximity to investment\amenity zones can now be examined at the parcel level, opening up new avenues for the bulk identification of specific development opportunities. The central purpose of this paper is to develop an approach to analyzing such data in an efficient manner. Our approach starts with Gaussian process regression (GPR), which is a well known prediction tool for analyzing spatial datasets. Moreover, the smooth nature of its prediction surfaces is particularly well suited for identifying the local marginal effects (LME) of key explanatory variables (as developed in Dearmon and Smith 2016, 2017). It is these effects that will allow an examination of more fine-grained spatial phenomena, such as the local development opportunities mentioned above. However, the application of such GPR methods to large data sets has thus far been limited by the need to invert large dense covariance matrices. Thus, it is not surprising that this practical limitation has led to a variety of methods for approximating GPR models by more efficiently computable versions (as reviewed for example in Chen et al. 2017). In the present paper, we focus on one of the most promising of these approaches, namely the development of a hierarchical covariance approximation to GPR by Jie Chen ([C1] = Chen et al. 2017; [C2] = Chen and Stein 2017), which we denote by GPR-HCA. This hierarchical extension of Nyström’s low-rank approximation yields dramatic improvement in both speed and accuracy of predictions. In fact, this approximation allows matrix inversions that achieve the optimal efficiency level of \(O(n)\), i.e., are linear in the matrix dimension, n. Of equal importance, these approximations are guaranteed to yield positive definite matrices that generate well-defined Gaussian Processes. So, from a methodological perspective, our central objective is to extend such approximations to the analysis of local marginal effects in large-data contexts. To do so, we begin in Sect. 2 with a review of the standard Gaussian Process Regression model, and in particular, its associated local marginal effects. In Sect. 3, we then develop the GPR-HCA method in detail. One contribution of this paper is to give an explicit probabilistic interpretation of this method, which we illustrate for two- and three-level hierarchies. In addition, we highlight some of the key auxiliary tools proposed by Chen ([C1],[C2]) which are particularly useful for our LME extensions. In Sect. 4, we test both the accuracy and scalability of this hierarchical approach by constructing a simple two-variable simulation model that allows for visual as well as numerical comparisons with other methods. Here we begin by comparing GPR-HCA with the standard Gaussian process regression model (GPR-FULL) over sample sizes small enough to allow the full version to be run. In addition, we compare GPR-HCA with two other large-scale prediction models for sample sizes up to half a million. Of particular relevance is the nearest-neighbor approximation of Gaussian processes (NNGP) first introduced by Datta et al. (2016), which also yields covariance approximations that are linear in matrix dimension and generate well-defined Gaussian Processes. We also compare GPR-HCA performance with one of the standard machine learning algorithms, namely the generalized boosted models (GBM) algorithm of Ridgeway (2007). In all cases we find comparable predictive performance, and much improved time costs over GPR-FULL in particular. However, while such comparative tests are important, they are not of primary interest for our present purposes. More important is the technical extension of GPR-HCA to the evaluation of LME’s for large data sets. Within the same simulation framework, such estimated LME’s are shown to accurately replicate the derivatives of well-behaved functions corrupted by noise. We then turn to an empirical application in Sect. 5, where these HCA-tools are applied to the difficult and often ill-behaved relationship between house prices and attributes using data obtained from nearly a decade’s worth of County Assessor’s databases in Oklahoma County. In particular, we focus on two distinct regions of Oklahoma County; one just north of downtown where spatial spillovers appear to be present and the other a small, wealthy municipality, located further north, where spatial infill opportunities appear to exist. We investigate and analyze such phenomena using GPR-HCA, and provide confirmatory evidence of our findings using building permit data. Finally, we conclude in Sect. 6 with a brief discussion of several possible extensions of this work that are of both practical and technical importance.",1
2.0,1.0,Journal of Spatial Econometrics,09 June 2021,https://link.springer.com/article/10.1007/s43071-021-00013-4,A spatial model averaging approach to measuring house prices,December 2021,Ryan Greenaway-McGrevy,Kade Sorensen,,,Male,Unknown,Mix,,
2.0,1.0,Journal of Spatial Econometrics,26 April 2021,https://link.springer.com/article/10.1007/s43071-021-00011-6,In memoriam of Professor Jesús Mur (1961–2020),December 2021,Fernando López Hernández,,,Male,Unknown,Unknown,Male,,1
2.0,1.0,Journal of Spatial Econometrics,19 April 2021,https://link.springer.com/article/10.1007/s43071-021-00010-7,Editorial note,December 2021,Giuseppe Arbia,,,Male,Unknown,Unknown,Male,,
2.0,1.0,Journal of Spatial Econometrics,08 March 2021,https://link.springer.com/article/10.1007/s43071-021-00008-1,A threshold extension of spatial dynamic panel model with fixed effects,December 2021,Junyue Wu,Yasumasa Matsuda,,Unknown,Male,Unknown,Male,"A panel data model with spatial interactions has been gaining more attention since the works of Baltagi et al. (2003), Kapoor et al. (2007) and Yu et al. (2008) in the field of econometrics. Many different settings, such as static or dynamic model with spatial lag (SL) or spatial error (SE) and fixed or random effect, have been explored with their corresponding estimation methods. The spatial dynamic panel data (SDPD) model with a fixed effect is one of the most popular models in spatial panel data analysis. See, for example, studies by Lee and Yu (2010) and Elhorst (2014, Chapter 3). This study focuses on a threshold extension of SDPD model with fixed effects, especially in a short panel setting. Tong and Lim (1980) pioneered threshold models in time series literature by self-exciting threshold autoregressive (SETAR) models, where a lagged variable is used as a threshold on which the model switches. Let \(y_{t}\) be a time series and \(R_1\cup \cdots \cup R_Q={\mathbb {R}}\) be a partition of real line by mutually disjoint subsets. Using a threshold variable \(y_{t-d},d>0\), they defined SETAR for t such that \(y_{t-d}\in R_q, q=1,\ldots ,Q\), as follows: where \(\varepsilon _t\) is a sequence of independent and identically distributed (i.i.d.) error terms. SETAR allows a temporal dependency of parameters by a threshold variable \(y_{t-d}\). Extensions of threshold models from time series to spatial data have not been conducted extensively except for a few empirical studies. For instance, Aquaro et al. (2015) applied spatial econometrics models with spatially dependent parameters, whereas Hansen (1999) extended the threshold techniques in time series to panel data, providing estimation and testing procedures for non-dynamic panels. Meanwhile, Majumdar et al. (2005) proposed a spatio-temporal model, which allows certain parameters to shift at a given time point. This study tries a threshold extension of SDPD model with fixed effect by allowing model parameters \(\theta\) to switch from one to another, depending on a threshold variable. We introduce an exogenous and time-independent variable \(z_i\) at ith spatial region as a threshold variable. Dependent on the partition \(R_q, q=1,\ldots ,Q\) in which \(z_i\) is included, dependent variable \(y_{ti}\) follows a SDPD model with parameters \(\theta _q\) fixed from among \(\theta _1,\ldots ,\theta _Q\). In other words, parameters in SDPD models can be spatially heterogeneous depending on a threshold variable, but they are time-independent. Threshold SDPD models reduce to usual SDPD when the threshold variables are constants. The threshold variable and the corresponding threshold value need to be determined prior to the estimation due to their exogenous nature. There are several possible criteria for the choice of the threshold, such as (i) one that provide the best forecasting performance; (ii) one that shows significant differences in the estimated parameter values among the groups and so on. We extend the unified M-estimation originally designed by Yang (2018) for usual SDPD models to that for threshold SDPD models. Yang (2018) demonstrated the consistency and asymptotic normality of the M-estimators in cases of short temporal length when the number of spatial regions tends to be infinite. We show that the M-estimation for threshold SDPD models still holds the consistency and asymptotic normality. Additionally, we conduct Monte Carlo experiments to compare M-estimation with conditional quasi-maximum likelihood estimation (CQMLE) to demonstrate the advantage of the M-estimation over CQMLE in finite sample sizes. The empirical illustration using U.S. state-level GDP and power usage growth data is also conducted to demonstrate how threshold SDPD models work to account for spatial dependencies of parameters, leading to a deeper analysis than that using usual SDPD models. Although existing studies (Fallahi 2011; Mahalingam and Orman 2018) have examined the relations between economic growth and power usage, this study is the first trial to it spatial models accounting for spatial dependencies of parameters to them. In Sect. 2, we set forth our threshold SDPD models as an extension of SDPD models. The M-estimation for threshold SDPD models is introduced in relation to that for SDPD models and the asymptotic results of consistency and asymptotic normality in Sect. 3. Monte Carlo experiments and applications to the real example are illustrated in Sects. 4 and 5, respectively. Finally, Sect. 6 presents our conclusion.",2
2.0,1.0,Journal of Spatial Econometrics,08 March 2021,https://link.springer.com/article/10.1007/s43071-021-00009-0,Automated valuation model for residential rental markets: evidence from Japan,December 2021,William Cheung,Lewen Guo,Yuichiro Kawaguchi,Male,Unknown,Male,Male,"With technological advances, the automated valuation model (AVM) has attracted increasing attention from researchers examining the real estate market and practitioners in the mass appraisal industry. The International Association of Assessing Officers defines AVM as: A mathematically based computer software program that produces an estimate of market value based on market analysis of location, market conditions, and real estate characteristics from information that was previously and separately collected. The distinguishing feature of an AVM is that it is an estimate of market value produced through mathematical modelling. Credibility of an AVM is dependent on the data used and the skills of the modeller producing the AVM. The AVM research origin may date back to the late 1980s when most scholars and practitioners used traditional models, such as the cost approach, income approach, and comparable sales method. It is a common practice at the time to apply the income approach as a theoretical basis to build AVMs or to conduct mass appraisal analysis. During that period, the multiple regression analysis (MRA) or the hedonic regression technique were widely used in their research (The Apprasial Foundation 2003; D’Agostino 1986). After the International Association of Assessing Officers set a standard for AVM in the industry in 2003, the AVM is officially distinguished from the traditional appraisal method in which an appraiser physically inspects properties and relies more on the experience and judgement to analyse the data and develop an estimate of market value. Several empirical studies related to mass appraisals and predictions of housing price were conducted only after the 1990s, with the availability of various statistical packages. Since then, AVM is being recognised as an important independent research field in real estate economics and appraisal. The focus of our paper is to propose the ordinary kriging method in an AVM as an efficient alternative to the more traditional hedonic model. The existing studies in this new field are heavily centred around building house-price-related AVMs (Faishal Ibrahim et al. 2005; García et al. 2008) and have seldom endeavoured to construct rental AVM, except for a few studies that investigate and compare different methodologies based on modelling the functions of housing rent (Brunauer et al. 2010; Djurdjevic et al. 2008; Löchl and Axhausen 2010; Seya et al. 2011). This void in rent-related research may be due to the following reasons. First, it is difficult to collect rental data because such information is often exclusively owned by big-brand housing brokerages. Conducting empirical studies without high-quality data is a huge challenge for researchers. Second, given the lack of consensus in academia on how to construct a standardised model for housing rents, benchmarking a related study becomes difficult, which in turn, disperses research interests among scholars. Given this gap in rental market research, real estate market needs to be more transparent for the public because it exhibits strong evidence of information asymmetry, which results in biased behaviours among market participants (Garmaise and Moskowitz 2003). Therefore, one of our objectives in this study is to alleviate information asymmetry by constructing an AVM that helps to estimate the rents of any type of room in the areas examined in our study. Market participants and the public can refer to the AVM-based information before making decisions. Efficient and active rental market (in addition to the housing market itself) is important for the growth of the sharing economy (Barron et al. 2018). This is vital for Japan because of its unique corporate loyalty and employment security, also known as lifetime employment practice (Moriguchi and Ono 2006; Kambayashi and Kato 2009). Young and middle-aged workers prefer to rent rather than purchase a house because of corporate subsidies and the high probability of being transferred by the employer to branches across different cities. In addition to solving the information asymmetry problems, another reason for us to select Japan as our study area is due to the stability of rental prices after the bubble burst (Deng et al. 2017), which provides a temporal-controlled environment for testing cross-sectional data.Footnote 1 Japan is a stable developed country, which suffered from housing bubbles and bubble burst. However, its housing rents remain almost unchanged after 2008—the average rate of appreciation between 2008 and 2013 in Tokyo is estimated at only 0.7% (Statistics Bureau et al. 2013). The asking rents in Japan could also be interpreted as a proxy for the real transactional rents as property owners seldom altered their rents after posting the ads on brokerages (Seya et al. 2011). Practically, we construct a micro-level dataset that includes both micro-level attributes of individual houses and their corresponding geographical coordinates–latitude and longitude, resembling the famous Boston housing price dataset (Harrison Jr and Rubinfeld 1978). Our dataset is unique and abundant in terms of the attributes of houses and geographical representativeness, which could be extended to a panel dataset, if necessary. We investigate the roles of spatial variables in Japanese rental markets. The latitudes and longitudes in our sample areas are extremely crucial in determining housing rents. The distance to Tokyo Station can explain part of the variations in housing rents but cannot completely capture the spatial effects in our hedonic pricing models. Other structural variables exhibit similar characteristics as those in several studies on hedonic pricing summarised by Sirmans et al. (2005). We also build AVMs based on both OLS and ordinary kriging method, an interpolation method in geostatistics, which only takes geographical coordinates as inputs and can be used to estimate unknown rents. Our AVMs exhibit spatial heterogeneity across different regions in both OLS-based and kriging-based AVMs. This study provides the following contributions. First, to the best of our knowledge, we are among the first to develop AVM in the rental market and the first few to investigate the roles of space in the Japanese rental market. This study fills the gap in AVM research between Japan and other leading global markets. Second, the AVMs that we develop provide an important database to researchers and practitioners, including appraisers, bankers, portfolio managers, government, and the public. Third, and perhaps more importantly, the literature often cites (e.g. Cocco (2000)) that the real estate market is opaque and information is not as transparent as that in the stock market. By providing an open-source AVM to the public, we alleviate the information asymmetry, thereby leading to a more efficient real estate market. Therefore, our study is important to potential tenants, property owners, and real estate investors. In addition, our research provides more accurate estimation of imputed rents for owner-occupied dwellings in the Japanese System of National Accounts. The rest of the paper is arranged as follows. Section 2 reviews the existing literature that uses different methodologies to model housing price (rent) functions. Section 3 introduces data constructions and estimation methods. Section 4 presents the results and discussions. Section 5 concludes our findings and contributions.",
2.0,1.0,Journal of Spatial Econometrics,04 January 2021,https://link.springer.com/article/10.1007/s43071-020-00006-9,Spatial clustering patterns of children in single-mother households in Japan,December 2021,Yukiko Abe,Mizuki Kawabata,Yuki Shibatsuji,Female,Female,,Mix,,
3.0,1.0,Journal of Spatial Econometrics,31 October 2022,https://link.springer.com/article/10.1007/s43071-022-00028-5,Specification and estimation of a periodic spatial panel autoregressive model,December 2022,Marius C. O. Amba,Julie Le Gallo,,Male,Female,Unknown,Mix,,
3.0,1.0,Journal of Spatial Econometrics,16 October 2022,https://link.springer.com/article/10.1007/s43071-022-00031-w,"Some useful details about the Moran coefficient, the Geary ratio, and the join count indices of spatial autocorrelation",December 2022,Daniel A. Griffith,Yongwan Chun,,Male,Unknown,Unknown,Male,"Spatial econometrics is a phrase coined by Paelinck and Klaassen (1979), who at that time characterized the mission statement of their newly named subdiscipline as follows: “concerned with the role of spatial dependence in regional economic model response and explanatory variables, asymmetries in spatial relationships, the specification of geographic structure governing spatial interactions, and the explicit modeling of space” (Griffith and Paelinck 2011, p. vii). Roughly a decade later, Anselin (1988) published his book largely responsible for popularizing this subfield, resulting in his now publicly available georeferenced Columbus, OH crime dataset becoming a standard empirical benchmark in the literature. Meanwhile, spatial statistics predates spatial econometrics (e.g., Cliff and Ord 1973), and deals with many of the same methodological issues; these two academic domains have a long synergistic history, one promoting the development of numerous common topics concerning spatial autocorrelation (SA; e.g., Griffith and Paelinck 2007). This paper contributes to the literature at this interface, seeking to explain a number of selected advantageous conditions for using the presently less popular and routinely overlooked Geary Ratio (GR) for measuring SA. This lengthy time period contains many developments about SA (e.g., see Arbia 2006; LeSage and Pace 2009; Kelejian and Piras 2017), some of which pertain to drawbacks affiliated with its widely preferred Moran coefficient (MC) index. A number of these weaknesses constitute the subjects of this paper. The SA literature focuses more on the MC than its competitor index, the GR. Remarkably, although common in the mathematical statistics literature, this emphasis on a doubly centered rather than a Laplacian matrix based computation is counter to what appears in other mathematics subdisciplines, such as graph theory and spectral geometry. In part, this focus is ascribable to the MC almost always being statistically more powerful (i.e., in this context, a relatively high probability of rejecting the null hypothesis of zero SA when the alternate hypothesis of nonzero SA is true; Luo et al. 2019) than the GR. In part, it is ascribable to the GR’s calculation being more sensitive to the presence of outliers and areal units with large numbers of neighbors [this well-recognized property is obvious by visually inspecting Eq. (1)]. The algebraic relationship between the global MC and GR may be written as follows [with general qualitative inverse relationship descriptions of it pre-dating this algebraic specification appearing in Griffith and Layne (1999, p. 15) and Chun and Griffith (2013, p. 12)], and an implicit matrix version of it appearing in Hepple (1998, p. 86)Footnote 1: where n denotes the number of areal units, cij is the (i, j)th cell entry in a spatial weights matrix C, and Y is a georeferenced random variable. This equation supports an articulation of MC and GR properties. Research summarized in this paper frequently exploits this equation to initiate this articulation. Seeking to undertake this task, one of the purposes of this paper is to highlight and uncover overlooked and glossed over properties of the GR that merit more serious acknowledgment and utilization by spatial econometricians/statisticians. This paper builds upon an extensive body of earlier work. Its contributions beyond those reported in this previous literature include five innovative conceptualization studies. The first one considered in this paper formally introduces the Geary scatterplot (which, as already noted, takes advantage of a Laplacian rather than a doubly centered spatial weights matrix). Griffith et al. (2019, p. 132) first describe this graphical possibility, presenting a positive SA (PSA) example of it cast in terms of local SA statistics, paralleling Anselin’s (1996) original Moran scatterplot presentation. The contribution here is a more detailed and comprehensive presentation of this new tool, cast in the context of global SA, and accompanied by a comparative assessment. A second conceptualization treated in this piece posits an optimally condensed analytical expression describing relationships between the join count statistics (JCS) and both the MC and GR. Cliff and Ord (1973, p. 33) initiated this line of work, reporting a rather cumbersome expression for only the MC. Partially successful intervening, but still unwieldly, refinements followed their reduction (e.g., Chun and Griffith 2013, p. 14). The contribution here is a thorough evaluation of a concise reduced parsimonious form relating to both the MC and the GR whose outcome appears as an underived statement in Griffith (2017, p. 173) and Griffith et al. (2019, p. 99). A third conceptualization establishes the expected value of GR for linear regression residuals. Cliff and Ord (1973, pp. 97–98) first introduced this idea, but with little success (even in their subsequent 1981 book; p. 200), ultimately favoring their derived regression residual MC results. Other researchers pursued this regression diagnostic possibility over the years, but with limited success. For example, Hepple (1998) formulated and stated the necessary matrix expression without deriving an explicit expression for practitioners to employ, and Leung et al. (2000) propose an approximation. The contribution here is a direct extension of Cliff and Ord’s original statistical distribution theory solution via Eq. (1), embedding it in the classical mathematical statistics tradition they helped foment, to establish a simplified additional diagnostic tool. A fourth conceptualization is a substantially more comprehensive treatment of the MC + GR ≈ 1 heuristic diagnostic, which had one of its first appearances in Griffith (2009, p. 314) as nothing more than an exploratory maxim, and is further bolstered by Eq. (1). The contribution here is a comprehensive investigation of this postulate, creating supporting evidence substantiating its heuristic utility. The final conceptualization addressed in this paper concerns a comparative sensitivity analysis of spatial weights matrix specifications, say S, embracing definitions spanning the two extreme cases of binary 0–1 matrix C and its row standardized matrix W version. A movement to replace these two popular spatial weights matrix versions with intervening matrix S never emerge during the several transpiring decades since the publication of Tiefelsdorf et al. (1999). The contribution here is a preliminary analysis suggesting, in part, why this replacement never occurred. This collection of examinations spawns several additional contributions, one regarding maximum connectivity in a geographic landscape, and another regarding relationships between the autoregressive SA parameter, ρ, and both the MC and the GR.",
3.0,1.0,Journal of Spatial Econometrics,13 October 2022,https://link.springer.com/article/10.1007/s43071-022-00026-7,Testing for spatial dependence in a spatial autoregressive (SAR) model in the presence of endogenous regressors,December 2022,Malabika Koley,Anil K. Bera,,Female,Male,Unknown,Mix,,
3.0,1.0,Journal of Spatial Econometrics,02 October 2022,https://link.springer.com/article/10.1007/s43071-022-00029-4,Modifying the linear two-step Windmeijer correction for the presence of spatial error dependence,December 2022,Bernard Fingleton,,,Male,Unknown,Unknown,Male,"The generalized method of moments (GMM) estimator is a very general approach to estimation with widespread application, which includes two-stage least squares (2SLS) as one member of the class of GMM estimators of the linear model, but in this paper, without loss of generality, we focus on a specific version of GMM applicable to dynamic panel data modelling. More generally, GMM can be applied to estimate parameters of linear or nonlinear models, with parameters chosen so as to satisfy moments conditions as closely as possible. So parameters are chosen which give the best fit to a set of equations, each of which sets a sample moment to zero. Invariably with over-identification these moments conditions cannot be satisfied simultaneously, so the approach involves minimising a quadratic objective function to achieve the best fit. While GMM can be applied to non-linear moments conditions, when all the moments conditions are linear in parameters, one typically obtains an improvement in the variance estimate (Windmeijer 2005, p. 29). This paper adopts a linear in parameters approach. GMM can be applied to linear cross-sectional models in which the sample covariance of regression error and exogenous variables is as small as possible, in other words one is minimising a quadratic function which is in terms of the regression residuals per se, the exogenous variables and an appropriate weight matrix. In the case of dynamic panel data models in which there is a compound error process which captures both individual heterogeneity and a remainder idiosyncratic error component, a commonly used approach is the GMM estimator in the model in first differences (see Arellano and Bond 1991). In this case the moments conditions are in terms of differences in residuals (to avoid correlation between regressors and residuals per se), exogenous variables and the weight matrix, which define the quadratic objective function. This naturally extends to the dynamic panel data model under consideration here, with the additional extension to accommodate spatial error dependence. One-step and two-step variants, in which the second step utilises residuals from the first-step, are also options. While the focus for the paper is on a particular two-step GMM estimator, the Windmeijer correction, which seeks to avoid the severe downward bias in the estimated asymptotic standard errors of the efficient two-step GMM estimator, and the modification proposed in this paper, it should be emphasised that spatial error dependence is undoubtedly present in data across the range of GMM estimators. For example in the cross-sectional regression context, Kelejian and Prucha (1998) give a generalized spatial 2SLS procedure for estimating a spatial autoregressive model with autoregressive disturbances. Fingleton and Le Gallo (2008) extend their feasible spatial 2SLS estimator to allow for several endogenous regressors, and also introduce spatial moving average (SMA) error dependence. Consider first a simple dynamic panel data model  in which there are \(N\) individuals /regions/locations and \(T\) times, \(x\) is an exogenous variable, \(\gamma ,\beta\) are scalar parameters to be estimated. The error term is compound, thus where \(\mu_{i}\) is a set of individual effects, one for each of the \(N\) individuals, controlling for unobserved time-invariant heterogeneity across individuals. The term \(\nu_{it}\) varies both by region and by time, and represents other, unpredictable, random effects. The assumption is that each \(\mu_{i}\) and \(\nu_{it}\) is a random draw from independent and identically distributed distributions thus \(\mu_{i} \sim iid(0,\sigma_{\mu }^{2} )\) and \(\nu_{it} \sim iid(0,\sigma_{\nu }^{2} )\) with \(\mu_{i}\) and \(\nu_{it}\) independent of each other and among themselves. Given \(\sigma_{\mu }^{2} > 0\) there is individual heterogeneity with \(\mu_{i}\) capturing individual effects and also regional variation in unobserved effects. A more general specification written in matrix terms is In which \({\mathbf{y}}_{t}\) is an \(N\) by 1 vector, \({\tilde{\mathbf{x}}}_{t}\) is an \(N\) by \(k\) matrix of exogenous regressors, \(\beta\) is a \(k\) by 1 vector of coefficients, and \({{\varvec{\upvarepsilon}}}_{t}\) is a vector of errors at time \(t\). Spatial dependenceFootnote 1 could be introduced into the errors by a spatial autoregressive error process, which is the most widely adopted on the spatial econometrics literature. Given an N by N connectivity matrix M, with spatial autoregressive (SAR) error dependence \({\mathbf{H}}_{1} = \left( {{\mathbf{I}}_{N} - \hat{\rho }{\mathbf{M}}} \right)^{ - 1}\) where \({\mathbf{I}}_{N}\) is an \(N\) by \(N\) identity matrix, and with SMA error dependence \({\mathbf{H}}_{2} = \left( {{\mathbf{I}}_{N} - \hat{\lambda }{\mathbf{M}}} \right)\), as in Baltagi et al. (2019). Below we use \({\mathbf{S}} \in \left\{ {{\mathbf{H}}_{1} ,{\mathbf{H}}_{2} } \right\}\) to refer to either version of \({\mathbf{H}}\). Accordingly, given \(N\) locations, for SAR error dependence it is assumed that in each period, The diagonal elements of \({\mathbf{M}}\) are zeros since a location cannot be a neighbour of itself, \(\left( {{\mathbf{I}}_{N} - \rho {\mathbf{M}}} \right)\) is non-singular and \({\mathbf{M}}\) is uniformly bounded in absolute value. This error process implies that a shock at location j is transmitted to all \(N\) locations, as shown, assuming \(\left| \rho \right|\)< 1 and the rows of \({\mathbf{M}}\) sum to 1, by the expansion In Eq. (5), \({\mathbf{M}}^{0} = {\mathbf{I}}_{N}\), \({\mathbf{M}}^{2}\) is the matrix product of \({\mathbf{M}}\) and \({\mathbf{M}}\),and \({\mathbf{M}}^{i}\) is the matrix product of \({\mathbf{M}}\) and \({\mathbf{M}}^{i - 1}\). A shock at \(j\) is felt directly at location \(j\), with an indirect effect due to \(\rho {\mathbf{M\xi }}_{t}\) affecting all pairs of locations with non-zero cells in \({\mathbf{M}}\). Shocks extend beyond these local impacts as a result of transmission via neighbours of neighbours, ultimately affecting all \(N\) locations. Working via neighbours of neighbours of neighbours, shock effect rebound to \(j\) so that the full impact of a shock at \(j\) is the initial shock plus the shock effects feeding back from other locations. In contrast, an SMA error process is given by Which implies that a shock at \(j\) will only affect locations that are directly connected by non-zero elements of \({\mathbf{M}}\), so shock effects are local rather than global. The consequence of spatially dependent errors is that the parameter standard errors differ from those obtained assuming independent errors.",
3.0,1.0,Journal of Spatial Econometrics,10 September 2022,https://link.springer.com/article/10.1007/s43071-022-00027-6,Wave after wave: determining the temporal lag in Covid-19 infections and deaths using spatial panel data from Germany,December 2022,Manuela Fritz,,,Female,Unknown,Unknown,Female,"By the end of 2019, a novel coronavirus, the severe acute respiratory syndrome coronavirus 2, in short Covid-19, was detected in the city of Wuhan in China (Guan et al. 2020; Zhang et al. 2020). What seemed first to cause only a country wide epidemic has fast developed into a worldwide pandemic, which is by now judged as the greatest human challenge since the Second World War. By the time of October 2021, the pandemic has caused about 246 million infections and more than 4.9 million deaths worldwide. As a policy response, several countries implemented severe lockdowns, including school and store closings, curfews and travel bans to reduce human interaction and thereby the spread of the virus. While aiming to save human life, such restrictions also limit human freedoms. Hence, they require a continuous evaluation of whether they are sufficient to protect vulnerable populations and whether more or less strict measures can and should be considered. One quantitative indicator of policy effectiveness and pandemic severity is the case fatality ratio (WHO 2020; Ioannidis 2021), which is based on the current number of deaths relative to the lagged number of infections. The appropriate length of the time lag to be used, however, is heavily debated (Baud et al. 2020; Kim and Goel 2020). An accurate measure is essential as both, over- and underestimation can have severe consequences, such as not taking the pandemic seriously or causing redundant panic (Kim and Goel 2020). The literature reflects the uncertainty about the appropriate length. Chrusciel and Szybka (2021), for example, investigate the time lag in several European countries and find that the lag between reported cases and deaths averages around 7 days. Vanella et al. (2020) also investigate the appropriate time lag for European countries to calculate an unbiased case fatality ratio and conclude that a lag between five and ten days should be used. Testa et al. (2020) determine the lag for US counties and find a substantially longer lag. They conclude that deaths often occur two to eight weeks after the onset of the first symptoms. Wilson et al. (2020) determine the case fatality ratio for China and find that a 13-day lag best describes the pattern of the data. To add to this debate, I provide rigorous evidence for the length of the time lag between a rise in infections and a subsequent rise in death cases using daily panel data for Germany’s 16 federal states from May 2020 to December 2020. In comparison to the studies outlined above, however, I rely on a spatial econometric approach to consider the dynamic spatial spread of the virus. I thereby also add to the literature that analyses the spatial dynamics of Covid-19 and quantifies the spatio-temporal interactions and spillovers of the virus (e.g., Guliyev 2020; Krisztin et al. 2020; Ehlert 2021). Specifically, I estimate different spatial econometric models that allow not only to consider the infections in a given state but also those in neighboring states, so-called spatial lags. Spatial econometric models are useful to model interaction effects between geographical units (Elhorst 2021) and are hence especially useful to model the global-spreading and infectious nature of the coronavirus. I determine the lag between the wave of infections and the wave of Covid-19 death cases in Germany’s federal states and their geographical spread with four spatial models: I use (1) a model with spatial lags in the independent variables (SLX model), (2) a non-dynamic and (3) a dynamic model that include spatial lags in both, the dependent and independent variable, together with space and time fixed-effects (Spatial Durbin Models with fixed-effects), and (4) a dynamic Spatial Durbin Model with common factors to capture potential strong cross-sectional dependence (i.e., cross-sectional averages instead of time fixed-effects). All of these spatial models allow to derive the direct (same-state) and indirect (other states) effects of infections on death cases. Specifically, the direct effect shows the marginal effect on the number of death cases driven by a change in the number of infections in the own state, while the indirect effect is the marginal effect on the number of death cases driven by an increase in infections in all other states, while both effects taken together form the total effect (Golgher and Voss 2016). All four spatial econometric models have the advantage that the spillover effects are fully flexible, i.e., they can take any value, which makes them more suitable for economic research focusing on spillover effects in comparison to a Spatial Autoregressive Model (SAR) or Spatial Autoregressive Combined Model (SAC) (Elhorst 2021). Moreover, the two dynamic models allow to differentiate between short-run (SR) and long-run (LR) effects, i.e., is possible to assess whether the effect of an increase in infections on the number of death cases fades out over time, if, for example, effective policies are implemented to protect the most vulnerable. The remainder of this article proceeds as follows. In Sect. 2, I present the data used for the analysis. In Sect. 3, I outline the empirical strategy and briefly discuss the differences in the spatial econometric models. I present the results in Sect. 4 and conclude in Sect. 5.",
3.0,1.0,Journal of Spatial Econometrics,01 September 2022,https://link.springer.com/article/10.1007/s43071-022-00025-8,Impact of COVID-19 on financial returns: a spatial dynamic panel data model with random effects,December 2022,Anna Gloria Billé,Massimiliano Caporin,,Female,Male,Unknown,Mix,,
3.0,1.0,Journal of Spatial Econometrics,24 June 2022,https://link.springer.com/article/10.1007/s43071-022-00024-9,The generalized spatial random effects model in R,December 2022,Giovanni Millo,,,Male,Unknown,Unknown,Male,"Panel data models usually incorporate individual effects in order to account for the unobserved heterogeneity at the individual level. The main issue is to decide whether said effects are allowed to be correlated with the regressors (known as the “fixed effects” case, henceforth FE) or not (“random effects”, or RE). In the former case, they are usually estimated out; in the latter, they are treated as a part of the error term which becomes composite: the sum of a time-invariant random effect, representing individual heterogeneity, and an idiosyncratic error representing shocks that happen independently across time and individual. This note is concerned with the RE case (as will be observed below, most of the following becomes irrelevant in a FE setting).Footnote 1 In the case of spatial panels, the error term is likely to be the result of a spatial diffusion process. The question arises then, whether one of the two error components, or both, diffuse spatially. There are two mainstream solutions to this issue which have been extensively studied in the literature, but each of which represents just a special case of a more general specification. The first model dates back to Anselin (1998), and assumes that the idiosyncratic errors follow a first-order spatial autoregressive (SAR(1)) process, while the individual effects are independent of each other. The second, due to Kapoor et al. (2007), assumes that both the individual effects and the remainder errors diffuse in space according to the same SAR(1) process. Henceforth we will label them, respectively, ANS and KKP. The generalizedFootnote 2 spatial random effects model (henceforth GSRE) encompasses the previous models by allowing for SAR(1) processes in both the individual effects and the idiosyncratic errors, with different parameters and without any restriction on them but for the standard requirements.Footnote 3 It has been first proposed in the literature by Baltagi (2007) and then discussed thoroughly in Baltagi et al. (2013). Nevertheless, practical applications of this model have been virtually non existent and spatial econometricians have continued to rely on the two usual specifications. To our knowledge, the only paper actually employing the GSRE has long remained Delbecq et al. (2012).Footnote 4 The ANS model is the standard specification and, it can be argued, the most commonly employed in applied practice. A review of the empirical literature would be vaste programme w.r.t. the scope of this short note, but a good starting point could be the Google Scholar citation hits for the relevant “software papers” of, respectively, Belotti et al. (2017) (Stata) and Millo and Piras (2012) (R) which will reveal a large number of empirical studies. As of now, the ANS model needs to be estimated by ML. The KKP model—which can indeed be estimated by ML (see Millo 2014)—was instead born in the tradition of generalized moments (GM) estimators of Kelejian and Prucha (1999), further popularized by Bell and Bockstael (2000) because of their many practical advantages. In fact, like all GM, the KKP-GM estimates are much easier to obtain computationally and do not depend on distributional assumptions on the error term. Moreover, they are asymptotically equivalent to the ML ones, and, unlike the ANS-ML counterpart, it is also possible to allow for endogenous regressors (Fingleton et al. 2008; Piras 2013). Actually, despite this, the KKP model is seldom employed in applied practice. Most of the literature building on it is methodological, and the applied papers are scarce. In a review of the first 130 Google Scholar citation hits (in order of relevance) for the Kapoor et al. (2007) paper, only a handful actually apply the KKP estimator (GM or ML) empirically: Chakir et al. (2013), Fingleton et al. (2015), Baylis et al. (2012), Wheeler et al. (2013), Romão et al. (2017), Wan et al. (2015), Gomez et al. (2013), Kopczewska et al. (2017), Padovano and Petrarca (2014) and Jacquot et al. (2013).Footnote 5 All this despite the fact that a user-friendly R implementation of the KKP-GM estimator has been available since before 2010 as function spgm in the ’splm’ package for R (Millo and Piras 2012), together with a more recent KKP-ML equivalent (see function spreml, Millo 2014). The dearth of applications of the theoretically more appealing generalized model of Baltagi et al. (2013) can instead be due to the lack of user-friendly and well tested software for: estimating the GSRE tout court (until 2017); and, later on, for combining the generalized RE structure with SAR. In fact, the current trend in spatial econometrics—at least since the “sea change” described in Elhorst (2010)—has been to consider more than one source of spatial dependence at once; in this respect, in the current taxonomy of spatial models, the GSRE stands out for resting on an exclusion assumption on the SAR term. This note aims at describing a software routine that fills this gap.",
3.0,1.0,Journal of Spatial Econometrics,10 May 2022,https://link.springer.com/article/10.1007/s43071-022-00023-w,Bayesian spatial econometrics: a software architecture,December 2022,Nikolas Kuschnig,,,Male,Unknown,Unknown,Male,"The spatial dimension of economic and other activities of interest is often vital for understanding processes at work. Spatial spillover effects, i.e. impacts of an observational unit i on other units \(j \ne i\), are commonplace in theory, but can pose considerable challenges for econometric modelling. Spatial econometrics allows researchers to analyse and control for this dimension in a parsimonious way. Spatial models are an important part of the empirical toolkit of many disciplines, in particular of economics. They have successfully been used to investigate the determinants of growth (Acemoglu et al. 2019; Crespo Cuaresma et al. 2014; Lesage and Fischer 2008; Panzera and Postiglione 2021), the drivers of land use change (Arima et al. 2011; Chakir and Le Gallo 2013; Kuschnig et al. 2021), international trade (Behrens et al. 2012; Krisztin and Fischer 2015; Yang et al. 2017), and many more pressing issues. Bayesian approaches to spatial models allow for flexible specifications, that loosen restrictive assumptions and impose structure where needed. This allows for models that better reflect reality and natively account for uncertainty. Related developments in the field of spatial econometrics include Bayesian model averaging and model selection (LeSage and Parent 2007; Lesage and Fischer 2008; Crespo Cuaresma and Feldkircher 2013; Pfarrhofer and Piribauer 2019), hierarchical and mixture modelling (Cornwall and Parent 2017; Dong and Harris 2015; Dong et al. 2015; Lacombe and McIntyre 2016), the flexible treatment of connectivity (Debarsy and LeSage 2018, 2020; Han and Lee 2016; Krisztin and Piribauer 2021), and models with limited dependent variables (Krisztin et al. 2021; LeSage 2000). However, Bayesian approaches are rarely used for applied spatial econometrics. This is due, in part, to a lack of dedicated software for Bayesian spatial modelling. The flexibility of Bayesian modelling and the peculiarity of spatial econometrics challenges good software implementations. General-purpose software for Bayesian modelling, such as JAGS (Plummer 2003) and Stan (Carpenter et al. 2017), are not optimised for these models and can be computationally inefficient (see Wolf et al. 2018). Bivand and Piras (2015) first document a lack of software for Bayesian spatial econometric methods, with the notable exception of the MATLAB (The MathWorks Inc 2021) Econometrics Toolbox by LeSage (1999). At the time of writing, some toolbox routines were ported to the spatialreg package (Bivand and Piras 2015), the R-INLA (Lindgren and Rue 2015) package allows for marginal inference (also see Bivand et al. 2015; Gómez-Rubio et al. 2021), and there exist many implementations of specific (e.g. Dong et al. 2016), or related models (e.g. Morris et al. 2019). However, comprehensive free and open source software for spatial econometric models remains scarce—particularly for the R (R Core Team 2021) ecosystem. In this paper, I present a layered object-oriented software architecture that bridges the flexibility of Bayesian modelling with the necessities of spatial econometrics. I provide an implementation in bsreg (Kuschnig 2021), an R package for estimating spatial econometric models. The package provides routines for common models and, thanks to its architecture, can readily be adapted and extended. A combination of two distinct programming and user interfaces allows for a universal underlying structure, while accommodating existing R workflows. The R6 (Chang 2021) object-oriented system is used for the underlying structure; outputs are provided in a standard format, integrating into established procedures with base, third-party, or custom functionality. This duality of a flexible, object-oriented structure and a familiar user interface makes the proposed software architecture maintainable, extensible, and convenient to use. I demonstrate the flexibility of Bayesian spatial modelling and bsreg by reproducing a frequentist analysis of cigarette demand. Halleck Vega and Elhorst (2015) propose a model with local spatial lags, where distance-based connectivities are parameterised—I present a Bayesian variant of their approach. I find that Bayesian posterior densities yield much improved measures of uncertainty. Uncertainty in non-linear models is characterised by heavy tails that are not reflected in conventional measures of uncertainty. I also find that estimates by Halleck Vega and Elhorst (2015) of the average spillover effects were inflated considerably for distance-based connectivities. This is due to a scaling issue that, at the time of writing, also exists in the widely used spatialreg package. This suggests that (a) Bayesian methods are suitable for flexibly extending spatial models, (b) yield improved insights into uncertainty, and (c) the complexities of spatial models, including their interpretation, present a dangerous source of errors for ad-hoc, untested approaches. The remainder of this paper is structured as follows. First, I introduce relevant econometric methods to the reader. This provides a foundation to discuss the software architecture and implementation. I start by sketching out spatial econometrics, and refer the interested reader to Anselin (2013) and LeSage and Pace (2009) for further information. Then, I introduce Bayesian inference and simulation methods for Bayesian estimation, where I also present a Bayesian approach to the parameterised connectivity model of Halleck Vega and Elhorst (2015). For more information on Bayesian inference and computation, I refer to Lancaster (2004), Gelman et al. (2013), and Gamerman and Lopes (2006). In Sect. 4, I present the proposed software architecture, discuss the implementation of the bsreg package and demonstrate its use. In Sect. 5, I estimate several spatial models of cigarette demand and discuss similarities and differences of the Bayesian approach to previous results by Halleck Vega and Elhorst (2015). Section 6 concludes and provides an outlook for future work.",1
3.0,1.0,Journal of Spatial Econometrics,07 March 2022,https://link.springer.com/article/10.1007/s43071-022-00020-z,Earthquake risk reduction and residential land prices in Tokyo,December 2022,Mizuki Kawabata,Michio Naoi,Shohei Yasuda,Female,Male,Male,Mix,,
3.0,1.0,Journal of Spatial Econometrics,07 March 2022,https://link.springer.com/article/10.1007/s43071-022-00022-x,Consistent EM algorithm for a spatial autoregressive probit model,December 2022,Wei Cheng,,,,Unknown,Unknown,Mix,,
3.0,1.0,Journal of Spatial Econometrics,21 February 2022,https://link.springer.com/article/10.1007/s43071-022-00021-y,Spatial wage curves for formal and informal workers in Turkey,December 2022,Badi H. Baltagi,Yusuf Soner Başkaya,,Male,Male,Unknown,Male,"The inverse relation between individual wages and regional employment rates, i.e., the wage curve, is regarded as an empirical law in labor economics. The findings in the literature, see Blanchflower and Oswald (1990, 1995), show that such a relationship holds for a wide range of countries and at different time periods.Footnote 1 While the early literature simply focused on how the wages for a region covaries with the unemployment rates for that region, more recent studies also focused on how the unemployment rates in the neighboring regions affect these wages. On the economics side, such studies provide insights into whether increases in unemployment rates in a region act as suppressing factor for the wages in the neighboring regions, where the neighborhood across geographical regions is defined with respect to whether they are linked via geographical or socio-economic characteristics. Incorporating the spatial dimension of the wage curve relationship is important as the absence of the spatial effects can lead to biased and inconsistent estimates for the relationship between the wages and the unemployment rates of the same region. With this motivation, several studies have estimated spatial wages curves for different countries, such as Longhi et al. (2006) and Baltagi et al. (2012a, b) for Germany; Elhorst et al. (2007) for East Germany; Baltagi and Rokicki (2014) for Poland; Ramos et al. (2015) for Spain, and Karatas (2017) for Turkey to mention a few. The spatial wage curve literature mainly focuses on the spatial aspect of the relationship for the entire population as well as specific demographic groups like age, gender, and education. One of the key characteristics of labor markets, especially for developing countries, is the considerable degree of informal employment. Despite the large size of the informal labor markets, and the significant need to understand the interplay between informality and earnings, a relatively small number of studies have analyzed wage curves along the formal and informal divide. For example, Ramos et al (2010) analyzed whether the elasticities of own wages with respect to unemployment rates differ across formal and informal workers in Colombia. Baltagi et al (2013) and Baltagi et al (2017) conducted a similar analysis for Turkey and Brazil, respectively. A ll these papers consistently find that the wages of informal workers are significantly more sensitive to variations in the unemployment rates of the region than wages of their formal counterparts. These findings contribute to the understanding of several policy related issues such as whether wage gaps between formal and informal workers change in response to swings in unemployment rates or whether informal labor markets play a different role than the formal labor markets in the wage adjustment response to labor market slack. This paper, as far as we know, is the first to add the spatial dimension to the wage curve literature along the formality/informality divide. We ask whether the differences between the wage curves for informal and formal workers are still observed when we incorporate the spatial effects of the unemployment rates. In doing so, we estimate spatial wage curves for Turkey using individual level data from the Turkish Household Labor Force Survey (THLFS) provided by TURKSTAT for the period 2008–2014. We use NUTS2 level variations in the regional unemployment rate. Our analysis is important to assess whether the earlier findings on the wage curves for the formal and informal workers are robust to the inclusion of unemployment variations in the neighboring regions. In particular, we empirically estimate whether the surges in the unemployment rates in the regions that are in economic and geographic proximity have disproportional effects on the wages of formal and informal workers. As another novel aspect of our analysis considering the earlier studies on the wage curves along the formality/informality divide, we model the selection into formal employment, informal employment, and non-employment explicitly. We follow a two-step procedure with a multinomial logit model projecting the employment/formality status on household characteristics, such as total household size, number of infants, children, elderly, and active members in the household, which are utilized in the literature on earnings of informal and formal workers, as factors that affect the formality/employment choice but do not have a direct effect on wages. Finally, we also check the sensitivity of our results with respect to three different spatial weight matrices. In addition to the standard spatial weight matrices based on geographical characteristics such as inverse distances and the contiguity of the NUTS2 level regions, we use another spatial weight matrix based on the migration flows between regions. Studies in Turkey on the interplay between the internal migration and the regional labor market dynamics argue that unemployment in the originating region is one of the key factors affecting internal migration flows. Moreover, these studies also suggest that internal migration is one of the factors feeding the informal employment in the destination regions.Footnote 2 These observations motivate us to extend our analysis to include spatial weights based on migration flows and how unemployment rates in other regions affect the wages of the formal and informal workers. In summary, we show that the hourly wages of the workers respond both to the variations in the region’s own unemployment rate and the unemployment rates of the neighboring regions. We further estimate different spatial wage curves with respect to the informality status of the workers and by gender groups. As in the case for standard wage curves, we find that informal workers experience steeper spatial wage curves compared to formal workers. We also find that the differences in the slope of the wage curves are more pronounced between informal females and informal males, as well as between informal females and formal females. These results provide further evidence for the significant differences in the labor market outcomes of formal and informal workers beyond the earlier results of Baltagi et al (2013). The rest of the paper is organized as follows: Sect. 2 reviews the previous literature, while Sect. 3 presents the data, the model and the spatial weight matrices used. Section 4 presents the estimation results, while Sect. 5 concludes.",2
3.0,1.0,Journal of Spatial Econometrics,21 February 2022,https://link.springer.com/article/10.1007/s43071-021-00019-y,Spatial panel count data: modeling and forecasting of urban crimes,December 2022,Stephanie Glaser,Robert C. Jung,Karsten Schweikert,Female,Male,Male,Mix,,
3.0,1.0,Journal of Spatial Econometrics,03 February 2022,https://link.springer.com/article/10.1007/s43071-021-00018-z,Spatial dependence in regional business cycles: evidence from Mexican states,December 2022,Keisuke Kondo,,,Male,Unknown,Unknown,Male,"As conditions in regional economies do not necessarily coincide with national economic conditions, regional business cycles tend to be highly heterogeneous. However, spatial proximity seems to characterize similarity among regional business cycles. Thus, in light of the interdependence of regional economies, we focus on spatial spillover (or neighborhood) effects across regional business cycles. In such an economic situation, a region-specific shock may cause deterioration in the economic conditions of neighboring economies. In recent years, the importance of conducting spatial analyses of economic activities has been emphasized from economic stability and growth perspectives (e.g., World Bank 2009). We therefore investigate spatial dependence within regional business cycles. To analyze spatial dependence in regional business cycles and spatial spillover effects, we integrate a spatial lag of the dependent variable into a Markov switching model. The Markov switching model with two regimes endogenously distinguishes business cycles between expansion and recession phases (i.e., high- and low-growth rate regimes). Our integrated approach from the Markov switching model and spatial econometrics thus enables us to identify which states experienced a transition from expansion to recession as well as to numerically examine the extent to which states that experienced such a transition caused a deterioration in their neighboring states’ economies. Regional business cycles are not perfectly uniform, and thus discussions of the national business cycle are not directly applicable. For example, in applying the Markov switching model proposed by Hamilton (1989), Owyang et al. (2005) found that business cycles across US states differed considerably in terms of expansionary and recessionary phases. Furthermore, Owyang et al. (2008) investigated business cycles at the US city level and drew similar conclusions. To explain the similarities and differences among regional business cycles, Hamilton and Owyang (2012) developed a Markov switching model based on the rationale that administrative units do not necessarily coincide with economic zones. In their model, US states are endogenously grouped into clusters that share similar economic characteristics by identifying common factors across states. Therefore, the authors’ focus is on regional recessions within each group.Footnote 1 They found that states that have a relatively high share of oil production or agriculture were more likely to be in recession than other US states. By contrast, we focus on the spatial association of regional business cycles because the empirical results of Owyang et al. (2005) imply that state recessions appear to occur among states located close to each other. Therefore, this study emphasizes spatial dependence in regional business cycles. This study uses quarterly data of state economic activity for Mexico. Previous studies, such as those by Owyang et al. (2008) and Hamilton and Owyang (2012), used employment data for business cycle analysis because monthly or quarterly economic activity data were not available at the city or state level in the US. However, employment data may not accurately reflect contemporaneous economic conditions because of labor market rigidities. By contrast, in Mexico, the economic activity data of each state have been collected quarterly and published as an official indicator since the early 2000s.Footnote 2 Capitalizing on these data, we investigate how a state recession, caused by the global economic crisis of 2008–2009, spread to the neighboring states through the domestic economic network. Recent studies have attempted to describe business cycles across Mexican states. Synchronization between the Mexican and US economies has long attracted economists’ attention. For example, Chiquiar and Ramos-Francia (2005) investigated business cycle synchronization between the Mexican and US manufacturing sectors. Although this type of analysis does not account for regional economic activities within Mexico, it offers suggestive evidence that Mexican states with stronger connections with the US exhibit business cycle synchronization within Mexico. In this sense, Mejía-Reyes and Campos-Chávez (2011) investigated synchronization between Mexican states and US manufacturing production, finding that Mexican states with a relatively high share of manufacturing are more strongly affected by US manufacturing production. Mejía-Reyes et al. (2018) also investigated synchronization between Mexican states and the US and found that FDI also had significant and positive effects on the synchronization between Mexican states and the US. To determine the phases of regional business cycles and investigate regional differences during the economic crisis of 2008–2009, Erquizio-Espinal (2010) calculated the coincidence index across Mexican states, in the spirit of Burns and Mitchell (1946). He found that the border states, which are closely related to the US economy, were more strongly affected by the US recession. As emphasized by Mejía-Reyes and Erquizio-Espinal (2012), one of the unique causes of the Great Recession of 2008–2009 in Mexico was the transmission of the business cycle shock from the US. This is consistent with Torres and Vela (2003) and Sosa (2008), who investigated business cycle synchronization between the US and Mexico before the Great Recession of 2008–2009 in Mexico. However, it remains unclear how a recession in the US economy spread across Mexican states. Although some states did not experience sharp declines in quarterly state economic activity during the Great Recession, recessions in states with stronger links to the US economy would have caused a slowdown in their neighboring states’ economies. By considering domestic factors in regional business cycles, this study sheds new light on the quantitative impact arising from this transmission.Footnote 3 This study contributes to the literature by demonstrating how a region-specific shock propagates to neighboring economies. In the literature on spatial econometrics, Anselin (1988) estimated spatial econometric models that were able to account for spatial dependence and heterogeneity. In this study, we connect regional interdependence with business cycles in a macroeconomic time-series analysis by estimating the Markov switching model proposed by Hamilton (1989).Footnote 4 We estimate the model using the Bayesian Markov chain Monte Carlo (MCMC) method.Footnote 5 LeSage and Pace (2009) described a Bayesian estimation methodology for spatial econometric models and applied the Metropolis–Hasting (MH) algorithm to estimate a parameter measuring spatial dependence. Hence, their study is notable in that the estimation method used is characterized by the MH within Gibbs sampling.Footnote 6 In this study, the MH within Gibbs sampling is applied for the Markov-switching model proposed by Kim and Nelson (1998, 1999a, b) with a spatial autoregressive process. Employing Bayesian inference for the Markov switching model with quarterly data of state economic activity during the period 2003:Q1–2015:Q4, this study finds that Mexican states with a higher manufacturing share tended to be in recession during the Great Recession. This study also finds that business cycles across states were spatially dependent during the Great Recession. The numerical simulations of spatial spillover effects suggest that states that experienced a transition from expansion to recession during the Great Recession caused a decrease in the quarterly growth rate of the neighboring economy by an average of 0.39 percentage points. The remainder of this paper is organized as follows. In Sect. 2, we describe the Markov switching model, including a discussion of the spatial lag of the dependent variable. In Sect. 3, we present the Bayesian estimation procedure using MCMC. In Sect. 4, we present the data. In Sect. 5, we discuss the estimation results. In Sect. 6, we provide a numerical simulation of the spatial spillover effects of a regional recession. Finally, In Sect. 7, we present our conclusions.",2
4.0,1.0,Journal of Spatial Econometrics,25 July 2023,https://link.springer.com/article/10.1007/s43071-023-00035-0,Covariates impacts in spatial autoregressive models for compositional data,December 2023,Thibault Laurent,Christine Thomas-Agnan,Anne Ruiz-Gazen,Male,Female,Female,Mix,,
4.0,1.0,Journal of Spatial Econometrics,22 July 2023,https://link.springer.com/article/10.1007/s43071-023-00034-1,Heterogeneous spatial models in R: spatial regimes models,December 2023,Gianfranco Piras,Mauricio Sarrias,,Male,Male,Unknown,Male,"Spatial effects are generally divided into two different categories: spatial dependence and spatial heterogeneity (Anselin 1988). While cross-sectional dependence has to do with correlation between spatial units, spatial heterogeneity consists of instabilities over space that are generally reflected by variations across individual units (Anselin 2010). In practice there are various ways of tackling unobserved heterogeneity, such as controlling for spatial heteroscedasticity (Kelejian and Prucha 2007), spatial regimes models (Anselin 1988; Anselin and Rey 2014), geographically weighted regressions (Fotheringham et al. 1998, 2002), and multilevel (or hierarchical) models (Arcaya et al. 2012), among others.Footnote 1 An interesting distinction between discrete and continuous spatial heterogeneity has been made by Anselin and Amaral (2021). From a discrete perspective, they argue that spatial regimes models are the most common way of dealing with spatial heterogeneity. In a nutshell, spatial regimes models are a class of models whose coefficients may vary across space. The term regimes indicates that the observations are grouped according to some criteria that relates to space. Interestingly, Anselin and Amaral (2021) point out that, even if the estimation of spatial regimes regressions is well established, the identification of the regimes still remains a subject for investigation. Additionally, they acknowledge the existence of three approaches to identify the regimes. The first approach is based on exogenous regimes (e.g., determined through administrative boundaries); the second is when the regimes result from a data-driven procedure (e.g., observation are aggregated using some clustering method); and the last one corresponds to a situation where the coefficients and the regimes are jointly determined. From an empirical perspective, attempts to consider spatial heterogeneity in model specification have mostly, but not exclusively, focused on economic geography and regional sciences. This is verified by the special attention that local labor markets (Huiban et al. 2004; Longhi and Nijkamp 2005; Melo et al. 2012), and regional economic convergence (Rey and Janikas 2005; Ramajo et al. 2008; Ertur et al. 2006) have received over the years. However, spatial heterogeneity has gained an increasing interest also in other disciplines, such as quantitative geography (Song et al. 2020; Georganos et al. 2021; Shu et al. 2019), urban growth (Zhai et al. 2021), urban sprawl (Deng et al. 2020; Irwin and Bockstael 2007), geology (de Marsily et al. 2005), ecology and evolution (Vinatier et al. 2011), epidemiology (Thomas et al. 2020), physics and air pollution (He et al. 2022), among others. From a software availability perspective, spatial models to control for spatial dependence are well established.Footnote 2 Code dealing with spatial heterogeneity is relatively sparse but also long-established.Footnote 3 In this scenario, hspm is an ambitious project that aims at developing and implementing various methodology to control for heterogeneity in spatial models. This article presents the methodological innovations that have been made so far dealing with spatial and (non spatial) regimes models. In particular, we present R functions that allow for the estimation of a general spatial regimes model, as well as all of the nested specifications deriving from it. The models are estimated by instrumental variables (IV) and generalized method of moments (GMM) techniques. The rest of this paper is a mere description of the package functionality to get the readers to familiarize with the different functions contained in it. In particular, Sect. 2 introduces the two data sets that we use throughout the paper: the first is based on a housing price model in the city of Baltimore; the second contains county level data for homicides and selected socio-economic characteristics for the continental United States. The difference between these two data sets is that the second one suffers from endogeneity and requires instrumental variables methods implemented in hspm. In Sect. 3 we introduce the function regimes which is the basic function to deal with (non-spatial) regimes models. Section 4 is devoted to the illustration of the function ivregimes that allows for endogenous variables in a non-spatial context. The function spregimes is presented in Sect. 5. spregimes is a wrapper function that allows to estimate a regimes model with a spatial lag of the dependent variable, the spatial lag of (part of) the regressors, a spatially lagged error term and additional (other than the spatial lag) endogenous variables. As we will see, spregimes also allows to estimate all of the nested specifications included in this general model. In Sect. 6, we explain why hspm does not calculate the impacts measures put forth by LeSage and Pace (2009), and we show a simple way to deal with those impacts in a special case (i.e., when the spatial weighting matrix is block diagonal). Section 7 draws some conclusions and gives indications for future developments of the package. Finally, “Appendix A” compares our implementation with code available from PySAL library (Rey et al. 2022; Rey and Anselin 2007, 2010) developed in Python (van Rossum 1995).",
4.0,1.0,Journal of Spatial Econometrics,17 January 2023,https://link.springer.com/article/10.1007/s43071-022-00033-8,'Traffic light' theory for Covid-19 spatial mitigation policy design,December 2023,Xieer Dai,Michael Beenstock,Nikita Kotsenko,Unknown,Male,Male,Male,"From the outset the Covid-19 epidemic has been characterized by its geographic heterogeneity. In some locations within countries the epidemic has been particularly intense, while in others it has been mild and even non-existent. In an attempt to control the pandemic, national governments adopted 'traffic light' policies, which differentiated mitigation measures across locations according to the intensity of their Covid-19 morbidities and recovery performance. Spatial units such as neighborhoods, cities or regions were assigned a Covid-19 performance score that was color coded according to traffic light colors. Seemingly arbitrary cut-off points determined the move from color to color. As Covid-19 outcomes rose or waned, locations found themselves moving across the different categories with their attendant lockdown or travel restrictions. In essence, traffic light policy was a tool for operationalizing spatially differentiated mitigation policy (MoH 2022, NZGOV 2022). Traffic light policy in practice (reviewed in Sect. 2) highlights the arbitrariness in determining color changes in traffic light policy. There is little common use of variables or criteria for assigning color codes, and in the absence of standardized measures for change, each country went its own way. Furthermore, many of the countries that adopted a traffic light system for the spatial mediation of Covid-19 ignored the challenges of distinguishing between indigenous contagion and imported contagion sub-nationally. The rate of reproduction for Covid-19, denoted by R, which exceeds 1 if morbidity is increasing, is less than 1 if it is decreasing and equals 1 if it is stable, is conceptually valid for countries but it is invalid sub-nationally because it does not distinguish between indigenous and imported contagion. We argue that operationalizing spatial mitigation policy by calculating R for locations, using the same methods as for countries, is likely to produce accident-prone traffic lights. Green locations might be mistaken for red, and red for green. Just because Covid-19 morbidity happens to be increasing in some location does not mean that R is truly greater than 1. If, for example, morbidity is increasing in location A because of contagion imported from B, spatially-adjusted R in A may be less than 1 when the standard measure of R exceeds 1. By the same token, just because Covid-19 morbidity happens to be decreasing does not mean that its true R is less than 1. For example, if location B exports contagion its spatially-adjusted R may exceed 1 despite the fact that the standard measure of R is less than 1. The conceptual misunderstanding between national and sub-national measures of R is widespread. For example, Theide et al. (2020) report R for sub-national areas in South Africa and for other countries including China and Italy. In the United Kingdom, R is officially reported for the seven National Health Service regions of England individually and for Wales, Scotland and Northern Ireland as separate entities. Government justifies sub-national calculation of R noting that ""UK-level estimates of the growth rate are less meaningful than previously given the increasingly localized approach to managing the epidemic"" (UKHSA 2022). These estimates themselves are synthesized from the combined efforts of several independent academic modeling groups. Interestingly, some of these produce much more granular estimates of sub-national R. For example, the University of Oxford (OxCSML) group generates R for over 300 English LTLA (lower tier local authorities) (see https://localcovid.info/). More generally, subnational estimates of R for regions (Italy), states (US, Brazil, India, Germany) or provinces (Canada) are readily available via central repositories. The Center for Mathematical Modeling of Infectious Diseases produces subnational R estimates for a slew of countries cognizant of the limitations of these measures that ""contain little data on the importation status of cases. This means that cases counts may be biased upwards by attributing imported cases to local transmission"" (Abbott et al. 2022, p6). Note that while some of these efforts at generating sub-national R have been discontinued with the advent of mass vaccine rollout, the key analytic observation remains pertinent: similar measures cannot serve both national and sub-national estimations of R as the same phenomena are much weaker at the international level than at the intra-national level. It is much easier to control cross-border movements between countries than within them and the scale of cross-border traffic is much greater intra-nationally than internationally. We therefore propose a new methodology for ranking the contagiousness of different locations in terms of their outdegrees from graph theory (Diestel 2005). Outdegree measures the salience of nodes in networks. In the present context it is the effect of a random increase in morbidity in a given location on morbidity in all other locations including itself. Locations with the largest outdegrees are color coded 'red' while locations with the smallest outdegrees are color-coded 'green'. Under this regime local imports and exports of Covid-19 are linked in a closed system. If an area increases its imports of Covid-19 then by definition other areas must be exporting more. Since outdegrees are equivalent to column sums of spatiotemporal impulse response matrices, they may be estimated by econometric methods designed for nonstationary spatial panel data (Beenstock and Felsenstein 2019). Since outdegrees are continuous, a practical problem is to categorize them into discrete color codes, and to determine the number of categories. This and related administrative decisions is not our present focus, which is to devise a conceptually valid criterion for ranking the contagiousness of locations throughout the network of Covid-19 diffusion that distinguishes between indigenous contagion within locations and imported and exported contagion between locations. This paper proceeds as follows. Section 2 reviews the literature on spatial mitigation policy for Covid-19. In Sect. 3 we present a stochastic SIR model in discrete time, in which contagion is transmitted between subnational units. Section 4 illustrates how outdegrees may be derived from spatial SIR models, and how they distinguish between indigenous and imported contagion. In Sect. 5 we compare contagion heat maps based on outdegrees with R-based contagion patterns derived for synthetic locations and highlight the superior performance of the former. Section 6 considers the role of 'spikes' in the coloring of traffic light policy. Since spiking is not randomly distributed across locations, it fattens the right-hand tails of morbidity distributions, which darken their color coding in traffic light terms. We conclude with an empirical illustration for Israel.",
4.0,1.0,Journal of Spatial Econometrics,26 December 2022,https://link.springer.com/article/10.1007/s43071-022-00030-x,Evaluating the performance of AIC and BIC for selecting spatial econometric models,December 2023,Christos Agiakloglou,Apostolos Tsimpanos,,Male,Male,Unknown,Male,"Spatial autocorrelation in errors is a very common problem in linear regression models with spatial data, which should be treated with caution, since it violates the assumption of the random sample, leading the analyst to ambiguous results. This behavior typically arises from observations corresponding to geographically proximate locations that are correlated because of their spatial dependence. As Anselin (1988a) has clarified, this spatial dependence along with spatial heterogeneity define the concept of spatial effects. For this purpose, a set of Lagrange Multiplier (LM) tests, known as spatial dependence tests (see Burridge 1980; Anselin 1988b; Anselin et al. 1996), have been developed in the literature to assist the analyst in terms of selecting and estimating the most appropriate spatial econometric model that considers the presence of spatial dependence. Moreover, spatially autocorrelated errors can also appear in spatial regression analysis as a symptom of a false indication of spatial dependence due to spurious behavior, as Finglenton (1999), Mur and Trivez (2003) and Agiakloglou et. al. (2015) have indicated. Nevertheless, these LM tests that have been widely used in many empirical applications contain two important drawbacks. The first one is related to the restrictive alternate model structure imposed by these tests and the second one is associated with their reliability in selecting the right model. Indeed, as it is known, these tests are applied exclusively to the choice between a simple econometric model and a spatial model with a spatial lag structure either in the dependent variable or in the error, whereas in several cases their application often leads to inconsistent conclusions as to the choice of the right spatial econometric model, a problem that has been addressed by Anselin and Florax (1995). In addition, LeSage and Pace (2009) point out that spatial dependence tests were developed and established in the logic that their statistics are calculated solely from the residuals derived from the estimation of the simple econometric model using least squares estimation without requiring estimating the corresponding spatial econometric model. Clearly, these tests for spatial dependence versus the null hypothesis of no dependence do not require maximum likelihood estimation of the spatial model under the alternative hypothesis. For this reason and given the current availability of software, LeSage and Pace (2009) suggested that the selection of a spatial model should be made in the context of comparing the likelihoods of different models, while the analysis should start from a more general model that nests both the spatial lag model and the spatial error model. Thus, it will be very interesting to investigate whether the use of any information criterion can help the analyst to select the true spatial econometric model, knowing that these criteria are usually applied to any quantitative analysis and that their performance has been limited explored to spatial econometric analysis. For this purpose, a Monte Carlo analysis is conducted to evaluate the performance of the two most frequently used information criteria, such as the Akaike’s Information Criterion (AIC) and the Bayesian Information Criterion (BIC), using only the three most important spatial econometric models, such as the SIM, SLM and SEM, suitable for the application of the LM tests, not only in terms of detecting spatial dependence but also in terms of selecting the right spatial econometric model as a complementary approach to model selection using the LM tests for these models. Simulation results show that these criteria can assist the analyst to identify the right spatial econometric model and spatial dependence more effectively in some cases than the LM tests. Note that the simulation process is conducted using rook and queen construction matrices along with a real geographical structure, i.e., the spatial structure of Greece, which has a lot of geographical peculiarities resulting in quite asymmetric spatial weights matrices. The research is also expanded, in term of selecting the right spatial econometric model, using the two aforementioned information criteria, by considering more spatial econometric models, namely the SLX, SDM, SARAR, and SDEM, as well as two non-ideal situations, such as heteroscedasticity and non- normality, where the results vary considerably. Hence, the objective of this research is concentrated on selecting the best-fitted spatial econometric model given the weights matrix formation, rather than searching for the most appropriate weights matrix formation knowing the spatial econometric model, as discussed in Zhang and Yu (2018). The remaining of the paper is organized as follows. Section 2 presents the three simple econometric models, namely the SIM, SLM and SEM, along with the SDM, as a special case of the SEM, the information criteria AIC and BIC and analyses the strategies applied for the LM tests. Section 3 describes the design of the simulation process and discusses the results. Section 4 presents the extension of the Monte Carlo analysis with all the elements that have been added including the additional spatial econometric models, such as the SLX, SARAR, and SDEM, along with heteroscedastic and non-normal errors and discusses the results. The concluding remarks are included in Sect. 5.",
4.0,1.0,Journal of Spatial Econometrics,06 December 2022,https://link.springer.com/article/10.1007/s43071-022-00032-9,A test to select between spatial weighting matrices,December 2023,Stephen G. Hall,George S. Tavlas,Deborah Gefang,Male,Male,Female,Mix,,
