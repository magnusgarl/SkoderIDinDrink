Volume,Issue,Journal Name,Published Date,Link,Title,Journal Year,Author 1,Author 2,Author 3,Gender_Author 1,Gender_Author 2,Gender_Author 3,Article_Gender,Intro,Citations
1.0,1.0,Eurasian Economic Review,28 August 2014,https://link.springer.com/article/10.14208/BF03353821,Editorial Note,June 2011,Hakan Danis,Peter Rangazas,,Male,Male,Unknown,Male,,
1.0,1.0,Eurasian Economic Review,28 August 2014,https://link.springer.com/article/10.14208/BF03353822,Relative Efficiency of Government Spending and Its Determinants: Evidence from East Asian Countries,June 2011,Eric C. Wang,Eskander Alvi,,Male,Unknown,Unknown,Male,,
1.0,1.0,Eurasian Economic Review,28 August 2014,https://link.springer.com/article/10.14208/BF03353823,Micro-Finance and Rural Enterprises: An Analysis of Operational Performance and Constraints in the SHG-Bank Linkage Program in India,June 2011,Sudhir K. Jain,K. K. Tripathy,,Male,Unknown,Unknown,Male,,
1.0,1.0,Eurasian Economic Review,28 August 2014,https://link.springer.com/article/10.14208/BF03353824,Fishing In Troubled Waters: The Lull Before The Storm,June 2011,Sílvia Bou Ysàs,Magda Cayón Costa,,Unknown,Female,Unknown,Female,,
1.0,1.0,Eurasian Economic Review,28 August 2014,https://link.springer.com/article/10.14208/BF03353825,The Position of Women in Social and Economic Life: A Comparison between the EU and Turkey,June 2011,Nuray Gökçek Karaca,Fatma Kocabaş,,Female,Female,Unknown,Female,,
1.0,2.0,Eurasian Economic Review,28 August 2014,https://link.springer.com/article/10.14208/BF03353826,"Capital Investment, Earnings, and Annual Stock Returns: Causality Relationships In China",December 2011,Ahmet Can Inci,,,Male,Unknown,Unknown,Male,,
1.0,2.0,Eurasian Economic Review,28 August 2014,https://link.springer.com/article/10.14208/BF03353827,Comparing High Frequency Data of Stocks that are Traded Simultaneously in the US and Germany: Simulated Versus Empirical Data,December 2011,Jörg Rieger,Kirsten Rüchardt,Bodo Vogt,Male,Female,Male,Mix,,
1.0,2.0,Eurasian Economic Review,28 August 2014,https://link.springer.com/article/10.14208/BF03353828,The Composition of Foreign Reserves of the Central Banks of Selected Countries: Will the Euro Replace the Dollar?,December 2011,Akbar Komijani,Hossein Tavakolian,,Male,Male,Unknown,Male,,
1.0,2.0,Eurasian Economic Review,28 August 2014,https://link.springer.com/article/10.14208/BF03353829,A Higher Moment Downside Framework for Conditional and Unconditional Capm in the Russian Stock Market,December 2011,Tamara Teplova,Evgeniya Shutova,,Female,Female,Unknown,Female,,
2.0,1.0,Eurasian Economic Review,28 August 2014,https://link.springer.com/article/10.14208/BF03353830,A Quantitative Mirror on the Euribor Market Using Implied Probability Density Functions,June 2012,Josep Maria Puigvert-Gutiérrez,Rupert de Vincent-Humphreys,,Male,Male,Unknown,Male,,
2.0,1.0,Eurasian Economic Review,28 August 2014,https://link.springer.com/article/10.14208/BF03353831,"A Panel Causality Analysis of the Relationship among Research and Development, Innovation, and Economic Growth in High-Income OECD Countries",June 2012,Bulent Guloglu,R. Baris Tekin,,Unknown,Unknown,Unknown,Unknown,,
2.0,1.0,Eurasian Economic Review,28 August 2014,https://link.springer.com/article/10.14208/BF03353832,General Analysis of Cournot Mixed Oligopoly with Partial Privatization,June 2012,Koji Okuguchi,,,Male,Unknown,Unknown,Male,,
2.0,1.0,Eurasian Economic Review,28 August 2014,https://link.springer.com/article/10.14208/BF03353833,The Effects of Population Ageing on Private Consumption — A Simulation for Austria Based on Household Data up to 2050,June 2012,Birgit Aigner-Walder,Thomas Döring,,Female,Male,Unknown,Mix,,
2.0,2.0,Eurasian Economic Review,28 August 2014,https://link.springer.com/article/10.14208/BF03353834,EU Enlargement to Turkey: Potential Effects on Turkey’s Agricultural Income and Markets,December 2012,Thomas Fellmann,Myrna van Leeuwen,Gulden Boluk,Male,Female,Unknown,Mix,,
2.0,2.0,Eurasian Economic Review,28 August 2014,https://link.springer.com/article/10.14208/BF03353835,"Financial Constraints, Quality of Institutions and Firm Size: What Do Perceptions Tell Us?",December 2012,Nurullah Gur,,,Male,Unknown,Unknown,Male,,
2.0,2.0,Eurasian Economic Review,28 August 2014,https://link.springer.com/article/10.14208/BF03353836,"Determining Hub Efficiency in Europe, the Middle East, and North Africa: The Impact of Geographical Positioning",December 2012,M. Sukru Nenem,E. Nur Ozkan-Gunay,,Unknown,Unknown,Unknown,Unknown,,
2.0,2.0,Eurasian Economic Review,28 August 2014,https://link.springer.com/article/10.14208/BF03353837,Macroeconomic Policies for Slovenia after the “Great Recession”,December 2012,Dmitri Blueschke,Viktoria Blueschke-Nikolaeva,Klaus Weyerstrass,Male,Female,Male,Mix,,
3.0,1.0,Eurasian Economic Review,28 August 2014,https://link.springer.com/article/10.14208/BF03353838,Introduction: The Dual Economy Approach to Economic Growth and Development,June 2013,Peter Rangazas,,,Male,Unknown,Unknown,Male,,
3.0,1.0,Eurasian Economic Review,28 August 2014,https://link.springer.com/article/10.14208/BF03353839,Supply Side Structural Change,June 2013,Juan Carlos Cordoba,,,Male,Unknown,Unknown,Male,,
3.0,1.0,Eurasian Economic Review,28 August 2014,https://link.springer.com/article/10.14208/BF03353840,Measuring Aggregate Agricultural Labor Effort in Dual Economies,June 2013,Dietrich Vollrath,,,Male,Unknown,Unknown,Male,,
3.0,1.0,Eurasian Economic Review,28 August 2014,https://link.springer.com/article/10.14208/BF03353841,Wage and Fertility Gaps in Dual Economies,June 2013,Peter Rangazas,Alexandros Mourmouras,,Male,Male,Unknown,Male,,
3.0,1.0,Eurasian Economic Review,28 August 2014,https://link.springer.com/article/10.14208/BF03353842,Surplus Labour and Urbanization in China,June 2013,Xiaobing Wang,Nick Weaver,,Unknown,Male,Unknown,Male,,
3.0,2.0,Eurasian Economic Review,28 August 2014,https://link.springer.com/article/10.14208/eer.2013.03.02.001,Technological Choices and Labor Market Participation: Negative Income Tax,December 2013,Samir Amine,Pedro Lages Dos Santos,,Male,Male,Unknown,Male,,2
3.0,2.0,Eurasian Economic Review,28 August 2014,https://link.springer.com/article/10.14208/eer.2013.03.02.002,Arm’s Length Method for Comparing Rating Scales,December 2013,Alexander M. Karminsky,Richard N. Hainsworth,Vasily M. Solodkov,Male,Male,Male,Male,,4
3.0,2.0,Eurasian Economic Review,28 August 2014,https://link.springer.com/article/10.14208/eer.2013.03.02.003,Mongolian and World Equity Markets: Volatilities and Correlations,December 2013,Yertai Tanai,Kuan-Pin Lin,,Unknown,Unknown,Unknown,Unknown,,
3.0,2.0,Eurasian Economic Review,28 August 2014,https://link.springer.com/article/10.14208/eer.2013.03.02.004,The Relationship between Economic Growth and Income Distribution in Turkey and the Turkish Republics of Central Asia and Caucasia: Dynamic Panel Data Analysis with Structural Breaks,December 2013,Mehmet Mercan,Ozlem Arzu Azer,,Male,Unknown,Unknown,Male,,6
3.0,2.0,Eurasian Economic Review,28 August 2014,https://link.springer.com/article/10.14208/eer.2013.03.02.005,"The Impact of Ownership Concentration, Commissioners on Bank Risk and Profitability: Evidence from Indonesia",December 2013,Mamduh M. Hanafi,Fitri Santi,Muazaroh,Male,Unknown,Unknown,Male,,12
4.0,1.0,Eurasian Economic Review,30 July 2014,https://link.springer.com/article/10.1007/s40822-014-0007-0,Editorial Note,June 2014,Hakan Danis,Peter Rangazas,,Male,Male,Unknown,Male,,
4.0,1.0,Eurasian Economic Review,27 August 2014,https://link.springer.com/article/10.1007/s40822-014-0006-1,Japan’s monetary policy in a challenging environment,June 2014,Sayuri Shirai,,,Female,Unknown,Unknown,Female,"On April 4, 2013, the Bank of Japan (BOJ) introduced quantitative and qualitative monetary easing (QQE), the most aggressive monetary accommodation policy in the contemporary history of the Japanese monetary policy.Footnote 1 Even before QQE was introduced, the impact had already started to materialize starting from the end of 2012 in anticipation of greater monetary easing by the markets and public. The impact was strengthened with expansionary fiscal measures taken by the new administration of the Japanese government. Consequently, compared with 2012, stock prices have been higher in 2013; private consumption is more resilient; more active commercial and residential investment have taken place; the yen’s exchange rate has been at more depreciated levels; and funding costs for firms and households in the loan and bond markets remain more accommodative. Most importantly, the growth momentum of Japan’s economy is gaining traction—this is evidenced by the positive economic growth rates seen in the last four consecutive quarters. The unemployment rate dropped to 3.7 % in December 2013, approaching the lowest level in recent years of 3.6 % recorded in July 2007, before the global financial crisis. There are some signs of the economy moving out of deflation with the year-over-year percentage change in the consumer price index (CPI) for all items less fresh food, or the core CPI, turning positive in June 2013 and reaching 1.3 % in December. QQE was formulated based on the experiences of previous monetary easing practices. In order to deepen the understanding of QQE, this paper first sheds light on two major nonstandard monetary easing policies adopted prior to QQE. The remainder of the paper is organized as follows: Sect. 2 focuses on the first round of monetary easing called quantitative monetary easing (QE) adopted during 2001–2006, while Sect. 3 examines the second round of monetary easing called comprehensive monetary easing (CME) adopted from 2010 to March 2013. Section 4 highlights the main features of QQE as well as the current performance of prices and economic activity and their outlook. Section 5 concludes.Footnote 2
",10
4.0,1.0,Eurasian Economic Review,12 August 2014,https://link.springer.com/article/10.1007/s40822-014-0002-5,Monetary policy challenges: how central banks changed their modus operandi,June 2014,Giorgio Di Giorgio,,,Male,Unknown,Unknown,Male,"The financial crisis that started in August 2007 had deep consequences for the world economy. In the second half of 2008, the waves of recession hit all the major economies, with impressive figures recorded in terms of negative growth rates for 2009. Notwithstanding the reduced but still positive performance of some of the largest emerging economies, 2009 was indeed the first year of recession for the world economy in the period after the Second World War. Negative real growth rates were coupled with raising unemployment and diffuse failures in both the financial and the real sector in many industrialized countries. Economic recovery started in 2010 at very different pace. Growth has been strong and back on track in emerging markets, moderate and very unstable in the US and Japan, low in the Euro area. The latter has been suffering from strong political doubts on the future of the single currency following the worsening of fiscal positions in most member countries. In the second half of 2010, a public debt problem returned to prominence in many countries, due to the joint effect of flat or decreasing GDP and the expanding fiscal deficits linked to policy attempts to stabilize the economy. In the Euro area, this problem exploded in 2011 due to the explicit binding constraints in the Maastricht Treaty and in the Stability and Growth Pact. The “Club Med” economies of Greece, Spain, Portugal and Italy have been particularly affected, together with Ireland. These countries experienced large swings in the yield spread of their government bonds vis-à-vis the German Bund. Interest rates on their government debt incorporated the risk of (partial) default and debt restructuring as well as of the possibility of a currency crisis (and consequent large depreciations). This imposed an additional burden on their public finance and growth prospects. Many observers have compared the 2008–09 global recession to the Great Depression in the 1930s, highlighting one of the main differences as the “learn from the past” factor that implied a prompt and intense policy response in the recent crisis, both on the fiscal and the monetary front. On the contrary, many explanations of the Great Depression point to slow and insufficient economic policy reaction. Clearly, even in presence of evident and timely policy response, an assessment of whether this has been properly conducted or badly managed is desirable. In this paper, we focus on monetary policy and we address several issues. Firstly, we analyze whether the existing monetary policy regimes in place before the crisis (in the US and in the Euro Area) were adequate and coherent with the prevailing academic consensus. Secondly, we provide an assessment of the monetary policy response of the FED and the ECB during the crisis. Finally, we discuss plausible new frameworks which allow extending the analysis of monetary policy by explicitly taking into consideration financial stability as an additional target. This may be helpful also in designing exit strategies from the unconventional policies adopted during the crisis. It also requires proper consideration of the relationship between central banks and other financial regulatory and supervisory authorities. The organization is the following. In Sect. 2, we briefly describe the main elements of the policy regimes in place on both sides of the Atlantic Ocean as of July 2007, and consider their adherence to the academic consensus framework on monetary policy management, that has been often ambitiously labeled as “the science of monetary policy”. In Sect. 3, we provide an assessment of how the FED and the ECB reacted in different phases of the crisis. In Sect. 4, we discuss some promising advancements in monetary policy theory focusing on the interaction between standard monetary policy targets and financial stability. Some concluding remarks are given in Sect. 5.",14
4.0,1.0,Eurasian Economic Review,05 August 2014,https://link.springer.com/article/10.1007/s40822-014-0001-6,Managing short-term capital flows in new central banking: unconventional monetary policy framework in Turkey,June 2014,Ahmet Faruk Aysan,Salih Fendoglu,Mustafa Kilinc,Male,Male,Male,Male,"Last two decades have witnessed significant increase in financial flows for most world economies. The financial globalization was not without challenges, though, especially for emerging countries. These countries have experienced challenges in managing these flows, confronting the risk of amplified business cycles and sudden reversal of such flows.Footnote 1 From an emerging country perspective, challenges due to open financial accounts and capital flows have been known long before the global financial crisis of 2008–2009. Nonetheless, the nature of capital flows-related problems has changed during the recent period. Historically, several emerging countries had financial crises stemming from volatile capital flows. Before the recent global financial crisis, most of these crises were country-specific (e.g. Mexican crisis in 1994, Argentine crisis in 2001, Turkish crisis in 1994 and 2001) or region-specific (e.g. Asian crisis in 1997). Accordingly, it has generally been thought that the crises were by and large related to domestic fundamentals and due to macroeconomic imbalances specific to these countries or regions. Several factors such as currency/maturity mismatches, overborrowing, severe financial market imperfections, unsustainable fiscal positions, or fixed exchange rate regimes with inconsistent fundamentals were put forward as possible explanations.Footnote 2, Footnote 3
 After the global financial crisis of 2008–2009, the nature of capital flows has changed for developing countries. The Fed and the European Central Bank have taken unprecedented steps to boost aggregate spending by reducing the overnight policy rate aggressively to almost zero, while fiscal authorities have allowed large budget deficits (in a comparatively very short period of time). Yet, the recovery was not as quick or strong as expected, and a battery of unconventional policies has been implemented in advanced countries.Footnote 4 The required level of household deleveraging, fiscal sustainability issues, and the resulting policy uncertaintiesFootnote 5 have nonetheless restricted the recovery, and in turn have created a volatile global financial environment. Accordingly, unlike the pre-crisis period, the driving force of capital flows to emerging markets pertains mostly to concerns about advanced economies in the recent era. Moreover, unlike the pre-crisis period, these flows were mostly short-term and very volatile, necessitating emerging country policy makers to follow a new and diverse set of policies.Footnote 6
 In response to financial stability challenges due to such volatile capital flows, emerging countries have resorted to quantity-based capital flow measures (e.g. Brazil, Colombia, etc.), or alternatively, implement more general macroprudential policies (e.g. Turkey). Theoretically, capital flow measures (e.g. levying tax on external borrowing) might reduce risks or externalities due to such flows.Footnote 7 On practical grounds, however, the empirical literature is inconclusive about the effectiveness of such controls.Footnote 8 It is usually easier for market participants to circumvent the controls as these controls are set only on one part of the financial system (e.g. foreigner’s transactions). Therefore, implementing more general macroprudential policies might be more practical and effective. The Central Bank of the Republic of Turkey (CBRT) has devised a new policy mix starting in the last quarter of 2010, acknowledging financial stability concerns and the aim to contain such risks. The new policy tools were not aimed directly on capital flows but were more in nature of general macroprudential policies: active use of reserve requirements, liquidity policy, asymmetric interest rate corridor between overnight borrowing and lending rates, and later the reserve option mechanism (ROM). The latter two are the new policy tools.Footnote 9
 This paper provides a detailed introduction on these novel policy tools, discusses their potential advantages in managing capital flows, and presents evidence on the effectiveness of these tools. We would like to briefly discuss these tools upfront: Interest rate corridor can be thought as a tool to smooth movements in the supply of foreign funds, and ROM as a tool to decrease sensitivity of equilibrium foreign exchange rate to movements in the supply. Under the interest rate corridor policy, the CBRT commits to an average cost of funding of the central bank to stay within a wide (and possibly asymmetric) corridor of borrowing and lending rates (rather than committing to a single policy rate within a narrow and symmetric band in open market operations). The upper and lower bounds of the corridor are determined by regular monetary policy meetings. The central bank ensures that the equilibrium money market rate falls within the corridor through open market operations. The degree of uncertainty about the likely level of equilibrium interest rate inside the corridor affects the volatility of return on Turkish lira assets and therefore the risk-adjusted return. Hence, as global risk perceptions change and supply of foreign exchange in Turkey responds to the global risk factors (the managed) uncertainty generated by the corridor can serve as another risk factor, and the corridor can be steered so as to smooth the movements in the supply of foreign funds. ROM, in contrast to the interest rate corridor policy, works through the demand for foreign funds. For domestic currency liabilities, banks are given an option of fulfilling their domestic currency reserve requirement by bringing in foreign instead of domestic currency (hence the term ROM).Footnote 10 The mechanism helps smooth movements in the exchange rate as follows. When risk appetite in the global financial markets rises, i.e. capital inflows surge, foreign funding is usually more favorable than domestic funding, and hence, banks would prefer keeping some of the extra foreign funds in the central bank rather than extending them to the economy. In case of capital outflows, i.e. a decrease in the supply, banks would prefer drawing down their reserve option at the central bank. This behavior then tilts down the demand for foreign funds, decreasing the sensitivity of equilibrium exchange rate to shifts in the supply. Accordingly, the mechanism decreases the volatility of exchange rate, and importantly, in a market friendly manner. Rest of the paper is organized as follows. Section 2 analyses financial stability in the theoretical literature and discusses the financial stability concerns related to capital flows. Section 3 explains the new monetary policy mix devised by the Central Bank of the Turkey to support financial stability, and explains the interest rate corridor and ROM. Section 4 discusses the effects of the new monetary policy tools on economic variables, and Sect. 5 concludes.",40
4.0,1.0,Eurasian Economic Review,30 July 2014,https://link.springer.com/article/10.1007/s40822-014-0004-3,Effects of additional monetary tightening on exchange rates,June 2014,Ergun Ermisoglu,Yasin Akcelik,Temel Taskin,Male,Male,Male,Male,"Before the 2008 global financial crisis, monetary policies exclusively focused on price stability across the globe while financial stability has been mostly faded into the background, and sometimes completely ignored. The crisis proved the inefficiency of the monetary policies conducted without considering financial risks and signified the need to observe financial stability along with price stability (Borio, 2011). To that extent, it was well understood that a policy rate that yields price stability may not necessarily provide financial stability. Therefore, it has become essential for central banks to utilize more than one policy instrument (Di Giorgio, 2014). Accordingly, since late 2010, the Central Bank of the Republic of Turkey (CBRT) has started to implement its new policy mix. In this framework, overnight (O/N) interest rates are adjusted according to the course of economic and financial developments without changing the weekly repo rates, i.e. the policy rate. In view of that, the CBRT has occasionally delivered Additional Monetary Tightening (AMT) in order to prevent temporary price movements from deteriorating the inflation outlook via expectations. On the days of AMT delivering, CBRT did not provide funding to the market via quantity auction method at the policy rate. Instead, it funded the market via market price based auctions, and hence, O/N rates settled close to the upper bound of the interest rate corridor.Footnote 1
 Additional Monetary Tightening is a unique tool designed to restrict liquidity supplied to the market so that volatility in the exchange rate does not pass through and deteriorate inflation expectations. Although there are studies about the impact of central bank interventions on FXFootnote 2 , to the best of our knowledge, this is the first empirical study on analyzing the effects of AMT on exchange rates. This study analyzes the effects of the AMT on exchange rates using Generalized Autoregressive Conditional Heteroskedastic (GARCH) models. We find that AMT is statistically significant in reducing the volatility of Turkish Lira. Moreover, our analysis shows that during the days of AMT, Turkish Lira appreciated against the other emerging market currencies. The remainder of the paper is organized as follows. Next section presents a brief review of the related literature. Section 3 details the new policy mix that the CBRT implemented. Section 4 gives details about the data and the methodology used. Section 5 shows the empirical results and Sect. 6 concludes the paper.",2
4.0,1.0,Eurasian Economic Review,08 August 2014,https://link.springer.com/article/10.1007/s40822-014-0005-2,The probability of default in Russian banking,June 2014,Alexander M. Karminsky,Alexander Kostrov,,Male,Male,Unknown,Male,"Achieving sustainable development of financial institutions has been at the forefront of the world agenda since the end of the recent economic crisis in 2008–2009. Prudent supervision of the banking sector is important to reach this goal. Russia ranks third in the number of banks, after the United States and Germany: there are about 900 operating banks in Russia. At the same time, the Central Bank of the Russian Federation (the Bank of Russia, CBR) lacks the necessary resources to organize regular field inspections of a large number of its banks. This is why the CBR needs a remote system to monitor the national-banking sector. The most vulnerable banks should be identified and properly supervised to improve banking sector stability. The probability-of-default (PD) model is a possible instrument to address this problem. The PD shows the likelihood of a bank failure over a fixed assessment period. This paper reviews binary choice models that attempt to describe, predict, and prevent defaults of Russian banks with regard to national banking sector peculiarities. We have used the experience of PD model creation for emerging economies, i.e., BRICS and Eastern Europe. The majority of the existing work on the Russian banking experience examines the collapse of the Russian banking system in 1998. However, the rules of the game and the economic environment have dramatically changed since that time. In addition, the PD model offers the advantage of being able to be utilized by other parties: banks, bank creditors and business partners. First, banks can use it to predict and prevent hardships. The model meets the requirements of Basel II and takes the dependence of credit risk on the business cycle into account. This can be exploited for internal financial monitoring in commercial banks. Second, information about a bank’s financial stability (its ability to survive in hard times and meet its financial obligations) is essential for bank creditors and business partners. The rest of the paper is organized as follows: The second section presents an overview of the Russian banking sector. Section 3 provides a brief literature review of PD-model development. Section 4 describes the database and sources used. Section 5 explains the methodology of PD model creation; a comparison of the derived model with alternatives is addressed, as well. Section 6 discusses the model estimation results. The final section contains a discussion and conclusions.",10
4.0,1.0,Eurasian Economic Review,30 July 2014,https://link.springer.com/article/10.1007/s40822-014-0003-4,Hedging China’s energy oil market risks,June 2014,Marco Chi Keung Lau,Yongyang Su,Zhe Zhang,Male,Unknown,,Mix,,
4.0,2.0,Eurasian Economic Review,22 January 2015,https://link.springer.com/article/10.1007/s40822-015-0013-x,"Modeling and forecasting Hang Seng index volatility with day-of-week effect, spillover effect based on ARIMA and HAR",December 2014,Yanhui Chen,Kin Keung Lai,Jiangze Du,Unknown,,Unknown,Mix,,
4.0,2.0,Eurasian Economic Review,11 November 2014,https://link.springer.com/article/10.1007/s40822-014-0009-y,Asset price volatility and financial contagion: analysis using the MS-VAR framework,December 2014,Chau Le,Dickinson David,,,Unknown,Unknown,Mix,,
4.0,2.0,Eurasian Economic Review,21 January 2015,https://link.springer.com/article/10.1007/s40822-014-0012-3,Hedging with mini gold futures: evidence from Korea,December 2014,Seokchin Kim,Cheolho Park,Youngjun Yun,Unknown,Unknown,Unknown,Unknown,,
4.0,2.0,Eurasian Economic Review,09 December 2014,https://link.springer.com/article/10.1007/s40822-014-0011-4,The impact of scale of operation on financial performance in microfinance,December 2014,Trong Vi Ngo,Andrew W. Mullineux,Anh Hoang Ly,,Male,,Mix,,
4.0,2.0,Eurasian Economic Review,11 November 2014,https://link.springer.com/article/10.1007/s40822-014-0010-5,The financial distress indicators trend in Italy: an analysis of medium-size enterprises,December 2014,Alessandro Zeli,,,Male,Unknown,Unknown,Male,"Recently the analysis of enterprises’ financial distress has become a study field of growing interest as a consequence of the economic crisis, driven by the disorder on financial markets (Popov and Udell 2010; Claessens et al. 2010; Bisogno 2012). Anyway it is important to give a historical perspective of the financial distress trend in order to better comprehend the real content of risk index systems, to study the behaviour of different economic sectors in relation to these systems themselves and to understand the framework of the present crisis. For these reasons this paper aims at detecting the different paths of enterprise financial distress risk over time according to the economic sector and the relationship with profitability. In particular we are interested in analysing the average risk failure trend of the Italian economy and its system of industries considering both sound and unsound firms. Hence this paper does not focus on calculating the probability of failure (or bankruptcy risk), but it aims at describing the trend of a set of financial distress indicators, calculated on a large micro-level database over the last two decades. This analysis intends to examine the trend of the distress indicators as a proxy of the average “state of health” of Italian firms. The paper covers, therefore, quite a large set of signals of distress possibility and considers a very large set of enterprises to represent the Italian manufacturing and service sectors. Moreover, although we want to obtain an “average” measure of the “early warning” of forthcoming company default or “state of health” of Italian firms, it is important to carry out an analysis sector-by-sector to have a representation of the diverse and particular trends of the different industries. In this paper we address some questions, such as: do the specific distress indicators of Italian firms differ according to different industries? How much and in which way? Is the trend of industry distress indicators influenced by the economic cycle, other relevant historical events or other factors? And, in particular, is it changing over the considered period regardless the economic cycle? Our analysis is based on the factorial methodology called Dynamic Factor Analysis (DFA). This work represents the first attempt to apply this methodology to bankruptcy risk calculation and it aims at detecting latent variables depicting the companies’ financial distress from 1989 to 2007. During this period the Italian economy has begun and then fully concluded a long process of integration with the other European economies. Until the end of 1989 the Italian currency (Lira) floated within the wider band of fluctuation of the European Monetary System (EMS), while from 1990 to 1992 it entered in a narrow one. In 1992, after a deep speculative attack and after a credibility crisis, due to the overvalued exchange rate, the Lira left the EMS. In 1992 Italy entered in the Single European Market (SEM) system and signed the Maastricht agreement on Economic and Monetary Union. According to this agreement the participant countries should have to match a series of economic targets in order to take part to the new planned Euro zone. From 1992 to 1998 Italian economic policy has been focusing on the respect of the Maastricht parameters and in 1999 Italy eventually entered in Euro zone. The time span from 1999 to 2007 can be considered as the Euro regular management period—the Euro economies passed successfully through the 2001 crisis and the slight recession in 2005. In 2008 the deep financial subprime crisis completely changed the scenario and the framework became absolutely different from that year onward. This is the reason why we choose to analyse the period 1989–2007 when Italy was involved in the EMS and in the Maastricht convergence process in a framework of growing rate of the trade openness that could have greatly influenced the profitability and the average distress index of economic sectors. In order to explain the firms’ financial distress risk, we considered a set of financial statement ratios, such as: leverage, liquidity measure and efficiency indicators. The elaboration of this ratios is based on the account data which represent the economic and financial features of a company. The target population, traced from 1989 to 2007, is represented by the Italian medium-sized enterprises (from 50 to 249 persons employed), which are the backbone of the Italian production system (Coltorti 2004). Moreover the analysis of larger enterprises may (most probably) be invalidated by the Government property, subsidies or by a different access to finance. Finally the medium enterprises give a less biased information on the actual financial distress of the economic operators.",3
4.0,2.0,Eurasian Economic Review,23 October 2014,https://link.springer.com/article/10.1007/s40822-014-0008-z,Young people and the digital divide in Egypt: an empirical study,December 2014,Mona Farid Badran,,,Female,Unknown,Unknown,Female,"The Digital Divide (DD) is a new phenomenon emerging alongside the development of Information and Communication Technologies (ICTs). The DD can be defined as “the gap between those with a permanent, effective access to new ICTs, and those with none” (e.g. Hoffman and Novak 2000, p. 2; Rice and Katz 2003; Fairlie 2004; Andonova 2006; Chinn and Fairlie 2007). Nevertheless, there may be other important dimensions of the DD, such as gender and geographic location (urban vs. rural communities), and these dimensions cannot be neglected. Accordingly, the OECD (2001, p. 5) defines the DD as “the gap between individuals, households, businesses and geographic areas at different socio-economic levels with regard both to their opportunities to access information and communication technologies, and to their use of the internet for a wide variety of activities.” Prior studies on the diffusion of ICTs have shown that disparities in ICTs diffusion may play a critical role in the propagation of knowledge, levels of political engagement, e-commerce growth, as well as economic growth (Ho et al. 2011; Norris 2001; Steinmueller 2001; Brynjolfsson and Hitt 2003; Wallsten 2005; Seo et al. 2009; Dosi and Nelson 2013; Vivarelli 2013). Developing countries have become aware of how essential it is to have a political strategy whereby the abovementioned effects can be eliminated in order to catch up with developed countries. Moreover, the ICT diffusion gap is found not only across different countries, but also within the same country, i.e. between urban and rural areas. According to the UNICT Task Force (2002), the digital divide between urban and rural areas in Sub-Saharan African countries is even greater than that found in the rest of the world; most of the telecommunication services and users are concentrated in cities and towns, while the majority of Africans are scattered in small communities spread out across vast rural areas. There is a very limited diffusion of telecommunications networks in rural areas. Often, over 75 percent of the country’s telephone lines are concentrated in the capital city and irregular or non-existent electricity supplies are a common feature and a major barrier to the use of ICT, especially outside major towns. The urban/rural digital divide is the main focus of the present study. In particular, the magnitude of this divide and its impact on the youth population is one of the research questions addressed in this study. As documented by leading international organizations (see, for instance, UNCTAD 2005), a better understanding of all aspects of the digital divide is essential to be able to implement adequate policy formulations. The processes involved in technology diffusion, emerging trends, and their magnitude can be important inputs for the design and implementation of public policies in both developed and developing countries. Table 1 displays the percentage of internet usage broken down into urban and rural areas, presented by the latest available date. The dominance of a negative gap measured as the difference between urban and rural internet usage should be noticed. This negative gap, i.e. the urban use of the internet being much higher than that of the rural use, reaches its highest value (−35.2 percent) in Morocco in 2010. Although Egypt has the same problem, it is not as acute, with the negative gap estimated at 16.5 percent. Surprisingly, a few countries such as Mauritius and Zambia suffer from the positive gap, where rural internet use is higher than that in urban areas; the average difference is approximately 1.75 percent. In 2004, 30 percent of the world’s population had 66 percent of the world’s GDP, 64 percent of the world’s PCs, and represented 58 percent of the world’s internet subscribers and 75 percent of broadband users. Despite the high level of these disparities, it is interesting to note that internet usage is experiencing a change in its trend toward inequality. In 1997, 93 percent of internet subscribers were concentrated among only a fifth of the world’s people (Kiiski and Pohjola 2002). With regards to the digital divide, little empirical research has been dedicated to addressing the issue of young people. Furthermore, primary analysis of the data obtained from the Survey of Young People in Egypt (SYPE) Population Council, 2011, emphasizes the existence of the rural/urban divide. The present research examines the source of inequalities in internet access and usage among young people in Egypt, using data from the SYPE Survey for the year 2009. The sample was restricted to individuals between 10 and 29 years of age, examining access and use of the internet by age, gender, and urbanization. To our knowledge, this is the first paper that includes micro-level data about the access or use of ICTs in Egypt, using the composite index of DD. This study also provides a number of innovative elements: (1) the construction of the ICT composite indices for Egypt: the Digital Divide Index (DDI) measuring the urban/rural DD among youth in Egypt based on the SYPE; and (2) an evaluation of the findings in light of the DD in order to provide appropriate policy recommendations on how to address the inequality between urban and rural areas in Egypt. The DDI is constructed from those questions in the SYPE survey addressed to young individuals about access to and use of internet, mobile phones, fixed-line phones, personal computers and laptops. A critical motivation of the present study is the importance of including the young population, especially rural youth, in the knowledge-based economy. This is important given the fact that over 76 percent of youth in Egypt reside in rural areas (42.6 percent in Lower Egypt, and 34.2 percent in Upper Egypt), while urban governorates contain just over 20 percent of young people (Population Council 2010). Accordingly, investigating the DD and examining whether urbanisation is an impediment to the participation of youth in the new paradigm of the knowledge- based economy, is an important contribution of the present study. Our findings show that urbanization is positively correlated with the DD composite indicator. Urbanization is associated with structural change where the share of the agricultural sector in the economy decreases, and both manufacturing and services sectors’ shares increase. Urbanization is a critical phenomenon, since by 2030 about 60 percent of the global population will live in urban cities. The urban context includes proximity, diversity, density, dynamics and complexity (Beall et al. 2012). Migration is one phenomenon associated with urbanization. Migration has to be viewed as a process not a problem, and policy interventions must be formulated accordingly. Migration is also associated with increases in transaction costs. The complexity of this phenomenon is due to the fact that it is a multidisciplinary process, which includes economics, sociology and political science. This migration process, together with other factors, deepens the divide between urban and rural areas, and further negatively impacts the DD globally, and Egypt is not an exception to this rule (Beall et al. 2012). The remainder of this paper is organized as follows. The following section describes the evolution of the ICT sector in Egypt. Section 3 discusses the empirical literature on the digital divide Index. Section 4 presents the data and outlines the empirical model. Section 5 discusses the main empirical findings, and Sect. 6 concludes with some policy recommendations.",6
5.0,1.0,Eurasian Economic Review,10 April 2015,https://link.springer.com/article/10.1007/s40822-015-0015-8,"Analyst coverage, syndicate structure, and loan contracts",June 2015,LiuLing Liu,,,Unknown,Unknown,Unknown,Unknown,,
5.0,1.0,Eurasian Economic Review,25 April 2015,https://link.springer.com/article/10.1007/s40822-015-0017-6,Excess premium offers and bidder success in European takeovers,June 2015,Wolfgang Bessler,Colin Schneck,,Male,Male,Unknown,Male,"For European takeovers, we study the valuation effects of bidder and target firms that result from offering an “excess” takeover premium and analyze the probability of deal completion and the occurrence of takeover contests for “excess” premium offers, expecting unique results and new insights. Our sample consists of 1437 successful and unsuccessful takeover attempts for European target firms for the 1990–2012 period. Traditionally, takeover premiums are determined as the difference between the offer and the target share price, divided by the target share price before to the announcement. However, several studies, provide evidence that takeover premiums differ between industries, countries, and periods (Madura et al. 2012), and that bid characteristics as well as industry and macroeconomic factors are important determinants. Additional premium size determinants are cross-country variables affecting deal characteristics (Rossi and Volpin 2004), the method of payment in that usually stock deal offers are higher than cash deal offers, and hostile and cross-border deals are also associated with higher premiums (Schwert 2000; Bris and Cabolis 2008; Eckbo 2009). Most importantly, premiums presently offered in the US are highly correlated with premiums paid in recent deals and for current deals (Madura et al. 2011; Madura and Ngo 2008). The objective of our study is to analyze whether the method used for calculating the premium has any effect on the empirical results. Because some empirical studies report substantial premium differences between industries and over time and others suggest an array of premium determinants, we conjecture that it is challenging to derive a coherent framework for analyzing and explaining premium size differences when using the standard premium measure. Moreover, traditional measures do not indicate whether a premium is relatively high or low. Therefore, we introduce a new “excess” premium measure that we define as a premium that is higher than the “expected” premium, which we derive from recent comparable deals. This new “excess” premium allows us first to identify relatively high or low premium takeover bids and then to analyze the subsequent valuation effects and success of European takeovers. For this, we split our sample into two groups, one containing the bidders making “excess” premium offers and the other one containing the non-“excess” premium bidders. Our empirical results suggest that target announcement returns are higher for “excess” premium offers. Another intriguing and significant finding is that bidders are better off in completing a deal regardless of whether they pay an “excess” premium or not. Moreover, bidders failing to acquire the target experience significant negative long-run valuation effects, which is consistent with the results of Antoniou et al. (2008) for an UK takeover sample. Hence, an important aspect to explore is whether offering an “excess” premium increases the likelihood of being successful. Based on our multivariate results, we find support for this hypothesis, which suggests that bidders, on average, benefit when paying an “excess” premium and increase the probability of completing the deal. One explanation for this empirical finding is that different bidders forecast and expect different benefits or synergies from an acquisition, depending on their own strengths and weaknesses. These factors should determine the maximum premium that bidders are able and willing to offer. Following this idea, mergers and acquisitions (M&As) can be viewed as large capital budgeting projects, which have a high likelihood of being successful in the long-run if they represent positive net present value projects. Consequently, premiums could be higher if the target provides the bidder with a competitive edge or other benefits (Akdoğu 2009). We also find that the probability of offering an “excess” premium increases when the bidder uses stock as a method of payment and in deals with bidder competition. For cross-border deals, this issue is more complex. We also find that “excess” premiums are more likely if the bidder is large and the target is small and rather overvalued. Interestingly, at the announcement date capital market participants, on average, are not able to distinguish or correctly anticipate whether an offer will be successful or not. The rest of this study proceeds as follows. In Sect. 2, we provide a brief review of the literature on bidder and target performance, the determinants of deal completion, and the occurrence of takeover contests. We present the data and outline the methodology in Sect. 3. In Sect. 4, we discuss the results of the “excess” premium measure and the bidder and target performance effects as well as our multivariate results on the likelihood of deal completion, and competition. Finally, Sect. 5 concludes.",5
5.0,1.0,Eurasian Economic Review,30 April 2015,https://link.springer.com/article/10.1007/s40822-015-0024-7,R&D spillovers and information exchange: a case study,June 2015,Klaus Kultti,Tuomas Takalo,Tanja Tanayama,Male,Male,Female,Mix,,
5.0,1.0,Eurasian Economic Review,17 April 2015,https://link.springer.com/article/10.1007/s40822-015-0021-x,Political uncertainty and non-pricing terms of financial contract,June 2015,Yun Zhu,,,,Unknown,Unknown,Mix,,
5.0,1.0,Eurasian Economic Review,28 April 2015,https://link.springer.com/article/10.1007/s40822-015-0018-5,Political regimes and stock market development,June 2015,Bill B. Francis,Eric Ofori,,Male,Male,Unknown,Male,"Recent empirical evidence has shown that stock market development promotes economic growthFootnote 1. In this chapter we seek to gain an understanding of the impact of cross-country differences in political institutions on stock market development. Numerous studies have found that financial markets develop in the presence of strong shareholder protection, secure property rights, and respect for the rule of law. This argument is not farfetched as the degree of protection received by investors determines the extent of their willingness to finance firms. La Porta et al. (1998, 1999) emphasize the role of legal origins for financial development; they argue that commercial laws “are not written from scratch” but are “transplanted—voluntarily or otherwise” from a few set of legal families—English common-law, French civil-law, German civil-law, and Scandinavian civil-law. They report that investors have more protection under English common-law than French civil-law with Scandinavian and Germanic falling in-between. Therefore, according to the legal origins theory common-law systems should have better developed financial markets compared to civil-law systems. This stems from the reasoning that civil law systems codify and are thus prone to excessive regulation compared to the common-law system. In other words, it is the legal origin that determines the rights and protection of investors and consequently affects a nation’s level of financial development. A moment’s reflection reveals weaknesses in the legal origins doctrine in explaining a country’s level of financial development. Indeed, Rajan and Zingales (2003) report that in 1913 France with a civil law code had better developed financial markets than the United States with a common-law code—the stock market capitalization to GDP in France was almost twice that of the United States—debunking the legal origin premise that civil law provides less protection for minority investors. Roe (2006) also presents explanations outlining the shortcomings with the legal origins argument. He points out that legal origins theory does not explain why for example, Britain with a common-law system experienced financial development similar to Switzerland—a civil law country over the last half-century. His argument is that civil-law countries experienced the 20th century differently compared to the common-law countries. Over the period from 1913 to 1945, he argues, France, Germany, and Japan, experienced major wars which made investors more risk averse to investing in financial markets leading to more stock market regulation by policy makers. La Porta et al. (1998, 1999) also report on the concentration of ownership of shares to be negatively correlated to the level of investor protection in the largest public companies and they argue persuasively that this relationship is due to the lack of investor protection stemming from the lack of legal enforcement. One can however argue that the concentration of ownership is a function of corporate governance standards which is a function of the political conditions prevailing in the economy. Pagano and Volpin (2005) argue that politics is the channel connecting legal rules to economic outcomes. We can infer from these arguments that political institutions play a vital role in determining the level of financial development. In this paper we develop a framework for understanding the role of political regimes for stock market development. The primary goal is to examine how variations in political regimes matter for stock market development. As stated by Gourevitch and Shinn (2005, p. 14): “Politics drives regulations, and regulations shape corporate governance patterns, which then protect or abuse investors”. Politics can influence the penalty for managerial misbehavior, auditing standards as well as how and when information is disclosed to shareholders—especially in situations where government cronies are likely to be serving as corporate board members. Keefer (2007) writes that “political checks and balances are a robust-determinant of financial sector development” (page 3). The political landscape thus motivates the enforcement of security laws and consequently the development of financial markets. Intuitively, weak political institutions are expected to stymie stock market development while on the contrary strong political institutions are expected to enhance financial development. The terms weak and strong might be ambiguous, however; for example, how should one characterize a leader such as Deng in China, who is committed to financial market development? As suggested by Alesina et al. (1996) there are two kinds of dictators—technocratic dictators, who are fixated on economic growth, and kleptocratic dictators who are on the opposite end of the spectrum and have their countries mired in economic quagmire. Essentially, the corporate finance and political economy literatures are not clear on how political institutions mesh with stock markets to foster economic growth. The widely held view however is that democracy generates accountability which helps to promote investment. In Sect. 2 we discuss the related literature on politics and finance. According to Wurgler (2000) the efficiency of capital allocation in an economy is negatively correlated with the extent of state-ownership. He argues that in state-owned firms the allocation of resources is guided more by political motives rather than by value-maximization. Morck et al. (2000) in their study on stock price movements report weak country level governance to be actually positively correlated with stock price synchronicity. They write: “Asset values are predominantly affected by political connections and events” (page 242). Despite previous studies recognizing the role of the state in financial development there are still open questions. Specifically, what political arrangement best promotes stock market development? What is the impact of a young democracy on stock markets? Though it is agreed that stock markets are de rigueur for economic growth, extant research has not yet addressed what factors matter for stock market development. This article seeks answers to these questions. The welfare implications of stock market development cannot be overstated. When stock markets are developed firms can raise more external financing; and can finance more positive NPV projects. Sylla (1998) argues that the development of the U.S. financial system in the 1790s jump started the U.S. economy to what it is today—he writes that improvements in the financial system preceded factories, canals, and railroads, all of which played an integral part in the U.S. industrial revolution. Boyd and Smith (1998) and Demirguc-Kunt and Maksimovic (1996) among others, report on stock markets having a complementary effect on the banking sector. Stock market development also affects managerial discipline and the cost of monitoring. It allows markets to discipline underperforming managers through takeovers. In Sect. 3 we develop our testable hypotheses. Our results do not support our first hypothesis that established democratic regimes have better developed stock markets than other regime types. However, support is found for our second hypothesis, indicating that for a newly established democracy the link between political regimes and stock markets is J-shaped. We elaborate on these issues later in the discussion of our results. The data which is discussed in Sect. 4 consist of a panel of 101 countries. The data have three main advantages. (1) It has a longer time series compared to most related work; it spans three decades—from 1980 to 2009. (2) It has a broader panel of countries at different stages of development: developed, developing, and transition economies. (3) It encompasses fairly recent years. With these advantages we are better able to address the impact of political regimes on stock market development. Also our sample of stock markets unlike a number of previous studies includes not only developed and emerging markets but also includes several frontier markets. Our findings and empirical analyses are therefore generalizable and broaden the scope of the scholarship on politics and finance. The article closest to my work is Huang’s (2010). He also examines the relationship between political institutions and financial development. However, his focus is on how improvements in political institutions affect financial development. Specifically he looks at how democratizations affect financial intermediation. I extend this work by including other political regimes—not only new democratizations. Also, my focus is on stock markets. The role of political regimes for stock market development is still not well understood. Understanding this issue is important as a number of countries especially developing and transition economies have accepted multiparty democracy at various levels. At the same time several of these countries on a quest for long-run economic growth have established stock markets. The endeavor pursued in this paper is therefore of particular significance. A good understanding of these issues can help multinationals better manage the risk they face abroad. Our empirical results outlined in Sect. 5 document that political regimes impact the size of security markets but not the degree of liquidity; there is no statistically significant difference in the volume of shares traded on stock markets between autocracies and non-autocracies. I find strong support for Rodrik and Wacziarg’s (2005) result that democratic transitions do lead to positive economic outcomes. Though the link between a new democracy on financial development is negative over the period 1990 to 1999, the relationship turns positive from 2000 to 2009, indicating that as democracies mature there is less uncertainty toward investment. This finding also goes against the view that a new democracy is likely to function like the typical autocrat (Clague et al. 1996). In essence, the effect of democracy on financial development is J-shaped. This is consistent with Papaioannou and Siourounis (2008) who report the effect of democracy on economic growth to be J-shaped. Though the data indicate that stock markets in established democracies are more developed compared to other regime types; we do not find statistically significant evidence that political rights matter for stock market development in established democracies. We attribute this finding to an increase in bureaucracy which is usually the hallmark of a democratic environment. The data also reveal that military leadership has a negative effect on financial development. Section 6 completes the paper with a discussion of our conclusions and an agenda for future research.",12
5.0,1.0,Eurasian Economic Review,14 April 2015,https://link.springer.com/article/10.1007/s40822-015-0019-4,Financing activities after accounting restatements: an examination of SEOs and PIPEs,June 2015,Kose John,Joe Z. Shangguan,Ravi S. Mateti,Unknown,Male,,Mix,,
5.0,1.0,Eurasian Economic Review,09 April 2015,https://link.springer.com/article/10.1007/s40822-015-0020-y,Institutional investors and conservative financial reporting: evidence from China,June 2015,Yue Chen,Lingxiang Li,Peng Wang,,Unknown,,Mix,,
5.0,1.0,Eurasian Economic Review,05 May 2015,https://link.springer.com/article/10.1007/s40822-015-0023-8,Distribution strategy and movie performance: an empirical note,June 2015,Rocco Ciciretti,Iftekhar Hasan,Maya Waisman,Male,Unknown,Female,Mix,,
5.0,2.0,Eurasian Economic Review,19 May 2015,https://link.springer.com/article/10.1007/s40822-015-0025-6,Better governance matters optimal privatization policy,December 2015,Leonard F. S. Wang,Tien-Der Han,,Male,Unknown,Unknown,Male,"The World Bank’s concise report on reducing the inefficiency of public firms (Nellis 1994) systematically analyzed the positive effects of improved governance in public firms and the concurrent need for privatization. By 1994, the world had already seen a wave of privatization for more than a decade. In the past 20 years, the impact of better governance has invited much scrutiny in the field of finance (Shleifer and Vishny 1997) and management (Coles et al. 2001),Footnote 1 but it has drawn relatively little attention in economics. A public firm most often needs reform because of its inefficiency. Inefficiency of public firms may overshadow the possible benefits of the public ownership, consequently motivating the privatization of public firms and the entry of profit-maximizing private firms to compete against a welfare-maximizing public firm. Improving the efficiency of public firms has been a concern in Western Europe since the late 1970s. Unlike poorly managed and operated public firms, private firms in many oligopolistic industries show better governance because of their focus on corporate governance, especially when faced with highly intense competition. Corporatization and privatization of public firms are often seen as two effective ways to improve their governance. Both privatization and corporatization are policy tools that help increase autonomy in such matters as staffing and the financial management of public firms (Aivazian et al. 2005). By raising their autonomy, governments hope to strengthen governance in public firms, boost their efficiency, and eventually enhance social welfare. Corporatization is the process by which a public firm acquires the ability and flexibility to operate more effectively. Such a process is not necessarily brought by a change of ownership but more by a process of institutional reform (Aivazian et al. 2005) that reduces the possibility of shirking responsibility and even rebuilds the corporate culture or reconstructs the board of directors (Vagliasindi 2008a, b).Footnote 2 Syriopoulos and Tsatsaronis (2012) empirically elaborated how the structure of board of directors affects the financial performance of a privately owned firm. Owing to the rigidity of public firms, it is usually more difficult to make adjustments properly in a timely manner. These problems become manifest in such symptoms as poor service, weak profitability, and inefficient employees. Corporatization offers a way out as a corporatized public firm is better placed to modify its operating structure so that the working environment encourages managers and employees to meet expectations. Choudhury and Khanna (2009) were able to verify this empirically. This paper distinguishes between the concept of “general motivation” and “managerial delegation” used in industrial organization research.Footnote 3 Managerial delegation focuses primarily on incentivizing managers such as bonuses and revenue sharing, but enhancing the overall efficiency of employees is the purpose of this paper, which differs from the focus of managerial delegation. Managerial delegation deals with modalities that motivate managers to pursue what firm owners want whereas “general motivation” deals with the general upswings of worker efficiency in daily operations. In other words, the manager of a firm is key to the whole idea of delegation, whereas all employees are key to the idea of corporatization. Above all, “managerial delegation” is often associated with reducing production costs, increase of sales or market share, which becomes part of a manager’s financial incentive to chase what the owner wants. On the other hand, “organizational reform” is a series of modifications to the motivations that make employees work more efficiently.Footnote 4 In short, “corporatization” does not add to the cost but keeps its employees from shirking their responsibilities and encourages them to boost their capabilities so that every task needs fewer workers or less time to complete. The World Bank supports this viewpoint.Footnote 5 According to the World Bank, corporatization is a series of approaches that raises worker efficiency. Such an approach involves a clear definition of responsibilities and processes, and clear policies on promotions based on meritocracy and on building a positive corporate culture. The privatization of a public firm is another way to enhance its performance. The pure pursuit of profits is an extreme method with the drawback of failing to fulfill the original responsibility of nationalized firms, which can cause the detriment of social welfare (De Fraja and Delbono 1989). Therefore, following Matsumura (1998), partial privatization offers a way to balance the efficiency improving of public firms and social welfare.Footnote 6 Matsumura and Kanda (2005) pointed out that while partial privatization was the optimal policy in the short run, the best policy choice in the long run was full nationalization. Many people have studied partial privatization ever since (Brandão and Castro 2007; Fujiwara 2007). However, it was not until Wang and Chen (2010) that an open economy, a free-entry market, and an efficiency gap among public and private firms were considered.Footnote 7 They unveiled that in the long run, the best policy in an open economy with domestic free entry and an efficiency gap was always partial privatization. Adopting a more generalized perspective, Okuguchi (2012) offered a general model on mixed Cournot oligopoly with partial privatization using a general inverse demand function and a firm’s cost function to show the optimality of partial privatization as well as the stability and existence of its unique equilibrium. Although Matsumura (1998) focused on the policy of privatization, his model’s policy implications went beyond that. Recall that in Matsumura’s model, the objective of a partially privatized firm comprises social welfare and profits whereas a fully public-owned firm pursues only the maximization of social welfare. If a firm is fully public-owned, it is merely dealing with the issue of welfare maximizing, meaning that to the public firm the market competition is not intense. On the contrary, when a firm wants to make profits, there will naturally be a strong incentive for it to reckon with the fluctuations of the market. The transformation from a welfare-oriented firm to a somewhat profit-oriented one implies the change within the firm. This change can also come with corporatization. According to the OECD’s hearing report (2010), though public firms create some problems, improved corporate governance and effective competition policy can bring efficient outcomes. However, studies on privatization have not explained how governance improving affects the effects of privatization during this process.Footnote 8
 Therefore, what has not been clarified in the literature is that the success of privatization hinges on the mutual complementarities between privatization and corporatization. Actually, just one year after Matsumura (1998), the enriching inferences of his model were echoed and verified empirically. Based on the empirical research, ShirleyFootnote 9 (1999, pp. 115) proposed that “… countries which improved state-owned enterprise performance the most followed a comprehensive strategy of reforms, including (a) combination of privatization and corporatization.” This paper sees corporatization as a process of internal structural change. This perspective, we believe, is missing in the literature on privatization. The rationale for transformation from a social welfare-maximizing firm to a profit-oriented is corporatization. Moreover, the viewpoint that this transition is not related to the costs incurred or to further investment was not only theoretically implied by Matsumura (1998) but also empirically evidenced by Aivazian et al. (2005, pp. 25): “our results also showed that corporatization had no impact on SOE investment levels; that the potential source of the efficiency delivered by corporatization could be from the change in the internal governance system of these enterprises.” Therefore, the importance of the issue discussed in this paper stems from efforts aimed at improving governance and the policy collaboration on corporatization and privatization. Reform of public firms sometimes triggers a dilemma for a government, since a government desires to alleviate the inefficiency of public firms and at the same time maintain social welfare. Many real-world cases show that corporatization can be a feasible solution. A classic case of the success of corporatization is the institutional reform of public hospitals implemented in New Zealand during the 1980s (Duncan and Bollard 1992). The strongest contrast between a non-corporatized public firm and a corporatized public firm is that provided by the Taiwan Railways Administration and the Taipei Metro Corporation. The Taiwan Railways Administration, which is a non-corporatized public entity, has been responsible for both management and operations for decades. Unfortunately, its ticketing system and consecutive financial losses are constantly criticized and train delays are a routine occurrence.Footnote 10 In contrast, the service of the Taipei Metro Corporation is much better. It is profitable and efficiently operated and, in many respects, is better than the Taiwan Railways Administration. Corporatization is one way to improve the governance and this is often seen in the reform of airports (Carney and Mew 2003; Gillen 2011),Footnote 11 railways, and hospitals whereas the policy of full privatization is sometimes not very successful.Footnote 12 It is not difficult to see that if privatization was indeed the panacea it was made out to be, there would not have been such overwhelming debate about it (Cavaliere and Scabrosetti 2008). Fundamentally, both privatization and corporatization are policy instruments to improve the operational efficiency of public firms, and ensure that the ultimate goal of raising social welfare is reached. In the following analysis, the policy of improving governance is examined in the context of a public firm being privatized. Furthermore, to reckon with the problem of employees shirking responsibility, this paper adopts the concept of efficiency of a firm given by Maiti and Mukherjee (2013). They detailed a method of defining governance in the economic sense. The remainder of this paper is arranged as follows. Section 2 describes the model, and analyzes the results. Section 3 briefly analyzes a scenario in which a public firm is as efficient as the private firm. Section 4 concludes the paper.",7
5.0,2.0,Eurasian Economic Review,03 September 2015,https://link.springer.com/article/10.1007/s40822-015-0034-5,"Privatization, intermediation and performance: global evidence",December 2015,Doug Dyer,Majdi Anwar Quttainah,Pengfei Ye,Male,Male,Unknown,Male,"This study examines whether the privatization of state-owned banks improves performance. Roughly speaking, over 300 commercial banks have been fully or partially privatized by the governments of 60 countries, either privately through asset sales (AS), or publicly through public share offerings (Megginson 2005). Despite this large number of privatized banks, empirical studies on bank privatization are relatively scarce, and the literature on this area is still being established. Researchers are particularly interested in whether privatized banks are more efficient than non-privatized banks.Footnote 1
 In addition to the privatization effect, two additional issues are often raised in the nascent literature. The first issue considers whether the full privatization outperforms the partial privatization. Clarke et al. (2005) argued that performance improves less following privatization when the government retains partial ownership of the privatized bank. We conjecture that this reduced improvement may be due to the fact that continued state-ownership allows politicians to exploit banks for their own purposes. Next, the type of privatization may affect the performance. Clarke et al. (2005) suggested that the approach of share issue privatization (SIP) results in dispersed ownership, while AS privatization displays more concentrated ownership. They suggest concentrated ownership is better than dispersed ownership, implying that the AS privatization outperforms that SIP. This is probably because that concentrated ownership creates larger incentives than the dispersed ownership to monitor managers and correspondingly minimizes the information asymmetries. While the number of studies addressing these issues is increasing, previous studies frequently confronted two challenges in methodology. First, the privatization may be endogenous. If high quality state-owned banks are especially prone to privatization, it would not be surprising to find superior performance after privatization. Therefore, studies assuming that privatization is exogenous may suffer a self-selection bias. We adopt Heckman’s (1979) two-step method to overcome this problem. Second, comparisons between privatized banks and non-privatized banks should share similar characteristics to avoid the effects of contamination by other factors. That is, a privatized bank that has certain characteristics, such as large asset sizes and low loan to deposit ratio, should be compared with a non-privatized bank with equivalent characteristics. These two challenges indicate that privatization should be a random process to avoid endogenous problems and problems relating to different bank characteristics.Footnote 2
 The aim of this study is to investigate the above three issues—the simple privatization effect, full versus partial privatization effect, and AS versus SIP privatization effect—by using both matching method and Heckman two-step estimation. The matching theory reestablishes the conditions of a randomized experiment where the randomization mimics a treatment. Thus, privatized and non-privatized banks are also termed treated and controlled banks, respectively. The basic concept of matching theory is that when making a comparison, the treatment sample (i.e., privatized bank) should have similar characteristics to the controlled sample (i.e., non-privatized banks). Provided the samples share similar characteristics, they can be considered to be randomly sampled, with the resulting difference between two matched observations representing the treatment effect (see Rubin (1973) for details). In addition to using matching theory, our study differs from the earlier ones in the following aspect. Past studies typically select a limited number of countries to examine their issues, which may create the sample selection problem. To ensure that the four privatization effects found in different countries is not due to the sample selection, we collect worldwide 110 privatized banks headquartered in 43 countries for the longest sample period 1993–2007. To the best of our knowledge, our study is the most comprehensive collection of privatized banks. This provides a systematic and more reliable investigation for this issue. Earlier studies use only a subsample of developing countries: Bonin et al. (2005) use eight countries and 29 privatized state-owned banks, and Boubakri et al. (2005) study the post-privatization performance of 81 privatized state-owned banks in 22 developing countries. The use of the more comprehensive data set and matching theory provide more robust results. Employing the comprehensive data and matching theory, our results confirm the existence of the privatization effect, on average. Also, our results find that the AS privatization is not always defeated against SIP privatization. This conclusion also applies to the full versus partial privatization. While some of our results are largely similar to those using case studies, the systematic study provides more reliable and robust results. The remainder of this paper is organized as follows. Section 2 then discusses the implication of our three hypotheses. Section 3 then discusses the matching methodology and its application. Subsequently Sect. 4 presents the empirical results. Section 5 then concludes the paper.",2
5.0,2.0,Eurasian Economic Review,10 April 2015,https://link.springer.com/article/10.1007/s40822-015-0016-7,Trade-off between financial sustainability and outreach of microfinance institutions,December 2015,Mira Nurmakhanova,Gavin Kretzschmar,Hassouna Fedhila,Female,Male,Unknown,Mix,,
5.0,2.0,Eurasian Economic Review,03 July 2015,https://link.springer.com/article/10.1007/s40822-015-0026-5,What makes banking crisis resolution difficult? Lessons from Japan and the Nordic Countries,December 2015,Michael Diemer,Uwe Vollmer,,Male,Male,Unknown,Male,"During the recent financial crisis, authorities intervened massively in the banking sector. They provided liquidity assistance as well as equity capital for distressed financial institutions, often in order to reduce the social costs of bank failures. In many cases, such financial assistance resulted in rising public budget deficits, which indicated a trade-off between stabilizing the banking industry and maintaining sound public finances. In some European countries, such as Ireland and Spain, bank bailouts even forced governments to ask for financial assistance from the European Union and the International Monetary Fund (IMF), showing that a banking crisis can often only be solved at the expense of an increasing risk of a sovereign debt crisis (Acharya et al. 2011). While it is important, the fiscal burden is not the only dimension of a crisis resolution. When reacting to a banking crisis, regulators must also take into account the impact of their actions on social costs in terms of GDP loss and the consequences of their actions for future risk-taking behaviour of banks. Unfortunately, the relationship between fiscal burden, GDP growth, and bank risk-taking incentives is not clear-cut. The appliance of a cheap crisis resolution tool, such as granting guarantees, might not always be efficient from a risk (moral hazard) point of view. Therefore, policy-makers have to make preferences with regard to the effects of resolution packages. This may not always be easy. In addition to conflicting goals, regulators may also face difficulties in implementing their preferred bailout policies. Such difficulties may result from transaction costs and coordination problems among authorities, such as sub-optimal allocation of responsibilities, and commitment problems. Against this background, the aim of this paper is to identify which specific difficulties authorities face when choosing and implementing crisis resolution packages.Footnote 1 We review the literature on the effects of crisis resolution measures and analyse resolution paths in past crises. We ask three interrelated questions: Which trade-offs and obstacles do policy makers face when resolving a banking crisis? How did these difficulties shape the course of past banking resolutions, and what were the impacts of these instruments on moral hazard and fiscal costs? What lessons can be learnt from these experiences for future crisis resolutions? We use the case-study method which allows us to cover contextual conditions. This approach is appropriate whenever the phenomenon studied and its context are not always distinguishable and when circumstances are highly pertinent to the phenomenon of study (Yin 2003). This is, in particular, the case during a financial crisis when policy decisions which are made reflect potential conflicts of interest between different regulatory agencies or mirror potential opposition of groups with different vested interests against single rescue packages. As the present crisis is still persisting and repercussions from the ongoing sovereign debt crisis on bank failures are still possible, we do not choose the current crisis resolution as the main subject matter for our present study; rather, we consider completed crisis resolution episodes which, however, should also not date back too far in the past. We thus take the 1990s as our preferred period of observation. We choose Japan and the Nordic countries as the subject matters for the following reasons: Firstly, both regions have suffered from the most serious financial and economic crisis experienced by advanced market economies since WWII. Secondly, economic crises in both regions came after a period of financial liberalization and happened within similar institutional contexts with great affinities to current circumstances; this allows us to transform some of the lessons learnt from past episodes to the current crisis. Finally, policy reactions are evaluated differently in the literature. While Japan is typically regarded as an example of a failed banking crisis resolution (Allen and Gale 1999; Kanaya and Woo 2000; Fujii and Kawai 2010; Hoshi and Kashyap 2010), crisis resolution in the Nordic countries is generally considered as successful, in particular in Norway and (less) in Sweden and Finland (Ingves et al. 2009; Jonung 2009). This paper proceeds as follows: Sect. 2 reviews the literature on the effects of banking crisis resolutions on banks’ risk-taking, on direct fiscal/social costs, and on the policy trade-offs for politicians; moreover, it discloses restrictions which policy-makers face when resolving banking crises. Section 3 turns to the two regions under consideration and asks why particular instruments were taken and examines how political conflicts shaped crises resolution processes. Section 4 reassesses the crisis resolution packages applied during the recent financial crisis in light of the experiences made in Japan and the Nordic countries during the 1990s. Section 5 concludes this paper.",6
5.0,2.0,Eurasian Economic Review,31 July 2015,https://link.springer.com/article/10.1007/s40822-015-0030-9,Optimal output for the regret-averse competitive firm under price uncertainty,December 2015,Martín Egozcue,Xu Guo,Wing-Keung Wong,Male,,Unknown,Mix,,
5.0,2.0,Eurasian Economic Review,23 April 2015,https://link.springer.com/article/10.1007/s40822-015-0014-9,Can tax simplification help lower tax corruption?,December 2015,Rajul Awasthi,Nihal Bayraktar,,Unknown,Female,Unknown,Female,"The tax administration of a country plays a central role in raising much needed revenues to finance government expenditures. No state can exist without taxes. In today’s world taxes go beyond merely raising revenues; they signify the “fiscal contract” between society and its government, the so-called “price for civilization” (attributed to Holmes 1904). The willingness for people of a country to pay tax relates very strongly with their identification with the state as citizens of the country they live in.Footnote 1 This intrinsic willingness to pay tax—also referred to as tax morale—is higher where taxpayers have more confidence in the integrity of government, and more specifically, the integrity of the tax administration. Therefore, a corruption-free tax administration is the basis for establishing good governance, the foundation on which a strong fiscal contract can be built, and determines the extent to which people are happy to voluntarily comply with their tax duties. Intuitively, there is an understanding that complexity of the tax system gives rise to corruption: the more complex a tax regime, the greater the opportunity for corruption. Complexity in tax law leads to opportunities for multiple interpretations of tax statutes, giving rise to incentives for choosing the lowest-tax options. Whether a tax official accepts the low-tax interpretation or not is at their discretion. Given that significant monetary stakes could be involved, this provides rent-seeking opportunities to tax officials. But, even at a more basic service-delivery level, tax corruption from complexity can arise. Complex declaration forms, high costs of compliance, and intricate compliance procedures may provide rent-seeking opportunities to tax officials that “facilitate” tax compliance for a “fee”.Footnote 2 Both these types of complexity exist in varying degrees in tax administrations around the world, but typically in developing countries with low levels of “maturity” of tax administrations, complex tax administrations abound. And, consequently, corruption in tax administrations is seen as a serious problem in developing countries, with a detrimental impact on tax collections, and on tax morale. This paper attempts to answer the question of whether or not there is empirical evidence that would link tax complexity and corruption in tax administrations. In the literature, there are several studies investigating the link between tax corruption and taxesFootnote 3 and also the link between tax complexity and taxes.Footnote 4 But, there are only a very limited number of empirical studies on the relationship between tax corruption and tax complexity which can be considered as an important component of the transmission mechanism between tax complexity and taxes. None of these studies on tax corruption and tax complexity involve a cross-country dimension. For example, Obwona and Muwonge (2002) and Kasimbazi (2003) find tax complexity and lack of transparency leads to tax corruption in Uganda, but focus only on one country in their analysis. In this paper, tax corruption is measured directly by using firm-level data from 104 different countries. Given data availability, we focus only on business taxes (corporate taxes, value added tax, and labor taxes) and exclude personal income tax. The main data source is the World Bank’s Enterprise Survey (ES) Database. The dataset covers the years from 2002 to 2012. Tax complexity is measured with two alternative variables: time to comply with tax requirements and the number of tax payments, both of which are from the World Bank’s doing business (DB) database. In this paper we try to identify empirical determinants of tax corruption, including tax complexity indicators, through different regression analyses. In the benchmark regression specification, tax corruption is the dependent variable, while tax complexity indicators and control variables are included as independent variables. The control variables include political and institutional determinants of tax corruption, as well as judicial determinants. A GMM technique is applied to investigate the impact of these variables on tax corruption due to the possibility of an endogeneity problem. The regression findings support the existence of a strong link between tax corruption and the indicators of tax complexity. After obtaining the estimated coefficients, different simulations are run to understand the economic significance of the tax simplification variables on tax corruption. The results show that while a 10 % drop in the number of tax payments leads to an approximately 4 % cut in tax corruption, the same amount of decrease in the hours to comply with tax requirements reduces tax corruption by 6 %. The combined effects of the two tax simplification variables (10 % cuts in both variables) are predicted to be even stronger, leading to a 9.6 % cut in tax corruption. To check for robustness, regional differences and the income level of countries are controlled. We find that tax corruption responds more to the changes in the tax simplification variables in the Latin America and Caribbean and Sub-Saharan African regions. Similarly, a stronger positive link is observed between tax corruption and tax simplification for lower-income countries. The empirical results, indicating that tax simplification has a strong impact on tax corruption, have important policy implications. Lowering corruption in tax administration is possible by simplifying the tax regime, often in various easy, non-controversial ways, many of which do not even need legislative changes. The paper attempts to provide a road map for tax simplification; steps that can be taken both in tax laws and tax administration which would move a tax administration towards simplification, and hence on a path of lower tax corruption. Section 2 gives information on the measurement of the tax corruption variable, as well as the indicators of tax complexity. Section 3 focuses on regression analyses and simulations. Section 4 presents some policy implications of the empirical results and includes suggestions on how to simplify taxes. Section 5 concludes.",17
5.0,2.0,Eurasian Economic Review,17 April 2015,https://link.springer.com/article/10.1007/s40822-015-0022-9,How will a risk of income fluctuations influence the suicidal decision making? Insights from a three-period model of suicide,December 2015,Tomoya Suzuki,,,Male,Unknown,Unknown,Male,"The objective of this paper is to formalise suicidal decision-making within the framework of economic models. In the economic literature on suicide, it is common to focus on economic difficulties among a variety of risk factors for suicidal behaviour. An economic agent is typically assumed to commit suicide when the discounted present value of the expected lifetime utility falls below a certain threshold level. Under this assumption, it is the expected value of future income that essentially determines whether or not for an agent to commit suicide. While following the convention in the literature, I pay a particular attention to the role of the standard deviation of future income, which measures a risk of income fluctuations, in the suicidal decision-making. A brief look at data shows that the risk of income fluctuations may be an important risk factor for suicidal behaviour. The statistics issued by the World Health Organization reveal that, as of March 2002, suicide rates per 100,000 per year are mostly higher in countries of Central and Eastern Europe (CEE) than in those of Northern and Latin America. Characteristically, CEE is composed of former communist states that have experienced radical transition to capitalism since the dissolution of the former Soviet Union. As Kornai (2000) points out, such transition generally generates inequality. Those who live in a country in transition may perceive the widening income inequality as an increase in a risk of income fluctuations. Certainly, an increased risk of income fluctuations can make risk-averse people more likely to commit suicide by reducing their expected utility for a given level of the expected income. As Dixit and Pindyck (1994) suggest, however, this impact should be discounted, at least to some extent. An increase in the risk of income fluctuations, which is measured by a rise of the standard deviation of future income, means that if things go well, people will earn higher income. The future income might be sufficient enough to compensate for the decrease in the expected utility. As such, the increased risk of income fluctuations can have two opposite impacts on the suicidal decision-making. It is not clear a priori whether or not an increase in the risk of income fluctuations will contribute to an increase in suicides. In this paper, I lay out a theoretical model to evaluate the net impacts of the income-fluctuations risk on the suicidal behaviour.",2
5.0,2.0,Eurasian Economic Review,08 July 2015,https://link.springer.com/article/10.1007/s40822-015-0027-4,Altruism and four shades of family relationships,December 2015,Yoshitaka Koda,Manachaya Uruyos,,Male,Unknown,Unknown,Male,"In this study, we develop and analyze a simple model of human capital investments decisions by utility maximizing households under four hypotheses of self-interest, filial altruism, parental altruism, and reciprocal altruism. If we look at studies on households’ fertility decisions, the majority of these studies have assumed that members of households are connected via altruism from parents to children as this leads to a reason for bearing children (see Barro and Becker 1989). More recent papers, which employ altruism from children to parents, argue that parents procreate because they expect to get old-age supports from their grown-up children who care well-being of their elderly parents (see Boldrin and Jones 2002). It seems that authors of these studies have chosen one from possible hypotheses on household preferences, which fits best for their theoretical proposition, but pay not so much attention to whether the particular hypothesis replicates the real economy well or not. According to Horioka (2002, 2014), who discusses the problems of bequest motives and bequest division for the cases of selfish, altruistic, and dynastic individuals, there is little agreement on which type of family relationships fits well to the real economies. Horioka (2014) shows that for Japanese and Chinese economies the selfish model is most applicable, whereas the (parental) altruism model is most applicable for American and Indian economies. The results go against the common believes that Americans are selfish as they appreciate individualism, and Japanese people are highly altruistic.Footnote 1 Under three hypotheses of self-interest, forward (parental) altruism, and backward (filial) altruism, Cigno and Rosati (1996) theoretically derive comparative-static predictions on households’ savings and fertility decisions and compare the predictions with empirical data from Germany, Italy, the United Kingdoms, and the United States. They conclude that the self-interest model with endogenous fertility is the only one consistent with their data while altruistic models are categorically rejected. The latter two studies are different from the former groups of theoretical works as they do not assume that household preferences can be chosen arbitrarily and have been contributing to the discussion on the most appropriate model of household behavior either on bequest motives and bequest division or on saving and fertility. At this point, it has to be noted that our fourth hypothesis, reciprocal altruism, is missing from the above arguments.Footnote 2 Horioka (2002) suggests that reciprocal (two-sided) altruism might be a highly plausible hypothesis as individuals were altruistic not only towards their children but also towards their parents.Footnote 3 Nevertheless, he does not include this hypothesis in his study. His explanation for the exclusion is that family members would help each other due to risk-sharing rather than purely altruistic considerations, and as Horioka (2002) analyzes data based on public opinion surveys it would have been difficult for him to separate the two considerations. Because there is no confusion between the two considerations in our theoretical framework, reciprocal altruism is included in this study. Preliminarily, we expect that individuals in households are at least partially connected via both filial and parental altruism therefore the rarely examined hypothesis of reciprocal altruism should be a strong candidate for the most appropriate model of household preferences.Footnote 4 However, to actually find a model that fits best for a specific economy requires empirical studies (i.e. two parameters measuring degrees of filial and parental altruism α
F and α
P in Eq. (1) have to be estimated). In this study, we concentrate on showing that predictions of theoretical models depend heavily on the models’ assumption on household preferences. Then, our main research questions are as follows: How are a model’s key household decisions modified if an assumption on household preferences is replaced by another without changing any other parts of its theoretical framework? What happens if policy makers introduce a government policy, which is known to improve social welfare under a particular hypothesis of family relationships, in a society under a different hypothesis? This paper’s focus is placed on advanced economies, which have gone through the demographic transition and are experiencing problems of aging population. In such economies, fertility rates tend to be around the replacement level, and individuals maintain nearly perfect health when young and are still healthy enough to work when old. Considering these stylized facts, studies on households’ fertility decisions have become less and less relevant whereas those on their health capital investments are gaining significance.Footnote 5 Following the seminal works of Grossman (1972) and Ehrlich and Chuma (1990), our model endogenizes households’ investments decisions on health capital in addition to those on education capital. Namely, middle-age agents choose fractions of time spent for education of their children and time devoted to old-age care services for their elderly parents. Though it is relatively straightforward to show that altruistic individuals have incentives to invest in family members’ human capital, to provide selfish ones with these incentives requires an intricate theoretical framework, which defines material interdependencies within their family. For this reason, our model also follows basic set-ups of Ehrlich and Lui (1991, 1998), whose notable feature is a self-enforcing family insurance system. Under this system, middle-age agents spend a fraction of time to educate their children, hence upon reaching old parenthood the same agents are entitled to financial supports from their grown-up children.Footnote 6 As an amount of financial supports for the elderly is set to be proportional to their children’s education capital stock, this mutual insurance mechanism provides selfish agents with incentives not only to have children but also to invest in their human (education) capital. The baseline model in this study adopts a modified version of the family insurance system. Under the modified system, an amount of financial supports available for old-age agents is agreed to be proportional to their children’s education capital stock and their own health capital stock.Footnote 7 This family insurance system together with norms of filial care of the elderly, whose details we will elucidate shortly, motivates selfish agents to invest in both education capital of children and health capital of old parents. It has to be noted that our study on endogenous longevity and economic growth differs from Ehrlich and Lui (1991, 1998), the studies on endogenous fertility and economic growth, at two particularly important points. In terms of key household choices, though individuals in their studies face a trade-off between the quantity (fertility) and quality of children, those in this study confront an alternative trade-off between the quality of children and the quantity (longevity via health investments) of old parents. In terms of household preferences, the baseline models in Ehrlich and Lui (1991, 1998) assume the hypothesis of self-interest, and in later sections they augment these models by adding the assumption of parental altruism, which further facilitates investments in both the quality and quantity of children. The model in this study, which deals with both problems of children and the elders, derives predictions on key household decisions under the four hypotheses of family relationships and compare them. The family insurance system motivates selfish agents to invest in education and health capital, and these investments are enhanced by adding assumptions of parental and filial altruism, respectively (or by adding that of reciprocal altruism). In reality, health capital investments flowing from children to old parents should be at least partially motivated by filial altruism, but this seeming relationship has not been examined in theoretical studies.Footnote 8
 Once individuals’ health capital investment becomes their choice variable, social norms dictating how they should behave towards their elderly parents become important. On one hand, education capital is transmitted from parents to children. Assuming that the family insurance system is in place, individuals educate their children and are compensated for the education efforts by the same children. Ehrlich and Lui (1991) discuss that, with some additional assumptions such as a penalty for violating the family contract, the system is self-enforcing under hypotheses with or without parental altruism. On the other hand, health capital is transmitted from children to parents. If there are no norms of filial care for the elderly, young parents have to provide their old parents with health care services not knowing whether they can get equivalent treatments from their children. Then, the mere existence of the family insurance system does not guarantee that young parents will be compensated for their past health care efforts by their children without filial altruism. Fortunately, according to Ogawa and Retherford (1993), social norms of filial care do exist, and people in the real world can expect old-age supports from their children. They report that even though Japan’s socioeconomic (e.g. real per capita income) and demographic (e.g. fertility and mortality) conditions are changing at extraordinarily fast rates during its post war period, norms of filial care for the elderly remain stable until recently. More specifically, their examination of the National Survey on Family Planning suggests that, before 1986, nearly 80 % of Japanese married women below age fifty consider norms of filial care as socially accepted standards.Footnote 9 If individuals spend a certain fraction of time for taking care of elderly parents knowing that their grown-up children mimic what parents did for grandparents, the family insurance system becomes self-enforcing under assumptions with or without filial altruism. Therefore, our theoretical model is meant to capture the salient features of Japanese economy for this particular period and incorporates the concept of norms of filial care for the elderly.Footnote 10
 Ogawa and Retherford (1993) discuss further that, after 1986, as the burden of old-age supports on adult children increases due to high old-age dependency rates in Japan, a major normative shift occurs, and only 50 % of respondents of the same National Survey give pro-care responses. Though we have to carefully distinguish social norms from altruistic traits of individuals, these two factors defining family relationships may affect each other.Footnote 11 As the major normative shift concerning filial care has observed after 1986, chances are that household preferences in Japan might undergo transformation from one hypothesis to the other as well.Footnote 12 Accordingly, the contribution of this study on endogenous longevity and economic growth would be the presentation of theoretical framework for future empirical studies in order to find the most appropriate model of household preferences for an economy in the time of rapid population aging. As the proportion of individuals who take norms of filial care as socially accepted standards decreases, a substantial part of the burden of old-age supports has been shifted from family insurance systems to public pension systems. By introducing Pay-As-You-Go (PAYG) social security into our baseline model, our numerical analyses find that impacts of the government policy on the macroeconomy depend on the choice of hypotheses of family relationships. The rest of paper is organized as follows: Sect. 2 reviews theoretical studies which assume one or more of the hypotheses of household preferences. Section 3 introduces the model which enables us to compare implications of the four hypotheses analytically. In Sect. 4, we introduce Pay-As-You-Go social security and calibrate the extended model to fit Japanese economy in order to analyze effects of increases in the PAYG contribution rate on key household decisions and social welfare numerically. Section 5 provides concluding remarks.",2
5.0,2.0,Eurasian Economic Review,09 July 2015,https://link.springer.com/article/10.1007/s40822-015-0028-3,Erratum to: Monetary policy challenges: how central banks changed their modus operandi,December 2015,Giorgio Di Giorgio,,,Male,Unknown,Unknown,Male,"On page 34, Fig. 5 ‘Composition of central banks’ balance sheets’, the legend has been published illegibly or incompletely. The author has provided a clearer illustration below (Fig. 5) to replace the published version. Composition of central banks’ balance sheets. Source: St. Louis Fed, European Central Bank This mistake happened during the production process of the article and unfortunately remained unnoticed. The publisher apologises for this mistake.
",
5.0,2.0,Eurasian Economic Review,09 July 2015,https://link.springer.com/article/10.1007/s40822-015-0029-2,Erratum to: The probability of default in Russian banking,December 2015,Alexander M. Karminsky,Alexander Kostrov,,Male,Male,Unknown,Male,"On page 88, Fig. 3 ‘Withdrawals of licenses and bank defaults in the Russian banking sector: Q11998–Q32011’, the legend has been published illegibly or incompletely. The author has provided a clearer illustration below (Fig. 3) to replace the published version. Withdrawals of licenses and bank defaults in the Russian banking sector: Q11998–Q32011. Notes 1—(Jan. 2000)—effect of 1998–1999 crisis has almost expired; 2—(Jan. 2004)—the Deposit Insurance System was launched in Russia; 3—(Sep. 2008)—2008–2009 financial crisis started in Russia. Source Bank of Russia, authors’ calculations This mistake happened during the production process of the article and unfortunately remained unnoticed. The publisher apologises for this mistake.",
6.0,1.0,Eurasian Economic Review,13 August 2015,https://link.springer.com/article/10.1007/s40822-015-0032-7,Trade liberalization and tax revenue in transition: an empirical analysis of the replacement strategy,April 2016,Ernesto Crivelli,,,Male,Unknown,Unknown,Male,"Trade liberalization has been a key component in the fundamental liberalization, privatization and stabilization reform process in transition economies in Eastern Europe, the Former Soviet Union, and the Middle East and North African regions. At the start of transition, most of the formerly socialist economies dismantled the bulk of the export and import controls and licensing arrangements that were in place under the old central planning system, reduced the dispersion of tariff rates applied to imports and lowered their (trade weighted) average level, rationalized and unified their exchange rates, and introduced more accommodating policies towards foreign direct investment. Later on, association agreements were signed between the EU and countries in Eastern Europe and North Africa and the Middle East that further lifted remaining trade controls, including by gradually reducing tariffs.Footnote 1 As a result, import tariffs have almost halved, while trade flows have increased substantially—both imports and exports are higher by about 10 percentage points of GDP, on average (Fig. 1, Panel A). Average tariffs, trade flows, and trade tax revenue. Panel A average tariff and trade flows, Panel B trade tax revenue. Source World Development Indicators; GFS (IMF); and IMF Country reports Trade liberalization policies in transition countries have been also accompanied by a significant reduction in government revenue from trade taxes,Footnote 2 from about 3 percentage points of GDP, on average, in the early 1990s to about 1.5 percentage points of GDP at present (Fig. 1, Panel B). This revenue loss has been a matter of concern for these countries, as it creates a source of fiscal instability. With trade taxes being still an important source of revenue in many transition countries, it remains also a relevant issue as they consider further liberalizing trade. While trade taxes represent only about 3 percent of total tax revenue collection (less than a ½ percentage point of GDP) in East Europe, it still accounts for more than 10 percent of tax revenue (about 2 percentage points of GDP) in Former Soviet countries and other transition countries in North Africa and the Middle East. Besides trade liberalization, the dramatic transformation of transition economies included significant institutional reform, in areas such as governance, competition policy, labor markets, privatization, and enterprise restructuring (IMF 2014). Subsequent reforms to their tax systems have not been less frequent in this context, including among others the adoption of value-added taxes, and a deep transformation of the concept of income taxation. This reform attempts affected tax revenue collection in the early stages of implementation of structural reforms (Coricelli 1998; Ebrill and Havrylyshyn 1999; Martinez-Vazquez and McNab 2000). Before the transition, the main sources of tax revenue came from taxes levied almost only on state-owned enterprises; the tax on profits and the turnover tax being by large the most important revenue sources. The tax on profits was collected mostly on the basis of negotiations between large enterprises and government officials (Buiter 1997), with tax rates adjusted frequently, and the tax burden usually being different depending on the industry. Turnover taxes were levied mainly on goods, collected at wholesale or retail level, and often used as a mechanism to regulate prices and support allocation of resources set in the plan. The transition towards market economy resulted in a significant decline in tax revenue collections usually related to the decline in the traditional tax bases—in part due to trade liberalization—and deterioration in the capacity of the tax administration. It is clear that the unsophisticated nature of the pre-transition tax administration, dealing with a few large state-owned enterprises, was not prepared to face a completely new environment and, therefore, prospects for tax evasion rose (Tanzi and Tsibouris 2000). In this context of challenging institutional reform, and with further trade liberalization potentially adding additional pressure on trade tax revenue, a concern arises as to whether this revenue stream can be replaced with other domestic tax sources.Footnote 3 This question has been empirically tested most prominently by Baunsgaard and Keen (2010), who analyze if—and to what extent—the loss in trade tax revenue has been recouped from domestic tax revenue in a panel covering 117 countries over the period 1975–2006. While this study is the most comprehensive available to date,Footnote 4 it does not cover the experience in post socialist transition economies in Eastern Europe and the CIS, where trade liberalization has been substantial, and sustainability of public finances must have created a need to find a substitute for the lost trade tax revenue. Indeed, a data plot of trade and domestic tax revenue for 33 transition countries confirms that over time, countries have increasingly replaced trade tax revenue with domestic revenue (Fig. 2). Trade and domestic tax revenue (in percent of GDP). Source GFS (IMF); and IMF Country reports Besides exploring whether countries have been able to recover the lost trade tax revenue with domestic taxation as a whole, a key remaining issue, however, is the assessment of the replacement strategy. In this regard, most of the literature has focused on identifying the alternative tax instruments that should be used—from a theoretical perspective—to replace the lost trade tax revenue, mostly on the basis of relative efficiency and equity impacts of those tax instruments. Keen and Ligthart (2001) argue in favor of broad-base consumption taxes—in particular the value-added tax (VAT)—to replace tariffs, as they find that for a small and competitive economy, this will lead to increased production efficiency and welfare, without affecting government revenue.Footnote 5 Other studies have favored taxes on corporate profits (Haque and Mukherjee 2005; Mujumder 2004). While no theoretical considerations have been put forward for or against the personal income tax, political economy considerations may favor this against consumption taxes in the grounds of progressivity of the tax system (Cnossen and Bird 1990). Very little empirical attention has been given, however, to which tax instruments actually have supported revenue collection along with trade liberalization. Baunsgaard and Keen (2010) focus only on the aggregate replacement of lost trade tax revenue through domestic revenue collection but do not analyze the impact of the alternative tax instruments. The authors only include a dummy on VAT adoption but find no evidence of stronger recovery associated to VAT. In contrast, Buettner et al. (2006) find evidence for the VAT to have contributed to the revenue recovery in 20 developing countries that adopted a VAT at the time of the WTO accession. Besides these examples, no empirical analysis exist on the extent to which domestic tax instruments—VAT, taxes on profits (CIT), or personal income taxes (PIT)—have replaced trade tax revenue, or what could have explained the choice of alternative tax instruments. This paper seeks to fill this gap in the literature by analyzing the experience in transition economies. The main reason for the scarcity of available empirical work on this subject is mostly related to the lack of reliable data on tax revenue components in transition economies and the length of the data series, usually too short to produce reliable results in the early stages of transition. This paper uses a constructed broad (unbalanced) panel dataset for 33 transition countries during 1991–2010, that covers the major tax revenue sources. The main purpose of the paper is thus twofold: (1) to assess whether and to what extent there has been revenue replacement between trade and domestic tax revenue as a whole in transition countries, and (2) to examine more in detail the actual replacement strategy, by analyzing the relationship between trade tax revenue and the main domestic tax revenue components. The paper follows the same empirical specification as in Baunsgaard and Keen (2010) but extends the analysis, first, by covering the experience in transition economies, and most importantly, by considering explicitly the importance of the different tax instruments in the replacement strategy.Footnote 6 In this context, additional extensions to previous work include also an assessment of how trade tax revenue replacement has evolved over time, considering how the reform momentum has change among transition economies. In addition, the replacement strategy may have been influenced by the several institutional arrangements that have likely affected the extent of the replacement and choice of the tax instruments, such as (1) the run-up to enter the European Union, which may have influenced the speed of the tax reform and ultimately positively impacted revenue performance (2) the extent of the replacement need, measured by the actual reduction in trade tax revenue over the sample period, and (3) the country’s initial conditions, measured by the total tax-to-GDP ratio. Finally, special attention is given to tax revenue compliance, not only affecting revenue collection but also likely affecting the extent of the trade tax replacement and the use of different tax instruments. The rest of the paper is organized as follows. Section 2 describes the dataset in more detail and sets out the empirical approach. Section 3 presents the main empirical results, with further robustness analysis reported in Sect. 4. Section 5 summarizes the results and concludes.",17
6.0,1.0,Eurasian Economic Review,13 August 2015,https://link.springer.com/article/10.1007/s40822-015-0033-6,Portuguese banks’ performance: comparing efficiency with their Spanish counterparts,April 2016,Maria S. Basílio,Maria Clara P. Pires,José Filipe Pires Reis,Female,Female,Male,Mix,,
6.0,1.0,Eurasian Economic Review,21 September 2015,https://link.springer.com/article/10.1007/s40822-015-0036-3,Is there a low-risk anomaly across countries?,April 2016,Adam Zaremba,,,Male,Unknown,Unknown,Male,"This paper is aimed at examining the low-risk anomaly at the country level. Low risk anomaly is a concept arising from the stock-level cross-sectional studies, which is related to one of the most profound questions in the financial literature, namely: Are safe stocks better investments than risky ones? The crucial assumption of the capital asset pricing model (CAPM) of Sharpe (1964), Lintner (1965) and Black (1972) is the existence of a positive linear relationship between the systematic stock market risk measured with their betas and the expected returns. This relationship has been generally confirmed by the initial tests of the U.S. stock market (Black et al. 1972; Fama and MacBeth 1973; Blume 1970; Miller and Scholes 1972; Blume and Friend 1973). The CAPM is built on the modern portfolio theory, according to which investors diversify risk by holding a portfolio of stocks. However, for various reasons, such portfolios are often poorly diversified (Goetzman and Kumar 2008). By assuming the phenomenon of the under-diversification, some theories indicate that also the idiosyncratic risk should be positively correlated with the expected returns in the cross-section analysis (Levy 1978; Merton 1987; Malkiel and Xu 2004). Papers of West and Tinic (1986), and Fu (2009) support the theoretical models and provide empirical evidence that portfolios with higher idiosyncratic volatility yield higher average returns. As the systematic and idiosyncratic risks sum up to the total volatility, this parameter should also be positively correlated with returns. Indeed, there are several studies which seem to confirm this assumption by showing that risk measures related to the total variability are positively correlated with the expected returns. For example, Bali and Cakici (2004) find that there is a strong positive relationship between the average returns and value at risk, which is robust against different investment horizons and various levels of loss probability. Chen et al. (2014) confirm this observation in the emerging stock market in Taiwan. In addition, Ang et al. (2006a) focus on the downside risk and show that the cross-section analysis of stock returns reflects a significant downside risk premium. Surprisingly, the results of many papers seem to be entirely contrary to the above-described theories. This phenomenon—called a “low-risk anomaly” (Ang 2014)—is a combination of three effects, where the third one is the consequence of the first two effects: Volatility is negatively related to future returns. Realized beta is negatively related to future returns. Minimum variance portfolios outperform the market. There is mounting evidence of the anomaly which follows from many studies conducted over the last forty years, since its first discovery in early ‘70s. In their paper of 1970, Friend and Blume examined the stock returns for the period 1960–1968 with the use of the CAPM beta and volatility, drawing a conclusion that “risk-adjusted performance is dependent on risk. The relationship is inverse and highly significant” (Friend and Blume 1970). Shortly afterwards, this observation was confirmed by Haugen and Heins (1975) who analysed the U.S. stock market in the period between 1926 and 1971, reaching the conclusion that “over the long run, stock portfolios with lesser variance in monthly returns have experienced greater average returns than their ‘riskier’ counterparts” (Haugen and Heins 1975). It also appears that market beta is far from being the ideal predictor of stock returns. The first challenge has been probably described in the paper of Jensen et al. (1972) who argue that, despite the positive relation between beta and returns, the correlation is probably “too flat” compared to the CAPM predictions. This results in the abnormal returns on low-beta stocks. Finally, the relevance of the CAPM was undermined in the influential paper of Fama and French (1992) which proves that “beta shows no power to explain average returns” (Fama and French 1992) when considering the size and value effects. These studies led to the proliferation of further research studies providing the evidence for the low-risk anomaly in the U.S. stock market (Baker and Haugen 1991; Chan et al. 1999; Jagannathan and Ma 2003; Clarke et al. 2006; Ang et al. 2006b; Baker et al. 2011) and in other global equity markets (Blitz and van Vliet  2007; Ang et al. 2008; Baker and Haugen 2012; Blitz et al. 2013). Furthermore, in recent studies, new asset pricing factors have been introduced based on the risk anomaly. Frazzini and Pedersen (2014) propose a betting-against-beta (BAB) factor which refers to the returns on the leveraged portfolio of low-beta stocks hedged with high-beta stocks. Ang (2014), p. 339 constructs a volatility factor which, despite similar design, is based on the standard deviation instead of the market beta. The above-mentioned factors have not only delivered long-term positive abnormal returns, but also managed to explain the alphas of Warren Buffet’s investment portfolio (Frazzini et al. 2013). Low-risk anomaly seems to be so astonishingly simple and powerful that Robin Greenwood, professor at Harvard Business School, called it “the Mother of all inefficiencies” (Ang 2014, p. 332) in 2010. Nevertheless, the grounds for its existence are still a mystery to a large extent. Several possible explanations are found in the financial literature. According to some papers, the reasons are data mining issues and the sensitivity of the resulting illiquidity effects and portfolio weighting methods (Bali and Cakici 2008; Han and Lesmond 2011). However, the best counterargument is probably the pervasiveness of this anomaly. The low-risk effect has been observed in international stocks, sovereign and corporate bonds, credit derivatives, currencies (Frazzini and Pedersen 2014), and even commodities (Blitz and de Groot 2014) or option markets (Cao and Han 2013). Frazzini and Pedersen (2014) attempt to explain the beta anomaly with leverage constraints, arguing that investors who are not able to borrow money create excessive demand for high-beta stocks. However, the leverage constraints explain only the low returns of risky stocks, whereas the abnormal positive returns of safe stocks remain unexplained (Ang 2014, p. 342). Ang (2014), pp. 342–343 blames the agency problems for the risk anomaly and suggests that institutional investors have to stick to the benchmark and, therefore, are unable to take bets on extreme-beta stocks characterized with significant tracking error. Furthermore, several studies suggest that the under-pricing of safe stocks and over-pricing of risky stocks may simply result from the investors’ preferences regarding the trade environment (Boyer et al. 2010; Bali et al. 2011; Ilmanen 2012). Finally Hou and Loh (2014) conduct a comprehensive analysis of numerous explanations, proving that even taken together as groups they are not able to explain more than half of all the anomalies. Previous studies on the low-risk anomaly concentrated solely on the stock-level effects. However, several questions remained unanswered, namely: Do any parallels occur the country level? Is the risk also a valid determinant of a cross-national variation in stock returns? In an attempt to answer these questions, this study aims to endow the low-risk investing with a new global dimension. The concept of finding parallels between stock-level and country-level cross-sectional return patterns has its precedence in a number of previous studies on the cross-national value, momentum and size effects. First, Macedo (1995), Asness et al. (1997), Kim (2012), Zaremba (2015a) claim that stock markets with low fundamental indicators, for example P/E ratio, yield higher returns than markets with high ratios. Second, Richards (1997), Bhojraj and Swaminathan (2006), Balvers and Wu (2006) and Blitz and van Vliet (2008) argue that top performing markets tend to continue to outperform the market, while ‘laggard countries’ retain their negative momentum. Third, Keppler and Traub (1993) and Keppler and Encinosa (2011) conclude their papers by saying that ‘small is beautiful’. According to them, the portfolios composed of small capitalization markets deliver higher returns than big markets in a long run. The additional evidence on the described phenomena is provided by Desrosiers et al. (2004), Asness et al. (2013), and Angelidis and Tessaromatis (2014). Finally, Zaremba (2015b) proves that certain parallels between country-level and stock-level quality effects are also observable across the data. This paper aims to comprehensively investigate the country-level risk effects. The study contributes to the financial literature in two ways. First, it examines and compares performance portfolios from sorts on the range of risk indicators. The calculations are based on a broad sample of 78 single country stock markets for the period 1999–2014. Second, inspired by similar observations from the stock-level studies (Novy-Marx 2013), the paper examines whether additional sorting on the risk may improve the performance of value and size strategies at the country level. The basic motivation to conduct this study were structural changes which have taken place in the international equity markets in recent decades. The increased integration and openness of global financial markets led to the rise in correlations between stock market returns in various countries (Bekaert and Harvey 2000; Quinn and Voth 2008). As a result, the diversification benefits of international investments have fallen markedly, and the cross-country correlations keep growing (Authers 2010).Footnote 1 The disappearance of diversification opportunities has significant impact on the market practitioners. This trend indicates the growing importance of country selection strategies as part of the investment process (Hester 2013). The described phenomenon is associated with the proliferation of passive investment products which ensure investors easy access to international markets (and it might have been fuelled by their emergence). Futures markets, index funds and exchange traded funds (ETFs) offer investors liquid and cheap investment opportunities in the global markets. Investment Company Institute (2014) reports that over 430 billion dollars were invested in 490 international equity ETFs in the USA, in September 2014. What is more, EY expects the global ETF market to rise 15–30 % annually over the forthcoming years (EY 2014). Compared to the abundant opportunities and the size of the global ETF market, investment tools available for ETF investors seem to be still astonishingly modest. The stock-level investors have at their disposal ample literature dealing with cross-sectional and time-series patterns, as well as asset pricing models. Such tools still need to be developed in the field of passive ETFs and index products. One of the overarching aims of this paper is to fill this gap, at least partially. Key findings of the study may be summarized as follows. First, there is no evidence for the country-level low-risk anomaly observed. Returns are positively correlated with the value at risk, standard deviation and idiosyncratic volatility, although it is largely explained by cross-national value, size and momentum effects. Second, the relationship seems to be stronger in the case of idiosyncratic risk measures and is almost non-existent in the case of the systematic risk (market beta). Third, additional sorting on value at risk may markedly improve the performance of size and value strategies at the country level. The primary source of the data at the country-level is Bloomberg. The sample period covers the years between 1999 and 2014. In terms of asset pricing tests, the study attempts to explain the returns on the portfolios sorted on risk. The returns are evaluated by means of the country-level cross-sectional pricing models. The structure of the further part of this papers is as follows. Section 2 describes research methods and data sources. Section 3 presents the findings of the study and Sect. 4 concludes the paper.",20
6.0,1.0,Eurasian Economic Review,23 September 2015,https://link.springer.com/article/10.1007/s40822-015-0031-8,Looking into the relationship between implied and realized volatility: a study on S&P CNX Nifty index option,April 2016,Alok Kumar Mishra,Siba Prasad Panda,,Male,Unknown,Unknown,Male,"Forecasting volatility is fundamental to the risk management operation in order to price derivatives, devise hedging strategies and estimate the financial risk of firm’s portfolio positions. There are several methods to predict the future volatility. Nevertheless, generally, we can split volatility models into two parts: historical volatility and implied volatility. Historical volatility models use time series of past market prices while implied volatility depends on a particular model of the relationship between trading option prices and volatility. A theoretical option pricing model, such as Black–Scholes, will pass the theoretical price for an option as a function of implicit parameters such as strike price, risk free rate of interest, spot price, volatility, and time to maturity. Amongst all except volatility, all other parameters are either given or realized in the market. The implied volatility of an option is the volatility in which the Black–Scholes theoretical price equals to the market price. Implied volatilities are used to device market’s expectation about future volatility. Thus, we can state that historical volatility is backward looking while implied volatility is a forward looking measure of volatility. Precisely measures and proper assessments of volatility are important for understanding the operation of the financial market. However, estimated volatilities vary based on the methodology, time period chosen and time horizon considered etc. In the light of the above discussion the objective of this paper is to look into the predictive power of implied volatility against the backward looking volatility of S&P CNX Nifty index option in India. The present study differs from previous study in four perspectives—firstly, it has considered volatility data, sampled over a longer period (sample size 2513) than in previous studies which increases statistical power and allows for evolution of efficiency of the market dealing with S&P CNX Nifty index option that was presented in 2001. Secondly, the study shows the predictability of both call and put implied volatility. Thirdly, the study deals with overlapping (telescoping) data. Fourthly, in order to assess the validity of all the applied volatility measurement models, we compare them in an out of sample framework. The major findings of the study propose that the conditional volatility measures provide a superior forecast of realized volatility than forward looking as well as other backward looking measures of volatility. The implied volatilities are biased and inefficient estimates over the remaining life of the option contract. The ARCH school of models outperformed all other prediction models with respect to predicting 1 month ahead volatility in the ‘out of the sample’ framework. The rest of this paper is structured as follows. Section 2 deals with the review of literature. In Sect. 3, we have presented the data and sampling process. The methodology for analysis that describes how volatility series are constructed is explained in Sect. 4. The empirical results are confronted in the Sect. 5 followed by the concluding remarks of the paper in Sect. 6.",3
6.0,1.0,Eurasian Economic Review,19 October 2015,https://link.springer.com/article/10.1007/s40822-015-0037-2,CO2 emissions and human development in OECD countries: granger causality analysis with a panel data approach,April 2016,Serap Bedir,Vildan Merve Yilmaz,,Female,Female,Unknown,Female,"In recent years, environmental pollution, greenhouse gases, and climate change have been among the most important environmental concerns worldwide. The ever-increasing levels of carbon dioxide (CO2) and other greenhouse gases in the atmosphere are considered to be some of the world’s greatest environmental threats. Among the greenhouse gases, CO2 plays a powerful role in enhancing the greenhouse effect and is responsible for greater than 60 % of this effect (Acaravci and Ozturk 2010). Consequently, CO2 should be closely examined by policymakers. Sustainably managing the natural environment is one of the most important issues for humanity, considering that future generations will have to rely on it for their sustenance and wellbeing. Thus, it is our responsibility to protect the natural environment for them. Energy is essential for all forms of economic activity. The increasing development and use of energy consuming technologies, resulting in increasing energy consumption per capita, have characterized industrialization and economic development processes over the past century (Warr et al. 2009). Thus, it is believed that a country with a high energy consumption is also likely to have high living standards. In addition, high energy consumption results in increased CO2 emissions, which adversely affects the environment. As a result of this documented linkage, academics and practitioners have intensively examined the effects of global warming and climate change on the world economy (Alkhathlan and Javid 2013). According to the first Human Development Report (HDR) published by the United Nations Development Programme (UNDP) in 1990, “People are the real wealth of a nation. The basic objective of development is to create an enabling environment for people to enjoy long, healthy, and creative lives. This may appear to be a simple truth. But it is often forgotten in the immediate concern with the accumulation of commodities and financial wealth.” Indeed, economic growth is an important factor in reducing poverty and generating the resources necessary for human wellbeing and environmental protection, but it does not solely guarantee an increase in living standards. It fails to justify the important factors of societal wellbeing that are not directly linked to economic production such as life expectancy, health, and education (Ouedraogo 2013, p. 29). Therefore, focus has been placed on human development indices in recent years. Few studies have focused on human development indices (e.g., Niu et al. 2013, Martinez and Ebenhack 2008, Steinberger and Roberts 2010). Due to a lack in this area, this study investigates the linkage between human development index (HDI) and CO2 emissions within a panel framework. Most studies in the literature use gross domestic product (GDP) as a proxy for growth (e.g., Kraft and Kraft 1978, Lee 2005, Mehrara 2007, Acaravci and Ozturk 2010); however, this study uses HDI as a proxy for growth so that wellbeing, rather than only monetary wealth, is considered. This results from HDI, including more comprehensive information using health and education data as well as per capita income data (UNDP, HDR 2014). Conversely, we use per capita CO2 emissions resulting from the use of total final energy as a proxy for environmental harm. As mentioned above, CO2 emissions are the largest component of greenhouse gas emissions and the greenhouse effect. As such, it is used herein to represent the degradation of the environment. According to Steinberger and Roberts (2010), developed nations use and emit far more energy and CO2 per capita than they need to maintain their high living standards. Therefore, they argue that truly sustainable social and environmental progress is only possible if industrialized nations substantially reduce their consumption and emissions. Most of the Organization for Economic Co-operation and Development (OECD) member countries have high incomes according to World Bank classifications. Therefore, we are interested in the OECD members in that study. Moreover, economically, OECD countries are highly intertwined with each other. Hence, this study employs the method proposed by Konya (2006) and considers both cross-sectional dependence and issues of heterogeneity. The remainder of the paper is organized as follows. Section 2 summarizes the hypotheses and discusses the empirical literature. Then, Sect. 3 discusses the data and methodology used in this study. Finally, Sect. 4 presents the conclusion and policy implications.",39
6.0,1.0,Eurasian Economic Review,26 November 2015,https://link.springer.com/article/10.1007/s40822-015-0039-0,The effects of low cost carrier entry in the Turkish Airline industry,April 2016,Resul Aydemir,Cihad Haytural,,Male,Male,Unknown,Male,"Over the years, following the successful paradigm of the pioneer Southwest Airlines in the United States, low cost carriers (LCCs) in various parts of the world have transformed themselves into strong competitors. Airlines such as Ryanair and EasyJet in Europe, Air Asia and Virgin Blue in the South Pacific, 1Time and Kulula in Africa, and Gol and U Air in South America are important examples of the LCC concept that has rapidly achieved global recognition (Oliveira 2008). LCC competition exerted dramatic downward pressure on airfares.Footnote 1 The pro-competitive effects of LCCs in air transport markets of advanced countries are well documented. Notable contributions include Dresner et al. (1996), Morrison (2001), Forsyth (2003), Goolsbee and Syverson (2008), Aydemir (2012) and Alderighi et al. (2012), and others. However, previous research to date that has focused on the empirical analysis of the effects of LCC entry in developing countries such as Turkey is scarce.Footnote 2
 Recently, the Turkish Airline industry has gone through substantial change. Turkish Airlines operated in a regulated market has been the state-owned sole carrier in the industry for a long time. Following deregulation attempts the industry has become a dynamic and competitive market. In this evolving environment, especially the entry of Pegasus Airlines (the largest LCC in Turkey), which started scheduled operations in 2005, has had tremendous impact on the industry. Turkish Airlines has been compelled to lower fares significantly on routes entered by Pegasus. For example, tickets that were previously sold at $400 by Turkish Airlines have dropped to $233 on its Istanbul–Moscow flights after Pegasus entry on October 8th, 2013 (Tourism-review 2013; Pegasus 2013). These pricing patterns, i.e., lower fares, can be noticed in other domestic and international markets of Turkish Airlines entered by Pegasus. Motivated by these observations, this paper extends previous research to examine competitive impacts of low cost carrier entry in developing countries. Specifically, we empirically analyze how Turkish Airlines responds to the entry by Pegasus Airlines on domestic and international routes served to and from Istanbul, which is one of the best performing hub cities in the world (Nenem and Ozkan-Gunay 2012). Estimation results suggest that Turkish Airlines has significantly lowered its fares in both domestic and international markets in response to Pegasus Airlines entry due to increased competition. The rest of the paper proceeds as follows. Next, we briefly present the historical background of the Turkish Airline industry and the recent outlook of the two carriers. Section 2 briefly touches upon literature review. Section 3 describes the data. We explain the empirical methodology in Sect. 4. Estimation results are discussed in Sect. 5. Then we conclude in Sect. 6. Dursun et al. (2014) divide the history of the Turkish Airline industry into three distinct eras: (1) before 1983; (2) between 1983 and 2003; and (3) from 2003 onwards.Footnote 3 Before 1983, Turkish Airlines was the only carrier operated in Turkey. The critical development in the history of the industry took place when the “Turkish Civil Aviation Act” was enacted on 14th October 1983. The act entitled private entrepreneurs to operate Airlines within Turkey. After the legislation, 19 new companies were established. However, 10 of them declared bankruptcy soon after mainly because of restrictive route entry rules such that other Airlines could only operate on domestic routes if Turkish Airlines did not have a scheduled flight on those routes or it could not meet the demand within an appropriate timeframe. The industry showed slow progress during this period. Eventually, the government deregulated the domestic market to encourage demand and create a more competitive industry. Hence, the entry of private carriers was effectively permitted in the Turkish Airline industry afterwards (Gerede 2010). 13 Airline companies (10 passenger and 3 cargo) operate within Turkey as of 2013 (Dursun et al. 2014). Two of these carriers are among the fastest growing Airlines in Europe. Turkish Airlines and LCC Pegasus Airlines increased available seat kilometers (ASKs) by 16 and 20 %, respectively in 2014. Turkey’s largest LCC Pegasus Airlines had attained a double-digit share (13 %) of all seats in/to/from Turkey by 2010 since its operations started in 2005. OAG Schedules Analyser reports that Turkish Airlines had a 53.5 % market share in 2010. Since then, both have grown strongly, but Pegasus has grown faster, increasing its total number of seats by 150 % from 2010 to 2014, while Turkish Airlines increased its capacity by 80 %, in line with the total market growth. As a result of its faster growth, Pegasus enjoyed an increase in seat market share, adding 6ppts to reach 19 % in 2014. Turkish had a share of 53.6 % in 2014, no real change from 2010. The main battlegrounds between the two are on international routes to/from Europe and in the domestic market, where Pegasus has grown particularly rapidly (CAPA 2015).",4
6.0,1.0,Eurasian Economic Review,22 September 2015,https://link.springer.com/article/10.1007/s40822-015-0035-4,A long-term mortality analysis of subsidized firms in rural areas: an empirical study in the Portuguese Alentejo region,April 2016,Anabela Santos,Paulo Neto,Maria Manuel Serrano,Female,Male,Female,Mix,,
6.0,2.0,Eurasian Economic Review,14 December 2015,https://link.springer.com/article/10.1007/s40822-015-0043-4,"Gender, caste and poverty in India: evidence from the National Family Health Survey",August 2016,William D. Lastrapes,Ramaprasad Rajaram,,Male,Unknown,Unknown,Male,"According to the World Bank (2014) almost two-thirds of India’s population are poor—living on daily incomes of under $1.25. Indeed, more than a quarter of the world’s poor, based on this measure, live in that country, even though the 2015 Millennium Development Goal (2015) report suggests that the country has already met its goals regarding poverty reduction. At the same time, societal mores and cultural attitudes have historically been unfavorable to women and individuals belonging to marginalized social castes, which can contribute to poverty directly and indirectly in India (Cagatay 1998). Custom and tradition typically have accorded lower status to women (Arokiasamy and Pradhan 2006; Das Gupta et al. 2003). Women often have restricted access to work and education, and thus do not participate in labor markets as freely as men (Dreze and Sen 1995; Dunlop and Velkoff 1999). Women’s access to family inheritance and productive assets can be limited or absent (Agarwal 1999), and many religious practices still prevalent in this country symbolize the subordination of women to men. Similarly, people belonging to Scheduled Caste and Scheduled Tribes—the historically marginalized social groups in India—continue to suffer from socio-economic oppression (Borooah 2008; Gaiha et al. 2008; Gang et al. 2008); and the practice of “untouchability” although prohibited by the constitution, is still prevalent, particularly in rural areas (Mehta and Shah 2003).Footnote 1 Access to public goods, land ownership in rural areas, and basic infrastructure for socially marginalized communities are limited (Kijima 2006; Mutatkar 2005). In addition, social institutions and networks that influence and protect people’s living conditions are inadequate or absent for these disadvantaged groups (Boscher et al. 2007). These facts beg the important empirical question: are households headed by women, and households belonging to the socially disadvantaged communities (SCST, hereafter) in India more likely to suffer from poverty than others? The answer to this question can help inform policies aimed at alleviating poverty, eliminating discrimination, and improving welfare through targeted programs. Almost all previous studies that investigate this question use data from the National Sample Survey (NSS) Organization, and rely on official measures of poverty based on income or expenditure predominantly tied to caloric intake thresholds. The primary purpose of our paper is to re-examine the links between poverty and gender, and poverty and caste, in India using data from the country’s National Family Health Survey (NFHS). The NFHS is an extensively used data source for studying health issues in India, but has not been exploited to systematically study poverty, caste and gender. This paper attempts to do fill this gap in the literature. Using this data set allows us to consider broader indicators of poverty than the official measures based on food consumption expenditure in the NSS. While every poverty measure has its own advantages and shortcomings, here we rely on wealth or asset-based measures of poverty, uniquely available from the NFHS data, rather than on standard income or consumption-based indicators. Asset-based poverty measures contain additional information about households’ permanent or chronic economic deprivations that may be missed by current flow measures. We use asset-based poverty measures to assess whether households are deprived in single and multiple dimensions of economic well-being. One aim of this study is to allow for an assessment of the robustness of previous findings on poverty, caste and gender that use ‘flow’ poverty with alternative asset-based poverty measures. If our results differ from studies that use official poverty measures, it provides opportunities for policy makers to reconsider poverty-reduction strategies by targeting specific vulnerable groups that may be deprived by our chronic measures, in addition to or in lieu of those shown to be poor by official measures. Several studies have criticized the NSS for projecting poverty statistics much lower than reality owing to political interference; there are statistical flaws as well (Deaton and Kozel 2005). Also the methods used in two kinds of NSS surveys—large and small surveys—are not standardized. Official poverty estimates are based on the large consumer expenditure survey, which typically occurs once in 5 or 6 years, while the smaller ones occur annually. The potential bias regarding consumption expenditure, and hence poverty measures inherent in NSS, may not be present in NFHS data since the intention of collecting data by the NFHS is predominantly for analyzing and reporting health statistics in India. Therefore, this additional information pertaining to economic status and poverty of households can potentially improve our estimates of the determinants of poverty in the country. We use household-level data from the NFHS and measure gender and caste in terms of the head of the household. As is the case with household-level analysis in general, our study cannot speak to intra-household allocations of wealth and well-being. At the same time, understanding how poverty is linked to the head-of-household is important in its own right since policies to eradicate poverty are often targeted at households based on the gender or caste of the head (e.g., Buvinic and Gupta 1997; Gang et al. 2008). Using the gender or caste of household head is also a common practice in this empirical literature (e.g., Dreze and Srinivasan 1997; Borooah 2008; Chudgar 2010; Oggini et al. 2013). Most of the current evidence on the relative poverty of female-headed households and SCST households in India suggests that these groups are indeed poorer than their respective counterparts. Swarup and Rajput (1994) show that lack of access to family property and deficient micro-credit facilities contribute to the relatively poor economic conditions of female-headed households. Using standard head-count ratios of poverty and accounting for economies in family size, Dreze and Srinivasan (1997) and Meenakshi and Ray (2002) find that female-headed households face a greater risk of being exposed to poverty. Gangopadhyay and Wadhwa (2003) also provide evidence that female-headed households are poorer than male-headed counterparts in India.Footnote 2 All of these studies use data from the NSS and caloric intake classifications of poverty. Likewise, Gaiha et al. (2008) estimate that in addition to the lack of access to endowments and productive assets, the marginalized classes receive lower returns to such endowments, which they interpret as a measure of “pure” social discrimination. Similarly, Gang et al. (2008) show that excessive poverty status of SCST is primarily caused by differential returns to education and occupation as compared to non-SCSTs. Kijima (2006) shows that the SCST households are typically isolated from mainstream neighborhood and thus lack access and connectivity to public facilities such as schools, tap waters, roads, electricity, and health facilities, which feed directly into their poverty status both in the short and long run. If these findings are valid, if indeed women and SCSTs in India face discrimination with respect to education, earnings, rights, and economic opportunities (Barros et al. 1997), then they lend credibility to policy proposals that target households in which these heads are typically the bread winners.Footnote 3 However, if gender or caste of the head is not clearly linked to poverty, then such targeted policy proposals will, at best, be ineffective. As mentioned earlier, while the studies mentioned above use consumption-based measures of poverty to establish their results, we attempt to corroborate those findings using asset-based poverty metrics. Using our new measures of poverty, we find evidence for female-headed households and SCST households to be poorer than male-headed and non-SCST households, respectively. Our results also suggest; however, that the social or cultural class of the household head—belonging to SCST—and the location of a household—rural or urban—are more strongly related to poverty than gender.",14
6.0,2.0,Eurasian Economic Review,18 December 2015,https://link.springer.com/article/10.1007/s40822-015-0044-3,Trade and income growth in the Ottoman Empire: assessing the role of volatility and trend growth in terms of trade,August 2016,Cemal Eren Arbatli,,,Male,Unknown,Unknown,Male,"The first half of the nineteenth century was the period when sustained economic growth began. However, it started unevenly across the world and led to what has become known as the ‘Great Divergence’ in living standards. While the industrial leaders (the Core) started growing rapidly during this period, commodity dependent price-taking economies (the Periphery) remained stagnant. There is an intense debate about the origins of the Great Divergence in income per capita. The explanations that were at the forefront of this debate advocated the primacy of geographical and institutional factors, human capital formation, cultural factors, ethnic, linguistic and religious diversity, colonialism and globalisation (North 1981; Jones 2003; Landes 1999; Baldwin et al. 2001; Glaeser et al. 2004; Acemoglu et al. 2005; Galor 2005; Ashraf and Galor 2011; Galor and Mountford 2008). Can the rapid expansion of international trade during the nineteenth century explain part of this divergence? Several studies suggest that the answer is affirmative (Blattman et al. 2007; Williamson 2008; Galor and Mountford 2008). Common to all of these explanations is the idea that secular movements in local relative price of exported goods compared to the imported goods, i.e., the terms of trade, can influence output growth. Having shown that the terms of trade (ToT) boom was much stronger before 1870 than after and arguing that the forces of de-industrialization and Dutch disease were also more pronounced in the pre-1870 period, Williamson (2008) concludes that rapid growth in ToT was an important driving cause behind the Great Divergence between the Core and the Periphery. It is commonly accepted that for many countries greater integration with the global economy led to greater macroeconomic volatility. Several papers have investigated the link between openness and overall volatility. Both cross-country (Easterly et al. 2001; Kose et al. 2003; Bekaert et al. 2006) and industry-level (Giovanni and Levchenko 2009) studies find that increased openness is positively associated with higher volatility in growth rates of GDP and consumption. This strong link suggests that ToT volatility might be one of the main drivers of aggregate macroeconomic volatility. Indeed, Rodrik (1998) finds that higher income and consumption volatility is positively related to the interaction of overall trade openness and terms-of-trade volatility, a proxy for ‘external risk’. Economists have argued that, beyond its impact on growth instability, ToT volatility might also contribute to poor economic performance. Several mechanisms may be responsible for such an effect. For example, when returns to capital are more volatile, risk averse households may choose to save less (Rosenzweig and Wolpin 1993). If greater price volatility results in revenue instability, it might discourage investment in public goods and lower economic growth. Another channel suggests that increased volatility may reduce export revenues and discourage capital inflows (Eichengreen 1998). Mendoza (1997) presents a model where greater ToT volatility leads to reductions in household savings and hamper economic growth. He finds a negative relationship between volatility and growth on a sample of 40 industrial and developing countries for 1970–1991. Other studies corroborate these findings (Bleaney and Greenaway 2001; Turnovsky and Chattopadhyay 2003). A similar relationship appears to hold for earlier periods. For instance, Williamson (2008) argues that ToT volatility, which was larger in the pre-1870 period and affected the poor Periphery more than it did the countries in the Core, might also have contributed to the Great Divergence. Focusing on the post-1870 period, Blattman et al. (2007) offer evidence that while ToT volatility had a big adverse impact on economic growth in the Periphery, trend growth in ToT had a much limited role in explaining output growth, possibly reflecting the presence of mainly two counteracting forces. While a secular ToT improvement might have encouraged a shift in resources to sectors with a comparative advantage and raise output, at the same time, in those Periphery nations with a strong comparative advantage in the production of primary commodities, de-industrialization forces might have reduced long-run growth potential. In the first part of the paper, we demonstrate that volatility, when measured by the coefficient of variation—rather than simply the standard deviation—of the cyclical components of ToT series, had a more substantial adverse effect on income growth than the estimates in Blattman et al. (2007) suggest. The reason, as will be argued later on, is that the latter estimates suffer from a downward bias when the average level of ToT trend is not accounted for. The second part of the paper focuses on the late Ottoman and early Turkish experience of ToT movements. Specifically, we evaluate the relative contributions of ToT growth and ToT volatility on the economic performance over the period 1800–1933. ToT experience across the countries in the Periphery showed significant variation (Williamson 2008). Therefore, although Blattman et al. (2007) find stronger effects for volatility than for trend growth in the Periphery, a priori, it is not clear which of the two factors was more important for explaining the growth performance of a particular country over different periods. The answer depends not only on the direction and magnitude of the ToT effects but also on how the levels of ToT trend and volatility in a country evolved over time. Looking at the Ottoman experience in the nineteenth century as a historical case study is relevant for various reasons. First, the Ottoman Empire was, at the turn of the nineteenth century, one of the most sizable states in terms of the territory it spans and its population. According to the population estimates by Maddison (2010), in 1820 the Ottoman Empire was the seventh largest state among the 27 nations in the Periphery including China and India. Thus, it is a highly relevant case to assess the impact of ToT movements on the economic wellbeing of the Periphery. Second and more importantly, the evolution of Ottoman ToT during the studied period was quite peculiar. Although the Ottoman Empire was involved in international trade through most of its history, nineteenth century stands out as a period when it experienced unusually large changes in its ToT. Over the course of this century, trade with Britain and Western Europe expanded. While in 1840 export shares were between 3 and 4 \(\%\) of GDP, by 1913 it reached 11.5 \(\%\) (Zurcher 2004; Williamson 2011). Secular rise in Ottoman ToT was particularly remarkable in the first half of the nineteenth century. Comparing the Ottoman experience with the rest of the poor Periphery, Pamuk and Williamson (2011) conclude that the Ottoman Empire, along with Egypt, underwent the greatest upswing in ToT up to 1860s, possibly making the first half of the nineteenth century an episode of rapid de-industrialization for the Empire. ToT series provided in Williamson (2008) suggest that from the first five years for which data is available (1800–1804) to 1855–1859—when ToT reached its peak—the annual growth rate of net barter ToT in the Ottoman Empire was about 2.55 \(\%\). This is substantially larger than the—population weighted—average growth rate—from start to peak—in the Periphery countries which stood around 1.43 \(\%\) per annum. Therefore, predicting the counterfactual income growth in the Empire—in the absence of these large ToT shocks—would also be informative about the upper bound of the changes implied by secular ToT movements in the Periphery at large. A 2 to 2.5-fold increase in the price of primary products relative to manufacturing products (Pamuk and Williamson 2011) and the accompanying shift of resources to the production of primary products are believed to be the main driving force behind this de-industrialization. Evidence suggests that indeed some sectors in the Empire such as the cotton textiles industry lost a significant share of the home market to foreign imports over this period.Footnote 1 Thus, if we are to find any important role for ToT growth in explaining income growth in the Periphery, a natural place to look at is the Ottoman economy in particular. Using a specific factors model calibrated to the nineteenth century Ottoman economy (Das et al. 2015) conclude that consistent with the de-industrialization hypothesis, the rapid increase in Ottoman ToT must have led to a slow-down in economic growth, but the effect they identify is quite modest. However, de-industrialization is certainly not the only mechanism through which secular ToT improvements may affect income growth in primary commodity exporters. As countries open up, favorable ToT movements would be akin to technological improvements that expand the production possibilities frontier. Several developing country studies find that increasing commodity prices improve growth performance (Basu and McLeod 1991; Deaton and Miller 1996; Mendoza 1997; Deaton 1999). Resource curse arguments, on the other hand, predict the opposite. ToT movements may reinforce existing patterns of comparative advantage whereby resource-rich, commodity dependent nations may further specialize in sectors with little room for productivity improvements or they may strengthen the incentives for expropriation of the resource sectors and encourage rent-seeking by the resource-owning elite (Prebisch 1950; Singer 1950; Krueger 1974). Evidence from a sample of commodity exporters indicate that positive terms of trade movements may influence growth negatively (Hadass and Williamson 2003). In a study that explores the links between globalization, structural adjustment and economic growth in developing countries McMillan and Rodrik (2011) show that, in countries with comparative advantage in natural resources, the forces of economic globalization contributed to an inefficient inter-sectoral reallocation of resources. They find that in both Africa and Latin America, the structural change was characterized by labor flows from high- to low-productivity sectors which in turn had a growth reducing effect since the 1990s. It was not only ToT levels that underwent drastic changes. Average ToT volatility in the Empire had increased more than two-folds between 1800–1820 and 1820–1870. However, unlike ToT trend, which was relatively stable over 1870–1913 and turned somewhat negative over 1914–1933, during these two periods, volatility remained well above the levels observed in the first two decades of the nineteenth century. This paper argues that ToT volatility, as a by-product of increased involvement in international trade of goods, was a far more important determinant of the poor economic performance of the Ottoman economy than the secular increase in relative prices of its exports. Based on our most preferred estimates, we predict that if volatility had been zero all throughout the nineteenth century and during the first three decades of the twentieth century, GDP per capita would on average have grown about 1.07–1.33 \(\text{percentage}\) points faster than it actually did. A significant portion of the estimated costs of volatility to the Ottoman economy can be attributed to the pre-1870 and post-1910 surges in ToT volatility. Our results suggest that in contrast to volatility, the adverse effect of ToT growth was both statistically insignificant and smaller in magnitude. Even if we take the estimated magnitudes at face value, they imply that lowering ToT trend growth all the way down to zero during the entire pre-1870 episode, when ToT trend increased at a remarkable rate of 1.9 \(\%\) per annum, would raise income growth only by 0.11–0.48 \(\text{percentage}\) points. The corresponding increase in growth rate, if we were to lower volatility to zero over the same period, would be 1.12–1.39 \(\text{percentage}\) points. These are large effects for the Ottoman economy which is estimated to have grown by a modest 0.5 \(\%\) per annum over the period 1820–1870. Even under the most optimistic scenario, the predicted volatility effect is greater than the ToT trend growth effect by a factor of 2.8. Put differently, lowering ToT trend growth to zero in all decades between 1800–1870 would result in an average increase in income growth that is more or less equivalent to the impact of reducing decadal volatility over the same period by only 34 \(\%\). Our findings call for further theoretical research geared towards understanding the greater importance of price volatility in the poor Periphery relative to the more modest role of a secular rise in ToT. We also believe that a detailed historical investigation of how greater volatility influenced different sectors of the Ottoman economy and how the impact of volatility depends on various country characteristics would be welcomed contributions to the literature.",2
6.0,2.0,Eurasian Economic Review,21 March 2016,https://link.springer.com/article/10.1007/s40822-016-0051-z,The challenge of predicting currency crises: how do definition and probability threshold choice make a difference?,August 2016,Dogus Emin,Aysegul Aytac,,Unknown,Unknown,Unknown,Unknown,,
6.0,2.0,Eurasian Economic Review,30 November 2015,https://link.springer.com/article/10.1007/s40822-015-0040-7,Stock markets and effective exchange rates in European countries: threshold cointegration findings,August 2016,Christos Kollias,Stephanos Papadamou,Costas Siriopoulos,Male,Unknown,Male,Male,"The relationship between stock prices and exchange rates has attracted considerable and growing attention in the relevant literature. Given the significance and role of the two markets, the recent financial crisis brings to the forth the need to re-examine this relationship (Lin 2012; Caporale et al. 2014) using techniques that can help unveil its more dynamic features that more traditional linear methodologies fail to do. Shedding light into such dynamic and probably non-linear characteristics and elements may reveal dimensions that can potentially have important implications both for market agents as well as market regulators and policy makers. Moreover, such insights into the dynamic interaction between the two markets can also assist in the understanding of the propagation mechanisms that can be set into motion during crises periods. A plethora of empirical studies, using various methodologies have examined the nexus between these two markets and the linkages that interconnect them. As many have stressed, both markets exert a significant impact on a economy’s overall performance especially in the context of globalized markets and cross-border flows of funds (inter alia: Swanson 2003; Phylaktis and Ravazzolo 2005; Yau and Nieh 2009; Kutty 2010; Diamandis and Drakos 2011; Chkili et al. 2012; Kollias et al. 2012; Chortareas et al. 2012; Tsagkanos and Siriopoulos 2013; Kumar 2013). If one attempts to summarize the hypotheses that have been advanced on a theoretical level to describe and analyze the relationship between the stock and the currency markets, then essentially three broad theses emerge. On the one hand, it has been argued that their association takes the form of unidirectional causality from exchange rates to stock prices. In brief, what the goods markets hypothesis postulates is that changes in exchange rates affect the international competitiveness of local firms and hence their earnings and share prices (Dornbusch and Fischer 1980). However, it should be noted here, that the sign of this causal ordering in the context of the goods markets approach is not a priori certain and depends on whether the economy in question is an export or an import oriented one. In countries where exporting firms play a dominant role in the economy, we expect a beneficial effect of currency movements on share prices. Currency depreciation leads to a significant increase in the demand of exports and, as a consequence, increased profits. In turn, this is reflected on stock prices. Hence, this constitutes a negative relation between the two markets. The reverse is the case for an economy with significant trade deficits. The assumed currency depreciation makes imports more expensive reducing the profitability of import companies leading investors to reduce their positions in such companies. The overall effect of currency fluctuations on the aggregate stock market index depends on the structure of the index. A further source for a positive effect of currency appreciation on stock prices emanates from the direct effect on corporate earnings through changes in the prices of imported raw materials and intermediate inputs. When the domestic currency appreciates (depreciates), profit levels are likely to expand (contract) as the costs of imported inputs decrease (increase). However, according to Kim (2003) there can be a portfolio adjustment effect, which will have also a favourable impact on stock prices. This occurs as a result of foreign investors’ expectations concerning stock performance. Good news in the economy relative to other countries, make investors want to shift from other markets to this market, putting pressures on the currency and finally pushing the capital market higher. The reverse causal ordering, i.e. from stock markets to exchange rates, is proposed by the portfolio balance thesis. In the context of portfolio balance models of exchange rate determination, exchange rates are assigned the role of balancing the demand for and supply of assets (Frankel 1983; Gavin 1989). In brief, this occurs through two important channels: firstly, in the presence of a dynamically growing stock market, the demand for domestic assets appreciates with the concomitant impact on exchange rates. More foreign capital inflows in the stock market mean higher demand for the domestic currency and therefore currency appreciation. The opposite occurs in a stock market crisis where investors sell stocks and capital flies out of the currency (Aysan et al. 2014). Secondly, the well-known wealth effect works via interest rates. More specifically, the increase of the stock market capitalisation has a significant positive effect on wealth of domestic investors that is a significant contributor to their money demand. A possible increase in the money demand function leads to higher interest rates—given a fixed money supply—attracting more investors in the domestic currency. A recent study for Asian countries by Moore and Wang (2014), shows that the trade balance is an important determinant of the dynamic correlation for the Asian markets, whereas the interest rate differential is the driving force for the developed markets. Finally, the absence of any strong linkage between the two is the thesis proposed by the asset market approach (Frenkel 1976). In this case, the positive effect of currency depreciation on export firms is offset by the negative effect on import firms. Or, in the reverse direction, the channel from stock market to currency may not work either if the country is not an open enough economy or the capital market is characterised by low development. Not surprisingly, as already pointed out above, a plethora of studies have empirically investigated this nexus between the two markets. In broad terms, the results yielded by these studies offer a mixed picture with findings very much dependent upon the time period covered, the methodology employed and the sample of countries used to investigate the issue at hand. Thus, strong causal linkages have been reported—but with no strong uniformity in terms of the direction of causality—as well as the absence of any statistically strong association (inter alia: Yau and Nieh 2009; Pan et al. 2007; Fernandez 2006; Griffin and Stulz 2001; Nieh and Lee 2001; Ajayi and Mougoue 1996; Bartov and Bodnar 1994; Choi 1995; He and Ng 1998; Donnelly and Sheehy 1996; Bhandari and Genberg 1989; Bahmani-Oskooee and Sohrabian 1992; Jorion 1991; Bodnar and Gentry 1993; Mok 1993). Most papers that have addressed this issue tend to rely on linear techniques (Granger 1969; Granger et al. 2000; Wu 2000; Smyth and Nandha 2003; Pan et al. 2007; Lin 2012; Rutledge et al. 2014). However, as Yang et al. (2014) argue, the causal nexus may vary across different quantiles and different periods. This can explain why conventional Least Square methods usually yield insignificant results in terms of causality. Moreover, as recent studies have argued and shown, this relationship may very well have non-linear dimensions that cannot be captured by traditional techniques (Yau and Nieh 2009, 2010).Footnote 1 In the spirit of such studies, this paper hopes to contribute to the existing literature by approaching the issue at hand through the non-linear framework of threshold cointegration, introduced by Balke and Fomby (1997) as a practical method combining non-linearity and cointegration. Further developments by Enders and Granger (1998) and Enders and Siklos (2001) introduced estimation tools that allow for non-linear adjustments towards a long-run equilibrium. In recent years threshold cointegration and, on a broader level, non-linear methodologies have found a number of applications in fairly varied thematic topics in finance (Gil-Alana 2008). This paper applies threshold cointegration analysis to eight selected European countries: Germany, France, Spain, Italy, Sweden, Denmark, Norway and the UK. The estimations span the period 01/2000–12/2011 hence they include the recent economic crisis. Thus they allow for more reliable inferences to be drawn. All the countries included in the sample are among the strongest European economies, well integrated into the global economic and financial system, with developed and mature stock markets. Apart from the adoption of a non-linear empirical methodology, this paper in line with previous ones (Kim 2003; Phylaktis and Ravazzolo 2005; Zhao 2010) uses effective exchange rates and not bilateral exchange rates since a country’s trading activity invariably includes a number of major trading partners. The effective exchange rate takes into account the allocation of trading activity of one country with its trading partners hence it allows for a better context within which the issue at hand can be investigated. Furthermore, the group of countries that make up our sample can be divided into two sub-groups. On the one hand we have four European countries with developed stock markets that have adopted the euro as their currency—Germany, France, Spain, Italy—while the remaining four—i.e. the UK, Sweden, Denmark and Norway—operate their own national currencies. The latter group of countries in the case of a stock market effect on currency are in a better position vis-à-vis the former sub-group, to absorb the shock by intervening in the foreign exchange market (Oduncu et al. 2014). Interesting findings may emerge from this sample division, given that our tests cover the period from the adoption of the euro and include the recent financial crisis. In the sections that follow the data and methodology employed are presented and then the empirical findings are analysed and discussed. Section four concludes the paper.",7
6.0,2.0,Eurasian Economic Review,23 October 2015,https://link.springer.com/article/10.1007/s40822-015-0038-1,Eurasian orientation and global trade integration: the case of Turkey,August 2016,Anagnostou Ageliki,Panteladis Ioannis,,Unknown,Unknown,Unknown,Unknown,,
6.0,2.0,Eurasian Economic Review,23 December 2015,https://link.springer.com/article/10.1007/s40822-015-0045-2,Exchange rate volatilities and disaggregated bilateral exports of Malaysia to the United States: empirical evidence,August 2016,Wong Hock Tsen,,,,Unknown,Unknown,Mix,,
6.0,2.0,Eurasian Economic Review,28 January 2016,https://link.springer.com/article/10.1007/s40822-016-0046-9,Defining the factors of Fitch rankings in the European banking sector,August 2016,Themistokles Lazarides,Evaggelos Drimpetas,,Unknown,Unknown,Unknown,Unknown,,
6.0,3.0,Eurasian Economic Review,01 October 2016,https://link.springer.com/article/10.1007/s40822-016-0058-5,Modelling banks’ credit ratings of international agencies,December 2016,Alexander M. Karminsky,Ella Khromova,,Male,Female,Unknown,Mix,,
6.0,3.0,Eurasian Economic Review,16 February 2016,https://link.springer.com/article/10.1007/s40822-016-0048-7,Macro-financial linkages and bank behaviour: evidence from the second-round effects of the global financial crisis on East Asia,December 2016,Chau H. A. Le,,,,Unknown,Unknown,Mix,,
6.0,3.0,Eurasian Economic Review,30 September 2016,https://link.springer.com/article/10.1007/s40822-016-0055-8,"Inflation, inflation uncertainty and relative price variability in Bangladesh",December 2016,Monir Uddin Ahmed,Md. Moniruzzaman Muzib,Md. Mahedi Hasan,Unknown,Unknown,Unknown,Unknown,,
6.0,3.0,Eurasian Economic Review,05 August 2016,https://link.springer.com/article/10.1007/s40822-016-0054-9,A systematic retrieval of international competitiveness literature: a bibliometric study,December 2016,Magdalena Olczyk,,,Female,Unknown,Unknown,Female,"International competitiveness is a key topic of interest to all, including managers, politicians and academics, especially as the globalization process is changing the competitive landscape. The popularity of the international competitiveness concept is clearly demonstrated by the more than 6.5 million results generated by a Google search and by the increasing interest around the issue of competitiveness rankings, especially at the country level (Hassett 2012). International competitiveness has also become a central objective of national economic policies and strategies. Despite its high popularity, international competitiveness has been described as one of the most misunderstood concepts, especially in economics, with even scepticism about the term itself being expressed by some academics (Krugman 1994; De Grauwe 2010). There are four main reasons why we do not have a widely accepted definition of international competiveness, not to mention a generally accepted theory of the subject (Lachmann 2001). First, the concept of international competitiveness is very broad. It can be examined at different levels: those of the product, firm, industry or sector, region, nation, commercial block, or as an aspect of global trade, and there is a close connection or relationship between all these levels of competitiveness (Anca 2008). It is a concept the understanding of which comes from different disciples, not only from economics but also from management, history, politics and culture. Even in the discipline of economics, the theoretical background to international competitiveness is related to various theories, i.e. the classical and neoclassical Keynesian theories, development economics theory, new growth theory and new trade theory. Additionally, due to globalization and liberalization processes the boundaries between domestic and international markets have faded, leading to a disappearance of the distinction between national and international competitiveness. Second, misunderstanding of the international competitiveness concept reflects the fact that its key insights are powerfully contrary to what our intuition leads us to expect (ITS Global Raport 2008). The idea of international competitiveness understood as the capacity to successfully compete with rivals in international markets is only properly understood as it applies at the microeconomic level. While companies compete with others for resources and market shares, and in the case of failure some have to go out of business, economies do not compete for resources, which are often fixed in space and time, and they never go bankrupt in an economic sense (Krugman 1994). These different ways of competing, depending on the level of discussion, imply different ways of measuring competitiveness for companies, sectors and economies, which makes the concept of international competitiveness more and more misunderstood. Third, we can only find a few statements in the literature which are widely accepted amongst academics dealing with international competitiveness issues. These argue that international competitiveness comes from competition (Porter 1990). Moreover, competitiveness has been delineated by many researchers as a relative and multidimensional concept (Spence and Hazard 1988; Flanagan et al. 2007) and is generally considered synonymous with success and economic strength in the global environment (Srivastava et al. 2006). Some economists also agree that the roots of international competitiveness studies can be found in classical international trade theories. Finally, debate about international competitiveness is based on a multitude of concepts, often without any explicit theoretical foundation. Reviews of the international competitiveness literature are very rare (Chaudhuri and Ray 1997; Banwet et al. 2002; Bhawsar and Chattopadhyay 2015). They all underline the multitude of definitions, focus on different measurements and theoretical models, but always describe international competitiveness as an elusive concept. They only propose an integrated and eclectic approach, combining different schools of thought and multiple measurements as the most suitable way to study international competitiveness issues. The existing reviews of international competitiveness literature have one major drawback. They do not synthesize the existing literature and do not show the relationship between the different understandings of the concept. Even the authors of the World Competitiveness Ranking highlight the difficulties in fitting competitiveness measurements to the conceptual framework of competitiveness and the absence of causality among the structural components of the competitiveness ranking (Bris and Caballero 2015). We still know nothing about the core publications or authors in the international competitiveness literature which may be the basis of the origin of international competitiveness theory. What is needed is the use of a new approach, a new methodology to investigate the competitiveness literature. According to Bofinger (1995) and Mitschke (2008), the concept of international competitiveness is probably located within an interface region in the scientific network, and the traditional approach of literature analysis is insufficient. Consequently, the aim of the present paper is to fill this research gap by using an absolutely new approach in this research area: bibliometric methods. According to the best knowledge of the author, an analysis of the literature on international competitiveness using bibliometric methods has not yet been carried out. This paper has the main aim of consolidating the state of the art of academic research on international competitiveness by making a bibliometric study of the literature published over the past 70 years, but only in the discipline of economics. Citation data is collected from Web of Science, Scopus and Google Scholar, and is analysed using HistCite, VOSviewer and Pajek software. The main purpose is to accomplish the following objectives: to investigate the growth pattern of the international competitiveness literature, and to identify the core journals, authors and key international competitiveness research domains and the relationship between them. Knowledge diffusion in the international competitiveness literature will also be examined. The rest of the paper is structured as follows. The next section reviews the literature on the international competitiveness concept. Section 3 presents the data and methodology. Section 4 provides the results of the estimations. Finally, Sect. 5 consists of discussion and concluding remarks.",20
6.0,3.0,Eurasian Economic Review,05 March 2016,https://link.springer.com/article/10.1007/s40822-016-0050-0,A characterization of implementability of decision rules via a menu of three-part tariffs,December 2016,Masahiro Watabe,,,Male,Unknown,Unknown,Male,"The purpose of this paper is to establish the taxation principle in a class of principal-agent problems within a class of simple tariffs. The paper focuses on the use of three-part tariffs. Three-part tariff is a price schedule consisting of a fixed fee, an allowance of usage, and a marginal price for additional usage beyond that allowance. There is a vast literature on consumer choice under three-part tariffs, compared with two-part tariffs or the optimal non-linear pricing, in economics and business.Footnote 1 From the perspective of the complexity of the structure of non-linear pricing schedules, it is more realistic to restrict the principal’s strategy space to a class of simple tariffs. The paper make a contribution to the theory of non-linear pricing under asymmetric information. The main result shows that any non-decreasing decision rule can always be implementable via a menu of three-part tariffs. I consider a model of contracting by a principal and an agent under asymmetric information. There is adverse selection because the agent’s characteristics/types are not observable to the principal (the distribution being known, however). The principal and the agent contract on a product characteristic such as quality or quantity, and a monetary transfer. The agent’s product choice can be described as a decision rule that assigns a product choice for each type. The strategy space of the principal is a set of non-linear price schedules. Each non-linear pricing schedule is considered a catalog of products and prices. The agent chooses a product so as to maximize his utility from trade. I say that a decision rule is implementable via price schedule if it is consistent with the agent’s type-dependence best responses for some price schedule. The principal selects a price schedule so as to maximize his expected profit from trade, subject to the implementability constraints and the participation constraints. The standard approach to the screening problem is reformulating the principal’s strategy space. Using terminology in the context of mechanism design, a price schedule is regarded as an indirect mechanism where the response by the agent takes the form of an announcement of a product quality/quantity. On the other hand, we can use a transfer function which is considered as a direct revelation mechanism where the message by the agent consists of private information. When the principal’s strategy space a set of direct revelation mechanisms, another notion of implementability of a decision rule is commonly used. A decision rule is said to be implementable via transfer or rationalizable if it is weakly optimal for the agent to announce the true value of his private information. Actually, it is well-known that the implementability via transfer is a necessary condition for the implementability via price schedule. This observation is so-called the revelation principle. As a result, the principal’s problem is rewritten as an expected profit maximization problem over the set of decisions and transfers satisfying the incentive compatibility constraints and the participation constraints. Because of the use of the revelation principle, the literature on non-linear pricing has argued some properties of decision rules indexed by types. The seminar article, Mussa and Rosen (1978), predicts that the principal’s optimal quality decision exhibits no-distortion for the highest type and downward distortions for all other types when the participation constraints are not type-dependent. It is well-known that when the utility that the agent gets in excess of the reservation utility is monotone, there is no pooling if the distribution of private information is not too irregular. Maggi and Rodriguez-Clare (1995) consider a model where the reservation utility depends on private information. They argue the structure of optimal contracts, in particular the occurrence of pooling, crucially depends on the shape of the reservation utility even when the monotone hazard rate condition is satisfied. The literature has argued a pattern of distortions and a possibility of bunching or pooling. These are, however, some properties of decision rules indexed by type. On the other hand, my concern is the nature of the principal’s strategy itself. Since restricting attention to strictly monotone decision rules is no longer “no without loss of generality” in general, my question is whether it is possible to design and analyze an indirect mechanism that is consistent with an incentive compatible direct revelation mechanism that involves bunching. The revelation principle states how to construct an incentive compatible direct revelation mechanism from an indirect mechanism. The hypothesis for the revelation principle is the implementability of decision rules via price schedule in the context of the screening problem. If we have a procedure to recover a non-linear price schedule from any incentive compatible direct revelation mechanism, then it means to claim that, without loss of generality, we can restrict attention to incentive compatible direct mechanisms for the analysis. The reverse of the revelation principle is known as the taxation principle. The purpose of the paper is to establish the taxation principle for any weakly monotone decision rules. Principle 2 in Rochet (1985) shows how to construct a non-linear pricing function for the taxation principle from any weakly monotone decision rule. However, to my best knowledge, any properties of his price schedule except the implementability via price schedule have not been discussed. On the other hand, the present paper aims to establish the taxation principle in a class of tractable price schedules.",1
6.0,3.0,Eurasian Economic Review,05 May 2016,https://link.springer.com/article/10.1007/s40822-016-0053-x,Regret theory and the competitive firm revisited,December 2016,Udo Broll,Peter Welzel,Kit Pong Wong,Male,Male,,Mix,,
6.0,3.0,Eurasian Economic Review,17 March 2016,https://link.springer.com/article/10.1007/s40822-016-0052-y,Cash benefits for poverty relief from the viewpoint of suicide prevention,December 2016,Tomoya Suzuki,,,Male,Unknown,Unknown,Male,"Economic hardships account for a certain proportion of suicides in a variety of countries. For instance, Classen and Dunn (2012) used data on the United States to statistically establish that a long duration of unemployment leads to an increase in the risk of suicide. Ceccherini-Nelli and Priebe (2011) performed co-integration and correlation tests to confirm a long-run association between economic factors and suicide rates for France, Italy, the United Kingdom and the United States. Hassan (1996) found a positive correlation between the unemployment and suicide rates in Australia during the sample period of 1901–1990. These empirical findings imply that a welfare programme can contribute to suicide prevention by granting cash benefits to those facing considerable deterioration in their living standards. However, undesirable side effects may arise from cash benefits aimed at poverty relief. The beneficiaries of cash benefits might depend heavily on welfare, thus finding themselves caught in an unemployment trap in which they have little financial incentive to seek work.Footnote 1 This problem should be considered when developing a welfare programme aimed at poverty relief. Section 2 surveys the economic literature for theoretical models of suicide. Those models assume that agents have only two types of options, namely, to live on their earnings or commit suicide. Section 3 amends one of those models by allowing agents in the model to live on welfare and considers two simplified welfare programmes. Section 4 specifies functional forms and parameter values to numerically simulate decision making under the availability of cash benefits aimed at poverty relief. This section also discusses the simulation results. Section 5 concludes the paper with remarks on future research.",
7.0,1.0,Eurasian Economic Review,19 November 2016,https://link.springer.com/article/10.1007/s40822-016-0059-4,Health-conscious consumer behavior,April 2017,Hiroaki Hayakawa,,,Male,Unknown,Unknown,Male,"With advancement of health and medical sciences, the world as a whole has become increasingly conscious of health as the foundation of productive life and quality living, both physical and mental. It is now common for people to watch weight, take food supplements, avoid trans-unsaturated fatty acids, break undesirable eating habits, exercise for physical and mental fitness, avoid stressful working conditions, achieve better work-life balance, and so on. In response, the market offers a large variety of goods and services to meet this trend. At the same time, facing population aging and low fertility, the governments of many nations are committed to the enhancement of the health status of their constituents in order to sustain economic growth and social welfare programs. Business firms, likewise, are now taking a more comprehensive approach to profit making by integrating the securement of health and wellbeing of employees with overall business strategies (Loeppke et al. 2009; Parkinson 2013; Prochaska et al. 2011).Footnote 1 On a global scale, the World Health Organization (2011) and the United Nations are running campaigns to fight against non-communicable diseases such as cardiovascular disease, cancer, chronic respiratory diseases, diabetes, and mental illness, that are estimated to take a heavy toll on the productivity of many nations in the future (UN  2011; Bloom et al. 2014a). Since many of the instances of NCDs are caused by lifestyle habits, it takes many years before a significant improvement can be expected on the projected disability adjusted life years (DALYs).Footnote 2 All of these developments indicate that health is now a public concern of a top priority addressed by individuals, communities, governments, and health organizations alike. With this trend in sight, this paper attempts to develop a theory of health-conscious consumer behavior by extending the Hicks–Samuelson utility-preference theory, by allowing health to enter the utility function explicitly and, at the same time, to affect the income earning capacity of the consumer, hence the budget constraint, and by integrating a health production function into consumer utility maximization. The idea that health, viewed as capital, needs to be produced and sustained through appropriate investment is well-established. Grossman (1972a, b, 2000), in line with the human capital approach of Becker (1964) and Ben-Porath (1967), modeled the idea of an optimal path of the stock of health in terms of the marginal efficiency of health capital and the marginal cost of investing in health, in which termination of life is endogenously determined when one reaches the age at which there is no more net returns to investing in health, which depreciates with aging. This model has been modified and extended by Galama (2011), by replacing the marginal efficiency of health capital with the marginal efficiency of investment in health and by incorporating the threshold level of health and corner solutions. Because both formulations are focused on intertemporal choice of either the stock of health or the investment in this stock in answering the fundamental question of how the demand for medical care is co-determined with the optimal stock of capital or the optimal level of investment, the question of how a consumer selects different goods and services within and across different periods with the effects on health and the income earning capacity taken into account remains implicit. Our analysis supplements their analyses in this regard, by focusing on choices made at a disaggregated level on a day-to-day basis that shares the same logic of the traditional consumer theory. It also supplements the analytics of productive consumption by Suen and Mo (1994), who isolated certain productive goods as sources of utility and income in a static context, by providing a more general treatment of health-conscious consumer behavior in both static and dynamic contexts.Footnote 3
 One can be healthy in the sense of not having contracted a disease or not suffering from a chronic medical condition, but, just as a car in good condition but without fuel does not run, a healthy individual, who is free of sickness but doesn’t eat properly and take a proper rest, is not productive in his work, hence his earning and consumption will suffer as his wage is paid according to his productivity in the market place. The health capital in this paper captures health in this sense. We may call it quasi-health, which depreciates very fast and has to be replenished constantly. An individual cannot ignore it since a cycle of productivity, income earning, and consumption is at stake. The market principle, “pay according to one’s productivity”, therefore, disciplines individuals to monitor their health by watching what they consume on a daily basis. Other path-breaking works in the literature are pertinent to our analysis. Stigler and Becker (1977) argued that what appears to be a perplexing behavior of an individual can be explained without resorting to preference changes if an underlying production function can be uncovered that mediates market goods to utility-yielding commodities. This idea can be applied to the production of health if health is viewed as a utility-yielding commodity that is produced from market goods in accordance with a certain health-production function. Lancaster (1966), likewise, regarded consumption as an activity that produces utility-yielding characteristics from market-purchased goods, in accordance with underlying consumption technologies. In this vein, consumption can be regarded as a health-enhancing activity in accordance with certain health-producing consumption technologies, in which market goods, used as inputs, are transformed to health. Lancaster’s idea of consumption as an activity can be recast as consumption as an investment activity which aims at building and maintaining health-capital. Pollak (1970), on the other hand, analyzed formation of habit in consumer choice that perpetuates its effect as habituated consumption, in a manner analogous to physical capital yielding its returns over time. Because health as a utility-yielding capital requires investing in consumption of healthy goods in accordance with certain health production knowhow, and because health is sustained by the habit of a healthy life-style (the habit of eating healthy food, doing regular exercises, and so on), these theories can support a thesis that health is an endogenous variable in consumer choice, serving both as a utility-yielding capital and as an important source of the productive capacity to earn income. Implications of health-conscious consumer behavior are extensive, four of which are discussed in this paper. First, health is not only a private good with narrowly confined externalities benefiting close circles of friends and relatives, but also a public good with externalities extending to the community as a whole. This implies that there may be strategic complementarities between health-conscious consumption of individuals and the health-promoting effort of the community (Cooper and John 1988). Second, a healthy life is more productive in every aspect of life and can lead to higher lifetime earnings. This implies that one’s wealth, as the discounted present value of expected lifetime earnings, is largely an endogenous variable (an extension of Friedman 1957). Third, since healthy workers are more productive, firms may include incentives for health enhancement in the wage packages they offer as part of efficiency wages (e.g., Stiglitz 1976; Solow 1979; Shapiro and Stiglitz 1984; Akerlof 1982; Yellen 1984). Fourth, health-conscious consumers are selective about the information they use for health-production purposes, advertised or scientific, which affects the marginal utility of health-enhancing or health-harming goods and the income earning prospect. This implies that a virtuous cycle of complementarities may arise between consumption of healthy goods on the one hand and information selection and gathering on the other (Becker and Murphy 1993). These implications will be discussed in the text. The rest of the paper is organized as follows: In Sect. 2, we present a static model to highlight our main point. Extending the Hicks–Samuelson preference-utility theory, we demonstrate how the equi-marginal principle works in the optimal allocation of the health-mediated endogenized wealth, and generalize the Slutsky Equation and Shephard’s Lemma. This will be followed by an intertemporal model with a finite horizon in Sect. 3, in which health of the succeeding period is affected by what is consumed in the preceding period. We show how the marginal utility of the endogenously determined wealth is equalized across all goods and all periods. We conclude in Sect. 4. Specific static and dynamic models in which leisure yields utility and enters a health-production function are presented in Appendices A and B, and Shephard’s Lemma in the static model without leisure is presented in Appendix C.",5
7.0,1.0,Eurasian Economic Review,09 January 2017,https://link.springer.com/article/10.1007/s40822-016-0062-9,"Education, R&D, and social progress",April 2017,Bruna Bruno,Marisa Faggini,,Female,Female,Unknown,Female,"Recently, economists have developed a new way of looking at policymakers’ objectives, which encompasses economic performance, and collective wellbeing, and social progress (Stiglitz, Sen and Fitoussi 2009). In light of this new interest in economic performance and social progress, the debate on public expenditure is not merely a question of economic growth. This is especially true when economic crises occur and the debate on the best way to restore growth in the gross domestic product (GDP) restarts. Austerity policies predict severe budget constraints whereas expansive policies imply budget deficit. In both cases, the focus is generally on the effects on economic performance, broadly described by GDP, national debt, the inflation rate, unemployment, and so on. The effects on other dimensions of collective wellbeing are rarely considered in economic debate, though it is evident that standard instruments of economic policies have various, relevant impacts on collective wellbeing. In this paper, we reconsider the role of public intervention while taking a broader objective function into account. Because of the conflicting points of view concerning the efficacy of expansive or restrictive policies, a cautious approach to introducing the multidimensional objectives of policymakers would be to investigate the impact of different policies when public expenditure is constant. Different categories of public expenditure have different effects on both economic growth and social progress; beyond the direct impact of expenditure on economic performance and public debt, each expenditure category often has an indirect effect on individual wellbeing and social progress. The policy design of health programs, unemployment benefits, pension schemes, and financing of education pose a budgetary problem, the effects of which are straightforward on individual health, personal insecurity, life perspectives, life satisfaction, and social progress. Among the categories of public expenditure, education is prominent both due to its incidence in total expenditure and its contribution to the various aspects of multidimensional wellbeing. Education is an input in the national production function and has a considerable impact on the economic performance (Wolf 2004). At the same time, education has a strong effect on individual wellbeing and social progress. Therefore, it is a good example for verifying how composite objectives interact in determining economic performance and collective wellbeing. We analyze the effects of policymakers’ choices about educational expenditure on economic performance and collective wellbeing when a multidimensional objective function is described. Expenditure intervention in education can be analyzed in relation to two different aspects: overall expenditure and its composition. Given the hypothesis of a constant level of total public expenditure, the analysis is focused on the composition of public expenditure on education, distinguishing between productive and unproductive spending. It is well known that the same incremental expenditure could determine different GDP changes, according to government efficiency in executing public expenditure (Wang and Alvi 2011). One major point in government efficiency concerns its preferences for unproductive use of public expenditure and corruption. Consequently, the relation between economic performance and social progress considerations is linked to policymakers’ choices about the composition of educational expenditure. The distinction between productive and unproductive spending is further discussed in Sect. 2.1 where a literature review on this theme is also provided. When dealing with education and economic performance, one cannot ignore the complementary role of investments in research and development (R&D). In growth theory, both R&D and education are considered to foster growth because of the complementarity between them (Redding 1996; Funke and Strulick 2000; Strulik 2004; Sterlacchini 2008). Given that the effects of education and R&D on growth are still subject to intense investigation, new insights can be derived from the analysis of the impact of education and R&D on a multidimensional objective of policymakers, encompassing both economic performance and social progress. The main aspect that will be analyzed is the role of government in fostering R&D when deciding the educational expenditure composition. As stressed by Flanagan et al. (2011), the multi-actor and multi-level implementation of policies concerning innovation is a key factor in understanding how policies work. Policymaker may act taking into account the firms’ decisions concerning R&D investment, following a passive policy, whereas in the active policy he acts independent of the firms’ optimal choices. The distinction between active and passive policies, as proposed in economic literature, is briefly discussed in Sect. 2.2. Three features of the analysis are addressed in the paper. The first is the need for multidimensional objectives for policymakers, considering social progress beyond the GDP objective. This implies the need to consider not only economic variables but also the level of expenditure on education as a value per se in the objective function of the policymakers. The second strand of analysis concerns the effects of different policies (active vs. passive) when dealing with the interaction between the public and private sectors supplying investment in education and R&D respectively. The third focus is on the composition of public expenditure (in terms of productive and unproductive expenditures). To provide an adequate discussion of these themes, in the following section we review some strands of literature, which will be merged into a unique framework. In Sect 3, we describe the hypothesis and the results of the analytical model. Section 4 discusses the main implications of the results and Sect 5 concludes the paper.",2
7.0,1.0,Eurasian Economic Review,17 October 2016,https://link.springer.com/article/10.1007/s40822-016-0056-7,Seat-vote elasticity and the provincial distribution of government spending in Turkey,April 2017,Çağrı Levent Uslu,,,Male,Unknown,Unknown,Male,"In this paper we look at how the central government in Turkey distributes spending across the provinces. Roughly Government spending can be categorized into three; (a) Government consumption, (b) Government investment and (c) transfer payments. Government consumption and transfer payments are not of interest to this paper. Furthermore, the core interest, Government Investment, can also be categorized into two according to the institutions that the spending is carried out. The first method is funding the Municipality Budgets in order to ensure the persistence of governmental services. The municipality elections are majoritarian type of elections, and thus, will also not be discussed in this paper. However, it is argued that “politics” has the predominant role in determining the municipality budgets compared to allocation of central budget in which “demographics and economics” have the predominant role. Yet, the relation between municipality budgets and politics may be the interest of a further study. The second is direct funding of projects in provinces by governmental institutions such as General Directorate of Highways, Provision of Social Housing or General Directorate of Mineral Research and Exploration. These projects include agriculture, mining, manufacturing, energy, transportation and communication, tourism, residential investment, education, health and unclassified infrastructure investments. This paper focuses on the behavior of the Government in allocating its infrastructure investment fund among provinces and especially its relation with political and demographic variables. The main hypothesis is that the central government budget allocation among provinces may differ due to seat-vote elasticity of the province. Seat-vote elasticity may be defined as the change in proportion of seats in a province caused by a change in proportion of votes in that province. The behavior of the Government in allocating resources, which is predominantly guided by political actors, may be a result of this elasticity. This is because seat-vote elasticity in proportional representation may be greater than one when there two or more parties actively competing in the province, and less than one if there is only one dominant party in the province. Although the theory fits majoritarian election systems better, it finds itself a meaningful room in Turkey given the existence of 10 % threshold in electoral system. If seat-vote elasticity can vary across the provinces in Turkey, so can the central government’s budget allocation to the provinces. This may lead the government to tilt spending towards provinces where the marginal benefit of votes in terms of seats in the parliament is high, and away from provinces where the marginal benefit of votes is low. In addition to the seat vote-elasticity, it is a fact that, beside the basic economic and demographic variables, central government spending may be affected by other political forces such as loyalty of the province to the incumbent party. The term “loyalty” may be used to define two opposing cases. In both cases the seat-vote elasticity is low, yet in the first case the province may already be very loyal to the incumbent party, which will lead to no severe change in proportion of the seats occupied by the incumbent, whereas in the second case the seat-share of the incumbent is considerably low and voters tend not to change their previous decisions. As far as can be determined, there are no studies that try to explain the allocation of central Government spending among provinces. The main interest in the Turkish context, on the other hand, is the contributions of the provinces to the central government budget rather than spending. The spending side have been implicitly studied under the headline of “economic self-sufficiency” which can be briefly explained as the ratio of provincial contribution to the central budget to the provincial government spending.",
7.0,1.0,Eurasian Economic Review,14 February 2017,https://link.springer.com/article/10.1007/s40822-017-0064-2,Two state disputes and outside intervention: the case of Nagorno–Karabakh conflict,April 2017,Ani Harutyunyan,,,Female,Unknown,Unknown,Female,"Disputes between two states are common events across the world. If the disputants do not resolve the issue via negotiations, they may go to war. In most cases those two states are not the only participants in the war, there is always a possibility of intervention by other states that pursue their own interests and affect the final outcome. Consider two states that are involved in a dispute. One side is “dissatisfied” and claims a territory from the other state, while the other is “satisfied” and prefers the status quo to conflict; therefore it may wish to make some concessions to the other side to avoid a possible conflict. This paper models such a dispute between two states in the framework of game theory. Hence, the purpose of this research is limited to game theoretical aspects of the conflict and does not include an examination of its underlying nature or detailed history. The theory is applied to the case of Nagorno–Karabakh conflict. Nagorno–Karabakh (Artsakh) is a landlocked region in the South Caucasus. It was claimed by both Armenia and Azerbaijan when both countries first became independent in 1918 after the fall of the Ottoman Empire, and a brief war over Nagorno–Karabakh broke out in 1920. The dispute was largely shelved after the Soviet Union established control over the area and created the Nagorno–Karabakh Autonomous Oblast within the Azerbaijan Soviet Republic in 1923. During the fall of the Soviet Union the conflict over the region re-emerged. Although there was no formal declaration of war, there was large-scale combat between Azerbaijan and the Armenian population of Nagorno–Karabakh in late 1980s. In 1991 the predominantly Armenian-populated region of Nagorno–Karabakh held a referendum and declared its independence backed by the Republic of Armenia. The large-scale ethnic conflict escalated into a full-scale war between the two newly-independent Republics of Azerbaijan and Armenia. The war ultimately brought victory for the ethnic Armenians who took Nagorno–Karabakh region under their control and additionally pushed on to control territories outside the region, creating a buffer zone and linking Nagorno–Karabakh with Armenia. Since the ceasefire of 1994, representatives of the governments of Armenia, Azerbaijan and unrecognized Nagorno–Karabakh Republic have been involved in peace talks mediated by the OSCE Minsk Group on the region’s disputed status. The format of the peace talks has slightly changed by the end of the 1990s, and currently the main actors and sides of this conflict are the Republics of Armenia and Azerbaijan. Azerbaijan is in “dissatisfied” position, since it claims Nagorno–Karabakh as part of its territory, which is under ethnic Armenian control. Armenia is “satisfied” and prefers the current status quo to conflict. This paper develops a model capturing the current state of the conflict and makes predictions on its possible future developments. The conflict is modeled based on Fearon (1995)’s take-it-or-leave-it bargaining game. The dissatisfied state makes an offer to the satisfied state demanding a part of its territory. In the case of Nagorno–Karabakh conflict Azerbaijan can demand from Armenia the whole territory of Nagorno–Karabakh region or a part of it, or only the buffer zone surrounding the Nagorno–Karabakh region.Footnote 1 The satisfied state can accept the demand and give up that part of its territory or reject the proposal, in which case the two states go to war. Note that there is no assumption about which state starts the war. The war is a result of failed negotiations. Extensive literature has been devoted to the modeling of war. In this study the war is modeled as a costly lottery based on a model proposed by Powell (1996). War is considered a risky event where the outcomes are uncertain. Players have costs for fighting and have expectations about the outcome. These expectations are based on the distribution of power which is common knowledge among players. The assumption about distribution of power being common knowledge is not a strong assumption for the case of Nagorno–Karabakh conflict, given the fact that the main actors of the conflict are small neighbor countries formerly belonging to the same bloc and have already had an experience of war with one another. First, under the assumption of perfect information, it is shown that there is no risk of war and the states always achieve a peaceful solution through negotiations. Next, the assumption is relaxed and uncertainty is introduced into the model. Following Powell (1996), it is assumed that the parties are not informed about each others costs of war.Footnote 2 Uncertainty makes war possible with positive probability. The probability of war depends on the level of uncertainty, distribution of power, and costs for fighting. Third parties can intervene and alter these factors affecting the probability of war and the final outcome of the dispute. There are different forms of third party intervention; conciliation, mediation and other forms of conflict management. As a form of third party intervention, this paper examines coercive intervention and considers two ways of implementations. The first is shifting the balance of power among players, which can be done by using military force and/or providing weapons, money or other forms of aid. The second way is to target one of the player’s costs for fighting, for instance by economic sanctions and embargoes. Given the geopolitical situation in the South Caucasus, the conflict between Armenia and Azerbaijan is subject to interventions by third-party countries which seek to promote their own interests in the region by supporting one or the other side. The Russian Federation has strong interests in the region. Together with several countries, including Armenia, Russia founded the Collective Security Treaty Organization, whose main goals are to deepen military-political cooperation and to create mechanisms for providing assistance, including military assistance to member states which find themselves victims of aggression. Given the existence of this organization, our model considers the possibility of intervention by Russia, which shifts the balance of power in favor of Armenia by providing military assistance. In order to support its ally Azerbaijan in the Nagorno–Karabakh war, the Republic of Turkey closed its border with Armenia in 1993 imposing an economic embargo on the country. This is a classical example of coercive intervention that increases the costs for fighting of one of the parties. The ongoing blockade isolated Armenia from all the regional pipeline and infrastructure projects; Baku–Tbilisi–Ceyhan oil pipeline, Baku–Tbilisi–Erzurum natural gas pipeline, Kars–Tbilisi–Baku railway, all of which bypass Armenia. The border between Turkey and Armenia remains closed till now. The recent negotiations to open it were unsuccessful. Even if there is a possibility of opening the border, Turkey always has the option of closing it again when a war breaks out, as a way to support Azerbaijan. Taking account of these developments and also the historical and political aspects of Armenian–Turkish relations, the model considers the possibility of an intervention by Turkey that targets Armenia’s costs for fighting. The paper incorporates third parties in the model based on an approach suggested by Rauchhaus (2005), that allows to identify above mentioned two ways of implementation of coercive intervention.Footnote 3 Rauchhaus (2005) assumes that the players are risk neutral. This paper takes a more general approach assuming that players can also be risk averse. Given the presumption that state leaders normally wish to retain the territory and power rather than accept gambles that have a risk of eliminating the state and the regime, this approach is much more plausible. Additionally, this paper examines the joint effect of two interventions which happen simultaneously. This investigation is particularly relevant for the case of the Nagorno–Karabakh conflict. The paper is organized as follows. Section 2 presents the formal model. The first part assumes perfect information, the second part introduces uncertainty. Section 3 presents the results of comparative statics. Section 4 incorporates a third party into the model. The first part of the section incorporates a form of coercive intervention that targets one of the disputant’s cost, and the second part incorporates a form of coercive intervention that shifts the balance of power. The last part of the Sect. 4 allows two forms of intervention to act simultaneously and investigates their joint effect. The final section of the paper, Sect. 5, makes concluding remarks on the results of the model and discusses its implications on the probability of war break out and possible resolutions of the Nagorno–Karabakh conflict. The Appendix presents the proofs of the propositions and results.",3
7.0,1.0,Eurasian Economic Review,01 December 2016,https://link.springer.com/article/10.1007/s40822-016-0060-y,Production technology and technical efficiency: irrigated and rain-fed rice farms in northern Ghana,April 2017,Benjamin T. Anang,Stefan Bäckman,Antonios Rezitis,Male,Male,Male,Male,"Ghana’s economy is highly dependent on agriculture, which is the second largest contributor to gross domestic product (GDP) after the service sector. According to Namara et al. (2011), agriculture contributes about 65% of the country’s labour force, generates about 40% of GDP, and provides about 40% of earnings from international trade. Despite the high dependence on agriculture, the country continues to experience inadequate food production because of high dependence on natural precipitation, use of inappropriate production technologies, planting of low-yielding varieties, among other factors (Chamberlin 2007; ISSER 2006). Smallholders who produce on subsistence basis dominate Ghana’s agricultural sector and account for the growth of the sector (Diao 2010). These smallholders cultivate less than two hectares of land (MoFA 2013) and contribute about 80% of the total agricultural production (Namara et al. 2011). Efforts at irrigation infrastructure development to harness the potential of the agricultural sector have been minimal despite the importance of agriculture to Ghana’s economic growth. Ghana’s irrigation potential remains largely unexploited with less than 2% of the irrigation potential harnessed for agricultural production. According to Diao (2010), agriculture in Ghana is highly dependent on rainfall with only 3% of total crop area under irrigation. Kuwornu and Owusu (2012) highlight Ghana’s low irrigation practice and limited irrigation infrastructure. The limited access to irrigation coupled with the predominance of smallholder producers who use mainly low-level technology in production partly account for the low agricultural productivity in Ghana. Furthermore, the rain-fed conditions that characterise the country’s agricultural sector also account for the low productivity and output levels (ISSER 2006). The productivity-enhancing role of irrigation, particularly in low-income food-deficit countries has been recognised by many authors (Lemoalle and de Condappa 2010; You et al. 2011, 2014; Xie et al. 2014). Available studies also point to an improvement in agricultural production in many Sub-Saharan African countries that rely more on irrigation technology (Adekalu et al. 2009; Lemoalle and de Condappa 2010). According to van Koppen et al. (2005), the promotion of irrigation is a prerequisite for agricultural growth, hence the need for developing countries to increase investment in irrigation infrastructure particularly for smallholder farmers. Access to irrigation also plays a positive role in food security, income and consumption at the household level (Sellamuttu et al. 2013). Similarly, Dillon (2008) found investments in irrigation to improve household consumption, food production as well as intake of calories and protein by households in northern Mali. Furthermore, the author found a positive correlation between investment in irrigation and household savings. Kuwornu and Owusu (2012) also found significant irrigation contribution to household per capita consumption expenditure in Ghana. One of the major crops produced with irrigation in Ghana is rice. According to the Ministry of Food and Agriculture (MoFA), rice production in the country provides employment for 10% of farm households (MoFA 2009). Rice production is categorised by agro-ecology into irrigated (16%), rain-fed lowland (78%) and rain-fed upland system (6%). The total rice cropping area in 2008 was 118,000 hectares, with an estimated average household landholding of 0.4 hectares (MoFA 2009). Irrigated rice yields range between 3.5 and 7 tonnes per hectare (FAO 2005). This gives an average yield of 4.6 tonnes per hectare for irrigated rice production, which exceeds the yield of 1.0–1.5 tonnes per hectare under uncontrolled water conditions. The estimated mean yield for sawah rice without fertiliser application ranges between 2 and 2.5 tonnes per hectare. Even though there are a number of studies on the technical efficiency of smallholder rice production in Ghana, the authors find very limited studies that compare the technical efficiency of irrigated and rain-fed rice production among Ghanaian smallholders. The few available comparative studies include Al-hassan (2008) who compared the technical efficiency of rice farmers in Northern Ghana by estimating technical efficiency for the pooled sample as well as separate functions for irrigators and non-irrigators. The study showed rain-fed farms to be 2.2% points more efficient than irrigated farms. In another study, Al-hassan (2012) compared technical efficiency of irrigated and rain-fed farms in the Upper East Region of Ghana and found irrigators to be 3% points more efficient than non-irrigators. In comparing technical efficiency of rain-fed and irrigated farms in Tigray, Ethiopia, Gebregziabher et al. (2012) used propensity score matching to account for differences in the biophysical environment of irrigators and non-irrigators. Their findings showed rain-fed farms to be 37% points more efficient than irrigated farms. Makombe et al. (2007) also compared the technical efficiency of rain-fed and irrigated rice production in Ethiopia and concluded that irrigation leads to an upward shift of the production frontier. This is because irrigation reduces the risk of crop failure and promotes the intensification of input use. The conflicting results from the studies above therefore calls for further investigation into the comparative efficiency of the different rice production systems among smallholders. To compare the efficiencies of different rice ecologies or farming systems requires that we control for the differences in biophysical conditions and test whether the two systems employ the same technology in production. As noted by Gebregziabher et al. (2012), comparing the efficiency of irrigated and rain-fed rice production without accounting for the differences in biophysical conditions is likely to lead to inconsistent and biased estimates. Furthermore, Stigler (1976) and Mayen et al. (2010) assert that an explicit test of the production technology type is required in comparative efficiency studies. We therefore find a drawback with previous studies that compared the technical efficiency of rice production systems that did not account for the differences in biophysical conditions and failed to conduct an explicit test of the production technology type. An implicit assumption of a homogeneous production type, as in the case of many previous studies, is likely to give misleading results. For example, Mayen et al. (2010) in their comparative study showed that a wrong assumption of technology type led to a downward bias in the efficiency on organic dairy farms relative to conventional farms in the United States. Other researchers including Elias et al. (2014) conducted formal tests of the technology type in their comparative efficiency studies. Thus in the current study, the study accounts for the differences in biophysical conditions and controls for self-selection in the estimation of technical efficiency of irrigated and non-irrigated farms using propensity score matching to obtain reliable estimates of the effect of irrigation participation on productivity and efficiency of production.",21
7.0,1.0,Eurasian Economic Review,17 January 2017,https://link.springer.com/article/10.1007/s40822-016-0061-x,The impact of wage share on domestic demand in the European Union,April 2017,Zita Tamasauskiene,Janina Seputiene,Daiva Berzinskiene-Juozainiene,Female,Female,Female,Female,"For many years, there was consensus in the constancy of labour and capital shares in national income. That is why the research interest has shifted from functional to personal income distribution. The labour share (or wage share) is the part of national income that goes to labour. Research reveals that the labour share has been falling for many years in most countries (Bassanini and Manfredi 2014; Guerriero 2012; Sweeney 2013). Although this fact has attracted the interest of scholars, international organisations and politicians worldwide, it remains an actual problem today. It should be mentioned that in recent years, the interest has centred more on the reasons for the decline in labour share than on the consequences of this decline. This paper investigates the impact of the wage share changes on domestic demand in the countries of the European Union (EU). The decrease in wage share has a positive effect on profits and investment, and in turn, it reduces the labour cost, which has a positive effect on exports. However, consumption is expected to decrease because the marginal propensity to consume out of capital income is lower than that out of labour income. If the overall effect on aggregate demand is positive, the demand regime is deemed to be profit-led; if the effect is negative, it is considered to be wage-led. Consumption is the largest part of the EU countries’ GDP. It also represents a large part of demand, which also has an impact on investment. Thus, a decline in the wage share can have a positive effect on investment owing to the increase in profits; however, in turn, it can have a negative effect owing to the decrease in demand (consumption). In the case of the EU countries, a positive and significant effect of the declining wage share on exports is unlikely as a much greater proportion of the EU member states’ total trade in goods (over 60%) is with partners inside the EU. If the wage share declines simultaneously for a large number of trading partners, the competitive gains of decreasing labour costs would be cancelled out and the wage share decline would depress domestic demand. Most of the studies find that domestic demand is wage-led; however, with the impact on net exports having been assessed, the aggregate demand regime could be said to be profit-led. There is a lack of research that assesses the shift of the impact of labour share changes on the components of domestic demand—consumption and investment—in countries with different levels of openness to international trade. The scientific problem of this study is reflected in the following question: Does the impact of labour share changes on domestic demand and its components differ in countries with different levels of openness to international trade? This assumption is justified by theoretical arguments. For example, the decrease in labour share has a positive effect on investment owing to an increase in profits; however, conversely, it has a negative effect owing to a decrease in consumption, which constitutes the majority of demand. However, this negative impact should be smaller in more open countries because the decrease in domestic consumption can be compensated by the increase in foreign demand (exports). The aim of this research is to assess the impact of wage share changes on domestic demand in the EU-country groups, which are determined by the individual countries’ levels of openness to international trade. The uniqueness of this paper is that most of the research in this field centres on the effects of changes in the functional income distribution on demand, but they pay little attention to other important factors such as the saving rate or debt. So, the first contribution of this paper is that we compare the impact of labour share changes on domestic demand in the country groups with different levels of openness to international trade. The second contribution is that we follow Stockhammer and Wildauer (2015) and extend the Bhaduri–Marglin model to include private debt. The third contribution is that our regression estimates are based on a panel of 28 EU countries covering the period 1995–2014, whereas most of the research in this field relies on time-series analysis for individual countries (i.e. Onaran and Galanis 2014; Stockhammer et al. 2011; Stockhammer and Ederer 2008). To the best of our knowledge, Hartwig (2014) and Stockhammer and Wildauer (2015) were the first to develop an empirical model using a panel of OECD countries. Hartwig (2014) uses a panel of 31 OECD countries from 1970 to 2011 and finds that a decline in the wage share has a negative impact on demand. Stockhammer and Wildauer (2015) reach the same conclusion using a panel of 18 OECD member countries from 1980 to 2013. Kiefer and Rada (2015) use a panel of 13 OECD countries, but they find that the demand regime is profit-led. Social and economic processes in the EU countries are relatively independent; however, they are much more integrated than the OECD countries. The EU not only connects the common market, which is established by standardised laws and regulations and assures the free movement of people, capital, goods and services, but it also has common policies for trade, agriculture and regional development. The EU countries participate in the common market and their international trade is regulated by the same rules; however, the level of openness of individual countries to international trade is different and this may affect the impact of the labour share on demand. We find that the average demand regime in the EU is wage-led, as both consumption and investment are negatively affected by the wage share decline. Domestic demand remains wage-led in both the more open and the less open economies, but the impact of the decline in wage share on investment in the more open economies changes from negative to positive. The remainder of the paper is organised as follows. Section 2 discusses the issues of measuring the labour share. Section 3 describes the impact that the wage share decline has on private domestic demand. Section 4 presents the data sources and research methods, and Sect. 5 presents the findings of the study. Section 6 compares our results with the previous findings in the literature and the final section concludes.",2
7.0,1.0,Eurasian Economic Review,24 January 2017,https://link.springer.com/article/10.1007/s40822-016-0063-8,Self-selection and learning-by-exporting hypotheses: micro-level evidence,April 2017,Naqeeb Ur Rehman,,,Unknown,Unknown,Unknown,Unknown,,
7.0,2.0,Eurasian Economic Review,23 February 2017,https://link.springer.com/article/10.1007/s40822-017-0069-x,Nonlinearity and asymmetry in the monetary policy reaction function: a partially generalized ordered probit approach,August 2017,Hakan Danis,,,Male,Unknown,Unknown,Male,"In the last two decades many economists have been interested in estimating monetary policy reaction functions because finding a well-specified monetary policy rule could help economic agents predict the Federal Reserve’s policy changes and decrease the uncertainty about the economy. It would also be easier for the Federal Open Market Committee (FOMC) members to decide what they should do. After Taylor (1993)’s seminal work, researchers have been trying to find whether the Federal Reserve follows a simple monetary rule called the Taylor rule. In his seminal work, Taylor characterizes the Federal Reserve’s monetary policy with a very simple linear model. He argues that the Fed changes its target rate in two cases: when the current inflation rate deviates from its target and when the output gap changes. Since the model became popular, new versions of the rule have appeared both in empirical and theoretical papers. Although vast majority of the estimated monetary rules are linear, researchers have also started to use nonlinear monetary rules in recent years. There are indeed several reasons to believe that the Federal Reserve might be following a non-linear monetary rule or, at least, Fed’s monetary policy could be explained by a nonlinear monetary policy rule model as pointed out in the recent literature. First, central banks’ preferences might be asymmetric regarding the weights on deviations of inflation and/or output from their targets. Even if the economic structure is linear, asymmetric preferences (i.e. non-quadratic loss function) lead to nonlinear monetary rules.Footnote 1 Therefore, for example, if a central bank is hawkish about inflation, it is more likely to increase the interest rate more aggressively when the inflation rate is higher than its target compared to when inflation is lower than its target. Moreover, as Blinder (1998) points out, central banks are confronted with more political pressures when they use preemptive strict monetary policy to avoid high inflation than when they use preemptive loose monetary policy to avoid higher unemployment. It will create similar nonlinearity in the monetary reaction function. Cukierman (2000) also argues that this nonlinearity arises because some central banks are accountable to politicians by law, which makes them biased to recessions than to expansions. By using a specific non-quadratic loss function (Orphanides and Wilcox (2002); Aksoy et al. (2006) argue that when inflation is above but close to its target, it may not be optimal to take anti-inflation actions. Instead, the central bank should wait for favorable exogenous shocks (focusing on output stabilization) because of a worsening trade-off between inflation and output. On the other hand, if inflation is too high from its target, the central bank should take anti-inflation policies. This will also create similar nonlinearity. Second, central banks following inflation targeting with a band rather than a point target would confront non-linearity in the monetary rule. In this case, if the inflation rate is within the target band, the interest rate changes more or less randomly because the central bank pursues non-active policies by only responding to exogenous shocks to the economy. On the other hand, if the inflation rate is outside the target band, the central bank can be more aggressive in changing interest rates because of both inflationary and deflationary fears. Taylor and Davradakis (2006) based their arguments on these issues and found a significant nonlinearity in the Taylor rule for the UK. Orphanides and Wieland (2000) consider this nonlinearity and find a theoretical rationale for targeting a band in inflation targeting policy. Although the Fed does not pursue an inflation targeting regime, having an explicit or implicit inflation band target would cause some nonlinearity in the Fed’s policies. Third, because recessions and booms have different characteristics, there might be some nonlinearities and asymmetries in the adjustments during business cycles. For example, Keynes (1936) states that an economy experiences sharp but short downturns in recessions and smooth but long upwards in recoveries. Therefore, the central bank should change interest rates at different phases in recessions and booms, which makes Taylor rule specifications nonlinear. Therefore, as Neftci (1984, p. 308) argues, ``If the time series exhibit an asymmetric behavior over the business cycle, then a model that generates sharp drops during contractions followed by gradual movements during expansions will have `better’ predictive power. Otherwise, one would expect the `fit’ to deteriorate around turning points.” Finally, an asymmetric interest rate smoothing might cause nonlinearity in the reaction function. The literature on smoothing generally focuses on linear smoothing behavior of the central banks. However, uncertainty about the current and future state of the economy makes central banks more cautious in implementing monetary policies. As Florio (2006) investigates, central banks might adjust interest rates at different paces during strict and loose monetary policy. If the central bank is more biased to recessions than to expansions (as Cukierman (2004) argues) a tight monetary policy would be more gradualist than a loose monetary policy. In her paper, Florio (2006) finds support for an asymmetric interest rate smoothing. Given the inherent nonlinearity in central banks’ policy actions, a nonlinear model should be used in the estimation of monetary policy rules. In this paper, therefore, we estimate nonlinear monetary rules by employing a partially generalized ordered probit model using monthly data. Using discrete choice models is not a new idea. However, this paper challenges and improves the literature by introducing a new form of nonlinearity in monetary rules. In our knowledge, this is the first attempt to use partially generalized ordered probit model in the monetary economics field. Previous literature (that used discrete choice models) has used ordered probit models which assume parallel regressions (lines) in other words, all parameters, βs, are identical across each choice. In this paper, we use a partially generalized ordered probit model, by eliminating parallel lines assumptions which do not generally hold. Employing a generalized ordered probit model reveals important information for people following the Federal Reserve’s actions, i.e. whether the Fed considers different variables when it is trying to make a decision for a big or small decrease rather than for a small decrease or no change. This feature of the partially generalized ordered probit model calculates a kind of new asymmetry in addition to nonlinearity in the monetary rule. Our particular goal is to estimate a nonlinear model to understand whether the Fed is following a nonlinear monetary policy rule or at least its policies could be explained by one. For this reason, we estimate three specifications following the previous literature by using ordered and partially generalized ordered probit model. The results indicate that the general monetary policy rule fits the data better than the standard Taylor rule model with or without interest smoothing. Standard Taylor rule exhibits misspecification issues as the coefficient for the inflation rate is found to be negative contrary to the previous literature and intuition. It has also the highest AIC statistics among the three models. For all models, threshold estimates indicate that the FOMC waits for relatively higher changes in the explanatory variables before it decides for a change in the key rates. However, once these thresholds are passed, relatively smaller changes in the explanatory variables are needed for FOMC to make a decision. The test statistics (LR test) for the parallel line assumptions results show the parallel line assumptions do not hold for all ordered probit models. Although generalized ordered probit models are very flexible they might be inefficient. Therefore, we estimate all models with partially generalized ordered probit models after testing whether any of the parallel regression assumption holds only for some of the variables. We impose parallel line restrictions on some of the variables and select the model with the lowest AIC. The AIC statistics are improved when the models are estimated by a partially generalized ordered probit model for all three models and the general monetary policy rule model still has the lowest AIC. The results indicate that the general model still fits the data better. Partially generalized ordered probit models show that the Fed assigns different weights for some macroeconomic factors when it is trying to make a choice, for example, between a big and small decrease or a small decrease and no change in the federal funds target rate. For example, the Federal Reserve gives equal (different) weights for the consumer sentiments (inflation rate) to decide between a big increase and a small increase or small decrease and big decrease. To check the reliability of the results, we also estimate the models using different cut points for the federal funds rate. The results support our previous findings.",1
7.0,2.0,Eurasian Economic Review,01 March 2017,https://link.springer.com/article/10.1007/s40822-017-0068-y,Effectiveness of monetary policy: evidence from Turkey,August 2017,S. Burcu Avci,Eray Yucel,,Unknown,Male,Unknown,Male,"The transmission from central bank policy rates to banks’ deposit and credit rates is crucial for the well-being of an economy. Central banks’ most important tool for achieving these objectives is the control of liquidity in the banking sector and hence the short-term interbank interest rate. The effectiveness of this policy tool depends on various channels of transmission. Hence identifying different transmission mechanisms is central to understanding the effectiveness of central banks’ actions (Loayza and Schmidt-Hebbel 2002). This study aims to test how long it takes policy rates to be transmitted to credit and deposit rates of banks operating in Turkey and also to identify the factors affecting the pass-through process. We limit our analysis to the 2002–2014 period because it was the longest stable period in Turkish monetary policy and banking environment. Our analysis is based on the interacted vector autoregressive (IVAR) methodology (Towbin and Weber 2011) because of its versatility and analytical power. The IVAR approach estimates a VAR with coefficients varying deterministically with individual characteristics (interaction variables). An important advantage of this approach is that it allows us to understand the pass-through of policy rates to market rates as a function of various values of other economic variables, whose presence results in interaction effects. We prefer an IVAR approach over other VAR specifications employing exogenous variables firstly because IVAR’s greater flexibility in capturing the effects of interaction variables. The selected low and high percentiles of the interaction variables (25 and 75%) allow us to avoid from redundant effects due to extreme values of interaction variables. Second, this approach is transparent, allowing to observe the effect of each interaction variable one by one. Effective transmission channels require a competitive banking sector, well-developed stock and credit markets, a fully liquid financial sector, an independent central bank, a high-quality institutional and regulatory environment, a floating-exchange rate regime, full market development, and an effective secondary market for government securities (Cottarelli and Kourelis 1994; Cottarellli et al. 1995; Cecchetti 1999; Ehrmann et al. 2001; De Bondt 2002; Ito and Sato 2006; Leiderman et al. 2006; Sorensen and Werner 2006; Betancourt et al. 2008; Frisancho-Marischal and Howells 2009; Mishra et al. 2012; Saborowski and Weber 2013; Leroy and Lucotte 2015). Following this long recipe based on previous research, we use proxies representing these factors as interaction variables. Thus, we group these variables into five broad constructs: regulatory quality and competitiveness, dollarization, financial development, banking sector features, and macroeconomic features. We measure regulatory “quality” and competitiveness by means of a regulatory quality index, the Boone (2008) indicator, and the Herfindahl–Hirschman index. We use: ratios of foreign currency loans and foreign currency position to measure dollarization; gross domestic product (GDP) per capita, “broad” money, and the short-term credit rate to measure financial development; and liquidity, profitability, and a “bad asset” ratio to capture attributes of the banking sector. Finally, our macroeconomic variables are Turkish LIBOR, the Turkish industrial production index, the consumer price index, and the ratio of the net financial account (balance of payments) to GDP. We find that short-term interest rate pass-through is positively related to competition in the banking sector, as increased competition leads to an increase in pass-through to deposit and credit rates. Regulatory quality has the opposite effect on pass-through to deposit rates, and no effect on pass-through to credit rates. Banking sector and dollarization variables—such as profitability, liquidity, bad asset (nonperforming loans) ratios, exchange rate flexibility, and dollarization—have a positive effect on pass-through. Financial development variables are negatively (resp., positively) associated with pass-through to credit rates (resp., deposit rates). Macroeconomic proxies have various effects on interest rate pass-through. For example, economic growth and capital inflows have a negative effect on interest rate pass-through whereas inflation has a positive effect. The inclusion of different interaction variables in the IVAR specifications results in different speeds at which pass-through is complete. Nonetheless, full diffusion is typically realized within 8 months. Our results have important implications for policy makers seeking to make monetary policy more effective. First, encouraging competition in the banking sector should enhance its profitability and liquidity. Second, non-US policy makers should not require the use of their national currency in banking transactions because dollarization has a positive effect on interest rate pass-through; in other words, it is not hindered by globalization. Third, inflation has a positive effect on pass-through and so need not reduce monetary policy effectiveness. Finally, interest rate pass-through declines after increases in production, in broad money, in financial development, and in capital inflows; it also falls in response to higher regulatory quality. This paper contributes to the literature on interest rate pass-through in several ways. First, it provides a thorough account of Turkish interest rate pass-through by employing several interaction tools. In particular, we employ a comprehensive list of interaction variables in order to shed light on the effectiveness of monetary policy in Turkey. Second, our paper utilizes the relatively new IVAR methodology, which improves the standard VAR approach by allowing one to assess the effects of extreme values of the interaction variables. The rest of our paper proceeds as follows. Section 2 reviews the related literature and details the Turkish experience with interest-rate pass-through. In Sect. 3 we present the data, explain our estimation method, and conduct an empirical analysis. We conclude in Sect. 4 with a discussion of—and recommendations for—policy.",10
7.0,2.0,Eurasian Economic Review,27 February 2017,https://link.springer.com/article/10.1007/s40822-017-0067-z,Value at risk (VaR) analysis for fat tails and long memory in returns,August 2017,Samet Günay,,,Male,Unknown,Unknown,Male,"Financial risk management is one of the most important topics of finance theory. High volatility in asset prices makes risk management essential for both individuals and corporations. Due to this essentiality, many methods and tools have been tested and improved upon through financial engineering. In addition to conventional derivative instruments, such as option, forward, future and swap contracts, the trading volume of other tools achieve very high values. These tools, which have been more recently introduced in literature, include the Credit Default Swap, Collateralized Debt Obligations, etc. In general, financial risk is classified under three titles: market risk, credit risk, and operational risk. In addition, market risk consists of interest rate risk, currency risk, and liquidity risk. Market risk can be defined as a decline in the value of any asset in portfolio. The most popular method used in market risk measurement is value at risk (hereafter VaR). The VaR, which was improved by J. P. Morgan in the beginning of 1990s, is a statistical method that represents the maximum loss that can be exposed in a portfolio in a specified confidence level and holding period. Various failures and scandals in financial markets in the 1990s (Orange County and Barings Bank) and 2000s (Enron and Lehman Brothers) indicate the importance of risk measurement and management. Since the creation of VaR analysis, many different variations and applications have been introduced in literature, such as; the Parametric VaR (Delta-normal VaR or Variance–Covariance), the Historical VaR, the Monte-Carlo Simulation VaR, the Delta-Gamma VaR (for option including portfolios), the Cornish-Fisher VaR, and the Conditional VaR. These methods differentiate from each other in some specific points. For instance, Parametric VaR assumes that returns are scattered in accordance with the Gaussian distribution. According to the Historical VaR, returns follow the same distribution as in the past. As stated by Yildirim and Colakyan (2014), since the Historical VaR considers real past returns, it may be an accurate method for investors. However, it cannot instantly respond to large movements in the market as it weighs each data point equally. Monte Carlo Simulation produces random numbers through a generating function for a respective time horizon. As for Cornish–Fisher VaR, it takes into account asymmetry and kurtosis features of the return distribution. However, as stated by Aktas and Sjostrand (2011) in cases where there are significant deviations from normal distribution, the model might be inaccurate. Since the pioneering studies of Mandelbrot (1963, 1972), it has been observed that financial time series have some stylized facts: deviation from normal distribution, volatility clustering, leverage effect and long memory (see Cont 2001). Traditional finance theory, which is based on Bachelier (1900) and Fama (1965, 1970), assumes that asset returns obey the normal distribution and follow a random walk. Therefore, models built on traditional finance theory, such as Efficient Market Hypothesis (EMH), Capital Asset Pricing Model (CAPM), Black–Scholes Option Pricing Model, also hold these two assumptions. On the other hand, ignoring stylized facts of financial time series would cause biased results in the analyses. It is obvious that this situation is also valid for the VaR analysis. Inaccuracy in measurement of risk would bring about a miscalculation in the magnitude of risk, and so with long or short positions, would deviate from the optimum point, becoming too big or too small. Therefore, taking into consideration the stylized facts of financial time series when carrying out of the VaR analysis would provide more accurate results. As stated by Rieger et al. (2011) it is not possible to have excess risk-adjusted returns in efficient markets, however it is known that excess returns exist in the markets. In this study, we employ VaR analyses using different models and simulations. In conjunction with the fundamental models (Parametric, Historical and Monte Carlo Simulation) we also used two alternative simulation models which take into account the long memory in returns and fat tails in return distributions which are named in this study as the Long Memory Simulation VaR and the Alpha-Stable Simulation VaR. Empirical analyses are first executed for single asset returns and portfolios formed by those assets. Assets used in the empirical analyses are as follows: BIST100 Index returns, Brent Oil returns, Dollar/Turkish Lira currency rate returns, Euro/Turkish Lira currency rate returns, and gold returns. Although there is a great deal of interest in the VaR analysis, we have seen that the aforementioned stylized facts have not been sufficiently studied in Turkish context. While in some studies student-t and GED distributions are used concerning Turkish financial markets (see Bostanci and Korkmaz 2014; Evci and Kandir 2015), alpha-stable distributions and the long memory feature are not taken into account. This literature gap is the motivation of this study. The following sections of this paper have been organized as follows: section two presents the literature for the VaR analysis. In section three, theoretical information will be given for the models used in empirical analysis. Finally, the last section submits the results of the empirical analysis through different VaR models and simulation studies.",8
7.0,2.0,Eurasian Economic Review,17 February 2017,https://link.springer.com/article/10.1007/s40822-017-0065-1,The impact of oil price volatility on net-oil exporter and importer countries’ stock markets,August 2017,Berna Aydoğan,Gökçe Tunç,Tezer Yelkenci,Female,,Male,Mix,,
7.0,2.0,Eurasian Economic Review,21 October 2016,https://link.springer.com/article/10.1007/s40822-016-0057-6,Stock liquidity on China NEEQ exchange,August 2017,Ning Liu,Wei Xu,,,,Unknown,Mix,,
7.0,2.0,Eurasian Economic Review,16 February 2017,https://link.springer.com/article/10.1007/s40822-017-0066-0,Financial liberalization and private sector borrowing in ASEAN 4 economies 1990–2012,August 2017,Percival Pineda,,,Male,Unknown,Unknown,Male,"This study applies Stein’s (2003, 2012) stochastic optimal control-dynamic programming to derive the optimal debt/net worth ratio of the business sector in the ASEAN 4 economies: Indonesia, Malaysia, the Philippines, and Thailand. These countries liberalized financial markets during the mid-1980s, which changed the borrowing and lending dynamics in their economies. Prefaced by empirical evidence that financial liberalization increases capital inflows and reduces cost of capital, I explore whether financial liberalization prompted excessive business sector borrowing. Data from The World Bank reveal massive capital inflows (the sum of foreign direct investment and portfolio equity inflows) into ASEAN 4 economies following financial liberalization. From 1985–1996, capital inflows surged 2485% in Indonesia, 1596% in Thailand, 631% in Malaysia, and 300% in the Philippines. During the 1997–1998 Asian financial crisis, however, Indonesia suffered massive capital outflows that continued until 2000. While capital inflows declined 58% in Malaysia and 2% in Thailand, inflows into the Philippines rose 213% during the Asian financial crisis. During the early years of financial liberalization, lending rates in the ASEAN 4 exceeded 10% (The World Bank 2015a). In 1987, they were 21.7% in Indonesia, 10.4% in Malaysia, 13.3% in the Philippines, and 11.5% in Thailand (The World Bank 2015a). Over 1990–2012 after financial liberalization, data from The World Bank (2015b) show  mean real interest rates were 4.5% in Indonesia, 3.8% in Malaysia, 5.1% in the Philippines, and 5.7% in Thailand. ASEAN 4 equity markets were buoyed by inflows until 1996. From 1990 to 1995, equity market capitalization in Indonesia, Malaysia, the Philippines, and Thailand rose 664, 436, 613, and 353%, respectively (Thomson Reuters, DataStream). Over 1990–2012, capital gains averaged 7.5, 3.4, 2.7, and 4.4% in Indonesia, Malaysia, the Philippines, and Thailand, respectively. This paper shows that massive capital inflows after financial liberalization led to unsustainable debt accumulation during the run-up to the 1997–1998 Asian financial crisis. In a scenario of lower interest rates with higher output, I surmise that risk-taking by the business sector could have intensified as the risk/reward ratio fell, leading to intemperate borrowing. Excessive debt build-up leading to unserviceable claims from domestic and foreign creditors creates macroeconomic pressures that could have precipitated the 1997–1998 crisis. In 1996, the economies of Indonesia, Malaysia, the Philippines, and Thailand’s economies expanded 7.6, 10, 5.8, and 5.7%, respectively (The World Bank 2015c). Indonesia, Malaysia, and Thailand were affected the most during the financial crisis, with their GDPs falling 13.1, 7.5, and 7.7%, respectively, in 1998 (The World Bank 2015c). The Philippines sustained a 0.6% drop in GDP in 1998. The rising magnitude of business sector debt has not been explored empirically as a cause of the 1997–1998 Asian crisis, which impacted the ASEAN 4 economies including Korea. In financial theory, firms borrow when their net worth increases through appreciation in assets. Firms leverage-up when borrowing costs are low and returns on capital are high. The spread between returns and borrowing costs influences risk-taking in the business sector. Thus, estimating the optimal debt/net worth or debt/equity ratios is critical to the analysis of business sector debt. The deviation between actual and optimal debt/net worth defines excess indebtedness. Quantifying excess indebtedness or debt above an optimal level provides an early warning of financial crises. No optimal debt/net worth ratio has been estimated for ASEAN 4 economies, particularly before the run-up to Asia’s worst and most contagious financial crisis. My empirical results support Stein’s (2003, 2012) theory on excessive borrowing, which predicted the 1997–1998 crisis, and illuminate how excessive business sector borrowing exacerbated it. My findings are important for constructing monetary and fiscal responses to financial crises. The 2008–2009 global crisis demonstrated that economic recovery can be slow and weak. Moreover, as Aysan et al. (2014) observed, quantitative easing when recovery is weak and fiscal positions are restrictive creates ample but volatile global liquidity, leading to short-term and volatile capital flows to emerging markets. Dramatically higher capital inflows to the ASEAN 4 starting in the mid-1980s were a catalyst for excessive business sector borrowing that precipitated the 1997–1998 crisis. Section 2 discuses two strands from the literature relevant to this study: the credit channel’s effect on output and the concept of optimal debt. Section 3 derives the optimal debt/net worth ratio, drawing upon Stein’s theory of stochastic optimal control-dynamic programming for modeling debt crises. Section 4 discusses my data and method and presents an estimate of excess indebtedness. Section 5 concludes by noting my findings support Stein’s theory that rising excess indebtedness signals financial crises.",3
7.0,2.0,Eurasian Economic Review,20 March 2017,https://link.springer.com/article/10.1007/s40822-017-0070-4,Stickiness of employee expenses and implications for stock returns,August 2017,Roi D. Taussig,,,Unknown,Unknown,Unknown,Unknown,,
7.0,3.0,Eurasian Economic Review,24 June 2017,https://link.springer.com/article/10.1007/s40822-017-0076-y,The tragedy of the commons: the logic of entry and the dynamic process under two scenarios,December 2017,Hiroaki Hayakawa,,,Male,Unknown,Unknown,Male,"The purpose of this paper is to make explicit the dynamics of entry and adjustment that takes place in the process leading to the tragedy of the commons that Hardin (1968) warned of. According to him, the commons are locked into an unavoidable system that compels the users to exploit without limit. Hardin named this fate the tragedy of the commons and attributed its cause to the behavior of individuals who seek private gains at the expense of the social good. The problem is deeply seated in the fatal tendency of mankind (Bastiat 1850), and it has been deplored since time immemorial.Footnote 1 In recent years, there has been a resurgence of interest in this problem along more focused lines that criticized Hardin’s model for its incompleteness and unrealizm in dealing with the commons.Footnote 2 The trend of the research took a sharp turn when Ostrom (1990) turned the question upside down by asking: If common resources are excessively used under the constraining rules of the game, how can we enhance the capabilities of the users themselves to change the rules of the game so that the tragedy may not ensue? (Ostrom 1990, p. 7) She demonstrated how the tragedy can be avoided by working out a binding contract that is enforced cost-effectively. An important message from this literature is (1) that the problems of the commons cannot be dealt with in an overarching manner since each has its own unique structural features and sits within a particular culture and social norms, all of which could potentially contribute to successful management, and (2) effective remedies of free rider problems could be worked out without resorting to the coercive power of states (Ostrom et al. 1994, 2010a, b). Despite such development, the question of the dynamic process of entry and adjustment has been left aside almost completely from the outset. A typical game-theoretical treatment of the non-cooperative outcome of the commons hinges on the assumption that the commons are used by a finite number of users (see, e.g., Ostrom 1990, 1998), and asks how this outcome diverges from the social optimum. This approach has dominated the field and has become a standard way of understanding the tragedy of the commons (e.g., Gibbons 1992; Osborne 2004). If only a finite number of users are at stake, it is not difficult to work out a solution through collective action. The more challenging question is what will happen if the number of users increases indefinitely with mounting pressure on the use of common resources. Such pressure makes it increasingly difficult to attain the needed collective action because all users must comply with a contractual agreement of some kind, even if some selective incentives are well delineated and provided (Olson 1965). This suggests that the prisoners’ dilemma game analogy of the tragedy of the commons, under the assumption that the number of users is fixed, is only half true because the problem facing the commons is not one of containment through a binding contract, but rather one of dis-containment due to unlimited population growth. This was the message of Hardin’s classical analysis.Footnote 3 This paper, therefore, attempts to fill this gap by making explicit the dynamic process of entry and adjustment through which the tragedy emerges. Hardin’s logic of the tragedy (1968, p. 1244), in the context of a bucolic example, is based on the following calculations: (1) In adding one more animal, the herdsman weighs the utility of the gain of the proceeds from the sale of the animal, which is nearly +1, against the negative utility of the cost of overgrazing which is shared by all the herdsmen, hence only a fraction of −1. Since the former outweighs the latter, the herdsman is compelled to keep adding more to his herd. Therefore, the herdsman has no choice but to raise as many cattle as possible in order to maximize his gain. But, this logic is only half valid because herdsmen certainly will not be able to maximize their gains by keeping as many cattle as possible. This is a serious fallacy in Hardin’s argument because the value function, which represents the average value of the herd as a function of the herd size (an equivalent to the market demand curve), is ignored altogether. In the absence of such valuation, no optimal decisions can be made. Knowing that Hardin’s overriding concern is the unregulated population growth as the ultimate cause of the tragedy, we need to correct this fallacy by elucidating the exact process that leads to the tragedy. To delve into this process, we need to answer two questions, first on the logic of entry that answers why it is profitable for a new entrant to enter the commons when the incumbent users are in equilibrium, and second on how the herd size of each herdsman is determined as potential herdsmen enter the commons sequentially. These questions need to be addressed from the standpoint of strategic behavior that distinguishes the reactionary and the proactionary nature of the users (Gordon 1954).Footnote 4
 The process of entry and adjustment analyzed in this paper can also account for a similar self-transformation process of the market structure through which duopoly and oligopoly emerge as a result of entry, leaving quite different equilibrium paths depending on how firms in general react or proact to the entry of other firms in the future. Such similarity is particularly useful in understanding why and how duopoly and oligopoly acquire such equilibrium features as are amenable to game-theoretical analysis once the number of firms is fixed. Our paper is organized as follows. In Sect. 2, in the context of a bucolic case, we define two key concepts, the additional benefit and the additional cost, of adding an animal to the stock, and analyze the dynamic process of entry and adjustment when all users react ex post to the entry of new users. Section 3 analyzes a similar process of entry and adjustment when all users anticipate and proact to the entry of new users at the point of entry. The difference between the two cases will be highlighted in terms of the distribution of the ownership, profits made in temporary stage equilibrium, cumulative profits of such profits, and the rate of depletion. We conclude in Sect. 4.",2
7.0,3.0,Eurasian Economic Review,03 July 2017,https://link.springer.com/article/10.1007/s40822-017-0075-z,Risk assessment of the local government sector based on the ratio analysis and the DEA method. Evidence from Poland,December 2017,Krzysztof Kluza,,,Male,Unknown,Unknown,Male,"Local governments (LGs) play an important role in national economies, providing public services and carrying out investment, especially in infrastructure. In the European Union (EU) countries, LG revenue amounted to 13.7% of GDP in 2015, remaining at a stable level of 13–14% of GDP over the last 10 years. The sector was a noticeable player in the stimulation of domestic demand during the 2008 post-crisis period. Its share in total investment in the EU grew from 7.0% in 2006–2007 to 9.2% in 2010. In 2014–2015 it stabilized at a relatively high level of 8.3%. Statistics for 2011–2015 are presented in Fig. 1. Source: Eurostat online database, Author's own calculation Significance of the LG sector in the EU countries from the perspective of revenues, investment and debt. Note 1 The color of the circles reflects the debt/GDP ratio of the LG sector in each country. White color ratio below 2.5%; checkered pattern ratio from 2.5 to 5.0%; grey color ratio from 5.0 to 10.0%; black color ratio above 10.0%. Note 2 The smallest countries such as Cyprus, Luxembourg and Malta are not included in the analysis The unchanged revenue base combined with increased investment efforts resulted in a durable adverse impact on the finances of LGs across the EU. Their average debt/GDP ratio grew significantly, from less than 5% in 2007 to 7.5% in 2015. In many countries the crisis also limited the financial resources transferred to LGs. This negatively influenced their financial standing and ability to provide public services as described in Vammalle and Hulbert (2013). The financial soundness of the LG sector may be an important factor facilitating economic growth. Several studies deliver arguments for the high effectiveness of LG spending, showing that fiscal decentralization increases GDP per capita, productivity, human capital, and the share of public funds directed to capital expenditures (see Blöchliger and Égert 2013). However, there is also evidence of politically driven transfers to local governments, targeted at securing support for elections, which causes inefficiencies (see Veiga and Veiga 2013; de Haan and Klomp 2013). The growing indebtedness of the public sector triggered a debate on how to implement fiscal consolidation and what choice of consolidation instruments favours long-term growth. The impact of fiscal policy tightening on growth is analyzed in Barrell et al. (2012). It shows the possible adverse impact of fiscal consolidation on growth in the short-term horizon. As described in Sutherland et al. (2012), the focus should be on finding policies with low multipliers in the short-term (e.g. related to pension systems) and undertaking reforms of budgetary institutions. In OECD reports devoted to Denmark (OECD 2012) and Finland (OECD 2014) policy recommendations point to merging LGs into bigger entities and implementing legal rules restricting growth of expenditure. Despite the worsening financial profile of LGs across the EU, there is little research devoted to the assessment of LG credit risk and debt repayment capacity. Research literature refers mainly to risk assessment of private sector entities and banking institutions. For example, a popular handbook on financial management and accounting in the public sector by Bandy (2011) devotes only a few pages to the issue of financial risk management. That there is less literature devoted to the risk of public sector entities is understandable, taking into account the considerably lower risk of this sector. However, after the 2008 crisis the developed economies experienced a few cases of restructuring of public sector debt, with such remarkable examples as the city of Detroit (USD 18 billion of debt) and Jefferson County, AL (USD 4 billion of debt). In 2014, the city of Rome (EUR 14 billion of debt) was on the brink of bankruptcy, but ultimately it was saved by the urgently passed legislation by the Italian government, which secured additional funds for Rome. Even if the final responsibility for the liabilities of LGs is transferred to central government, it does not eliminate their negative impact on the stability of the public sector and the whole economy. The financial distress of the LG sector is also noticeable in Poland. Although only 2% of LGs do not comply with the statutory debt limits, around 10% of LGs temporarily lose their ability to fulfill their financial obligations in the course of a fiscal year, and half of the entities in this group experience overdue liabilities unsettled at the end of the fiscal year according to research by Filipiak (2014, p. 30). In Poland, one LG (Ostrowice borough) is already facing a liquidation procedure. A vastly popular approach to risk assessment was proposed by E. Altman (see the revised concept in Altman 2000). Although this method is applicable to the evaluation of private and public companies, its application to the risk assessment of LGs is very limited. There are several financial measures which are critical for the Altman model (such as market value of equity, common equity, retained earnings etc.) that cannot be used to characterise LGs, as they are public governance bodies. Moreover, the notion of ‘revenue’ has a completely different dimension than in the corporate sector. Similarly, working capital, which is one of the critical factors in the Altman model, is not relevantly reflected in the LGs’ financial reports. Thus, interpretation of the liquidity ratios may be misleading—they are typically very high in LGs (see Galiński 2015, p. 26), as they are distorted by funds dedicated solely to specific commissioned activities or particular investment projects. They cannot be disbursed for any other operating expenses or for servicing the debt. As a result, traditional risk evaluation methods cannot be directly employed for the LG sector, and non-financial indicators should also be considered. Research on specific factors which influence the financial stability of large municipalities in Spain (148 entities) was conducted by Rodríguez-Bolívar et al. (2016). LGs in Spain experienced similar processes as in many EU countries—their revenues and expenditures have increased very significantly as a result of the growing number of functions undertaken, and this process has resulted in high levels of public debt. The authors tested the impact on the LG financial stability and net debt of the following socio-demographic and economic parameters: population, population density, dependent population below 16 years and over 65 years, unemployment rate, immigrant population, level of education, budget results per capita, GDP, touristic activity and concentration of firms. The research identified unemployment, population aged under 16 years and budget surplus/deficit per capita as the most important factors in the assessment of LG financial sustainability. However, the coefficients of determination were low in all models (between 0.009 and 0.274), which shows that the omission of financial indicators results in insufficient characterisation of the LG risk profile. Extensive research on the systematic and unsystematic factors which have an influence on the probability of default of the large municipalities was presented by Lara-Rubio et al. (2017). The authors analyze 23 dependent variables ranging from demographic measures to political criteria (such as the number of parties represented in a city council). The financial indicators reflecting debt repayment capacity were not included. The analysis showed that the probability of default rises in response to a fall in such factors as population density, dependent population, municipal income per capita and GDP growth and with the ideological alignment of the LG with the national government. It also rises with an increase in short-term borrowing and the market risk premium. The model results in very high probabilities of default—over 50%. This is a result of the definition of a default event as a lack of cash surplus for overheads or debt exceeding 110% of revenues or current revenue smaller than current expenditure or current assets smaller than current liabilities. In practice, these are not default events nor even payment incidents; they just reflect certain aspects of the deterioration of the risk profile of LGs based on the changes of the above demographic and economic indicators. As such, they require enhancement by financial measures. Given that the Altman model cannot be applied directly, because only a limited set of financial indicators is qualified to the risk analysis of LGs, and that numerous non-financial factors cannot sufficiently explain the changes in an LG’s risk profile, the practical challenge is to propose a methodology based on a set of qualified and relatively easily available indicators, preferably reported quarterly to allow more accurate risk monitoring. This research develops a risk assessment methodology with the use of selected applicable financial indicators based on free operating cash flow and net debt as an alternative to the statutory limits on LG debt. Next, it combines these indicators with efficiency indicators for LGs using the Data Envelopment Analysis (DEA) method. Such an approach allows the risk of individual LGs to be ranked according to both their debt service capacity and their long-term ability to manage costs and carry out rational investment policy. The quantitative analysis is conducted for the LG sector in Poland for the 2008–2015 period. The analysis provides guidance about which LG categories are more vulnerable to problems with servicing their financial liabilities in the future due to their cost management and investment policies, and which may suffer structural problems. As in the above-mentioned research, the focus in this analysis is on large municipalities (towns with county rights), which play a central role in the LG sector in Poland.",12
7.0,3.0,Eurasian Economic Review,08 July 2017,https://link.springer.com/article/10.1007/s40822-017-0080-2,Efficiency-solvency linkage of Indian general insurance companies: a robust non-parametric approach,December 2017,Ram Pratap Sinha,,,Male,Unknown,Unknown,Male,"The general insurance industry in India started functioning in the 1850s and up to the early 1970s had only private insurers. In 1973, the industry came under the public sector as 107 private non-life insurance companies were merged to form four general insurance companies and one holding company. However, with the introduction of financial sector reform in India in 1991, the government thought about deregulating the industry out of efficiency considerations. The broad measures of such deregulation were provided by the Malhotra Committee (1993). The policy reforms were implemented in 1999 by permitting private sector entry and the setting up of a regulatory institution (Insurance Regulatory and Development Authority (IRDA)). In the next one and a half decade, the industry had a rapid change in several respect including the degree of competition, size and depth. Apropos of the aforementioned changes, the present study is an attempt to provide robust estimation of efficiency of the major general insurance companies currently operating in the Indian insurance market. The extant literature on the Indian general insurance industry includes quite a few efficiency studies focusing on the efficiency issue. However, one finds that the existing studies have two major limitations. First, the studies are based on point estimations of performance (in a scenario where the number of observations is extremely limited) making unbiased estimation of efficiency a difficult proposition. Second, the existing literature did not attempt to explain the performance of the in-sample companies in terms of the environmental variables through a robust econometric methodology. The present study seeks to make a value addition by removing these shortcomings. The key features of the present study are as follows: In the first stage, the study develops a robust performance indicator using a smoothed bootstrap data envelopment analysis. In the next stage, the study tries to explore the linkage between efficiency and solvency of the observed insurers in terms of truncated regression. The study has six sections and is organized as follows. Section 2 gives an outline of Indian general insurance industry and of the solvency regulation. Section 3 provides a review of the related literature. Section 4 traces the evolution of non-parametric methodology for performance benchmarking and introduces the bootstrap DEA based conditional performance evaluation method. Section 5 discusses the results. Finally, Sect. 6 concludes.",4
7.0,3.0,Eurasian Economic Review,30 June 2017,https://link.springer.com/article/10.1007/s40822-017-0079-8,Analyzing the impact of oil price volatility on electricity demand: the case of Turkey,December 2017,Gülsüm Akarsu,,,Female,Unknown,Unknown,Female,"Based on the precautionary savings motive, theories of investment under uncertainty, and the real options effect, the decision-making behavior of economic agents is invariably affected by increased uncertainty (Van Robays 2016). As electricity demand is also an economic decision, one expects economic uncertainty to have a significant effect on the demand for electricity. Consumption of electricity has rapidly increased worldwide over the last 25 years as a result of population and income growth, urbanization, and industrialization, displaying the highest rate of increase of all end-user energy forms (International Energy Agency [IEA] 2011). Turkey has also experienced high growth in electricity demand, with an average annual increase of 7%. Net electricity consumption increased from 46,820 to 207,375 GWh over the period 1990–2014. The main aim of this study is to examine the effect of oil price volatility on the demand for electricity in Turkey. The study also analyzes the determinants of electricity demand using province-level data for the periods 1990–2001 and 2004–2014. The electricity sector in Turkey has undergone significant transformation, commencing with the privatization of electricity generation in the 1980s and liberalization policies implemented via the enactment of the Electricity Market Law (No. 4628) in 2001. These liberalization policies aimed to increase competition in the generation and trading segments of the electricity market, and also to liberalize the demand side by allowing bilateral agreements between suppliers and eligible consumers. In addition, the Energy Market Regulatory Authority (EMRA) was established with the introduction of the Electricity Market Law to regulate the market. The EMRA regulates tariffs relating to transmission, distribution, and retailing of electricity, as well as the Electricity Trading Company of Turkey’s tariff through the presence of purchase-guaranteed generation companies in accordance with Law No. 3096. In addition, analysis of the supply and demand sides of the sector shows that electricity is mainly generated using natural gas, which accounted for 47.9% of supply in 2014 compared with 17.7% in 1990 (see Fig. 1), and industrial consumers are responsible for the largest share of net electricity consumption, although this decreased from 62.4% in 1990 to 47.2% in 2014, as can be seen in Fig. 2. Source: Author’s representation based on data obtained from the Transmission Company of Turkey Electricity generation by primary energy source Source: Author’s representation based on data obtained from the Statistical Institute of Turkey (TURKSTAT) Consumption by sector Turkey is dependent on imports for 93.6 and 99.2% of its oil and natural gas requirements, respectively (Turkish Petroleum [TP] 2016), and long-term contracts for natural gas purchases are indexed to the oil price (Rzayeva 2014). During the period from 1990 to 2014, Turkey’s dependence on imported energy sources increased from 51.6 to 75% (TP 2016). Although the share of primary energy consumption of oil decreased from its 1990 level of 48.4 to 29.5% in 2014, natural gas share increased from 6.41 to 32.8% between 1990 and 2014. Oil price volatility is expected to affect the electricity sector significantly because of the indexing of long-term natural gas contracts to the oil price. On the other hand, as seen from Fig. 3, although electricity generation was sufficient to meet the gross demand up to 2011, after this year gross demand exceeds the electricity generation and this difference in demand was met by net electricity imports. If electricity demand continues to increase, there can be excess demand in the coming years which can only be met by generation capacity additions. Finally, electricity prices increased during the period 1990–2014 from 0.000192 and 0.000114 TL/kWh to 0.213 and 0.255 TL/kWh for industrial and residential consumers, respectively, in nominal terms. Source: Author’s representation based on data obtained from the Transmission Company of Turkey Electricity generation, gross demand and annual increase in gross demand Therefore, understanding the factors affecting electricity demand and accurate estimation of income and price elasticities is important for electricity demand forecasting, investment planning, regulation of the sector, formulation of policies regarding demand management, restructuring of the electricity sector, and determining the social, economic, and environmental impacts of implemented policies (Narayan and Smyth 2005; Carlos et al. 2009). Since the pioneering study of Houthakker (1951), which can be viewed as the result of economists’ interest in empirical estimation of the demand functions for all consumer goods, including electricity, during the 1950s (Fisher et al. 1992), more than 450 studies have focused on electricity demand estimation (Dahl 2011). In contrast to these studies, this study analyzes the effect of oil price volatility on electricity demand. To show how uncertainty affects economic decisions, particularly investment decisions, previous theoretical studies have focused on two channels based on the precautionary savings motive and the real options effect (Plante and Traum 2012). According to the precautionary savings motive, higher uncertainty leads to an increase in investment by reducing consumption and increasing savings. However, based on the irreversibility of the investment, the real options effect predicts a reduction/delay in investment as a result of higher uncertainty because ‘if an investment is irreversible, increased uncertainty raises the option value of waiting to invest’ (Guo and Kliesen 2005, p. 679). Many theoretical and empirical studies have included different types of uncertainty in their models (Grier and Perry 2000; Elder and Serletis 2010; Bahmani-Oskooee and Xi 2011–2012; Chen and Hsu 2012; Berument et al. 2012). This study uses oil price volatility to represent uncertainty related to the energy market. An increase in oil price volatility can lead to a reduction in energy demand or inter-fuel substitution through its negative impact on economic activity (Arize 2000). Therefore, one cannot ignore the effects of energy price volatility on the energy sector. According to Weller and Fields (2011), because of increased energy price volatility, households, businesses, and policy-makers cannot react to rising energy prices by investing in energy-efficient machines and appliances and/or by switching to alternative energy sources. Instead, they defer spending, energy-saving investments, and other investments. However, among the energy studies to date, only a few have analyzed the effect of economic uncertainty. Pourshahabi et al. (2012) incorporate volatility into their petroleum consumption model to analyze energy demand. They find a significant negative effect of oil price volatility on the petroleum consumption of OECD countries during the period from 1980 to 2008. Chiou-Wei et al. (2016) also consider economic uncertainty while analyzing the direction of causality between energy consumption and economic growth in five Asia–Pacific countries using a bivariate EGARCH-M model for the period from 1965 to 2010. Their findings show that uncertainty has adverse effects on economic growth and energy consumption. In addition, Kuper and van Soest (2006) analyze the effect of oil price uncertainty on the energy use of 15 OECD countries over the period from 1978 to 1996. They find that the asymmetric effect of energy price changes is affected by oil price uncertainty as measured by oil price volatility. This study aims to contribute to the literature by including oil price volatility as a factor determining electricity demand using panel data for Turkey. Based on the precautionary savings motive, theories of investment under uncertainty, and the real options effect, volatility is expected to have a significant effect on electricity demand. Therefore, in this study, per capita aggregate electricity demand is modeled as a function of electricity price, per capita income, the urbanization ratio, and oil price volatility. To enable a stable relationship and unbiased elasticities for the overall economy, the focus is restricted to total electricity demand (Pouris 1987). The findings indicate a short run negative impact of oil price volatility for the period from 2004 to 2014. The results for this period show that electricity demand is income elastic and price inelastic in the long run; however short-term electricity demand is price elastic and income inelastic. Moreover, the estimation results show that electricity demand is inelastic with respect to price and income both in the short run and long run for the period from 1990 to 2001. The rest of the paper is organized as follows. Section 2 provides a brief review of the literature on econometric studies of total electricity demand. The proposed empirical model is introduced in Sect. 3. Section 4 discusses methodological issues. Section 5 provides information on the data used for the empirical study, as well as the results of the various tests and estimations. Section 6 concludes, and presents some policy recommendations.",2
7.0,3.0,Eurasian Economic Review,31 May 2017,https://link.springer.com/article/10.1007/s40822-017-0073-1,Do service sectors need core sectors to improve their productivity?,December 2017,Sachiko Kazekami,,,Female,Unknown,Unknown,Female,"Improving productivity in the service sectors is particularly important in developed countries as in such countries, service sectors account for a very large share of the economy in terms of added value as well as employment. In early literature, “Baumol’s diseases” (Baumol 1967) were postulated, which means that increasing income levels enriches the proportion of service sectors whose productivity level is relatively-low, and slows down economic growth. However, researchers are finding that some service sectors are able to increase productivity and, at the same time, contribute to overall economic growth (Bosworth and Triplett 2007; Maroto-Sánchez and Cuadrado-Roura 2009). There are several factors that can improve productivity in the service sectors. Some of these are company-related factors such as know-how (Ligthelm 2011; Japan Revitalization Strategy 2016) and others are market environment related such as competition. Among those factors, this study focuses on market environment related factors because the market environment should be considered by policy makers. Moreover, the productivity of the service sectors differs by region because each market environment differs depending on the regional industrial structure. However, research on the productivity in the service sectors in Japan has been limited due to data constraints. One of the few previous Japanese studies is that of Morikawa (2014), but it does not consider regional productivity differences in the service sectors due to differing regional industrial structures. One typical characteristic of a service sector is “non-tradable” products. The goods and services in the service sectors are consumed in the same places where these goods and services are supplied.Footnote 1 Therefore, the size of the demand for the service sector will be determined by the size of the local economy, for instance, the volume of local value added, the local residents’ income levels, and the local population size. The number of employees in wholesale and retail sales, representative non-tradable local services, accounts for the largest share of the service sectors in Japan; namely, 24% of total employment in the service sectors (10,540,000 employees). The employment in the medical and welfare sectors, the other representative non-tradable local service sectors, accounts for 17%, and is the fastest growing. In contrast, manufacturing sector goods can be traded outside the local regions where these goods are produced. If some innovative tradable sectors or manufacturing sectors, namely, “core sectors” in most regions, are active, generate more employment, and pay higher wages, such sectors will then demand more goods and services from the local service sectors. The local service sectors then become more active. In fact, this study attempted to use a simple fixed effect regression on Japanese data from 1995 to 2013,Footnote 2 and found that municipalities with larger manufacturing output per capita generate larger wholesale and retail sales. Moreover, municipalities with higher income per capita generated a greater demand for wholesale and retail sales, and furthermore, manufacturing output per capita also increased regional income per capita.Footnote 3 At the same time, active service sectors may induce more competition or spillover effects, and thereby increase productivity. Furthermore, in Japan in particular, people discuss a “trickle-down effect,” where the benefits from the economic policy for international trade and large firms spread to small and medium domestic firms that supply goods and services to local residents. There are some who criticize this international trade economic policy as not providing benefits to small and medium firms and argue that directly improving the domestic local sectors, such as nursing and retail, is important. However, is it possible that these local firms can grow by themselves? Some municipalities have only declining industries and project a drop in future population density. For other municipalities, a major source of employment is in the welfare centers, which are a non-tradable sector. Examining Japanese micro-data, this study demonstrates that large, active core sectors in the local economy improve the productivity of local non-tradable service sectors and thereby increase employment in those service sectors. Here, “core sectors” are defined as: (1) specialized sectors or (2) manufacturing sectors. After demonstrating that the core sector increases productivity in the local service sectors, this study briefly examines the mechanism behind this (why the core sectors improve productivity in the service sectors). This study demonstrates the need to look beyond the service sectors, namely, at the industrial structure, to improve productivity of service sectors and suggests to policy makers that economic policy alone in the service industry is not enough to improve productivity. One limitation of this study is that the results are estimated at the municipal level. However, economic activity often integrates across municipal borders. However, this study does not describe results estimated examining commuting zones due to space constraints. Additionally, the Ministry of Internal Affairs and Communications publishes a specialized index (this index is necessary to determine a core sector), calculated for each municipality. If self-sufficient data were available, the specialized index for each commuting zone could be calculated. Furthermore, even if it is demonstrated that large core sectors increase the productivity of service sectors, a more detailed investigation of mechanisms behind this (why large core sectors and large demand for service sectors improve productivity) is needed. In the next section, previous literature on the topic is summarized. Section 3 explains the empirical approach and data. Section 4 summarizes the Japanese local economy, including regional differences in productivity in service sectors, regional industrial structure, and the distribution of the population. The estimation results are presented in Sect. 5 and in Sect. 6 the mechanism of increasing productivity in the service sectors is investigated. Finally, this paper presents a discussion and conclusion in Sect. 7.",4
7.0,3.0,Eurasian Economic Review,08 May 2017,https://link.springer.com/article/10.1007/s40822-017-0072-2,The impact of shadow economy and/or corruption on private consumption: further evidence from selected Eurozone economies,December 2017,Ioannis Kostakis,,,Male,Unknown,Unknown,Male,"The analysis and interpretation of public economics is based on the coexistence of several schools of different macroeconomic perspectives. These schools have many discrepancies, using a plethora of labels to designate these discrepancies, such as “neo,” “new,” “old,” and “post” prefixes (Dequech 2008). Whereas both theoretical and empirical literature regarding the effects of monetary policy exists, it is only until recently that the fiscal policy implementation has received more attention in research of economic. This lack of significance was the reason for many debates on macroeconomic importance of government spending and taxation as a tool of fiscal policy implementation. The main discussions around the Growth and Stability Pact under European Monetary Union are based on the hypothesis that governmental policy could be an effective tool for stabilizing the fluctuations of business cycles (Fatás and Mihov 2001; Blanchard and Perotti 2002; Perotti 2002). Empirical findings across research illustrate different results and therefore different policy implications. This variability of results might arise from different approaches, scope data and time availability. As it can be expected, fiscal policy in various economies leads to specific measures which improve the standards of public economics. A generalization of policy implications with respect to fiscal policy seems unreasonable. Moreover, the scale of fiscal policy changed over time,Footnote 1 making this issue further complicated. The existence of Wagner law has led European economies to high levels of public expenditures over time, while national revenues seem to follow expenses in this rise. That expresses the deficits creation between countries changing the target and the tools of public policy. According to the existing literature, the use of beneficial/non-beneficial policy implementation is a main factor explaining the relation between fiscal policy (consolidation or expansion) and consumer behavior. Most surveys measure or estimate fiscal policy’s effects on economic growth or other variables (foreign direct investment, GDP, etc.); nonetheless there are still a few surveys investigating political accountability indexes such as shadow economy or corruption’s impact on real economy (Klarita 1999; Dell’Anno 2007; Schclarek 2007; Dreher and Schneider 2010). This article presents the influence of corruption and shadow economy on private consumption growth using the hypothesis that they can be substitutes or complements within European economies. The hypotheses are tested using a dynamic panel dataset of seventeen Eurozone countries over twenty years. To the knowledge of the authors, most empirical studies analyze specific countries or groups of countries with similar geographical or income characteristics. In this specific study an alternative selection of countries is made. This selection is based on countries using the Euro currency. All countries are high income members of Eurozone group and follow the same monetary policy. Still, fiscal policy and political accountability indexes are related to specific country decisions. Thus, in the following analysis, monetary policy is controlled by the European Central Bank but political and fiscal policy tools are national decision tools, also affecting national private consumption. This article has two main goals which will add to the existing debate. First of all, a panel of seventeen Eurozone countries was conducting leading to robust findings on the dynamic effects of variation in political accountability and fiscal policy. These reported empirical evidences are considered to be helpful in the current policy discussions. The second goal of this paper is based on the mirror case of neoclassical predictions, meaning that fiscal consolidations should be associated with higher private consumption growth. Thus, the estimation of a structural model of private consumption will be specified and the behavior of private consumption growth of fiscal contractions will be analyzed. This provided new outcomes concerning the variables of corruption and shadow economyFootnote 2 that are highly important for the debate. Alternatively, the main goal of the present work is to scrutinize the relationship between a shadow economy and corruption in relation to growth of private consumption during times of fiscal consolidation. Previous studies were based on the seminal methodologies of Giavazzi and Pagano (1996) and Alesina and Perotti (1999) estimating how private consumption responds to variables of fiscal policy during fiscal contractions or expansions. In this research the estimation of growth of private consumption during eras of fiscal consolidations/expansions after controlling additional economic variables including income, risk, uncertainty, exchange rate volatility and interest rates will be assessed by mimicking Hjelm’s (2002) approach. Simultaneously, further investigation will be done on the hypothesis whether political accountability affects individuals’ real consumption. The econometric methodology is based on a yearly panel data of seventeen Eurozone economies following the IV GMM estimation. Further, the data spans from 1995 to 2015 while the main sources of the data are the Ameco database (European Commission), the World Governance Indicators dataset and the Schneider’s database. Furthermore, panel methodology overcomes the lack of data availability as it provides a higher number of degrees of freedom, allowing the inclusion of many economies that could be previously omitted. Furthermore, it does account for the heterogeneity of countries whilst both developing and developed economies were included in the same regression without losing any information and with increasing the degrees of freedom. By also accounting cross-sectional variation, panel data analysis overcomes the issue of variables exclusion because on its non-intra-country variation over time. This research study has five sections after this introduction. Section 2 discusses a brief review of the empirical literature. It concludes with a theoretical pattern as a basis for the empirical part of research. Section 3 presents a snapshot of information regarding private consumption growth and the political accountability indexes within the Eurozone. Section 4 describes the methodology and data used, while structural consumption function is gradually estimated. The evaluation of private consumption growth equations is being carried out in Sect. 5. Finally, conclusions are presented in Sect. 6.",5
7.0,3.0,Eurasian Economic Review,17 May 2017,https://link.springer.com/article/10.1007/s40822-017-0071-3,The impact of foreign direct investment on economic growth in Singapore between 1980 and 2014,December 2017,Ergin Akalpler,Hemn Adil,,Male,Unknown,Unknown,Male,"For the past 30 years, FDI has significantly increased in importance among nations globally, with most economic analysts strongly contending that FDI is a powerful engine for economic growth. The strong desire by nations to attract significant amounts of FDI has not only being limited to GDP. For instance, it can be noted that FDI also enables nations to enter certain markets, particularly when the countries limit foreign firms’ access to their domestic markets. Such access can, therefore, be obtained by acquiring or starting a business in that nation. Other explanations seem to point to the need to access and control resources that are not available in the domestic economy, while some point to the requirement to lower costs of production. In modern economics, significant emphasis is now placed on attracting FDI rather than injecting FDI into foreign nations. Through FDI outflows, companies can expand their operations and engage in what is known as international or regional diversification. This idea is supported by Busse and Königer (2012), who contend that nations ought to invest in other countries, particularly at a time when domestic markets show evidence of underperforming. On the other hand, Agrawal (2001) argues that it is FDI inflows that have the most significance because they allow new inputs and technology to be incorporated into the domestic production. Global economic focus is shifting immensely and is now becoming growth oriented, whether inward or outward, with nations such as Zimbabwe blueprinting and branding economic goals towards an increase in economic growth in both the short and long-run periods. Agrawal conducted a cross-sectional analysis of Pakistan, India, Nepal, Bangladesh and Sri Lanka. He used time series data to analyze the impacts of foreign direct investment on national investment. The results revealed that there is a linkage between foreign direct investment and national investment. Further results revealed that there was a unilateral relationship between FDI and economic growth before 1980, mildly positive in the early eighties, and positively strong in the early nineties. Athukorala (2003) conducted an examination of the impact of foreign direct investment on economic growth based on Sri Lanka. Time series data from the period 1959–2002 was used and the results showed that there was no robust linkage between economic growth and FDI. Having used the Vector Error Correction model, the results also showed that FDI was positively related to domestic economic activities and business opportunities. Factors such as corruption, bad governance, bureaucratic inertia and political instability were implicated as major factors that were hampering the investment outlook. Blomstrom et al. (1994), assert that there is a significant correlation between FDI and per capita GDP. Their study was based on time series data from the period 1960–1985 and their results suggest that there is a large technological and productivity gap between poor and rich countries. This gap was assumed to be in the relation between domestically owned and foreign owned firms. This study argues that foreign direct investment does not always benefit poorer countries.",7
8.0,1.0,Eurasian Economic Review,03 October 2017,https://link.springer.com/article/10.1007/s40822-017-0084-y,A model of search and matching with PES intermediation,April 2018,Twisha Chatterjee,,,Unknown,Unknown,Unknown,Unknown,,
8.0,1.0,Eurasian Economic Review,11 July 2017,https://link.springer.com/article/10.1007/s40822-017-0078-9,Fertility and education investment incentive with a pay-as-you-go pension,April 2018,Masaya Yasuoka,,,Male,Unknown,Unknown,Male,"In some economically developed countries, an aging society with fewer children is underway. In an aging society, social security costs continue to increase. Younger people must increasingly finance the provision of social security services. Therefore, a child care policy is necessary to increase the number of younger people supporting the future society, to produce a sustainable social security system. As child care policies supporting child rearing activities, several nations have adopted child allowances, child care service subsidies, and subsidies for education investment. Child allowances are provided proportionally to the number of children. Oshio (2001), van Groezen et al. (2003), and Yasuoka and Goto (2015) examined the effects of child allowances on fertility and derive that child allowances can raise fertility. Child allowances reduce the net cost of rearing children. A decrease in the net cost raises fertility. However, child allowances cannot always raise fertility. In France and Sweden, which have succeeded in increasing fertility, child care services are sufficiently available. In Japan, because of the shortage of child care services, fertility has not increased in spite of the provision of child allowances. An increase in the female wage rate reduces fertility because of opportunities to have children. Child care time is necessary to rear children. By virtue of child care services, parents can continue working. Therefore, they have few confrontations with opportunity cost. Apps and Rees (2004) and Ferrero and Iza (2004) derive that child care services can raise fertility. Basic models of the quantity and quality of children have been reported by Becker et al. (1990), de la Croix and Doepke (2003), and others. In the quantity and quality of children model, parents decrease fertility and increase education investment if their income level is high because the opportunity cost of having children and financing their subsequent education investment cost is high. Moreover, Zhang (1997) and Zhang and Casagrande (1998) examine the effects of education investment subsidies on education for the children. Child allowances can raise fertility. However, education investment decreases because the education investment costs are high. Endogenous fertility and education investment have positive externality effects with a pay-as-you-go pension. The pension benefit during an old-age period increases because younger people and the income level increase if a household increases fertility or education investment for children. As reported by Zhang and Nishimura (1993) and Wigger (1999), a pay-as-you-go pension reduces fertility because the parents can obtain an income during an old-age period from the pension. Without a pension, the parents must depend on gifts from the children, which would induce the parents to choose to have more children. However, if the pension benefit is determined by the number of children that the parents have, then this pension has the same effect as a child care policy. The net cost to have children decreases because of an increase in the pension benefit. Such a pension system is examined in some reports of the related literature. Kolmar (1997), Fenge and Meier (2005), Fenge and Meier (2009) and Fanti and Gori (2013) set the fertility-related pension model. The pension benefit depends on the fertility of the parents. This paper sets a model in which fertility and human capital accumulation are determined endogenously. We consider not only fertility-related pensions but also human-capital-related pensions. Meier and Wrede (2010) examine both fertility and education investment related pensions. Pension benefits increase because of an increase in human capital accumulation if parents invest in education for their children. This result the overall cost of education investment is reduced and human capital accumulation is promoted. This paper sets a simple model of endogenous fertility and education investment and presents some derived results. The following results were obtained from analyses described herein. The effect of a pension incentive policy on education investment depends on the preference parameter of the utility function. As long as the preference for fertility is high, education investment is pulled up by the incentive policy. Otherwise, the pension incentive policy reduces the education investment. These results can be derived in the model of quantity and quality of children. The effects of the pension incentive policy on fertility depend on the preference parameter and human capital productivity. Therefore, the pension incentive policy is not directly substitutive for a child care policy such as a child allowance or subsidy for education investment. These results differ from those reported by Meier and Wrede (2010). The remainder of this paper presents the following arguments and results. Section 2 describes the model with fertility and human capital-related pension model and Sect. 3 presents derivation of the equilibrium. Section 4 presents an examination of the effect of the pension incentive policy on the fertility and income growth. Section 5 presents some discussion related to parameter conditions and contributions of this paper. The final section concludes our manuscript.",2
8.0,1.0,Eurasian Economic Review,17 July 2017,https://link.springer.com/article/10.1007/s40822-017-0074-0,Influence of women’s workforce participation and pensions on total fertility rate: a theoretical and econometric study,April 2018,Tomáš Evan,Pavla Vozárová,,Male,Female,Unknown,Mix,,
8.0,1.0,Eurasian Economic Review,01 September 2017,https://link.springer.com/article/10.1007/s40822-017-0081-1,A new evidence from the effects of Russia’s WTO accession on its foreign trade,April 2018,Ehsan Rasoulinezhad,,,Male,Unknown,Unknown,Male,"The topic of Russia’s WTO (World Trade Organization) accession has been the subject of intense research over the past decade. The debate on this topic among scholars has led to the emergence of two opposing views. One point of view is that the WTO accession of Russia on August 22, 2012 has pushed Russia to form a new foreign trade pattern (Khairullov 2015; Vertakova et al. 2015; Leibman 2016) to become more in line with WTO principles. The other point of view states that although the WTO membership of Russia has brought important opportunities like improving the overall environment in which economy of this country operates, enhancing the international position of Russia in global trade, allowing greater participation of the private sector and lifting price controls, it has presented various challenges for Russian foreign trade (Malle 2013; Popa 2012; Mau and Ulykaev 2015). While the existence of two opposing views show that the impacts of accession of Russia to the WTO on its foreign trade pattern are vague, it is important to reach unambiguous results for policy implementation. The objective of this paper is to provide an overview of bilateral trade pattern between Russia and 40 trade partners before and after the WTO accession of Russia: 2000–2011 and 2012–2015, in a panel data framework. The samples are gathered from Europe, Asia, Africa, South and North America. The period under our study is from 2000 to 2015, during which time, the membership of Russia to WTO took place. With this aim, we estimate a panel-gravity model to measure and compare the impacts of variables included in the gravity model on the trade volume of Russia before and after the Russia’s WTO accession. Our gravity model can be viewed as an extension of Rasoulinezhad (2017) who investigated the trade pattern of Russia with the OPEC members. Our main contribution is to update previous gravity model by adding new variables like TCI, using disaggregated trade data of Russia into agricultural and industrial sectors, and comparing the estimations before and after 2012—the year of Russia’s WTO accession. Although the trade pattern of Russia has been an active research area (see e.g. Rasoulinezhad 2016; Idrisov et al. 2016; Schierhorn et al. 2016; Zakharova 2016; Ivanenko 2004; Berryman 2000; Buryukova 2014; Wyatt 2014; Torkkeli et al. 2009; Sutyrin et al. 2012), we did not find any study, considering the analysis of Russia’s disaggregated bilateral trade pattern with its trading partners through a gravity model before and after the Russia’s WTO accession. As mentioned earlier, the following study is different from the existing literature on the Russia’s trade pattern. We did not use the aggregate trade volume. We split the aggregate Russia-40 global partner’s trade into two separate groups of agricultural commodities and industrial trade. It allows us to draw out the dissimilarities in trade of these two kinds of commodities between Russia and its trading partners, and test the sensitivity of the variables in our gravity trade model in each case before and after the WTO accession of Russia. No study, to the best of our knowledge, has been done using a gravity model to investigate the Russia’s trade pattern with its trading partners before and after WTO accession. The rest of this study is outlined as follows: Sect. 2 provides a brief literature view. Data and econometric method are introduced in Sect. 3. Section 4 discusses the empirical research results and, Sect. 5 provides concluding remarking.",16
8.0,1.0,Eurasian Economic Review,13 July 2017,https://link.springer.com/article/10.1007/s40822-017-0077-x,Information and communications technology (ICT) and international trade: evidence from Turkey,April 2018,Burcu Ozcan,,,Female,Unknown,Unknown,Female,"The use of technology in our daily lives has gained much importance during the current wave of globalization. By allowing cross-border flow of ideas, knowledge, expertise, and innovations, information and communications technology (ICT), in general, and the Internet, in particular, have also contributed significantly to the globalization of the world economy (Choi 2010).Footnote 1 As a result of the revolution in the ICT sector in the 1990s, the world has witnessed some remarkable changes such as enhanced economic activity, accelerated productivity growth and rising international trade. For instance, the technological progress in telecommunications and associated decline in communication costs have frequently been cited as the leading cause of growing world trade in the last quarter of the 20th century (Fink et al. 2005). As for the relationship between ICT and trade, the advances in ICT have made physical distance irrelevant as an impediment to trade. Thus, the discussion in the popular press of the “death of distance” has been commonplace (see Demirkan et al. 2009; Freund and Weinhold 2004b). The proximity requirement for face-to-face interaction between business partners is no longer a necessary condition because innovations in ICT such as telephone, email, and virtual conference have become substitutes for face-to-face interactions (Dettmer 2014). In particular, such ICT-enabled innovations have helped poor and developing countries with considerable geographic distances and cultural and political barriers with their trading partners in increasing trade ties by compensating for the lack of strong historical trade linkages (Freund and Weinhold 2004b). There are several plausible mechanisms through which ICT may affect the flow of international trade (see Liu and Nath 2013). These mechanisms make markets more competitive and efficient by improving information flows and lowering transaction costs, such as fixed market entry cost, communication and information costs, and bargaining and coordination costs associated with trade (Jungmittag and Welfens 2009; Park and Koo 2005). Thus, ICT has trade-creation (trade-enhancing) effects. For instance, in respect of fixed market entry costs, through organized exchanges with several buyers and sellers over the Internet and through powerful search engines providing for sellers and buyers to find each other at a low cost, ICT has the potential to lower market-specific fixed entry costs, such as those of searching, advertising, and establishing a distribution network into a market (Freund and Weinhold 2004a; Lin 2015). Regarding communication costs, telecommunication creates an avenue to maintain a fast and an efficient communication with trade partners to sustain business competitiveness (Bankole et al. 2015). Besides, cheaper and faster communication may boost market transactions and also enlarge the radius of international trade (Jungmittag and Welfens 2009). In case of information costs, ICT provides a low-cost channel for information gathering, processing, and dissemination. It also leads welfare enhancement by reducing information asymmetries as all members of any given exchange share the same information (Ahmad et al. 2011; Freund and Weinhold 2004b). Furthermore, the delays in acquiring and transmitting information are reduced and planning is more efficient and accurate due to advances in ICT (Liu and Nath 2013, 2017). All these explanations indicate that there would be a positive impact of ICT on trade between countries. Against the backdrop of the rising importance of ICT on international trade, this study aims to analyze the impact of ICT on Turkey’s bilateral exports and imports for the period 2000–2014 through an augmented panel data gravity model. The Turkish economy was in disarray in the first half of the 2000s. Due to the earthquake in 1999 and the domestic financial crises in 2000–2001, the end of the 20th century and the early 2000s were drastically destructive for Turkey (Babacan 2010). However, through the enforcement of the “Transition to the Strong Economy Program” in May 2001, many structural reforms, such as market liberalization, privatization, banking system strengthening, fiscal discipline, tight monetary policy, inflation targeting, and a floating exchange rate regime, were undertaken to alleviate the impacts of these severe crises and to recover the Turkish economy. Since 2002, Turkey’s imports and exports of goods and services have followed upward trends except for the world financial crisis period (2008–2009) (see Fig. 1).Footnote 2 During this period, the access, use, and skills necessary for the deployment of ICT also increased manifold in Turkey. For instance, the percentage of Internet users was only 3.7% in 2000 while it steadily increased to 51.04% in 2014 (ITU 2015). Source: Turkish Statistical Institute 2016. Attained from http://www.turkstat.gov.tr
 The value of exports and imports of goods and services (thousands of current US dollar) To the best of our knowledge, this is the first study of this kind for Turkey. Karagoz (2007) is the only other study that analyzes the influence of ICT on Turkish exports in the literature. However, he employs a time series analysis. Additionally, the studies in the literature generally analyze the effect of ICT on trade among a group of countries, i.e. on a multilateral basis. In contrast, we consider bilateral trade. Besides, we analyze the effect of ICT on both Turkish exports and imports volumes separately, instead of Turkish total trade volume or only exports or only imports. This study also sets an example and provides policy implications for developing countries at the same development level as Turkey. Furthermore, there are only few studies (Liu and Nath 2017; Mattes et al. 2012) that consider all aspects of ICT (by computing and using ICT Development index) while examining its impact on trade. We use a comprehensive aggregate index that combines three different aspects (access, use, and skills) of ICT. Besides, we use three different sub-indices representing those three aspects separately in our regression analysis. This is another contribution of this study. Instead of utilizing only one indicator as a proxy for ICT, we represent ICT in a more comprehensive and a detailed way. The rest of the paper is organized as follows. Section 2 briefly reviews the related empirical literature while Sect. 3 explains the model and data. The results from the empirical analyses are presented in Sect. 4. Finally, Sect.  5 concludes this study with a summary of the research findings and some important policy recommendations.",33
8.0,1.0,Eurasian Economic Review,12 September 2017,https://link.springer.com/article/10.1007/s40822-017-0083-z,"Inflow of educational capital, trade liberalization, skill formation and informal sector",April 2018,Biswajit Mandal,Sangita Roy,,,Female,Unknown,Mix,,
8.0,1.0,Eurasian Economic Review,09 September 2017,https://link.springer.com/article/10.1007/s40822-017-0082-0,Impact of institutions on entrepreneurship: a panel data analysis,April 2018,Turan Yay,Gülsün G. Yay,Tolga Aksoy,Male,Female,Male,Mix,,
8.0,2.0,Eurasian Economic Review,20 January 2018,https://link.springer.com/article/10.1007/s40822-018-0094-4,Development of stock market and economic growth: the G-20 evidence,August 2018,Rudra P. Pradhan,,,Unknown,Unknown,Unknown,Unknown,,
8.0,2.0,Eurasian Economic Review,19 February 2018,https://link.springer.com/article/10.1007/s40822-017-0090-0,Portfolio and hedging effectiveness of financial assets of the G7 countries,August 2018,Selma Izadi,M. Kabir Hassan,,Female,Unknown,Unknown,Female,"Over the last few decades there have been excess volatilities in the financial markets especially during different financial crises. This uncertainty in the markets cause investors to be more concerned about their decision-making process and to look for proper hedging instruments to overtake these undesired volatilities in their expected returns. This research integrates different lines of studies that conduct the correlations in the financial markets. Previous studies have tried to find the spillover volatility between different financial markets. Additionally, new literature has analyzed the portfolio construction and hedging effectiveness. Bekaert and Harvey (1997) examine the volatility in emerging stock markets from 1976 to 1992. They study the effect of local and world factors on emerging stock returns employing a volatility spillover model. Their findings suggest that the international factors impact on the volatility in emerging markets is very small. Ng (2000) analyzes the effect of international and regional factors in the Pacific-Basin region. The results indicate that both world and regional factors influence the Pacific-Basin stock markets although world factors have higher impact. Skintzi and Apostolos (2006) examine the volatility spillover in the US and the aggregate Euro area bond markets to twelve individual European bond markets. They find that there are significant volatility spillovers from the Euro zone bond market and the US bond market to the individual European markets. Mishra and Panda (2016) apply the daily returns of S&P CNX Nifty to analyze the robustness of implied volatility oppose to the backward looking volatility. The findings suggest that Conditional Volatility gives a preferable prediction of realized volatility than forward looking volatility and other backward looking volatility. Levy and Lerman (1988) and Izadi and Hassan (2017) find a positive and significant relationship between the equity market and the bond yield spreads in different regions, indicating a strong relationship between fixed income and stock markets in developed countries. By analyzing the US and UK financial markets between January 1990 and June 2010, Ciner et al. (2013) find that on average the bond market plays a hedging role in the equity market. Hillier et al. (2006), using the daily data from 1976 to 2004, study the diversifying benefits of including precious metals (gold, silver and platinum) to the portfolios of stocks. They find a low correlation between precious metals and stock index indicating that these metals may provide diversification in investments. They also find that these hedging abilities increase during crisis periods. Arouri et al. (2011) examine the volatility transmission between oil and sector stock markets in Europe and the United States using various GARCH-based models. They find that all the models (VAR-GARCH, BEKK-GARCH, DCC-GARCH and CCC-GARCH)
similiarly indicate that including the oil commodity to well-diversified portfolios improves their risk-adjusted returns. Antonakakis and Badinger (2012) analyze the spillover between output growth and output growth volatility for G7 countries using the VAR-based spillover index approach. They employ the real industrial production index for measuring output. They find that spillovers increase after the mid-1980s and the US has the major effect in transmitting the volatilities to other G7 countries. The findings also indicate that volatility shocks grow in the long run and there is a negative cross-variable effect between volatility shocks and economic growth. Vivian and Wohar (2012) using a GARCH model, analyze whether there are structural breaks in commodity spot returns volatility from 1985 to 2010. The empirical findings suggest supply or demand factors in the commodity markets could determine the volatility. They also find that many commodity returns experience high volatility even after structural breaks. Mensi et al. (2013), employing a VAR-GARCH model, examine the correlation and volatility spillover between equity and commodity markets. They study the daily returns of the commodity futures (Brent, WTI, Wheat, Gold), beverage spot prices and S&P 500 returns from 2000 to 2011. The findings illustrate significant correlation and volatility spillover across commodity and US stock market. They also calculate the greatest weights and hedge ratios for the commodity-stock portfolios. They conclude that including commodity to a well-diversified stock portfolio improve its overall return after adjusting for risk. Chang et al. (2013) examine the volatility spillovers between crude oil and stock indices returns applying several multivariate GARCH models like, CCC, DCC, VARMA-GARCH and VARMA-AGARCH. Their results indicate significant conditional correlation between crude oil and stock returns only based on DCC model. Lee et al. (2014) applies BEKK, CCC and DCC models to investigate the volatility spillover between stock price and oil price. Their empirical results show that the DCC model is preferred to the CCC model and the BEKK model. Gao and Lu (2014) study the volatility and correlation of seven commodity futures and S&P 500 during 1979 to 2010 applying a bivariate model of switching autoregressive conditional heteroskedasticity (SWARCH). The results show that the return volatilities are not correlated and there is risk diversification between commodity futures and stocks. Kumar (2014) studies the return and volatility spillover between gold and Indian industrial sectors employing the vector autoregressive asymmetric dynamic conditional heteroskedasticity (ADCC-BVGARCH) model from 1999 to 2012. The results show a significant return transmission from gold to Indian industrial sectors but not any significant evidence for volatility spillover. He also finds that negative values of conditional correlation mainly occur during the period of crisis illustrating the advantage of portfolio diversification during these durations. The findings from hedging effectiveness suggest that including gold in stock portfolios can manage the investment risk. Aydogan (2017) studies the effects of investor sentiment on volatility of nine stock markets from January, 2004 to June, 2015. The results indicate that portfolio performance can be improved by contemplating investor sentiment. In this paper, we aim to analyze stocks portfolio execution after including commodities. The factors that determine commodity prices such as weather conditions, storage and transportation costs, etc. are particular to commodities. Therefore the behavior of commodity prices is different from that of stocks and bonds (see Symeonidis et al. 2012). We are not able to find any comprehensive paper that investigates the role of several commodity futures in diversifying stock portfolios in the context of developed financial nations. The goal of this research is to examine the dynamic conditional returns, the hedge ratios, optimal portfolio weights and hedging effectiveness for several commodity/stock pairs in G7 countries. The stock indices of G7 countries include United States (SPX), Canada (SPTSX), France (CAC), Germany (DAX), Italy (FTSMIB), Japan (NKY) and the United Kingdom (UKX). The commodities include the index of Bloomberg commodity-contracts on 22 physical commodities (BCOM), Crude and Brent oil futures, gold and silver futures, wheat, corn and soybean futures and CRB Index (commodity research BUREA BLS/US spot all commodities). First, we apply the time-varying conditional correlation GARCH model. The conditional variance and covariance estimates from the DCC-GARCH model are utilized to project the greatest hedge ratios. Consequently, we compute the optimal portfolio weights and hedging effectiveness for the commodity/equity pairs in the context of portfolio management. The remaining of this research is divided into three parts. Section 2 explains the data and research methodology. Section 3 reports the empirical findings, and finally Sect. 4 describes the overview of the main results and conclusion.",13
8.0,2.0,Eurasian Economic Review,26 December 2017,https://link.springer.com/article/10.1007/s40822-017-0085-x,Financials sector intraday volatility characteristics in the emerging Turkish economy,August 2018,A. Can Inci,,,Unknown,Unknown,Unknown,Unknown,,
8.0,2.0,Eurasian Economic Review,18 January 2018,https://link.springer.com/article/10.1007/s40822-018-0095-3,Shock transmission and volatility spillover in stock and commodity markets: evidence from advanced and emerging markets,August 2018,Gülin Vardar,Yener Coşkun,Tezer Yelkenci,Female,Male,Male,Mix,,
8.0,2.0,Eurasian Economic Review,03 February 2018,https://link.springer.com/article/10.1007/s40822-017-0086-9,"Outsourcing, factor prices and skill formation in countries with non-overlapping time zones",August 2018,Biswajit Mandal,Sugata Marjit,Noritsugu Nakanishi,,Female,Unknown,Mix,,
8.0,2.0,Eurasian Economic Review,17 January 2018,https://link.springer.com/article/10.1007/s40822-018-0092-6,Fiscal policy and national saving in emerging Asia: challenge or opportunity?,August 2018,Duy-Tung Bui,,,Unknown,Unknown,Unknown,Unknown,,
8.0,2.0,Eurasian Economic Review,12 February 2018,https://link.springer.com/article/10.1007/s40822-018-0098-0,India’s comparative advantages in services trade,August 2018,Hiranya K. Nath,Binoy Goswami,,Unknown,Unknown,Unknown,Unknown,,
8.0,3.0,Eurasian Economic Review,30 January 2018,https://link.springer.com/article/10.1007/s40822-018-0096-2,"Ambiguity preferences, risk taking and the banking firm",December 2018,Udo Broll,Peter Welzel,Kit Pong Wong,Male,Male,,Mix,,
8.0,3.0,Eurasian Economic Review,02 February 2018,https://link.springer.com/article/10.1007/s40822-017-0088-7,Output volatility and savings in a stochastic Goodwin economy,December 2018,Jochen Jungeilges,Tatyana Ryazanova,,Male,Female,Unknown,Mix,,
8.0,3.0,Eurasian Economic Review,06 February 2018,https://link.springer.com/article/10.1007/s40822-018-0093-5,Behaviors in the market for safe vegetables under information asymmetry: modeling approach,December 2018,Hoi Quoc Le,Thi Minh Nguyen,,,,Unknown,Mix,,
8.0,3.0,Eurasian Economic Review,16 February 2018,https://link.springer.com/article/10.1007/s40822-018-0097-1,Gender inequality and FDI: empirical evidence from developing Asia–Pacific countries,December 2018,Thi Mai Hoai Bui,Xuan Vinh Vo,Duy Tung Bui,,,,Mix,,
8.0,3.0,Eurasian Economic Review,19 February 2018,https://link.springer.com/article/10.1007/s40822-018-0099-z,Cognitive skills and economic performance: evidence from the recent international student assessment tests,December 2018,Hüseyin Taştan,Selin Erdoğan,,Male,Female,Unknown,Mix,,
8.0,3.0,Eurasian Economic Review,26 December 2017,https://link.springer.com/article/10.1007/s40822-017-0087-8,Motives behind voting and the perception of the motives: paradox of voting in Bosnia and Herzegovina,December 2018,Anida Krajina,Jakub Prochazka,,Unknown,Male,Unknown,Male,"Understanding why people vote appears to be fundamental to the theory and practice of democracy (Ali and Lin 2013). According to standard economic theory (Hillman 2010), deciding how to vote may be perceived similarly to deciding which goods to consume. In other words, both voting and consumption may bring benefit to the voters/consumers. If the standard economic theory were true in the case of voting, people should vote rationally. Rational voting means voting from material self-interest or not voting if the benefit of voting is smaller than the costs of voting. In general elections a single vote is one of hundreds thousands and there is only a very small probability that the vote would be pivotal (Feddersen et al. 2009). Therefore, there is a very small chance to influence the election result and voter benefit, and so rational-choice models of voter behavior tend to dramatically underestimate voter turnout (Gintis 2016). The costs of voting (e.g. time, effort, and travel costs) exceed the expected outcomes (the probability of having a decisive vote × the benefit from the election result), and that is why rational voters should not vote. However, a large number of people do vote in large general elections. This is called the “paradox of voting” (Hillman 2010). According to Schnellenbach and Schubert (2015), the ancestor of this description of the ""paradox of voting"" was Adam Smith, who gave a larger role to emotions and ignorance in political life in any other ordinary economic matter. There is an obvious gap in the standard theory which requires further explanation. Furthermore, why does the paradox of voting even happen?",3
8.0,3.0,Eurasian Economic Review,19 January 2018,https://link.springer.com/article/10.1007/s40822-018-0091-7,"Autonomy-induced preference, budget reallocation, and child health",December 2018,Biswajit Mandal,Prasun Bhattacharjee,Souvik Banerjee,,Unknown,Unknown,Mix,,
8.0,3.0,Eurasian Economic Review,09 August 2018,https://link.springer.com/article/10.1007/s40822-018-0113-5,"Correction to: Autonomy-induced preference, budget reallocation, and child health",December 2018,Biswajit Mandal,Prasun Bhattacharjee,Souvik Banerjee,,Unknown,Unknown,Mix,,
9.0,1.0,Eurasian Economic Review,28 April 2018,https://link.springer.com/article/10.1007/s40822-018-0104-6,Big moves of mutual funds,March 2019,Thorsten Lehnert,,,Male,Unknown,Unknown,Male,"Shares of mutual funds are typically held by (unsophisticated) retail investors, which are vulnerable to fluctuating market conditions. For example, when investors are bullish on equity, mutual funds experience cash infusions and managers need to quickly equitize their net inflows. Given that retail investors are prone to herding, the directional trading of mutual funds is correlated, and their collective actions can generate short-term price pressure on aggregate stock prices. Hence, the direction of mutual fund trades may be predictable, because of the price pressure problem associated with “crowded trades”, even at the daily level. By moving in the opposite direction to those trades, short-sellers outsmart mutual funds. This appears to be healthy for the overall market, but mutual funds’ vulnerability substantially reduces their profits. For informed traders, the equity lending market and the options market are substitutes for one another. In this paper, I empirically investigate how big moves of mutual funds affect the cross-section of option prices. Early studies like Warther (1995), Fant (1999) and Edelen and Warner (2001) find no empirical evidence of a negative relation between flows and future returns. Using aggregate daily flows to equity mutual funds from TrimTabs, Edelen and Warner (2001) find a weak relation between flows and subsequent daily returns. Goetzman and Massa (2003) show supporting evidence for the hypothesis of causality from flows to returns. They find a strong contemporaneous correlation between funds inflows and S&P market returns, but no evidence for positive feedback trading. But, apparently, the arrival of flow information and fund managers’ trading activity is correlated. By analyzing intraday volatility, Cao et al. (2008) show that fund managers have access to flow information during a trading day, and trade based on that flow information. Intraday volatility decreases (increases) over the trading day, as fund managers receive additional information about fund inflow (outflows). In recent years, Ben-Rephael et al. (2011) and Arif et al. (2016) find strong support for the temporary price pressure hypothesis. The empirical findings of Arif et al. (2016) suggest that short-sellers trade strongly in the opposite direction to these flows. They find that the ability of short-sellers trades to predict stock returns is up to 3 times greater when fund flows are in the opposite direction. Short sellers were extremely quick to mirror “unexpected” mutual fund moves, meaning those moves that weren’t part of an ongoing pattern. However, does the trading activity originate from the options market or the equity lending market? Typically, when short selling becomes more costly, investors buy put options as substitutes (Lamont and Thaler 2003) and stocks exhibit more severe violations of put-call parity (Ofek et al. 2004). Figlewski and Webb (1993) argue that options market makers must hedge the risk of writing puts through short selling. They show that short interest increases near options listing dates, which is consistent with the argument that options could encourage short selling and mitigate short-sale constraints. Recently, Lin and Lu (2015) and Lehnert (2016) study the interaction identified in the literature between equity short selling and put option trading. Short-sale costs can influence put option trading activity, because higher short-sale costs may drive investors with negative private information or a long position to hedge from the equity lending market to the put options market. They conclude that the two markets are substitutes for one another for informed traders and, therefore, flow-induced trading activity can be observed in the equity lending market and the options market. The options market is in particular interesting to study, because option prices reflect expectations of market participants about future returns. For example, bearish options trading resulting in a negative shift in risk-neutral skewness would suggest that market participants expect stock prices to fall in the future. This negative shift can be a result of increased put option trading (e.g. causing an increase in out-of-the-money put option implied volatility) or a decrease in call option trading (e.g. causing a decrease in out-of-the-money call option implied volatility). Hence, the interpretation of those alternative effects would be quite different. In order to differentiate between the two effects, my variables of interest are various measures of risk-neutral volatility and skewness that are calculated by using only put option prices or by using only call option prices in the calculations. Overall, I find strong empirical evidence for directional trading in index options. The flow-induced bearish trading activity of short-sellers is price destabilizing and greatly influences put and call option prices. Firstly, in line with the short-selling channel, inflows into mutual funds mainly impact the pricing of put options. The demand for out-of-the money put options leads to a significant drop in risk-neutral skewness. Secondly, inflows (outflows) affect the risk-neutral volatility negatively (positively); the impact on prices is consistent across put and call options. Thirdly, while the effect on risk-neutral skewness is associated with the unexpected component (based on same-day flows) only, the effect on risk-neutral volatility is associated with the unexpected component and the expected component (based on prior days’ trading). Finally, while the negative relationship of inflows on risk-neutral volatility and skewness is consistent over time, the effect of outflows on risk-neutral volatility is mainly observable in bullish markets. The remainder of the paper is organized as follows. Section 2 discusses related literature. In Sect. 3, I describe the data and methodology. Section 4 presents my empirical results on the relationship between mutual fund trades and risk-neutral moments. Section 5 concludes with a summary of key results.",3
9.0,1.0,Eurasian Economic Review,17 August 2018,https://link.springer.com/article/10.1007/s40822-018-0108-2,Exploring the dynamics of Bitcoin’s price: a Bayesian structural time series approach,March 2019,Obryan Poyser,,,Unknown,Unknown,Unknown,Unknown,,
9.0,1.0,Eurasian Economic Review,25 April 2018,https://link.springer.com/article/10.1007/s40822-018-0103-7,The importance of timing in estimating beta,March 2019,Roi D. Taussig,Dror Tobi,Moti Zwilling,Unknown,Male,Male,Male,"Asset pricing models seek to explain and to predict movements in stock returns. The best known asset pricing models are the Capital Asset Pricing Models (CAPM) of Sharpe (1964), Lintner (1965), and Black (1972) and Fama and French’s Three-Factor (1993) and Five-Factor Models (Fama and French 2016). These models connect returns to risk, defined as the variability in expected returns. Beta, the generally accepted proxy for risk, denotes the systematic risk inherent in an entire market as the slope of a time-series regression of stock returns against market returns. Our study more precisely measures daily stock and market returns on the same day. Day-specific returns presumably matter to short-term traders; however, are they important for investors generally? To answer that question, we adopt a measure from bioinformatics: the Needleman and Wunsch (1970) dynamic programming algorithm (NW). Used within its own discipline to align sequences of proteins, we adopt it to align time-series stock and market returns. The NW score parallels beta in several respects. Like beta—the covariance of individual stock returns and market returns divided by variance in market returns—the NW score increases when a change in market returns generates a greater change in stock returns. In addition, both measures share the same theoretical foundations. However, the NW algorithm allows for inserting sporadic daily gaps in returns. Although each gap reduces the NW score, daily gaps are allowed for if the overall alignment is stronger—i.e., the NW score is higher. The algorithm analyzes all the possible alignments of the individual stock and market returns, and the NW score is the highest possible match. Therefore, it allows observers to inspect the importance of returns on a specific day. Each gap reduces the NW score; however, gaps are inserted only when the NW score for the entire alignment is higher. Beta alone does not facilitate that examination. This study provides insight into investors’ behavior with respect to daily returns. Its findings suggest that investors may not insist on receiving the return on a stock on a specific day or a nearby date. This is logical for investors who are not daily speculators. Accounting for gaps in the daily returns (but with a penalty in the NW measure for gaps) improves the CAPM’s ability to explain the cross-section of stock returns. The core contribution of this study is in making the CAPM model more robust by permitting “gaps” to be included in time series evaluations. Our results from examining all the stocks on the NYSE, the NASDAQ, and the AMEX with appropriate data show that the NW score alone can explain the cross-section of individual stock returns (with controls as in Fama and French 1992). Moreover, adding the NW score to beta as an explanatory variable renders both measures statistically and economically significant and raises the adjusted R-square.",3
9.0,1.0,Eurasian Economic Review,23 July 2018,https://link.springer.com/article/10.1007/s40822-018-0111-7,Reactions of emerging stock markets to dividend announcements during economic growth: evidence from India and Russia,March 2019,Irina V. Berezinets,Liliia A. Bulatova,Marat V. Smirnov,Female,Unknown,Male,Mix,,
9.0,1.0,Eurasian Economic Review,18 April 2018,https://link.springer.com/article/10.1007/s40822-018-0102-8,Role of governance on performance of microfinance institutions in Bangladesh,March 2019,Tanweer Hasan,Shakil Quayes,Baqui Khalily,Unknown,Male,Unknown,Male,"Microcredit has emerged as a feasible financial alternative for poor people with no access to credit from formal financial institutions, where its objectives include amelioration of poverty by fostering small-scale entrepreneurship, through simple access to credit. With its rapid expansion, governance of Microfinance Institutions (MFIs) has received increasing attention, particularly in view of its managements’ efficiency pertaining to financial performance and social outreach. MFIs are quasi-formal financial institutions that primarily provide small loans to poor borrowers. Over time, they have expanded their range of services into asset building, consumption smoothing, remittances, and risk management by offering savings schemes, short-term loans, money transfer, and insurance. The MFIs in our sample are not for profit organizations but are expected to attain financial self-sufficiency, and as such, governance issues play an important role in their financial performance. By the 1980s, microfinance was able to attain global prominence as a poverty alleviation tool and as a viable alternative to existing development finance models. The lack of success of the traditional development finance models, e.g., subsidized rural credit in the 1950s–1980s encumbered by high default rates and inherent inefficiency, allowed microfinance to establish itself as a feasible tool in reducing poverty, with high loan repayment. Microfinance is accepted as an effective poverty alleviation tool around the globe and is very high on the priority list of the public agenda of various countries and donor agencies. While the primary objective of MFIs is reaching the poorer strata of the population, long-term profitability or sustainabilityFootnote 1 of MFIs is also critical for this quasi-formal or alternative development finance model to continue to have a lasting impact. However, against the backdrop of a rapid global growth of the microfinance sector, a recent report identified institutional governance as one of the principal concerns facing the microfinance sector, jeopardizing its role as both a business and a social service (Centre for the Study of Financial Innovation or CSFI 2008). Governance, in microfinance, refers to the mechanisms through which equity investors, partner institutions, and donor agencies ensure that their funds are utilized according to their intended purpose. With the increased competition for funding, sustainable MFIs look particularly attractive to donors, equity investors, and other providers of fund. An MFI may signal quality and transparency through various governance mechanisms like board size and composition, board independence, audited financial statements, good internal control measures, etc. In addition to playing a pioneering role in microfinance, Bangladesh has by far the largest and most extensive microfinance program in the world, with approximately 16.3 million active borrowers and USD 3.7 billion gross loan portfolio. This sector manages USD 2.7 billion worth of deposits from 17.4 million depositors who are often referred to as members (www.mixmarket.org/mfi/country/Bangladesh). The extensive network of over six hundred MFIs have provided to access to financial service to 77% of the population. Furthermore, according to the microfinance regulatory board, conclusions drawn from an analysis of the microfinance governance issues in Bangladesh can be generalized for entire industry. In the context of a firm, shareholders (the Principal) are the residual claimant of profit (or loss) and also bear the residual risk of the firm (Jensen and Meckling 1976) while the management (an Agent) is entrusted with making the decisions that pertain to running the firm, but it does not have residual claim over the firm’s wealth. The principal-agent theory provides an explanation as to why it is incentive compatible for shareholders, to design a pay structure for managers and workers that is partially based on performance. If it were possible to design a complete and comprehensive contract that covers future periods in a costless fashion, it would deem the agency theory redundant in providing a role for corporate governance structure. However, such contracting costs may be quite large, and the absence of a complete contract necessitates additional measures of ownership control including corporate governance (Fama and Jensen 1983). The literature has identified three such transaction costs as being important—(i) the cost of taking into account the various contingencies that may arise over the period of the contract, (ii) the financial and non-pecuniary costs of negotiating with relevant parties about such future plans and contingencies, and (iii) the cost of formulating such plans so that the clauses can be enforced by a third party in case of a dispute (Hart 1995). Given these transaction costs associated with reducing the principal-agent problem, the parties often prefer a contract that is incomplete rather than being comprehensive. Governance structure is a mechanism that minimizes agency costs and covers aspects that have not been specified in the contract. This study focuses on the importance of governance mechanisms such as, ownership structure, CEO (manager) and director (board member) remuneration, board structure (size and composition), auditing, information. Majority of MFIs operate as nonprofit organizations and are often accountable to multiple entities some of whom may not even fall under the traditional definition of a principal. Although there are more than fifty variations of the definition of Stakeholder Theory (Friedman and Miles 2002; Miles 2012) in the organizational modeling the relationship between MFIs and the set of stakeholders, especially their donors and other funding agencies. We can also apply the resource dependence theory to the behavior of MFIs since these organizations heavily rely on external funding and other resources. While some donor agencies require transparent and stringent governance mechanisms, others simply require a nominal level of governance; most of the MFIs fall somewhere in between. On the other hand, many MFIs may also have internal motivation for highlighting an organization with well-functioning governance to attract more funding by demonstrating their success. The underlying reason for governance stems from the asymmetry in resource dependence, between the donor-supported organizations and their donors. While majority of the MFIs are registered as Non-Governmental Organizations (NGOs), a large number of MFIs are registered as commercial banks, cooperatives, credit unions, nonbank financial institutions, or rural banks. MFIs depend on their donors for funds and the donors depend on MFI’s for reputation and to some extent attaining their social goals (Ebrahim 2002, 2003; Hudock 1999; Perera 1997). The key mechanisms of an effective governance framework include ownership, board size and board structure, board diversity, independent directors, board committees, executive pay, etc. Academic researchers and practitioners have advocated for incorporating the best practices of governance in the corporate world into the microfinance industry (Rock et al. 1998; Otero and Chu 2002; Helms 2006). However, given the duality of the mission of sustainability and outreach, variation stakeholder structure, and the diverse ownership structure (non-profits, cooperatives, credit unions, etc.) it may not be easy to supplant typical governance mechanisms from the formal financial sector into the microfinance industry. While practitioner-based organizations (e.g., C-GAP) have laid out some broad measures of governance, very little academic research has been done in this area, primarily due to dearth of relevant data. To our knowledge, there are only seven studies on governance issues pertaining to the microfinance sector—Hartarska (2005), Hartaska and Nadolnyak (2007), Mersland and Strøm (2009), Strøm et al. (2010), Merslnad (2011), Galema et al. (2012), and Quayes and Hasan (2014). The first two studies focus on the governance issues of MFIs in Central Asia, Eastern Europe, and the Newly Independent States (former republics of the USSR). Of the remaining four, three studies use panel data across countries compiled from the risk assessment reports from various rating agencies under one umbrella (www.ratingfund2.org) to look into various aspects of MFI governance, while Merslnad (2011) makes a historical analogy of governance of MFIs with the governance of savings banks. It is worthwhile to note that there is an inherent selection bias in the database used in these three studies, as their sample uses only larger MFIs.Footnote 2 Quayes and Hasan (2014) use a large sample of MFIs and show that better disclosure and financial performance have a positive correlation. The present study investigates the possible impact of various governance attributes on the financial performance, using a sample of sixty-eight microfinance institutions (MFIs) from Bangladesh. Our results show that powerful CEOs have a positive impact on the financial performance of MFIs, and gender diversity in board can have a positive impact if it is also augmented by gender diversity in management. The rest of the paper is organized as follows. Section 2 provides an overview of extant literature on governance of MFIs; Sect. 3 describes the research methodology; Sect. 4 contains the empirical analysis of the impact of governance structure on MFI performance, and finally, Sect. 5 comprises of some concluding remarks.",12
9.0,1.0,Eurasian Economic Review,02 November 2018,https://link.springer.com/article/10.1007/s40822-018-0122-4,Foreign institutional investors and stock price synchronicity of Chinese listed firms: further evidence,March 2019,Tina T. He,Wilson X. B. Li,Gordon Y. N. Tang,Female,Male,Male,Mix,,
9.0,2.0,Eurasian Economic Review,07 November 2018,https://link.springer.com/article/10.1007/s40822-018-0123-3,"Bureaucratic efficiency, economic reform and informal sector",June 2019,Sujata Ghosh,Biswajit Mandal,,Female,,Unknown,Mix,,
9.0,2.0,Eurasian Economic Review,05 July 2018,https://link.springer.com/article/10.1007/s40822-018-0101-9,The role of local government policy on secondary school enrolment decision in Indonesia,June 2019,Ferry Prasetyia,,,Male,Unknown,Unknown,Male,"It is widely recognized that education is one of the most significant components contributing to the human capital, which in turn determines economic growth and poverty alleviation. In addition, education act as an important part in preparing individual for market labor force in the future (Badea 2011). As a developing country, Indonesia is still lagging behind neighboring countries regarding human capital development (Booth 1999; Posso 2011; OECD/ADB 2015). The Indonesian government has been paying attention to education development since 1970s by investing greatly in improving access to education through the Primary School Presidential instruction program (Sekolah Dasar Inpres). This program has been designed to promote and ensure that each village should have at least one primary school. As a consequence, the number of primary schools has increased massively alongside a significant rise in the primary school enrollment rate (Duflo 2001, 2004). After declaring a 6-year compulsory primary education in 1984 and achieving the target of universal primary education in 1988, government policy has shifted to the focus on secondary school (Government of Indonesia 1988; Suryadarma et al. 2006; Pradhan 1998; Takahashi 2011). In 1994, junior secondary school became obligatory and part of basic education (6-year primary school and 3-year junior secondary school), and targeted at 2008 as a year of achievement for universal 9-year education. However, until 2013, the junior secondary net enrollment rate reached only 73.88%. Furthermore, the regional disparity in junior secondary school enrollment rates is also high. For example, in provincial disparity level is ranging from 83.31% in DKI Jakarta to 45.76% in Papua (BPS 2014). This raises the question of what factors are determining inter-regional disparities in the secondary school enrollment rate and to what extent the local government policy drives it. A large body of literature attempts to differentiate between causes across countries, especially in developing countries. Schultz (1999) asserts three main factors drive school enrollment in Africa: public education spending, household income, and parent education. More recently, some researchers highlight the critical point of educational policies, economic environment, and education expenditure as school enrollment rate (Whitsel and Mehran 2010; Lincove 2012; Chyi and Zhou 2014; Fairhurst and Nembudani 2014; Estevan 2015; Gaddah et al. 2016). They find that government intervention on education through program and education expenditure has an impact on school enrollment expansion. In the context of Indonesia, most researchers point out the importance of individual, household, and community characteristic to analyze the factor driving school enrolment (Chernichovsky and Meesook 1985; Pradhan 1998; Levine and Ames 2003; Suryadarma et al. 2006; Takahashi 2011). The other researcher points out the importance of education policy on school enrollment. Duflo (2001), for example, analyzes the effect of a national program of massive primary school building on school enrollment by using data of adult’s education and wage from the 1995 intercensal survey of Indonesia (SUPAS) combined with the district level data on the number of new school between 1973/74 and 1978/79. She finds that the national government program has a significant contribution to the increasing enrollment rate. Furthermore, by evaluating the district’s data level, Granado et al. (2007) find that education spending per population in school age has positive and significant effect on school enrollment rate. More recently, Al-Samarrai (2013) has conducted a survey in 50 districts (9 provinces) in 2009 and 2012 to investigate the relationship between the quality of local governance and education performance (indicated by net enrollment rate and national examination score). Using the Indonesia Local Education Governance (ILEG) Index and a regression method, he finds that the district with higher ILEG score shows a better quality of inputs (e.g. qualified teacher). In addition, the districts with a bigger share of education spending and qualified teachers tend to have high enrollment rates and examination scores. However, this survey is not representative of Indonesia as a whole since the participating districts in the survey tended to be poorer than other districts but had similar levels of education access and attainment (Al-Samarrai 2013). Such analysis does not account for how local government policy on education (i.e. education spending, school access and quality, etc.) affects the decision of the parents to send their children to school. Linking individual, household, and local government policy enables us to determine accurately the micro determinants of school enrollment decisions. This paper contributes to the literature by examining whether local government policy on education has an impact on school enrollment decisions in a detailed inter-district household-level study in Indonesia. Furthermore, we also examined the effect of local government policy on the school enrollment decision by interacting with female children. We combine data of the individual, household and community survey from Indonesia Family Life Survey (IFLS 2014) which represents about 83% of the Indonesia population. The village survey 2014 and district-level data from official and other publicly available sources. This allows us to unravel two main research questions: (1) how do local policy decisions influence the decision of households to send their children to secondary school? (2) to what extent does the local government policy have an impact on school enrollment by gender? The main results can be summarized as follows: the full sample estimation reveals that local government policies on education, which is indicated by pupil to classroom ratio and education expenditure per population in secondary school age, are found to have a significant impact on parents’ decision to enroll their children in the school. Interestingly other local policy indicators, such as the share of education spending, teacher experience, number of school of public and private per population in secondary school age, are insignificant. In addition, the interaction of local government policy with a female child show that only the number of secondary public schools by female child is weakly significant with negative sign. Comparing rural and urban areas, we find that education spending per population in secondary schools age and the share of education spending are positively and significantly affecting the school enrollment only in the rural area. In the urban area, our results show that reducing the number of student per class room and the number of public school per population in secondary school age has a negative impact on the parent decision for sending their children to school. The rest of this paper is organized as follows: the literature review on the determinant of school enrollment is presented in the next section. Section 3 contains the brief explanation of the current education system in Indonesia. Section 4 presents the data and the main hypothesis. This is followed by Sect. 5, where the results are presented. Section 6 presents the discussion and conclusion.",3
9.0,2.0,Eurasian Economic Review,29 May 2018,https://link.springer.com/article/10.1007/s40822-018-0100-x,Effects and burdens of a carbon tax scheme in Thailand,June 2019,Anan Wattanakuljarus,,,Male,Unknown,Unknown,Male,"Thailand is the 21st largest CO2 emitter in the world, the 10th in Asia, and the 2nd in Southeast Asia, releasing 4.1tCO2e per capita per year.Footnote 1 In 2015, the country emitted approximately 280MtCO2e into the atmosphere, constituting approximately 1% of the world’s CO2e emissions. After joining the United Nations Framework Convention on Climate Change (UNFCCC) in 1992, the country has been putting more effort into driving forward climate change agendas and the reduction of greenhouse gases (GHG) emissions, as exemplified by the inclusion of “a low-carbon society” in the 11th and 12th editions of the National Economic and Social Development Plan (NESDB) (2012–2016 and 2017–2021).Footnote 2 Recently, Thailand pledged to reduce its GHG emissions by 20% from the projected business-as-usual (BAU) level by 2030 (Thailand’s INDC 2015) at the 21st Conference on Climate Change (COP21 Paris). Ambitious plans have been laid out to achieve this goal, including the Power Development Plan (PDP), the Alternative Energy Development Plan (AEDP), and the Energy Efficiency Plan (EEP).Footnote 3 The proposed actions are, for example, a promotion of road-to-rail modal shift for the transportation sector, a vehicle tax scheme based on CO2 emissions, the adoption of the Waste Management Roadmap, and the study of Reducing Emissions from Deforestation and Forest Degradation (REDD +). The energy sector, which releases about 70% of the total manmade GHG emissions nationwide,Footnote 4 is the main target for the planned 20% reduction, and a carbon tax can be a key instrument to achieve such a goal. Normally, a carbon tax is levied on the carbon content of energy or fossil fuels. It is a pricing instrument and a market-based mechanism that creates an incentive for emitters to emit less. It corrects alleged market failure by incorporating the social cost of carbon into energy prices. It also provides an incentive for shifting toward cleaner energy in the long run and increases the competitiveness of renewable energy. Moreover, a carbon tax could stimulate an energy policy reform through a more efficient pricing scheme (Kossoy et al. 2015). Introduced in European countries since 1990 (World Bank, Ecofys 2017), the carbon tax has become more popular around the world in recent years. Mexico and South Africa, for example, have commenced their implementation plan while Singapore is the first country in Southeast Asia to announce a national carbon tax scheme, which is scheduled for launch in 2019. However, while experts from the International Monetary Fund (IMF) suggest that a carbon tax be used to fulfill INDC plans for developing economies (Farid et al. 2016), there are distributional concerns of regressive welfare effects. This problem means that low-income households proportionally suffer a larger welfare loss than their high-income counterparts, which consequently worsens income inequality and poverty reduction. This distortion has occurred in even developed economies such as the United Kingdom, Sweden, Denmark, and Ireland. Given such circumstances, a carbon tax could raise public concerns and political resistance. For Thailand, the implementation could contribute to reaching the INDC goal and thus protecting the global environment, but the reduction would be achieved at the country’s expense since a carbon tax would cause economy-wide negative effects on production, consumption, income distribution and, by extension, slower economic growth, higher production costs, lower purchasing power, and social welfare losses. The effects are expected to spread throughout the economy, not only through higher energy prices and commodity prices, but also via lower primary factor income or returns. Higher energy prices increase the production costs of energy-intensive sectors and their downstream sectors, which eventually causes many intermediate and final goods and services to be more expensive. As a consequence, higher production costs can affect the use of intermediate inputs along with the employment and wages of primary factors that comprise the major sources of household income. Lower primary factor income or returns and higher prices for goods and services can be a burden on households, given that they reduce households’ purchasing power, consumption levels, utilities, and social welfare. Variations in primary factor employment and wages might alter the effects, more or less, depending on the degree of responsiveness of labor and capital to the shock. The effects, in general, are not distributed equally across household groups due to differences in demand elasticities, shares and consumption patterns, shares and sources of factor income or returns, energy intensity of goods and services consumed, and labor and capital shares of contracted sectors. So far, the economic costs and environmental benefits of a carbon tax scheme have not been adequately studied. This paper thus aims to examine the economy-wide effects and burdens of a 20% reduction of carbon emissions as pledged by Thailand’s INDC through a carbon tax scheme-based simulation on key economic and environmental indicators using a computable general equilibrium (CGE) model. In addition, the role of labor and capital markets in altering the effects will be evaluated, and the effects of relief measures—an across-the-board increase in the existing social transfers—will be examined. The CGE model simulates and estimates the costs and benefits and other related consequences of any relevant policy in question. Based on a social accounting matrix (SAM), the model exhibits various inter-linkages among production activities, factor markets, commodity markets, final demands by domestic and foreign institutions (i.e., households, corporations, governments, and the rest of the world) as well as taxes, subsidies, and transfers. Both producers and consumers are assumed to behave optimally, and other agents are constrained by appropriate assumptions. Hence, for any shock that arises in the economy, the model can properly estimate through such inter-linkages the effects and the deviations of macroeconomic indicators that are influenced by changes in related microeconomic variables.",18
9.0,2.0,Eurasian Economic Review,12 May 2018,https://link.springer.com/article/10.1007/s40822-018-0105-5,"Informal economies around the world: measures, determinants and consequences",June 2019,Ceyhun Elgin,Ferda Erturk,,Male,,Unknown,Mix,,
9.0,2.0,Eurasian Economic Review,23 June 2018,https://link.springer.com/article/10.1007/s40822-018-0109-1,Ownership structure and firm patenting activity in Italy,June 2019,Marianna Succurro,Giuseppina Damiana Costanzo,,Female,Female,Unknown,Female,"Innovation—a key determinant of firms’ performance—is at the basis of future economic growth, competitiveness, employment and ecological sustainability. As in the modern economy it emerges from a continuous interaction among firms, between firms and universities (so called universities’ third mission), suppliers, buyers, and external environment at sectoral, regional and national levels, there is an increasing need to understand both the driving forces and the consequences of innovation and technological change. Several studies have been possible and significant progress has been made on applied research regarding innovation thanks to publicly available, internationally comparable and reliable micro-data on the innovation process. However, the choice among different innovation indicators is not trivial since they are characterized by strengths and weaknesses at the same time (Kleinknecht et al. 2002). Since inventions are hard to observe, scholars often look at the invention process through the lens of patent data (De Rassenfosse 2010). Even if it is well known that “not all inventions are patentable and not all patentable inventions are patented”, understanding “…what differences exist among firms […] in the propensity to patent is one of the most important question concerning the patent system” (Mansfield 1986). It is all the more true 30 years later, with the increasing availability of international patent data and the great success that patent data meet with scholars and policymakers. In spite of an international debate on whether today’s patent regime leads to more innovation (or not) and numerous researchers supporting the need to abolish or fix them (see Boldrin and Levine 2012; The Economist 2015), the patent indicator is still one of the best measures in the absence of specific, more detailed, information on innovation activity from questionnaires. Moreover, while the collection of data through questionnaires is often characterized by a very low participation rate and/or incomplete answers, patent data are reliable, available over long time periods and they show only minor disturbances caused by occasional changes of patent laws. Thus, we use patents as an output measure of innovation and investigate the determinants of patenting activity in Italian manufacturing firms from 2006 to 2013. Both the firms with successful patent applications and accounting data are extracted from the Bureau van Dijk’s Orbis database. Given the potential impact of innovation on firms performance and growth of nations, it is extremely important to understand the incentives to innovate at the firm level. With reference to the literature on the driving forces of innovative activity, there is a growing consensus among scholars that the ability of firms to innovate is influenced by their corporate governance, among other factors like the institutional context, the availability of financial resources, the industrial structure and its dynamics and so on. However, there is little agreement on the channels through which ownership structure exerts this influence. On the one hand, it is argued that firms with dispersed ownership are suitable for promoting innovation because they diversify their risk across a large number of investors (Aghion et al. 2009). On the other hand, it is also highlighted that firms with concentrated, stable ownership can better control their activities and undertake long-term projects, which is essential for investing in new technologies that need a long time to yield results (The Economist 2012). Since the microeconomic evidence on the link between ownership structure and innovation remains conflicting, the objective of this paper is to shed new light on this branch of empirical literature. More specifically, the aim of the paper is to analyze the relationship between the ownership structure of Italian manufacturing firms and their patenting activity. The majority of previous empirical works uses a dichotomous approach by classifying companies as independent or non-independent and family or non-family firms on the base of a minimum equity stake of the founding family and/or additional criteria. This research, instead, employs an indicator which allows investigation of the effect of different degrees of firms ownership concentration on patent probability. Thanks to the information on firms ownership structure included in the Bureau van Dijk’s Orbis database, we are able to build an accurate indicator of different levels of control characterizing a company and evaluate the impact of ownership concentration on patenting activity. Moreover, this paper provides a comprehensive analysis of the impact of firm-specific resources and capabilities and industry characteristics on patenting activity by relating to the overall and most recent branches of the scientific literature. Finally, with reference to methodology, our analysis explicitly deals with the endogeneity problem in binary choice models by following Lewbel’s recent approach based on a “Special Regression” analysis. The rest of the paper is organized as follows: Sect. 2 briefly illustrates the related literature and the main contribution of this research; Sect. 3 specifies the relevant variables for the empirical investigation and illustrates some descriptive statistics; Sect. 4 presents the model and the empirical evidence on the determinants of innovation output probability; Sect. 5 illustrates the limits and future developments of the research; finally, Sect. 6 concludes.",10
9.0,2.0,Eurasian Economic Review,04 October 2018,https://link.springer.com/article/10.1007/s40822-018-0117-1,Informal employment in Kazakhstan: a blessing in disguise?,June 2019,Altay Mussurov,Dena Sholk,G. Reza Arabsheibani,Male,Female,Unknown,Mix,,
9.0,3.0,Eurasian Economic Review,05 July 2018,https://link.springer.com/article/10.1007/s40822-018-0110-8,Duality in human capital accumulation and inequality in income distribution,September 2019,Hiroaki Hayakawa,Yannis P. Venieris,,Male,Male,Unknown,Male,"Poverty and income inequality are closely and inversely related to human development. The lower the human development of a nation, the higher the degree of poverty and income inequality. This relationship is one of the more established propositions in economics, yet, historically, human capital was ignored by the stylistic neoclassical growth models developed by Solow (1956) and Swan (1956) in the 1950’s. They both assumed that the output of a country is a function of capital and labor (both expressed in physical units) and is subject to diminishing returns. Unfortunately, these models became known more for the magnitude of their unexplained residual, their stylistic clarity and pedagogic simplicity, and less for their predictive power. Indeed, Solow (1957) showed nearly half a century ago that only approximately twelve percent of economic growth in the United States during 1909–1949 could be attributed to increased capital intensity. The implication of these models was that growth must be related to technological changes that were considered exogenous to the system; however, economic experience does not comply with this conclusion. Indeed, it became obvious that a number of other variables are important in the process of economic growth. The augmentation of capital, including human capital, was one of them, which led to a series of models that became known as the endogenous growth models (e.g., Romer 1986, 1990; Lucas 1988, Rebelo 1991). The main message of these models is that the law of diminishing returns to scale may not ensue and the development of human capital is one of the sine qua non factors for growth and development. Indeed, human capital development and foreign direct investments are now accepted as important strategic variables that promote growth in the Less Developed Countries (LDC’s). The development of Singapore and mainland China—particularly their enterprise zones—testifies in favor of this proposition. These zones not only promote growth individually but also in conjunction with each other through their intrinsic complementarity. In other words, investments in education improve domestic skills and invite direct foreign investments by providing a fertile environment for the adoption, adaptation, and use of new technologies (Noorbakhsh and Youssef 2001). There is no question that a number of strategic variables played a significant role in the success of Singapore and mainland China. However, it would be a serious mistake to ignore the close association between expenditures in human capital and their economic evolution. Indeed, the per capita spending on human capital can predict the subsequent rates of growth of the various countries although this relationship is compounded by other factors. Income inequality is probably neither the best nor the only indicator of structural inequalities in LDC’s. Conceivably, the statistics on the health of a population provide a more comprehensive picture of the fundamental and long term inequality among the socioeconomic classes. The World Bank (2005), Table A3 (p. 282) makes this point abundantly clear. This same table shows another aspect of the predicament of the poor. Although progress took place during the past 20 years, the mortality rate of the children of the poor within 12 months of their birth is more than one hundred percent higher than that of the affluent classes. There are a number of reasons for this gap, but the interaction of education and health is of particular importance. Education is a significant determinant of an individual’s station in the labor market and predicates the income of the family, its housing, and other material resources. All of these factors influence the health of the household, the incidence of inequality of health, and better prepare the actors for parenthood. Moreover, education prepares children with the emotional, social and knowledge skills to attain a full and healthy life. It also readies children to become citizens who are aware of their responsibilities and rights, and teaches them how to interact with groups and society at large. Yet the trend of the health inequality is not unique to LDC’s. Public health and epidemiology journals are full of examples of the inequality in health delivery, not only in LDC’s but also in Western democracies (Marmot 2006). They show how deep and structurally embedded is inequality in health delivery and how strongly health delivery is associated with income and wealth inequality, and other socioeconomic factors (Brenner 1995; Adda et al. 2003; Lynch et al. 2004; Marmot and Wilkinson 2006; Drakopoulos 2011), as evidenced by several European countries where this same pattern of health inequality is confirmed. For example, Acheson (1998) showed that the inequality in health delivery increased in England ever since the Black Report, which was published in 1980. In particular, several studies have found that economically inactive men have three times the risk of premature death than employed men. While the lack of good health increases the risk of exclusion in the labor market, it also appears there is a reverse causation due to social stigma and stress. Again, in Norway and Denmark, differences in the mortality among the classes increased. This same study also found that a mortality advantage in favor of the higher socioeconomic classes occurred in all EU countries (Kunst et al. 1998; Judge et al. 2006). Education is the other aspect of human capital. World Bank (2005), Table A4 (pp. 284–285) provides the appropriate statistics for a number of LDC’s by region and compares them with those of developed countries. It paints a very pessimistic picture concerning the prospects of development in the third world. Indeed, the level of education in general, and higher education in particular, leaves plenty of room for improvement. In Africa, for example, the average years of schooling are 3.97 years with 45% of the population illiterate, only 4% attaining more than 13 years of education, and a Gini index of educational distribution of 0.58. However, as always, averages mask the extent of the problem. In Chad, the illiterate percent of the population amounts to 76%, in Ethiopia 74%, in Mali 81%, in Senegal 77%, and in South Africa 74%. In the same countries, the percent of the population that completed 7–12 years of education amounts to 6, 9, 6, 7, and 9%, respectively. The corresponding percentages for more than 13 years of education for the same set of countries are: 1, 1, 3, 3, and 3%, respectively. Finally, education in the same countries is distributed very unequally, as evidenced by their Gini coefficients for education, which are: 0.66, 0.83, 0.87, 0.83, and 0.79, respectively. Admittedly, these countries are examples of extreme low educational attainments and high poverty, but the rest of the African counties, although they do not show such extreme attainment values, are, nevertheless, too close for comfort. Clearly, these educational achievements and their distribution determine not only the current income distribution and degree of poverty, but they also predict the future of these countries and their people. They also give rise to a great deal of pessimism regarding the present and future likelihood that these countries will adopt inclusive governance, which has clear implications concerning the presence and intensity of socio-political instability.Footnote 1 Finally, the accumulation of human capital among countries is also one of the most important factors that determine the geographical distribution of foreign investments (Hanson 1996; Funke and Strulik 2000). In fact, its importance increases over time as foreign direct investments play the role of externalities for each other. In addition, poor education generates de facto elites, who may very well perpetuate it in their quest for status quo that serves their interests and power. Indeed, the 18th and 19th centuries witnessed the importation of French, German, Spanish, and English colonial-structures into the traditional cultural settings of what we now collectively call the Third World states. Social and cultural disruption was inevitable given the collapse of traditional modes of authority. The displacement of historical models of authority by western colonialism, as well as the attendant economic machinery and power of western intervention, caused the realignment of social classes and gave rise to new elites. These new elites were educated in and adopted the cultures of the respective European centers. Returning to their homelands, they advocated and pursued policies that reflected the interests of their own class and those of their newly obtained foreign partners. In the process, they intentionally ignored the aspirations of their countrymen when such aspirations were in opposition, directly or indirectly, to their interests, while they clearly acknowledged and satisfied their own desires and demands (Mills 1956, 2010).Footnote 2 Although the initial conditions might very well be attributed, at least partially, to the colonial rule and historical legacy of the past, their continuation may also be the outcome of inertia and the collective action of their elites, who seek to maintain their position by actively advocating this duality and the benefits associated with it. We cannot simulate history and provide empirical evidence as to how poor or rich Africa would have been absent its colonization by Europeans. Nevertheless, other European colonies that inherited different sets of institutions; such as, the United States, Australia and New Zealand evolved in a different way. However, we are quick to point out that even in these counties, the indigenous population exhibited, and still exhibits to a lesser extent, all the characteristics of LDC’s, at one time or another, due to continued discriminatory practices against them. Such practices existed in these countries during the colonial times with respect to the opportunities and development of human capital and its sustainability. Given the state of distribution of educational attainment, the existing duality in human capital, the inequality in income and wealth distribution, and the importance of human capital for economic development, this paper puts forth a strategic choice-theoretical model by which to analyze how these facts emerge and are sustained as a result of strategic choices made by individual agents, rich or poor, on how much human capital to accumulate as an endogenous response to technological innovations. In doing so, we explicitly consider the fact that human capital complements the productivity of each individual, hence turning human capital accumulation by the rich or poor, into choices that exhibit strategic complementarities. Although technical and vocational education and training (TVET) were used by a number of developing countries as instruments of sustaining development, their significance was not accompanied by appropriate action and their appreciation was left to the periphery. Our idea of the strategic complementary in human capital accumulation is closely related to Adam Smith’s notion of division of labor in the Wealth of Nations (2007). That is, the division of labor, by breaking up the production process into a number of sub-processes, not only increases the productivity of each of the workers assigned to these smaller processes, but also brings about the refinement of skills for each part (including the development of better equipment to do the work). In the end, a productive economy thrives on the division of labor that is facilitated by the refinement of skill and equipment. Once the work is divided into specialized sub-works, these are linked by the complementarity that runs through them; i.e., if other sub-works are performed to a greater degree, the remaining sub-work must also be performed to a similar degree. Thus, the principle of strategic complementarity underlies the productivity of the division of labor. If the productivity of each sub-work is enhanced by the specific skill or work-specific equipment, various forms of human capital and physical capital are also locked into the relations of strategic complementarity that as a whole constitute the production technologies. Such division of labor, along with the accompanying division of human and physical capital, is even more important for the economies of our times, which are now globally linked through divisions of work that are connected by numerous chains. In other words, designers need also blueprint makers, as well as, die casters, lathe operators, plumbers, wood workers, and wheel and caster makers, etc. We also note that as an economy advances by the division of labor, the members of the society become increasingly aware of their dependence on each other as the work performed by each member is only a very small part of the whole production process, which puts out a multitude of finished goods that are beyond any single man’s power to produce. This increased dependence and awareness generates the sense of organic solidarity that binds the society together (Durkheim 1947). Indeed, societies of organic solidarity are arranged around economic and political organizations, and their legal systems regulate behavior on the basis of the principle of exchange and restitution rather than punishment. The Smithian division of labor brings about a grand order of production and consumption of our economy, and the Durkheimian division of labor in society in terms of the organic solidarity breeds and sustains social cohesion. In this paper, we argue that as the modern technologies result in increased intensity of complementarity of human and physical capital in the division of labor, it becomes quintessential for labor to equip itself with matching skills and trades to integrate with technologies of the time. Such integration is essential for social cohesion, harmony, socio-political stability, and the survival of democracy. Today, we are witnessing that human capital in various forms of scientific knowledge and technologies is highly diversified and the principle of complementarity runs through it as a breakthrough in one area raises the productivity of other areas. This implies that the Smithian division of labor, if extended to the entire economy, is essentially a principle of diversifying and organizing various forms of human and physical capital (i.e., knowledge and technology) to expand the order of an economy. To thrive on this principle in all areas of human endeavor, labor and human capital must be combined into skilled labor, which matches the technologies that evolve constantly. The Durkheimian view of the division of labor is a principle of the generation of solidarity and social cohesion that accompanies the Smithian grand order.Footnote 3 A detailed inquiry into the relationship between the strategic complementarity of human capital and the division of labor à la Adam Smith and Emile Durkheim is relegated to a separate paper. To anticipate some of the results, our model explains why the dualities in human capital arise, why they contribute to the deterioration of income distribution, and why such dualities get worse with economic growth when accompanied by inflation. We extend the analysis to the distribution of the health of the actors, and show how dualities in health distribution are similar to those in human capital. We begin our analysis by recognizing a two-class society; that is, the haves and have-nots. This classification is also reflected in the specification of the production function in which human capital is divided into the same classes of labor inputs that are introduced as complementary arguments. In addition to human capital, each class owns its respective physical capital and labor time, all of which are assumed to be given in our analysis. If technological innovations shift the production function, such a shift changes both the mix of the two classes of human capital and their optimal levels, which are endogenous responses. It is interesting to note that such responses may shift the production function even further, if human capital feeds technological innovations, thereby inviting further accumulation of human capital, etc. The paper addresses the possibility of such multiplier effects. While the importance of human capital has occupied a central place in the literature of human capital and economic growth (e.g., Nelson and Phelps 1966; Mincer 1984; Mankiw et al. 1992; Benhabib and Spiegel 1994; Hanushek and Kimko 2000; Bassanini and Scarpetta 2001; Hanushek and Woessmann 2009; Hanushek 2013; Cadil et al. 2014; Pelinescu 2015; Teixeira and Queirós 2016), what has been missing is a mechanism that mediates technological innovations, human capital and economic growth. By focusing on human capital as a strategic choice made by individual agents, this paper adds one more consideration to the literature of economic development and growth. While human capital can be accumulated through learning by doing, here we focus on human capital acquired through education (inclusive of general, vocational and specialized education). Because education, particularly at the vocational and specialized level, imparts different skills and knowledge depending on the occupational choice, more education must be interpreted contextually with care.",5
9.0,3.0,Eurasian Economic Review,12 July 2018,https://link.springer.com/article/10.1007/s40822-018-0112-6,Human capital and genetic diversity,September 2019,Tiago Neves Sequeira,Marcelo Santos,Alexandra Ferreira-Lopes,Male,Male,Female,Mix,,
9.0,3.0,Eurasian Economic Review,31 August 2018,https://link.springer.com/article/10.1007/s40822-018-0114-4,Human capital and economic growth across regions: a case study in Indonesia,September 2019,Yoga Affandi,Donni Fajar Anugrah,Pakasa Bary,Unknown,Unknown,Unknown,Unknown,,
9.0,3.0,Eurasian Economic Review,28 June 2018,https://link.springer.com/article/10.1007/s40822-018-0107-3,Unemployment gender inequality: evidence from the 27 European Union countries,September 2019,Marina Faďoš,Mária Bohdalová,,Female,Female,Unknown,Female,"Gender inequality is still persistent in many aspects of our lives. However, gender inequality in the labor market is the most discussed one. Women were considered throughout the history as less suitable for the labor market compared to men. It was expected that women were more suitable for family care, while men earned money. It is obvious that this perception of women remained in the minds of many men nowadays (Krainska 2016). There are many policies that have been implemented to reduce gender inequality to achieve equality (Zachorowska-Mazurkiewicz 2009). Charter of Fundamental Rights (European Commission 2017) guarantees gender equality for people from the EU countries. Nevertheless, gender inequality varies depending on the analyzed country. A question arises: does the gender inequality in unemployment depend on the unemployment rate or rather something else? We have chosen quarterly data of the 27 European countries on unemployment rates disaggregated by gender. We have proposed unemployment gender inequality indicators. These indicators helped us extract the trend of the unemployment gender inequality from the trend of the unemployment rates and provided us an insight to the real gender inequality in the countries of the European Union. Before analyzing the relationship between unemployment gender inequality and the level of unemployment, we checked presence of the hysteresis process including zero, one and two structural breaks for both univariate and panel data series. This enabled us to exclude time as a potential exogenous factor. Unemployment gender inequality differs across countries. In some countries, for example Austria, Denmark, France, Hungary and Sweden, gender inequality was low and almost non-existent. Unemployment rates there were at some point higher for women and at some other points higher for men. However, there are countries with low gender inequality or low variance intervals. However, Ireland, Latvia and Lithuania exhibited very high variance of gender inequality that disadvantaged men during the observed period. In majority of the countries, unemployment rates of women were higher than unemployment rates of men during the observed period. The most critical gender inequality that disadvantaged one gender was in Greece, where during the whole observed period, unemployment rates of women were substantially higher than unemployment rates of men (Fig. 1). Source: Authors’ calculation Unemployment gender inequality in the European Union countries. Countries differ not only by unemployment gender inequality, but also by the levels of the unemployment rate, which was the reason for conducting this research. We did this research under the assumption that an increase in unemployment rates would lead to an increase in gender inequality in unemployment which occurred for a different reason than from the impact of the economic shock. We can also see that the unemployment rate has been higher for only one gender in some countries throughout the surveyed period. Therefore, we also assumed that gender inequality was lower when men unemployment rate was higher than the unemployment rate for women and higher otherwise. Some countries, such as Austria, Belgium and some others, switched the gender at disadvantage. At the beginning of the period, the unemployment rate of women was higher than the unemployment rate of men, and then it switched to the opposite behavior and vice versa. This is the line of investigation which can be investigated further, however the results are not presented in this paper. The paper is structured as follows. We start with literature review of gender inequality on the labor market, and we present the unemployment gender inequality studies during recent years. Afterwards, we describe the methodology of unemployment gender inequality indicator computation, followed by methods which are used in this study. Next, we introduce the results from our study. We start with data representation, stationarity test results, the relationship between the levels of the unemployment and unemployment gender inequality, as well as the results of dependence of gender at disadvantage and the levels of the unemployment rates. In the last section, we give our conclusions. The paper provides an insight into unemployment gender inequality in the European Union countries. We have enabled some level of gender inequality as a measurement scale, which is free of the trend of the unemployment rates to compare gender inequality. Further, we contribute to the hypothesis of hysteresis validation of unemployment gender inequality literature, by validating the indicator of unemployment gender inequality that we propose, using a battery of unit root tests, both on univariate country series and panel data containing the analyzed EU countries.",4
9.0,3.0,Eurasian Economic Review,21 February 2018,https://link.springer.com/article/10.1007/s40822-017-0089-6,Female employment status: a survey analysis of selected member states of the Arab League,September 2019,Meltem Ucal,Simge Günay,,Female,Female,Unknown,Female,"There have been positive developments in the Middle East and North Africa (MENA) in terms of reform movements, social and economic freedoms, and employment opportunities. Moreover, the award of the 2011 Nobel Peace Prize to Tawakel Karman, a Yemeni woman, drew the region’s attention to the power of Arab women regarding these changes. However, the lack of prevention of violations of women’s rights and women’s lack of access to opportunities concerns society. Thus, challenges remain to achieving gender equality so it is crucial to prioritize reforms regarding this issue (World Bank 2013). Although MENA countries have narrowed gender gaps in basic education and health, it has been claimed that these developments are not yet reflected in female participation in economic and political life because of individual preferences in the region (World Bank 2013). To test this claim, we looked at the sixth wave of the World Values Survey data using an online analysis tool offered by the website itself. According to the results of this analysis, we found that the percentage of full-time women employees in selected Arab League states is lower than that of men, except in Morocco (see Fig. 1). Source World Values Survey, The Sixth Wave Online Analysis (2010–2014), http://www.worldvaluessurvey.org/WVSOnline.jsp Full time employment status by gender. Our online analysis also indicates that almost the entire population of women in selected member states of the Arab League are housewives. This may explain why the percentage of unemployed men is greater than the percentage for women except in Libya, Morocco and Qatar (see Figs. 2 and 3). Source World Values Survey, The Sixth Wave Online Analysis (2010–2014), http://www.worldvaluessurvey.org/WVSOnline.jsp Population of women who are housewives in selected member states of the Arab League. Source World Values Survey, The Sixth Wave Online Analysis (2010–2014), http://www.worldvaluessurvey.org/WVSOnline.jsp Percentage of unemployed by gender. These findings are important because they reflect that, even though the percentage of unemployed women in the region does not exceed that of men, this does not make it unnecessary to explore the issue of female labor force participation rates to fully understand women’s employment status. Excess unemployment among men is not an indicator of high female labor force participation in the region. The following example illustrates the problems of female labor force participation in the Arab region. It is very important to note that lower levels of education and lower labor force participation rates among women result from the interaction between the region’s economic structure and its conservative culture. Women in Arab societies are mostly economically dependent upon their husbands. The region’s economic structure based on oil affects gender roles. The use of capital-intensive technologies in the region results in high wages for men and the exclusion of women labor force (Roudi-Fahimi and Moghadam 2016). Saudi Arabia is a useful example for understanding the socio-economic situation of this region independently of the employment status of women. Although we have not analyzed Saudi society because of data limitations, we include it as an example of socio-economic status in the region since it shares a border with our selected countries, such as Iraq, Jordan, Yemen, Kuwait and Qatar. Women in Saudi Arabia, which is accused of having slow growth of financial sector because of its conservative socio-cultural beliefs and practices, do not use the banking system effectively for keeping their money. Furthermore, men are offered superior services by banking institutions to those offered to women, which upsets female customers. As a result, Saudi women cannot participate in socio-economic life independently (Hamid 2014). Given this regional situation, this paper explores the female perspective in selected member states of the Arab league, namely Algeria, Bahrain, Egypt, Iraq, Jordan, Kuwait, Lebanon, Libya, Morocco, Palestine, Qatar, Tunisia and Yemen, regarding possible determinants of their employment status and their opinions about women’s employment status, drawing on specific questions in relation to the region’s patriarchal culture and conservative social norms. We argue that the ideas of women in this region concerning this issue should be considered in detail because they may help analyze the problem from their perspective. These women’s subjective perspective on female labor force participation could add an interesting point of view to the existing literature and reveal some intriguing (maybe different) results since we could not find similar studies to ours in the literature. Before considering our analysis, it is first necessary to review the literature concerning labor force participation in the Arab region generally to understand more deeply possible problems concerning female labor force participation. Accordingly, the next section reviews research on this issue in the Arab region to show (albeit differently from our subjective analysis) the factors affecting female labor force participation. The following section introduces the paper’s methodology and theoretical framework. The data and the results are presented in the fourth and the fifth sections respectively while the sixth section concludes the paper.",10
9.0,3.0,Eurasian Economic Review,01 June 2018,https://link.springer.com/article/10.1007/s40822-018-0106-4,Migration and labor supply in Georgia: an empirical study,September 2019,George Berulava,,,Male,Unknown,Unknown,Male,"Georgia has experienced large-scale emigration since the period following the breakup of the former Soviet Union in 1991 and obtaining independence. There were several driving forces behind migration processes in Georgia: political and ethnic conflicts (and as sequence a substantial number of refugees) as well as economic motives due to the deterioration of the national economy (Gerber and Torosyan 2013). Because of these processes, thousands of people emigrated from Georgia in search of high-wage employment opportunities. According to the National Statistics Office of Georgia, approximately 867.6 thousand persons out-migrated from Georgia during the period of 1991–2005. Along with an increase in international migration, remittance flows into the Georgian economy have increased dramatically. In 2015, net remittances from abroad accounted for almost USD 1.5 billion or 10.4% of the GDP (OECD/CRRC-Georgia 2017). Although remittances from international migration, in general, have positive macroeconomic effects, recent empirical findings suggest that high migration and remittance levels may also have a negative impact on the functioning of the labor market. Whilst in developed countries, the total factor productivity growth and capital deepening are among the major factors that account for within-industry contraction of the labor share (Bassanini and Manfredi 2014), in developing countries, the weak performance of labor markets is usually associated with high migration and remittance levels (Kim 2007). It is well known from academic literature that international migration affects labor market performance in two ways (Rodriguez and Tiongson 2001). First, it reduces the labor force directly when a potential participant in the labor market migrates abroad. Second, the inflow of remittances can negatively influence the behavior of left-behinds. Thus, emigration and remittances could be among the factors that explain the poor functioning of the labor market in Georgia (Berulava and Chikava 2012). Despite its importance, the link between migration and the labor market behavior of left-behind household members remains relatively unstudied in Georgia. Moreover, the few studies that explore this relationship in Georgia do not account for the potential endogeneity between migration and the labor market choices of left-behinds. Hence, the causal link between these two household choices is still undetermined. Another comparatively unexplored issue is whether or not the impact of migration on the labor market outcomes of left-behinds depends on the household status of migrants (relationship to the household head). We aim to fill in these gaps in this paper by studying the effects of migration on the labor supply decisions of left-behind family members on the basis of information from the Georgian Household Survey. We account for the potential endogeneity issue between migration and the labor market behavior of left-behinds by employing the instrumental variable (IV) estimation technique. We also explore the impacts of migration differentiated by the household status of an emigrant on the labor market participation/inactivity decisions of left-behinds. The results of the study suggest that international migration is an important predictor of the labor participation choices and the employment status of left-behinds and that this effect is robust to the control of remittances. However, the effects of migration on the labor market participation/inactivity decisions of left-behind family members differ substantially by the household status of the migrant, the gender of left-behinds and the settlement type. We find that migration has a statistically significant impact only when the migrant is from a nuclear family. Migrants from extended families have no statistically significant effect on the labor participation choice of both female and male left-behinds. Whilst migration, generally, has a negative impact on the labor market activity of females, males living in migrant-sending households increase their participation in labor markets when migrants are children. The rest of the paper is organized as follows. We will examine the existing literature on migration-labor market behavior relationships in the paper’s second section. Research questions and objectives have been formulated based on a literature review. In the paper’s third section, we turn our attention to a discussion of the research methodology, including empirical strategy and measures. The data set and the characteristics of the variables used in the study are described in the fourth section. The paper’s fifth section provides an analysis of the study results. The sixth section offers up some final remarks.",2
9.0,4.0,Eurasian Economic Review,07 November 2018,https://link.springer.com/article/10.1007/s40822-018-0119-z,Effectiveness of public investment on growth in sub-Saharan Africa,December 2019,Nihal Bayraktar,,,Female,Unknown,Unknown,Female,"Public investment is considered essential to promote economic growth. Public capital establishes a foundation which private capital can build on. Public investment and public capital accumulation in infrastructure, education, and health are all expected to be important for private capital accumulation and thus for growth.Footnote 1 However, the effectiveness of public investment in supporting economic growth exhibits significant differences across countries (IMF 2015). While public investment leads to higher growth rates in some economies, the impact is limited in others. Given the unquestionable importance of public investment in an economy, the aim of this paper is to identify possible reasons behind its low effectiveness. More specifically, the significance of the level and volatility of public investment is studied.Footnote 2 The importance of the level of public investment is investigated under the name of threshold effects. It is expected that returns from public investment on output are exponentially higher in economies where the level of public investment increases beyond a threshold level. When the level of public investment is fairly low, it cannot effectively promote public capital accumulation and, as a result, economic growth because such low investment can barely even cover maintenance expenses of available public capital.Footnote 3 It can be said that public investment can effectively promote economic growth only if its amount raises public capital accumulation. Not only the threshold effect, but also the volatility of public investment can determine the growth path of countries. It is expected that the greater is the volatility of public investment, the larger the fluctuations in the growth process, thus the lower the growth rate. In light of these expectations, countries with low and volatile public investment should grow at a much slower pace, even after other possible determinants of the effectiveness of public investment, including corruption, are controlled for. In such economies, only a larger amount of consistent public investment can give the most needed push to the engine of growth because private investment, which is considered another important determinant of economic development, is expected to flourish more easily and promote growth more effectively in countries where public investment, especially the infrastructure component, is high and stable enough. Based on these arguments, it can be concluded that an economy with fairly low and volatile investment would be trapped in a period of low or even negative growth (low-investment trap) as long as these conditions continue. In the literature, there are many studies focusing on the effectiveness of public investment and growth. The contribution of this paper is that, to my best knowledge, no other paper has considered the combined effects of the volatility and level of public investment on growth. The additional significance of the paper is that it systematically tests the efficiency of public investment in different income groups. Finally, another important point is that the paper measures public and private investment in per capita real terms, instead of as a share of GDP. In this way, it is easier to see the striking differences in the level of investment across income groups. In the paper, a simple growth model is first introduced to illustrate the importance of the threshold and volatility effects of investment. Then, a set of statistical and regression analyses follows. The dataset covers selected sub-Saharan African (SSA) countries for the period of 1980–2014. The methodology introduced by Hansen (1999) and Herzog (2010) is used to identify the threshold effect of public investment. Furthermore, following Museru et al. (2014), the volatility of public investment is measured by calculating the rolling standard deviation of public investment over 2-year overlapping sub-periods. Different growth specifications are estimated by applying a dynamic general method of moments (GMM) introduced by Holtz-Eakin et al. (1988) and Arellano and Bond (1991). The aim is to control for possible endogeneity and causality issues. The instrumental variables consist of lagged values of the independent variables. Because annual data are used in the analysis, the focus of the estimation results refers to a dynamic multi-year framework. The statistical and graphical analysis shows that the volatility of investment is much higher, and the level of public investment per capita is extremely low in lower-income countries. The regression analysis for such countries indeed presents that public investment, even though still being a significant determinant of growth, is less effective when compared to the effectiveness of investment in the middle- and high-income groups. This finding is important because, even though the efficiency of public investment is expected to be higher in lower-income countries due to diminishing returns to scale, the regression results show that it is not always true. In the higher-income group, where investment is more stable and high, the estimated coefficients of public and private investment are both economically and statistically more significant, indicating a higher efficiency of investment. The empirical results further show that when the level of public investment per capita increases beyond a specific threshold, it gets exponentially more effective in promoting growth. Additionally, the volatility measure of public investment has a clear negative and significant impact on growth, especially in the lower-income group where volatility is highest. The structure of the paper is as follows. Section 2 summarizes the existing literature on public investment and its effects on growth. In Sect. 3, a simple model explains the importance of the volatility and threshold effects of public investment on growth. Section 4 presents the statistical and graphical analysis on investment and income in different income groups. Section 5 shows the regression results and investigates the impacts of public investment on growth across income groups in the presence of the volatility and the threshold effects. Section 6 concludes with some policy implications.",7
9.0,4.0,Eurasian Economic Review,21 November 2018,https://link.springer.com/article/10.1007/s40822-018-0120-6,Unit versus ad valorem tax comparisons in a simple New Keynesian dynamic stochastic general equilibrium model,December 2019,Kazuki Hiraga,,,Male,Unknown,Unknown,Male,"Many advanced countries introduce unit or specific as well as ad valorem taxes as value-added taxes. U.S. and Canadian states, most of EU countries and Japan apply an ad valorem consumption tax in addition to using unit taxes on goods such as gasoline, liquor and tobacco. Concurrently, when the government increases consumption taxes, some firms increase product prices more than the tax increase; that is, firms engage in price gouging. This paper compares unit and ad valorem taxes using the New Keynesian dynamic stochastic general equilibrium (DSGE) model. Producer price stickiness follows the previous research of Forni et al. (2009) and Iwata (2011). We show that the ad valorem tax increase is equivalent to the unit tax increase, even when price stickiness and monopolistic competition are present. Previous literatures have investigated the welfare effect of unit or ad valorem tax is more efficient in realizing objectives, e.g. Suits and Musgrave (1953), Delipalla and Keen (1992), Blackorby and Murty (2007, 2013), Häckner and Herzing (2016), Weyl and Fabinger (2013), Adachi and Fabinger (2017) and Wang and Chou (2018). These studies show that the ad valorem tax is superior to the unit tax.Footnote 1 This study expands on the relevant literature by using the DSGE model to compare unit and ad valorem taxes. Our result shows not only the comparative statics at the steady states, but also the comparative dynamics which analyzes the log-linear (i.e. first-order) approximation of model. The remainder of this paper is organized as follows: Sect. 2 outlines the study model. Section 3 compares the two tax schemes using welfare criteria. Section 4 concludes.",2
9.0,4.0,Eurasian Economic Review,10 November 2018,https://link.springer.com/article/10.1007/s40822-018-0121-5,"Banks’ capital buffers, risk, and efficiency in emerging economies: are they counter-cyclical?",December 2019,Syed Moudud-Ul-Huq,,,Male,Unknown,Unknown,Male,"Due to the rapid expansion of the global banking sector, it has experienced with multifaceted financial crisis and regulatory changes since 1980s (Bougatef and Mgadmi 2016). In this consequences, the Basel Accord (Basel I) was formed in 1988 to build a safety net against contingent risk by holding enough capital. Later, Basel II was adopted in 2004 to make a liaison between banks’ risk-taking and minimum capital requirements. Drawing attention on the recent financial crisis (2007–2008); the Basel Committee implies more stringent requirements of capital buffers and standardized liquidity in the form of Basel III. Capital buffer refers to holding sound capital above of regulatory requirement. From manifold of benefits of high capital buffers, most exclusively they can reduce extra financial costs by sending positive signals to the market (Bolton and Freixas 2006; Markovic 2006; Meh and Moran 2010). But the level of capital buffers may vary with individual bank characteristics like their risk expectancy, size, and the stage of economic fluctuations (García-Suaza et al. 2012). The negative relationship between the capital buffers and the business cycle is termed as counter-cyclicality, and lack of this factor has been blamed for a recent global financial meltdown. During economic expansion, banks adopt risky projects without having much justification and deteriorating capital accordingly (Chaibi and Ftiti 2015; Zheng and Moudud-Ul-Huq 2017). Thus, their risk accelerates and hit hard to adverse financial shocks. Concerning credit risk, poorly performed banks will probably fall below the levels of required capital. Therefore, to maintain the capital above of minimum requirement, they will have to either issue new shares or reduce their lending by increasing capital buffers. But this is quite hard to manage capital during economic downturns as scarcity of funding from other banks due to their conservative attitude of lending. As a consequence, the requirement of more capital intensifies the negative impact on economic stability through conservative lending (Borio and Zhu 2012; Repullo and Suarez 2009). That is why new Basel framework is established to ensure countercyclical capital buffers to boost banks correspondingly in different stages of business cycles. Mainly, this mechanism acts as a hedge against pro-cyclical capital buffers effect in the financial turmoil. So, during economic booms, banks need to establish enough capital buffers as future loss absorbent. This mechanism causes banks to change the capital adequacy ratio and behave predictably during economic upturn (Huang and Xiong 2015). A very few literature (e.g. Ayuso et al. 2004; Berger and Udell 2004; Bikker and Metzemakers 2004; Boucinha and Ribeiro 2008; Guidara et al. 2013; Lindquist 2004; Shim 2013; Stolz and Wedow 2006; Tabak et al. 2011) has been developed concerning counter-cyclical behavior, and mostly done on American, European, and developed countries banks. On the one hand, Jokipii and Milne (2011) find capital buffers of commercial, savings, and large banks behave counter-cyclically, and cooperative and small banks fluctuate pro-cyclically. Fonseca and González (2010) find different results of the cyclical pattern of capital buffers across and within developed and developing countries. Similarly, by 13 Latin American and Caribbean developing countries, Carvallo et al. (2015) also find both pro-cyclical and counter-cyclical effects in different countries. From most developed economy in the Asian counterpart in terms of GDP (CIA World Factbook), Huang and Xiong (2015) find five key features of Chinese banking industry in considering macroeconomic fluctuations. Those are: (1) banks capital buffers fluctuate counter-cyclically over business cycle; (2) by increasing equity capital, banks built their counter-cyclical capital buffers; (3) credit growth behaves counter-cyclically; (4) during economic downturns, there is strongly negative relationship between deposit premium and capital buffers; (5) regardless the interaction of business cycle, capital buffers are less powerful in influencing loan premiums. Moreover, they opposed to the findings of Western economies that state-owned banks have poor counter-cyclicality. However, the relationship between the business cycle and banking variable, i.e. capital buffer is not identical in different countries. In connection with this, business cycle (capital buffer) of Brazil, Russia, India, China, and South Africa are − 3.85% (11.76%), − 3.73% (11.10%), − 7.56% (8.34%), 6.91% (12.21%), and 1.26% (12.55%) respectively (Bureau Van Dijk’s Bankscope and WDI database 2015). From this statistics, Brazil and Russia behave counter-cyclically to its capital in response to the business cycle. Beyond these, majority of the studies (such as Aggarwal and Jacques 2001; Altunbas et al. 2007; Jacques and Nigro 1997; Laeven and Levine 2009; Lin et al. 2005; Rime 2001; Shrieves and Dahl 1992) have been focused on testing whether changing capital keep pressure banks to improve risk. Most of these studies have predicted by the theory that higher capital adequacy will also have a craving to undertake more risk over time and better corporate performance (Dietrich and Wanzenried 2011; Laeven and Levine 2009). But reverse results are also available (Ho and Hsu 2010; Lee and Hsieh 2013; Lee and Chih 2013; Raluca Busuioc Witowschi and Alexandru Luca 2016; Zhang et al. 2008). Besides, concerning the relationship between capital and risk; Kwan and Eisenbeis (1997) and Altunbas et al. (2007) argue the essence of efficiency in their econometric models. From the regulatory hypothesis point of view, efficient banks may have greater incentives to adjust capital and risk with better management during the business cycle. On the other hand, the efficiency of banks can also be affected by adjusted capital and risk. From moral hazard hypothesis view, inefficient banks may be persuaded undertaking more risk to adjust lost returns. However, from the points above discussions, it warrants to examine the relationship among adjusted capital, risk, and efficiency with macroeconomic influences. To our knowledge, contributions of this paper to the existing literature are many from following aspects. Firstly, this study empirically examines the impact of business cycle simultaneously on capital buffers, risk and efficiency of BRICS countries for the most recent period 2007–2015. Secondly, due to the prominent growth rates, emerging markets became an important sector for investors. Traditionally, being more bank-oriented, emerging markets experienced substantial growth of the financial markets during the last decades (Davydov 2016). Hence, from the macro approach, this paper is the anatomy of BRICS financial markets and enables us to differentiate from one to another. Thirdly, this study has a unique platform in emerging economies and still there have no research on the issues mentioned above, and the effect of the business cycle on efficiency is entirely missing in the literature. Fourthly, we use dynamic panel data that embraces global economic downturns of 2007–2008. To carry on this paper, we extend the scope of studies of Shim (2013) and Carvallo et al. (2015).Footnote 1 Finally, the outcomes of the study have diverse insights from the results of Altunbas et al. (2007), García-Suaza et al. (2012), Zheng et al. (2012), Shim (2013), Carvallo et al. (2015), and Huang and Xiong (2015). The rest of the paper is structured as follows. Section 2 develops empirical research framework and methodology. Section 3 describes data and variables. Section 4 presents the empirical results and robustness checks of results. Finally, Sect. 5 concludes the paper.",43
9.0,4.0,Eurasian Economic Review,07 December 2018,https://link.springer.com/article/10.1007/s40822-018-0116-2,Kazakhstan trade with its partners and the role of tenge: an asymmetric analysis,December 2019,Mohsen Bahmani-Oskooee,Hanafiah Harvey,Amr Hosny,Male,Unknown,Male,Male,"Recent episodes of tenge depreciation had renewed the interest in understanding its potential impact on the dynamics of the trade balance in Kazakhstan. The tenge has typically depreciated in nominal terms to preserve competitiveness with its trading partners, most notably the Russian ruble. In September 2013, Kazakhstan announced a move from an exchange rate regime linked exclusively to the dollar to one linked to a basket of currencies: the dollar, euro and ruble (Frankel 2013). In August 2015, the National Bank of Kazakhstan together with the government announced the transition to inflation targeting over the medium term as a new monetary policy framework, which among other pre-requisites, in principle requires a flexible exchange rate regime. The exchange rate band was thus abandoned and a float of the tenge was introduced. The National Bank of Kazakhstan announced that it would no longer intervene in the foreign exchange market to influence the tenge price, except to prevent excessive market volatility that could have a disruptive effect on the financial system (IMF 2017b, and National Bank of Kazakhstan 2015). Most recently, the economy has been hit by a series of negative shocks including lower global oil prices and weak external demand from major trading partners in Russia, China and the EU (IMF 2017b and World Bank 2014). These shocks led to heightened market volatility and eventually a significant depreciation in the exchange rate to regain external competitiveness. It is thus important to study the possible effects of such exchange rate depreciation on bilateral exports and imports, especially if the positive effects are to come with a lag.Footnote 1 This is the research question addressed in this paper. Theoretically, due to lag structure, a devaluation or depreciation may not affect the trade balance immediately as price effects dominate over volume effects in the short-run. If sketched over time, the trade balance could initially worsen before improving over time, resembling a “J” letter shape, hence the J-curve effect. The concept was originally introduced by Magee (1973) and empirically tested by Bahmani-Oskooee (1985). Review articles by Bahmani-Oskooee and Ratha (2004) and Bahmani-Oskooee and Hegerty (2010) reveal that every country has its own literature. In the case of Kazakhstan, we came across only one relevant study, i.e., Hosny (2014a) who examined the J-curve phenomenon in Kazakhstan using a linear error-correction model. He found positive long-run effects in Kazakhstan’s trade only with France and Romania; two countries that account for only about 10 percent of the country’s total trade. However, recent advances in error-correction modeling and cointegration analysis reveal that failure to find a significant link between the trade balance and the exchange rate could be due to ignoring asymmetric effects of exchange rate changes or due to not using non-linear models (Bahmani-Oskooee 2018). Despite its importance, only a few studies have empirically studied the effects of changes in exchange rate in Kazakhstan, mostly focusing on the impact on prices and dollarization. IMF (2017a) studies the exchange rate pass-through impact of depreciation on inflation and finds that around a 10% depreciation is associated with an increase of 3% in inflation, close to findings for other developing and emerging market economies. In the same vein, Hosny (2014b) finds no association between exchange rate changes and interest rates in Kazakhstan using a Taylor rule model over the 2003Q1–2013Q3 period. Naceur et al. (2015) find that asymmetric exchange rate policies, namely a foreign exchange policy biased toward more frequent depreciation than appreciation, has led to increased dollarization in many countries in Central Asia, including Kazakhstan. Hosny (2014b) also use data over 2000Q1–2014Q1 to study the determinants of deposit dollarization in Kazakhstan and find similar evidence about the statistically significant impact of exchange rate asymmetric policies, albeit with no impact from exchange rate changes or exchange rate volatility. Hasanov and Baharumshah (2009) use gravity models and find that exchange rate risk has no impact on the bilateral trade for many transition economies including Kazakhstan. For some other trade issues from central and Eastern Europe, see Caputo et al. (2016). Therefore, our goal in this paper is to examine exchange rate effects on the bilateral trade balance of Kazakhstan with each of its 13 top trading partners using the linear ARDL approach of Pesaran et al. (2001) and the non-linear ARDL approach of Shin et al. (2014) with a hope of discovering some new asymmetric effects of exchange rate changes. The 13 partners engage in more than 80% of Kazakhstan’s overall trade. As can be seen from Table 1, China, Russia and the Euro area countries represent the bulk of such trade. The rest of the paper is organized as follows. In Sect. 2 we introduce the models and methods. We then report our findings in Sect. 3 followed by a summary in Sect. 4. Data definition and sources are provided in an Appendix.",6
9.0,4.0,Eurasian Economic Review,28 September 2018,https://link.springer.com/article/10.1007/s40822-018-0118-0,Effects of geopolitical risks on trade flows: evidence from the gravity model,December 2019,Rangan Gupta,Giray Gozgor,Ender Demir,Unknown,Male,Male,Male,"Geopolitical risks are considered as one of the determinants of investment decisions by business investors, central bankers, financial sector, and the press. Hence, geopolitical risks are likely to affect not only business cycles and financial markets, but also international trade, as shown to be the case for the United States (U.S.) by Caldara and Iacoviello (2018). Geopolitics is used to describe the practice of states to control and compete for territory (Pollins 1989a). However, recently, power struggles and other events involving corporations, civil organizations, political parties, and rebel groups, are considered as a part of geopolitics. Therefore, the current usage of the word “geopolitics” covers a diverse set of events with a wide range of causes and effects, from terrorist incidents to nuclear tensions and from global warming to the great trade collapse in 2009 (Caldara and Iacoviello 2018). Not surprisingly, these events being global in nature and with the modern world being highly interconnected are likely to affect all economies and their international economic relations, i.e. international trade. Traditionally, the so-called gravity models used for studying the trade flows relate the same to measures of joint economic activity and costs of trade (Baier and Bergstrand, 2009). Geopolitical risks are likely to affect international trade by raising the costs to private agents engaging in international business through not only new risks being created but also via escalation of existing risks. This line of reasoning is validated by the international monetary fund (IMF) that highlighted geopolitical uncertainties as a salient risk to the economic outlook (International Monetary Fund 2017). Furthermore, wars and other militarized conflicts may affect trade among partners as those events are mostly followed by the partial or total trade embargoes (Glick and Taylor 2010). At this point, Glick and Taylor (2010) and International Monetary Fund (2017) theoretically and empirically illustrate that there are the direct effects of geopolitical risks on the trade flows. On the other hand, there could be the indirect effects of geopolitical risks on trade flows via the investment channel. For instance, geopolitical risks can cause the decline of investments due to the increasing costs of doing business and transaction; thus, geopolitical risks can indirectly affect exporting and importing decisions of firms (Balcilar et al. 2018). In addition, geopolitical risks can affect the trade via the exchange rate, the fiscal policy, and the monetary policy channels. According to the theoretical models, the real value of the exchange rates is mainly determined by expectations (Engel 2014). At this stage, geopolitical risks can affect the expectations on monetary and fiscal policy, and these issues can provide significant effects on the exchange rates, thus can affect trade flows (Mueller et al. 2017). The objective of our paper is to investigate the effects of the geopolitical risks, which is measured by a new index of geopolitical risks (GPRs) in 18 emerging economies, on trade flows among 164 countries for the period from 1985 to 2013. It is noteworthy to note that the importance of the new GPR index comes from the issue that it measures the real time geopolitical risk as perceived by the global investors, policymakers, the press, and public. We use the news-based indices of GPRs recently developed by Caldara and Iacoviello (2018) and Caldara et al. (2018), who define the geopolitical risks as the risk associated with tensions, terrorist acts, and wars between states that affect the normal and peaceful course of international relations. These indices do not only relate to geopolitical events of the global world, but are also available country-specific levels in 18 emerging economies. Hence, this index helps us to capture geopolitical risks of various forms continuously and enables us to go beyond the impact of specific events at a specific point in time, and in turn, provides a more holistic view of geopolitical risks, beyond just wars and terrorist attacks.Footnote 1 While there exist some studies in economics literatureFootnote 2 that analyze the relation of international trade to political disturbances and conflict (see e.g., Blomberg and Hess 2006; Glick and Taylor 2010; Martin et al. 2008), our paper aims to analyze the impact of emerging country-specific GPR indices on its international trade relations. We go beyond Caldara and Iacoviello (2018), who just concentrate on the impact of the U.S. gross trade (i.e., the sum of the exports and the imports), and focus on trade flows among 164 countries.Footnote 3 Indeed, the GPR indices have recently been used in empirical papers since they have provided useful measures of conflicts, political instability, and terrorism (see e.g., Apergis et al. 2018; Bouri et al. 2018). The contributions of our paper to the existing literature are as follows. This is the first paper investigating the effects of the geopolitical risks on trade flows in the panel dataset by using the GPR index recently developed by Caldara and Iacoviello (2018). Our paper provides the first empirical evidence in the literature for the effects of the GPRs on the global trade flows. To achieve the objective of the paper, we implement various econometric estimation techniques (the random-effects, the fixed-effects, the Hausman–Taylor (HT), and the Poisson Pseudo-Maximum-Likelihood (PPML) within a classical gravity model of Glick and Rose (2016). It is important to note that the gravity model uses various control variables; and therefore, addresses a possible omitted variable bias. In addition, we include a relatively long time period (from 1985 to 2013) in the dataset. Finally, we focus on 164 developing and developed countries in our dataset. Our paper shows that the global trade flows have been significantly and negatively affected by the GPR indexes of 18 emerging economies. The rest of the paper is organized as follows. Section 2 reviews the related literature on the effects of the conflicts, geopolitical risks, terrorism, and wars on trade flows. Section 3 provides the data, the empirical model, and the econometric estimation techniques to estimate the gravity model. Section 4 provides the baseline empirical results as well as the discussions and policy implications. Section 5 concludes.",56
9.0,4.0,Eurasian Economic Review,26 September 2018,https://link.springer.com/article/10.1007/s40822-018-0115-3,Exogeneity of world oil prices to the Russian Federation’s economy and monetary policy,December 2019,Victoriia Alekhina,Naoyuki Yoshino,,Unknown,Male,Unknown,Male,"Following the first oil price shock of 1973, the volatility of energy prices and its impact on the macroeconomy has become an important area of research in the field of economics. The second oil shock of 1979, caused by a cut in the oil supply, highlighted once again the significance of immediate energy price changes. Hamilton (1983) was one of the first scholars to show the importance of energy price changes for the United States (US) economy when he concluded that oil price increases had contributed to the recessions in the country during 1948–1972. Interest in oil price fluctuations and their role in the macroeconomy was renewed again due to a sharp increase in the oil price in early 2000 and an immediate drop in 2008 caused by the Lehman crisis (Hamilton 2009; Yoshino and Taghizadeh-Hesary 2014). There is a rich literature on the underlying sources of oil price fluctuations and their impacts on different economies. Kilian (2009) first differentiated between three types of oil shocks: oil-supply shocks, oil-demand shocks caused by increased economic activity, and oil-specific demand shocks driven by expectations of the oil market. Research has shown how much each of these shocks contributed to the evolution of the real price of oil during the 1975–2007 period. Askari and Krichene (2010) showed that factors such as US monetary policy, exchange rates, and the price of gas had a significant impact on the oil market. They suggest that the stability of oil prices cannot be achieved unless monetary policy is restrained, and real interest rates are significantly positive. Ratti and Vespignani (2014) investigated the impact of the oil supply sector on oil prices. They disaggregated supply into Organization of the Petroleum Exporting Countries (OPEC) and non-OPEC supply and found that the effect of non-OPEC oil production on oil prices was larger than that of OPEC production during 1997–2012. Ghalayini (2017) advocated that in the short run, Granger causality goes from oil inventories to oil prices; however, oil demand, oil supply, the US dollar to special drawing right exchange rate, speculation in the oil future market and oil inventories are associated in a long-run relationship. While earlier studies, including Hamilton (1983) and Kilian (2009), have shown the significance of the effects of oil price movements on the US economy, recent studies have documented the cross-country differences in responses to oil price shocks of different origins. These studies include that of Peersman and Van Robays (2012), who found that the responses varied across a set of industrialized countries that were structurally very diverse with respect to the role of oil and other forms of energy in their economies. Yoshino and Taghizadeh-Hesary (2016) identified economies that benefited and those that lost out after the recent oil price shock, while Taghizadeh-Hesary et al. (2016) highlighted the differences in the responses of the macro variables of emerging and developed oil importers to oil price movements. Aydoğan et al. (2017) assessed the relationship between oil prices and stock markets and showed that the correlation between them varied according to whether the country was an oil exporter or an oil importer. Ju et al. (2016) provided a comparison of the macroeconomic impacts caused by oil price shocks for 19 major oil-related countries/regions from the outlier perspective and found an asymmetric relationship between oil prices and macroeconomy in oil exporting/importing countries. Moreover, high economic growth in the People’s Republic of China (PRC) in recent decades has attracted significant attention, as it has caused an energy consumption boom, and made the PRC one of the world’s top energy consuming and importing countries. Cross and Nguyen (2016) assessed the PRC’s output and oil price relationship using an identification technique developed by Kilian (2009) and considering PRC’s role in the global oil market. Ou et al. (2012) investigated the responses of 71 Chinese macroeconomic indicators, including domestic oil prices, to the world oil price shock. They found that some indicators, such as price indices and interest rate, raised while others, such as stock prices, fall in response to global oil price increase. Meanwhile, Kim et al. (2017) estimated the reactions of the PRC’s monetary policy to oil price shocks using three different models and identification methods. They found that China’s interest rate response to oil price shocks is time-varying and shows different signs of responses. Nevertheless, it is widely accepted that energy price volatility is not only an important cause of macroeconomic fluctuations in both energy exporting and importing economies but also an influencing factor on fiscal and monetary policy. In this paper, we estimate the effects of oil price changes on the Russian Federation’s economy and monetary policy. Although the country is the largest non-OPEC oil exporter, only a few studies have examined the Russian Federation so far, mostly due to absence of long-term macroeconomic data. Existing studies include that by Ito (2012), who showed using quarterly time-series data that the Russian Federation’s real gross domestic product (GDP) and inflation rate was vulnerable to world oil price fluctuations during 1995–2009. Meanwhile, Yoshino and Alekhina (2016) examined the impact of domestic oil and gas producers’ price movements on the country’s aggregate supply and demand during 2000–2016 and found a significant impact of energy prices on both sides of the economy. Finally, Alekhina and Yoshino (2018) explained the impact of oil price fluctuations on the Russian Federations’ macroeconomy and monetary policy. In this study, we take an unconventional approach by assessing the impact of oil prices on the macroeconomy together with monetary policy given exogeneity of oil prices to the Russian Federation’s macroeconomy. While this country is an important player in the oil market, we assume that its macroeconomy cannot affect international oil prices. For the empirical estimation, we rely on the well-established vector autoregressive (VAR) method (Sims 1980; Christiano et al. 2005). We confirm oil prices exogeneity to Russia’s indicators through the Hausman test, also, we conduct a Granger causality test and confirm one-way causality from oil prices to the Russian macroeconomy. That allows us to use SVAR ordering with oil prices regarded as the most exogenous variable, which is affected only by its lagged value. On the other hand, the Russian Federation’s macroeconomic and policy indicators are allowed to be affected by oil prices. This, to the best of our knowledge, has not been done in previous studies of the country’s oil price and macroeconomic relationship using monthly data and incorporating monetary policy factors. This paper complements the existing literature in several ways. First, besides using a larger data sample with a higher frequency, covering the period from January 1993 to December 2016, we also explain the transmission channels of oil prices to the Russian economy through fiscal and export channels following macroeconomic and monetary policy theory. Secondly, since the main focus of this paper is on monetary policy, for the first step, we test the exogeneity of oil prices to the country’s monetary policy and confirm this assumption. We also conduct a breakpoint test and divide the data sample into two subsamples, since the Russian Federation experienced a financial crisis in 1998 and number of economic reforms afterwards and estimate both periods separately using a SVAR approach with identification based on the exogeneity of oil prices. Impulse-response functions and variance decomposition analysis help us understand the scale of variation in each variable of our model due to an unexpected exogenous oil price shock. At the end of this paper, we analyze the monetary policy rule for this energy-exporting country using the Taylor rule approach and newly-modified Taylor rule equation. The novelty of our findings is that the Russian macroeconomic variables were not responsive to oil prices during 1993–1999 but had significant responses during 2000–2016. We can conclude that although the sharp increase of oil prices at the end of 1990s crucially benefited the Russian economy and helped it recover from the financial crisis of 1998, it also made the Russian economy highly vulnerable to oil price movements. Moreover, we find that the Russian monetary authority had been targeting inflation since 1993, and the decisions of central bank were affected by oil prices and the exchange rate only during the period after the global financial crisis of 2008. These results can be interpreted as a reluctance from the central bank to take action when oil price growth rates are high (as during 2000–2008) but a willingness to adjust monetary policy when oil price growth rates are low or even negative (as during 2008–2016). The contribution of our paper is also the fact that it explains the recent economic downturn in the Russian Federation in light of the oil price drop in 2014, when oil prices decreased from more than $100 per barrel to less than $40 per barrel. As oil is the Russian Federation’s main export and also contributes significantly to the government budget, following this drastic drop, the ruble depreciated along with GDP growth. However, on the other hand, the inflation rate increased, and the interest rate was raised by the central bank as a monetary policy response to stabilize the economy in response to the unexpected oil price shock. The rest of this paper is structured as follows. In the next section, we provide an overview of the Russian economy, its role in the global oil market, and the transition channels of oil prices to the macroeconomy and monetary policy. In the third section, we provide a description of the data and the results of the statistical tests. In the fourth section, we provide the empirical methodology, the impulse response functions (IRF) and variance decomposition. In the fifth section, we conduct monetary policy rule analysis. In the last section, we summarize our results and conclude the paper.",15
10.0,1.0,Eurasian Economic Review,30 July 2019,https://link.springer.com/article/10.1007/s40822-019-00132-2,Entrepreneurship and culture,March 2020,David B. Audretsch,,,Male,Unknown,Unknown,Male,"While there is a long tradition in economic thinking on what influences economic performance and growth, entrepreneurship seemingly had scarcely any role to play. Rather, the focus on what drives economic growth and performance was more on key factors of production and resources, such as physical capital, human capital and knowledge, rather than on a particular type of organizational form or behavior, such as entrepreneurship. However, in recent years, entrepreneurship has emerged as a policy priority for igniting and sustaining economic performance in general and growth in particular (Audretsch 2007). Thought leaders in policy and business have increasingly turned to entrepreneurship to enhance economic development and generate employment, a high standard of living and competitiveness in global markets. Most recently, entrepreneurial ecosystems have captured the attention of both thought leaders in business and policy as well as scholars to facilitate entrepreneurial activity and ultimately growth and performance (Cunningham et al. 2019). While a rich body of empirical studies has emerged focusing on specific policy instruments targeted to foster entrepreneurial activity, less attention has been paid to the policy context. The purpose of this paper is to suggest that not only does the context matter for the efficacy of entrepreneurship policies, but in particular, the cultural context. While most studies and policy makers pose the question, “Which policies are most effective in fostering entrepreneurship and ultimately economic development,” this paper considers the policy context by instead asking, “Under which cultural contexts will entrepreneurship policies be more effective and under which cultural contexts will entrepreneurship policies be less effective?” The Sect. 2 of this paper explains the role of factors and resources in shaping economic performance in general and growth in particular. Section 3 focuses on the role of spatial structure and organization. How and why culture, including institutions and behavior influences entrepreneurship is the focus of the Sect. 4. In the final Sect. 5, a summary and conclusions are provided. This paper finds that the impact of policies to promote entrepreneurship are influenced by the cultural context. While entrepreneurship can play an important role in igniting economic performance and growth, the effectiveness of policy to promote entrepreneurship depends upon the cultural context.",7
10.0,1.0,Eurasian Economic Review,04 September 2019,https://link.springer.com/article/10.1007/s40822-019-00136-y,Determinants of foreign direct investment from OECD countries in Poland,March 2020,Andrzej Cieślik,,,Male,Unknown,Unknown,Male,"Multinational enterprises (MNEs) are important actors in the ongoing process of globalization. During the last 25 years, foreign direct investment (FDI) made by MNEs grew more rapidly than both world trade and world GDP. FDI originates predominantly from developed countries which have been at the same time the major recipients of FDI. According to UNCTAD (2018), the world inward FDI stock amounted to $31.5 trillions of which 64.5% was located in the developed countries. Poland which joined the Organisation for Economic Co-operation and Development (OECD) in 1998 and the European Union (EU) in 2004 has become an important target destination for inward FDI location in the last two decades. In 2017, the inward FDI stock invested in Poland since its economic transition in the early 1990s amounted to $238.5 billions which still accounts for less than 1% of the world inward FDI stock (NBP 2018). Nevertheless, compared to the pre-EU accession stock equal to $55.2 billions in 2003 the inward FDI stock has increased more than fourfold and compared to the pre-OECD accession stock equal to only $14.6 billions in 1997 the inward FDI stock increased more than 16-fold. The majority of foreign capital stock invested in Poland in 2017 originated from the other OECD countries—$227.6 billions (95.4%), and mostly from the other EU member states—$220.0 billions (92.3%). In 2017 the top five source countries were the developed West European economies, respectively: the Netherlands ($45.8 billions), Germany ($41.9 billions), Luxembourg ($33.2 billions), France ($21.5 billions) and Spain ($14.4 billions). Most foreign capital in Poland was invested in the manufacturing industry—$73.8 billions (31%), finance and insurance—$48.8 billions (20.5%), and wholesale and retail—$33.2 billions (13.9%). While numerous theoretical models try to shed light on FDI determinants, the main motives why firms internationalize production include: market access and cost cutting (Markusen 2013). On the one hand, MNEs are vehicles to overcome distance and lower costs of foreign markets access. Foreign direct investment undertaken to serve local markets is often called horizontal FDI. It refers to producing abroad roughly the same goods and services as in the home country. On the other hand, firms internationalize production in order to acquire inputs at a lower cost. Foreign direct investment aiming at cost reductions is called vertical FDI. It involves fragmenting production processes and locating various stages in different countries where the factors used intensively in particular stages are relatively cheap. These two alternative reasons have different empirical implications. As FDI in Poland originates predominantly from the OECD countries the main goal of this paper is to validate the predictions of competing theoretical models and identify the main determinants of inward FDI in Poland using bilateral panel dataset on FDI stock from the OECD member states covering the period 1996–2015. The estimated specification of the empirical model is based on the modified knowledge-capital model of the multinational enterprise that combines the horizontal and vertical reasons for FDI and includes two types of capital: human and physical. Moreover, in our study in addition to the full sample results, also the empirical results obtained separately for the pre-EU and the post-EU accession sub-periods are reported. The paper is structured as follows. The next section surveys the relevant MNE literature and discusses the empirical implications of competing theoretical frameworks. Then, definitions, data sources and the empirical methodology are described. Finally, we present and discuss our estimation results. The paper concludes with final remarks, policy guidelines and directions for future studies.",19
10.0,1.0,Eurasian Economic Review,18 July 2019,https://link.springer.com/article/10.1007/s40822-019-00131-3,Evaluating the logistics performance of OECD countries by using fuzzy AHP and ARAS-G,March 2020,Bahadir Fatih Yildirim,Burcu Adiguzel Mercangoz,,Unknown,Female,Unknown,Female,"Logistics is defined as a part of the supply chain that plans, implements and effectively controls the forward and reverse flow of goods, services and the information between the parties (Jhawar et al. 2014). With the rise of the numbers of internet users all over the world, logistics operations become an important issue for world commerce. To carry out the logistics operations effectively, there are some functions that need to be considered such as infrastructure and custom regulations of governments. To become competitive in logistics operations, it is important to provide suitable conditions in these functions. Therefore; not only is logistics an important issue for governments, but also for private companies. Logistics is an important driver for the countries’ economies. The Logistics Performance Index (LPI) was first published by the World Bank (WB) in 2007. This index ranks countries according to their logistics performance. LPI is used for benchmarking a country’s logistical performance with other countries. This index and its components can help countries to get to know their business partners more closely (Yaprakli and Unalan 2017; Martí et al. 2017). The survey is conducted on approximately 1000 professionals working in international logistics operations in various (up to 166) countries. The seven indicators used in the calculation of the index were revised and reduced to six indicators as of 2010. These indicators are titled: customs, infrastructure, international shipment, logistics quality and competence, tracking and tracing, timeliness. LPI is formed by a model where each expert scores eight different countries using six indicators. In this respect, it is discussed here as a Multi-Criteria Decision Making (MCDM) problem. As of this date, LPI data has been published every 2 years for a total of five periods (2010, 2012, 2014, 2016, 2018). The data obtained for each indicator is averaged and the country’s LPI score is calculated. In other words, all the indicators are considered to have equal effect on calculating the countries’ LPI scores. In this study, a model is proposed to develop the Logistics Performance Index, which is used as a tool to measure the international logistics performance of countries. With the proposed model, the logistic performance of OECD countries between the years 2010–2018 is analyzed and compared with the existing LPI rankings. Research Question 1 Do the indicators used in the LPI truly have equal importance? How can the importance (weight) of indicators be effectively measured in order to improve LPI? LPI is an accepted index used to compare the logistics performance of countries. While developing strategies, countries aim to raise the overall LPI scores and to rank higher in the index. For this reason, they develop strategies based on the scales obtained from six indicators in order to decide which one of the indicators should improve. Equally accepted indicator weights in the LPI constitute an obstacle for countries to create effective policies. The World Bank used the Basic Component Analysis for weighting the LPI indicators. Unlike their method, the fuzzy AHP method is used to determine the weighting scores of the six indicators of LPI. ARAS-G method is used for evaluating and ranking the performance of the alternatives. As with most decision problems, the effect of the criteria on the LPI should be measured accurately. Different from the WB, the weights of the six indicators used in LPI is not accepted as equal and they are weighted by a method based on expert opinion. There are many methods used to determine the criteria (indicator) in the literature. In this study, the AHP method, based on pairwise comparisons, was used for determining the weights of indicators. The AHP method has been used in many studies in the literature as an effective and accepted method; therefore, this method is used in this study. It is also preferable for AHP to allow decision-makers to make effective decisions based on bilateral comparisons. Notwithstanding, the AHP method was extended to fuzzy AHP by using fuzzy numbers in order to eliminate measurement errors due to use of 1–9 scale. This was among the criticisms brought to the AHP method. Linguistic variables were used to enable decision makers to make subjective evaluations more effective in case of uncertainty. Research Question 2 How can the time period be included in measurements to improve LPI? Are the results sufficient to represent all periods? LPI has been published every 2 years since 2010 using the six indicators. The latest one was published in 2018. Using only the latest data may be an obstacle to achieve realistic results. In order to have detailed information about the logistics performance of a country, LPI should be analyzed as a whole within the selected time period. This will determine the strengths and weaknesses of the country and follow its development over time resulting in a more efficient evaluation. In the literature, when the time dimension is included in the decision process, the periodic data (arithmetic, geometric) is taken into consideration and converted into a single data or the results obtained by repeating the analysis for each period are interpreted as a whole. Unlike the current approaches, this study converts the period data into a single data which is expressed by grey numbers. In the formation of grey numbers, the maximum value of the period data is used to create the upper limit of the grey number and the minimum value is used to create the lower limit. It can be interpreted that a country performs between the boundaries of the grey number. Grey numbers are used as a means to express situations where the knowledge level is not sufficient. A partial uncertainty arises when the period data (white information) is reduced to a single data (grey information). Grey numbers are preferred because this uncertainty is too small to be expressed by fuzzy numbers. In the study, five-term LPI scores of the countries are analyzed by Additive Ratio ASsessment (ARAS) method using grey numbers. The Additive Ratio Assessment (ARAS) method is presented by Turskis and Zavadskas as a new approach to the solution of MCDM Problems (Turskis and Zavadskas 2010). Different from the classical approach to decision making in the ARAS method, function values belonging to the alternatives are compared to the function value of an optimal alternative that is determined by the decision maker at the beginning of the process. It can also be integrated with fuzzy logic and grey theory (Yildirim 2015). The Grey Additive Assessment (ARAS-G) is the method that integrates the ARAS method with the grey theory. Although the ARAS method is new in the literature, it is used in many studies in different disciplines and fields. The ARAS method is preferred because it is adaptable to all kinds of decision making problems, it can be used with the AHP method to determine the criteria weight and it can be modeled with grey numbers. It is aimed to expand the use of ARAS-G method in this study. The study is organized in six parts. The next part of the study is the literature search. The literature is searched in the perspective of finding the research gap of this field. The studies are examined, and the results of the studies related with the LPI, MCDM and ARAS-G are widely given in the literature section. The structure of the methods used in this study is given in Sect. 3. In Sect. 4, the dataset and the application steps of the evaluation methods are given. The fourth section named “Results” contains the findings of the analysis and results of the Spearman ρ and Kendall’s Tau correlation methods that are used to investigate the relationships within the yearly rankings and the ranking calculated by ARAS-G. Results section of the study covers the general discussion of the proposed model and suggestions for future studies.",30
10.0,1.0,Eurasian Economic Review,16 April 2019,https://link.springer.com/article/10.1007/s40822-019-00129-x,Asymmetric effects of inequality on real output levels of the United States,March 2020,Adnen Ben Nasr,Mehmet Balcilar,Seyi Saint Akadiri,Unknown,Male,Unknown,Male,"The relationship between economic growth and income inequality has long been of importance in the field of economics. A substantial number of studies have asserted that income inequality has positive impacts on economic growth (see Benabou 2000; Deininger and Olinto 2000; Chen 2003; Nahum 2005; Voitchovsky 2005; Lopez 2006; Frank 2009; Shin 2012; Chan et al. 2014; Wahiba and El Weriemmi 2014; Henderson et al. 2015; Saari et al. 2015; Babu et al. 2016), while some have found the opposite (see Alesina and Rodrick 1994; Perotti 1996; Lui 1997; Deininger and Squire 1998; Mo 2000, 2009; Panizza 2002; Knowles 2005; Ostry et al. 2014; Wan et al. 2006; Sukiassyan 2007; Nissim 2007; Majumdar and Partridge 2009; Ogus Binatli 2012; Fang et al. 2015; Muinelo-Gallo and Roca-Sagalés 2013; Rubin and Segal 2015). The theoretical reasoning for negative and positive relationships between income inequality and economic growth is as per the following discussion. The negative relationship between income inequality and economic growth can be explained in terms of the theory of credit market imperfection. This theory, according to Galor and Zeira (1993), Piketty (1997) and Aghion et al. (1999) states that an inverse relationship exists between income inequality and economic growth as a result of the inadequate funds of low-income households available for investment. It is argued that low-income households have insufficient and limited access to investment funds, owing to the existence of imperfections in the credit market. This, in one way or another, makes it difficult for these households to invest their available resources. Thus, investments are feasible only for the few rich with a high incomes, and consequently, there is a decline in the marginal productivity of capital and lagging economic growth. In addition, Bertola (1993), Perotti (1993), Alesina and Rodrick (1994), Persson and Tabellini (1994), and Benabou (1996), using a more extensive political economy ideology, have argued that economic inequality would probably lead to distorted redistribution policies, a situation that could reduce labor incentives and retard economic growth. Even if veritable redistribution policies are not executed, persuasion to obstruct their establishment and successive political misrepresentation could impede economic growth, by squandering economic resources that would otherwise have been used to further enhance production activities in the economy. Similarly, Gupta (1990), Alesina and Perotti (1996), Benhabib and Rustichini (1996), in their socio-political instability views, are of the opinion that an increase in income inequality could raise the possibility of poor masses engaging in highly damaging activities such as rioting, revolution and crime and the likes while the resulting economic and/or political instability and skepticism in the whole economic system could lead to a decrease in investment stimuli, thereby impeding economic growth in the long run. On the positive relationship between income inequality and economic growth, it has been argued that income inequality could increase in the early stages of economic development (Mercan and Azer 2013). According to Galor and Tsiddon (1997a), this is only feasible when a native environmental externality is the dominant factor in human capital accumulation before the dominance of the general technological externality in the distribution of human capital (Hsing 2004; Hayakawa and Venieris 2018). In periods characterized by significant technological advancements, a reduction in the relative significance of initial conditions enhances inequality. At the same time, an accumulation of skilled and highly capable individuals in technologically advanced sectors could enhance economic growth (Galor and Tsiddon 1997b). Forbes (2000), on the other hand, argues that a positive relationship between income inequality and economic growth could be feasible in the short and medium-term. He posits that the relationship between income inequality and economic growth could possibly be negative in the long run and positively significant in the short run. This finding is in line with Li and Zou’s (1998) study, which used a fixed-effect model in a cross-country panel analysis. Despite the extensive existing literature on income inequality and economic growth, there remains considerable disagreement on the effect of income inequality on economic growth. Inferring from the above, it would be theoretically correct to assume that an increaseFootnote 1 in the level of income inequality will have a different effect on economic growth than a decrease in income inequality. Following the relationship between the variables, an increase in income inequality (a negative shock) indicates bad news, while a decrease in income inequality (a positive shock) signifies good news for the level of real output. For instance, a decrease in the level of income inequality, through a tax reduction would have a positive shock on economic growth. It was argued that progressive taxation with negative net tax rates for the low-income earner are meant to result in the lowest level of consumption and also to reduce income inequality among various groups. According to Biswas et al. (2017), taxation at various levels of the income distribution has heterogeneous effects on individuals and members of households’ motivation to work, invest, and consume. However, reducing income inequality, through poverty alleviation programs and schemes, between low- and median-income individuals and families stimulates small and medium business growth, the supply of female labor and consumption expenditure, and hence, results in economic growth. On the other hand, reducing income inequality between median and high-income families suppresses economic growth, through inhibiting the creation of jobs, the growth of small businesses and the supply of female labor. These asymmetric economic growth effects are associated with both demand- and supply-side factors, that is, changes in labor supply and small-scale business activity (Biswas et al. 2017). For example, overall US trends in income inequality were examined in the study of Piketty and Saez (2003, 2006), where they constructed several time-series measures of the percentage of the top US incomes for the period between 1913 and 1998. They found that income inequality in the US has shown a definite U-shaped (negative and positive) pattern. At the wake of this century, income inequality decreased considerably, especially during World War II and the Great Depression. As discussed earlier, an increase in the level of income inequality is conducive to adopting distortionary redistributive and economic growth retarding policies, which slow down the growth process (see Persson and Tabellini 1994; Alesina and Rodrick 1994; Benhabib and Rustichini 1996). In addition, due to financial market imperfections, an increase in the level of income inequality would overemphasize the negative impacts of credit constraints on small business growth and human capital accumulation, thus reducing economic growth (Galor and Zeira 1993; Galor and Moav 2004). Moreover, an increase in income inequality might increase economic growth. According to Guvenen et al. (2013), a rise in inequality creates the motivation to work harder, invest more, and assume risks in order to enjoy higher rates of returns. This can also stimulate gross savings and, thus, capital accumulation, since the few rich have a lower marginal propensity to consume (Biswas et al. 2017). Our empirical results show that increasing and decreasing income inequality do have asymmetric impacts on economic growth. Several authors have investigated the impact of income inequality on economic growth, and vice versa, using time-series econometric models. While some have employed panel-data-based approaches, others have focused solely on the United States, due to the availability of long-span time-series data. At the cross-country level, one could mention Forbes (2000), who investigated the hypothesis for a panel of 45 countries and concluded that both in the short and medium run, a rise in a country’s level of income inequality has a positive significant relationship with economic growth. This result is in line with the work of Li and Zou (1998), which concluded that income inequality is not harmful to economic growth. The opposite was the case with Alesina and Rodrick (1994), Persson and Tabellini (1994) and Banerjee and Duflo (2003), with the latter using non-parametric approaches. These studies revealed that the rate of economic growth is an inverted U-shaped function of the net variations in income inequality. According to them, variations in the level of income inequality, no matter the direction, are correlated with reducing economic growth. The non-linearity approaches employed in their studies made their empirical findings sufficient to highlight why previous studies on the existing relationship reported between income inequality and economic growth demonstrate a lack of consensus. Using time-series models to examine the relationship between the level of income inequality and economic growth for the United States, Ram (1991) concluded that there is an inverse relationship between income inequality and economic growth. This result was confirmed by Hsing and Smyth (1994) and Jacobsen and Giles (1998). Meanwhile, in a panel framework, the same modelling approach was employed by Frank (2009), who constructed annual indicators of income inequality over the period 1945–2004 for individual states in the US. Using a panel autoregressive distributed lag (ARDL) model, he concluded that in the long-run, income inequality has contributed positively to economic growth. A recent study by Bahmani-Oskooee and Motavallizadeh-Ardakani (2018) on the impact of growth on inequality, using a nonlinear autoregressive distributed lag (NARDL) model for each state in the US over the period of 1959–2013, found that economic growth has impacted positively on income inequality, but within 20 states. It was found that economic growth has an asymmetric impact on income inequality both in the short and long-run. These found that increases and decreases in real output levels have worsened income inequality. Based on this premise, our study sought to examine the presence of the short-run and long-run asymmetric effects of income inequality on real GDP per capita, i.e., the impact of an increase or decrease in income inequality on the real output levels in the US. This study used a larger sample size, over the period of 1917–2012 (96 years). The sample size appears to be large enough to cover different economic growth/development stages in the US; hence a reliable and robust time-series empirical outcome. Additionally, unlike previous studies that used only the Gini coefficient as a measure of income inequality in the US, our study employed six measures of income distribution, namely the Atkinson index, the Gini coefficient, a relative mean deviation (Rmeandev), Theil’s entropy index, and the Top 10% and Top 1% income shares, respectively. The choice of these income inequality indicators was supported by the importance of examining the reliability of the income inequality proposition using different inequality indicators. Using diverse indicators would allow a more meaningful empirical analysis of the pathogenic impacts of inequalities in various intervals of the income scale (see Wagstaff 2002; Weich et al. 2002). Third, unlike the studies of Bahmani-Oskooee and Motavallizadeh-Ardakani (2018) examined the impact of growth on inequality in the US, this study examines the opposite. We investigated the impact of inequality on the growth of output, and the effects of negative inequality and positive inequality shocks (increase and decrease of inequality) on the economic growth of the US. The major objective of this study was to examine the short- and long-run (increase and decrease) asymmetric effects of income inequality on real output levels over a long time span in the United States. In order to achieve the research objective, we employed a nonlinear ARDL model approach, developed recently by Shin et al. (2014a, b), which is an asymmetric extension of the linear ARDL cointegration model proposed by Pesaran et al. (2001), to capture the short- and long-run asymmetric behavior of the model. We found that the long-run coefficients of positive changes have positive signs while the signs of those of negative changes were negative, indicating that a decrease or an increase in income inequality improves the real output levels in the US. The remaining sections of this paper are as follows. Section two discusses, in detail, the data and methodology employed in the study. In section three, we report the empirical results and present a discussion on the findings, while the concluding remarks to be found in section four.",4
10.0,1.0,Eurasian Economic Review,05 April 2019,https://link.springer.com/article/10.1007/s40822-019-00128-y,Volatility transmission in the South African white maize futures market,March 2020,Ayesha Sayed,Christo Auret,,Female,Unknown,Unknown,Female,"The importance of grain price volatility is embedded in its intertwined relationship with food security. The last decade has witnessed unprecedented price spikes in agricultural commodities, paired with extreme weather and waning stocks, all contributing to historic levels of food price volatility. According to Wright (2011) grains like maize (also referred to as corn) are a crucial source of the world’s food energy consumption. Despite maize being commonly consumed as second-cycle produce through its use as livestock feed; it is also the main staple food for inhabitants in Africa and South America and boasts a global production higher than that of rice and wheat. The latest report by CIMMYTFootnote 1 (2018) designates maize as the number one food crop is sub-Saharan Africa, as well as the preferred staple food for 900 million people worldwide who live on less than $2 a day. According to contagion theory, information shocks in one market often spillover onto the price and volatility of other markets (King and Wadhwani 1990). While volatility in agricultural futures is often found to be time-varying and seasonal, it is equally as important to assess volatility transmissions to and from other futures markets. Research into the US agricultural futures markets have found maize (what they refer to as corn) to be the commodity that most broadly received and transmitted volatility transmissions (Grieb 2015). The presence of volatility transmission implies that an unexpected shock in a market increases volatility both in its own market and across other markets (Kalu 2014). Grain price volatility became significant in South Africa following the deregulation of agricultural markets in 1997, which ended grain boards seasonally fixing prices (Monk et al. 2010). Several other significant structural changes have taken place in the South African futures market over the last two decades. These developments have transformed the country’s grain futures market into a more volatile and faster trading environment, with heightened volatility expected to continue. Maize continues to gain traction globally as a leading grain crop given its importance to both food security and the renewable energy sector. In South Africa, maize is the largest locally produced field crop, with an average production of 10–12 million tons per annum. Maize is also the staple food of the South African population with maize for human consumption exceeding 4 million tons on average annually. South Africa is not only the main emerging market for price discovery of maize in Africa, but also leads the continent in technology adoption. According to The Maize Trust (2013), South Africa became the first African country in 1998 to grow biotech crops commercially, and by 2010 was the world’s ninth largest cultivator of biotech crops, with 2.2 million hectares under cultivation. The importance of volatility transmission in the South African with white maize futures market as a research topic is further reiterated by the sheer size of the market. Maize futures contracts are the largest and most liquid contract traded on the South African Futures Exchange (SAFEX), with an average daily trading volume of 200,000 tons (Adelegan, 2009). The volume of maize futures contracted traded on SAFEX over the last 20 years was 16,143,074 for white maize futures and 6,295,601 for yellow maize futures.Footnote 2 The importance of investigating volatility transmission also has implications in the regulation of futures exchanges. The dynamic analysis of volatility across futures markets has important policy implications as any imposed regulatory initiative will be unsuccessful if markets are interrelated (Hernandez et al. (2014). Sayed and Auret (2018) empirically investigated the effectiveness of price limits in the South African white maize future market over the period March 2010–December 2017.Footnote 3 The authors found them to be ineffective and even contributing to excess volatility instead of constraining it. The presence of volatility transmissions and spillover effects between futures markets could help explain why price limits have been ineffective in controlling volatility in the South African white maize futures market. Beckmann and Czudaj (2014) point out that examining spillover effects is important in identifying causality patterns as well as in examining the co-movements of futures, a crucial issue for both investors and policymakers. Evidence of cross-commodity and external market spillovers therefore also has implications for investors and commercial traders. Investors are concerned with portfolio allocations while commercial traders are concerned with effective hedging strategies. Commercial traders should remain the main benefactors of efficiently functioning futures markets as hedging prevents the cost of risk-taking from filtering down to the price consumers pay for food. This paper analyzes South African futures markets from a new perspective as all previous studies either used a univariate approach or merely examined the link between spot and futures markets. The proposed methodology in this paper contributes to the literature by investigating volatility transmission by using a multivariate generalized autoregressive heteroskedasticity (GARCH) model. This multivariate approach will examine how the returns distributions in the South African white maize futures market is influenced by information shocks in the other futures markets. To this end, the Dynamic Conditional Correlation (DCC) model of Engle (2002) is used to examine the degree of interdependence between markets and if this has changed over time. This paper uses daily data to investigate volatility spillover effects between grain futures (white maize, yellow maize, wheat and sunflower seed) over the period 1999–2018; and between white maize futures against currency futures (Dollar/Rand and Euro/Rand), equity futures (JSE Top 40 Index) and interest rate futures (JIBA) over the period 2008–2018. The results confirm that there are strong interactions among futures markets listed on SAFEX and that the level of interdependence and correlations between these markets are varying over time. The paper is organized as follows. The next section presents a brief literature review, while the section that follows looks at the data and methodology used. The section thereafter summarizes the results and then a conclusion is presented.",11
10.0,1.0,Eurasian Economic Review,31 July 2019,https://link.springer.com/article/10.1007/s40822-019-00134-0,Consumer behavior in a monetary economy and smoothing of composite consumption,March 2020,Hiroaki Hayakawa,,,Male,Unknown,Unknown,Male,"Since Modigliani and Brumberg (1954) and Friedman (1957) introduced the hypothesis of life cycle planning or permanent income, their ideas have kept inspiring many generations of researchers (Modigliani 1975; Sargent 1987; Deaton 2005; Baranzini 2005). In more recent years, the permanent income hypothesis (particularly, the presence of liquidity constraints and the excess sensitivity) has been tested on various sets of data and by employing different statistical methods (e.g., Hall 1978; Flavin 1981, 1985; Runkle 1991; Deaton 1992; Attanasio 1995; Hayashi 1996, 1997; Seater 1998; Serlenga 2001; DeJuan and Seater 2006; Dejuan et al. 2006; Omgba and Djiofack 2010; Gomes 2011; Beznoska and Ochmann 2012; Ni and Seol 2014; Alimi 2015; Kelikume et al. 2017; Tekin 2018; Noor et al. 2018). The conclusions from this research are mixed, but we do now have a broad contextual understanding of the validity of the hypothesis, if not universal. We note, in particular, that the testing of the stochastic process of consumption has been mostly focused on consumption and real income changes (and on the constant rate of time preference), and that the fact that consumer choice decisions are actually made in a monetary economy and that such decisions differ from the case of a real economy has not been given enough attention. This makes it difficult to assess how rational decisions underlying the hypothesis are made when monetary variables such as nominal interest rates and real balances (or, more generally, the services of real balances) are taken into account in consumers’ utility calculus under more general recursive preferences that allow the rate of time preference to vary endogenously. This paper, therefore, takes another close look at consumer choice as an optimization problem in a monetary economy and analyzes how this behavior differs from its real economy counterpart. By so doing, we hope to elicit the conditions required for consumption smoothing in the context of a monetary economy as well as to identify such additional variables that are needed to describe consumer behavior in this context, supplementing, thereby, our understanding of consumer choice in a more expanded framework. The consumption–wealth relation we derive, in particular, will provide a conceptual scheme by which to understand consumption in its relation to wealth comprised of many components including financial and housing wealth, although our analysis is carried out in a more restricted context.Footnote 1 More precisely, we know that, under recursive preferences \(\grave{a}\)la Koopmans (1960), the consumption of infinitely-lived agents in a one-sector real economy is a variable proportion of wealth, with this proportion being determined by the current and future values of the real interest rate and the current and future values of planned consumption (Hayakawa and Ishizawa 1994). This factor is determined only by the former values if preferences are homothetic. Furthermore, in the long-run, when the real interest rate equals the rate of time preference, consumption is equalized across time and settles at the level of permanent income defined as the real interest return on wealth. The question is whether these properties carry over to a monetary economy in which consumers value various services of real balances, e.g., as a medium of exchange \(\grave{a}\)la Baumol (1952) and Tobin (1956), as a form of insurance against unexpected events or stochastic payment processes \(\grave{a}\)la Patinkin (1956), or as a social contrivance to store value in order to carry saving into the future \(\grave{a}\)la Samuelson (1958) and Lucas (1972), or as a cash-in-advance or financing constraint \(\grave{a}\)la Clower (1967), so that their preferences are defined on the space of twin paths of consumption and real balances. If consumers, benefiting from transacting in a monetary economy, demand real balances at the cost of holding them, the path of consumption must be determined jointly with the path of real balances. Moreover, it is equally meaningful to ask what it is that consumers try to equalize across time in their intertemporal optimization, consumption alone or composite consumption (i.e., the combined total of consumption and transactions services of real balances), when proper conditions for such smoothing actualize. To address these issues, this paper considers infinitely lived agents who hold recursive preferences expressed in a functional form that allows the rate of time preference to change endogenously. In this functional form, both consumption and real balances enter the instantaneous utility and discounting functions. Since money in the utility function can be viewed functionally equivalent to those various services of real balances mentioned above, money in the utility function is not unduly restrictive (Clower 1967; Brock 1974; Feenstra 1986; Hayakawa 1994),Footnote 2 although this treatment of money, dating back to Walras (1874–1877) and elaborated by Hicks (1935) and Patinkin (1956), is still controversial. Also, the endogenously varying time preference rate adds to the breadth of the transmission mechanisms through which money may affect agents’ decisions on how much to consume and how much to hold of real balances. It also bears on the question of the superneutrality of money that has been debated since the 1960s (Mundell 1963; Tobin 1965; Sidrauski 1967a, b; Deev and Hodula 2016; Wang 2011; Reis 2007; Longaretti and Delli Gatti 2004; Rapach 2003; Ascari 1998) and, by extension, on the issue of the optimum quantity of money (Friedman 1969).Footnote 3 A word of caution is in order at the outset. In this paper, we obtain the consumption–wealth relation under the assumption of perfect foresight with respect to all price variables. While this relation remains to hold even if the intertemporal substitution of leisure is allowed, if the assumption of perfect foresight is violated, consumers will prepare for risks and uncertainty through precautionary saving. While a full analysis of the presence of risks in the context of intertemporal choice requires a specification of stochastic processes of the price variables involved (interest rates, inflation rates, and wage rates), one way to address the issue as a first hand is by allowing the assessment of wealth to be adjusted by risk factors. The expected human wealth, for instance, may be obtained by considering the mean values of expected wages at each point in time (through rational expectations), but the obtained wealth could well be discounted by risks involved in expectations, so that consumers might conceivably allocate this risk-adjusted wealth to consumption; that is, the higher the risks, the lower the risk-adjusted human wealth, hence lower the consumption. Alternatively, expected wages into the future may be adjusted by their risks, which implies that the intertemporal substitution of leisure will not be as complete as in the case of perfect foresight. Either way, the derived value of the adjusted human wealth will be low under highly risky situations. How consumers respond to the presence of risks is a matter of great importance, and we remain open to this question. The paper is organized as follows: Sect. 2 defines the framework of our analysis, states the consumer optimization problem, and derives the Keynes–Ramsey rules of consumption of real balances, from which a consumption–wealth relation is obtained by integration. Section 3 defines the neutrality of money, identifying the conditions under which money remains neutral to consumer decisions despite the fact it yields utility. Section 4 examines the relationship between the homotheticity of preferences and the property of consumption and real balances as related to wealth, showing that this property is equivalent to certain restrictions on the form of the instantaneous discounting and utility functions. Section 5 examines the proportionality of consumption to wealth apart from homothetic preferences. Section 6 discusses composite consumption, identifying the conditions under which such consumption is equalized across time. Section 7 concludes with a summary of our results, policy implications, and extensions.",
10.0,1.0,Eurasian Economic Review,26 August 2019,https://link.springer.com/article/10.1007/s40822-019-00138-w,Non-organized boycott: alliance advantage and free riding incentives in uneven wars of attrition,March 2020,Yi Zheng,,,,Unknown,Unknown,Mix,,
10.0,1.0,Eurasian Economic Review,09 September 2019,https://link.springer.com/article/10.1007/s40822-019-00139-9,Are labor unions important for business cycle fluctuations? Lessons from Bulgaria,March 2020,Aleksandar Vasilev,,,Male,Unknown,Unknown,Male,"The standard real-business-cycle (RBC) model, featuring a perfectly-competitive labor market, e.g. Kydland and Prescott (1982) and Long and Plosser (1983), was shown to be unable to capture the dynamics in the labor markets in the US. For Bulgaria, Vasilev (2009) documented a similar failure for the model to match the observed wage- and employment fluctuations. As a general rule, most of those earlier studies in the literature have tried to explained the mismatch with a modeling choice based on perfect information and market-clearing, and thus involuntary unemployment is absent from the framework. Bulgaria, however, along with many other Eastern European countries, registers a significant amount of involuntary unemployment, which was due to the process of structural transformation in the economy. In other words, being out of job in such an environment is clearly not an optimal choice, as it represents a waste of non-storable labor resources. Modeling correctly unemployment as an inefficient outcome requires researchers to depart from the Walrasian (market-clearing) view of labor markets. In other words, involuntary unemployment can only appear in a model setup where certain labor market imperfections that are present in the economy are also modeled. One typical example of labor market frictions is the prevalence of collective bargaining arrangements between labor unions and firms in the economy. Figure 1 below documents their quantitative importance in Bulgaria. Source: European Trade Union Institute (2018) Union density and coverage rates in Bulgaria. The results above suggest that those arrangements need to be taken seriously when modeling labor markets in Bulgaria. In particular, despite the fall in the overall unionization rate, measured by “union density”, over the period covered, and the decentralization of collective bargaining to individual firm’s level, such collective agreements are still important on the aggregate level—after all, over a third of employed workers in Bulgaria are covered by some form of collective agreement. Moreover, given that such agreements usually take place in the largest firms (and in the public sector), the remaining firms generally follow closely those agreements in the non-unionized sectors as well. For example, Paskaleva (2016) demonstrates that the fact that real wages in Bulgaria are downward rigid is exactly due to the collective agreements in place, which prohibit cuts in base wages, and only allow for temporary wage freezes.Footnote 1 In addition, such legal restrictions in place mean that adjusting labor costs needs to happen mostly through employment reductions.Footnote 2 Therefore, real rigidities in the labor market along those lines could potentially generate a qualitatively important propagation mechanism in the model, which, in addition to making the setup more realistic, can help the artificial economy match observed business cycle fluctuations better, especially along the labor market dimension. We take the empirical findings presented in Fig. 1 above as an empirical regularity, which in turn motivates our modeling approach. In this paper, we take the presence of unions in the setup as an important ingredient in the theoretical framework. We then adapt the standard Dynamic Stochastic General Equilibrium (DSGE) model by augmenting it with a plausible mechanism of collective wage bargaining procedure. This modeling approach deviates from spot wage contracting, and instead emphasize institutional labor arrangement. Furthermore, the alternative mechanism of wage contracting considered here is also based on non-Walrasian settings, which are promising area of research, as pointed above, and in Blanchard and Fischer (1989). We follow Maffezzoli (2001), and introduce monopoly labor unions in the general-equilibrium setup, in order to study their quantitative implications for business cycle fluctuations in Bulgaria.Footnote 3 In contrast to Vasilev (2015c), who introduces a union in the government sector only, here the union is to be interpreted as a private-sector union, as we do not model public employment explicitly.Footnote 4 Another novelty relative to the setup in Maffezzoli (2001) is that we make the reservation wage in the monopoly-union objective function conditional on the total factor productivity, which, aside from making the model more realistic, further helps to improve the model’s performance vis-a-vis data. In addition, we also discuss the business cycle properties of real wages and employment, their auto-correlations, and the dynamic correlation between employment and the wage rate, which is missing from Maffezzoli (2001). We then proceed to calibrate the model to Bulgarian data after the introduction of the currency board arrangement, which was a period of aggregate stability, and study the impulse responses of aggregate variables in the face of exogenous technological shocks. We compare and contrast the monopoly-union model against a framework without unions, and more specifically to the Rogerson and Wright (1988) setup with indivisible labor and inseparable utility in consumption and leisure. The latter was chosen, as it was shown in King and Rebelo (2000) to dominate the standard model with divisible hours, while retaining the perfectly-competitive labor markets assumption. Also, the indivisible labor model is more realistic, when compared to the setup with divisible labor, Vasilev (2009), as in Bulgaria most of the people work full-time, so the variability in hours happens mostly along the extensive margin, i.e., employment, and not that much along the intensive margin, or hours per worker. Overall, the calibrated model with collective bargaining mechanism between the union and the firm provides a tractable general-equilibrium setup, which performs well vis-a-vis data when it comes to relative volatilities of time series, auto- and cross-correlation functions, and in addition dominates both the market-clearing labor market specification with indivisible labor as in Rogerson and Wright (1988). More specifically, the presence of the monopoly union causes labor productivity in the model to lead employment over the business cycle, which is what we observe in the data as well. The very low dynamic correlation between wages and employment in Bulgaria is well-approximated in the model, mostly due to the fact that the wage rate is generated as an outcome of a sequential bargaining procedure. The model with unions also generates persistence in output and both employment and unemployment, and is able to respond to the criticism in Nelson and Plosser (1982), Cogley and Nason (1995), Rotemberg and Woodford (1996), and Hall (1999) who all argue that RBC models generally do not have a strong internal propagation mechanism (besides the strong persistence in the TFP process, that is). The rest of the paper is organized as follows: Sect. 2 describes the model setup and characterizes the decentralized competitive equilibrium system, Sect. 3 discusses the calibration procedure, and Sect. 4 presents the steady-state model solution. Section 5 proceeds with the out-of-steady-state dynamics of all model variables, and compares the simulated second moments of theoretical variables against their empirical counterparts. Section 6 concludes the paper.",4
10.0,2.0,Eurasian Economic Review,08 August 2019,https://link.springer.com/article/10.1007/s40822-019-00137-x,Asymmetric J-curve in the commodity trade between Pakistan and United States: evidence from 41 industries,June 2020,Mohsen Bahmani-Oskooee,Ahmed Usman,Sana Ullah,Male,Male,Female,Mix,,
10.0,2.0,Eurasian Economic Review,29 July 2019,https://link.springer.com/article/10.1007/s40822-019-00133-1,Does the digital gap matter? Estimating the impact of ICT on productivity in developing countries,June 2020,Ronia Hawash,Guenter Lang,,Unknown,Unknown,Unknown,Unknown,,
10.0,2.0,Eurasian Economic Review,12 February 2020,https://link.springer.com/article/10.1007/s40822-020-00147-0,Economic diversification and human development in Europe,June 2020,Muhammad Ali,Uwe Cantner,,Male,Male,Unknown,Male,"Economics, from a welfare perspective, is the study of actions taken by economic agents to maximize their social welfare.Footnote 1 The roots of this definition go back to Marshall (1898, p. 1): ‘Political Economy or Economics is a study of mankind in the ordinary business of life; it examines that part of individual and social action which is most closely connected with the attainment and with the use of the material requisites of well-being’. In other words, economics relates the decisions and activities of economic agents to the overall welfare of the society. The ultimate goal of economics, therefore, should be the improvement of social welfare. Although the broad economic policy aims to identify and facilitate the determinants of economic growth, most of the conventional determinants of sustainable economic growth are production oriented. The implicit assumption behind the emphasis on production-related determinants of growth is that growth automatically implies social welfare gains (Hartmann and Pyka 2013). Innovation, for example, is considered an important driver of growth; however, the welfare implications of innovation are not straightforward. Although innovation is an essential component of human development, the negative features of innovation—in the form of the concentration of market power in a few hands, obsolescence of existing skill sets, and inequality—should not be overlooked (Myrdal 1957). Recent research in evolutionary economics explains the process of creative destruction through the lens of dynamic economic change; seen though this lens, economic diversification is an important determinant of economic change (Frenken and Boschma 2007; Hanusch and Pyka 2007; Saviotti and Pyka 2004). The connection between economic diversification and creative destruction is straightforward if creation outweighs destruction; i.e. if some pre-existing sectors survive alongside new ones, overall diversification will increase (Saviotti and Frenken 2008). Diversification increases the choices available to economic agents, and the ability to choose from many alternatives not only spurs economic development, but also increases well-being by satisfying the preference for variety (Clark 2005). If new opportunities do not replace existing ones, then overall employment levels are expected to increase. However, if new opportunities replace the existing ones, even in part, obsolescence of existing skills and unemployment will occur, at least in the short run. Increasing variety can have positive or negative effects on the economy, depending on the levels of existing variety. If a country already has a highly diversified product portfolio, further increases in diversification may not have positive effects because not all people can develop new capabilities quickly with changes in economic structure and may become unemployable. Moreover, in terms of consumption choices, more choices are not always better. Too many choices can lead to decision paralysis and excessive expectations. Therefore, the complex relationship between diversification and well-being necessitates detailed study. Ali and Memon (2019) studied the relationship between diversification and human development in South Asia and found that all three types of variety (related, unrelated and overall) have a positive and significant relationship with human development in South Asia. They also found that the existing level of human capital significantly moderates the relationship between related variety and social welfare. To the best of our knowledge, there have been no empirical studies on the impact of diversification on human development in Europe. One possible exception is Mohler and Seitz (2012), who studied the above-mentioned relationship using elasticity of substitution between consumption alternatives available to consumers to derive the implicit effects on well-being. Therefore, the present study contributes to the literature by empirically analyzing the impact of diversification on human development in Europe. We distinguish between overall (OV), related (RV), and unrelated (UV) diversification. We also distinguish between a full sample of 20 European countries and a subsample of the transition economies of Central-Eastern European countries, between all sectors and just the manufacturing sector, and between 1- and 5-year lags. Our results show evidence for positive welfare effects of economic diversification in Central and Eastern European Countries (CEECs), suggesting that diversification is especially important for social welfare in transition economies. Our results hold for all three types of diversification indices and are robust to the choice of industries and lag specifications. For the full sample, variety only affects human development after a significant lag. More specifically, in the long run, OV improves social welfare while RV reduces it. Our results also show negative productivity effects of OV and UV, while RV appears to enhance productivity in both the long and short run. The structure of the paper is as follows: Sect. 2 highlights the relationship between growth and human development; Sect. 3 establishes a conceptual link between diversification, growth, and human development; Sect. 4 outlines the model specifications; Sect. 5 introduces data and methodology; Sect. 6 presents results; and Sect. 7 offers conclusions, limitations, and ideas for further research.",9
10.0,2.0,Eurasian Economic Review,13 August 2019,https://link.springer.com/article/10.1007/s40822-019-00135-z,Tax reform and fiscal space in developing countries,June 2020,Sèna Kimm Gnangnon,Jean-François Brun,,Unknown,Unknown,Unknown,Unknown,,
10.0,2.0,Eurasian Economic Review,12 November 2018,https://link.springer.com/article/10.1007/s40822-018-0124-2,"Initial public offering price support, valuation, and returns",June 2020,Lokman Tutuncu,,,Male,Unknown,Unknown,Male,"This study investigates the impact of price support on share prices in the short- and medium-term, and the association between valuation of initial public offerings (IPO) and aftermarket price stabilization. The motivation for the study stems from the increasing availability of price support and valuation data as well as lack of extensive studies on price stabilization in the Turkish market. I take advantage of the mandatory disclosure requirements for going public firms and utilize pre-issue prospectuses and valuation reports in addition to post-issue material event files to collect data. In a manner similar to Hanley et al. (1993), I investigate stabilizing bids by underwriters since they are directly observable from post-issue reports, the type of activity called pure stabilization by Aggarwal (2000). Understanding the effect of price stabilization is important in the sense that artificially propping up the price has implications for underwriters as well as primary and secondary investors (Wilhelm 1999; Aggarwal 2000; Ellis et al. 2000; Fjesme 2016, 2018). Many studies fit price support activities into an underpricing narrative, where information asymmetries between potential investors and issuers lead underwriters to underprice the offering, signalling firm quality (Allen and Faulhaber 1989) and rewarding informed investors, allowing them to obtain positive initial returns. Chowdhry and Nanda (1996) envision price support as a means to compensate uninformed investors and argue that informed investors do not invest if the true value does not exceed the offer price. In contrast, Benveniste et al. (1996) argue that price stabilization rewards the informed investor and it is only meaningful if the offer value exceeds the true value of the firm. In this market design, price stabilization and underpricing act as substitutes, and observed underpricing would be less when issuer is committed to price support. I argue that price stabilization activities are associated with the preceding IPO valuation. To my knowledge, the relationship between IPO valuation and price support has not been formally tested before; however, one theoretical explanation is offered by Hao (2007). The explanation posits that underwriters may choose to select higher offer prices if laddering is practiced in the secondary market. Since stabilization and laddering are expected to have the same effect on secondary trading (Fjesme 2016), I am able to extend Hao’s theoretical framework to examine the relationship between valuation and price stabilization. Recent studies provide more details of the valuation process, documenting the techniques used by underwriters to value IPOs and showing that underwriters have optimistic valuation bias (Roosenboom 2012; Paleari et al. 2014; Bonaventura and Giudici 2017). In Turkey, the regulatory authority, the Capital Markets Board (SPK) Issue Directive 128.VII.1 stipulates publication of valuation reports at least three days prior to going public. At the same time, issuing firms disclose their intention to use price support in their prospectus. In several cases, the valuation procedure is also explained in the very prospectus where intention of the going public firm is stated. Thus, I infer that issuing firms are likely to be aware of the details of valuation when they declare their intention to implement price support. If price support acts as an efficient substitute to underpricing (Benveniste et al. 1996), underwriters can overvalue the offering with a commitment to price stabilization. In this setting, the requirement for price support would increase in proportion to the degree of overpricing the issue and the two would be positively associated. The sample comprises 114 firms that went public between January 2010 and December 2017 in Turkey. In the study, I am able to cover the population of IPOs between 2010 and 2017, of which I document implementation of price support for 27 IPOs, approximately a quarter of the firms that went public. I utilize detailed data obtained from the Public Disclosure Platform (KAP) to document the length, first and last days of support period. In Turkey, SPK regulates the market conduct and its Issue Directive 128.VII.1 declares permission of stabilizing activities if the share price falls below the offering price, provided that a detailed report is filed to the authority following the cessation of price support, which may be sustained for a maximum of 30 days after going public. These reports are then made available to the investors and general public via KAP. I find that support IPOs are overvalued and over-discounted by underwriters relative to non-support IPOs. The median valuation bias for support IPOs is 36.09% while the bias is 23.7% for non-support IPOs, and the 12.39% difference is statistically significant. The median deliberate discount is 9% larger for support IPOs; however, this does not translate into positive initial returns for investors. The median underpricing for support IPOs is 0%, while non-support IPOs provide a 3.4% median initial return. In the short-term, support IPO returns measured by 30-day and 60-day CAR are negative and significantly lower than non-support IPO returns. In the medium-term, differences between subsamples disappear. In the probit regressions I find that the likelihood of implementing price support increases with the degree of valuation bias and underwriter optimism, while it decreases with the degree of underpricing. The price support itself is negatively associated with short-term returns, after controlling for selection bias related to simultaneously deciding on the issue value and implementing price support. One standard deviation increase in price support is associated with a 25.8% reduction before, and a 19.4% reduction in 1-month CAR after controlling for selection bias. The contributions of the study are mainly twofold. First, it contributes to the IPO literature by showing the relationship between IPO valuation and price support. To my knowledge, this is the first study to directly investigate the relationship between valuation and price support. Second, this is the first study to document price support activities in Turkish IPOs. The study has implications for investors and regulators as well as other market players engaged in IPOs. The rest of the study is organized as follows. The next section provides an overview of the literature and develops hypotheses. Section 3 describes the data and descriptive statistics. Section 4 presents empirical tests and Sect. 5 concludes.",4
10.0,2.0,Eurasian Economic Review,05 January 2019,https://link.springer.com/article/10.1007/s40822-018-00125-7,Collusive corruption in public services: evidence from Chinese state corruption audits,June 2020,Anthony Liu,,,Male,Unknown,Unknown,Male,"Corruption is severely disruptive to socio-economic progress in emerging Asian markets. Most Asian economies are now on their path to social and economic transitions, reforms, and even revolution, targeting rapid growth. Corruption almost unavoidably accompanies socio-economic changes in emerging markets because institutional reforming pace lags behind. Even though China has impressed the world with her economic growth over the past 4 decades, extensive corruption threatens the basis of the national economy and socio-political stability (Pei 2007). The bureaucrat-business collusive corruption between governmental bureaucrats and business people is the most disruptive type of corruption, because of its serious effect on public trust in governments charged with national governance (Neu et al. 2013). This type of bureaucratic corruption is found when officials, conspiring with bribes, bend or break the rules and regulations (Sukhtankar and Vaishnav 2015). China’s open-door policy and socio-economic reforms have liberated national productivity and increased financial impetus and entrepreneurship. A strong nationwide greed for economic wealth and quick money, however, encouraged by the introduction of free markets, has changed the socialist mindset of national governance. As a result of the socio-economic changes in China, some former ‘public servants’, once governmental bureaucrats, have become rent seekers attempting to profit from private interests. Bureaucrat-business collusive corruption has become a tumor in the nation’s socio-economic development. Unfortunately, China is not the only country whose economic development and social stability are threatened by collusive corruption. Levine (1981, p 156) explained that collusive corruption exists in all human societies, like ‘the weather, which most people have little faith that anything can be done about.’ Leff (1964) suggests that collusive corruption ‘greases the wheels’ of the economy by providing incentives for bureaucrats to work harder, and also by allowing firms and individuals to get around costly and inefficient red-tape and regulations. Most existing research papers define corruption as the misuse of public resources and power for private gain (Shleifer 1997) or the breaking of rules by public officials for private gain (Banerjee 1997). Neu et al. (2013) describe collusive corruption as a legally-condoned way for politicians or bureaucrats to use their influence for their own benefit. From the perspective of government audits, collusive corruption involves those governmental bureaucrats who improperly and unlawfully enrich themselves and the people close to them by misusing their positions in public and private sectors (Kayrak 2008). Aware of the widely-observed fact that collusive corruption is the worst and most disruptive type of corruption in transitory emerging economies (Shleifer 1997; Banerjee 1997; Neu et al. 2013), this study raises two bureaucrat-business collusion-oriented research questions. What features of corruption are most likely to be associated with bureaucrat-business collusion in emerging markets? This involves the scope of the embezzlement, political status of the corrupt perpetrator, crime as either a group or an individual, and the types of public services provided. Do institutional frameworks moderate these features and the effects of corruption? This study conjectures that institutional factors may enhance or weaken the associations between the features of corruption and bureaucrat-business collusion. The empirical investigation in this study is based on 334 reported corruption audits manually collected from the online official public resources of the Chinese National Audit Office (hereafter referred to as CNAO). Logistic regression tests are run to test the main effects under investigation and the moderating role of two institutional factors. This study aims to make three contributions to the existing literature in the anti-corruption and auditing studies. First, it sheds light on the collusive nature of bureaucratic corruption crimes. Second, it introduces institutional factors to the investigation of bureaucrat-business collusive corruption. Thirdly, it links anti-corruption efforts and state audits, and thus leads to a better understanding of how the state’s anti-corruption audits function. The remainder of this study is structured as follows. Section 2 describes the state corruption audits in China. Section 3 includes a literature review and development of the research hypotheses. Section 4 introduces the research methodology of this study. Section 5 reports the empirical results and analyses. Conclusions, limitations and implications are presented in the Sect. 6.",2
10.0,2.0,Eurasian Economic Review,25 January 2019,https://link.springer.com/article/10.1007/s40822-019-00126-0,Local government efficiency: is there anything new after Troika’s intervention in Portugal?,June 2020,Maria Basílio,Clara Pires,José Pires dos Reis,Female,Female,Male,Mix,,
10.0,2.0,Eurasian Economic Review,17 June 2019,https://link.springer.com/article/10.1007/s40822-019-00130-4,The comparison of empirical methods for modeling credit ratings of industrial companies from BRICS countries,June 2020,Alexander M. Karminsky,Sergei Grishunin,Maxim Bisenov,Male,Male,Male,Male,"Higher than average economic growth, strengthening macroeconomic environment in BRICS countries, coupled with increased investor interest, have led to an accelerated trend in growing investments in debt issued by industrial companies (ICs) from these countries. Simultaneously, these assets are the source of the credit risk of significant magnitude. The latter is explained by the various inefficiencies and structural problems in BRICS economies and capital markets (Staples et al. 2013). To minimize credit losses, the debtholders of BRICS ICs badly need reliable tools to assess and forecast the creditworthiness of these assets. One of the tools that fit the above-mentioned purposes is the public credit ratings (PCRs) assigned by “big-3” international credit rating agencies (ICRAs): Moody’s, Standard and Poor’s (S&P) or Fitch Ratings (Fitch). These ratings determine the grades to which the debt instruments belong, based on their probability of default (Karminsky and Polozov 2016). The PCRs, assigned by ICRAs, proved their ability to effectively discriminate between defaulters and non-defaulters (including ICs from BRICS) while reflecting more permanent changes in credit risks (Karminsky and Polozov 2016). However, the large number of ICs’ debt in BRICS remained uncovered with CRs from ICRAs. This is underpinned by (1) the significant direct and indirect cost of the rating process for the issuers; and/or (2) the restrictions on the operations of international CRAs in some BRICS countries such as Russia. In absence of PCRs, the debtholders, to assess creditworthiness of the asset, must construct internal credit ratings (ICRs) replicating the missed PCRs. The ICRs are easy to use, low cost and require limited involvement of experts. Having a stable methodology from reputable CRA as a base for the modeling also helps to quick replication of the model. The well-proven method of modeling of reliable ICRs is the reproduction of missed PCRs with various econometric models from publicly available information (issuers’ financial statements, macroeconomic and industry data, etc.) (Karminsky and Peresetsky 2007; Karminsky and Khromova 2016). In these settings, ICRs constitute the forecast of a relative creditworthiness of the debt instrument in the next 12–24 month expressed by the symbol system. The debtholders, knowing the ICR level, can infer the probability of default of the asset from the statistics published by ICRAs (see “Appendix”). However, our research shows that the debtholders of ICs from BRICS face the following problem: what econometric models to apply to ensure that ICRs accurately reflect the creditworthiness of the assets as if they were assessed with the PCRs? The goals of this paper, though, are (1) to compare the ability of various statistical methods to replicate Moody’s PCRs for debt issued by BRICS-based ICs and (2) to select the statistical methods, which produces ICRs with the highest predictive power. The relevance of the paper is determined by (1) the solution of one of the critical problems of ICR modeling and (2) the narrow research in this area (see discussion below). The novelty of the paper is the application and comparison of wide range of statistical models for ICR forecasting while the peers applied only narrow set of models (mainly OLR or OPR). It is also driven by (1) the selection of explanatory variables in the models that provide the best match to the credit factors listed in Moody’s rating methodologies; (2) the study of diversified sample of ICs from all BRICS countries (218 ICs from 12 industries); and (3) the application of the most actual data (for the period from 2006 to 2016) to control for the data stationarity. The rest of the paper is structured as follows. Section 2 represents the literature review in field of ICR modeling. Section 3 explores the data, the set of explanatory variables and the methods of modeling. Finally, in Sect. 4, the accuracy of each method of reproducing Moody’s PCRs is discussed and conclusions are formulated.",4
10.0,3.0,Eurasian Economic Review,29 July 2020,https://link.springer.com/article/10.1007/s40822-020-00154-1,The relationship between cryptocurrencies and COVID-19 pandemic,September 2020,Ender Demir,Mehmet Huseyin Bilgin,Asli Cansin Doker,Male,Male,Unknown,Male,"Coronavirus (COVID-19) outbreak, which began in Wuhan, China, has rapidly spread all over the world infecting millions of people and causing thousands of deaths. World Health Organization declared this outbreak a global pandemic. The governments are implementing several restrictions such as travel bans, school closures, and curfews, and the lives of billions are affected. The interest of the financial researchers on the impacts of COVID-19 on financial markets is rapidly rising. Onali (2020) explores the effect of COVID-19 cases and deaths on Dow Jones and S&P500 indexes. He finds that the number of infections and deaths in Italy, Spain, the UK, Iran, and France does not affect the stock market returns except for the number of reported cases in China. Al-Awadhi et al. (2020) focus on the Chinese stock market and document that both the daily growth in reported cases and the increasing number of deaths caused by COVID-19 lead to a decrease in stock returns. Zhang et al. (2020) show that the uncertainty raised by COVID-19 makes stock markets more volatile and unpredictable. Corbet et al. (2020) explore the volatility relationship between the Chinese stock markets and Bitcoin. This relationship becomes significantly tighter during the Covid-19 period. Zaremba et al. (2020) explore the association between policy responses to the COVID-19 pandemic and stock market volatility. It is documented that stringent policy responses cause a rise in return volatility. In this paper, we use daily US$ prices of Bitcoin (BTC), Ethereum (ETH), and Ripple (XRP) for the period of 01/09/2019 to 31/03/2020. The wavelet coherence analysis indicates that there is initially a negative relationship between the number of reported cases and deaths and Bitcoin; however, the relationship becomes positive in the later period. The findings for Ethereum and Ripple are also similar to the Bitcoin evidence, however, the interactions are weaker compared to Bitcoin. This shows the hedging role of cryptocurrencies against the uncertainty raised by COVID-19. In the beginning, their pricing behaved like that of traditional assets, but it starts to become a hedge as the effect of COVID-19 materializes. This is in line with previous studies that provide evidence on the hedging role of Bitcoin against uncertainty (Demir et al. 2018; Fang et al. 2019). The rest of the paper is organized as follows. Section 2 briefly summarizes the studies examining the impact of COVID-19 on cryptocurrency market. Section 3 explains the data and methodology. Section 4 presents the results, and last section concludes the paper.",105
10.0,3.0,Eurasian Economic Review,29 January 2020,https://link.springer.com/article/10.1007/s40822-020-00143-4,The importance of default risk awareness in conducting monetary and fiscal policies,September 2020,Eiji Okano,Masataka Eguchi,,Male,Male,Unknown,Male,"At first glance, discussions on optimal monetary and fiscal policy seem to be established and unwavering. However, frequent government debt crises provide a new research agenda and a novel avenue for the discussion of optimal monetary policies. Not long ago, the Greek 10-year credit default swap premium rapidly increased to an eventual value of USD 20,404 in April 2012, and the ECB faced increased difficulty in conducting monetary policy. Subsequently, the harmonized consumer price index (HCPI) inflation rate began to increase from –0.6% in July 2009, and the ECB’s policy interest rate (short-run buying operation rate) remained at 1% until April 2011 when HCPI inflation was 2.8%. However, the Greek tax rate was nearly constant at that time. Can these correspondences be justified from the perspective of optimal monetary policy? Although we refrain from answering this question immediately, the Greek case clearly reveals that there is enough room to discuss optimal monetary and fiscal policy.Footnote 1 In this study, we analyzed optimal monetary and fiscal policy amid a sovereign debt crisis. We found that policy authorities should adopt monetary and fiscal policy rules that do not severely suppress inflation or intend to cause fiscal retrenchment. In other words, policy authorities must not only stabilize inflation but also minimize the premium difference between (virtual) government debt yield and its coupon rate, which we refer to as the premium difference, to diminish welfare costs. The period welfare costs function that stems from second-order approximated utility function includes not only a quadratic inflation term but also a quadratic term for the coupon rate gap. This implies that the cost of sovereign risk is summarized as the coupon rate gap, which is analogous to inflation-generating price stickiness. This study attempted to address two questions: Why does the quadratic term of the premium difference appear in the welfare costs function, and why is the coupon rate gap the cost of sovereign risk? First, we briefly introduce our model, which is based on Gali and Monacelli’s (2005) model, and introduce Uribe’s (2006) fiscal theory of sovereign risk (FTSR), which is notably similar to that of Okano and Inagaki (2017). Our model differs from Gali and Monacelli’s (2005) in that we assume a closed economy. Similar to studies developed by Gali and Monacelli (2005) and Uribe (2006), Calvo pricing is assumed, but the steady state is distorted because tax is levied on the output. Several other aspects of our model reflect Uribe’s (2006) work: There are safe assets that are state-contingent claims and risky assets such as government debt, and the FTSR is applicable. The government budget constraint is iterated forward, and an appropriate transversality condition is imposed. The FTSR is based on the fiscal theory of price level (FTPL), which is advocated by Cochrane (1998), Leeper (1991), and Woodford (1994), and the net present value of the sum of fiscal surplus decides not only price level and inflation but also the default rate. Suppose that the net present value of fiscal surplus decreases. Under the FTPL, this increases the price level while possibly increasing the default rate instead of simply increasing the price level, which occurs under the FTSR. If there are only safe assets, households choose a consumption schedule in which the intertemporal marginal rate of consumption substitution corresponds to the stochastic discount factor—namely, the inverse of the gross nominal interest rate. In our model, there are both safe assets and risky assets, such as government debt. If households purchase government debt, households’ optimal consumption schedule makes the intertemporal marginal rate of substitution correspond to the inverse of the gross expected rate of return to holding government debt, which consists of the government debt yield and expected default rate. Thus, households must adjust their balance of government debt appropriately. By adjusting the balance, which affects the inverse of the gross expected rate of return to holding government debt through changes in government debt yield, optimal consumption schedule attains. If the government debt coupon rate precisely corresponds to the government debt yield, such adjustment is not needed. However, this is rare, even in an actual economy. Thus, methods of adjusting the balance of government debt, such as portfolio rebalancing, are essential. The premium gap is a function of the expected default rate, and the appearance of the quadratic term on the period welfare costs function implies that the premium gap is the cost of sovereign risk. In other words, sovereign risk generates a cost, forcing households to rebalance their portfolios. We analyze both “Exact” and “False” policies. Under the exact policy, the exact welfare cost function is minimized by policy authorities, the central bank, and the government while under the false policy, a false welfare cost function is minimized. The exact welfare cost function is derived exactly, assuming sovereign risk. That is, the second-order approximated FTSR equation is used to eliminate linear terms that generate welfare reversal. There are two primary differences between the exact and false welfare costs functions: the target level of output and existence of a quadratic term for the premium gap. The difference in the target level of output between the exact and false welfare costs functions depends on the interest rate spread in the steady state, which determines the steady-state value of the default rate. If the interest rate spread in the steady state is zero (the steady-state value of the default rate is zero simultaneously), the target level of output in both welfare costs functions is the same. Similarly, the existence of the quadratic term of the premium difference in the exact welfare costs function is contingent upon the interest rate spread in the steady state. If the interest rate spread in the steady state is zero, the premium difference becomes zero, and its quadratic term spontaneously disappears from the exact welfare costs function. These differences depend on the interest rate spread in the steady state. If the interest rate spread in the steady state is zero, the exact welfare costs function precisely corresponds to the false welfare costs function. The interest rate spread in the steady state decides the default rate steady-state value; thus, sovereign risk affects the period welfare costs function, affecting the policy target. If sovereign risk exists, authorities must pay attention to the target level of output and consider minimizing the premium gap. It is tempting to believe that the difference between welfare costs functions can be ignored. Whether this is true depends on the steady-state value of the interest rate spread between safe and risky assets. We utilized numerical analysis with plausible parameters and compared the results of the exact policy with those of the false policy. Furthermore, we calculated “optimal” monetary and fiscal policy rules that are classes of Taylor and Bohn rules to ensure that welfare costs reflect those under the optimal monetary and fiscal policies. Calculating such optimal monetary and fiscal policy rules has been attempted by Ferrero (2009). Interestingly, there are no differences in our Taylor and Bohn rules in the case of a low steady-state value of interest spread that approximately corresponds to the average of the difference between long-term government debt yield and the Federal Fund rate in the US. However, if the steady-state value of the interest spread is high and corresponds to the value in Greece during the Greek debt crisis, the rules are quite different. If policy authorities do not respect the default risk that generates differences in welfare costs function, they suppress inflation and initiate fiscal retrenchment incorrectly. Finally, to bolster our results from the perspective of minimizing welfare costs, we calculated welfare gains under the exact policy. If the steady-state value of the interest spread is low, the gains are 31% and 0% under the optimal monetary and fiscal policies with simple rules replicating welfare costs under the optimal monetary and fiscal policies, respectively. The gains are not necessarily significant or insignificant. However, if the steady-state value is sufficiently high, the gains are 90% and 29% under the optimal monetary and fiscal policy and simple rules, respectively. In this case, the gains are not negligible. Policy authorities should recognize the default risk and not stabilize inflation and fiscal retrenchment. Following the European debt crisis, several influential authors have analyzed monetary policy amid sovereign or default risk. Corsetti et al. (2013) argue that fiscal retrenchment is essential in stabilizing the macroeconomy. Their argument is the reverse of ours. They do not attempt to minimize the welfare cost function and simply focus on suppressing the default. However, the default itself does not necessarily create welfare costs. Although it is the source of the default, the primary difference between (virtual) government debt yield and its coupon rate generates welfare costs. Thus, the optimal policy is not necessarily fiscal retrenchment policy when the steady-state value of the interest spread is sufficiently high. The remainder of the paper is organized as follows: Sect. 2 develops the model, Sect. 3 derives the welfare cost function and solves the linear quadratic (LQ) problem, Sect. 4 is devoted to numerical analysis, and Sect. 5 analyzes welfare costs. Section 6 concludes the paper. The appendix provides technical information in detail.",3
10.0,3.0,Eurasian Economic Review,01 February 2020,https://link.springer.com/article/10.1007/s40822-020-00145-2,Is the emphasis on unit labor costs an effective export-promoting policy? A comparison between Greece and Portugal,September 2020,Dimitris Doulos,Odysseus Katsaitis,George Zombanakis,Male,Unknown,Male,Male,"The financial integration and common monetary policy for the European Monetary Union (EMU) members triggered a flow of funds from “core” to “periphery” countries, and caused a positive aggregate demand shock and significant external deficits in the latter (Lebrun and Perez 2011; Chen et al. 2013). These deficits were, largely, due to rigidities in labor and product markets (Berger and Nitsch 2010), fiscal imbalances and enhanced access to foreign savings that were used for investments in non-tradable sectors, such as construction (Lebrun and Perez 2011). With the beginning of the Greek debt crisis in 2010, such imbalances in European periphery countries like Ireland (2010), Portugal (2011), Italy and Spain (December 2011) attracted particular attention. All these countries experienced deficits and competitiveness problems. In all cases, to a greater or a lesser extent, internal devaluation was proposed as a remedy (Peeters and den Reijer 2012). Given that in a monetary union the nominal exchange rate cannot be used as a policy instrument in such cases, any competitiveness improvement through real exchange rate depreciation would be attained through a decline in relative prices, that is, either an increase in prices in the surplus countries or a decrease in the deficit countries. The extent to which resorting to internal devaluation practices constitutes a fruitful policy measure to increase competitiveness has been extensively discussed in the literature (Decressing and Loungani 2015; Medaiskyte and Klyviene 2012; Aslund 2012) and it seems that it still remains an open issue following the European crisis and the differences between “core” and “periphery” countries concerning key macro variables. Spain is a good example of a Eurozone country where internal devaluation has been successful through the cost-competitiveness rather than the price-competitiveness channel. Fernandez (2014) argues that internal devaluation has made the Spanish industrial activity more profitable by reducing the cost rather than the price of Spanish exports, thus attracting more domestic and foreign productive investment. Ireland right after the crisis had to implement large wage and price adjustments, for its own reasons (McDonnell and O’Farrell 2015). Finally, Greece and Portugal had to sign a Memorandum of Understanding (MOU) with their creditors, in a wage and cost-cutting plan to eliminate their current account deficits. These countries had to adopt austerity measures to restore their lost competitiveness in terms of unit labor cost. There is no clear—cut conclusion, however, concerning the effectiveness of internal devaluation in restoring competitiveness through labor cost reduction in all these economies. As far as Spain, Portugal and Greece is concerned, the policy was successful in reducing unit labor costs. It was only in the case of Spain and Portugal, however, that this contributed to a sustained export growth. Therefore, one may argue that the appropriate policy mix required for a wage-moderation policy to be effective will vary between countries. For example, several studies have underlined the need for structural reforms to accompany internal devaluation (Tressel et al. 2014). In fact, the IMF and the OECD have stressed repeatedly in the past the need to accompany competiveness improvement strategies with structural reforms in the European “periphery” (IMF 2016, 2019; OECD 2017a, b). In terms of an ex-post evaluation of the policies followed, it seems that the structural problems facing the economies of Spain and Portugal were less serious compared to those of Greece with the economy of the latter suffering “from major structural weaknesses” (IMF 2016), such as excessive tax evasion, bureaucracy, corruption and extensive government interference in the markets. This paper aims at investigating the extent to which the existence of such problems has been the reason behind the failure of internal devaluation to improve Greek industrial export competitiveness. In addition, it attempts to explain the reasons why the Portuguese industrial goods exports performed much better compared to those of Greece, both during and after 2010. In an effort to address these issues, the paper proceeds as follows: Sect. 2 presents a comprehensive background and literature review on the subject while Sect. 3 deals with the estimation issues. Section 4 presents the empirical results derived concerning the manufacturing sectors price and output determination for Greece and Portugal. The policy implications relying on the results derived are analyzed in Sect. 5 while Sect. 6 presents the conclusions.",4
10.0,3.0,Eurasian Economic Review,31 January 2020,https://link.springer.com/article/10.1007/s40822-019-00140-2,The Beveridge curve in the OECD before and after the great recession,September 2020,Sergio Destefanis,Matteo Fragetta,Nazzareno Ruggiero,Male,Male,Male,Male,"The aim of this paper is to appraise the evolution of the Beveridge curve across twelve OECD countries from 1985 to 2013 (our choice of countries primarily depended on the quality of available data, discussed further in Sect. 3). Drawing inspiration from Nickell et al. (2003), our analysis sheds light upon a wide spectrum of labour-market policies and institutions. In recent years, the Beveridge curve has been the object of renewed analytical attention (see, for instance, Bonthuis et al. 2013; Hobijn and Şahin 2013; Arpaia et al. 2014). However, we are not aware of papers dealing with the impact of a large set of policies and institutions before and after the recent recession, which is believed to have brought about long-lasting changes in the world economy. Some papers assess whether the Beveridge curve shifted outwards during the recession, but fairly few studies have explored the connections between this (possible) shift and labour institutions and policies. Furthermore, very few works have considered the role of technological progress and globalisation as potential shift factors for the Beveridge curve, with no unanimity on the sign of their impact (see Sect. 2 for a survey of the literature). This paper is structured as follows: In Sect. 2, we examine some empirical literature on OECD countries, providing the motivation behind our study and focusing on the role of the current crisis in this context. In Sect. 3, we present the empirical specification and data. The results are presented in Sect. 4, while Sect. 5 provides concluding remarks.",
10.0,3.0,Eurasian Economic Review,03 April 2020,https://link.springer.com/article/10.1007/s40822-020-00148-z,Returns to schooling in Kazakhstan: an update using a pseudo-panel approach,September 2020,Saule Kemelbayeva,,,Female,Unknown,Unknown,Female,"The ‘returns to schooling (education)’ concept, as developed by Mincer (1974), was subsequently theoretically enriched and empirically tested in various contexts, and contributed to the evaluation of the economic role of education, labor market conditions and human capital productivity. Although the model in its basic form has certain conceptual flaws—in particular, it ignores bias potentially caused by unobservable factors that can influence both schooling and earnings—methods have been proposed to overcome them such as a use of panel data allowing to explicitly control for unobserved heterogeneity, assuming it is time-invariant. The aim of this study is to estimate the returns to schooling in Kazakhstan with the use of massive repeated cross-sectional data collected by the Household Budget Survey in 2002–2016, as a synthetic or pseudo-panel. The approach proposed by Deaton (1985) suggests adopting a pseudo-panel of cohort means, where a ‘cohort’ we consider to be a group of people of the same gender born in the same year who are assumed to share some common, unobserved characteristics. There are no assessments available for the returns to education in Kazakhstan during the Soviet period, but they are believed to be low due to wage levelling, wage ‘grids’, and the centralized allocation of the labor force. However, according to a few post-Soviet examinations, they soared with the transition. In Kazakhstan, whose independence can be roughly divided into two sub-periods—the severe crisis of the 1990s and the oil boom of the 2000s (Fig. 1)—the later economic growth might additionally have contributed to the increase in returns via several channels. Demand for education consistently grew during the period of independence, with the number of university students increasing from 287,367 in 1990/91 to 542,458 in 2018/19, and the number of college students (technical and vocational education and training) from 247,650 to 489,818 for the same years, respectively (with a corresponding net increase in population of around 1.5 million).Footnote 1 Kazakhstan’s educational institutions expanded accordingly: from 55 HEIs in 1990/91 to 124 in 2018/19, and from 247 colleges to 769 for the corresponding years.Footnote 2 On the other hand, with this nearly twofold increase in the inflow of educated people, it might be reasonable to predict a decrease in returns to schooling over time. Additionally, the period under consideration represents the oil boom decade when GDP per capita grew from 1658.00 USD in 2002 to 13,890.80 USD in 2013,Footnote 3 but with signs of recession starting in 2014 when world commodity prices plummeted, dragging down an economy that was (and still is) highly dependent on oil and gas exports, which might also have intriguing effects. Source: World Bank Data GDP per capita, (constant 2010 USD).  With the pseudo-panel approach, we found the returns to schooling to be relatively high (7–13% with the fixed effects and 8–11% with Mundlak random effects, depending on a set of additional control variables) and essentially identical to simple OLS estimates obtained from individual data (8–12% for men and 10–13% for women), which are in turn very similar to the only previous examination that used the instrumental variables approach (Arabsheibani and Mussurov, 2007). Though the results for schooling are robust across models regardless of controlling for cohort heterogeneity, with the Mundlak model the cohort effect (between-estimator) turned out to be highly significant and negative: while an increase in cohorts’ average schooling over time increases their wages, less educated cohorts earn more than more educated ones. More educated cohorts in the sample are the younger individuals whose school-leaving age fell roughly within the recession of the 1990s, suggesting the business cycle impact interpretation: cohorts entering the labor market during a recession and facing a lack of jobs apparently end up getting more education and lower lifetime wages. The study additionally uncovers other curious results. First, though real wages rocketed during the observed period (by about 500–600% for men and 300–400% for women), the returns to schooling dropped (by about 4–5% and 2–3% for men and women, respectively). Second, the rapid growth in real wages over the period could only partially be explained by the changes in the working population’s observed characteristics, including education, by about 30% for men and 40% for women, leaving the remaining part likely due to the oil boom growth. Third, despite females earning less, their returns to schooling were consistently higher for all models. The latter could probably be explained by gender differences in the labor force allocation between industries and sectors, with men mainly employed in market-oriented, riskier, but better paid industries with predominantly private ownership that probably value education less than the public sector and those industries absorbing the female labor force, where a certain level of schooling is often formally required and, indeed, rewarded. This, in turn, complies with the higher level of education amongst women compared to men due to their rational decisions under the prevailing labor market conditions. The paper is organized as follows. The following section discusses the theoretical framework, the pseudo-panel methodology and its possible drawbacks, and briefly reviews its previous applications worldwide. It also details some of the very few research efforts to examine the returns to schooling in Kazakhstan and the region. Section 3 depicts the sampling methodology and the questionnaire, stating data limitations and caveats with regard to the interpretation of the results so arising. It familiarizes the reader with descriptive statistics and visualizes the most important individual-level variables disaggregated by gender, as well as the cohort-level data. The following section discusses the main findings from the estimated models and their possible interpretations in the context of the Kazakhstani labor market, as summarized by the conclusions.",5
10.0,3.0,Eurasian Economic Review,06 February 2020,https://link.springer.com/article/10.1007/s40822-020-00146-1,Propagation of economic shocks from Russia and Western European countries to CEE-Baltic countries,September 2020,Nazmus Sadat Khan,,,Unknown,Unknown,Unknown,Unknown,,
10.0,3.0,Eurasian Economic Review,27 March 2019,https://link.springer.com/article/10.1007/s40822-019-00127-z,Reassessing the environmental Kuznets curve: a summability approach for emerging market economies,September 2020,Seref Bozoklu,A. Oguz Demir,Sinan Ataer,Unknown,Unknown,Male,Male,"In the post-World War II era—the Golden Age of Capitalism—reconstruction and development gained unprecedented momentum, which increased the importance of examining and making inferences about environmental policies. Among others, setting production facilities without environmental measures, increasing the number of facilities with limited protective measures and production realized without evaluating renewable energy resources resulted in an excessively negative burden on the environment. Therefore, environmental scientists have asserted that increasing energy usage due to the economic growth increases CO2 emission which is the fundamental causes of greenhouse gases, global warming, and climate change. These results have drawn more attention among environmentalists and economists due to the negative potential threats such as rising sea levels, altered rainfall patterns, increased ocean and atmospheric temperatures, and lower agricultural and labor productivity. Societies have also started to pay more attention to their living conditions, especially environmental, which has stimulated the number of studies conducted on the relationship between economic growth and environmental degradation. Because this relationship is crucial to sustainable development, the results from empirical studies could provide important implications of environmental policies on economic growth. There has been considerable debate over the relationship between economic growth and environmental improvement. Early proposals have suggested that as economic growth increases, greater energy inputs are required; consequently, the increased use of natural resources causes environmental pollution. These proposals also stated that the consumption of natural resources will eventually make economic activity risky in a limited global ecological framework. From this perspective, the Limits to Growth Approach (Meadows et al. 1972), for instance, suggests that these constraints may restrict economic growth and harm a stable economy. However, some other proposals (Dasgupta and Heal 1979) have argued that economic growth makes policy makers create and implement necessary environmental protection measures, causing growing public interest in a cleaner environment and providing improved environmental quality. In opposition to these initial arguments, which implicitly mimic a fixed link between economic growth and environmental development for all phases of economic growth, some researchers at the beginning of the 1990s hypothesized a nonlinear relationship that changes in accordance with different stages of economic growth and, therefore, there is no fixed correlation between economic growth and environmental development. As income level increases during the early stages of economic growth, environmental quality deteriorates, which refers to the positive correlation. In contrast, ongoing increases in income level transform society and generate environmental awareness, which improves environmental quality and, therefore, the correlation is negative for this second phase. As a result, this awareness creates an inverse U-shaped pattern between economic growth and environmental degradation (Grossman and Krueger 1991). In light of these arguments, the environmental Kuznets curve (EKC)Footnote 1 indicates that a nonlinear connection exists between per capita environmental pollutants and per capita income, meaning that the connection displays different characteristics at different stages of economic growth. At the beginning of growth, rises in environmental pollutant are observed; however, at later phases of growth, environmental pollutants decrease significantly and environmental quality increases remarkably (Stern 2004). It is, therefore, assumed that a threshold level exists where environmental pollutants increase with the rise in income; however, after reaching this threshold, the environmental pollutants decrease following continuous economic growth. As a result, the EKC refers to the inverse U-shaped pattern between per capita environmental pollutants and per capita income (Dinda 2004). Grossman and Krueger (1995) suggest there are three main phases to the EKC. In the first phase, economic growth creates a scale effect on the environment, which means that a greater quantity of economic and industrial activities increases environmental pollution. The second phase includes the composition effect such that economic activities become cleaner and environmentally friendly activities increase in their share of total activities with stable economic growth. In the third phase, a wealthy economy starts to invest in research and development, and there may be a structural change from energy-intensive industries to technology-intensive ones. These innovative attempts and structural changes generally lead to dirty heavy industries transforming into clean ones, which is called the technique effect. The EKC can be flattened by properly implementing policies, such as the removal of subsidies for and the environmental externalities of economic activities, the introduction of more secure property rights over resources, and the enforcement of effective environmental regulations. International society can play a worthwhile role in flattening the ECK through financing policy reform, accumulating information, and public environmental education (Dasgupta et al. 2002). Additionally, it is likely that the ECK can be flattened under the combined impact of economic liberalization, improved information, and more stringent and cost-effective approaches to regulating pollution if the policies and institutions are more sensitive. As a result, policies and institutions can significantly reduce environmental degradation at lower income levels and speed up improvements at higher income levels (Panayotou 1997). Although more recent studies have used larger data sets to find out whether an inverse U-shaped relationship holds in diverse countries and situations, Lee et al. (2005) assert that because the EKC hypothesis only focuses on pollution, it should not be considered as an overall measure of the linkage between economic growth and environmental quality, and that the direction may be negative for eco-efficiency indicators even if there is a significant positive link between income and pollution-related indicators. Additionally, it is usually assumed that economic growth will lead to technological changes and improvement. However, if economic growth emerges without changes in technology or economic structure, then pollution may also increase, and environmental degradation may continue, creating a scale effect as stated by Stern et al. (1996). Such economies may grow due to the labor required for manufacturing-based economies but this does not mean they are reducing pollution emissions. As a result, the possibility that economies may grow without the improvement of technology, especially in the case of developing and underdeveloped countries, should be considered. The reason that emerging economies are chosen as the research sample in this study is that the robustness of the EKC hypothesis is still uncertain and the curve does not display an explicit pattern, which means environmental and growth policies based on the EKC hypothesis may have potentially unexpected effects on one another in these countries. Our study aims to examine the long-term relationship between CO2 emissions per capita and GDP per capita for emerging economies and makes several contributions to the empirical literature on EKC. First, focusing on a sample for emerging market economies allows us to consider the development phases covering the transition from the early stages to the current status of these economies. Second, as an improved method to detect nonlinear long-term relationships, we employed summability techniques to test for the validity of the EKC hypothesis. The main motivation of our study is to examine whether economic growth can be part of the solution rather than the cause of the environmental problems and to search for better policies for emerging economies. The rest of the paper is organized as follows: Sect. 2 explains the previous studies; Sect. 3 introduces data and model; Sect. 4 refers to the econometric methodology; Sect. 5 presents the empirical results; and Sect. 6 concludes.",8
10.0,3.0,Eurasian Economic Review,05 February 2020,https://link.springer.com/article/10.1007/s40822-020-00144-3,"Subjects in the lab, activists in the field: public goods and punishment",September 2020,Chetan Dave,Sjur Hamre,Alicja Reuben,Unknown,Male,Female,Mix,,
10.0,4.0,Eurasian Economic Review,07 July 2020,https://link.springer.com/article/10.1007/s40822-020-00152-3,An augmented P-Star model of US inflation,December 2020,Imad Moosa,Basil Al-Nakeeb,,Male,Male,Unknown,Male,"While some economists view inflation as a purely monetary phenomenon, emerging when too much money chases too few goods, the effect of structural factors cannot be overlooked. Two important structural factors are import prices and wages. Inflation, therefore, may be attributed to a combination of demand-pull factors, pertaining to monetary expansion, and cost-push factors such as rising import prices and wages. Yet, inflation in the US and other OECD countries remains subdued, at least according to the official figures, despite a massive monetary expansion (resulting from quantitative easing) and recovery from the Great Recession. Some economists describe this observation as a “puzzle”, which Corrigan (2005) explains in terms of favorable “supply shocks”, including soft energy and commodity prices as well as gains in labor productivity. The objective of this paper is to provide evidence on the underlying propositions by specifying, estimating and testing a model of US inflation over the period 2000–2018. The model encompasses monetary factors and cost-push factors—specifically, import prices and wages. It is basically a P-Star model augmented by adding import prices and wages as explanatory variables. We start with a description of the underlying theory and relevant evidence.",
10.0,4.0,Eurasian Economic Review,30 January 2020,https://link.springer.com/article/10.1007/s40822-020-00142-5,Market reaction to regulatory policy changes in financial statements filings: evidence from Turkey,December 2020,Mustafa K. Yılmaz,Mine Aksoy,Tankut T. Çelik,Male,Female,Male,Mix,,
10.0,4.0,Eurasian Economic Review,10 September 2020,https://link.springer.com/article/10.1007/s40822-020-00153-2,Impact of public and private sector external debt on economic growth: the case of Portugal,December 2020,Jorge Silva,,,Male,Unknown,Unknown,Male,"The relationship between economic growth and debt is an attractive subject in the macroeconomics field. High levels of public debt, private debt and external debt may impact economic growth and assign future resources. Previous literature on external debt focused on emerging economies individually or sets of countries. The innovation of our study is the simultaneous focus on three features: the split of external debt between public and private sectors, a highly indebted country and an advanced economy.Footnote 1 Portugal had the highest net external debt-to-GDP ratio among the founding members of the euro area. In this study, we concentrate on the case of Portugal for the 1999–2019 period and highlight the relationship between the stock of external debt and economic growth. The euro currency was introduced in 1999 and consequently the monetary policy became an external variable. Gros (2011) considered that external debt was the key factor during the European crisis in 2010–2011 and the focus on total public debt was misleading. Portugal was an example of how external debt is more important than public debt. Belgium and Portugal had similar fiscal positions and public debt-to-GDP in 2010, but financial markets were worried about Portugal. While Belgium was a net creditor, Portugal had a high external debt-to-GDP ratio. Therefore, the contribution of this study is to assess how external debt was (not) allocated to the channels of transmission through which external debt may affect economic growth. Portugal has country-specific features that emerged after the introduction of the euro: low economic growth, high external debt-to-GDP, and the economic and financial adjustment programme (EFAP).Footnote 2 While other studies have focused on public debt, we focus on external debt because this is a proxy for the funding of the economy as a whole (Gros 2011). Additionally, we split the external debt of the private and public sectors due to the different conditions that exist when accessing external funding. In this study, we use quarterly data and estimate the effects of leveraging and orderly deleveraging on the channels through which external debt may affect economic growth. Therefore, we identify the amount of public debt held by non-residents. While public debt held by residents may not be very detrimental for the economic growth rate, government debt held by non-residents may have negative consequences on the external accounts and on economic growth.Footnote 3 Furthermore, the external debt of the private sector could have an impact on private gross added value and would necessarily assign future resources generated by the private sector to the payment of interests to the rest of the world. The net external debt is the largest subset of the international investment position (IIP). A sustainable trajectory of the net external debt requires that the resident institutional sectors have the capacity to generate future resources and pay interests to non-residents over the medium and long run. Additionally, a sustainable trajectory cannot jeopardize the rollover of external debt, reduce the potential output growth and crowd out the other components of the IIP. During the 1999–2019 period, the low economic growth rate did not generate abundant resources to simultaneously pay interests and increase investment. The increasing share of portfolio investment and debt instruments resulted in vulnerability to financial markets (Faria et al. 2007). The increasing external debt made rollover difficult, and the sudden stop in 2010 led to the EFAP. This country-specific analysis may be useful for small open economies in a monetary union. This paper is organized as follows: Sect. 2 presents the literature review, Sect. 3 addresses the theoretical framework, Sect. 4 details the data, Sect. 5 presents the methodology, Sect. 6 discusses the results, Sect. 7 presents the robustness analysis, and Sect. 8 concludes.",6
10.0,4.0,Eurasian Economic Review,30 January 2020,https://link.springer.com/article/10.1007/s40822-020-00141-6,Is size an input in the mutual fund performance evaluation with DEA?,December 2020,Sevgi Eda Tuzcu,Emrah Ertugay,,Female,Male,Unknown,Mix,,
10.0,4.0,Eurasian Economic Review,16 April 2020,https://link.springer.com/article/10.1007/s40822-020-00149-y,Cultural fractionalization and informal finance: evidence from Indian firms,December 2020,Khondker Aktaruzzaman,Omar Farooq,,Unknown,Male,Unknown,Male,"Why do some firms have higher appetite for informal finance than the others? What are some of the factors that result in high/low demand for informal finance? These questions have attracted significant interest in prior literature. Stiglitz and Weiss (1981), for instance, argue that demand for informal finance is an increasing function of the extent of information asymmetries between lenders and borrowers. Love and Mylenko (2003) also note that poor information environment increases the demand for informal finance because it is hard for formal lenders to screen borrowers, thereby making it hard for them to extend credit. A related strand of literature extends the above arguments by associating legal and institutional environment with the demand of informal finance (La Porta et al. 1997; Jappelli and Pagano 2002; Djankov et al. 2007). This strand of literature argues that inefficiencies in legal and institutional environment can increase the demand for informal finance. Moro et al. (2018), for example, document that firms find it relatively difficult to obtain formal funding in environments characterized by weak legal enforcement. They argue that ineffective institutional environment makes it difficult for financial institutions to extend funding because they will find it hard to enforce formal contracts. Inability of firms to obtain financing from financial institutions leads them to seek and use informal finance. A casual look at prior literature suggests that an important factor that has received relatively lower attention is the effect of social environment (for instance, fractionalization) in which the firms operate in on the demand for informal finance. Ajide (2019, p. 5) notes that fractionalization “in its various ramifications has received less research attention if at all, thus creating a gap”. The aim of this paper is to fill this gap by documenting the relationship between the extent of fractionalization in the society and the demand for informal finance. Our paper, to some extent, extends the prior literature on the effect of fractionalization on various dimensions of financial development (Easterly and Levine 1997). However, instead of highlighting the impact of fractionalization on financial development, we document the impact of fractionalization on the demand for informal finance. We test our arguments within the context of India because the country is characterized by more ethnic and religious groups than most other countries of the world. It is the land where almost all the major religions of the world are practiced by their respective followers. According to 2011 census, Hinduism is practiced by majority of the population (79.8%), followed by Islam (14.2%), Christianity (2.3%), Sikhism (1.7%), Buddhism (0.8%), and Jainism (0.4%). Other than these six religions, there are many tribal religions as well. In India, religious fractionalization has been a major source of disunity and disharmony in society. This is because religious affiliation appears to be overemphasized and plenty of the times people seem to forget the national unity and express their loyalty more towards their own religion. The incidents like Partition, Punjab conflict, Babri mosque destruction, Godhra train burning, Gujarat violence, Assam violence, and Muzzafarnagar riots have left deep scars on Indian society. These incidents have resulted in mistrust among individuals of different religions, leading to civil unrest and adverse impact on economic behaviors. Chuah et al. (2013) also report lower trust between individuals belonging to different religions in India. We would also like to mention that a single country focus of this research can also shed a light on the sources of economic disparities across different regions within India. Furthermore, a single country focus can help us isolate the impact of fractionalization because the country-level characteristics will be the same for all states/provinces. This paper argues that fractionalization affects the demand for informal finance via two channels. The first channel exerts its impact on the demand for informal finance through inefficiency of formal institutions that are present in fractionalized societies. La Porta et al. (1999), for example, document that fractionalization is related to lower governance quality. Touchton (2013) supports the findings of La Porta et al. (1999) by arguing that fractionalization negatively affects the rule of law due to the prevalence of ethnically-based patronage networks. This paper contends that inefficient institutions present in highly fractionalized societies make enforcement of contracts a difficult task. In fact, we argue that economic agents are more likely to enter into financial contracts when they feel that the contracts are enforceable. Therefore, we should expect higher demand for informal finance in societies with high levels of fractionalization (due to inefficiency of formal institutions). The second channel makes use of lower levels of social trust that characterizes highly fractionalized societies. Fukuyama (1997) contends that societies with lower levels of social trust are often characterized by higher dependence on transactions from families and friends. Therefore, we should expect higher demand for informal finance in societies with high levels of fractionalization (due to lower levels of social trust). Guiso et al. (2004) also find that the likelihood of generating finance from a relative or a friend is a decreasing function of the level of trust prevailing in the society. We use the data provided by the World Bank’s Enterprise Survey to test the validity of above arguments in India. Based on the estimation of various OLS regressions, our findings show that fractionalization has a positive impact on the demand for informal finance. Our results are robust across sub-samples of small and large firms. Interestingly, we also show that most of the demand for informal finance is met by the funding provided by families and friends. In the case of informal finance provided by suppliers and customers, we report positive but insignificant impact of fractionalization on the demand for informal finance. We also show that, when it comes to the use of formal finance, firms headquartered in states/provinces with high levels of fractionalization are more likely to use retained earnings (internal finance) than bank loans. It, further, supports our arguments that fractionalization reduces the demand of formal funding from financial institutions. Given that banks may not be able to enforce contracts, they are less likely to supply funding to firms headquartered in states/provinces with high levels of fractionalization. Interestingly, the findings of this paper show that the impact of fractionalization on the demand of informal finance is less pronounced in environments characterized by stronger governance. For the purpose of this paper, we use two proxies for state-level governance environment (human development index and economic freedom index) and two proxies for firm-level governance environment (ownership concentration and exposure to competition). Our results for all proxies for governance environment show less pronounced relationship between fractionalization and the demand of informal finance in environments characterized by stronger governance. We argue that, when state-level or firm-level governance environment is strong, the faith of financial institutions in recovering their funding is high. Therefore, it is relatively easy for firms characterized by stronger governance environment to obtain formal financing, thereby reducing their reliance on informal finance. This finding is consistent with Guiso et al. (2004) who note that societies with weaker legal enforcement of contracts are more likely to rely on informal finance. The remainder of paper is structured as follows: Sect. 2 develops the hypothesis. Section 3 briefly presents information on informal finance in India. Section 4 summarizes the data and Sect. 5 presents assessment of our arguments. Section 6 presents additional tests. The paper ends with Sect. 7 where we present our conclusions.",4
10.0,4.0,Eurasian Economic Review,30 June 2020,https://link.springer.com/article/10.1007/s40822-020-00151-4,Does corporate governance really matter for bank efficiency? Evidence from ASEAN countries,December 2020,Thi Lam Anh Nguyen,Xuan Vinh Vo,,,,Unknown,Mix,,
10.0,4.0,Eurasian Economic Review,06 October 2020,https://link.springer.com/article/10.1007/s40822-020-00156-z,Impact of macroeconomic cyclical indicators and country governance on bank non-performing loans in Emerging Asia,December 2020,Nurfilzah Arham,Mohd Shamlie Salisi,Jasman Tuyon,Unknown,Unknown,Unknown,Unknown,,
10.0,4.0,Eurasian Economic Review,11 June 2020,https://link.springer.com/article/10.1007/s40822-020-00150-5,"Optimal policies, middle class development and human capital accumulation under elite rivalry",December 2020,Elena Sochirca,Pedro Cunha Neves,,Female,Male,Unknown,Mix,,
11.0,1.0,Eurasian Economic Review,19 February 2021,https://link.springer.com/article/10.1007/s40822-020-00165-y,Drivers of green bond issuance and new evidence on the “greenium”,March 2021,Kristin Ulrike Löffler,Aleksandar Petreski,Andreas Stephan,Female,Male,Male,Mix,,
11.0,1.0,Eurasian Economic Review,26 February 2021,https://link.springer.com/article/10.1007/s40822-021-00166-5,The relationship between trend and volume on the bitcoin market,March 2021,Beata Szetela,Grzegorz Mentel,Urszula Mentel,Female,Male,Female,Mix,,
11.0,1.0,Eurasian Economic Review,02 December 2020,https://link.springer.com/article/10.1007/s40822-020-00160-3,How have the European central bank’s monetary policies been affecting financial markets in CEE-3 countries?,March 2021,Wojciech Grabowski,Ewa Stawasz-Grabowska,,Male,Female,Unknown,Mix,,
11.0,1.0,Eurasian Economic Review,18 November 2020,https://link.springer.com/article/10.1007/s40822-020-00157-y,The impact of cultural distance on salary: the case of Samurai Japan,March 2021,Wen-Jhan Jane,,,Unknown,Unknown,Unknown,Unknown,,
11.0,1.0,Eurasian Economic Review,03 January 2021,https://link.springer.com/article/10.1007/s40822-020-00161-2,The impact of the Eurasian Economic Union–Iran preferential trade agreement on mutual trade at aggregate and sectoral levels,March 2021,Amat Adarov,Mahdi Ghodsi,,Unknown,Male,Unknown,Male,"On 27 October 2019, the trade agreement between the Eurasian Economic Union (EAEU) and Iran was implemented. Although at times called a free trade agreement, de facto, it is a preferential trade agreement (PTA), as its scope is limited to a selection of product lines for which mutual import tariffs are reduced or eliminated. However, the agreement has sufficient depth and covers the main product categories traded between Iran and the EAEU (Armenia, Belarus, Kazakhstan, Kyrgyzstan and Russia). The EAEU framework, amongst other foreign trade regulations, enforces a common customs territory and imposes a common external tariff (CET) against non-bloc trading partners (see Adarov 2018, for details). Therefore, free trade agreements or PTAs facilitate access to a rather large, joint market of the five EAEU member states. The EAEU–Iran PTA covers approximately 55% of the total mutual trade between the partners and focuses on a range of agricultural and selected manufacturing products. On the one hand, in line with the agreement, Iran grants preferential treatment for meat and selected agri-food products, metals, electronics and other items. The average import tariff applied by Iran to imports from the EAEU in line with the agreement decreases from 22.4 to 15.4% for manufactured goods and from 32.2 to 13.2% for agricultural products. Overall, 360 product lines are affected. On the other hand, Iran receives preferential treatment for its exports of fruits and vegetables, metal products, construction materials, and selected other items such as tableware and carpets. The average import tariff applied by the EAEU against Iran is to decline for agricultural products from 9.6 to 4.6% and for manufactured goods from 8 to 4.7%. In total, 502 product lines are affected by the preferential treatment (Sect. 2 provides a more detailed review of the tariff changes associated with the PTA). Although the import tariff reductions are not comprehensive in scope, they are significant and cover a large share of traded products. This makes the agreement essential particularly for Iranian exports, as the EAEU market is much larger than Iran’s. As of 2019, Iran’s gross domestic product (GDP) constituted only approximately 24% of the aggregate EAEU GDP; however, it remains a relatively large market in the regional context. The PTA is based on the World Trade Organization (WTO) rules. In this context, note that four of the EAEU economies are already members of the WTO; the exception is Belarus, which, however, has to comply indirectly with the WTO regulations via the common EAEU framework.Footnote 1 However, Iran is not yet a WTO member, mainly because of its strained political relations with the US. The implementation of the agreement will thus indirectly facilitate longer-term mutual cooperation consistent with the WTO rules. In fact, the current PTA is a fixed-term agreement (currently fixed for 3 years), but throughout this period, the parties agree to consider a possible transition to a more comprehensive and deeper free trade agreement. The trade agreement is thus expected to bring benefits to both parties. However, to date, no formal empirical analysis of the possible effects of the EAEU–Iran PTA agreement has been found, and the present study was the first attempt to fill this gap. Generally, there are only a few studies that analyze ex ante or ex post trade impacts of the Eurasian economic integration (see, for instance, Adarov 2018; De Souza 2011; EBRD 2012; Tarr 2016). In addition to this, our study was most closely related to the empirical literature studying the trade effects of PTAs, free trade agreements and other forms of bilateral or multilateral integration in a gravity model setting (Tinbergen 1962; Anderson and Wincoop 2003; Head and Mayer 2014). In most cases, the impact of trade agreements is evaluated empirically by introducing a simple dummy variable or, in some cases, a variable that reflects the depth of an agreement (See, for instance, Baier and Bergstrand 2007; Caporale et al. 2009; Carrère 2006; Gylfason et al. 2015; Okabe and Urata 2014; Sandberg et al. 2006. For a comprehensive review of the related literature and approaches, also see Baier and Bergstrand 2018.). The approach of using a dummy variable for PTA to measuring their effect is, however, rather simple and does not allow a more granular differentiation of the depth of an agreement by sectors, which is necessary in our case, considering that the agreement is a PTA and affects only a fraction of mutually traded products with varying intensity of trade across the participating countries. Generally, import tariffs had been theoretically and empirically found to produce diverse impacts on trade flows depending on the elasticity of substitution of products. As Chaney (2008) for instance argued and proved using a constant elasticity of substitution, products with larger elasticity of substitution may be more sensitive to ad valorem (iceberg) trade costs. Naturally, trade elasticities of variable costs vary across products, and, therefore, different trade agreements have different impacts depending on the products they cover; thus, the effects are not directly comparable. In this respect, our study was related to the papers that analyzed the impact of trade integration by relying on preferential import tariffs rather than a PTA dummy variable (see, e.g. Cipollina and Salvatici 2007; Emlinger et al. 2006; Disdier et al. 2015) and estimate trade–tariff elasticities in a gravity setup (Fontagné 2020; Feenstra and Romalis 2014; Caliendo and Parro 2015). Particularly, in Fontagné (2020), using a fine level of disaggregation at the harmonized system (HS) six-digit level allowed to consistently estimate trade elasticities and reduce the downward bias when a higher level of sectoral aggregation is used (Imbs and Mejean 2015). Finally, the theoretical underpinning behind our approach was provided in Baier et al. (2018), who, inter alia, developed a theoretical framework for comparative statics associated with the ‘partial effects’ of changes in bilateral variable trade costs. In our case, we exclusively focused on bilateral import tariffs at the HS six-digit level (constituting bilateral variable trade costs in a general framework) as the trade regime between the EAEU and Iran does not change otherwise, e.g. the EAEU–Iran PTA does not envision changes in non-tariff barriers. Specifically, considering these developments in the literature, we used the gravity model of trade estimated for the detailed product data at the HS six-digit level to examine the ex ante effects of the implementation of the agreement at aggregate and sectoral levels. Notably, the EAEU–Iran trade agreement is a PTA covering only a fraction of products and corresponding import tariffs rather than attempting to achieve deeper forms of integration. This allowed us to focus explicitly on these tariffs at a fine level of sectoral disaggregation rather than to use a more crude approach of relying on a bilateral PTA dummy variable, as often done in similar literature applying the gravity model of trade. Our analysis suggested that the implementation of the agreement will boost mutual trade for both the EAEU and Iran, albeit with several asymmetries in terms of the beneficiary countries and sectors. The total gains in mutual trade were estimated to reach over USD 72 million, with exports from the EAEU to Iran expected to increase by 19.1% and exports from Iran to the EAEU by up to 7%. The impact also differed significantly across sectors. The results suggested that the major increases in exports will accrue to the agri-food sectors, as well as to chemicals, rubbers/plastics (polymers), textiles and selected electrical and machinery manufacturing sectors. The gains in exports from the EAEU to Iran were larger and more diversified across sectors. Iran, by contrast, will see most gains in its exports of fruits and vegetables, as well as foodstuffs (however, its polymer production, chemicals, textile and machinery/electrical equipment sectors will also benefit significantly). In terms of the expected increase in trade, both in absolute values and in percentage terms relative to the pre-PTA levels, exports from the EAEU to Iran appeared to benefit more than exports from Iran to the EAEU, although the EAEU market is much larger than that of Iran. This was, however, perfectly consistent with the much greater import tariff liberalization introduced by the EAEU–Iran PTA on imports to Iran, whereas Iran maintained a much more restrictive trade regime before the PTA implementation in comparison with the EAEU (it should also be noted that the average import tariff imposed by Iran after the entry into force of the PTA was still much higher than the tariff applied by the EAEU). The rest of the paper is structured as follows. The methodology, the data and present stylized descriptive facts on the EAEU–Iran PTA trade agreement and trade dynamics are outlined in Sect. 2. The results of the econometric analysis and their policy implications are reviewed in Sect. 3. Finally, conclusions are provided in Sect. 4.",4
11.0,1.0,Eurasian Economic Review,19 October 2020,https://link.springer.com/article/10.1007/s40822-020-00155-0,Fiscal institutions: different classifications and their effectiveness,March 2021,Patrícia Martins,Leonida Correia,,Female,Male,Unknown,Mix,,
11.0,1.0,Eurasian Economic Review,23 February 2021,https://link.springer.com/article/10.1007/s40822-020-00164-z,Heterogeneity of fiscal adjustments in EU economies in the pre- and post-crisis periods: common correlated effects approach,March 2021,Olgica Glavaški,Emilija Beker Pucar,,Female,Female,Unknown,Female,"The EU economies’ fiscal adjustment issues have attracted considerable attention in the past three decades, particularly when questions related to fiscal sustainability and fiscal policy prudence were renewed during the global crisis. EU economies undertook heterogeneous fiscal adjustments in terms of time and procedures due to the lack of unique fiscal policy. Fiscal adjustment heterogeneity in terms of time is related to public revenue and/or public expenditure adjustment either in the recession or expansion phase of the business cycle. In contrast, the issue of procedures is related to the composition of public revenue/expenditure increase/decrease. While all EU economies take part in economic union, 19 EU economies have taken integration further in the Economic and Monetary Union (EMU). Due to a common monetary policy and coordinated fiscal policy with stronger fiscal rules in the EMU, fiscal adjustment heterogeneity is present in the EU economies. The Maastricht Treaty (1992) and Stability and Growth Pact’s (1997) pre-crisis fiscal policy framework was relatively weak due to the absence of unique fiscal policies. Although the Stability and Growth Pact made distinction between the eurozone (EMU) and non-eurozone countries using “stability programs” and “convergence programs” respectively, the scope of heterogeneous fiscal adjustments and potential fiscal irresponsibility are left to the EU economies. Establishing post-crisis complementarity between supranational and domestic fiscal arrangements is complex. However, new mechanisms of European fiscal policy framework, such as the Fiscal Compact (2012), include tools such as medium-term objectives and provision for corrective mechanism in case of goal deviations. Moreover, independent fiscal institutions are established to monitor fiscal rule implementation in coordination with the European Fiscal Board (established in 2015). Further mechanisms for strengthening the European fiscal framework are related to the initiative to establish the European Investment Stabilisation Function and European Monetary Fund. This study estimates fiscal adjustments in terms of time (before and after the global crisis) and procedures to determine the success of substantial measures undertaken to fortify fiscal policy in EU economies. The empirical literature shows that spending-side fiscal adjustments are more efficient compared with tax-side fiscal adjustments in terms of public debt reduction and GDP effects (Alesina and Ardanga 2010; Alesina et al. 2015b). Therefore, this paper empirically assesses the heterogeneity of spending-side fiscal adjustments of 28 EU economiesFootnote 1 (hereinafter EU-28) in the period 2000–2018 (quarterly data) to analyze fiscal adjustment differences between pre- and post-crisis periods. Although various definitions due the EMU membership and historical expansion of the EU exist (such as eurozone, non-eurozone economies, EU-15, EU-25, EU-28) we decided to analyze the EU-28 to cover fiscal adjustment heterogeneity. Fiscal adjustments and sustainability in the empirical literature are frequently tested through cointegration approach based on long-term (in)consistency between tax and public expenditure policies (flow approach). Public debt accumulation in a stochastic environment represents a crucial factor for fiscal sustainability. This condition implies the necessity of applying stock-flow models based on multicointegration analysis. Therefore, governments use fiscal adjustments not only to control a flow variable, i.e. fiscal deficits, but also by taking corrective measures on flow variables governments control a stock variable, i.e. public debt. Therefore, the goal of this paper is twofold: (1) to estimate the effects of fiscal adjustments on public debt and fiscal deficit using stock-flow models (panel multicointegration approach) and (2) to estimate heterogeneous fiscal adjustments in the pre- and post-crisis periods in EU-28. This study estimates heterogeneous parameters in stock-flow models using Comm on Correlated Effects (CCE) approach, particularly Eberhardt and Teal’s (2009) Augmented Mean Group (AMG) estimator with ‘common dynamic effect’. To the best of our knowledge a stock-flow model estimated through CCE method has not been used in the literature on the effects of fiscal adjustments, i.e. heterogeneous regression coefficients have not been considered in this area. Therefore, this paper significantly contributes to heterogeneous parameters in stock-flow models by providing fiscal adjustment information in each EU economy in pre- and post-crisis periods. Ad hoc public expenditure changes are distinguished from proposed fiscal adjustments to stabilize public debt. Results indicate that fiscal performances are better in the post-crisis than in the pre-crisis period. This finding may be attributed to numerous measures for fortifying fiscal policy in EU economies. The remainder of this paper is organized as follows. Section 2 reviews existing evidence in the empirical literature. Section 3 presents fiscal rules and a comparative analysis of the fiscal variables. Section 4 elaborates used methods and data, and Sect. 5 highlights econometric techniques. Section 6 discusses estimation results in the pre- and post-crisis periods using multicointegration analysis with heterogeneous parameters and robustness checks. Finally, Sect. 7 presents conclusions and policy recommendations.",
11.0,2.0,Eurasian Economic Review,16 January 2021,https://link.springer.com/article/10.1007/s40822-020-00159-w,COVID-19 and its economic consequences for the Euro Area,June 2021,Dirk Ehnts,Michael Paetz,,Male,Male,Unknown,Male,"The economic consequences of the shutdown in response to the COVID-19 pandemic are difficult to predict. The IMF (2020) in its World Economic Outlook from June 2020 expects the greatest worldwide downturn since 1930 and forecasts a contraction of the advanced economies by 8%. However, for the Euro Area (EA) the expected reduction in real GDP is even greater at about 10.2%. Compared to the global financial crisis (GFC) 13 years ago, governments and central banks all over the world have reacted swiftly. Without these interventions, the world economy would probably have collapsed. Nevertheless, the short-run negative economic impact of the pandemic is already bigger than that of 2008/09. It should be clear that a quick return to pre-COVID-19 policies in the EA would have devastating consequences for economic and political reasons. If governments would try to consolidate their budgets, as they did during the years after the financial crisis, a long-lasting depression is the most likely outcome. Yet, Southern European countries have already been in a bad economic shape before COVID-19. The unemployment rates in 2019 for Spain (14.1%), Italy (10.0%) and Greece (17.3%) were in the double digits, with a recession in Germany looming at the end of the year. In Greece and Italy, real GDP per capita was still lower in 2019 than in 2007. If forced to return to austerity measures, they might prefer to leave the Euro. Austerity policy cannot be successful within the next few years for the same reason it has not been successful in the past decade: It exacerbates the economic downturn and the substantial fall in income increases both public deficits and debt-to-GDP ratios. On a theoretical level, we recognize that unemployment is caused—ceteris paribus—by a lack of demand. Businesses are currently not constrained by the supply side, but by a general lack of spending. Over the medium term, the ECB (2020, 3) expects that “weaker demand will put downward pressure on inflation”. In contrast to the European Commission and Roeger et al. (2019), which believe that output gap indicators perform well, we believe that the rate of unemployment is a better indicator to understand whether the economy is reaching its limits. Given the relatively high unemployment rates in some EA countries, we believe there are quite a lot of idle resources available, including labor. We therefore recommend using the upcoming years to reconsider the macroeconomic policies in the EA. A Green New Deal (GND) including public employment would prevent a depression in the short-run and likewise improve the long-run economic prospects through a pioneering switch towards a sustainable production. Contrary to prevailing opinion, we do not believe that such policies are unavailable due to a lack of money. The pandemic causes painful real costs, in terms of losses in production and employment. However, the financial costs of the pandemic—losses in revenues of households, firms and the public sector—can be neutralized by increases in government spending. Instead of aiming at low public debt ratios, governments should therefore spend whatever it takes to keep demand at a level that is consistent with full employment. As long as the European Central Bank (ECB) cooperates with national governments, higher public deficits will not have any negative impact in our current constitutional setup—neither in the short nor in the long-run. On the contrary, cutting public spending would increase the real costs of the crisis and possibly feed right-wing anti-European forces (Funke et al. 2016). The paper is organized as follows. In Sect. 2, we illustrate the economic development of the EA after 2008 and carefully sketch the expected difficulties of the upcoming years. This is a challenging task, since we have not seen anything comparable to the current situation. The subsequent section separates the real from the financial costs that will occur during and after the pandemic, before Sect. 4 discusses the special institutional framework within the EA. From the preceding analysis, we will be able to derive short-term recommendations that are feasible within the current EA framework. In addition, we will present some medium-term reform proposals. The final section concludes.",21
11.0,2.0,Eurasian Economic Review,02 February 2021,https://link.springer.com/article/10.1007/s40822-020-00162-1,"The COVID-19 crisis in the EU: the resilience of healthcare systems, government responses and their socio-economic effects",June 2021,Katerina Aristodemou,Lucas Buchhass,Duco Claringbould,Female,Male,Male,Mix,,
11.0,2.0,Eurasian Economic Review,03 March 2021,https://link.springer.com/article/10.1007/s40822-020-00163-0,COVID-19: stress-testing non-financial companies: a macroprudential perspective. The experience of Poland,June 2021,Natalia Nehrebecka,,,Female,Unknown,Unknown,Female,"Initially, the COVID-19 epidemic affecting China accounted for differences in international value chains that were only of limited size. However, that local epidemic has since assumed pandemic form, transforming into a major economic shock-factor around the world, when it comes to the transactions of both businesses and consumers. In contrast, all previous global economic changes (not least the crisis of 2008–2009) had a financial background. Credit risk threatens the stability of the entire financial system, as has been seen with the recent crisis in the United States. This is particularly important in the context of the business sector. First of all, enterprises cover the majority of general loans, as opposed to consumer loans for the household sector. Secondly, at a time of constant threat of economic slowdown, and in a post-crisis period, it is worth paying attention to the sector in which the losses will be greater, and that is undoubtedly the enterprise sector. The International Monetary Fund (IMF) (2003) defines stress tests as a set of techniques used to measure the sensitivity of an entity’s financial portfolio to likely extreme events (Jones et al. 2004). Banks often have to explain the impact of an economic shock on risk parameters via the Basel II credit-risk framework (Basel Committee on Banking Supervision 2006, 2009). Under that, IRB banks must reflect an economic downturn in their risk parameters under Pillar 1 (Art. 177 CRR), or in line with the CEBS stress-testing guidelines (CEBS 2010), which require banks to consider a severe economic downturn in their calculations of internal-risk coverage under Pillar 2. Stress tests are used at every level of risk management at a bank, including through the Internal Capital Adequacy Assessment Process (ICAAP); as well as in the construction of capital plans. The exact objectives of sensitivity analysis are not clear to all units tested, but depend on the structure of the body. However, the general idea is similar and was defined by the Office of the Polish Financial Supervision Authority (2009; 2013a, b) as ensuring the financial balance of a plan in the event of adverse development scenarios. The running of tests should improve an entity's corporate management, and be treated as one of the main risk-management tools. It is worth noting that there is currently an interesting problem in Poland when it comes to tests of the banking sector. The process involved operates in such a way that each commercial bank individually defines the macroeconomic scenario, with the variables transferred to the PFSA differing fundamentally between them. If the assumptions and method of calculating parameters differ greatly, results are non-comparable from the very outset. It was expected that the current pandemic would cause capital ratios to fall significantly further than the results of stress tests would suggest in the case of major shocks. Data on the latter are not available publicly, and it would definitely be worth considering suggestions for a central body, e.g. the PFSA, to start preparing macroeconomic scenarios. The main purpose of this article is to detail and offer a stress-testing framework that investigates the impact of COVID-19 scenarios on the probability of default of non-financial companies (the new micro stress-test). The work has addressed both the uniform and the asymmetrical transmission of shocks, and considers these in relation with company size and sector of activity. The two scenarios considered are a baseline one for a hypothetical state that would have been observed without COVID-19, as well as an adverse scenario that takes the impact of the pandemic into account. To generate the stress tests, a general model was constructed using a two-step approach comprising microeconomic and macroeconomic modules. The former includes an internal rating system to estimate the probability of default (ICAS), while the macroeconomic module strives to capture the feedback effects from the macroeconomic stance into the banking sector, via the corporate-sector channel. Non-financial enterprises in Poland were assessed using data on banks’ large exposures to non-financial enterprises, financial statements, data from the National Court Register and balance-of-payment figures for the external statistics of enterprises. The proposed tool can be used in: (1) corporate risk assessment at sectoral and aggregate-economy levels; (2) the measurement of trends when it comes to the default rate in the corporate sector, with highlighting of the most reliable direction in which the NPL ratio is likely to move; (3) complementing the macro-prudential approach with a microeconomic perspective that calculates the portfolio put at risk by entities capable of exerting pressure on financial stability. The present study extends these approaches by: filling a gap in existing research, given that there has been a strong focus on the risk of bankruptcy of large international companies and the dominance of stress scenarios subject to regulatory criteria (among banks, insurers and other financial-market entities), and also given the way in which non-financial entities build rating classes, and expose the risk of loss of liquidity, which is different from the approach associated with values for prudential indicators being exceeded, addressing the circumstance in which the crisis caused by the proliferation of COVID-19 represents the first of a pandemic nature in recent history, leaving the process of forecasting especially difficult, proposing scenarios for stress tests related to the impact of COVID-19, studying a unique and comprehensive Prudential Reporting database detailing significant exposures of whole commercial banks to the corporate sector, using a microeconomic module, i.e. a model for the probability of default in the corporate sector, to quantify developments a year ahead, when it comes to the quality of banks’ corporate loans, using a macroeconomic (satellite) model, which assesses the relationship between macroeconomic variables and the risk parameter (the probability of default). An original contribution has been made in these matters and one that serves to expand upon existing research. Additionally, the proposed methodology can be used by banks and supervisory institutions, so it has major potential for use. The remainder of this paper is organized as follows. Section 2 presents the literature review, and Sect. 3 the methodology; while Sect. 4 covers data sources. Section 5 presents and discusses the empirical results, and Sect. 6 concludes the paper.",13
11.0,2.0,Eurasian Economic Review,26 February 2021,https://link.springer.com/article/10.1007/s40822-021-00167-4,Towards a more resilient European Union after the COVID-19 crisis,June 2021,Amélie Barbier-Gauchard,Meixing Dai,Jamel Trabelsi,Female,Unknown,Male,Mix,,
11.0,2.0,Eurasian Economic Review,28 April 2021,https://link.springer.com/article/10.1007/s40822-021-00171-8,US banks in the time of COVID-19: fresh insights from the wavelet approach,June 2021,Saeed Sazzad Jeris,Ridoy Deb Nath,,Male,Unknown,Unknown,Male,"On January 19, 2020, the Coronavirus pandemic (COVID-19) spread to the United States (Holshue et al. 2020). Over 9 million cases of infection and over 235 thousand cases of deaths were reported thereafter, as per the 30th October data of Worldometer (2020). In addition to the health crisis, the pandemic initiated a severe economic downturn in the nation. Economic downturn, caused by the rapid transmission of COVID-19 and the following oil price shock, is supposed to drive the national economy into its next recession. As the pandemic hit hard, the financial markets suffered a great damage. On February 27, Dow Jones Industrial Average (DJIA) witnessed its largest single-day point drop in the history and S&P 500 observed a 4.4% decline (Li 2020). Although significant rises were also observed in association with the government’s responses, the records of decline in stock market have been beaten several times since then. Nevertheless, the five major US banks observed the strongest results in nearly a decade, as trading levels and debt issuance increased amid COVID-19 (Fitch Ratings 2020). Volatility in the US stock market induced an increase in the trading activities, therefore, banks’ trading revenues jumped up to a significant scale. Additionally, the increased need for liquidity by corporations to survive in the economic shutdown gave rise to the debt issuance. Fitch Ratings (2020) reveal that Goldman Sachs enjoyed its greatest fixed income, currencies, and commodities trading revenues in the past five years and Bank of America had its strongest-ever equity-trading results. In addition to that, JP Morgan enjoyed a significant increase in the debt underwriting revenues, as it notched its best-ever investment grade debt issuances. However, the blessing of the increased client activity may prove to be momentary. Federal Reserve brought down its Fed funds rate to between 0.00% and 0.25% (Fitch Ratings 2020). Thus, a follow-up drop in short-term and long-term interest rates is supposed to hamper the bank profitability. Moreover, the decline in economic activity may also cause the banks a significant decline in profitability for several months, as Fitch Ratings (2020) reveal. Client activities are also supposed to drop, causing a fall in fee income, as corporate clients continue to pull back from the market. Therefore, the financial impacts of COVID-19 caused US banks to eventually project a downward fashion in profitability. However, how the US banks may react to the pandemic and how they can survive in the long run by maintaining a healthy profitability margin requires scholarly attention. As the pandemic continues, a lot of factors in the economy are supposed to affect the banks’ return. Prior literatures suggest some of these factors that influence bank performance. Ashraf and Shen (2019) studied the relationship between economic policy uncertainty (EPU) and bank loan pricing. They suggest a significant positive relationship between EPU and interest rates of bank loans. Francis et al. (2014) report that EPU increases the cost of loan contract between banks and US firms. A recent study conducted by Karadima and Louri (2020) suggest that EPU positively impacts bank NPLs. Additionally, Bordo et al. (2016) argue that EPU has a significant negative association with credit growth of banks. Another study conducted by Hu and Dong (2019) reveal similar findings. They suggest that banks’ credit growth is affected by EPU, but the effect may vary across banks. However, Jin et al. (2019) argued that EPU has a positive association with bank earning opacity. Although the relationship between oil price movements and stock performances is thoroughly addressed in the literature, the relationship between oil and bank performances is not well-addressed. However, Hesse and Poghosyan (2016) conducted a study on oil-price shocks and bank performance and reported a significant relationship between them. Khandelwal et al. (2016) studied the relationship between oil price and financial development. Their findings suggest a strong linkage between oil price and balance sheets of banks. More recently, Al-Khazali et al. (2017) investigated the relation between oil-price movements and bank NPLs and suggested that oil price movements affect bank stability in oil-exporting countries. Moreover, existing literature suggest that stock market volatility may also impact bank performances. Tan and Floros (2012) suggest that high level of volatility in stock market can lead to high return on equity (ROE). However, Rashid and Ilyas (2018) argue that volatility in stock market has significant negative impacts on return, assets and equity of the banks. Another stream of study reveals that investor sentiment influences the performance of banking sector in a country. Irresberger et al. (2015) argued that banks’ stock performance is significantly driven by investors’ “irrational market-wide crisis sentiment” and “idiosyncratic crisis sentiment”, especially during financial crisis. Another study conducted by Rashid et al. (2014) reveals that investor sentiment influences bank deposit in Malaysia. Despite the richness in the existing literature, the economic challenges posed by COVID-19 require new insights. Moreover, the importance of scholarly contribution in the finance literature regarding COVID-19 was extensively addressed by Goodell (2020). Although many prior studies address the economic impact of COVID-19 (e.g. Sharif et al. 2020; Jeris and Nath 2020; Zhang et al. 2020), Therefore, this study attempts to add to the literature by unveiling the banking industry condition in the time of COVID-19 pandemic. In this study, we use the Dow Jones US banks index and the S&P 500 banks index to proxy for banking sector performance. We address both the global and US COVID-19 infection cases reported daily to proxy for COVID-19. Additionally, we address the relationship between stock volatility and banking performance. We use the VIX index to represent volatility in US stocks. We use the WTI crude oil prices to analyze the association of oil prices with banking sector performance. Furthermore, we address the relationship between economic activity and bank performance. We use the Baltic Dry Index (BDI) to proxy for economic activity. Lastly, we address how the US EPU may affect the US banking sector performance. For this purpose, we use the popular EPU index developed by Baker et al. (2016). We use the wavelet coherence analysis in our study. Wavelet coherence analysis has been previously used by various scholars in economic research (e.g. Demir et al. 2020; Karabulut et al. 2020; Sharif et al. 2020). The rest of the paper advances as follows. Section 2 presents the data and methodology. Section 3 discusses the empirical results. Section 4 concludes and discusses the policy implications and future research areas.",12
11.0,2.0,Eurasian Economic Review,17 March 2021,https://link.springer.com/article/10.1007/s40822-021-00172-7,A survival analysis in the assessment of the influence of the SARS-CoV-2 pandemic on the probability and intensity of decline in the value of stock indices,June 2021,Beata Bieszk-Stolorz,Krzysztof Dmytrów,,Female,Male,Unknown,Mix,,
11.0,2.0,Eurasian Economic Review,05 May 2021,https://link.springer.com/article/10.1007/s40822-021-00173-6,Pan(dem)ic reactions in Turkish stock market: evidence from share repurchases,June 2021,Burak Pirgaip,,,Male,Unknown,Unknown,Male,"Stock markets that have already been showing a sharp declining trend for some time under the uncertainty of the COVID-19 outbreak, literally collapsed almost everywhere with the declaration of pandemic alert by the World Health Organization (WHO) on March 11, 2020. On that day, the “fire” spread very fast from one stock exchange to another. S&P500 suffered its quickest descent into bear market. Nikkei225 and FTSE100 plunged as much as 10%. In France and Germany, indexes cratered more than 12% and in Italy the figure was 16.9%. The “fear” also manifested itself in the surge of the CBOE Volatility Index, i.e. VIX, which hit historically highest levels.Footnote 1 The situation was even worse in many emerging markets. For example, MSCI Emerging Markets index lost 10.5%, while individually, South Africa and Brazil stocks closed down nearly 10% and 15%, respectively and circuit breakers were triggered in many markets including South Korea, Thailand and Philippines. The pandemic shock waves immediately spilled over into Borsa Istanbul, the Turkish Stock Exchange, as well. Turkey’s benchmark stock index closed the day with a 7.26% decline. In the aftermath of the pandemic designation, the stock market tried to achieve recovery to some extent by means of governmental actions, but the attempts were not worthy of note. The damage was so severe that the market experienced a further 8.07% decline on March 16, 2020 and reached its trough eventually on March 23, 2020 after consecutive days of falling prices. In these circumstances, some of the companies interestingly started to announce to buy back their shares as a preventive measure against plummeting prices. This was interesting for two reasons. One, although signaling or undervaluation is the most well-known motive attributed to share repurchases,Footnote 2 one might justifiably argue that the main motivation in these times of unprecedented turmoil, would rather be holding more cash (Pirgaip & Dinçergök, 2019). Indeed, repurchase actions in the vast majority of countries were canceled by the firmsFootnote 3 or restricted by the regulatory bodies.Footnote 4 Given this, it was somewhat contrary to the expectations in the market where investors were frustrated with the uncertainty regarding the COVID-19. Two, Turkish government, as part of an omnibus bill, emphasized the importance of the preservation of companies’ equities and imposed severe limitations on the amount of cash dividends.Footnote 5 Another common aspect of share repurchases is that they are substitutesFootnote 6 to cash dividends (Grullon & Michaely, 1992; Jiang et al., 2013; Skinner, 2008). Yet, the government did not intervene in share repurchase decisions of firms. Conversely, Capital Markets BoardFootnote 7 removed regulatory constraints on the share repurchase transactions for publicly listed companies on March 23, 2020 (CMB, 2020). This was contradictory in that a company, which would not be entitled to distribute a restricted level of cash, would be able to buy its shares back at the same amount. For these reasons, the recent share repurchase activity in Turkey is worth to be further investigated in order to explore the market reaction towards repurchase events under COVID-19 conditions. In this context, we employ an event study methodology to analyze the investor behavior. Empirical results suggest that repurchase transactions had significantly positive effects on stock prices. This finding is robust when repurchasing firms are compared with their non-repurchasing peers. The originality of the paper is twofold. First, our paper fills a gap in the contemporaneous work on firms and the COVID-19 crisis and contributes to the literature on how repurchases are used in distressed times. As we shall see in our literature review, to date, there has not been much research on the role of share repurchases in curbing the market downturn under uncertain conditions brought by COVID-19. But, we are of the view that the signaling power of share repurchases should not be ignored since they may serve as a credible tool for managers in conveying to investors that the true value of their firm is higher than its current market value (Hackethal & Zdantchouk, 2006), particularly in turbulent times (Stonham, 2002) such as the global financial crisis of 2008–2009 (Chen et al., 2018). In this regard, it is worth exploring why firms may have preferred to buy their shares back instead of holding cash for precautionary purposes. Second, most of the event studies carried out by researchers in the COVID-19 era has considered the stock market reaction around the date of events associated with various pandemic announcements. However, it was nearly impossible to set one clear point of time as the event date, which would probably obscure the source of price movements since there were multiple declarations regarding COVID-19 alongside with news on other notable developments such as the price war in the oil market, the trade war between the U.S. and China, and the U.S. presidential elections (Ashraf, 2020; Ramelli & Wagner, 2020). Our goal, rather, is to unveil the stock market reaction to a single and a specific corporate event, i.e. share repurchases, which took place as a response to the negative shocks posed by COVID-19 in the stock market. The structure of the paper is as follows. Section 2 outlines recent literature on the impact of COVID-19 on stock markets. Section 3 describes the data and methodology employed in the study. Section 4 presents the empirical results and Sect. 5 concludes.",4
11.0,3.0,Eurasian Economic Review,26 July 2021,https://link.springer.com/article/10.1007/s40822-021-00182-5,Efficiency in cryptocurrency markets: new evidence,September 2021,Carmen López-Martín,Sonia Benito Muela,Raquel Arguedas,Female,Female,Female,Female,"Efficient market hypothesis (EMH) is one of the main paradigms in corporate finance and one of the most widely used theories to study the behavior of prices in financial markets. This hypothesis is of paramount importance in the area of finance as many theories like Markowitz’s portfolio theory (Markowitz, 1952, 1959), the Capital Asset Pricing Model (Lintner, 1965; Mossin, 1966; Sharpe, 1964), the Arbitrage Pricing Theory (Ross, 1976) and the Black–Scholes–Merton option pricing model (Black & Scholes, 1973; Merton, 1973) have directly and indirectly originated from it. Efficient Market Theory is based on the original contributions from Samuelson (1965), Mandelbrot (1963a, 1963b, 1966), Malkiel (1992) and above of them Fama (1965, 1970, 1991, 1998). These authors propose that a market is efficient if the agents are rational and there is enough liquidity so any type of relevant information is included in the prices instantly, making systematic prediction impossible. More specifically, according to Fama (1970), a market is efficient if the current price of an asset fully reflects all available information. In an informationally efficient market, price changes must be unpredictable if they fully incorporate the information and expectations of all market participants. Depending on the available information included in the prices, three types of efficiency stand out (Fama, 1970): (i) Weak efficiency: asset prices reflect all historical information; (ii) Semi-strong efficiency: in this case, prices reflect both the historical and public information available on the assets and (iii) Strong efficiency: asset prices reflect all existing information (historical, public and private). If any investor had access to inside information, the price would adjust quickly, and would not allow them to benefit from that information. The financial academic literature has focused mainly on testing the weak-form efficiency which implies that the future price changes are purely unpredictable based on the asset’s price history. This is equivalent to say that the assets price follows a martingale model and/or a random walk. So that to test weak-form efficiency implies testing these models (LeRoy, 1989; Malkiel & McCue, 1985; Mills & Patterson, 2009).Footnote 1 Recently, the efficiency of the cryptocurrency markets has received increasing attention, especially the Bitcoin market,Footnote 2 see for instance, Urquhart (2016), Nadarajah and Chu (2017), Bariviera et al. (2017), Bariviera (2017), Tiwari et al. (2018), Wei (2018), Vidal-Tomás and Ibáñez (2018), Aggarwal (2019), and Köchling et al. (2019). The literature approach to this market is quite conclusive in terms of showing Bitcoin as an inefficient behavior in the beginning but evolving to greater efficiency over the time. For the other cryptocurrencies, the existing literature is somewhat reduced. See for instance, Caporale et al. (2018), Kristoufek and Vosvrda (2019), Charfeddine and Maouchi (2019), Zhang et al. (2018) and Hu et al. (2019) among others. All these papers conclude that the cryptocurrency markets are clearly inefficient although some of them point out that the inefficiency tends to decrease with the time. This is in line with the studies made by Brauneis and Mestel (2018) and Wei (2018). These authors analyze efficiency and liquidity of a large number of cryptocurrencies and, although there is a heterogeneous pattern of behavior, they find markets become less inefficient as liquidity increases. As the depth and liquidity of these markets increases their efficiency will tend to increase as well. As the behavioral economics point out, the market efficiency can be influenced by change in market conditions, the number of competitors, composition of investors, profit opportunities, and the risk–reward relationship. According to this, Lo (2004) proposed a new concept called adaptive market hypothesis (AMH); this author argues that financial markets are not static, but they change over time. As a consequence, the degree of efficiency may also change over time. Thus, the AMH entails the efficiency not only can adopt two states (efficient or inefficient) but even the level of efficiency varies over the time. Support in favor of the AMH can be found in Alvarez-Ramirez et al. (2018), Sensoy (2019), Zargar and Kumar (2019), Khuntia and Pattanayak (2018), Mensi et al. (2019), Chu et al. (2019) and Tran and Leirvik (2020). In line with this group of studies, this paper assesses the efficiency of the cryptocurrencies market from a dynamic perspective. The study improves and complements previous literature in several aspects: first, it is a new contribution in the incipient study of cryptocurrency analysis; secondly, unlike most of the papers focused on the study of Bitcoin, this study covers six of the most important cryptocurrencies by capitalization; and thirdly, unlike the most above-cited papers which analyze the efficiency in a static context, we analyze the efficiency in both a static and a dynamic context. The aim is to know whether the degree of efficiency of the cryptocurrency markets changes over time suggesting that the AMH is fulfilled. Unlike the papers aforementioned, we assess the robustness of the results obtained by considering four subsamples. In the static analysis and different size rolling windows in the dynamic analysis which notably contributes to enrich the study. To last, the paper ranks the markets analyzed in terms of efficiency. Our findings indicate that, in line with a literature trend, the efficiency of the cryptocurrencies markets tends to increase over the time. Second, although the efficiency market seems to change with the time, the changes in the Bitcoin, Litecoin and Ethereum market show a clear tendency that has evolved from less to more being currently efficient. In the case of Ripple, Stellar and Monero periods of efficiency alternate with periods of inefficient, being consistent with the AMH. This result opens the door to the possibility that, trend trading strategies may be used in certain periods to generate abnormal profits in the Ripple, Stellar and Monero markets. The rest of the paper is organized as follows. Section 2 presents a brief recent literature review on efficiency in cryptomarkets. Section 3 describes the methodology used in this paper; in this section we summarize the statistical test used to evaluate the market efficiency. Section 4 presents the data and empirical results and Sect. 5 ends with the main conclusions.",19
11.0,3.0,Eurasian Economic Review,05 July 2021,https://link.springer.com/article/10.1007/s40822-021-00180-7,Modeling Bitcoin price volatility: long memory vs Markov switching,September 2021,Walid Chkili,,,Male,Unknown,Unknown,Male,"The last decade has experienced an explosive development of cryptocurrencies including Bitcoin. Even more, Bitcoin is the most widely used cryptocurrency in the world. It is also the most capitalized virtual currency, with a capitalization of USD 138 billion in 2020Q1, which represents 45% of the total market capitalization.Footnote 1 In addition, the Bitcoin has received extensive attention among investors and portfolio managers. As a new financial asset, Bitcoin provides to international investors a more portfolio diversification opportunity and potential hedging strategies. It is worth noting that modeling and explaining the volatility of financial asset is a crucial mission in the sphere of financial markets. In this context, several studies have been carried in order to achieve accurate modeling of Bitcoin prices. The preliminary work conducted in this area use the GARCH-type models (see e.g. Chu et al., 2017; Katsiampa, 2017; Kochling et al., 2020; Lahmiri et al., 2018; Mensi, 2019). These studies have tried to include in their analyses all the stylized facts of time series such as volatility clustering, asymmetry, long memory and fat tails. Moreover, one of the main advantages of GARCH model is its ability to be combined with other types of model. Given that, the most recent studies apply a hybrid models that combine GARCH models with Markov switching in order to consider regime shifts in Bitcoin volatility (Aradia et al., 2019). The issue of the volatility spillover between Bitcoin prices and financial and commodity markets has been recently raised by several related studies (see e.g. Al-Yahyaee et al., 2019; Guesmi et al., 2019; Katsiampa, 2019; Pal & Mitra, 2019; Palazzi et al., 2020; Poyser, 2019; Stensas et al., 2019; Urom et al., 2020; Wang et al., 2019). The objective is to check the extent and the magnitude of volatility transmission between Bitcoin and other financial and commodity markets. In addition, the intention is to uncover the ability of Bitcoin to serve as hedge and safe haven against market risks. Guesmi et al. (2019) apply various multivariate GARCH models in order to explain the joint dynamic volatility of Bitcoin and financial indicators. They reveal that the DCC-GJR-GARCH is the best specification for modeling the volatility spillover between Bitcoin and different financial assets. Thus, insert Bitcoin in a portfolio composed of gold, oil or stocks reduces significantly the portfolio risk. Katsiampa (2019) uses the BEKK-GARCH model to explore the correlation and volatility dynamics of Bitcoin and Ether. Empirical results show that the volatility interdependence between the two cryptocurrencies is not stable and is considerably affected by major news. Urom et al. (2020) find that volatility spillovers between Bitcoin and other financial assets substantially strengthen during extreme global market movements. From a portfolio perspective and to achieve profitable diversification, investors, financial analysts and portfolio managers should opt to the appropriate model for volatility processes. Several studies point out that modeling and forecasting financial market is the pivotal task to accomplish profitable portfolio management and optimal hedging strategies (Degiannakis et al., 2018; Malepati et al., 2019; Mallikarjuna & Rao, 2019). Degiannakis et al. (2018) point out that investors and portfolio managers try to predict their future investment uncertainty in order to estimate the level of risk to accept, from which they choose optimal portfolio allocation and appropriate hedging instruments. Further, forecasting volatility is the most fundamental determinant for pricing derivatives. In this context, the accuracy forecasting of the expected volatility of asset allows to reach the correct derivatives contract. Malepati et al. (2019) emphasize that volatility is a fundamental risk measure in the area of empirical finance. In addition, it is used to quantify the financial market uncertainty, to estimate the value at risk and to perform asset pricing, portfolio allocation, asset valuation and risk management. The Bitcoin occupies nowadays special place in the area of finance. It provides for investors new opportunities of portfolio diversification. In this vein, modeling the volatility of Bitcoin market is becoming a requirement for all market participants and policy makers. In fact, any decision on portfolio management requires a better understanding of the price dynamics. This task is the main objective of our research in order to provide a clear conception to Bitcoin market volatility. This paper attempts to determine the suitable model to describe the volatility of Bitcoin returns. Despite the few studies that tried to investigate the properties of conditional volatilities of Bitcoin returns using various types of models, no one of these studies has attempted to specify the best model. The objective of the study is to fill the gap in the literature by considering long memory model and regime switching model simultaneously. Then, we specify the appropriate model for Bitcoin market volatility. Thereby, the volatility modeling is a pivotal task providing crucial information for international investors, risk-managers and financial analysts as regards portfolio allocation, risk management, security valuation and Value at Risk estimation. The remainder of the paper is organized as follows. Section 2 presents a short literature on Bitcoin price volatility. Section 3 explains the empirical methodology. Section 4 describes the data and provides some preliminary analysis. Section 5 discusses the estimation results of the considered models. Section 6 concludes the paper.",6
11.0,3.0,Eurasian Economic Review,21 July 2021,https://link.springer.com/article/10.1007/s40822-021-00181-6,Volatility spillovers and contagion between energy sector and financial assets during COVID-19 crisis period,September 2021,Achraf Ghorbel,Ahmed Jeribi,,Male,Male,Unknown,Male,"The COVID-19, which began in Wuhan, China, in December 2019, has rapidly evolved from a provincial health scare to a global meltdown, throwing the world to fear. According to the European Commission for Disease Control (ECDC 2020), this pandemic has now spread to more than 200 countries around the globe causing a severe global economic recession that began affecting the world on 20 February 2020. It is significantly worsened with the exceptional increase in the number of cases and deaths caused by this pandemic, as by the end of July 2020 more than 17 million cases of COVID-19, as well as 600.000 deaths, have been detected worldwide. Opinions about the COVID-19 pandemic are currently divided. Some research organizations believe that it could trigger another global financial crisis, while others believe that the impact of the pandemic, if not quickly stopped, could be worse than the outbreak of the SARS in 2003 in China, the 2008 global financial crisis, and the Second World War combined. The COVID-19 pandemic generated a human and health crisis. The required measures to contain the virus have resulted in an economic downturn. The International Monetary Fund’s rapport indicated that, on 14 April 2020, all the G7 countries have already reached a “deep recession”. The IMF has announced that global growth, which is estimated at −3% in 2020, is “much worse” than it was during the 2009 Great Recession. According to Salisu et al. (2020) and Ghorbel and Jeribi (2021a, 2021b), the exclusion of the oil-stock nexus study from other variables during the pandemic is intentional. As the COVID-19 pandemic rages, oil prices have fallen by 30 percent, the biggest decline since the Gulf War of 1991 (Schneider & Domonoske, 2020). Also, the collapse of oil prices caused by the 2020 Russia–Saudi Arabia oil price war opened a new battlefront for pandemic-battered economies. In the absence of a major Middle East conflict, Jefferson (2020) foresees that crude oil prices may be expected to recover by the third quarter of 2020. The negative economic consequences of this pandemic are significant for the G7 countries. There is a disruption in global supply chains. There is also a decline in demand for imported goods and services and a decrease in international tourism and business travel. We note that the global economy has become much more integrated if we compare this situation with the SARS outbreak in 2003. China, as the root of this pandemic, now plays a far more pronounced role in the industry, commerce, tourism, and FDI. China is now a manufacturing and a top power trade giant. The economic consequences of China’s negative shock would have a considerable impact on the global economy. Investors tend to look for new investment options that can deliver diversification and/or hedge benefits following periods of financial volatility experienced during the last decade. Financial markets have become more volatile and unstable due to the great uncertainty of the COVID-19 pandemic and its related economic losses (Zhang et al., 2020). At the beginning of the pandemic outbreak, Rizwan et al. (2020) and Gorbel and Jeribi (2021b) revealed a significant rise in systemic risk among the G7 countries. However, compared to the pre-COVID-19 period, China is showing some recovery. For decades and through various crises, the yellow metal has historically been viewed as a safe haven asset in periods of financial uncertainty (Bouri et al., 2020; Ghorbel & Jeribi, 2021a, 2021b; Jareno et al., 2020; Selmi et al., 2018; Vardar et al., 2018). Gold values have risen significantly since the global economic and financial crises, while other commodities have sustained declines (Beckmann et al., 2015; Fakhfekh et al., 2021). During the COVID-19 pandemic, Conlon and McGee (2020), Conlon et al. (2020), Ghorbel and Jeribi (2021a), and Jeribi and Fakhfekh (2021) found that, contrary to gold, Bitcoin does not serve as a safe haven for the S&P500. In the same line of results, Corbet et al. (2020), Ghorbel and Jeribi (2021a), and Jeribi and Fakhfekh (2021) found that both Bitcoin and Ethereum do not serve as a safe haven for international stock markets. Studying the relation between stock markets and oil prices and vice versa began with Hamilton’s (1983) work. Current pieces of Literature in this concern have expanded this research to the financial market and similar results have been identified (Arouri & Rault, 2010; Aydogan, 2017; Ghorbel & Jeribi, 2021b; Narayan & Gupta, 2015; Salisu et al., 2019). The latest instability in the global economy as a result of the COVID-19 outbreak has gained a great deal of interest, including the interaction among movements in oil prices, the economy, and stock markets. Ali et al. (2020) found that, unlike gold, crude oil has the highest volatility due to the COVID-19 pandemic and the regional disputes between oil-producing nations. However, Bakas and Triantafyllou (2020) and Albulescu (2020) suggested that the uncertainty surrounding the 2020 global pandemic had a significant negative effect on the volatility of commodity markets and, in particular, on the crude oil market, with a positive but less significant impact on the yellow metal market. After the announcement of the COVID-19 pandemic, Sharif et al. (2020) studied the connections between the shock of oil price volatility, the US financial market, geopolitical risk, and economic policy instability. They demonstrate that oil prices were influenced by the COVID-19 pandemic, which can be justified by imposed travel bans and OPEC + agreements. Salisu et al. (2020) developed a panel Vector Autoregressive (pVAR) model to evaluate the behavior of the oil-stock nexus during the COVID-19 pandemic. Their findings show a unidirectional causality from oil price returns to stock returns in the pre-COVID-19 period, while during the 2020 global pandemic, a bi-directional causality between crude oil price and stock returns is reported. Chang et al. (2020) examined the risk spillover effects of the energy sectors in the USA, Europe, and Asia stock markets during three types of global crises. Their results indicated that for low extreme oil returns during the coronavirus crises, investors are more likely to display herding in the stock market. In addition, during the 2020 global pandemic, investors panic so they may unwisely sell their financial assets. In the same line of research, Mazur et al. (2020) found that natural gas, healthcare, software, and food stocks earn high positive returns, whereas, petroleum, entertainment, real estate, and hospitality sectors stocks fall dramatically during the COVID-19 pandemic. Adekoya and Oliyide (2021) and Gorbel and Jeribi (2021b) show that the latter cited pandemic is responsible for risk transmission across commodity and financial markets. Contrary to gold, Ghorbel and Jeribi (2021b) found that Bitcoin cannot be considered as a safe haven during the global pandemic when investing in crude oil. Based on the above-mentioned studies, this paper extends the related literature and makes an original contribution in identifying the contagion between energy, traditional, and digital financial assets and indicates that Gold is a safe haven when investing in energy assets during the COVID-19 crisis. Bitcoin is considered a safe haven only when investing in the energy index. In this study, firstly, we apply the combined Markov Switching model and GARCH model on the G7 stock indices and the energy index (NYSE energy index), oil (WTI), gas (Henry Hub Natural Gas Spot Price), Bitcoin, and Gold prices. The choice of these countries is explained by the fact that they hold more than 2/3 of the world’s net wealth. In addition, they are the most affected by the COVID-19 (Amar et al., 2021). Secondly, we estimate the MSBEKK-GARCH model. Third, by using the MSDCC-GARCH model, we analyze the dynamic correlations between the studied assets to investigate the contagion effects of the COVID-19 pandemic. The layout of this paper is as follows. Our econometric methodology is discussed in Sect. 2. Section 3 is devoted to highlighting the relevant data and empirical findings. Finally, Sect. 4 concludes.",15
11.0,3.0,Eurasian Economic Review,29 July 2021,https://link.springer.com/article/10.1007/s40822-021-00177-2,Dynamic modeling of the impact of socio-economic restrictions and behavior on COVID-19 outbreak,September 2021,Mikhail Pomazanov,Artem Arkhipov,Alexander Karminsky,Male,Male,Male,Male,"In 2020, the world faced an unprecedented challenge in the form of a new coronavirus outbreak. One of the characterizing features of the outbreak is the difficulty in forecasting its size, and how to link the pandemic to containment measures. The pandemic became a trigger which activated the need to predict the dynamics of infections and their impact on social and economic processes and conditions. However, the available approaches to model these aspects of epidemics do not appear to be plausible solutions to the current situation. Among the classical epidemiological models, there are three main types of deterministic (parametric) models for infectious diseases that spread as a result of contact with a person in a population, which are well discussed in Hethcote (1989). The acronym SIR stands for a proportion of susceptible (or healthy) “S” people in the population, the proportion of infected “I”, and the percentage of recovered or dead “R” who are supposed to be immune, so that S + I + R = 100%. SIR is used for diseases where the infection provides permanent immunity. The second approach, SIS (susceptible-infected-susceptible), does not take into account immunity, so that S + I = 100%. The third type of model takes into account the natural birth and mortality rates in the population, so this type is focused on long-term modeling of epidemics. When a SIR outbreak happens over a relatively short time (less than 1 year), then this outbreak is called an epidemic. Since an epidemic is relatively fast, the model does not include birth and death dynamics. Epidemics are common in diseases such as flu, measles, rubella, and chickenpox. A good overview of non-parametric models is presented in Choisy et al. (2007). Classical parametric models cannot be used to describe the COVID-19 pandemic, as they have serious drawbacks, e.g. they do not take into account active administrative restrictions to prevent the spread of the epidemic. On the contrary, the parameters of infection distribution are assumed constant, which implies that diseases are left to spread on their own. According to empirical observations, modeling attempts are based on a set of assumptions, e.g. defining the epidemic as a time period when the number of confirmed cases increases exponentially, and defining the starting date of the epidemic at a date when a certain artificially chosen threshold (“zero”) level has been overcome, which in many cases is set at the first 100 infected people. The number of infected people at the end of the outbreak can ensure the slow speed of the increase in the total number of infected. The total share of infected people is a small proportion of the population, so S ≫ I + R, hence there is no sense to include immunity in the model (and thus SIR would not work properly). For the SIS approach there are solutions to differential equations in finite functions (the Bernoulli equation), yet it follows exponential growth at the beginning of outbreak only if the number of infected people does not tend to zero after the peak of the disease. The purpose of the paper is to build a model which would help in predicting the length and severity of COVID outbreaks in different countries on the basis of the relevant theoretical background, and to discuss reasons for deviations in the actual dynamics from the predicted path. Such a model and a discussion would provide valuable support to instruments of containment of this and other outbreaks, and would help to minimize the negative impact such outlying events might have on economies and lives. In Sect. 2, we propose a theoretical approach to modeling the number of those suffering from COVID-19 on the basis of the model developed in Volterra (1976) (which has never been applied to this type of problem) and substantially amended in Pomazanov (2020) to include the peculiarities of epidemic situations. In Sect. 3, we present a parametric contagion model that is being successfully tested for the Ebola virus epidemic. Data sources are described in Sect. 4. In Sect. 5, we consider the deviation from the static model. In Sect. 6, we compare and contrast the findings at the country level and try to identify the nexus between the easing of administrative restrictions and the chances of a second wave of the pandemic. In the last section, we develop an approach which could show how to deal with situations with high numbers of residual infections.",1
11.0,3.0,Eurasian Economic Review,20 May 2021,https://link.springer.com/article/10.1007/s40822-021-00175-4,Diverse effects of fossil fuel subsidy reform on industrial competitiveness in Thailand,September 2021,Anan Wattanakuljarus,,,Male,Unknown,Unknown,Male,"A number of studies assert that fossil fuel subsidy reform, energy taxes, and environmental taxes, such as carbon taxes, can lead to efficiency and encourage innovation, thus increasing competitiveness in the long run (Crespi et al., 2015; Kossoy et al., 2015; Porter & Van Der Linde, 1995), as implied by the Porter hypothesis (Porter, 1990) that properly designed environmental policies can stimulate innovation and production efficiency and may lead to an absolute advantage (Baranzini, 2000). However, multiple contradictory investigations point out that such initiatives can give rise to adverse effects on competitiveness, income distribution, and poverty in the short run (Callan et al., 2009; Cornwell & Creedy, 1996; Dorband et al., 2019; Kerkhof et al., 2008; Symons et al., 1994; Wier et al., 2005). In view of political economy challenges, the unfavorable short run effects of such programs during the reform transition are crucial for achieving long-term benefits (Di Bella et al., 2016; Dresner et al., 2006; Feng et al., 2018; Vagliasindi, 2012). A comprehensive body of literature, employing either partial or general equilibrium analyses, concentrates on fossil fuel subsidy reform, energy taxes, and environmental taxes on households’ related challenges, particularly household welfare, income distribution, and poverty (Coxhead & Grainger, 2018; Coxhead et al., 2013; Saelim, 2019a, 2019b; Soile & Mu, 2015; Wattanakuljarus, 2018; Yusuf & Resosudarmo, 2015). Nevertheless, the effects of such reforms on industries’ major concerns, particularly competitiveness, output performance, and cost effectiveness, have received scant attention from related literature in this area, as asserted by Rentschler et al. (2017), even as these effects remain central concerns of both public and private policymakers. Although the effects of these initiatives can be found in some studies at the firm or industry level (Bitat, 2018; Costantini et al., 2019; Godal & Holtsmark, 1998; Jaffe et al., 1995; Rentschler et al., 2017), they are considered only partial equilibrium analyses. To capture insights that encompass the whole context, the general equilibrium effects and the influences of structural economic characteristics of the specific economy in question should also be considered, as programs such as fossil fuel subsidy reform, energy taxes, and environmental taxes generally cause both direct and indirect impacts, hence necessitating an economywide perspective (Coxhead & Grainger, 2018). To fill this gap in the literature, this study endeavors to develop and apply an economywide model to capture critical structural economic characteristics, simulate general equilibrium effects, and convey ample insights on the impacts on key variables required to measure the effects of fossil fuel subsidy reform on industrial competitiveness. This study employs a simple nonparametric method for testing the monotonic association between related structural economic characteristics and the impacts on industrial competitiveness. This economywide industrial competitiveness model is then applied to assess the potential short run effects of fossil fuel subsidy reform, particularly diesel subsidy reform, on industrial competitiveness in the case of Thailand. Thailand, like other developing countries, applies fossil fuel subsidy measures to improve access to energy, protect the cost of living of vulnerable target groups, aid businesses, stabilize price fluctuation, and control inflation (Kojima, 2016; Marchan et al., 2017). Despite these efforts, these measures have been found inefficient for attaining intended benefits, and also generate unintended consequences, including underinvestment in the energy sector, fuel smuggling, wasteful energy consumption, increased air pollution and GHGs emissions, unsuitable investment decisions, and robust political resistance (Beaton et al., 2013; IEA, 2018; Rentschler & Bazilian, 2016). While advocating efforts to reform these programs, as declared in the National Climate Change Master Plan (2015–2050), Thailand is also considering approaches for mitigating the negative impacts of such reform and expanding support for all stakeholders, including households and industries, nationwide during the reform transition. Diesel, liquefied petroleum gas (LPG), and natural gas for vehicles (NGV) are major fuels in Thailand, and are greatly subsidized through various measures in order to cap the ex-refinery or retail prices for domestic consumption. Diesel largely benefits from the exemption of excise taxes and VAT in the amount of US$3.5 billion (1.4% of GDP); LPG benefits from market support prices in the amount of US$2.1 billion (0.83% of GDP); and NGV benefits from retail price cap in the amount of US$0.7 billion (0.27% of GDP) (ADB 2016; EPPO, 2018). Provided such notable statistics, the removal or revision of these fuel subsidies with the aim of improving economic efficiency should be anticipated to impact the entire economy. Focusing on the reform of only one type of fossil fuel subsidy in Thailand, this study examines the effects of a complete removal of diesel subsidies on industrial competitiveness, as it is the most used energy in the country and thus merits further examination on the potential effects of subsidy removal. Specifically, diesel has the highest proportion of usage, at around 19%, followed by electricity (from non-renewable energy) at 18%, natural gas (raw) 14%, natural gas (separated) 13%, crude oil 12%, and gasoline 6% (EPPO 2010, 2018). Diesel also holds the largest energy subsidy share, at 51%, which is composed of a diesel excise tax exemption of 47% and a diesel VAT exemption of 4%, followed by LPG at 30%, NGV at 9%, natural gas at 3%, and electricity at 2% (ADB 2016; EPPO 2010). Moreover, diesel combustion in Thailand carries a major threat of pollution and greenhouse gasses, with particulate matter less than 10 and 2.5 microns (PM10 and PM2.5, respectively) (PCD, 2020). As such, diesel subsidy reform is subsequently expected to improve air quality. The highest proportion of diesel use in Thailand, around 56%, is industry-related intra-national demand, followed by industry export demand, at 16%, household consumption at 14%, tourism at 9%, government consumption at 3%, and investment, at 3%. The industries with the highest demand for diesel are transportation, at 41% of diesel supply, followed by the energy sector at 20%, services at 9%, agriculture at 7%, manufacturing equipment at 5%, and chemical products at 4% (EPPO, 2010). Although investigation of removing all fossil fuel subsidies may have generated more insight, article space limitations did not allow for this. More importantly, the individual effects of any particular fossil fuel subsidy removal can be expected in the overall effects of any removal. Therefore, the diesel subsidy removal, given the statistics described above, was chosen as the main focus for further examination in this current study. The diesel subsidy removal was selected for in-depth analysis that is representative of the broader potential effects on competitiveness, output performance, and cost effectiveness of all fossil fuel subsidy removals. The rest of the fossil fuels are aggregated into the energy sector, which is included in the model. Future extensions to other fossil fuel subsidy removals can be accomplished as illustrated in this study. This study helps fill a gap in the literature by combining an economywide model with an industrial competitiveness model to identify how various industries are affected, quantifying the subsequent adverse effects that stifle competitiveness, and recommending strategies to alleviate negative impacts, while taking an economywide perspective into consideration. Ultimately, the findings of this study will aid policymakers in recognizing concerns regarding negative impacts to industry competitiveness, as it deconstructs the primary causes, as they represent a key political obstacle to fossil fuel subsidy reform and economic growth unless meaningfully addressed.",1
11.0,3.0,Eurasian Economic Review,13 March 2021,https://link.springer.com/article/10.1007/s40822-021-00168-3,Analysis of international trade integration of Eurasian countries: gravity model approach,September 2021,Anna Golovko,Hasan Sahin,,Female,Male,Unknown,Mix,,
11.0,3.0,Eurasian Economic Review,08 April 2021,https://link.springer.com/article/10.1007/s40822-021-00170-9,A hybrid econometric–machine learning approach for relative importance analysis: prioritizing food policy,September 2021,Akash Malhotra,,,Male,Unknown,Unknown,Male,"One of the most common requests made by economists to statisticians is for a measure of relative importanceFootnote 1 of independent variables in their econometric models. For example, health economists are interested in assessing the relative importance of various socioeconomic variables like income, wealth, social class, education etc. in determining health inequalities (Mondal and Shitan 2014; Kjøllesdal et al. 2010). Although there are no unambiguous measures of relative importance, standardized regression coefficients and zero-order correlations are often used to answer this question by researchers, but they have been shown to fail in considering both the effect the variable has by itself and in presence of other variables in the model (Johnson 2000). There are two approaches in statistics for making inferences from data: one assumes that data are generated from a given stochastic process and then builds the statistical model, while the other focusses on algorithmic models and treats the data-generating mechanisms as unknown (Breiman 2001). Econometricians tend to subscribe to the former and it is only recently that economists have started exploring algorithmic approaches. In this backdrop, I propose a hybrid approach based on a conflation of Machine Learning (ML) and conventional econometrics to assess the relative importance of independent variables. Here, I demonstrate the applicability of the proposed hybrid econometric-ML approach to already-established determinants of food inflation in India, where statistically significant independent variables are first identified through common econometric techniques, and those variables are then used in constructing an exploratory (no independent testing) model using machine learning techniques which provides an opportunity to quantify the relative variable importance. Unlike other domains of science, the adoption of ML in economic research has been sparse (Einav and Levin 2014) and slow, but now these techniques are being adopted in empirical work and are the topic of expanding methodological literature (Athey and Imbens 2019). ML techniques could potentially serve as a powerful econometric tool in estimating exploratory/predictive economic models on high-dimensional data (Varian 2014). In the future, ML is expected to become a standard tool of empirical research in economics as well as contribute to the development of economic theory. The development of new methods combining conventional econometrics and ML for solving traditional estimation problems in social science has begun (Athey and Imbens 2019; Storm et al. 2020) and this literature is expected to expand remarkably over the next two decades. The rest of the article is organized as follows: Sect. 2 presents the limitations of existing approaches in determining the relative importance of variables. Section 3 expounds on the hybrid approach central to this article. Section 4 illustrates the applicability of the proposed approach in assessing the relative importance of determinants of food inflation with appended takeaways for food policy in the Indian context. Section 5 concludes with caveats and suggestions for future research.",4
11.0,4.0,Eurasian Economic Review,07 March 2021,https://link.springer.com/article/10.1007/s40822-021-00169-2,Regional employment support programs and multidimensional poverty of youth in Turkey,December 2021,Eleftherios Giovanis,Oznur Ozdamar,,Male,Unknown,Unknown,Male,"Poverty continues to be acutely persistent, notably in developing economies. In 2006, the next generation of the economic, financial and social actors in the developing world is estimated to be around 1.3 billion young individuals aged 10–24 (World Bank 2006). Because human growth is a cumulative process, missed investment opportunities and preparedness for this generation will be extremely costly to reverse, not only for the youth but also for the entire society. It is well acknowledged that it is difficult for children to recover from early reverses. However, new conditions mean that governments in many developing, and in developed countries over the recent years, must address the needs of the older people, with the next generation problems of the growth of human capital among youth, if they want to strengthen and build on the gains made to date. Even in the poorest nations, increasing primary school completion rates have tremendously pressured higher education. While primary education spreads across the developing world, technological change requires from young individuals more than basic skills and fundamental abilities to compete effectively in the employment market. Changes in the political and civil society landscape that the developing world has experienced, especially over the last 10 years, have shifted the significance of citizenship, and with it what young individuals have to learn to take part in the community and the society efficiently. Given these facts, it is crucial to investigate the multidimensional poverty in the youth population. Poverty can be defined narrowly or more widely, depending on how well-being is understood. According to the narrow definitions, poverty is primarily expressed in monetary terms in relation to consumption and income (Haughton and Khandker 2009). The narrow aspect contains definitions which are usually consumption-related, such as whether people or households have sufficient resources to fulfill their demands. Broader definitions of poverty, however, also include quality of life dimensions and standards using non-monetary elements, such as life and job satisfaction; physical, mental health; access to energy, water, and clean air; social networks and links with friends, families, peers, and values, social norms among others. The traditional conception of poverty based on income and consumption has been criticized for neglecting the multidimensional nature of poverty and the significance for well-being of public services (Kanbur and Squire 1999; Hulme and McKay 2013). The human development approach, based on the theoretical foundations of the works by Sen (1999) and Nussbaum (2000), is an alternative to the narrow monetary definitions of poverty, and the UNDP’s Human Development Index is its best known practical implementation. Sen (1999) has stated that poverty can be seen as a deprivation of capacity or as an absence of substantial liberties that individuals love to have in order to live the kind of life they consider valuable, such as social functioning, better fundamental education, access to enhanced health care, and longevity (Kanbur and Squire 1999; Prasetyia 2019). However, the broader definitions of poverty have also been subject to criticism, especially regarding the difficulties entailed in measuring the poverty in a multidimensional aspect (Hulme and McKay 2013). Nonetheless, the multidimensional definitions of poverty are important because widening the definition of poverty changes it may shift significantly the way of thinking and the design of poverty reduction strategies (Kanbur and Squire 1999). Despite the reduction in monetary poverty Turkey has experienced since 2002, the multidimensional poverty level is still well above the EU average. Karadag and Saracoglu (2015) created two different indices to measure the multidimensional poverty level in Turkey and to compare it to the poverty of the EU countries. In their study, both measures have shown that Turkey has the highest poverty rates. According to their first measure, the poverty headcount ratio—the proportion of people that are poor—in Turkey was 43.2 percent and over two times of the average poverty headcount ratio in the EU at 18.1 percent in 2006. In 2012, the estimated poverty headcount ratio was 34.6 percent in Turkey and 15.2 percent on average in the EU. Based on the second measure, Turkey was the multidimensionally poorest country, both in 2006 and 2012, compared to the EU countries. Hence, the multidimensional poverty gap between Turkey and the EU was not closed during the period 2006–2012. The first aim of this paper is to develop a multidimensional poverty index only for the youth, using the most recent method (Alkire and Foster 2011). The measurements used to estimate the multidimensional poverty index (MPI) rely on various dimensions, and in particular, the education, employment skills, and health. Our main reason of focusing on the multidimensional poverty for youth in Turkey is twofold. First, the high level of economic growth rate in the last decade has failed to generate a significant growth in job creation. According to 2020 figures, youth unemployment rate between aged 15–24 years realized at 26.1 percent, almost double of the national unemployment level that is 13.2 percent. Second, at risk of poverty rate for the youthFootnote 1 was 44 percent in Turkey, while it was 29 percent in EU-27. Although unemployment and at risk of poverty rate representing monetary poverty level of the youth are statistically known, there has been no study that has measured the multidimensional youth poverty index. Regional poverty inequalities can be persistent, not only between the EU and Turkey but also within Turkey, and especially between the East and the West part of the country. To reduce poverty inequalities, governments often implement policies and interventions to encourage job creation and formal employment, particularly in the poorer regions, which are associated with lower salaries and standards of living, and greater levels of financial and social inequality that reduce the welfare of society. The Eastern part of Turkey is typically characterized by elevated poverty and material deprivation and low rates of investments in industry. One policy implemented in 2012 is the “Regional Investment Incentives Scheme” aiming at increasing jobs and investment. Thus, the second aim is to evaluate the impact of this scheme, which includes major employment subsidies and investment programs. The motivation of using these “exogenous” shocks created by this policy, lies in the fact it has not been systemically explored and its impact on education, labor outcomes, health and poverty, including the multidimensional poverty, remains unknown. Furthermore, the evaluation of the effectiveness of this policy can be considered for future applications in Turkey and other countries, and it may serve as an example for future policies and reforms that reduce inequalities and poverty. We analyze the effect of this policy specifically on the multidimensional youth poverty, since employment subsidies aim at creating new job opportunities. The rest of this paper is divided into four sections. In Sect. 2 we briefly present the main studies on poverty and employment support programs. In Sect. 3, the methodology and data employed in the empirical analysis are described. Section 4 reports the results, and in Sect. 5 we present the main conclusions of the study.",
11.0,4.0,Eurasian Economic Review,17 June 2021,https://link.springer.com/article/10.1007/s40822-021-00176-3,Joint estimation of intertemporal labor and consumption decisions: evidence from Spanish households headed by working men,December 2021,Antonio Cutanda,Juan A. Sanchis-Llopis,,Male,Male,Unknown,Male,"The empirical research on the elasticities of intertemporal substitution for leisure and consumption using the corresponding intertemporal Euler equations has provided disappointing results. On the one hand, the elasticity of intertemporal substitution for leisure using microeconomic data has traditionally produced very low estimates, as compared to the values used for this elasticity in the business cycle models (Keane, 2011; Chetty et al., 2011; Chetty, 2012). This discrepancy between the empirical evidence and the parameters considered in many theoretical macroeconomic models is a crucial question in the debate within both literatures and also for policy purposesFootnote 1 and has motivated a renewed effort to reconcile both facts (Chang & Kim, 2006; Rogerson & Wallenius, 2009). On the other hand, the estimation of the intertemporal elasticity of consumption have yielded quite poor results using macroeconomic data, and only those estimates using individual data provide positive and statistically significant values (see Hall, 1988; Thimme, 2016).Footnote 2 The elasticity of intertemporal substitution for leisure measures labor supply responses to wage changes, a key determinant for the internal organization of labor within a firm. Similarly, the elasticity of intertemporal substitution for consumption measures consumption responses to the real interest rate and determines the allocation in time of savings and consumption. Both parameters have relevant policy implications, given that they determine the response of leisure, and so working hours, or consumption, to changes in wages and prices, respectively, which might be modified through tax policies such as the VAT, the income tax or the social security contributions.Footnote 3 There are different ways to obtain an estimate for these elasticities that vary according to the assumptions adopted in their analytical derivation. In this paper, we will estimate the so-called Frisch elasticities for labor supply and consumption using Spanish microdata. Frisch elasticities are derived using life cycle models under the assumption that the marginal utility of wealth is constant. We consider this is the most accurate approach to analyze the behavior of labor supply and consumption along the life cycle.Footnote 4 However, the traditional methodological approaches to estimate these intertemporal conditions (for leisure and/or consumption) ignore that individuals decide jointly (and simultaneously) about their intertemporal labor supply and consumption profiles. This might be due to either the limited results obtained in the first attempts to tackle this issue (see Mankiw et al., 1985, for the US economy, or Cutanda, 2019, for Spain).Footnote 5 The joint analysis of labor and consumption decisions for the Spanish economy has been traditionally limited by data availability.Footnote 6 Thus, previous research has analyzed only one of the two decisions, specially the consumption decision, as Cutanda et al. (2020).Footnote 7 In this paper, we try to overcome these drawbacks by jointly estimating the first order intertemporal conditions of the individual optimization program with microeconomic data.Footnote 8 In recent years, the traditional empirical approach for the estimation of the elasticities of intertemporal substitution for leisure and consumption has experienced a new impulse as there are new attempts to estimate them. See for example Blundell et al. (1994), Imai and Keane (2004), or Attanasio et al. (2018), for the estimation of the elasticity of intertemporal substitution for leisure, or Thimme (2016), for the estimation of the elasticity of intertemporal substitution for consumption. Finally, there is also a renewed interest to study the effect of taxes both on consumption and labor supply, with the aim of explaining the different behavior of the U.S. and the European economies (see Silva, 2008).Footnote 9 In this paper, we provide new evidence for the elasticity of intertemporal substitution for leisure and consumption, by analyzing the complete system of intertemporal optimization first-order conditions. We estimate the log-linearized version of the Euler equations for the individual optimization problem. Attanasio and Low (2004) and Alan et al. (2009) demonstrate, using simulation techniques, that the elasticity of intertemporal substitution might be consistently estimated by log-linearized estimation procedures using sufficiently large datasets. We consider that our empirical work lies in this category as we use a long (pseudo) panel with 41 quarters. To jointly estimate the intertemporal labor supply and consumption decisions, implies using a data set with information on both individual consumption and hours worked (that would allow calculating wages). As there is not a microeconomic statistical source with these two basic pieces of information in Spain we will combine two available data sets that provide detailed information for these two variables. In particular, we combine the Spanish Family Expenditure Survey (the Encuesta Continua de Presupuestos Familiares, ECPF), that provides information on individual consumption and income, with information on individual labor supply from the Spanish Labor Force Survey (Encuesta de Población Activa, EPA). To combine these two data sets, we use pseudo-data panel techniques (Browning et al. 1985). Combining these two microeconomic data sets for Spain makes it possible to empirically analyze the intertemporal substitution of leisure and consumption. As regards the estimation results, we get estimates both for the elasticity of intertemporal substitution for consumption and leisure in line with the empirical literature (below one in both cases), using a sample of working men. In relation to consumption, we obtain an elasticity between 0.4 and 0.5, that is in line with Cutanda et al. (2020).Footnote 10 For leisure we also get a statistically significant estimate for the elasticity of intertemporal substitution, above 0.3. We consider this is significant given that Cutanda (2019) obtained a non-significant estimate using Spanish regional data. Our results are comparable to the estimates obtained for other economies (Altonji, 1986; Blundell et al., 2016; MaCurdy, 1981). Further, this is a relevant result given the controversy in the values traditionally used for this parameter in business cycle macroeconomic models.Footnote 11 One of the reasons explaining the relatively lower aggregate elasticity for intertemporal substitution in Spain might be related to the high persistence of the unemployment rate and the high rate of temporary workers.Footnote 12 The contribution of this paper is threefold. First, we add evidence to the intratemporal separability between consumption and leisure, as we estimate the two decisions jointly in a system. Considering this system, that combines the intra and intertemporal equations, involves assuming that the individual’s decisions on consumption and leisure are taken jointly. We consider that this evidence is key given that the standard tests of intratemporal separability between consumption and leisure are excess of sensitivity tests, considered weak tests for this hypothesis. Moreover, our estimates allow also detecting differences with respect to the results of the traditional approach in the literature, consisting of estimating the intertemporal decision as single equations. Second, we provide the first estimate of the elasticity of intertemporal substitution for leisure for Spain. The estimate we obtain is statistically significant and in line with the values estimated for other countries. And, finally, our estimate is based in microdata. This is quite relevant, provided that in previous works, the main reason behind not being capable to estimate this parameter was the availability of appropriate statistical data. The rest of the paper is organized as follows. In Sect. 2, we develop the theoretical model and discuss the main aspects related to the model. In Sect. 3, we present the data used and how we build the pseudo-panel data set. In Sect. 4, we report the results and in Sect. 5 we conclude.",2
11.0,4.0,Eurasian Economic Review,03 September 2021,https://link.springer.com/article/10.1007/s40822-021-00190-5,Correction to: Joint estimation of intertemporal labor and consumption decisions: evidence from Spanish households headed by working men,December 2021,Antonio Cutanda,Juan A. Sanchis-Llopis,,Male,Male,Unknown,Male,"In the original publication of the article, the author missed to provide the Acknowledgements. The Acknowledgements is given below in the erratum article: Acknowledgements This paper received the Best Paper Award in the 33 Eurasian Business and Economics Society (EBES) conference held in Madrid 2020. We are very grateful to the committee. We also thank two anonymous referees and the Editor for their helpful comments and suggestions.",
11.0,4.0,Eurasian Economic Review,04 July 2021,https://link.springer.com/article/10.1007/s40822-021-00179-0,Global production sharing and trade effects: an analysis of Eurasian Economic Union,December 2021,Sanjeev Vasudevan,M. Suresh Babu,,Male,Unknown,Unknown,Male,"The process of Eurasian economic integration starts with establishing a free trade area for the Commonwealth of Independent States in 1993 and, more formally, with the establishment of the Eurasian Economic Community in 2000 to create a single economic space (Khitakhunov et al., 2017). The Eurasian Customs Union (ECU), from 2010 to 2014, consisting of Belarus, Kazakhstan and Russia, forms the next major step towards integration. The ECU installed a Common External Tariff (CET) with other countries and eliminated all internal customs controls (Khitakhunov et al., 2017). The gradual removal of tariff and non-tariff barriers was the stated common goal of Eurasian integration. In contrast, the immediate effect of the ECU was a hike in the external tariff applied by the member countries, although the internal barriers lowered significantly (Hartwell, 2016). A robust form of integration was the Eurasian Economic Union (EAEU), formed in 2015, which included Armenia and the Kyrgyz Republic and the three members of the ECU. Despite its steady integration process, Eurasia has played a minor role in global production sharing and related trade in intermediate goods. Empirical studies state the lack of competitiveness in high-tech manufacturing as the prime reason for Eurasia's overall sluggishness compared to many other regions in the world. For instance, Falkowski (2017) showed that Eurasian countries have comparative advantages in medium and low technology manufacturing trade, and Belarus is the only country that holds higher Revealed Comparative Advantage (RCA) in high-tech manufacturing. In this context, the EAEU facilitates new opportunities to enhance production sharing, thereby intensifying the region's participation in the global trade of intermediate goods. Following the elimination of institutional barriers and reduced transaction costs, Eurasia's business environment has improved (Ustyuzhanina, 2016). As a result of these policy changes, foreign investment in these countries increased considerably (Balas et al., 2018). Foreign direct investment inflows within the Eurasian Economic Union have increased from $16.41 billion in 2015 to $37.15 billion in 2019. Similar values for Eurasia show that in 2015 foreign direct investment inflows amounted to $26.59 billion, and it increased to $51.03 billion in 2019. The motives behind attracting foreign direct investment range from gaining managerial technologies to accessing new markets that enable the Eurasian firms to engage in global value chains (Balas et al., 2018). Eder (2020) argued that one of the dimensions of industrial policies in the EAEU is integrating regional firms into global production sharing. The Eurasian region has shown a significant increase in intermediate goods trade for the last 2 decades. Between 2000 and 2019, Eurasia's intermediate goods trade increased from $43 billion to $291.23 billion. A substantial increase in the parts and components trade in the last 2 decades suggests that Eurasia has evolved as an active participant in global production sharing. An analysis of the trade effects of Eurasian integration on global production sharing is crucial in this context. As the most recent form of integration, we analyze the trade creation and diversion effects of EAEU formation on global production sharing in the region. Following the standard trade literature, we employ intermediate goods exports to measure production sharing between the EAEU countries and their partners. The sample period of empirical analysis is 2000–18, from the inception of the integration process. The study estimates a theoretically justified gravity model based on Anderson and Van Wincoop (2003). We estimate three models for EAEUs exports of intermediate goods, parts and components and final assembly. Based on the Standard Industrial Trade Classification Revision 3 (SITC, Rev 3), we define intermediate goods as the sum of 22 product categoriesFootnote 1 at 2-digit classification, exported by a country to a set of 39 partners, obtained from the United Nations Commodity Trade Statistics (UN Comtrade) database. Similarly, we identify 361 product groupsFootnote 2 as parts and components based on the 5-digit classification of SITC, Rev 3, to estimate the effect the formation of EAEU has on intra-bloc and extra-bloc trade patterns. The existing empirical literature on the trade effects of the EAEU provides mixed evidence. For instance, Blockmans et al. (2012) and Tumanyan (2018) highlighted the trade-diverting nature of the EAEU. However, country and sector-specific empirical analyses provide evidence to trade creating effects in the EAEU (Isakova et al., 2015). Our paper extends the existing literature on trade effects of economic integration agreements on global production networks by examining EAEU's impact on Eurasia's intermediate goods trade. We provide a comprehensive analysis of how the formation of EAEU has affected intermediate goods exports at the aggregate and disaggregate levels. The significance of our paper is that existing studies on the trade effects of Eurasian integration examined trade flows at the aggregate level (see, e.g., Blockmans et al., 2012; Isakova et al., 2015; Mogilevskii, 2012; Tumanyan, 2018; Vinokurov et al., 2015a). The review of existing literature shows that hardly any research has been conducted on the dynamics of global production sharing despite the region's notable performance in the last 2 decades. Our study fills this gap. The contributions of our paper to the existing literature are threefold. First, this is the first empirical analysis examining the trade effects of the EAEU, focusing explicitly on production sharing and intermediate goods exports at the aggregate and the disaggregate levels. Our analysis provides new empirical evidence on the trade creation effects of the EAEU in intermediate goods exports, unlike previous studies that concluded that Eurasian integration is trade diverting. We also find that the trade effects of EAEU differ between two stages of production sharing at the disaggregated level. Our analysis shows that the increase in intra-bloc exports of intermediate goods is sourced from increased intra-bloc final assembly exports, while trade diversion effects originate from parts and components exports. Second, our dataset is large in scope on multiple dimensions. Our sample period spans from 2000 to 2018, from the starting point of Eurasian integration to the latest year for which continuous data are variable. Hence, our analysis is based on the most recent dataset. In addition, unlike the previous empirical studies on the early impact of Eurasian integration, we include the new entrants, Armenia and the Kyrgyz Republic, along with all non-EAEU Eurasian countries in the empirical analysis. Based on the country-specific analysis, we show that the trade effects of EAEU on the member countries are heterogeneous. Third, we estimate an augmented gravity model using the Poisson Pseudo Maximum Likelihood (PPML) method to mitigate the potential issues of zero trade values, heteroscedasticity, endogeneity and multilateral resistance. In contrast, the previous empirical research on the trade effects of EAEU fails to provide robust estimates to these econometric issues aforementioned. The rest of the paper is structured as follows. In Sect. 2, we present a brief review of the empirical literature on the trade effects of economic integration. We review several studies specific to the Eurasian region to substantiate our contributions. Section 3 presents some stylized facts on the region's performance in production sharing. To examine the dynamics of production sharing comprehensively, we analyze the trends in intermediate goods at the aggregate level and in parts and components and final assembly trade at the disaggregated level. Section 4 discusses the data, variables, and empirical approach adopted in the paper. Section 5 discusses the empirical results in detail, followed by the conclusions and policy implications in Sect. 6.",
11.0,4.0,Eurasian Economic Review,22 July 2021,https://link.springer.com/article/10.1007/s40822-021-00174-5,A neutral core of degressively proportional allocations under lexicographic preferences of agents,December 2021,Katarzyna Cegiełka,Piotr Dniestrzański,Maciej Szczeciński,Female,Male,Male,Mix,,
11.0,4.0,Eurasian Economic Review,27 July 2021,https://link.springer.com/article/10.1007/s40822-021-00178-1,"Trade credit, trade income elasticity and the international transmission of shocks",December 2021,Anna Watson,,,Female,Unknown,Unknown,Female,"One of the prevalent features of international business cycle fluctuations which is difficult to reconcile with standard open economy macroeconomic models is the high volatility of imports and exports relative to output and strong procyclicality of international trade. The average elasticity of world trade to world income was estimated to be equal to 1.7 during the second half of the last century (Irwin, 2002) and 3.7 in the 2000s (Freund, 2009).Footnote 1 In contrast, a canonical international business cycle model implies trade income elasticity equal to one. While recent research has demonstrated that the high sensitivity of international trade to changes in output can to some extent be explained by the composition of international trade, vertical trade integration and inventory adjustment (Alessandria et al., 2010; Bems et al., 2010; Bussière et al., 2013; Eaton et al., 2016; Engel & Wang, 2011; Levchenko et al., 2010), the impact of financial factors on cyclical trade fluctuations is not well understood. This paper investigates whether and to what extent trade credit representing inter-firm lending contributes to the high volatility of international trade flows and the procyclicality of trade openness, measured by the trade to output ratio. The key contribution of this paper lies in its analysis of the impact of trade credit on cyclical fluctuations in international trade and the international transmission of shocks. The paper first provides new empirical evidence on the differences in the intensity of trade credit use by exporting and non-exporting firms based on financial data of 60,000 firms in the UK and Ireland. It shows that the percentage of firms supplying and receiving trade credit is higher among exporters than non-exporters and that firms engaged in international trade extend significantly more credit to their customers as a fraction of their revenues than firms serving only the domestic market. Secondly, the study introduces inter-firm lending and counterparty risk into an open-economy general equilibrium model with heterogeneous firms and the extensive margin of trade. It then examines how trade credit alters the transmission of shocks in the economy and the dynamics of international trade. Trade credit, which allows customers to delay payment until some time after delivery and is mostly associated with the purchase of intermediate goods, is one of the most important sources of short-term financing for firms (Demirguc-Kunt & Maksimovic, 2001; Petersen & Rajan, 1997; Rajan & Zingales, 1995; Kohler et al., 2000). Corporate surveys indicate that the majority of firms make the majority of their sales on credit (Wilson & Summers, 1997). Raddatz (2010) reports that in 60 percent of countries covered by Worldscope trade credit constitutes a more important source of short-term financing for firms than bank credit. Trade credit plays a particularly important role in facilitating international trade. It is estimated that between 80 to 90 percent of international transactions rely on some trade finance facilities (Auboin, 2009). According to the IMF/BAFT-IFSA Trade Finance Surveys, over 60 percent of these transactions are supported by trade credit (Asmundson et al., 2011).Footnote 2 While most empirical studies on trade credit do not distinguish between its use in domestic and international trade, Eck et al. (2012) demonstrate, based on German survey data, that companies that export their goods are significantly more likely to extend and receive trade credit than firms selling their goods only on the domestic market and they also have relatively larger average shares of transactions for which trade credit is given and received. There are a number of factors which may contribute to the relatively more intensive use of trade credit in international transactions. Firstly, due to the fact that international trade involves longer shipment times and additional time for the completion of cross-border administrative procedures,Footnote 3 it is associated with longer time lags between production and the receipt of sales revenues, including trade credit repayments. This leads to greater working capital requirements and it also increases the value of accounts receivable in proportion to annual sales revenues, which is the standard measure of the intensity of trade credit provision.Footnote 4 Secondly, exporters, which are on average larger and more productive than non-exporting firmsFootnote 5 tend to have better access to external finance and may be in a better position to supply trade credit to their customers.Footnote 6 Furthermore, Eck et al. (2012) show within a theoretical model, for which they find empirical support, that the widespread use of trade credit in international trade may be due to the inherently greater degree of uncertainty in international than in domestic transactions. Trade credit can reduce this uncertainty and alleviate the resulting financial constraints by serving as a quality signalling device. Trade credit exposes its supplier to a counterparty risk which has been shown to be substantial. Using French firm-level data, Boissay and Gropp (2007) show that defaults on trade credit are common—on average 19 percent of firms default at least once per quarter. The defaults faced by firms correspond on average to about 2 percent of their receivables. The average share of quarterly defaults in current liquid assets is as high as 44 percent—they can therefore constitute a major liquidity shock. Jacobson and Schedvin (2015) demonstrate using Swedish data that trade credit suppliers incur considerable trade credit losses due to trade debtor failures and that their bankruptcy risks increase with the size of the losses incurred. The authors find that 8.3 percent of firms face at least one trade debtor failure in a year and that firm failures impose larger credit losses on the corporate sector than on the banking sector. Bradley and Rubach (2002) and Bradley and Cowdery (2004) find that non-payment of trade credit by customers is one of the most important causes of bankruptcy among US firms. The high risk associated with trade credit is reflected in the relatively high cost of this type of financing. The discount rates typically offered for early payment, which can serve as a proxy for trade credit price, are equivalent to annual interest rates of over 40 percent (Boissay, 2006; Petersen & Rajan, 1997). Cuñat (2007) shows theoretically and empirically that the high interest rates on trade credit arise from the existence of a default premium and a premium for insurance against potential liquidity shocks, which the supplier provides for the customer. As the non-payment risk depends on macroeconomic conditions and changes over the business cycle, inter-firm lending can be expected to play a role in the propagation of shocks in the economy. In the model developed in this paper, macroeconomic shocks affect the default rate among firms and the fraction of trade credit which is not repaid. Changes in the riskiness of inter-firm loans lead to changes in their cost, which in turn alters firms’ marginal costs and prices. Due to the differences in the intensity of trade credit use in domestic and international transactions, macroeconomic shocks and the accompanying changes in the counterparty risk associated with inter-firm lending affect the domestic and foreign market price of traded varieties differently, which leads to changes in the relative price of domestic and imported goods. Macroeconomic shocks as well as the resulting changes in international relative prices affect the profitability of exports and induce changes in the fraction of varieties which are traded internationally. This causes further adjustment in the relative price of and the demand for domestic and imported goods and, in consequence, also in the volume of international trade. This study demonstrates that due to differences in the riskiness of international and domestic transactions, cyclical changes in the cost of trade credit amplify the impact of macroeconomic shocks on trade both along the intensive and extensive margins. The model generates trade income elasticities considerably larger than one and shows that inter-firm lending significantly contributes to the high volatility and strong procyclicality of international trade flows observed in the data. The remainder of the paper is organized as follows. Section 2 discusses related literature. In Sect. 3 new empirical evidence on the use of trade credit by exporters and non-exporters in Ireland and in the UK is presented. Section 4 outlines the model developed to account for the impact of inter-firm lending on cyclical fluctuations in international trade. Section 5 describes the calibration of the model parameters. In Sect. 6 the quantitative effects of trade credit on cyclical trade fluctuations and the international transmission of shocks are discussed. The last section concludes.",3
11.0,4.0,Eurasian Economic Review,04 August 2021,https://link.springer.com/article/10.1007/s40822-021-00184-3,Related bank deposits: Good or bad for stability?,December 2021,Aldy Fariz Achsanta,Tastaftiyan Risfandy,Herman Saheruddin,Unknown,Unknown,Male,Male,"The vast majority of literature on banks and their related parties has investigated the related party transactions in the form of lending. Banks' controlling shareholders tend to have a stake in non-financial firms that may potentially lead to a conflict of interest (Barry et al. 2011). Several studies have provided empirical evidence on how related party transactions can be harmful to minority shareholders or even taxpayers (Johnson et al. 2000; La Porta et al. 2003; Peng et al. 2011). Controlling shareholders also benefit themselves at the expense of minority shareholders or even taxpayers in the case of bailouts by conducting related party transactions. These transactions can take the form of ""tunneling,"" where controlling shareholders undertake a wealth transfer, or the form of ""propping,"" where the related party transactions are designed to save related firms during financial distress. In the case of ""tunneling,"" stakes in non-financial firms may prompt controlling shareholders to use their banks to lend money directly to their related parties. In most instances, these loans come with favorable terms such as lower interest rates, no collateral requirements, and longer maturity and grace periods compared to similarly risky loans granted to non-related parties (La Porta et al. 2003). Markets may also react negatively to a high volume of related party transactions when firms with high related party transactions are granted loans by banks, as minority shareholders are aware of the risk of expropriation (Bailey et al. 2011; Huang et al. 2012). Thus, loans granted are most likely based on a looting perspective instead of profit maximization that may reduce minority shareholders' wealth. With the growing assets generated by business groups, banks' controlling shareholders have the ability to improve bank stability via related deposits. Excess cash in their business group can be a useful propping tool for improving banks' stability. Moreover, controlling banks' shareholders benefit from financing their related parties and take advantage of easy access to funding from their related parties. Deposits tend to be a shield for banks from bank-run risk; banks with higher deposits have less funding liquidity risk, which reduces market discipline, and leads to greater risk-taking (Khan et al. 2017). On the other hand, banks with higher related deposits will have more incentive to take risks because they have enough funds, and they find it relatively easy to access funds from their related parties. Nys et al. (2015) found that politically connected banks are able to attract deposits more easily than their non-connected counterparts. However, holding a higher ratio of related deposits might not be good, especially for smaller banks, since the related depositors could withdraw their funds in a crisis or when they are in financial difficulty. Moreover, banks benefit from having easy access to related deposits during financial distress or a liquidity crisis to lower liquidity risk. Hence related deposits have the potential to be either harmful as it may encourage banks to take more risks or beneficial as related deposits can act as propping tools to improve banks' stability. This study also examined the impact of related deposit transactions on banks' risk-taking and financial stability by considering the ratio of related deposits to total deposits to capture dependency on deposits from related parties. To the best of our knowledge, few papers have focused on examining the effect of related party transactions in the form of related deposits. Our sample consisted of 90 Indonesian banks during the period 2009–2019. Habib et al. (2017) argued that Indonesia offers an interesting setting in related party transactions due to its unique institutional features. Our finding shows that variable related deposits scaled with total deposits (RDTD) and total assets (RDTA) significantly increase the z-score (denote as LnZROA). Our deeper investigation shows that when we split the sample based on size, we find that related deposits increase the z-score only for small banks. We also try to see whether market power could affect the relationship between related deposits and z-score. However, we find that no strong results showing market power affect the relationship between related deposits and stability. We contribute to the literature in several ways. First, we contribute to the literature on deposits by showing that banks may attract deposits from connected parties to bolster stability (Alamsyah et al. 2020; Ibrahim and Rizvi 2018; Martinez and Schmukler 2001; Nys et al. 2015b; Trinugroho et al. 2020). Secondly, to the best of our knowledge, this is the first paper to examine the role of related deposits. Our analysis, therefore, contributes to the literature of related party transactions providing evidence that related party transaction in the form of related deposit is regarded as beneficial where banks' ultimate owner may use it to prop up and bolster banks stability to maintain their soundness (Khanna and Yafeh 2010; Wang et al. 2019). Our evidences are of interest to policymakers and regulators in countries where related party transaction remains a concern. We provide insights and noteworthy policy implications for regulators to consider related party transactions in deposits to have better control over the behavior of banks' risk-taking, maintain the soundness of banks, and mitigate financial instability. The rest of the paper is organized as follows. Section 2 presents related literature. Section 3 describes our sample and defines our variables of interest. Section 4 presents our empirical result. Section 5 discusses our result. Section 6 concludes the paper.",1
11.0,4.0,Eurasian Economic Review,17 August 2021,https://link.springer.com/article/10.1007/s40822-021-00185-2,Financial connectedness of GCC emerging stock markets,December 2021,Ngo Thai Hung,,,Unknown,Unknown,Unknown,Unknown,,
12.0,1.0,Eurasian Economic Review,18 January 2022,https://link.springer.com/article/10.1007/s40822-021-00197-y,The value of political connections and Sharia compliance during the COVID-19 pandemic,March 2022,Budi Wahyono,,,Unknown,Unknown,Unknown,Unknown,,
12.0,1.0,Eurasian Economic Review,11 February 2022,https://link.springer.com/article/10.1007/s40822-021-00196-z,Depicting ethical dilemma in Islamic financial institutions; addressing the gender heterogeneity,March 2022,Shinaj Valangattil Shamsudheen,Aishath Muneeza,,Unknown,Unknown,Unknown,Unknown,,
12.0,1.0,Eurasian Economic Review,18 February 2022,https://link.springer.com/article/10.1007/s40822-022-00200-0,On the role of Islamic banks in the monetary policy transmission in Saudi Arabia,March 2022,Amine Ben Amar,,,Male,Unknown,Unknown,Male,"In 1933, Ragnar Frisch dissociated the analysis of the dynamics of economic fluctuations into impulse processes and propagation processes (Frisch, 1933). Impulses occur irregularly, but when they occur, a propagation process transmits their effects through the economic system. Contemporary economists replace “impulse” with “shock” and “propagation” with “transmission” (Meltzer, 1995, p. 49) and define the monetary policy transmission mechanism as “the process through which monetary policy decisions are transmitted into changes in real GDP and inflation” (Taylor, 1995, p. 11). Although all the theories on monetary policy transmission mechanisms share the view that (1) central banks can, through their central bank money supply monopoly, regulate and control money market interest rates and thereby influence the prices of a wide range of assets, and (2) the presence of nominal rigidities prevent prices from adjusting fully in the short term, the consensus on the mechanisms through which monetary policy would affect the behavior of households and firms is less clear.Footnote 1 Indeed, the effectiveness of monetary policy transmission mechanisms depends on the structure of the financial systems through which changes in key rates are transmitted to the real economy and the economic conditions of each country. Since economic conditions and the structure of financial systems in different countries are far from being the same, transmission mechanisms are likely to differ in their importance from one economy to another (Mishra & Montiel, 2012; Van Els et al., 2001). To describe the link between the monetary sphere and the real economy, Brender and Pisani (1997, p. 75) note that “fluctuations in the level of nominal short-term rates—monetary policy—are easy to observe. Through several mechanisms—the transmission channels of monetary policy—these nominal fluctuations induce real fluctuations over time. Their effect, however, depends on […] anticipated inflation”. Thus, understanding the mechanisms through which output and price respond, with some time lag, to monetary shocks enables monetary policymakers to act in a timely and appropriate manner. The transmission channels of monetary policy, although they differ from one economy to another, can be classified into two categories: neoclassical channels and non-neoclassical channels (Boivin et al., 2010). The former, developed during the second half of the twentieth century, are based on models of investment (Hall, 1977; Hayashi, 1982; Jorgenson, 1963, 1972; Tobin, 1969), consumption (Ando & Modigliani, 1963; Brumberg & Modigliani, 1954; Friedman, 1957; Modigliani & Brumberg, 1979) and international trade (Bordo & Schwartz, 1988; Fleming, 1962; Meade, 1951; Mundell, 1963a), and they analyze the influence that monetary policy can have on the components of output (consumption [wealth effects channel],Footnote 2 investment [interest rate channel and Tobin's q theory] and net exports [exchange rate channel]). As for the non-neoclassical channels, these owe their appearance to imperfections in the market, and they analyze the role of these imperfections in monetary transmission. They include the bank credit channel (Bernanke & Blinder, 1988; Blinder & Stiglitz, 1983;Footnote 3 Sudrajad & Hübner, 2019), the balance sheet channel (Bernanke & Gertler, 1995a; Dell' Ariccia and Marquez, 2006), the bank capital channel (Bernanke, 2007; Blum & Hellwig, 1995; Moudud-Ul-Huq, 2019; Van Den Heuvel, 2002a, b; Van Den Heuvel, 2007a, b), and the risk taking channel (Acharya et al., 2010; Adrian & Shin, 2009; Borio & Zhu, 2008; Gambacorta & Marques-Ibanez, 2011). Central Bank indirect control of interest rates is the monetary policy regime currently used in most countries. There is therefore an inconsistency between one of the main principles of Islamic finance, i.e. the prohibition of riba, and the conduct of monetary policy within a conventional framework. Although the literature on monetary policy transmission mechanisms in conventional finance is abundant (see Boivin et al., 2010 for a review), the study of the role of Islamic banks in monetary policy transmission has been the subject of very few empirical investigations (e.g. Ben Amar et al., 2015; Di Mauro et al., 2013; Hamza & Saadaoui, 2018), despite the rapid growth of the Islamic banking industry. Therefore, the purpose of this paper is to empirically investigate the role of Islamic banks in the monetary policy transmission process in Saudi Arabia. In two articles published in 2005 and 2008, Muhammad Al-Jasser, former governor of the Saudi Arabia Monetary Agency (SAMA), and Ahmed Banafe attempted to expose, analytically, the transmission mechanisms of monetary policy in Saudi Arabia. They consider in their analysis that the bank credit channel is potentially the only channel that plays an important role in the transmission of monetary policy. Also, Al-Hamidy (2011) believes that the interest rate channel is marginal in Saudi Arabia and that an increase in the real interest rate is not likely to contain inflation because, in his view, the weight of credit relative to GDP is relatively small. There are essentially three reasons why this should be put into perspective. First, and contrary to Al-Hamidy's (2011) claim, the ratio of bank credit to GDP has improved since the 1970s, which could improve the effectiveness of monetary policy (Westelius, 2013). Second, for the study of transmission to be relevant, it is necessary to analyze the structure of value added in Saudi Arabia in order to understand to which compartment of economic activity monetary policy shocks are transmitted (Ben Amar et al., 2015).Footnote 4 Third, economic theory suggests that Saudi monetary policy is, at least in part, non-autonomous. Indeed, given its largely liberalized capital account and fixed exchange rate regime against the US dollar, SAMA's interest rate policy is de facto dependent on the Fed's. Therefore, improving the synchronization between Saudi Arabia's economic cycles and those of the United States is likely to improve the effectiveness of SAMA's interest rate policy. The results found in the empirical literature on the transmission of monetary policy in Saudi Arabia are concordant and, contrary to the analysis of Al-Jasser and Banafe (2005, 2008) and Al-Hamidy (2011), suggest that interest rate and bank lending channels appear to play an important role in the transmission process of monetary policy (e.g. Cevik & Teksöz, 2012; Espinoza & Prasad, 2012; Prasad & Khamis, 2011; Westelius, 2013). These results are somehow expectable since the effectiveness of the bank lending channel requires banks to play an important role as a source of external funding for the private sector (Bernanke & Gertler, 1995a), a condition which, a priori, is likely to be verified in emerging and developing economies with underdeveloped capital markets. Indeed, credits to non-financial agents in Saudi Arabia are mainly provided by the banking system and by specialized credit institutions sponsored and controlled by the government.Footnote 5 For instance, Prasad and Khamis (2011) use a panel VAR model to study the effects of US monetary policy on GCC activity and inflation over the period 1978–2009 (annual data). They find that the U.S. Federal Reserve's monetary policy has a significant influence on the money supply (M2), non-oil activity, and inflation of GCC countries. Following Bernanke and Blinder (1992), Cevik and Teksoz (2012) estimate an SVAR model over the period 1990–2010 (quarterly data) to study the importance of different monetary policy transmission channels in GCC countries. They find that the interest rate channel and the credit channel play a relatively important role in the transmission of monetary policy, while the exchange rate does not play a significant role. These results are in line with the results of Espinoza and Prasad (2012). Cevik and Teksoz (2012) suggest that strengthening financial intermediation and facilitating the development of domestic capital markets would improve the effectiveness of transmission mechanisms in these countries. Ziaei (2012) studies the transmission channels of monetary policy in Saudi Arabia using a structural VAR (SVAR) model estimated over the period 1992–2007 (quarterly data). It shows that shocks to the Saudi three-month interest rate explain a significant part of the variability of Saudi GDP, and that most of this variability is transmitted through the credit channel. This result can be explained by the fact that in developing countries, the financial system is dominated by the banking sector whose main function is to collect deposits and grant credit. Westelius (2013) uses a VAR model to study the relationship between bank credit and non-oil economic activity in Saudi Arabia over the period 1980–2010 (annual data). In order to test for the presence of structural change, i.e. to check whether the influence of bank credit on non-oil activity has changed over time, the author splits the sample into two sub-periods: 1980–1995 and 1996–2010. He chose these two sub-periods because the correlation between the Saudi business cycles and those of the US and Asian countries improved from the mid-1990s onwards. The results found show that the role of bank credit in the transmission of monetary policy improved over the period 1996–2010, while it was almost ineffective over the periods 1980–2010 and 1980–1995. More recently, Bilgin et al. (2020) examine the impact of economic uncertainty on the credit growth of Islamic and conventional banks in 12 countries. Their results indicate that an increase in economic uncertainty significantly decreases the credit growth of conventional banks but does not have a significant impact on the credit growth of Islamic banks, especially in (1) countries with an explicit deposit protection scheme for Islamic banks, (2) countries with low foreign dominance, and (3) countries with higher deposit and asset shares in Islamic banks. However, the literature does not provide empirical evidence of the dynamic structure of the underlying economy. Thus, to analyze the transmission channels of monetary policy in Saudi Arabia, we use a time-varying VAR model with drifting parameters and stochastic volatilities (Primiceri, 2005), which enables us to capture possible nonlinearities in the underlying structure of the Saudi economy and provides us a diagnosis on the persistence of shocks as well as their variance. Our findings (1) support the dependence of Islamic banking activity on oil revenues, which is consistent with the analysis of Mohieldin (1997) and Gazdar et al. (2019), and (2) suggest that, in the medium term, conventional and Islamic banks respond in the same way to interest rate shocks, which suggest that, in practice, there are few differences between the Islamic banks’ modus operandi and the methods used by conventional banks, which is consistent with the results of Cihak and Hesse (2010), and Azad et al. (2018). Moreover, our results do not provide clear evidence that Islamic banks are more stabilizing than conventional banks, which is consistent with the results of Johnes et al. (2014), Beck et al. (2013), and Bitar and Peillex (2018). The rest of the paper is organized as follows. Section 2 analyzes the structural features of the Saudi economy. Section 3 examines the structure of the Saudi banking system. Section 4 presents the empirical strategy. Section 5 outlines results and their economic interpretation. Section 6 discusses the main results of the paper brings practical recommendations. Finally, Sect. 7 highlights the main conclusions and practical recommendations.",1
12.0,1.0,Eurasian Economic Review,14 February 2022,https://link.springer.com/article/10.1007/s40822-022-00198-5,How do the global equity and bond markets affect Islamic and conventional banks? A comparative cross-country analysis using multivariate regression quantiles,March 2022,Resul Aydemir,Huzeyfe Zahit Atan,Bulent Guloglu,Male,Unknown,Unknown,Male,"Financial crashes and spillover effects over global markets are of increasing interest in empirical finance literature recently. During the 2008 recession, the United States stock markets adversely affected global markets as major global indices fell down to record low levels. For example, the Dow Jones industrial index hit an historical low return with 777.68 basis points on 29 September 2008, while the MSCI index recorded 53.18 percentage loss. These shocks in major financial markets like the United States have significantly affected other stock markets during the last decade. (Chulia et al., 2017). As the frequency of financial crises has forced international investors to seek out alternatives for risk diversification, interest-free Islamic banking as an alternative to conventional banking has started to attract attention from academics as well as policy makers. Many researchers find that Islamic banks were not affected by the adverse conditions conventional banks faced during the 2008 crisis due to several factors. (Boumediene, 2010; Boumediene & Caby, 2009; Hasan & Dridi, 2011). However, recent evidence suggests that Islamic financial institutions might have lost this advantage over interest-based financial system and economic environment has become less favorable for Islamic finance as systemic risks tend to rise. (IFSB,Footnote 1 2017). This paper aims to investigate the Islamic banking system’s stability to financial risk spillovers and compare it with the conventional banking system. Using multivariate quantile autoregressive model, we look at financial risk spillovers that may occur in major financial indices to banks’ equity prices. The model provides an ideal setting to assess directly the responsiveness of value at risk (VaR) of a bank to shocks (Acharya et al., 2010; White et al., 2015). Bank equity price provides information about overall performance of a bank’s management and its cost efficiency (Beccalli et al., 2006; Ionnidis et al., 2008). Moreover, if a bank which performs poorly in terms of its stock price in a crisis, then it fails to act cautiously and is more likely to perform badly in upcoming crises (Fahlenbrach et al., 2012). Therefore, investigating bank equity returns is important for understanding its current cost efficiency and future performance during a crisis among other things. To analyze the nexus between major global financial indices and bank equity prices of dual banking system, we measure the 1st quantile of several indices including the Dow Jones US Index (a proxy for the overall US stock market), the MSCI World Index (a benchmark for global stock funds representing a broad cross-section of global markets), the US 10-year Treasury bond interest rate (a proxy for global interest rates) and the Volatility index (the fear index capturing the US stock market volatility) with multivariate quantile model. Producing pseudo impulse response functions (PIRFs), multivariate quantile models enable us to compare a financial shock’s impact on different kinds of banks. We know that Islamic law jurisdictions vary significantly by regions. Therefore, Islamic financial tools exhibit some heterogeneity across regions which may result in different risk concepts for each country (Ernst and Young, 2013). Differences in Shariah governance practices across countries can be identified as strict, moderate and flexible approaches in developing regulations for Shariah governance structure and processes. For example, Islamic banks operating in countries which adopt moderate and flexible approaches are likely to be more varied in terms of Shariah governance practitioners and practice to ensure Shariah compliance as opposed to those Islamic banks in countries with strict approaches (Fatmawati et al., 2020). Meanwhile, institutions such as Accounting and Auditing Organization for Islamic Financial Institutions (AAOIFI), IFSB recently published general standards for global Islamic banking system that is intended to reduce this heterogeneity across regions. We compare dual banking system not only at the global level, but also across different regions (i.e. MENA, Gulf and Asian countries) to figure out whether there exists any heterogeneity between Islamic banks in terms of their performance. The remaining of the paper is arranged as follows. Section 2 briefly touches upon the background of the interest-free Islamic banking system and its main differences with the conventional banking system. Section 3 presents the literature about comparative studies between dual banking system. Sections 4 and 5 describe the multivariate quantile regression methodology and data, respectively. Finally, Sect. 6 summarizes the empirical findings before discussion and conclusion in Sect. 7.",
12.0,1.0,Eurasian Economic Review,16 February 2022,https://link.springer.com/article/10.1007/s40822-022-00201-z,Proposed model of integrated Islamic commercial and social finance for Islamic bank in Indonesia,March 2022,Ascarya Ascarya,Ugi Suharto,Jardine A. Husman,Unknown,Unknown,Unknown,Unknown,,
12.0,1.0,Eurasian Economic Review,29 January 2022,https://link.springer.com/article/10.1007/s40822-021-00195-0,Market discipline and capital buffers in Islamic and conventional banks in the MENA region,March 2022,Rihab Grassa,Nejia Moumen,Khaled Hussainey,Female,Unknown,Male,Mix,,
12.0,1.0,Eurasian Economic Review,09 February 2022,https://link.springer.com/article/10.1007/s40822-022-00202-y,"The links between gold, oil prices and Islamic stock markets in a regime switching environment",March 2022,Walid Chkili,,,Male,Unknown,Unknown,Male,"The relationship between stock and commodity markets has been extensively examined during the last two decades. Even more, most of research has focused on the links between conventional stock markets and crude oil and gold prices. This interest has swiftly grown in recent years with the instability of the oil and financial markets owing to the emergence of several political and economic events. Therefore, understanding the linkages between these markets and specifying their evolution over time can provide important implications for international investors, risk-managers and policy makers. Large number of studies has been carried to uncover the connectedness between oil and stock markets. In this vein, various econometric models have been applied in order to test the volatility spillover between the two markets and to derive the diversification opportunities between them (see inter alia Filis et al., 2011; Chkili et al., 2014; Boubaker & Raza, 2017; Mokni & Youssef, 2019; Sakaki, 2019; Gomez-Gonzalez et al, 2021).Footnote 1 In addition, some researches try to check the validity of the oil market financialization hypothesis. They find that fluctuations of stock returns can impact oil returns suggesting the financialization process of crude oil market (Creti et al., 2013; Gomez-Gonzalez et al, 2021; Kolodziej et al., 2014; Olson et al., 2014; Zhang et al., 2017). The issue of the role of gold as a hedge and safe haven for stock market goes back to the seminal paper of Baur & Lucey (2010). According to the authors, an asset is regarded as a hedge during a given period if it is negatively correlated or uncorrelated with another asset on average. While, an asset is considered as a safe haven if it is negatively correlated or uncorrelated with another asset in times of extreme markets movements. Afterwards, several studies have been developed to investigate the sort of relationship between gold and various financial markets including stock, foreign exchange and bond markets (see eg. Baur & McDernott, 2010; Coudert & Raymond-Feingold, 2011; Ciner et al, 2013; Reboredo, 2013a; Chkili, 2016; Wen & Cheng, 2018; Izadi & Hassan, 2018; Vardar et al, 2018; Shahzad et al., 2020; Uddin et al., 2020). More precisely, these researches attempt to check the role that can play the gold as a hedge and safe haven for these markets and to uncover any beneficial diversification opportunity between them. Uddin et al. (2020) examine the risk spillover between US stock market and precious metals and oil. Using the copula approach, they find weakly spillover effect from gold to US stock market indicating that international investors can use this precious metal as an equity portfolio diversifier. Shahzad et al. (2020) reveal that gold can be regarded as indisputable safe haven and hedge for several G7 stock indices. Roboredo (2013a) tests the ability of gold as hedge and safe haven for USD exchange rate variations. Empirical results point out on the one hand that gold can serve as a hedge against USD rate movements. On the other hand, gold can be considered as an effective safe haven against extreme USD rate downturn. Recently, this topic is extended to the nexus between gold and other commodity prices, with special attention is paid to crude oil market. In this vein, Roboredo (2013b), Chkili (2015), Tiwari and Sahadudheen (2015), Salisu et al. (2020), Salisu and Adediran (2020), Saadaoui et al. (2020) and Adekoya et al. (2020) among others examine the hedge and safe haven potential of gold against oil price fluctuations. Roboredo (2013b) suggests that gold exhibits safe haven qualities against oil price movements. Salisu et al. (2020) assess the possibility of using gold as hedge and safe haven against oil price risks using the asymmetric VARMA-GARCH model. They conclude that gold can act as a significant safe haven against oil price fluctuations namely during the COVID-19 outbreak. It is worth noting that a great interest has been addressed during the few recent years towards the Islamic finance area. This interest is due to the risk-hedging alternatives and investment opportunities offered by the Islamic financial markets to portfolio managers, financial analysts and investors. Thereby, the Islamic capital markets have grown rapidly, achieving a growth rate between 19 and 23% at the end of 2017 (IFSI, 2018).Footnote 2 The reasons for this fast growing are the strong investment in the halal sectors and the raise in demand for products complying with the principles of the Islamic law (or Sharia).Footnote 3 In addition, the competitive nature for some of these products has attracted both Muslim and no Muslim investors. Given the importance granted to these markets, it is interesting to analyze the extent of information transmission between these markets and other asset classes such as gold and crude oil as well as the potential diversification benefits between them. This paper contributes to the existing literature in three ways. Firstly, this paper investigates the relationship between Islamic stock market and two major commodities namely crude oil and gold. The main objective is to verify on the one hand the financialization process of the crude oil market through the analysis of the correlation between the oil and Islamic equity index. On the other hand, to test the role of gold as a hedge and safe haven against the oil and Islamic stock market movements. Secondly, the period under investigation covers several economic and political events namely the Asian financial crisis, the dot-com bubble, the global financial crisis and the COVID-19 pandemic. Such events can affect the market dynamics and so the extent of connectedness between the three variables. Given these circumstances, we fill the vacuum in the topic by analyzing the nexus between the three markets for both bear and bull market conditions. Thirdly, we apply the Markov switching VAR (MS–VAR) approach which allows us to test the relationship between the three assets for both normal and turbulent periods. This study is becoming increasingly important after the current outbreak of COVID-19. The pandemic is emerged in China and has swiftly spread globally. In addition, its effects have been quickly reverberated on the financial and commodity markets. Therefore, this survey can help Islamic investors to opt for the optimal diversification strategies and to choose the better hedging tools namely for period characterized by the alternation between normal and turbulent phases. The remainder of the paper is organized as follow. Section 2 displays a short literature on the nexus between Islamic stock market and commodity prices. Section 3 describes the methodology. Section 4 presents the data and preliminary analysis. The empirical results are reported in Sect. 5. Section 6 concludes the paper.",5
12.0,2.0,Eurasian Economic Review,25 September 2021,https://link.springer.com/article/10.1007/s40822-021-00186-1,Regular employment and intergenerational income mobility in Japan,June 2022,Zhi-xiao Jia,,,Unknown,Unknown,Unknown,Unknown,,
12.0,2.0,Eurasian Economic Review,05 August 2021,https://link.springer.com/article/10.1007/s40822-021-00183-4,A bibliometric review of the Waqf literature,June 2022,Muneer M. Alshater,M. Kabir Hassan,Rashedul Hasan,Male,Unknown,Unknown,Male,"Waqf is a crucial Islamic social finance tool. Waqf is essentially seen as a trust of an asset that generates income for the benefit of specific groups or individuals (El Khatib 2016). These charities' recurring nature is often considered the stepping stone for Waqf development in Islam (Abdel Mohsin 2009). Otherwise, similar charitable activities, such as zakat, have been cited in academic literature having a profound impact from individual and commercial standpoints (Hassan and Rashid 2017; Ahmad et al. 2015; Rashid et al. 2017). While the zakat fund is restricted to be used for certain groups of recipients, in general, the payment of Waqf for the benefits of Muslims and non-Muslims is allowed. Contributions of the Waqf fund can be distributed for the causes of not only religious, such as building places of worships or financing the expenses during the war, but also for the general socio-economic needs of all sorts, such as establishing schools, developing infrastructure, the welfare of the poor, and sustainable entrepreneurship activities (Al-Gebori and Humaish 2008; Hasan et al. 2018; Hasan et al. 2019a, 2019b). However, due to the perpetual nature of the asset under Waqf, apart from the legal challenges, other difficulties with Waqf grossly include the management aspect of the asset. As such, past researchers have embarked on the journey to explore the ability of Waqf to bring socio-economic changes in poverty-stricken emerging economies (Sadeq 2002; Mohsin 2013). After a brief review of existing studies on Waqf, we find that past researchers have covered Waqf from various dimensions. We find waqf studies covering legal (Kuran 2001), economic (Sadeq 2002), social (Douman 1998), financial (Mohsin 2013), and accounting issues (Yatla 2011). Although research issues in Waqf have evolved from the general aspect of Waqf (Jurist 1914), recent studies are focusing on transparency and governance among waqf institutions (Hasan et al. 2017). Research interest in Waqf is growing (see Table 2), which motivates this study to conduct a bibliometric review of past waqf literature with a specific objective to classify past waqf literature into study themes, highlight gaps and propose future research directions. This study extends on this pursuit of identifying, categorizing, and analyzing a comprehensive list of tasks on Waqf using bibliometric analysis. The research will identify influential topics, significant dimensions of research, and impactful researchers across several periods in a nutshell. In this study, we extracted relevant publications using the Scopus database that included a post-filtered final sample of 319 research publications from 1914 until 2020. Our selection included both journal articles and reviews. We employed R-Studio, VOSviewer, and Microsoft Excel for citation analysis, content, and network analyses. Given the importance of Waqf studies, we covered the most extensive indexed collection of documents available on Waqf. The review resulted in four major dimensions of Waqf's research. These are: (1) Cash Waqf endowment, (2) Islamic accountability and Waqf, (3) Waqf and Islamic social Finance, and (4) Governance for Waqf endowment. Cash Waqf stood out of the crowd as the most cited topic. Overall, the number of researches on Waqf increased at a rate of 9.27% annually. Malaysian researchers contributed the most to scholarly works (155 out of 319), followed by researchers from Indonesia, the United States, the United Kingdom, and Germany in the top five. We supplemented our findings with Bradford's Law, bibliographical coupling, co-citation analysis, cartography, and several content analyses. Our analyses yield three critical conclusions. Firstly, cash Waqf has been investigated the highest number of times, indicating its popularity to expand the boundaries of traditional Waqf. The apparent etiology behind the growing attention to cash Waqf appears from specific inherent characteristics of the cash Waqf system. These include flexibility, diversity of the usage, and convenience of managing the fund or trust compared to the legal complexities associated with the real estate Waqf. Secondly, the geographic penetration of the research on Waqf has crossed the boundary of religious practices. Aside from Malaysia and Indonesia, Waqf has been discussed as a valuable economic tool in the United Kingdom, the United States, and Israel, among many. Even though applying the common law in these non-Muslim-dominant countries is to be adjusted for the inclusion of Waqf, increasing practice at the individual level rightfully seeks more scholarly and professional attention. Thirdly, Waqf has its tremendous benefit via connecting poverty, sustainability, and social welfare to ensure socio-economic justice. Researchers have reported Waqf to help reduce socio-economic inequality. Future research, thus, can be expanded into several areas, including law, management, economics, finance, and Islamic studies. We discuss the methodology in Sect. 2. Next, results are presented in Sect. 3. Section 4 provides the results of content analysis of selected literature for an in-depth review of the results from Sect. 3. Finally, Sect. 5 concludes the study with a summary of the findings and implications for future research.",13
12.0,2.0,Eurasian Economic Review,10 November 2020,https://link.springer.com/article/10.1007/s40822-020-00158-x,Do Islamic fundamental weighted indices outperform their conventional counterparts? An empirical investigation during the crises in the MENA region,June 2022,Rasha Tawfiq Abadi,Florinda Silva,,Female,Female,Unknown,Female,"Market stability is one of the main standards that encourages investors to allocate their money primarily in emerging market assets. In the last few years, many countries in the Middle East and North Africa (MENA) region suffered from geopolitical conflicts that affected the economies of all countries in the region. In late 2010, revolutions in Tunisia, Egypt, Yemen, and Libya had begun. These revolutions, which also spread to Syria, Iraq, and many other countries, became known as the Arab Spring. Because of these conflicts, the Tunisian stock exchange was closed for more than two weeks and the Egyptian stock exchange was closed for two months. Moreover, some economies in the MENA region also suffered from the conflicts in neighboring countries. The continued fighting in Syria and Egypt affected the stability of Lebanon and Jordan. Before the Arab Spring, the region also suffered from the global financial crisis of 2007–2009, which had a detrimental effect on the real estate sector in many Gulf countries, including the United Arab Emirates and Kuwait (Martin et al. 2014). The global financial crisis led to the failure of many large financial institutions and to a sharp decline in oil prices due to weak global demand. In 2014, this region faced another oil price slump, as oil prices plummeted by around 60% in the fourth quarter of that year. These events had severe consequences on the national economies of the MENA region as a whole, particularly, on investment decisions and financial asset prices. The MENA region is dominated by the financial sector, which is one of the most affected sectors by market instability. Rejichi et al. (2014) find that the banking sector plays an important role in ensuring market efficiency in the MENA region. Furthermore, there are Islamic institutions, which operate based on Islamic law, and non-Islamic institutions whose operations are based on conventional banking laws. During the last decade, the Islamic finance industry has seen a huge expansion in global capital markets. The demand for Islamic-compliant financial assets is expanding, mainly, in Islamic emerging markets, where many investors prefer to invest in stocks and portfolios that follow Islamic laws. Among the MENA countries, Bahrain, Qatar, Kuwait, Oman, United Arab Emirates, and Saudi Arabia have the most developed Islamic sectors and provide the largest chunk of the total value of Islamic investments worldwide. The Islamic-compliant financial institutions operate differently from their conventional peers since they follow the principles of Shari’ah law (i.e., Islamic law). Shari’ah principles prohibit the charging of interest and use risk sharing instead. This makes the general conceptual framework for Islamic institutions’ financial statements different from that of conventional financial institutions. The two sides of the balance sheet, liabilities, and assets, will be affected by Islamic law. The funds on the liabilities side are collected through investment deposits and demand deposits. The assets side is affected because Islamic institutions use interest-free financing instruments since the Shari’ah prohibits charging an interest rate (Hassan et al. 2003). Revenues and expenses are also affected since the type of loans (Murabaha, Mudarabah, and Musharaka) on which Islamic banks rely to generate their income are different from those of conventional banks. In addition, an argument in the Islamic finance literature contends that Islamic banks generate higher income from their assets (Viverita 2011). Based on the financial characteristics of Islamic institutions (i.e., low leverage, low account receivables, and low cash), the cash flows of these institutions could be affected. Moreover, the capital structure of Islamic banks depends more on shareholders’ capital, while that of conventional banks depends more on loans, which may affect dividend payments. Along with the previously mentioned characteristics, Islamic investing is also based on the asset-backing principle (financing is based on illiquid assets) and the profit-loss sharing principle (contracting parties share not only the profits but also the losses). In this manner, we expect the Islamic financial institutions’ fundamentals such as revenues, dividend payments, and equity book value to be higher than those of their conventional counterparts. Furthermore, we expect the impact of Islamic laws on these firm fundamentals to be also shown in their stock values. The different characteristics of Islamic and non-Islamic financial institutions make it valuable to evaluate the performance of FW portfolios that are constructed based on accounting data, as proposed by Arnott et al. (2005). Despite the significant expansion in Islamic finance and in FW indexation strategies, there are very few studies that examine the performance of Islamic FW portfolios. Boudt et al. (2019) analyze the effect of the weighting method on the financial performance of portfolios composed of Shari’ah-compliant S&P 500 stocks over the period 1986–2014. Their results suggest that the choice of the weighting method matters for Shari’ah-compliant equity investors in terms of optimizing the financial performance of their portfolios. However, portfolio performance evaluation for countries affected by political and financial crises is still rare in general, particularly, in the MENA region. The absence of such studies motivated us to investigate whether accounting-based portfolios of Islamic stocks outperform those of non-Islamic stocks during periods of crisis in the MENA region, since the literature argues that Islamic financial institutions are more stable during financial crises and do not face solvency challenges or losses, unlike their non-Islamic peers.Footnote 1 Thus, this study aims to investigate whether Islamic portfolios that are constructed based on firm fundamentals are able to outperform their conventional counterparts and to analyze the impact of the global financial crisis and the Arab Spring on the performance of those portfolios. The contributions of this research are twofold. First, this is the first study that investigates the performance of Islamic FW portfolios in comparison with non-Islamic FW portfolios in the MENA region, a region where Islamic investing is a very important issue. In this context, the current study contributes to the Islamic finance literature and to the investing decisions made in Islamic portfolios. Moreover, it provides additional empirical evidence to the fundamental indexation literature by examining the performance of financial institutions that operate differently. Second, this research extends the methods applied in prior literature. In particular, more robust performance measures based on the Fama and French (1993) three-factor model, the Fama and French (2015) five-factor model, and the Abadi and Silva (2019) seven-factor model are used along with the more traditional risk-adjusted measures to check the robustness of our results. The remainder of this paper is structured as follows. Section 2 reviews the relevant literature on the performance of Islamic and FW portfolios and the effect of financial and political crises on their performance. Section 3 describes portfolio construction methods and the risk-adjusted performance measures used. Section 4 presents the dataset and variables used. Empirical results are presented and discussed in Sect. 5. Finally, Sect. 6 presents the main conclusions.",6
12.0,2.0,Eurasian Economic Review,04 April 2022,https://link.springer.com/article/10.1007/s40822-022-00209-5,Cross-time-frequency analysis of volatility linkages in global currency markets: an extended framework,June 2022,Hasan Fehmi Baklaci,Tezer Yelkenci,,Male,Male,Unknown,Male,"Amongst the most critical matters for traders over and above for policymakers is the form of volatility transmission in global currency markets, because a strong volatility linkage among several markets may cause together benefits and drawbacks. Especially, the presence of volatility transmissions in currency markets is prone to bound hedging opportunities, however may correspondingly set the stage for probable speculative trading gains. Regarding a policymaker’s perspective, there is an ongoing debate on the impact of Central Bank intervention on exchange rate volatility. Some studies claim that these interventions either augment, or have no impact on volatility (Dominguez, 2003; Fratzcher, 2006; Rogers & Siklos, 2003), whereas others document a decreasing volatility (Kim et al., 2000; Qiumin & Qian, 2017). In this respect, volatility transmission analysis between currencies is crucial for Central Bank authorities, as the results may be useful in formulating their decisions. There are numerous studies on volatility spillovers in global currency markets, with various stories encapsulated (Kocenda & Moravcova, 2019; Panda et al., 2019; Salisu et al., 2018; Kenorgios et al., 2015; Bubak et al., 2011, Kitamura, 2010; Chang & Taylor 2003). Nevertheless, the sample datasets in the majority of these were confined to major currencies, and generally ignored interactions between major and minor currencies. In addition, in the majority of studies examining the volatility dynamics that utilized various frequencies, samples were limited to either single or a small number of currencies (Seemann et al., 2011; Gau & Hua, 2007; Melvin & Melvin, 2003). Contrarily, Baklaci et al. (2020) try to identify the impact of stock market trading on currency market volatility spillovers while taking interactions between major and minor currencies into consideration and analyzing the diversity of findings regarding to different sampling frequencies. However, since the study’s sub-samples are based on operating and non-operating hours of three major stock markets (Tokyo, London and New York), volatility linkages among sample currencies are analyzed using discrete samples representing the stock market sessions. This approach distorts the continuous information flow between currencies but distinguishes the impact of stock market trading on currency market. In addition, as a result of discrete sub samples, higher sampling frequencies are employed to satisfy the required number of observations for a feasible estimation. In this respect, the literature still lacks a combined study embracing the volatility spillover effects among various currencies with regard to different sampling frequencies. This particular study aims to fill this gap by detecting volatility spillover patterns among eleven currency pairs, which, in our opinion, represents an extensive number of currency pairs. One other unique feature of the data set is that it is comprised of major, minor and exotic currencies. Furthermore, the volatility transmissions among eleven currency pairs are scrutinized by employing different sampling frequencies: namely daily, 30-min and 15-min data. The sample period spans from 1st January, 2009 to 31st December, 2020. Since the intraday data for the sample can be traced to the beginning of 2009, data availability is the main cause for defining this sample period. As a result, the data set contains sufficient numbers of observations to analyze inter-currency volatility spillovers. The research questions of the study can briefly be summarized as follows: What are the primary roles of major and minor currencies in volatility transmission process? Which of the sample currencies play the role of volatility transmitter in different sampling frequencies? Is there a change in number of unilateral/bilateral volatility linkages when different intraday frequencies are employed? The reminder of the paper is organized as follows: the next section includes a brief discussion of relevant literature. The third section includes the discussion on data and methodology, followed by the interpretation of empirical findings. The final section presents concluding remarks.",1
12.0,2.0,Eurasian Economic Review,29 March 2022,https://link.springer.com/article/10.1007/s40822-022-00211-x,Volatility dependent smooth transitions and abrupt switches: why they are needed for better forecasting the FX rates,June 2022,Arif Orçun Söylemez,,,Male,Unknown,Unknown,Male,"One of the basic premises that the entire behavioral finance literature depends on is the mood switches of the investors (López-Cabarcos et al., 2020; Lux, 1995). According to the results of many empirical and experimental studies, investors can go from a state of complete euphoria to an opposite state of despair conditional on various factors (Hu & McInish, 2013; Livanas, 2011). The following excerpt in that sense is highly intriguing for it clearly provides us with an example of how these kinds of swings in the mental states of investors can affect the foreign exchange market. The excerpt is an illuminating text also for it hints that risk can be an important factor provoking the shifts in the investors’ sentiment. Foreign exchange markets experienced a substantial increase in volatility in August 2007... Prior to August, historically low volatility and large interest rate differentials had underpinned cross-border capital flows that put downward pressure on funding currencies, ..., and supported high-yielding currencies. (As a result of the heightened volatility) there was a substantial reassessment... as the... problems in financial markets became more apparent. In this environment, (other) factors... which have an important bearing on the future path of monetary policy, became more of a focal point for market sentiment than the prevailing level of interest rates. Bank for International Settlements (BIS) (2008), 78th Annual Report, July 2008 Foreign exchange determination has been a long-standing problem of the international finance literature since Meese and Rogoff (1983) have shown in a seminal paper that a driftless random walk model is the champion of the out-of-sample foreign exchange rate predictions. To be more articulate, determining the future exchange rates had become an important research topic in the late 1970s and early 1980s when the foreign exchange rates were let to float freely in the international markets following the collapse of the Bretton System in 1971. Meese and Rogoff (1983) have taken six of the most popular models of exchange rate determination at the time—three structural and three purely time series models—and tested their out-of-sample predictive powers. However, so ingeniously, they have not only compared those models against each other but also against a random walk model. The result has been a shocking finding, which remains to be valid still today after almost four decades and a myriad of papers written in an attempt to overturn it: the simple driftless random walk model has been the best predictor of the future exchange rates with respect to both mean squared prediction error (MSPE) and mean absolute error (MAE) criteria. However, most of the models that have been tried so far had linear specifications, including the structural models in the Meese and Rogoff (1983). But the lines in the above excerpt are suggestive of a nonlinear regime-switching process. This point will be the basis of this paper anyway: can we improve our existing linear foreign exchange models by converting them to nonlinear as regime-switching models? And what kind of regime switches should we consider, i.e. abrupt or slow? This paper is an attempt to answer these questions but if we return to the cornerstone finding of Meese and Rogoff (1983), it was a shocking finding because a driftless random walk model cannot be used as a prediction model due to a technical reason, i.e. random walk processes are the discrete time counterparts of the continuous Brownian motion processes and it is a well-known fact about the Brownian motion processes that they cannot be predicted. Even in the case that one insists on using the driftless random walk process as a prediction model, there is basically no useful information that she could extract from this simple model above that of what she would have extracted if she had thrown dices. We can easily see the reason why if we recall the specification of the driftless random walk model as follows. In Eq. 1, \({s}_{t+1}\) and \({s}_{t}\) are the spot exchange rates at time \(t\) and \(t+1,\) respectively. ‘\(\varepsilon\)’ is a white-noise error term distributed around zero with time-invariant variance \(\sigma\). It should be now clear why we cannot use this model as a prediction model. Assume that we want to predict the spot exchange rate at time \(t+1\). Since, we know \({s}_{t}\) at time \(t\), \(E({s}_{t})={s}_{t}\). Plus, we know \(\varepsilon\) is distributed around zero symmetrically which means that we are not making systematic estimation errors. That is why \(E({\varepsilon }_{t}{)}_{t}=0\). In return, our best prediction for \({s}_{t+1}\) would be equal to \({s}_{t}\). In plain English, the best prediction we can make using the random walk model is equal to the spot exchange rate today. Plus, the very same model also tells us that there is fifty percent chance that the spot exchange rate tomorrow will be higher than the spot exchange rate today and there is fifty percent chance that it will be lower than the spot exchange rate today since \(\varepsilon\) is symmetrically distributed around zero. In sum, the random walk model carries no more information that can be used for predictive purposes than a pair of dice. It is, therefore, really miserable that the random walk model has repeatedly and almost universally beaten all the other models, both the structural or purely time series, since 1983 and remained as the best prediction model of exchange rates. Therefore, this paper is interested in whether we can improve our existing structural prediction models. The rest of the paper is organized as follows. Some of the leading structural foreign exchange models are reviewed in detail in Sect. 2. In Sect. 3, two different regime-switching models are introduced, namely the threshold autoregressive model and smooth transition model. Dataset and estimation outputs are presented in Sect. 4. Section 5 concludes.",
12.0,2.0,Eurasian Economic Review,20 September 2021,https://link.springer.com/article/10.1007/s40822-021-00191-4,Herding behavior during the Covid-19 pandemic: a comparison between Asian and European stock markets based on intraday multifractality,June 2022,Faheem Aslam,Paulo Ferreira,Sumera Kauser,Male,Male,Unknown,Male,"The first 4 cases of coronavirus (Covid-19) were officially announced in Wuhan, China on December 31, 2019, and the disease has infected almost 80 million people and caused nearly 1.8 million deaths globally as of December 2020 (WHO, 2020). This novel virus has a mortality rate of nearly 6.07% in contrast to the mortality rate of influenza which is less than 1% (Gormsen & Koijen, 2020; Peters et al., 2020; WHO, 2020). The scale of the spread and trajectory of Covid-19 led the World Health Organization (WHO) to declare it as a global emergency on Feb 20, 2020 and then a pandemic on March 11, 2020. Black Swan events, like epidemics and terrorist attacks, cause shock, fear and panic among international investors and result in a sharp panic-selling response (Burch et al., 2016). Herding intensity rises during market stress moments due to the uncertainty. The Covid-19 pandemic, which is a clear public health issue, turned out to be also an unprecedented economic and financial crisis. The Covid-19 outbreak produces an environment of uncertainty and fear at the global level which has driven market movements (Aslam et al., 2020a; Lyócsa et al., 2020). In such an environment, investors who are less informed try to imitate the behavior of agents who have more information, leading to the psychological state of behavioral biases such as herding behavior. Without adequate information, at the first sign of trouble, investors search for, and flee to safer havens. For instance, according to National Securities Depository Limited (NSDL) data, Foreign Portfolio Investors (FPIs) withdrew a huge amount of 247.76 billion and 140.50 billion rupees from Indian equity and debt markets in only 13 days from March 01, 2020 to March 13, 2020. In a recent study, Salisu and Akanni (2020) reveal that the increasing number of Covid-19 deaths and cases creates fear among investors due to its risk to health and economic activities worldwide. This fear of death and infection could lead to increased trading and herding behavior among stock market investors. The most common reasons for herding behavior include imperfect information, concerns about reputation and compensation structure (Bikhchandani & Sharma, 2000). More specifically in a crisis situation, uncertainty about the accuracy of private information increases, leading to price bubbles and informationally inefficient herding behavior. Moreover, the fear and panic regarding decreasing reputation and compensation in this period is also noted in the manager’s ability to handle the portfolio, which results in herding behavior,especially if other investment professionals are in the same position. The concept of herding is present in different research fields, including neurology, zoology, sociology, psychology, economics and finance, as mentioned by Spyrou (2013), who discusses it extensively, both theoretically and empirically. Herding is observed: because agents want to preserve their reputation (Graham, 1999; Rajan, 2006; Scharfstein & Stein, 1990; Trueman, 1994); irrational investors may herd due to psychological stimuli or restraints (Baddeley et al., 2004; Keynes, 1936); as a rational choice (Devenow & Welch, 1996; Froot et al., 1992), as rational arbitrage strategies (Shleifer & Summers, 1990); due to informational cascades (Bikhchandani et al., 1992); due to investor sentiments (Barberis et al., 1998). Bikhchandani and Sharma (2000) distinguish between “spurious herding” as happens when investors make similar decisions based on a similar set of fundamental information and “intentional herding”, when investors purposefully imitate the actions of others. For instance, Scharfstein and Stein (1990) claim that through fear of losing their reputation, financial managers imitate the behaviors of others instead of using significant private information. This behavior could lead them to rational but socially inefficient herding behavior which might be perceived as protection against their underperformance (Rajan, 2006). Besides, herding can be a rational choice if investors (speculators) have short horizons and may herd on similar information, thus learning from the knowledge of other informed investors (Froot et al., 1992). This indicates that research resources are allotted in a non-optimal manner which may harm informational efficiency. Likewise, informational cascades take place if new entrants in the market prefer to ignore their own private information and imitate existing investors’ trading strategies, assuming that those investors have better private information (Banerjee, 1992; Bikhchandani et al., 1992). Although herding can be understood as entirely rational, and may result in bubbles, some authors (Avery & Zemsky, 1998; Cipriani & Guarino, 2005; Drehmann et al., 2005) argue that it is not possible to create herding particularly in the form of an informational cascade but when simple information structures and price mechanism are considered. However, in the case of complex information structures, herding is viable and can affect the prices of most assets only when market uncertainty is high. Even experienced agents could move towards herding due to asymmetry and scarcity of information and common heuristic rules (Baddeley et al., 2004). Interestingly, arbitrageurs are regarded as entirely rational and noise traders (Shleifer & Summers, 1990) but exit the market when prices are near the top to collect their profits. Lastly, investor sentiments may also affect trading behavior and lead to systematic mispricing (Barberis et al., 1998). In 1992, a new measure to analyze herding in financial markets was proposed: the Lakonishok, Shleifer and Vishny (LSV) measure (Lakonishok et al., 1992), and used later, for example by Uchida and Nakagawa (2007) or Tiniç et al. (2020). The LSV measure captures the extent to which fund managers deviate from average investment decisions depending upon overall economic conditions. According to the LSV measure, herding is defined as traders’ tendency to accumulate on the same side and at the same time for a given specific stock, when an independent trade is expected (Lakonishok et al., 1992). It is commonly used to quantify institutional investor herding since it measures the imbalance in the numbers of buyers and sellers of each stock over a given period. However, this approach has certain drawbacks, for example, the assumption of short selling, considering a small number of investors involved in herding or the fact that it does not distinguish between managers who follow their own trading patterns and those who imitate the behavior of others (Sias, 2004; Wylie, 2005). For example, Bikhchandani and Sharma (2000) argue that LSV does not account for trading volume, and therefore, does not lessen the strength of herding. The herding measure proposed by Christie & Huang (1995) looks for only one form of herding and avoids other situations. In their approach, Christie and Huang (1995) applied a Cross-Section Standard Deviation (CSSD) model and argue that in the case of herding behavior, the market dispersion from average returns is anticipated to be lower. For extreme market movements, investors tend to imitate the trading behavior of more informed senior agents. However, the major drawback of CSSD is that it can be easily influenced during periods of extreme movements (Tan et al., 2008). Therefore, it is hard to locate the presence of herding behavior in the usual conditions. Later, Chang et al. (2000) enhanced the measurement of dispersion and recommended the Cross-Section Absolute Deviation (CSAD) model. Various studies incorporated both CSSD and CSAD models to examine the presence of market-wide herding behavior (Mnif et al., 2019). Some studies have shown that periods of instability and crises trigger trading behavior towards herding, and this was recurrent throughout the global financial crisis (GFC) and periods of bubbles (BenMabrouk & Litimi, 2018; BenSaïda, 2017; Litimi et al., 2016). Bowe and Domuta (2004) documented that foreign investors are more prone to herding behavior than domestic investors. Moreover, the existing literature on how pandemics influence herding behavior is limited, especially for Covid-19 (Goodell, 2020). For instance, Chang et al. (2020) examine the effect of the global financial crisis, SARS, and Covid-19 on energy stock markets by applying CSSD and CSAD approaches, concluding that herding behavior exists in stock markets because after the GFC investors have become more sensitive to losses. Therefore, during SARS and Covid-19, investors’ panic has led them to sell their assets unwisely. Likewise, Espinosa-Méndez and Arias (2021) find evidence of an effect of Covid-19 on herding behavior in European capital markets by employing Cross-Section Standard Deviation (CSAD). The stability of financial markets is crucial for secure and safe investments. The existence of volatility bubbles that are investigated by herding and other trading behaviors can originate market instability for a certain period. For this reason, changes in market prices and volatility can be examined by innovative financial tools based on mathematics heuristics (Li et al., 2014). Earlier models based on Gaussian distribution are not sufficient to forecast the trading behavior of financial markets. Therefore, this herding behavior can be well described by complex systems of fractals. In this context, Mandelbrot (1975) was the first to study the fractal theory that was later operationalized in finance to examine crises and crashes by Peters (1991). Fractal market analysis is a valuable tool as it gives an innovative framework to add precision modeling for the crisis, incoherence and non-periodicity that describe financial markets. Detrended Fluctuation Analysis (DFA) and Multifractal Detrended Fluctuation Analysis (MFDFA) are two of the main approaches generally used in fractal market analysis. These methods examine the presence of dependence, distinguishing between persistency and anti-persistency in financial markets’ behavior (Dewandaru et al., 2015). In non-stationary financial time series, DFA has been commonly used as a dynamic tool to identify long-range autocorrelations and correlations. The MFDFA approach is the generalized method of DFA that examines the multifractal pattern of financial time series (da Silva Filho et al., 2018). The effectiveness of these methods is reflected in examining the characteristics of multifractality, long-memory autocorrelations, and asymmetry of financial markets during crises (Hasan & Mohammad, 2015; Rizvi et al., 2014). Price variations in stocks could be better explained through multifractal patterns which provide a more realistic view of market uncertainties. Moreover, fractals along with the scaling concept are best used for measuring price bubbles (Ghosh & Kozarević, 2019). Recently, Mnif et al. (2020) examined the herding behavior of the cryptocurrency market before and during Covid-19 by employing the technique of MFDFA with the Hurst Exponent and Magnitude of Long Memory (MLM), as suggested by Fernández-Martínez et al. (2017) and Khuntia and Pattanayak (2020). Besides using the MFDFA, we calculate the correlation coefficient from the Detrended Cross-Correlation Analysis (ρDCCA) with the objective of analyzing the cross-correlation, in our case, between the Chinese and the other stock markets. We chose the Chinese stock market as the benchmark due to Covid-19 originating in this country, which will allow us to study the effect of the turmoil between markets. As we separate our data into the four quarters of 2020, it will also be possible to analyze the evolution of the cross-correlation between the specified markets during 2020. We find a growing number of studies on the financial impacts of the Covid-19 pandemic. Recently, various themes have been developed, including financial networks (Aslam et al., 2020c; Zhang et al., 2020), stock market reactions (Aslam et al. 2020e, 2021; Haroon & Rizvi, 2020; Zhang et al., 2020), exchange rate fluctuation during the pandemic (Aslam et al., 2020b; Njindan Iyke, 2020), oil market reactions (Apergis & Apergis, 2020; Devpura & Narayan, 2020), air quality performance and multifractality (Ming et al., 2020; Sipra et al., 2021), insurance (Wang et al., 2020) and gold and cryptocurrencies (Corbet et al., 2020). The Covid-19 pandemic has also affected the efficiency of different financial markets. For instance, the intraday efficiency of European stock markets (Aslam et al., 2020d) and exchange rate markets (Aslam et al., 2020b) declined during the Covid-19 outbreak. Furthermore, Aslam et al. (2020e) reported that stock market efficiency varies with the evolution of Covid-19, with decreasing efficiency in February–March (2020) and a recovery in April–May (2020). Also, in the context of Covid-19, but applying the DCCA or its variants, Wang et al. (2020) showed the impact of Covid-19 on agricultural commodities, with an increase in the cross-correlations, while Chakrabarti et al. (2021) and Okorie and Lin (2021) find evidence of contagion effects in stock markets. As far as we know, there is no comprehensive comparative study addressing the changes in herding behavior by incorporating the evolution of the Covid-19 pandemic. Though psychological factors cannot be directly observed, it is possible to detect herding behavior by quantifying the self-similarity intensity in stock markets. Therefore, we propose to analyze this effect on six stock markets, using Econophysics modeling. Econophysics is an interdisciplinary field of research covering a variety of approaches with its origin in statistical physics and being used to study economic and social phenomena (see, for example, Jovanovic & Schinckus, 2013). By filling this gap, this study contributes to the literature in three main aspects. Firstly, in order to reveal the new inner dynamics, it employs the high frequency, 15-min interval data of three Asian and three European markets. The Asian markets are India, China and Japan and the European markets are the UK, France and Spain, based on their high number of Covid-19 cases and deaths (WHO, 2020). Secondly, as Covid-19 spread, several changes occurred in investors’ expectations, financial markets’ policy responses and the structure of global financial intermediation, during 2020. To incorporate these dynamics, this study investigates the quarterly changes in herding behavior through multifractality by employing the MFDFA technique of Kantelhardt et al. (2002) along with the Generalized Hurst Exponent. Thirdly, this study ranks the countries based on an index of Magnitude of Long Memory (MLM) to quantify the levels of herding and market efficiency quarterly, as proposed by Khuntia and Pattanayak (2020) Our main findings show that Covid-19 had a significant but time-varying impact on the efficiency of Asian and European stock markets. During the first quarter of the year, the European stock markets remained efficient when compared to Asian markets, but in the subsequent two quarters, the Chinese stock market shows a significant improvement, with a decline in the market efficiency of the UK and Japan. Furthermore, European stock markets follow herding behavior as compared to Asian markets. Herding was at its peak during the 2nd quarter of 2020.",19
12.0,2.0,Eurasian Economic Review,19 September 2021,https://link.springer.com/article/10.1007/s40822-021-00189-y,The effect of ICT development on innovation: evidence from G-20 countries,June 2022,Rudra P. Pradhan,Ajoy K. Sarangi,Ashim Sabat,Unknown,Unknown,Unknown,Unknown,,
12.0,3.0,Eurasian Economic Review,04 August 2022,https://link.springer.com/article/10.1007/s40822-022-00214-8,Can wavelets produce a clearer picture of weak-form market efficiency in Bitcoin?,September 2022,Andrew Phiri,,,Male,Unknown,Unknown,Male,"The pseudonymous person(s) Satoshi Nakamoto developed Bitcoin as an open source software code that implements a decentralized peer-to-peer system for electronic transactions and its design is “…based on cryptographic instead of proof, allowing two willing parties to transact directly with each other without the need for a trusted third party…” (Nakamoto, 2009). Naturally, earlier academic work on Bitcoin, and the development of cryptocurrency markets, was mainly centered around research in fields of computer sciences (Merediz-Sola & Bariviera, 2019) but quickly attracted interest amongst financial economists and regulatory authorities following the exponential growth of Bitcoin prices, trade volume and market capitalization experienced over the last decade or so (Smith & Kumar, 2018; Corbert et al., 2019). The growing consensus within the economics paradigm is that Bitcoin bears certain characteristics of traditional financial assets. For instance, Baur et al., (2018) find that Bitcoin has financial features of a speculative asset as opposed to a medium of exchange and performs poorly as a unit of account or store of value because of its high volatility. Other authors find that Bitcoin can be used for hedging purposes against equity assets (Garcia-Jorcano & Benito, 2020), currencies (Urquhart & Hanxiong, 2019; Bedi & Nashier, 2020) and commodities such as gold (Pal & Mitra, 2019) and oil (Symitsi & Chalvatzis, 2019). Moreover, in similarity to other traditional financial assets, Bitcoin is affected by policy announcements (Pyo & Lee, 2020), social media (Shen et al., 2019; Kraaijeveld. and De Smedt, 2020; Geugan & Renault 2021), google trends/investor sentiments (Urquhart, 2018; Shen et al., 2019; Bouri & Gupta, 2021) and has been punctuated by episodes of bubble-like behavior (Chaim & Laurini, 2019; Xiong et al. 2020; Hafner 2020; Kyriazis et al., 2020; Moosa, 2020; Enoksen et al., 2020). Due to its similarity to financial assets, Bitcoin has inherited some of the classical academic debates on assets markets, chief among these is the efficient market hypothesis (EMH), which questions whether financial markets are informationally efficient or not. Fama (1970) identifies three forms of information (i.e. private, public and historic) which rational participants can use to influence market efficiency. Markets are considered to be informational efficient if new information is immediately absorbed into asset prices and cannot be used for predicting purposes. From the Bitcoin literature, most studies focus on weak form market efficiency, that is, determining whether market participants can use historic information from the Bitcoin time series to predict future returns and thus ‘beat the market’. These studies employ a wide range of statistical tools to determine whether Bitcoin returns evolve as a random walk/martingale process (efficient) or stationary/long-memory process (inefficient) (see Merediz-Sola & Bariviera, 2019; and Corbert et al. 2019, for indepth reviews). The general consensus derived from literature is that Bitcoin is only market (in)efficient over certain time periods (i.e. time-varying efficiency), as insinuated by the adaptive market hypothesis (AMH) of Lo (2004), although these studies identify different time periods or structural break points when the Bitcoin market switches from being inefficient to market efficient or vice versa (Urquhart, 2016; Nadarajah & Chu, 2017; Bariviera et al., 2017; Bariviera, 2017; Tiwari et al., 2018; Jiang et al., 2018, Alvarez-Ramirez et al., 2018; Zhang et al., 2018; Vidal-Tomas et al., 2018; Khuntia & Pattanayak 2018; Aggarwal, 2019; Chu et al., 2019; Sensoy, 2019; Tran & Leirvik, 2020; Vidal-Tomas, 2020; Wu & Chen, 2020; Lopez-Martin et al., 2021; Manahov & Urquhart, 2021; Yaya et al., 2021). There also exists a smaller and more recent strand of studies (Corbet & Paraskei, 2020; Naeem et al., 2021) which identify a different mechanism for asymmetric behavior in the Bitcoin returns in which market efficiency switches between bear and bulls markets. These later studies insinuate asymmetric cyclical behavior in market efficiency for Bitcoin returns which differ from the time-varying dynamics identified in other literature. Our study proposes a novel method of simultaneously examining time-varying and cyclical-varying dynamics in the random walk model of Bitcoin prices as a means of testing for market efficiency. Using continuous wavelet transforms, we develop a random walk testing procedure for Bitcoin returns in a time frequency domain which are consistent with the assumptions underlying the traditional Dickey-Fuller test for (non)stationarity. The mathematical precision wavelets present in capturing the temporal and spectral dynamics in the co-movement between a pair of time series allows us to gain new insights to random walk behavior of Bitcoin time series as we are able to capture different cycles of weak-form market efficiency/inefficiency across different time periods. Notably, similar wavelet coherence techniques have been widely applied in the cryptocurrency literature to examine the time-frequency co-movement between Bitcoin and gold (Kang et al., 2019), Bitcoin returns and volatility (Qiao e al., 2020), Bitcoin and COVID-19 health statistics (Goodell & Goutte, 2021) and Bitcoin and COVID-19 fear index (Rubbanly et al., 2021). The main contribution of our study is that it harmonizes ‘bits-and-pieces’ of seemingly contradictory empirical evidences found in the previous literature which have investigated the efficiency of Bitcoin markets. Firstly, our study demonstrates that the Bitcoin market has been alternating between efficiency and in(efficiency) more frequently yet irregularly than previously studies suggested. Secondly, we find that Bitcoin returns are more predictable or market inefficient during November to February periods every year which reflect calendar effects anomalies recent confirmed by Kaiser (2019), Baur et al., (2019), Kinateder & Papavassiliou (2021) and Qadan et al., (2021). Thirdly, we find that Bitcoin markets are most inefficient during periods in which Bitcoin markets experience bubble build-ups and crashes. Fourthly, our study is consistent with literature which suggest that predictability in Bitcoin markets is more prominent over the short-run or at high-frequency oscillations (Kakinaka & Umeno, 2021). Fifthly, consistent with more recent literature, we find that COVID-19 pandemic has an adverse impact on market efficiency of Bitcoin markets (Manif et al., 2020; Kakinaka & Umeno 2021; Naeem et al., 2021). We also present novel evidence suggesting that overall market efficiency in Bitcoin markets has been progressively diminishing across the Bitcoin halving dates in which the supply of the cryptocurrency is consecutively halved in four-year cycles. Moreover, our study further finds that during the post-2021 period, whom Rouatbi et al., (2021) dub the ‘immunization period of the COVID-19 pandemic’, Bitcoin has been become more frequently market inefficient as more variants of the diseases have been announced by the health community. Altogether, this study not only adds new knowledge to the scientific literature but also has important implications for different stakeholders in Bitcoin markets. The rest of the study is structured as follows. The next section presents the empirical data and study outlines the empirical approach of the study. The third section presents the empirical results whilst section four concludes the study.",2
12.0,3.0,Eurasian Economic Review,08 April 2022,https://link.springer.com/article/10.1007/s40822-022-00206-8,Testing for asymmetric non-linear short- and long-run relationships between crypto-currencies and stock markets,September 2022,Achraf Ghorbel,Wajdi Frikha,Yasmine Snene Manzli,Male,Male,Female,Mix,,
12.0,3.0,Eurasian Economic Review,09 February 2022,https://link.springer.com/article/10.1007/s40822-022-00203-x,Forecasting performance of Bayesian VEC-MSF models for financial data in the presence of long-run relationships,September 2022,Anna Pajor,Justyna Wróblewska,,Female,Female,Unknown,Female,"Widely-used models for financial time series are based on conditional heteroscedasticity processes. The most popular ones are the Generalized Autoregressive Conditional Heteroskedastic (GARCH) and the Stochastic Volatility (SV) processes. The latter are less often used, though (for a review see, e.g., Silvennoinen & Teräsvirta, 2009; Asai et al., 2006; Shephard & Andersen, 2009; Chib et al., 2009; Eratalay, 2016). However, some research has shown that apart from the fact that the variability of financial time series (measured, for example, by the conditional covariance matrix) varies over time, on financial markets there can also exist long-term relationships. Therefore, it appears essential to construct such models in which the possible presence of long-run relationships and time-variable volatility are simultaneously taken into account. As the vector autoregression (VAR) models underlie the cointegration analysis, the efforts have been focused on suitably tailoring the vector error correction (VEC) representation of VAR so as to accommodate for time-varying conditional covariances, see, e.g., Seo (2007), Herwartz and Lütkepohl (2011), Koop et al. (2011), Osiewalski and Osiewalski (2013), Osiewalski and Osiewalski (2016), Cavaliere et al. (2015), Pajor and Wróblewska (2017), Cavaliere et al. (2018). Although there exists a growing number of publications discussing the forecast accuracy of Bayesian VAR models with time-varying parameters or with the time-varying covariance structure (see, e.g., Clark, 2011; D’Agostino et al., 2013; Rossi & Skhposyan, 2014; Clark & Ravazzolo, 2015; Berg, 2017; Abbate & Marcellino, 2018; Chan & Eisenstat, 2018; Vardar et al., 2018; Huber et al., 2020; Kastner & Huber, 2021), one can find rather few publications in which different vector error correction models are compared in respect to their forecasting potential (see, e.g., Anderson et al., 2002; Swanson, 2002; Kuo, 2016; Huber & Zörner, 2019). The main conclusion of the papers mentioned above is that VAR models with time-varying parameters and with time-varying covariance structure are often found to have better forecasting performance than their constant coefficient variants. On the other hand, Kuo (2016) showed that VEC models outperform VAR models in forecasting stock prices on Taiwan markets. Our research is focused on Bayesian Vector Error Correction - Multiplicative Stochastic Factor (VEC-MSF) models, proposed by Pajor and Wróblewska (2017). These models integrate the VEC representation of a VAR structure with stochastic volatility. In consequence, the VEC-MSF models enable us to capture long-run relationships among processes. Also, they make it possible to formally examine the presence of time-variation in the conditional covariances. In the VEC-MSF models proposed by Pajor and Wróblewska (2017), conditional heteroskedasticity is taken into account by the Multiplicative Stochastic Factor (MSF) process, or, alternatively, by one of its generalizations, namely, by the hybrid Multiplicative Stochastic Factor - Scalar BEKK (MSF-SBEKK) specification. It is worth mentioning that, in the VEC-GMSF-SBEKK models proposed by Osiewalski and Osiewalski (2016), the authors consider only two cases of reduced rank long-run multiplier matrix, \({\varvec{\Pi }}\). In their paper only three partial and one global relationships are analyzed. In our paper, by contrast, all possible cases of the long-run multiplier matrix \({\varvec{\Pi }}\) are considered. The main purpose of this paper is to discuss properties of Bayesian VEC-MSF models in the context of modeling financial time series. Another purpose is to compare the forecasting performance of three types of model specifications: the VEC-MSF model with constant conditional correlations, the VEC-MSF-SBEKK and VEC-SBEKK models with varying conditional correlations, and the VEC model with constant conditional covariance matrix. Based on daily quotations on three exchange rates: PLN/EUR, PLN/USD and EUR/USD, the predictive capacity of the models under consideration is compared. By modeling the exchange rates (where, as arbitrage opportunities are lacking, the cointegrating vector may be assumed to be known a priori, see Osiewalski and Pipień, 2016), it will be possible to show how important for prediction it is to incorporate a long-run relationship in financial data. It is important to stress that our attention is focused on pure time-series specifications for daily data, without applying any extra variables suggested by economic or financial theory. The fundamentals of exchange rate modeling are explained in Kębłowski et al. (2020), where the classical VEC model with constant conditional covariance matrix is used for monthly data spanning a period from January 2000 to June 2017. The main criterion used in this study for drawing this comparison is the predictive Bayes factor. The Probability Integral Transform (PIT) of Rosenblatt (1952) is also applied. As it is pointed out by Geweke and Amisano (2010, p. 229) “the two approaches can be complementary, each identifying strengths and weaknesses in the models”. A popular measure of forecasting performance is the so-called continuous ranked probability score (CRPS). The definition of CRPS and its generalization to energy score can be found in Gneiting and Raftery (2007). As the analysis conducted here is mainly Bayesian, the predictive Bayes factor will be used as the main criterion applied for evaluating the forecast performance of models under consideration. The paper is organized as follows. In Sect. 2 Bayesian VEC-MSF models are presented. Sections 3 and 4 are devoted to the predictive Bayes factor and to the PIT in the context of predictive performance of models. Section 5 contains empirical results, and Sect. 6 concludes the paper.",2
12.0,3.0,Eurasian Economic Review,06 June 2022,https://link.springer.com/article/10.1007/s40822-022-00212-w,Does international trade favor proximity in cultural beliefs?,September 2022,Chiara Franco,Daniela Maggioni,,Female,Female,Unknown,Female,"The importance of culture as a driver of international economic flows has been extensively studied by the international business literature. Specifically, the role of cultural ‘distance’ in the international management literature is quite well explored and measured (e.g. Ambos & Hakanson, 2014; Hofstede, 1980) and it is considered as one of the main core constructs of this field of research. It is, instead, only recently that the concept has become central in the trade literature. The gravity models of trade have mostly focused on economic variables—such as countries’ GDP, transportation costs, tariffs—to explain the pattern of flows of goods across countries. Recently, the literature has also highlighted the role of non-economic variables, and in particular of culturally based variables, as relevant determinants of trade. However, as Alesina  and Giuliano (2015) point out, the boundaries of the broad concept of culture remain ambiguous. Culture has a multidimensional nature. Different historical, religious and institutional traits contribute to build countries and regions’ cultural ground that turns to be relevant in shaping economic development (Tabellini, 2010) and trade patterns. Studies have, indeed, highlighted that religion (e.g. Helpman et al., 2008; Lee  & Park, 2016), language (e.g. Melitz, 2008), common ethnic origin (e.g. Rauch  & Trindade, 2002) and a general notion of bilateral trust (e.g. Guiso et al., 2009) can be important to explain trade flows. Works accounting for the existence of a trade-culture nexus have progressively risen. This probably stems both from the availability of new data measuring cultural values, as well as from the growing importance attributed to informal barriers to trade. Heterogeneous cultural values may turn into hidden transaction costs, thus representing a sort of trade barrier that may gain the same importance as tariffs and quotas (e.g. Lee  & Park, 2016). Most contributions to the literature focus on culture as a key driver of trade flows, and, more in general, of economic development (Tabellini, 2010). The interest on the linkage between culture and economic development is not new and dates back, at least, to Max Weber (1930)’s leading contribution where he discussed the role of some religious traits of Calvinism for the spread of ideas supporting growth. Nevertheless, the impact of trade on cultural distance has been scarcely explored so far, with few exceptions (Cyrus, 2012; Maystre et al., 2014). Despite the existence of some deep beliefs which may be hardly eradicated, trade may change people’s way of thinking and shape beliefs by promoting personal contacts among people and by building trust. These processes can further reinforce each other in the long run. International trade can then narrow cultural distance between trade partners and drive to changes in countries’ culture with potential repercussions on their economic development path. The idea that economic exchanges can shrink cultural distances is, for example, recalled by the concept of MacDonaldization that supports the spread of one unique global culture around the world as a consequence of the fragmented production processes of multinational enterprises. In this work we study whether bilateral international trade helps to reduce cultural differences among countries by exploiting a fairly large country level sample gathered by merging different waves of the World and the European Values Surveys, thus covering the 1989–2014 period. Our contribution to the scant existing literature is twofold. First, we enrich the trade-culture literature by examining the direction of causality that has been disregarded so far, that is the role of trade on cultural convergence. In particular, our theoretical hypothesis revolves around the idea that for trade to shrink cultural distance, some culture related dimensions, such as traits associated to historical or institutional legacy, represent a fundamental requisite. The presence of such a common background can favor the role of trade in spreading knowledge and information, and in trust-building. In this respect, we show how religious ties, common ancestry and legal origins, on the one hand, and migration flows, on the other hand, can foster cultural convergence promoted by trade. In the absence of these dimensions, the role of trade is negligible. Second, we provide empirical evidence on a large sample of countries, allowing us to draw generalizable results. Anticipating our results, we find that bilateral flows of goods reduce cultural distance between countries. This result proves robust when we extend the time span of our analysis and we allow trade to influence cultural distance over a 10 or 20 years period. While most of literature investigates the other side of the relationship—from cultural distance to trade—we provide evidence suggesting that trade acts as a diffusion channel of culture. Moreover, we find that the existence of a common background, reflected into historical religious ties, or commonality of ancestry and legal origins, as well as a certain level of bilateral migration, positively influences the role of trade as factor of cultural convergence. The paper is organized as follows. Section 2 reviews the relevant literature and discusses the theoretical framework, Sect. 3 describes the data used in the empirical analysis and presents the econometric methodology we adopt. Section 4 provides the results of the empirical analysis together with some robustness checks and the investigation of some factors moderating the trade role on culture. Section 5 offers some concluding remarks.",1
12.0,3.0,Eurasian Economic Review,09 March 2022,https://link.springer.com/article/10.1007/s40822-022-00204-w,FDI propensity and geo-cultural interaction in former Yugoslavia: pairwise analysis of origin and destination countries,September 2022,Joel I. Deichmann,Stephen Grubaugh,Patrick Scholten,Male,Male,Male,Male,"This research examines the role of geo-cultural interaction on foreign direct investment (FDI) propensity in the seven successor states of Yugoslavia,Footnote 1,Footnote 2 with two objectives. First, the study helps rectify a lack of scholarship on FDI to the successor states of Yugoslavia, which has received far less attention than other post-socialist regions of Europe (Bevan & Estrin, 2004; Brada et al., 2006; Demekas et al., 2007; Estrin & Uvalic, 2014; Pavlinek, 2017). Second, the complex history of this European region has led to strong economic, political, and cultural differences between the successor states of Yugoslavia. These differences, along with a wide range of initial conditions following dissolution, have contributed to varying propensities by multinational enterprises (MNEs) to invest across the states of former Yugoslavia. In this examination of FDI propensity, special attention is paid to the impact of and interaction between the variables of geographic distance and cultural similarity. In an increasingly globalized environment, FDI is the primary mode of operation by MNEs (Dicken, 2015). As a crucial form on international money transfer, FDI has led to a large and sometimes critical body of scholarship that varies greatly by context. FDI’s relationship with economic growth continues to be disputed by scholars. FDI is widely regarded as a potential engine for economic growth, particularly in Europe’s post-socialist transition countries, which include the successor states of Yugoslavia (Hunya, 2000a, 2008; Dicken, 2015; Estrin, 2017). UNCTAD (2017) data indicate that global FDI growth over the long term has been strong, despite periodic and localized decreases in FDI as observed following international conflicts, the 2008 Global Financial Crisis (GFC), and the COVID-19 pandemic (Sharma, 2021; UNCTAD, 2021). Excluding such disruptions, most of the states under investigation in this paper have experienced steady FDI growth since independence (WIIW, 2018). Doh’s (2019) extensive review concludes that most academic studies support the view that FDI leads to economic growth, although it may worsen income inequality. While government policy seeks investment that promotes positive effects on local economies, Curwin and Mahutga (2014) find evidence that some FDI can reduce both short-and long-term economic growth. Curwin and Mahutga’s (2014) view is supported by a sizable critical literature on FDI. Ford et al. (2008) note that the nature of FDI impact can depend upon the national origins of MNEs. Because the present research is concerned with the location decisions of MNEs, further discussion of the complex consequences of FDI lies beyond the scope of this paper. The approach taken here is an augmented logit gravity model focusing primarily on the role of geographic distance and cultural similarities between country pairs. These two relational variables—along with their interaction—are examined empirically with reference to FDI origin and destination. Other mainstream variables that have been found to be important elsewhere provide the backdrop for the examination of geo-cultural interaction. The paper is organized as follows: first, a general overview of initial conditions is provided, followed by a brief review of relevant literature. Next, the hypotheses are set forth, followed by an explanation of the data and methods employed. The discussion of results then leads to suggestions for policy and further inquiry, followed by conclusions.",3
12.0,3.0,Eurasian Economic Review,01 March 2022,https://link.springer.com/article/10.1007/s40822-022-00208-6,Cultural values and the global financial crisis: a missing link?,September 2022,Adem Baltaci,Raif Cergibozan,Ali Ari,Male,Male,Male,Male,"The world economy faced a severe financial crisis that started in the US banking system in late 2007 and turned into global following the failure of Lehman Brothers in September 2008. Despite expansionist monetary and fiscal policies, and bank rescue plans, the “Great Recession” deeply affected the world economy. Several empirical studies (i.e., Obstfeld et al. 2009; Siebert 2010; Lane and Milesi-Ferretti 2011; Frankel and Saravelos 2012; Feldkircher 2014 among others) were then conducted to explain the occurrence and the severity of the global crisis across countries. In general, these papers focus on the impact of macroeconomic and financial vulnerability on the outbreak of the global financial crisis. Contrary to previous studies, we do not only consider macro and micro variables, but also the impact of investors’ decisions on the occurrence of the crisis. Because we argue that economic and financial outcomes are the consequences of economic agents’ decisions. These decisions in turn are affected by culture. North (1990) describes culture as “intergenerational transmission of shared values and preferences that influence individuals’ behavior and choices”. Beugelsdijk and Maseland (2011) emphasize that culture matters for behavior as it channels actions, guides preferences, and shapes the process of decision-making. Besides, Elias (2004) and Rupert (2003) underline the fact that markets are embedded within a social context, thus, the economic spaces are shaped by structured relations of social power. Therefore, the present paper aims to examine whether cultural values may bring further clarifications on the occurrence of the global financial crisis. To do that, we employ two different econometric approaches, namely self-organizing maps (SOM) and logistic regression model, in a panel set of 38 countries. We consider cultural values indexes proposed by Hofstede (2001) who differentiates countries according to some specific social and cultural characteristics which are individualism, masculinity, power distance, and uncertainty avoidance. In the literature, there exists a few descriptive papers on the relationship between cultural factors and crises. For instance, Griffin (2012) argues that individualistic and masculine structure of capitalist system make the economy more prone to crises. Mixa and Vaiman (2015) affirm that individualistic societies were affected much more from the global financial crisis than collectivist countries. On the other hand, there are few empirical works on the impact of cultural values on the risk-taking behavior of banks. Kanagaretnam et al. (2011) indicate that banks in high individualism, high masculinity, and low uncertainty avoidance societies tend to take higher risks to manage earnings to just-meet-or-beat the prior year’s earnings. Similarly, Ashraf et al. (2016) find evidence that bank risk-taking is higher in countries which have high individualism, low uncertainty avoidance, and low power distance cultural values. These results, thus, suggest that countries where this risk-taking behavior is encouraged experienced more bank troubles during the global crisis. Berger et al. (2021) is the only study which empirically examines the impact of cultural values on individual bank failures using bank-level data. They find that individualism increases the probability of bank failure as managers in individualist countries have higher risk-taking incentives. Their results also indicate that masculinity augments the risk of bank failure since authorities in masculine countries allow banks to operate with less liquidity and capital. We empirically estimate the impact of cultural values on the occurrence of the global financial crisis. Contrary to Berger et al. (2021), we focus on systemic banking crises and use aggregate banking data. Moreover, using the novel SOM approach to reduce the complexity of multidimensional datasets is another contribution of our study. Besides, we use a hierarchical estimation approach that allows us to avoid correlation problem among variables and selection bias, frequently encountered in econometric models. To be more precise, we first run a nonparametric cluster analysis through the SOM with 21 explanatory variables representing both cultural values and different sectors of the economy, we then estimate a panel logit model with variables found to be significant in the SOM model. Empirical findings obtained from the SOM analysis indicate that the probability to be in crisis in the period of 2007–2009 was higher for countries with lower power distance and higher individualism. Logit results confirm the SOM findings as individualism and power distance are correctly signed and statistically significant. Our results are in general robust to the introduction of different control variables such as budget deficits, trade openness, credit growth, and currency appreciation. The paper is organized as follows. In Sect. 2, we discuss the data and methodology used in our empirical analysis. Section 3 presents empirical results. Section 4 concludes.",2
12.0,3.0,Eurasian Economic Review,22 February 2022,https://link.springer.com/article/10.1007/s40822-022-00199-4,"Employment effects of immigration to Germany in the period of migration policy liberalization, 2005–2018",September 2022,Isil Erol,Umut Unal,,Unknown,Male,Unknown,Male,"Migration is a reality in today's world and particularly in the European Union (EU). According to the latest available data on international migration stock provided by the United Nations, Department of Economic and Social Affairs (UN-DESA, 2019), as of mid-2019, 50.1 million residents of the 443.8 million (11.3%) people living in the EU-27—excluding Cyprus, for which data is unavailable—were non-nationals. Among the EU countries, there has been widespread discussion concerning the eastern enlargement of the EU, and the further introduction of transitional measures to restrict labor migration from the new Member States. Besides, citizens also concern that immigrants may compete in the labor market for the same jobs and reduce job opportunities for native workers (Glitz, 2012). Immigration and integration issues across Europe have been politically sensitive, especially in the aftermath of increased refugee flows over the last few years. As the Standard Eurobarometer (2017) survey results reveal, immigration is considered the EU's most important problem, according to about 40% of survey respondents.Footnote 1 A considerable amount of research, including theoretical and empirical studies, has examined the labor market impacts of immigration for many countries since the early 1980s. As highlighted by Okkerse (2008), the effect of immigration on labor market remains uncertain as the theoretical models are susceptible to changes in the model's assumptions. Okkerse (2008) emphasizes that if the immigrants are perfect substitutes, they may lower the price of factors, whereas if they are complements, they may raise them.Footnote 2 The lack of consensus between the theoretical models revealed the need for quantitative work. However, empirical studies do not provide a common picture, either. This is mainly due to the lack of readily available, robust, and timely data. Empirical studies use different datasets for different countries over different periods with different empirical specifications and sometimes end up with conflicting results. The majority of studies in the related literature are focused on the United States (US), whereas the number of studies for the individual European countries is limited.Footnote 3 Germany has been the most immigrant-receiving EU-27 Member State in 2019 as the country had 13.1 million international migrant stock according to the UN-DESA dataset. The share of immigrants in the total population increased from 7.5% in 1990 to 15.7% in 2019. There are several reasons for such an increase. First, as indicated by Glitz (2012), the Berlin Wall fall allowed ethnic Germans living in Eastern Europe and the former Soviet Union to migrate to Germany. Second, there has been an accelerated liberalization of migration policies in Germany starting from 2000. Additionally, the 2004 EU Qualifications Directive and 2011 EU Asylum Procedures Directive obligated Germany to gradually abolish many of the restrictions introduced by the 1992 asylum agreement. Third, Germany has been leading macroeconomic indicators to most of the EU countries and exhibits persistently low unemployment rates, which can be considered a significant pull factor for immigrants. It is, therefore, timely to investigate the impact of immigration on the German labor market, which has been untouched for the last years. This paper uses a regional approach and employs unique and first-hand-collected data for 156 agency districts or statistical regions across ten States of Germany during the period of 2005–2018. The statistical districts are defined according to the Federal Employment Agency's (Bundesagentur für Arbeit) classification of ""territorial structure."" Compared to ""political-administrative structure,"" such a dataset kindly allows us to construct more unified labor market regions in line with our goal of securing economically meaningful regional units without sacrificing too much of the interregional variation in the data.Footnote 4 According to the Federal Employment Agency data, the share of foreign-born population or immigrantsFootnote 5 in the working-age population climbed from 10.63% in 2009 to 15.64% in 2018, increased by 5.01 percentage points in the last decade. The highest increase in immigrants' share was observed in 2015 when the massive humanitarian inflows began. Labor markets are linked to each other so that natives may respond to the entry of immigrants in a market by moving their capital and labor to another area (Borjas, 1999). If such a movement occurs, it will bias the estimates of immigration effects towards zero because labor market effect will be diffused throughout the economy. Therefore, following the leading studies in the literature, the present study assumes that the internal economy of Germany is far from the Heckscher-Ohlin world of factor price equalization theorem. As highlighted by Friedberg and Hunt (1995), cross-sectional studies using regional variation and aggregate time-series studies resulted in very similar estimates of the labor market impact of immigration for the case of the US. Furthermore, Decressin and Fatas (1995) showed that labor market adjustments in Europe and the US take a similar amount of time. Such an outcome makes us more confident in exploiting regional variation in the German case as well. One of the main difficulties of the regional approach is the immigrants' self-selection endogeneity problem; immigrants may choose to locate in areas that have a strongly growing labor market, thus creating an endogeneity problem in the estimation. Following the leading studies in the literature (e.g. Altonji & Card, 1991; Bartel, 1989; Pischke & Velling, 1997), we argue that the location decisions are based on the past labor market conditions, which can be easily controlled by using lagged immigrants share as an instrument variable. Furthermore, in line with the previous research of Noja et al. (2018) and McKenzie and Rapoport (2006), a possible exogenous labor supply shock in a district (or the divergence in demand for labor) is proxied through the unemployment rate of the foreign-born population and the percentage of unemployed foreigners in the working-age population as the instrument variables. The contributions of the present paper are twofold. First, we investigate the total employment effect of immigration in the rapid liberalization of migration policies in Germany from 2005 to 2018. We ask the question, 'To what extent has immigration policy shift from the early-2000s to the mid-2010s affected the local labor markets through the changes in employment rates across the country?' Second, we divide the sample period into two subsamples in order to explore the possible impacts of massive humanitarian inflows that began in 2015 on the overall employment rate. German states have experienced substantial and sustained differences in employment growth rates during the last fourteen years. While East Germany has consistently grown at rates entirely above the national average, states across the southern and western parts of the country have experienced employment growth rates that are considerably below the national average. Our full sample regression results show that there has been a significant negative effect of new immigrants on overall employment rates between 2005 and 2018, and this negative impact is substantially larger than those reported in previous studies using data from the 1980s to the early-2000s for Germany. Apart from the displacement effect induced by newcomers, the new immigrants' lower rate of integration into the local labor markets may possibly explain the adverse effects of new migrants on the total employment rate. The German vocational training system hinders immigrants, especially those whose Facharbeiter certificate is not accepted, from moving upwards to qualified work. Our finding is in line with Pischke and Velling's study (1997), which stated that labor force participation rates for immigrants might have been lower than for those foreigners already in the country, leading to falling employment rates overall. The results also indicate that the recent migrants in the 2015–2018 period had a lower labor force participation rate (or higher unemployment rate) in comparison to those in the period 2005–2014, which led to a substantially falling employment rate overall. The arrival of significant numbers of asylum seekers along with the possible displacement effect of immigrants and their lower rate of integration into local labor markets resulted in a substantial reduction in the total employment rate. The next section outlines a review of studies on the labor market effects of immigration to Germany. In Sect. 3, we provide a brief discussion on the country's immigration policy shift since 2000. We then describe the data and methodology in Sect. 4. Section 5 provides empirical results and discusses the findings, with conclusions following in the final section.",1
12.0,3.0,Eurasian Economic Review,23 July 2022,https://link.springer.com/article/10.1007/s40822-022-00216-6,"Correction to: Employment effects of immigration to Germany in the period of migration policy liberalization, 2005–2018",September 2022,Isil Erol,Umut Unal,,Unknown,Male,Unknown,Male,"The article “Employment effects of immigration to Germany in the period of migration policy liberalization, 2005–2018”, written by Isil Erol and Umut Unal., was originally published electronically on the publisher’s internet portal on 22 Feb 2022 without open access. With the author(s)’ decision to opt for Open Choice the copyright of the article changed to © The Author(s) 2022 and the article is forthwith distributed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0. Open access funding enabled and organized by Projekt DEAL. Original article has been updated.",
12.0,4.0,Eurasian Economic Review,28 February 2022,https://link.springer.com/article/10.1007/s40822-022-00210-y,Dynamic effects of network exposure on equity markets,December 2022,Mardi Dungey,Moses Kangogo,Vladimir Volkov,Unknown,Male,Male,Male,"The occurrence of the 2007–2009 global financial crisis still raises concerns to policy makers, regulators and academic researchers. The focus has been to find ways and mechanisms to develop measures to predict distress in financial institution so as to limit further destabilization of the global economy. Until recently, there has been growing research focusing on how to predict systemic risks to minimize the recurrence of financial crises, while the importance of understanding how network exposure contributes to the spread of financial distress in the financial system has been largely underestimated. Motivated with increasing uncertainty of the stability of the financial markets, this paper aims at investigating the effect of network exposure to common factors. With the advances in both technology and globalization in recent years, there has been an increase in size, complexity, interconnectedness and concentration of the financial system. These factors combined make the financial system more vulnerable to a collapse. To ensure stability in the entire financial system, it is important to study how the global financial system is interconnected. In a nutshell, interconnectedness (the key source of systemic risk) helps to assess systemic risk and financial stability (Billio et al., 2010; Cai et al., 2014). To enable effective monitoring conditions, there is need to quantify and measure these financial linkages. This paper focuses on identifying the effect of interconnectedness in the financial system. This is achieved through examining the cross-border financial linkages using real data. The paper aims to identify the impact of interconnectedness in either absorbing or spreading risks in the financial system. It focuses on the cross-border exposure, aiming at identifying the role played by interconnectedness in propagating shocks across countries, in the period of 1999–2018. The sample period covers different crisis periods which include the global financial crisis of 2007–2009, the European sovereign debt crisis of 2010 and the Chinese stock market crash of 2015. Different approaches have been used to measure financial networks, systemic risks and interconnectedness. Recent studies on measuring systemic risk show that it was not only the size of the institution that led to the distress in the financial system but also the interconnectedness between institutions (Billio et al., 2012; Dungey et al., 2012).Footnote 1 Contagion rapidly spread the crisis through financial linkages, leading to severe disruption of financial stability in both the United States and globally. The recent financial crisis emphasized the importance of using interconnectedness (defined as a set of relationships and interactions among the financial markets participants) as a proxy in measuring systemic risk. Hautsch et al. (2014) note that both size and interconnectedness of financial institutions determine its systemic relevance. Although currently there is ongoing research focusing on the interconnectedness of institutions (Diebold & Yilmaz, 2009, 2012, 2013; Glasserman and Young, 2015; Tonzer, 2015), there is still need to understand whether an increase of financial linkages affect the stability (either weakening or strengthening) of the financial system and the impact of financial interconnectedness to both common factors and contagion. It is also important to assess the resilient nature of financial networks to shocks (both exogenous and endogenous). Different studies have extended the variance decomposition model proposed by Diebold and Yilmaz (2012) to measure connectedness in across different markets. For example, Giudici et al. (2021) provide a methodology to build a minimum variance currency basket aimed at assessing contagion spillovers among foreign exchange markets using the variance decomposition model. Giudici and Pagnottoni (2019) extent variance decomposition model to examine the relationships of five major Bitcoin exchange platforms. Giudici and Pagnottoni (2020) also extent the variance decomposition model to a generalized vector error correction framework to investigate return connectedness across eight of the major exchanges of Bitcoin. Other emerging research have proposed different approaches to predicting systemic risks across different markets. For example, Resta et al. (2020) apply technical analysis on bitcoin market and find trading on daily data is more profitable than going intraday. Peralta and Zareei (2016) use Markowitz framework to construct a network-based investment strategy. Spelta et al. (2021) develop a novel methodology to detect the emergence of crisis and provide early-warning market signals to policy makers. Spelta (2017) introduces a tensor decomposition technique to empirically extract complex relationships from prices’ time series. Spelta et al. (2022) propose a dynamical systems theory for non-linear time series forecasting and investment strategy development which correctly make predictions at long time horizons. Our paper differs from these approaches in measuring dynamic exposures in the financial system. To estimate the network exposure in the financial system, this paper uses spatial economic approach proposed by Anselin (1988). This is innovative way of estimating the intensity of the exposures to vulnerabilities. The network intensity parameter measures the network exposure in the financial system. We use data on equity because of its ability to accurately reflect market conditions and sentiments. Our work focusing on the dynamic effects of the network exposure on the financial market has the following contributions. First our paper contributes to the existing literature on interconnectedness by using the spatial econometric approach. Previous research has mainly focused on the advance economies however, little attention has focused on emerging economies. This paper aims at identifying network exposure on both advanced and emerging economies. To the best of our knowledge, this is a major piece of work, that utilizes spatial econometric techniques to estimate the network exposure in the financial system. The key findings of this paper highlight the role of network exposure in increasing vulnerability, with both interconnectedness and network intensity playing key roles in monitoring these exposures. We find high network intensity coefficient to be associated with extreme events. This suggests that high network intensity parameter relates to crisis period. We also find that both interconnectedness and network intensity increase exposures in the financial system. Cautions must be taken by policy makers in regulating and monitoring financial system to avoid re-occurrences of crises. The remainder of this paper is organized as follows. Section 2 reviews related literature and develops key hypotheses which form the basis for empirical testing. It also introduces the spatial econometric concept. Section 3 discusses the mechanism underlying network exposure to common factors. Section 4 presents the results and the effect of network exposures. Section 5 discusses various methods of estimating the network intensity parameter. Section 6 presents empirical evidence of the network intensity parameter. Section 7 outlines the implications of our results, and Section 8 concludes.",
12.0,4.0,Eurasian Economic Review,31 March 2022,https://link.springer.com/article/10.1007/s40822-022-00207-7,Systemic risk and the financial network system: an experimental investigation,December 2022,Yudistira Permana,Saiqa Akbar,Anisa Nurpita,Unknown,Unknown,Female,Female,"The financial systemic risk becomes one main concern in the modern financial system in which it leads to a bankruptcy—of the financial institutions—and economic crisis (Acharya et al., 2017; Hellwig, 2009). We try to put into a context of financial systemic risk where the initial shock of a bank impacts other banks within the same financial network which includes simultaneous financial stabilities, syndication, contagion, interconnectedness, etc. (Billio et al., 2012; Cai et al., 2018; Chen et al., 2016; de Bandt & Hartman, 2000; Giudici & Parisi, 2018); where the interbank network is one of main cause of the systemic risk due to financial shortage. This interbank network exists due to the financial obligations between banks where its value is determined by the claim of a bank to each other (Eisenberg & Noe, 2001). This network also exists indirectly through financial market when a bank’s asset decreases significantly hence decreasing the bank’s liquidity. Hansen (2014) proposes three main factors to increase the financial systemic risk: (1) bank run due to liquidity problem, (2) financial network fragility due to contagion effect, and (3) the risk of the major banks to default. In addition, the general factors like the economic shock and institutional failure—to provide prudential regulations—will only result in an economic crisis (Schwarcz, 2008). However, contagious might not be avoided though the regulators have provided a thorough prudential regulations to enhance financial institutions’ resilience (Filippopoulou et al., 2020; Jin & De Simone, 2020). In this case, technological development in the financial system and in the market have been found to increase the systemic risk (Cifuentes et al., 2005; Magnuson, 2018). We, therefore, try to address the contagion channel that potentially increases the systemic risk through the interbank market to help understand the systemic risk management. We follow Chen et al.’s (2016) model that incorporates the network channel (interbank network) and the liquidity channel (asset market) to identify how both network multiplier and liquidity amplifier determine the probability of the systemic risk. We adopt and test the intuitive optimal strategy of Chen et al.’s model—which we will explain in the next section—using a laboratory experiment. We use students and bankers as our subjects to see how close they are to Chen et al.’s optimal strategy and to see both groups differ behaviorally in order to avoid the failure.",
12.0,4.0,Eurasian Economic Review,05 October 2022,https://link.springer.com/article/10.1007/s40822-022-00218-4,Comparing cryptocurrencies and gold - a system-GARCH-approach,December 2022,Jens Klose,,,Male,Unknown,Unknown,Male,"The use of cryptocurrencies is increasing rapidly in recent years. Because of its independence of national monetary policies and the technology limiting the supply of cryptocurrencies, it may be argued that cryptocurrencies are safe haven assets just like gold. Gold is typically seen as an asset to store value, i.e., in times of turmoil. We will test whether the properties of cryptocurrencies are indeed the same or different from gold. The literature investigating the role properties of cryptocurrencies is growing rapidly. This article contributes to the literature by estimating a novel system-GARCH in-mean model in this context for four different cryptocurrencies (Bitcoin, Ethereum, Bitcoin Cash and Litecoin), allowing for volatility spillovers among them and comparing those individually to gold. Using a system estimator has the advantage that we can directly compare whether there are significant differences between cryptocurrencies and gold with respect to various determinants. These are: First, an effective exchange rate to cover currency-like properties, second, liquidity premia, third, a measure of global uncertainty and fourth, a volatility premium of the underlying asset and also volatility spillovers from other assets. This being said, this article merges three strands of literature with respect to cryptocurrencies and gold: First, it measures the impact of global uncertainty for cryptocurrencies and gold simultaneously. Second, two new determinants are introduced in the context of cryptocurrencies being a multilateral exchange rate and liquidity. Third, differences between gold and cryptocurrencies with respect to the determinants are investigated empirically. The results indicate that the negative response to exchange rate is more pronounced for cryptocurrencies than for gold, i.e., if developing countries are added. Liquidity premia are less important in the gold as well as in the cryptocurrency markets. Volatility premia exist for all assets. Cryptocurrencies and gold differ considerably with respect to global uncertainty, i.e., gold can be seen as safe haven asset increasing its value in times of financial stress, the reverse is true with respect to all four cryptocurrencies. So those can be classified as rather speculative assets. The remainder of the article is organized as follows: Sect. 2 presents a literature review. Section 3 develops the estimation model. Section 4 describes the data used. Section 5 presents the results and Sect. 6 finally concludes.",2
12.0,4.0,Eurasian Economic Review,01 November 2022,https://link.springer.com/article/10.1007/s40822-022-00219-3,Does the impact of geopolitical risk reduce with the financial structure of an economy? A perspective from market vs. bank-based emerging economies,December 2022,Ecenur Ugurlu-Yildirim,Beyza Mina Ordu-Akkaya,,Female,Female,Unknown,Female,"Geopolitical risk is one of the key factors whilst giving an investment decision both for individuals and corporations and hence heightened geopolitical risk has several economic and financial consequences such as shrinkage in output (Cheng & Chiu, 2018), substantial flee from equity market and thus significant change in portfolio allocations (Omar et al., 2017). Geopolitical risk decreases the economic output through risk-averse agents who are reluctant to get economic incentives and invest abroad with an increase in geopolitical risk. Therefore, in times of instability, private investment declines, which results in a reduction in economic growth (Bilgin et al., 2020). Furthermore, an increase in the geopolitical uncertainty enhances the motivation of precautionary savings that makes firms to delay their investments and consumers to postpone their consumption (Bloom, 2009). It is also significantly worthwhile to note that economies which are more prone to geopolitical risk are also economically more fragile. Therefore, it is of utmost importance to understand how geopolitical risk alters policy-making through economic structures. We approach this phenomenon by means of a novel perspective. Financial systems could be classified as market- or bank-based depending on which major tool investors or corporations access funds in a country; banks or financial markets. Two examples to bank and market-based economies are Japan and Bangladesh, respectively (Beck & Levine, 2002). Although, there are advantages and disadvantages to both classifications, the aspire of emerging markets to pull international funds make them shift towards market-based system (or rather have a blend of bank and market-based system) further with the globalization phenomenon. Market-based systems are perceived to be more transparent through releasing more information. However, could having a market-based system also reduce the negative impact of geopolitical risks on economic growth in the long run? We seek to find a satisfactory answer to this question in our paper. The major contribution of our paper is showing the negative impact of geopolitical risk on economic growth to diminish significantly, as the emerging economy gets further market-based. This finding shed light on the dilemma why the emerging markets are switching to the market-based system from a bank-based system, though neither of these systems is found to be superior to the other in the previous studies. The underlying reason for the shift towards market-based economy—even if it does not help the economic growth—could be due to policy-makers discretely or openly stating that they are becoming more transparent. This transparency might be positively perceived by investors, which could reduce the negative effect of geopolitical risk on financial markets in the long run. Furthermore, our findings demonstrate that while having a market-based system reduces the negative effect of GPR on consumption growth, when it comes to investment growth, bank-based system diminishes negative impact of GPR in the long-run. Since banks lock in a significant amount of funds for a longer period of time, investments could have been affected less in a bank-based environment during turbulent times. Moreover, we empirically document that emerging markets examined in this study display consumption-led growth. This finding might explain why having a market-based system diminishes adverse effects of geopolitical risk on economic growth in the long-run, whilst enhancing in the short-run. Another contribution of our paper is utilizing panel ARDL methodology with country-based GPR indices. Panel ARDL allows one to analyze both short and long-run relationships and it offers consistent estimators (Pesaran et al., 1999). Furthermore, our paper uses country based GPR indices, so that we can analyze each and every country by its own dynamics. The remaining parts of the study are structured as follows. Section two summarizes related literature, three provides data and methodology employed in this paper. The empirical findings are discussed in section four and section five provides further robustness tests. Finally, section six concludes the paper.",1
12.0,4.0,Eurasian Economic Review,04 November 2022,https://link.springer.com/article/10.1007/s40822-022-00220-w,Cost efficiency in financial exchanges and post-trade infrastructures: a closer look at integration and product diversification,December 2022,Seven Ipek,Cumhur Ekinci,,Unknown,Male,Unknown,Male,"Financial exchanges and post-trade infrastructures (FEPTIs) constitute the fundamental value chain from trade execution to settlement. Financial exchanges provide listing and trade execution facilities. Post-trade infrastructures include central counterparties (CCPs) and central securities depositories (CSDs). CCPs do clearing and assure risk management and collateral management while CSDs provide settlement and custody services. FEPTIs are characterized by high fixed costs. Although competition was introduced to the industry by the early 2000s, market power and high fixed costs are still an issue. Therefore, entries are still limited and existing FEPTIs usually have market power. They can be integrated in various ways, and over the last two decades, the industry has faced consolidation and increased competition on global scale.Footnote 1 Two major drivers of the consolidation faced in the last two decades are the privatization of exchanges that has raised competition and the appearance of alternative trading venues endowed with high technology. Competitors using new technologies have been challenging conventional exchanges in terms of faster trading capabilities at lower costs. Market share of conventional exchanges started to fall dramatically which led these venues to take measures. For instance, in 2006, NYSE acquired its major competitor alternative trading platform Archipelago. Similarly, in 2009, London Stock Exchange acquired competing alternative trading platform Turquoise. BATS was founded in 2005 as an alternative trading venue. It acquired several other venues and asked to be a regulated exchange in 2008. After acquiring Chi-X in 2011, it merged with CBOE in 2017 and became one of the biggest global exchanges. BATS is a good example of an alternative trading venue growing up to become one of the largest exchanges. Oxera (2019) estimates that less than 40% of trades are executed on conventional regulated exchanges in Europe. The competition from alternative venues also urged exchanges to pool scale and upgrade their technology. Pagano and Padilla (2005) show that the merger of Amsterdam, Brussels and Paris exchanges into Euronext benefited the market in terms of reduced cost and increased market microstructure aspects. Their study reveals that, after the merger, IT (overall) costs reduced by 29% (24%), average trading fees reduced by 45%, bid-ask spreads reduced by 48%, total trading volume increased by 40% and volatility of large capital stocks decreased by 9–18%. A second wave of consolidation is in the form of multiway integration which incorporates regional expansion, consolidation of scale and technology transfers. It also benefits network economies and offers advantages within the exchange group. Standardized and globalized derivative products have become common while securities exchange mergers have introduced multinational global exchange groups. Exchanges have differentiated products with new asset classes (stocks, debt instruments, derivatives), IT and data business or new services back in the value chain (clearing and settlement). As alternative trading venues have emerged, clearing houses and CCPs have become incentivized to loosen their conventional vertical ties to exchanges and reorganize themselves to attract trades form multiple trading venues. On the other side, Junarek and Walz (2014) indicate that CCP mandate for OTC trades makes CCPs more attractive for global exchange groups. While these occur in developed markets, emerging markets have chosen to be restructured mostly as national vertical silos and differentiated to new asset classes. In this paper, we explain the economies behind merger, acquisition or restructuring events and propose the best performant consolidation way for the industry. Although mergers, acquisitions and restructurings are extensive in the industry, a comprehensive modeling of these events and their economic assessment is missing. Within an industrial organization framework, we assess the cost reduction performance of FEPTIs based on their integration method. To the best of our knowledge, our study is the first to track the performance of industrial organization models of integration in both securities and derivatives market and in both exchange and post-trade business lines. More specifically, we categorize these merger events into explanatory variables as business integration models (no integration, horizontal integration, vertical integrations of exchanges with CCPs, vertical integration in silo model and multiway integration) and diversification models (adding new asset classes and ICSD diversification), and then, consider their effect on cost efficiency. Our model focuses on the cost reduction performance of FEPTIs considered as transaction processing factories. Therefore, we use cost efficiency measures such as total cost, average cost and scale elasticity of the cost function, and assess the effects of business integration or diversification model on the cost. Indeed, FEPTIs reflect their costs to end-investors through service fees and commissions. For instance, Schulze and Baur (2006) argue that an 18% decrease in post-trade transaction costs would increase the gross domestic product (GDP) in the European Union by 0.6%. Thus, from the regulators’ perspective, it is critical to lower the costs associated with this industry. Cost efficiency is achieved when the highest productivity is reached with a given level of expense, or alternatively, when the lowest cost is achieved at a given output level. Output level, meaning the number of transactions that a FEPTI processes, is assumed to be exogenously determined by the market participants. Therefore, cost reduction is key to increasing cost efficiency, and ultimately economic welfare. Business integration and diversification models affect cost efficiency in various ways, and these effects will be discussed throughout the paper. The paper poses the following critical questions. Do various types of integrations witnessed in FEPTI industry contribute to cost efficiency? Which type of integration is most beneficial in short and long term? Is the industry characterized by economies of scale and scope? Are there regional tendencies in cost efficiency? Do the effects of integration on cost efficiency reveal the same across developed and emerging market FEPTIs? Does integration affect securities and derivatives trading in the same way? Does entity size matter for cost efficiency? This study builds on the literature about the design and competitive environment of FEPTIs (Schmiedel et al. 2006; Van Cayseele & Wuyts, 2007; Serifsoy, 2007; Schaper, 2012; Li & Marinč, 2016, 2018) and, in a broader framework, on the industrial organization theory developed by Tirole (1988) and Baumol et al. (1988). It refers to cost efficiency to assess the cost reduction performance of FEPTIs based on their integration method. It reports on novel measures developed to clearly capture both short- and long-run effects. Previous literature does not distinguish between short and long run. Besides, it focuses on either securities or derivatives markets. However, most exchanges actually have both securities and derivatives platforms and many CCPs clear securities transactions as well as derivatives contracts. Consequently, we adopt a methodology that covers both securities and derivatives transactions. Moreover, previous studies consider only vertical and horizontal integration as two major integration models in the industry. However, global mergers and acquisitions result in complex business models that go beyond simple vertical and horizontal integration. To address this issue, we separately evaluate vertical integration (i) of exchanges and CCPs, (ii) of the whole value chain (exchanges, CCPs and CSDs) in silo model, and (iii) combined with horizontal integration (multiway integration). We use data from both developed and emerging markets to reach a global outlook. In addition, we include post-trade infrastructures in the analysis for the purpose of capturing the whole capital market infrastructure value chain. This differs from earlier studies, which focus on a single function in the value chain, i.e. either stock exchanges or CSDs. Note that our focus is on the effects of integration on cost efficiency, hence the effects of integration on market microstructure, liquidity and market power are beyond the scope of our analysis. The results put forward that many FEPTIs operate below the optimal output level and are not characterized by optimal economies of scale. In comparison to securities markets, derivatives markets can achieve more cost saving by increasing their scale. Economies of scope is also available. Any kind of integration reduces costs in the long run. Horizontal integration is the most cost-efficient organization method in the short run. We are inconclusive about the effects of vertical integration in the short run. There is no significant difference between vertical integration in silo model and the vertical integration augmented with horizontal integration. Yet, these two vertical integration models are more cost efficient than the vertical integration of exchanges with CCPs. The results also indicate that the United States provides the highest cost efficiency. Costs are higher in Europe than in the United States and the Asia Pacific region. These results point out to regional differences in terms of market structure. In emerging markets, entity size is the only significant factor for efficiency. Product differentiation and vertical integration are the sole means of consolidation within national borders in emerging markets, yet greater integration is needed for cost efficiency. The remainder of the paper is organized into six sections. The next section reviews the literature and sets the main hypotheses, Sects. 3 and 4 describe the data and model, respectively, Sect. 5 presents the empirical findings, Sect. 6 provides summary results with a detailed discussion, and the final section offers an overall conclusion.",
12.0,4.0,Eurasian Economic Review,20 September 2022,https://link.springer.com/article/10.1007/s40822-022-00217-5,Balance-of-payments-constrained growth model: an application to the Kazakhstan’s economy,December 2022,Zhandos Ybrayev,,,Male,Unknown,Unknown,Male,"The balance-of-payments-constrained growth model by Thirlwall (1979), originally was developed as an instrument to study the constraint imposed by the need to generate foreign exchange for developing countries, provides an explanation of demand-side structural economic barriers that can limit economic growth. There is now a growing literature that provides support and extends both theoretical and empirical propositions that aggregate demand plays a key role in determining growth in the long run. According to this framework, Setterfield (2003) outlines that the accumulation and allocation of productive capacity in terms of capital and labor is determined by demand, which ultimately sets the limit to economic growth to which potential output (supply) can adapt. According to the hypothesis of “balance-of-payments constrained (BPCG) growth”, given that relative prices are stable in the long run (real exchange rates are constant or have minor variations) and trade must be balanced, there is a very robust approximation between the growth rate of output and the ratio of the income elasticity of demand for a country’s exports to the income elasticity of the country’s imports times the rate of world income growth. This outcome later became known as Thirlwall’s Law. The ratio determines the balance-of-payments-constrained growth rate based on the assumptions that balance of payments equilibrium on current account is preserved and the real terms of trade remain unchanged. Thirlwall and Hussain (1982) summarize that the actual experience of advanced economies proves the validity of original Thirlwall’s Law. As a consequence, differences in growth performances between countries are linked to the relative strength of their balance of payments position. Thus, in the long run, when the actual growth is faster than the BPCG growth rate, it leads to a significant worsening of the current-account balance, which puts additional pressure on the exchange rate and the financial system. Practical evidence demonstrate that flexible exchange rate effectively facilitate short-run adjustments, whereas in the long-run, the adjustment process occurs through slower growth to rebalance the current account. As a result, the long-term constraint, derived from the BPCG growth rate is not influenced by the price elasticities. The primary factors are income elasticities for country’s exports and imports, which reflect the country’s competitiveness of a country’s goods relative to alternatives on the world market. Therefore, it is largely real income (and employment) that adjusts to preserve the balance of payments equilibrium. The estimates on different income elasticities of demand for imports and exports essentially demonstrate the non-price features of goods, and thus, the structure of production of the economy (Thirlwall, 1997). Consequently, different sectoral income elasticities form different sectoral demand growth, which are reflected in the structure of production and the changes in the rate of growth of countries. In our paper Kazakhstan serves as an example of a commodity exporting (primarily oil extraction), small open economy, which cannot absorb foreign exchange rapidly and efficiently. The growth rate of Kazakhstan since its independence in 1991 has demonstrated a very dynamic rise and today is among the world’s upper middle income group of countries by World Bank classification. At the same time, the structure of the economy has concentrated on heavy exploitation of natural resources, primarily of oil reserves, and thus, lacks an adequate level of sector-wise development of manufacturing and other value-creating industries. This paper aims to study the macroeconomic performance of Kazakhstan since 2005Q1 till 2019Q2 and explains the path of its growth rate using the Thirlwall’s balance-of-payments-constrained growth model. After the collapse of the Soviet Union in 1991, Kazakhstan’s economy experienced all the difficulties of transition from state planned organization into a capitalistic one. Hyperinflation of the early years, overall disintegration of trade and production links within the post-Soviet countries, and the recent Asian and Russian economic crises in the 90s have led to a sort of “lost decade” phenomenon. It is with the start of 2000s and emerging super cycle of commodities, has paved the path for a rapid economic recovery and growth. Thus, we investigate the period of the last 18 years of robust economic development, during which we can observe a certain composition of sectoral structure of the economy. In this paper, we embark to study whether the Kazakhstan’s growth rate is balance-of-payments constrained? We use quarterly data of main macroeconomic variables of Kazakhstan, obtained from the Committee of Statistics of Kazakhstan. Following the theoretical predictions and after studying the time-series characteristics of export and import functions, our investigation specifically focuses on two parts: one analyzing the “weak” form of the BPCG hypothesis and the other studying its “strong” form. We use Johansen’s cointegration technique and establish a stable long-run relationship between Kazakhstan’s real imports, real GDP, and real effective exchange rate. Then, the cointegrating vector was embedded in a Vector Error Correction Model (VECM) to analyze the short-run adjustments of income elasticities. The rest of the paper is structured as follows. Section 2 presents a broad overview of both theoretical and practical studies testing and extending the Thirlwall’s Law. Section 3 introduces the balance-of-payments-constrained growth model. In Sect. 4 we present the empirical investigation of Kazakhstan’s growth rate based on our model. Section 5 presents our findings and the final section concludes.",2
12.0,4.0,Eurasian Economic Review,23 June 2022,https://link.springer.com/article/10.1007/s40822-022-00213-9,Friends with or without benefits? An empirical evaluation of bilateral trade and economic integration between some of the post-Soviet economies,December 2022,Andrzej Cieślik,Oleg Gurshev,,Male,Male,Unknown,Male,"Ever since the dissolution of the Soviet Union in 1991, there were several significant attempts at re-establishing economic ties between the former republics, including the formation of the Commonwealth of Independent States (CIS), the Eurasian Economic Community (EurAsEC), and the current Eurasian Economic UnionFootnote 1 (EUEA). In particular, the third decade of post-Soviet transition has seen a considerable expansion of trade cooperation both within and beyond the region. First, it was a consolidating CIS free trade treaty in 2012, then the ascension of Armenia and Kyrgyzstan to the EUEA in 2015, and finally the signing of the EUEA-Vietnam and Iran preferential trade agreements in 2016 and 2019, respectively. Given the geostrategic locationFootnote 2 of the EUEA between the European Union (EU) and China as well as the importance of Russia to the post-Soviet economic space, it is very puzzling why the existing trade literature on the topic has remained rather thin (Adarov & Ghodsi, 2021).
 The goal of this paper is twofold. First, we empirically study bilateral trade flows of the EUEA member states: Armenia, Belarus, Kazakhstan, Kyrgyzstan, and Russia across 2008–2019. To this end, we employ a nested gravity equation based on three competing theoretical frameworks of international trade: (i) Heckscher-Ohlin-Samuelson (HOS), (ii) Chamberlin-Heckscher-Ohlin (CHO), and (iii) pure monopolistic competition (PMC) to study the effects of various country characteristics on trade flows. Our approach features the explicit use of per worker physical capital endowments in determining cross-country trade as well as the theory-consistent discrimination method between the aforementioned models. Second, we broadly consider joint and country-specific impacts from participation in the related free/ preferential trade agreementsFootnote 3 (FTAs) across various treaties, members, and modes of trade. This study is related to the following three literature strands. The first is the literature on the gravity equation. In particular, studies that derive the bilateral trade equation instead of bilateral import or export equations: Helpman (1987), Hummels and Levinsohn (1995) and studies that assume product homogeneity and incorporate incomplete specialization in production: Evenett and Keller (2002), Haveman and Hummels (2004). The featured theoretical approach largely borrows from Cieślik (2009), where model identification procedure is based on the signs and statistical significance of the estimated parameters on factor proportion variables. Because factor proportions are important only in models with incomplete specialization and only when at least one of the traded goods is homogeneous, the proposed identification mechanism allows for clear identification across the aforementioned theoretical models of international trade. Second, the paper is linked to the vast literature studying the effects of FTAs as well as other bilateral and multilateral forms of economic cooperation: Sandberg et al. (2006), Carrere (2006), Baier and Bergstrand (2007), Caporale et al. (2009), Baier et al. (2019). In particular, we employ two-lag specification from Baier and Bergstrand (2007) to study the impact of economic cooperation on various modes of bilateral trade across the EUEA members. As we discuss below, our approach is necessarily very general as the analysis of post-Soviet economic integration has been mostly absent from the literature. Hence, the paper’s contribution to this strand is mostly empirical as the featured methodology has not been previously applied to the EUEA trade data. Third, this paper is also related to empirical studies that offer quantitative analyses of trade and economic cooperation/integration (both ex-ante and ex-post) across the post-Soviet space. The examples include: De Souza (2011), EBRD (2012), Tarr (2016), Falkowski (2018), Adarov (2018), Adarov and Ghodsi (2021), Golovko and Sahin (2021), Mazhikeyev and Edwards (2021). This set of studies has considered a fairly broad range of topics, ranging from the estimation of ex-ante effects of the Eurasian Customs Union (EACU), analysis of tariff barriers to comparative advantages of the EUEA members, gravity estimation, and so forth. Our contribution to this strand is the introduction of empirical analysis, based on the theoretical framework that assumes incomplete specialization in production, using data that features all of the EUEA members across 2008–2019. This approach consolidates previously found evidence with respect to the sectoral competitiveness of the EUEA member states, which is largely concentrated in the low value-added/tech sectors that produce relatively homogeneous goods: agri-food, petroleum products, and metals (Adarov, 2018; Falkowski, 2018). Moreover, the existing gravity analysisFootnote 4 have only relied on trade theory with complete specialization, hence our study offers an alternative view from a significantly different theoretical angle that, in our opinion, better describes the specificity of the studied economies. Further, the presented analysis offers novel insights into the newly created network of preferential and free trade agreements across the post-Soviet space by considering country- and agreement-specific effects on various modes of trade among Armenia, Belarus, Kazakhstan, Kyrgyzstan, and Russia. A topic, which has only been considered very recently in Adarov and Ghodsi (2021) with respect to the EUEA-Iran preferential trade treaty. The rest of the paper is organized as follows. Section 2 introduces and describes theoretical framework. Section 3 details econometric methodology and data. Section 4 presents and discusses results. Section 5 summarizes and concludes.",1
13.0,1.0,Eurasian Economic Review,04 March 2023,https://link.springer.com/article/10.1007/s40822-022-00223-7,Do fiscal policies affect the firms’ growth and performance? Urban versus rural area,March 2023,Alessandra Amendola,Marinella Boccia,Luca Sensini,Female,Female,Male,Mix,,
13.0,1.0,Eurasian Economic Review,09 November 2021,https://link.springer.com/article/10.1007/s40822-021-00193-2,An analysis of COVID-19 and WHO global research roadmap: knowledge mapping and future research agenda,March 2023,Mohammad Ashraful Mobin,Masnun Mahi,Tahmina Hassan,Male,Unknown,Female,Mix,,
13.0,1.0,Eurasian Economic Review,17 March 2023,https://link.springer.com/article/10.1007/s40822-023-00224-0,The Green Asset Ratio (GAR): a new key performance indicator for credit institutions,March 2023,Volker Brühl,,,Male,Unknown,Unknown,Male,"The European Climate Law has been an important milestone in implementing the European Green Deal (EGD, European Commission, 2019), which entered into force on 29 July 2021 (Regulation (EU) 2021/1119). The agreement sets a 55% net greenhouse gas emission reduction target compared to 1990 for 2030 and an EU-wide climate neutrality target for 2050. This entails a fundamental transformation of basically all economic sectors, requiring enormous investment volumes. Against this background, the EU has developed the European Action Plan on sustainable finance (European Commission, 2018) to enhance transparency for investors, avoid greenwashing and channel more capital into sustainable economic activities. Therefore, disclosure and reporting requirements have been enhanced by various regulatory initiatives which have to be adopted by financial market participants in the coming years. At the same time, regulatory and supervisory authorities are putting more emphasis on the identification, disclosure and management of ESG risks by banks. This includes regular climate stress testing and the assessment of ESG risks as part of regular supervisory reviews (European Banking Authority, 2021a, b, c; European Commission, 2021, a, b, c). The introduction of a “Green Supporting Factor” which would reduce the capital requirements for green exposures has been the subject of considerable debate but has so far been rejected. This would constitute a break in the fundamental relationship between risks and capital requirements as there is so far no empirical evidence that green investments are less risky than other exposures (Coelho & Restoy, 2022; Dankert et al., 2018). In this context, new key performance indicators (KPIs) have been introduced for corporates and financial institutions to measure the proportion of sustainable economic activities in relation to their overall economic activities. For banks, the Green Asset Ratio (GAR) has been established by the European regulatory authorities. Based on an overview of the regulatory background in the EU, the paper addresses the question of how the GAR can be disaggregated into various components in order to get a deeper understanding of the sustainability profile of the respective credit institution. The mathematical decomposition of the overall GAR—which to the best of our knowledge has not been done so far—leads to a breakdown into partial GARs measuring the degree of sustainability by type of counterparty, environmental objective and type of asset. Finally, the potential benefits and the limitations of the GAR are discussed. The paper complements the existing research on the impact of ESG scores on bank risk taking (e.g. Di Tommaso & Thornton, 2020; Galletta et al., 2023) and the financial performance of banks (e.g. Buallay et al., 2021). Related research fields include the impact of ESG risks on banking relationships (e.g. Houston & Shan, 2022) and on the financial stability of banks (e.g. Chiaramonte et al., 2022). The implementation of a GAR may, over time, also influence hedging strategies against climate risk, an aspect that has been discussed in the context of green assets (e.g. Cepni et al., 2022 or Anderson et al., 2016).",
13.0,1.0,Eurasian Economic Review,02 January 2023,https://link.springer.com/article/10.1007/s40822-022-00222-8,Monetary shocks on the Korean stock index: structural VAR analysis,March 2023,Yongseung Han,Myeong Hwan Kim,,Unknown,,Unknown,Mix,,
13.0,1.0,Eurasian Economic Review,05 April 2023,https://link.springer.com/article/10.1007/s40822-023-00227-x,Financial deepening and income inequality: is there a financial Kuznetz curve in Latin America?,March 2023,Peter Mikek,,,Male,Unknown,Unknown,Male,"While remaining the region with the highest inequality (Gini Index Map, 2019), Latin America has recently seen a strong downward trend in income inequality (Lustig, 2013; Gasparini & Lustig, 2011; Gasparini et al., 2011). However, how much of this trend can be attributed to financial development in the developing countries of the region? In fact, literature provides contrasting answers to this question. While some claim that financial deepening worsens income distribution (Dabla-Norris et al., 2015), others suggest that financial development is beneficial for reducing the income gap (Zhang & Naceur, 2019). Therefore, we ask whether financial deepening was an important contributor to the recent inequality trends in Latin America. Furthermore, we wonder if a financial Kuznetz curve may be at work in this region. The contribution of this paper to the existing literature, thus, consists of investigating the effect of financial deepening on income distribution focusing specifically on Latin America. Unlike the previous studies, we ask whether there exists a financial Kuznetz curve in this region and what is the effect of financial deepening on Gini coefficients. Additionally, we study the relevance of education to income distribution in the context of financial deepening. Furthermore, unlike the three previous studies that either focused on Europe (Baiardi & Morana, 2016) or a very broad set of quite different developing countries (Nikoloski, 2010; Sahay et al., 2015), we focus on a rather narrowly defined group of countries. They have similar economic characteristics closely related to their colonial past with predominantly extractive institutions to benefit the colonizers. Different from these studies, we use an updated panel with a different time period that covers the 2008–2009 global economic crisis but excludes COVID pandemic. The decreasing income inequality in Latin America has been a persistent trend over the last few decades. The overall downward trend has been suggested by, for example, Gasparini and Lustig (2011) and Lustig (2013). This is clearly illustrated by Fig. 1, which shows the Gini coefficients for most Latin American countries between 1990 and 2017. The trend has become even more pronounced after 2000. Reduction of income Gini coefficients in Latin America 2000–2017 While initially Brazil exhibited the highest levels of the Gini coefficient, reaching to about 60,Footnote 1 it was Bolivia and Honduras that showed the highest inequality between 2000 and 2005. Finally, Colombia with 50.8, Panama with 50.4 and Brazil with 51.3 have the highest income gap at the end of the sample. The lowest income inequality at the end of the sample is in El Salvador at 40.6 and Uruguay at 40.2. These levels are comparable to the USA at 41 but still higher than most of the developed countries. Two countries that started with relatively low Gini coefficients are Argentina and Costa Rica. As can be seen in Fig. 2, Argentina’s inequality was increasing until 2002 and has experienced a substantial drop after that, with an overall downward trend. Thus, Costa Rica is the only country in the group that exhibits an upward trend over the sample period. The dynamics are surprising for a country with rather strong social transfers and relatively good support for health care. Hidalgo (2014) reports that this is the outcome of substantial growth coupled with a failure to reduce poverty and Arauz (2016) suggests that the main source for this are hours of working and the dynamics of real wages. It seems that Gini has stabilized after 2009. Income inequality in Argentina and Costa Rica 1990–2017 Our results suggest that (1) there exists a financial Kuznetz curve in Latin America and (2) confirm that financial deepening contributes to higher income inequality. Additionally, we found that (3) years of schooling is a very important contributor to the downward trend in income distribution in Latin America. Finally, we found (4) no evidence of the existence of the traditional Kuznetz curve in this dataset and discovered that (5) FDI over the period exacerbated the income gap in the region. The rest of the paper is organized as follows: We review the relevant literature in Sect. 2. The data along with the methodology are described in Sect. 3. Section 4 presents and discusses the empirical results and provides some robustness checks. We conclude with a summary and some policy implications in Sect. 5.",
13.0,1.0,Eurasian Economic Review,10 April 2023,https://link.springer.com/article/10.1007/s40822-023-00225-z,Do currency manipulations hurt US bilateral trade balance?,March 2023,Muhammad Aftab,Mohsen Bahmani-Oskooee,Huseyin Karamelikli,Male,Male,Unknown,Male,"In 2010 Guido Mantega, a Brazilian Finance Minister noted that “The world is in an international currency war as governments manipulate their currencies to improve their competitiveness” (Dominguez, 2020). Currency manipulation is a decline in a currency value by the intentional intervention of a country to make its imports expensive and exports cheaper thus improving the trade balance. In the words of Mattoo and Subramanian (2009, p. 1139), ‘An undervalued exchange rate is both an import tax and an export subsidy and is hence the most mercantilist policy imaginable’. Some stylized facts show that currency manipulations cost two million jobs in the USA. Estimates show that for every dollar spent on currency manipulation, the current account improves by 65 centsFootnote 1. Although China is at the center stage when it comes to currency manipulations, there are many other countries from the developing as well as the developed world, committing this actFootnote 2 (Gagnon, 2013; Staiger & Sykes, 2010). Given the progress, world economies have made in economic integration globally, it is worth researching, how currency manipulations relate to trade balance. The literature is abundant on how exchange rate changes affect trade. Starting with the seminal theoretical work by Magee (1973) and later empirical examination by Bahmani-Oskooee (1985), there are vast studies that establish the effect of exchange rates on tradeFootnote 3. However, these studies investigate the exchange rate change effects while ignoring currency manipulations. The empirical evidence on the effects of currency manipulations on trade balance is scarce. This study aims to fill this gap by investigating the effect of currency manipulations on the US bilateral trade balance with its twenty-one major trading partners over a long-term period of 2000Q4 to 2020Q2. This research contributes to the literature in at least three ways: firstly, by providing empirical evidence on the topic, which is scarce in the extant literature; Secondly, by creating a novel currency manipulation index based on the US Treasury-defined variables for a comprehensive set of twenty-one US trading partners. Finally, it attempts to bring research rigor by using time series and panel approaches along with disaggregated analysis on the effect of each currency manipulation index variable. The study’s unique and long-term dataset, combined with the panel of major trading partners, make it a valuable contribution to the literature on this topic. The rest of the paper is organized as follows. The next section reviews related literature that is followed by the method and data in Section 3. Section 4 provides and discusses estimation results that is followed by our concluding remarks in Section 5.",
13.0,1.0,Eurasian Economic Review,27 February 2023,https://link.springer.com/article/10.1007/s40822-022-00221-9,Pairs trading in the index options market,March 2023,Marianna Brunetti,Roberta De Luca,,Female,Female,Unknown,Female,"This paper investigates the index option market efficiency through pairs trading, a specific kind of statistical arbitrage strategy usually applied to the stock market. This strategy requires the identification of pairs of assets whose prices co-move and the setting of a trading rule to profit from any price divergence. Our work represents one among the few attempts in this direction, as the only study we are aware of performing a similar analysis is Ammann and Herriger (2002). We implement a variation with respect to their methodology, consisting in estimating the mean-reverting relationship aimed at identifying potential options’ mispricing directly on the options’ implied volatilities, rather than indirectly deriving it from the one estimated on underlying index returns. Then, whenever significant deviations from this mean-reverting relationship between implied volatilities (interpreted as signals of one option being not “correctly” priced with respect to the other) are observed, a simple pair trading strategy is triggered, buying the relatively underpriced option and contextually selling the relatively overpriced option. The positions are then unwounded as soon as the mispricing signal re-enters within the significance boundaries. According to the Efficient Market Hypothesis, as postulated by Fama (1970), in efficient markets no abnormal return can be obtained if the information is fully disclosed.Footnote 1 That is, arbitrage opportunities are short lived since mispricing are immediately identified and exploited. Therefore, significant profits generated by this trading strategy would be interpreted as disproving the index option market efficiency. In our application, we use at-the-money one-month maturity index options traded on the European market. This choice comes with several advantages. First, since the underlying is a synthetic representation of a stock portfolio, the final payoff is cash-settled rather than paid by an exchange of goods. Hence, cashing-in the payoff does not incur additional transaction costs to those related strictly to the trade. Second, at-the-money options are the most informative in terms of volatility, as most of their value is driven by this component. This is crucial for our application since the long-run equilibrium relationship between pairs of options is established through their (implied) volatilities. Last, short-term-maturity options are among the most liquid in the market, thus guaranteeing sufficient and reliable data for the empirical application. Being among the few applying pairs trading to test index options market efficiency, this paper represents a novel contribution to both the strands of literature dealing with option market efficiency, on the one hand, and with statistical arbitrage, and in particular pairs trading, on the other. Section 2 briefly reviews these two branches of literature. Section 3 outlines the methodology and the arbitrage strategy employed to test market efficiency, while Section 4 describes the dataset used and presents the results. Finally, Section 5 discusses the robustness of the results and last Section concludes.",1
13.0,1.0,Eurasian Economic Review,07 April 2023,https://link.springer.com/article/10.1007/s40822-023-00226-y,Correction to: Pairs trading in the index options market,March 2023,Marianna Brunetti,Roberta De Luca,,Female,Female,Unknown,Female,,
13.0,2.0,Eurasian Economic Review,10 April 2023,https://link.springer.com/article/10.1007/s40822-023-00228-w,"The financial access, ICT trade balance and dark and bright sides of digitalization nexus in OECD countries",June 2023,Mansour Naser Alraja,Faris Alshubiri,Mahmood Shah,Male,Male,Male,Male,"Information communication technology (ICT) trade balance have been commonly associated with digitalizing manufacturing while their importance of financial access in service companies and banks have received less attention in the current literature. This views the main focus of the international trade on manufacturing industry comparing to the usage in banks/service’s companies (Balgobin & Dubus, 2022; Francois & Hoekman, 2010; Myovella et al., 2021). Despite of this view, digital transformation have constantly affected societies and economies (Ayyagari et al., 2011) as well institutional entrepreneurship (Tumbas et al., 2018). This transformation leads to unusual radical shifts in digital infrastructures (Cabral, 2021; Mignamissi & Djijo, 2021; Øvrelid & Bygstad, 2019; Rodon & Eaton, 2021). This transformational revolution of digitalization has brought great benefits at different levels i.e. individual, societal, and organizational whereas these meaningful merits possess a dark side effects which also affect negatively human well-beings when dealing with IS (Tarafdar et al., 2015b). Growth and sustainability however have become a necessity to any business to acclimatize the new ICT conditions and climate. Theory of product life cycle indicates that business organizations growth consists of different steps to grow and sustain in the market, i.e., introduction, growth, maturity and decline (Lorentz et al., 2016). The maturity stage as a critical phase requires continuous innovation to sustain the business performance. However, the innovation in the financial services as called digital finance imitates more easily access for businesses to increase the growth of their economy (Calvano et al., 2021; Mohseni & Cao, 2020; Ozili, 2018; Waheed & Rashid, 2021). Furthermore, according to Silber (1983) the theory of financial innovations emphasized the idea that increased expansion in obtaining benefits from money-related institutions is the main reason for financial inclusion, and most of the fundamental ideas behind new innovations are the shortcomings of the money-related business sector. In light of the prevalence of wealth inequality in society and its negative effect on technological growth, standard growth theory assumes that long-term income per capita growth mainly comes from increases in digital investments and technological innovations (Aghion & Howitt, 1998). According to the theory of creative destruction (Schumpeter, 1912), technological progress plays a vital role in financial and economic development by increasing the production function and is the main reason behind any economic growth (KallalaI & Guetat, 2020; Ngo & McCann, 2019). Similarly, according to classical growth models (Solow, 1956), growth is determined by the crucial role played by technological progress, namely, its enhancement of the production function, which leads to a significant increase in productivity, especially when different production factors are to produce high technology products. Furthermore, the theory of creative destruction suggests that the key driving force behind economic growth is the replacement of existing enterprises with innovative organizations. Meanwhile, the endogenous growth theory asserts that technological progress is the central stage of economic development e.g., (Aghion & Howitt, 1992, 1998; Boikos, 2020; Romer, 1990). Recently, technology has had a prominent role in innovation and invention activities, especially in the financial and industrial sectors (Barefoot, 2020; Almudi et al., 2013) and led numerous countries to export and/or import various information and communication technology (ICT) goods. Hence, the technology sector is a crucial driver in a country’s economy through the technological investment opportunities available to foreign investors (Abubakar & Handayani, 2018). However, it can be very challenging for small and medium-sized enterprises (SMEs) and individuals to gain access to finance in the present climate of intense competition. Financial access refers to the ability of individuals and institutions to obtain financial services, including credit, deposits, insurance and risk management services (Diniz et al., 2012). Financial access supports emerging companies through credit, especially in entrepreneurial projects, while they work to utilize any opportunities for increase credits and ICT investments (Kerr & Nanda, 2015; Yoshino & Morgan, 2016). Thus, improving financial access will improve the economy and the ICT trade balance, enhance competition and stimulate the employment sector (Wagner, 2019). This will help increase the income of individuals, especially those with a low income, as limited access to financial resources through credit can weaken the financial capacity of individuals and lead them to use internal financial sources. Consequently, they might lose many economic opportunities, and the cohesion of their social network may decline; this reflects the dark side of financial technology (FinTech) (Tarafdar et al., 2015a; Yang et al., 2020). Although technological growth reflects the adaptation of various industrial and financial sectors to digital applications in order to achieve creativity of production, adopting digital technology can also negatively affect entrepreneurial projects due to technological risks from unsafe applications. Thus, technology has a dark side that investors are averse to the risks of the dark side of technology (Caruana, 2016; Ozili, 2018; Helm et al., 2019). This dark side is known among a literal community of information systems, and it is usually linked with another term, technostress, which represents the negative direct or indirect effects of technology on the body, behavior, attitudes or thoughts (Weil & Rosen, 1997). Meanwhile, the increased individual workload that results from using information systems, e.g., being permanently connected or struggling to catch up with the latest technology, leads to opposite behavioral and/or psychological responses for adopting the digitalization (Ragu-Nathan et al., 2008). When users feel psychologically exhausted or their satisfaction levels slope down (Tarafdar et al., 2011), their expected behavioral response is a drastic reduction in performance (Broni, et al., 2016) or a cessation of the use of the technology (Harris et al., 2014). Thus, the increased use of information systems has dual (negative/dark and positive/bright) effects on end users, and the negative effects may adversely influence their behavioral and/or psychological responses. In this regard, as mentioned above, one of the dark sides of technology is stress, which is responsible for many health issues and may push individuals to stop using digitalization (Rizzo et al., 1970; Tarafdar et al., 2011). Even though the increasing pervasiveness of digital transformation in the financial sector can lead to dual consequences, countries must operate within the digital network in order to achieve progress in the world of financial and technological innovation, compete on the international stage and obtain an international classification of a product (Tedeschi et al., 2014). However, according to Fanta and Makina (2019), explorations of the link between financial inclusion and technology are still in the early stages due to several factors (Beyene Fanta & Makina, 2019). First, few studies have examined the relationship between technology and financial inclusion because the availability of time series data for both topics is limited. Second, the main aim of the rapid development of technologies in the financial sector is profit rather than financial inclusion. However, FinTech, which is recognized as a merger of technology and the financial sector, supports financial inclusion by allowing lower transaction costs while boosting poor of society. Researchers have not yet studied the bright and dark sides of digitalization in much detail, especially the nexus of financial access and the ICT trade balance. Furthermore, previous studies in the financial field have not examined the effects of both financial access and the ICT trade balance on an ethical proxy (secure internet servers), a technological growth proxy (high-technology exports (% of manufactured exports)), a technological innovation proxy (patent applications, residents) and a technological performance risk proxy (individuals using the internet (% of population)). To address this research gap, we aimed to answer the following important question in the present study: Does the use of digitalization for financial access and the ICT trade balance increase or decrease: (1) the ethical proxy, (2) the technological growth proxy, (3) the technological performance risk proxy and (4) the technological innovation proxy? To answer this question, we analyzed the dark and bright sides of the digitalization paradigm nexus of financial access and ICT trade balance in 31 OECD countries during the period of 2008–2019. We investigated various financing sources of investments in technology and technological growth indicators using a panel data methodology to understand the dark and bright sides of digitalization risks and the vulnerability of digital platforms in the selected OECD countries. In addition, in spite of the rising greatness and significance of technological investments and ICT international trade in sectors, such as services, very little research has investigated the indicators/factors motivating companies to invest in technology (Yang et al., 2020). Hence, we aimed to provide important insights for researchers and practitioners regarding the digitalization in the financial sector and whether increasing financial access (which is expected to be followed by ICT exports and imports) has a positive (bright) or negative (dark) impact on the sector. The innovation of the present study lies in its focus on the dark and bright sides of digitalization, which have been explored in terms of ethical, technological, innovation and technological risks, as well as its examination of how digital finance institutions and innovators can develop and deliver products and services. The study findings can help policy makers and customers understand the negative and positive aspects of digitalization and use those insights to make innovative applications more useful for organizations within the financial access system. In addition, digitalization enhances the rapid pace of the modern lifestyle. Furthermore, technological innovation can increase the efficiency of financial inclusion and digitalization, thereby enhancing the diverse stages of financial expansion and reducing technology-related risks. Moreover, the study highlights the importance of financial technology (FinTech) companies in increasing exports of technological applications and innovation services and keeping patent applications as indicators of innovation in order to increase high-technology exports. The rest of this paper is structured as follows. Section 2 describes the literature review. Section 3 explains the econometric model and the data specification under the methodology. Section 4 presents the empirical results. Section 5 presents a discussion of the results. Section 6 concludes the paper and suggests policy implications.",
13.0,2.0,Eurasian Economic Review,08 April 2023,https://link.springer.com/article/10.1007/s40822-023-00229-9,Bayesian VARs of the U.S. economy before and during the pandemic,June 2023,Anna Sznajderska,Alfred A. Haug,,Female,Male,Unknown,Mix,,
13.0,2.0,Eurasian Economic Review,31 May 2023,https://link.springer.com/article/10.1007/s40822-023-00230-2,Catching up or getting stuck: convergence in Eastern European economies,June 2023,Istvan Konya,,,Unknown,Unknown,Unknown,Unknown,,
13.0,2.0,Eurasian Economic Review,14 June 2023,https://link.springer.com/article/10.1007/s40822-023-00233-z,Health care financing and productivity of health care in OECD countries: a stochastic frontier analysis,June 2023,Constantin Ogloblin,,,Male,Unknown,Unknown,Male,"Over the last decades, the OECD countries have notably improved their populations’ health. The average health-related mortality rate fell by 34% in 2019 compared to 1995.Footnote 1 The improved health status, however, was costly. Over the same period, the average real health-care expenditure per capita increased by 96% and the average share of health expenditures in GDP increased from 7.2% to 9.3%.Footnote 2 Moreover, a country’s higher spending on health care relative to other countries did not necessarily result in its achieving relatively better health outcomes. For example, in 2019, per capita health expenditure in the United States was 2.5 times greater than in the United Kingdom, but the mortality rate in the United Kingdom was by 7% lower. As most OECD countries are now facing hard financial constraints that make continuing increases in their health-care spending unsustainable, investigating the effect of health-care expenditure on health outcomes and the efficiency of health-care systems from that perspective is of key importance. The purpose of this study is to examine how OECD countries’ health outcomes depend on the amount of resources they devote to health care and on the financing schemes they use to allocate those resources. The study contributes to the existing literature in several ways. First, applying the stochastic frontier (SF) method allows it to estimate the parameters of the health production function and health-care efficiency by enveloping the data econometrically, i.e. maintaining the assumption of random statistical error. As shown in the literature, this approach is superior to the deterministic methods used in most of the existing studies of health production efficiency. Second, unlike most of the previous studies, it estimates the effects of factors influencing health-care efficiency rather than simply ranking countries by it. And it examines health-care efficiency, which measure how far the actual health outcome deviates from the potential outcome achievable with given resources, in conjunction with the potential returns on health-care inputs. Third, the stochastic frontier model used in the study accommodates nonmonotonic relationships between the factors of interest and the outcome, allowing us to find the optimal levels of the factors. The present study uses the improved System of Health Accounts (SHA) recently developed by the OECD, Eurostat, and WHO (OECD et al., 2017), which is based on more accurate and relevant categorization of health financing schemes and provides more reliable and complete data on their characteristics. The data sample used is a balanced panel of 30 OECD countries over the period of 1995–2019. The dataset is compiled from the OECD.Stat (2022) website. The remainder of the paper is organized as follows. Section 2 reviews the previous literature. Section 3 presents, specifies, and explains the stochastic frontier model used to quantify the returns on health-care expenditure and estimate the efficiency of health care. Section 4 describes the data used and outlines the trends in the OECD health outcomes and health-care expenditures, as well as the characteristics of the health-financing schemes. Section 5 reports and discusses the results obtained from estimating the model. Section 6 provides concluding remarks.",
13.0,2.0,Eurasian Economic Review,14 June 2023,https://link.springer.com/article/10.1007/s40822-023-00232-0,Forecasting bitcoin volatility: exploring the potential of deep learning,June 2023,Tiago E. Pratas,Filipe R. Ramos,Lihki Rubio,Male,Male,Unknown,Male,"Civilization at its present conception would not exist without money. Recent advancements in blockchain technology enable the creation of decentralized monetary systems called cryptocurrencies, where most famous one is Bitcoin, which has become a new asset class. This new type of asset is becoming part of the global financial and economic ecosystem, bringing new and interesting research questions that represent investigation opportunities. Current macro-economic conditions, with the EUR/USD parity in hand with worldwide high inflation, make it the right time to question the concepts of money, the role of central banks and to better understand what opportunities these alternative systems can bring to the discussion and, ultimately, whether these new ideas can in fact help to improve our societies as whole. The motivation for this study is to address the need for better understanding and forecasting of Bitcoin volatility, as this new asset class becomes increasingly relevant in the global financial and economic ecosystem. While traditional econometric models have been used to forecast financial assets volatility, the high volatility and unusual market patterns of cryptocurrencies present a challenge for these techniques. As a result, there is a need for more modern and innovative forecasting models that can better capture the nature of these markets. This study compares the prediction results of traditional econometric models, such as ARCH and GARCH, with machine learning models, specifically neural networks, in predicting Bitcoin volatility while doing a review on what might be the causes of this extraordinary volatility. In addition, the additional computational costs associated with machine learning models are justified by the improved forecasting accuracy. Thereby, a new insight into forecasting Bitcoin volatility will be provided and a contribution to the current discussion on the role and potential of cryptocurrencies and machine learning techniques in econometric studies will be made. Forecasting models are critical decision-making tools for economic agents, investors, and governments, particularly when predicting financial and economic data (Aminian et al., 2006). Econometric models, such as autoregressive conditional heteroskedasticity (ARCH) and generalized autoregressive conditional heteroskedasticity (GARCH) models, have been extensively used to model the volatility of financial assets. However, the high volatility and unusual patterns and behaviors of cryptocurrency markets make it challenging to apply such models (Franses & Van Dijk, 1996; Pilbeam & Langeland, 2015). To address this challenge, some scholars have proposed the use of modern techniques, such as machine learning/deep learning, to develop models that better explain and predict the nature of cryptocurrency markets (Bezerra & Albuquerque, 2017; Liu, 2019) and help businesses better understand the risks associated with these assets or assist in pricing derivatives. However, most of the time, there are no references to the implicit computational cost. For example, regarding stock price forecasting, Costa et al. (2019), Lopes et al. (2021) and Ramos et al. (2018) report that some Recurrent Neural Networks (RNN) models, e.g., Long Short-Term Memory networks—LSTM, can be promising for modeling and forecasting time series with structure breaks, or with very irregular behavior (such as time series related to financial markets). However, despite the good forecasting quality, Lopes et al. (2021) and Ramos et al. (2021) note that these neural network architectures have a significant computational cost. Due to the facts mentioned by these authors, further reflection is important, combining the prediction power and computational cost of DNN models. Thus, in addition to comparing methodologies (classical and deep learning), this work seeks to bring a scientific contribution in two aspects: (i) a comparative analysis between different deep learning methodologies, seeking to understand any differences; (ii) a critical analysis of the implicit computational cost (often omitted in scientific papers). These are aspects that have not been much discussed in the literature, so this work aims to contribute to the scientific debate on the subject. The results of our study indicate that machine learning models, specifically neural networks, outperform traditional econometric models in forecasting Bitcoin volatility, especially in short-term horizons. Although requiring significant computational costs (specially LSTM models). This paper is structured as follows: Sect. 2 reviews the relevant literature. The forecasting models are defined formally in Sect. 3, as well the data to be used in the study (including graphics illustrating the volatility to be forecast). Section 4 outlines the methodology employed in the implementation, including the forecasting models, statistical tests, and evaluation metrics. Section 5 presents a descriptive and inferential data analysis, along with visualizations of the forecast obtained by each model and accuracy tables. Finally, Sect. 6 concludes the paper and outlines directions for future research.",
13.0,2.0,Eurasian Economic Review,14 June 2023,https://link.springer.com/article/10.1007/s40822-023-00231-1,Dynamic correlation and hedging strategy between Bitcoin prices and stock market during the Russo-Ukrainian war,June 2023,Mariem Gaies,Walid Chkili,,Unknown,Male,Unknown,Male,"The last 3 years, the word has experienced two unprecedented events namely the COVID-19 pandemic in 2020/2021 and the Russia’s invasion of Ukraine in 2022. The COVID-19 pandemic has caused an economic crisis worldwide and its harmful repercussions have affected various sectors such as financial and commodity industries. The geo-political event has led to a shortage in commodities such as crude oil, gas, wheat, sugar and other food products. Besides, financial asset uncertainty has amplified during this period leading to the increase of investor fear and the decrease of the volume of investments. Several previous studies have examined the repercussions of the COVID-19 on stock and commodity markets. More precisely, the interest is focused on stock market uncertainty and diversification strategy. In this vein, studies suggest that gold and Bitcoin have played significant role in hedging stock uncertainty during turbulent periods (Akhtaruzzaman et al., 2021; Chemkha et al., 2021; Chkili et al., 2021; Huang et al., 2021; Kumar & Padakandla, 2022; Wen et al., 2022) reveal that gold continues to play the safe haven role for oil and stock markets during the COVID-19 pandemic. However, Bitcoin loses the safe haven propriety during the pandemic. Huang et al. (2021) find that, during COVID-19 crisis, Bitcoin can serve as an effective hedging and risk reduction for stock markets in five major countries. Therefore, they conclude that this cryptocurrency can act as an effective haven in major financial markets worldwide during severe downturns. Chkili et al. (2021) share the same view for some Islamic stock markets. In regards to the Ukraine war period, studies on stock market uncertainty are still rare. These studies have interested primarily to the response of markets towards this political event (Boungou & Yatié, 2022; Lo et al., 2022; Umar et al., 2022). Therefore, they fail to determine the appropriate hedging strategies and diversification opportunity between assets and other financial and commodity assets. Such analysis can help investors, financial analysts and portfolio manager to reduce the loss of their portfolios. Umar et al. (2022) examine the influences of the geopolitical risks caused by the Russian–Ukrainian conflict on Russia, European financial markets, and the global commodity markets. Results show that this conflict affects both returns and volatility connectedness among markets. Lo et al. (2022) investigate the impact of the Russo-Ukrainian war on financial markets of 73 countries. They conclude that financial markets have reacted significantly to the shock induced by the war. In addition, these markets become more volatile while the impact on asset prices is weak. Będowska-Sojka et al. (2022) suggest that the Russia-Ukraine war heightened global geopolitical risk and affected various financial and commodity markets to varying extents. They also reveal that green bonds, gold, silver, CHF currency and real estate are the best assets to hedge a portfolio against uncertainty induced by the war. Yousaf et al. (2022) reveal that stock markets of European and Asian regions are significantly and adversely affected by the conflict between Russia and Ukraine. The analysis of the financial and cryptocurrency markets behavior during crisis periods represent an interesting task in the area of finance. On the one hand, the investigation of the dynamic behavior of these markets taking into account the main stylized facts of time series such as volatility clustering, fat tails and asymmetry helps investors to forecast the movements with greater precision. This assessment can orient market participants towards better policy selection during the financial slump. On the other hand, international investors should take into consideration the global context when they decide to diversify their portfolio given that a geopolitical event such as Ukraine war represents a fundamental factor of uncertainty and consequently can amplify financial market volatilities. The aim of the paper is to fill the gap in the literature through the analysis of the relationship between stock index and the most popular cryptocurrency namely the Bitcoin. More interestingly, we contribute to the existing literature in three ways. First, we examine the co-movement between stock market and Bitcoin prices during the two important recent events namely the health crisis of the coronavirus and the Russia’s invasion of Ukraine. This allows us to verify how the link is changed over time following the characteristics of each event. In fact, some previous studies have pointed out that these two events have affected the dynamic of stock and cryptocurrency markets. For instance, Bejaoui et al. (2023) emphasize that these geopolitical and health crises are unmatched events and which are expected to substantially affect the pairwise levels of the different asset classes. Secondly, we apply the Asymmetric GARCH model to expose on one hand the dynamic correlation between the two markets. On the other hand, to examine the extent of reaction of the two markets to good and bad news. In this vein, Chkili et al. (2016) and Jia et al. (2023) prove that asymmetry is an important feature of financial time series and should be considered in analysis to overcome the undervaluation of financial market response to negative shocks and the magnitude of dependence between them. Ghorbel et al. (2022) conclude that most stock market react more to negative shocks occurring in cryptocurrency markets compared to positive shocks. Finally, we try to determine any diversification opportunity exist between the two assets through the compute of the optimal portfolio diversification and hedging ratio using the estimation result of our model. The rest of the paper is organized as follow. Section 2 describes the empirical methodology. Section 3 resumes the data and descriptive statistics. The empirical results and portfolio design are reported in Sect 4. Section 5 concludes the paper.",
