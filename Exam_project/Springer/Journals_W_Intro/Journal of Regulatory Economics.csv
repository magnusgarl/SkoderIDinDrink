Volume,Issue,Journal Name,Published Date,Link,Title,Journal Year,Author 1,Author 2,Author 3,Gender_Author 1,Gender_Author 2,Gender_Author 3,Article_Gender,Intro,Citations
1.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00150294,A test for regulatory lag and the role played by periodic contract renewals in mitigating such lag in local cable franchise relationships,March 1989,Mark A. Zupan,,,Male,Unknown,Unknown,Male,,6
1.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00150295,A role for preferred stock in the financing decision of a public utility,March 1989,Louis O. Scott,,,Male,Unknown,Unknown,Male,,1
1.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00150296,An informational effect when regulated firms enter unregulated markets,March 1989,Tracy R. Lewis,David E. M. Sappington,,,Male,Unknown,Mix,,
1.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00150297,Firm/interruptible gas pricing patterns in a regulated environment,March 1989,Daniel R. Hollas,,,Male,Unknown,Unknown,Male,,2
1.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00150298,A long-run cost allocation problem in the political economy of electric utility power pools,March 1989,Scott R. Herriott,,,Male,Unknown,Unknown,Male,,1
1.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00140019,Incentives for cost reduction under price cap regulation,June 1989,Luis M. B. Cabral,Michael H. Riordan,,Male,Male,Unknown,Male,,116
1.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00140020,"Regulatory standards, noncompliance and enforcement",June 1989,John Kambhu,,,Male,Unknown,Unknown,Male,,47
1.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00140021,Franchise bidding for natural monopoly: The case of cable television in Massachusetts,June 1989,Robin A. Prager,,,,Unknown,Unknown,Mix,,
1.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00140022,Regulating by capping prices,June 1989,Timothy J. Brennan,,,Male,Unknown,Unknown,Male,,116
1.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00140023,Optimal rate base additions and the regulated firm,June 1989,Robert H. Patrick,,,Male,Unknown,Unknown,Male,,3
1.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00140024,Pricing periods under rate-of-return regulation,June 1989,Roger Sherman,,,Male,Unknown,Unknown,Male,,5
1.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00140025,A note on the disinterest in deregulation,June 1989,Roger Frantz,Michael Naughton,,Male,Male,Unknown,Male,,
1.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00134956,Ramsey pricing of priority service,September 1989,Robert Wilson,,,Male,Unknown,Unknown,Male,,21
1.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00134957,Efficient menu structures for pricing interruptible electric power service,September 1989,Stephen A. Smith,,,Male,Unknown,Unknown,Male,,10
1.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00134958,Industrial cogeneration and regulatory policy,September 1989,Paulette Barclay,Douglas Gegax,John Tschirhart,Female,Male,Male,Mix,,
1.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00134959,An analysis of some aspects of regulatory risk and the required rate of return for public utilities,September 1989,Chang Mo Ahn,Howard E. Thompson,,,Male,Unknown,Mix,,
1.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00134960,"The effects of United States railroad deregulation on shippers, labor, and capital",September 1989,Henry McFarland,,,Male,Unknown,Unknown,Male,,25
1.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00134961,The rational regulator's pricing response to enhanced opportunities to “bypass” the public telephone network,September 1989,Lewis Evans,Steven Garber,,Male,Male,Unknown,Male,,2
1.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00134962,An expository note on depreciation and profitability under rate-of-return regulation,September 1989,Richard Schmalensee,,,Male,Unknown,Unknown,Male,,41
1.0,4.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00139899,Public utility pricing and capacity choice under risk: A rational expectations approach,December 1989,Stephen Coate,John C. Panzar,,Male,Male,Unknown,Male,,16
1.0,4.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00139900,The economics of deregulation of local exchange telecommunications,December 1989,Bruce C. Greenwald,William W. Sharkey,,Male,Male,Unknown,Male,,5
1.0,4.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00139901,Optimal new-product pricing in regulated industries,December 1989,Gerald R. Faulhaber,James Boyd,,Male,Male,Unknown,Male,,6
1.0,4.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00139902,Full price competition and Dupuit's defense of the long-and-short-haul “discrimination”,December 1989,Robert B. Ekelund Jr.,Yeung-Nan Shieh,,Male,Unknown,Unknown,Male,,10
1.0,4.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00139903,A first-best regulatory tax for oligopoly,December 1989,Sherrill Shaffer,,,,Unknown,Unknown,Mix,,
1.0,4.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00139904,Book reviews,December 1989,Michael A. Crew,Glenn A. Woroch,,Male,Male,Unknown,Male,,1
1.0,4.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00139905,Editors' report,December 1989,,,,Unknown,Unknown,Unknown,Unknown,,
2.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00139359,Interruption insurance for generation and distribution of electric power,March 1990,Shmuel S. Oren,Joseph A. Doucet,,Male,Male,Unknown,Male,,21
2.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00139360,The Public Utility Regulatory Policy Act and regulatory behavior,March 1990,Clifford Nowell,John Tschirhart,,Male,Male,Unknown,Male,,14
2.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00139361,Cross-subsidization and cost misallocation by regulated monopolists,March 1990,Timothy J. Brennan,,,Male,Unknown,Unknown,Male,,47
2.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00139362,The impact and politics of entry regulation on intrastate telephone rates,March 1990,Alan D. Mathios,Robert P. Rogers,,Male,Male,Unknown,Male,,10
2.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00139363,Efficient electricity pricing with self-rationing,March 1990,Chi-Keung Woo,,,Unknown,Unknown,Unknown,Unknown,,
2.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00139364,State monopolies and alcoholic beverage consumption,March 1990,Jon P. Nelson,,,Male,Unknown,Unknown,Male,,30
2.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00139365,Regulatory compliance with nonlinear penalties,March 1990,Sherrill Shaffer,,,,Unknown,Unknown,Mix,,
2.0,2.0,Journal of Regulatory Economics,28 March 2014,https://link.springer.com/article/10.1007/BF00165929,“Fifty in five”: The prospects for merger in the electric utility industry,June 1990,Dennis J. Ray,Howard E. Thompson,,Male,Male,Unknown,Male,,8
2.0,2.0,Journal of Regulatory Economics,28 March 2014,https://link.springer.com/article/10.1007/BF00165930,Auctions for PURPA purchases: A simulation study,June 1990,Edward P. Kahn,Michael H. Rothkopf,Jean-Michel Nataf,Male,Male,Unknown,Male,,6
2.0,2.0,Journal of Regulatory Economics,28 March 2014,https://link.springer.com/article/10.1007/BF00165931,The effect of annual changes in automobile fuel economy standards,June 1990,Andrew N. Kleit,,,Male,Unknown,Unknown,Male,,26
2.0,2.0,Journal of Regulatory Economics,28 March 2014,https://link.springer.com/article/10.1007/BF00165932,Electricity wheeling and incentive regulation,June 1990,Michael A. Einhorn,,,Male,Unknown,Unknown,Male,,10
2.0,2.0,Journal of Regulatory Economics,28 March 2014,https://link.springer.com/article/10.1007/BF00165933,The regulated firm and the DCF model: Some lessons from financial theory,June 1990,William Beranek,Keith M. Howe,,Male,Male,Unknown,Male,,2
2.0,2.0,Journal of Regulatory Economics,28 March 2014,https://link.springer.com/article/10.1007/BF00165934,Book reviews,June 1990,Harsharanjeet S. Jagpal,Thomas H. Norris,Charlotte Twight,Unknown,Male,Female,Mix,,
2.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00134061,The market response to product safety litigation,September 1990,W. Kip Viscusi,Joni Hersch,,Unknown,Female,Unknown,Female,,30
2.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00134062,Cross-subsidization in telecommunications: Beyond the universal service fairy tale,September 1990,David L. Kaserman,John W. Mayo,Joseph E. Flynn,Male,Male,Male,Male,,32
2.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00134063,Multifactor productivity growth: Empirical results for a major United States utility,September 1990,Jasmin Ansar,,,Female,Unknown,Unknown,Female,,2
2.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00134064,Market-based regulation of natural gas pipelines,September 1990,Dan Alger,Michael Toman,,Male,Male,Unknown,Male,,13
2.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00134065,"Relative price efficiency, technical change, and scale economies for large commercial banks",September 1990,Douglas D. Evanoff,Philip R. Israilevich,Randall C. Merris,Male,Male,Male,Male,,18
2.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00134066,Spot and forward markets for natural gas: The effects of state regulation,September 1990,Thomas P. Lyon,,,Male,Unknown,Unknown,Male,,7
2.0,4.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00134475,Sequential regulatory oversight,December 1990,Tracy R. Lewis,David E. M. Sappington,,,Male,Unknown,Mix,,
2.0,4.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00134476,Cross subsidies in the telephone network after divestiture,December 1990,Peter Temin,,,Male,Unknown,Unknown,Male,,15
2.0,4.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00134477,The effects of regulation and competition on the price of AT&T intrastate telephone service,December 1990,Robert Kaestner,Brenda Kahn,,Male,Female,Unknown,Mix,,
2.0,4.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00134478,Product availabilty as a strategic variable: The implications of regulating retailer stockouts,December 1990,Barbara G. Katz,Julianne Nelson,,Female,Female,Unknown,Female,,
2.0,4.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00134479,Concealment of risk and regulation of bank risk taking,December 1990,John Kambhu,,,Male,Unknown,Unknown,Male,,4
2.0,4.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00134480,Targeted price subsidization of access to the telecommunications network,December 1990,Vinson Snowberger,,,Unknown,Unknown,Unknown,Unknown,,
3.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00157608,Multiproduct tariffs,March 1991,Robert Wilson,,,Male,Unknown,Unknown,Male,,6
3.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00157609,Entry into the electric power industry,March 1991,John Tschirhart,,,Male,Unknown,Unknown,Male,,6
3.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00157610,An evaluation of incentive regulation for electric utilities,March 1991,Sanford V. Berg,Jinook Jeong,,Male,Unknown,Unknown,Male,,20
3.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00157611,Welfare and product testing by a regulated monopolist,March 1991,Tim S. Campbell,Yuk-Shee Chan,Anthony M. Marino,Male,Unknown,Male,Male,,2
3.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00157612,Peak-load pricing with continuous and interdependent demand,March 1991,H. Stuart Burness,Robert H. Patrick,,Unknown,Male,Unknown,Male,,10
3.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00157613,Phasing of deregulation: Normative versus positive objectives,March 1991,Franz Wirl,,,Male,Unknown,Unknown,Male,,3
3.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00140954,Carrot and yardstick regulation: Enhancing market performance with output prizes,June 1991,Mark Bagnoli,Severin Borenstein,,Male,Male,Unknown,Male,,6
3.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00140955,Endogenous hospital regulation and its effects on hospital and non-hospital expenditures,June 1991,Joyce A. Lanning,Michael A. Morrisey,Robert L. Ohsfeldt,Female,Male,Male,Mix,,
3.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00140956,Elasticities of rate schedule parameters,June 1991,Joseph G. Hirschberg,,,Male,Unknown,Unknown,Male,,
3.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00140957,Designing price caps for gas distribution systems,June 1991,Thomas P. Lyon,Michael A. Toman,,Male,Male,Unknown,Male,,6
3.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00140958,Price cap regulation: A case study of some pitfalls of implementation,June 1991,R. Mark Isaac,,,Unknown,Unknown,Unknown,Unknown,,
3.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00140959,Erratum,June 1991,,,,Unknown,Unknown,Unknown,Unknown,,
3.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00135362,Commitment in regulation: Defense contracting and extensions to price caps,September 1991,William E. Kovacic,,,Male,Unknown,Unknown,Male,,18
3.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00135363,The managerial response to regulation of financial reporting for segments of a business enterprise,September 1991,Frank R. Lichtenberg,,,Male,Unknown,Unknown,Male,,22
3.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00135364,Mixed linear-nonlinear pricing with bundling,September 1991,Padmanabhan Srinagesh,,,Unknown,Unknown,Unknown,Unknown,,
3.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00135365,Endogenous change and the economic theory of regulation,September 1991,Jerome Ellig,,,Male,Unknown,Unknown,Male,,4
3.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00135366,Auction markets for dispatchable power: How to score the bids,September 1991,Steven Stoft,Edward P. Kahn,,Male,Male,Unknown,Male,,11
3.0,4.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00138470,Telephone pricing structures: The effects on universal service,December 1991,Paul Cain,James M. Macdonald,,Male,Male,Unknown,Male,,15
3.0,4.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00138471,Incentives for firms to provide safety: Regulatory authority and capital market reactions,December 1991,Ivy E. Broder,John F. Morrall III,,Female,Male,Unknown,Mix,,
3.0,4.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00138472,Toward improved and practical incentive regulation,December 1991,Lorenzo Brown,Michael Einhorn,Ingo Vogelsang,Male,Male,Male,Male,,18
3.0,4.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00138473,Trucking deregulation and highway safety: The effect of the 1980 Motor Carrier Act,December 1991,Thomas L. Traynor,Patrick S. Mccarthy,,Male,Male,Unknown,Male,,4
3.0,4.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00138474,A note on the effect of rate-of-return regulation under uncertainty,December 1991,Kuo-Ping Chang,,,Unknown,Unknown,Unknown,Unknown,,
3.0,4.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00138475,A note on the effect of rate-of-return regulation under uncertainty: Reply,December 1991,Satya P. Das,,,Male,Unknown,Unknown,Male,,3
3.0,4.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00138476,A note on the effect of rate-of-return regulation under uncertainty: Reply,December 1991,Yoram C. Peles,,,Male,Unknown,Unknown,Male,,
3.0,4.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00138477,Regulation and the provision of quality to heterogenous consumers: The case of prospective pricing of medical services,December 1991,Robin Allen,Paul Gertler,,,Male,Unknown,Mix,,
4.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00134216,Optimal depreciation schedules for regulated utilities,March 1992,William P. Rogerson,,,Male,Unknown,Unknown,Male,,16
4.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00134217,"Optimal depreciation, payments to capital, and natural monopoly regulation",March 1992,H. Stuart Burness,Robert H. Patrick,,Unknown,Male,Unknown,Male,,11
4.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00134218,Economic depreciation and the regulated firm under competition and technological change,March 1992,Michael A. Crew,Paul R. Kleindorfer,,Male,Male,Unknown,Male,,16
4.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00134219,Depreciation and profitability under rate of return regulation,March 1992,Shimon Awerbuch,,,Male,Unknown,Unknown,Male,,5
4.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00134220,Implementation issues for marketable permits: A case study of newsprint,March 1992,Terry M. Dinan,,,,Unknown,Unknown,Mix,,
4.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00134221,The political economy of corporatism in medicine: Self-regulation or cartel management?,March 1992,Peter Zweifel,Reiner Eichenberger,,Male,Male,Unknown,Male,,18
4.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00157160,Ex post vs. ex ante pricing: Optional calling plans and tapered tariffs,June 1992,Karen B. Clay,David S. Sibley,Padmanabhan Srinagesh,Female,Male,Unknown,Mix,,
4.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00157161,The effects of regulation on stochastic systematic risk,June 1992,Leigh A. Riddick,,,,Unknown,Unknown,Mix,,
4.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00157162,Disutility and constrained quality choice in self-selection problems,June 1992,Jae-Cheol Kim,Byong-Hun Ahn,Hyun-Joo Moon,Male,Unknown,Female,Mix,,
4.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00157163,Airline networks as joint goods: Implications for competition policy,June 1992,Andrew N. Kleit,Stewart G. Maynes,,Male,Male,Unknown,Male,,2
4.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00157164,The Incremental Surplus Subsidy and rate-of-return regulation,June 1992,B. Glenn Blackmon Jr.,,,Unknown,Unknown,Unknown,Unknown,,
4.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00157165,Capital waste in the rate-of-return regulated firm,June 1992,Roger Sherman,,,Male,Unknown,Unknown,Male,,28
4.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00133621,Contract networks for electric power transmission,September 1992,William W. Hogan,,,Male,Unknown,Unknown,Male,,603
4.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00133622,"Stand-alone costs, Ramsey prices, and postal rates",September 1992,Thomas M. Lenard,Monica M. Bettendorf,Stephen Mcgonegal,Male,Female,Male,Mix,,
4.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00133623,Regulatory regimes in the electric power industry: Implications for capacity,September 1992,Esther Gal-Or,Michael H. Spiro,,Female,Male,Unknown,Mix,,
4.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00133624,Upstream vertical integration with automatic price adjustments,September 1992,John R. Morris,,,Male,Unknown,Unknown,Male,,1
4.0,4.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00134924,Capacity-contingent nonlinear pricing by regulated firms,December 1992,Daniel F. Spulber,,,Male,Unknown,Unknown,Male,,11
4.0,4.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00134925,Should earthquake mitigation measures be voluntary or required?,December 1992,Howard Kunreuther,Anne E. Kleffner,,Male,Female,Unknown,Mix,,
4.0,4.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00134926,Public regulation of private accident risk: The moral hazard of technological improvements,December 1992,Alf Erling Risa,,,Male,Unknown,Unknown,Male,,10
4.0,4.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00134927,The effects of deregulating cable television: Evidence from the financial markets,December 1992,Robin A. Prager,,,,Unknown,Unknown,Mix,,
4.0,4.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00134928,Issue costs and regulated returns: A general approach,December 1992,Keith M. Howe,William Beranek,,Male,Male,Unknown,Male,,
4.0,4.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00134929,State mandated benefits and the small firm's decision to offer insurance,December 1992,Gail A. Jensen,Jon R. Gabel,,,Male,Unknown,Mix,,
4.0,4.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00134930,Editors' report 1992 (volume 4),December 1992,,,,Unknown,Unknown,Unknown,Unknown,,
5.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01066311,Peak-load pricing and reliability under uncertainty,March 1993,Paul R. Kleindorfer,Chitru S. Fernando,,Male,Unknown,Unknown,Male,,45
5.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01066312,Price-cap versus rate-of-return regulation,March 1993,Catherine Liston,,,Female,Unknown,Unknown,Female,,97
5.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01066313,The political economy of deregulation: The case of intrastate long distance,March 1993,David L. Kaserman,John W. Mayo,Patricia L. Pacey,Male,Male,Female,Mix,,
5.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01066314,Workers' compensation: Determining a feasible payment structure in a regulatory environment,March 1993,Richard J. Butler,John D. Worrall,,Male,Male,Unknown,Male,,1
5.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01066315,"Scale, scope, and regulation in the Texas gas transmission industry",March 1993,Jerry Ellig,Michael Giberson,,Male,Male,Unknown,Male,,5
5.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01066316,Efficient self-rationing of electricity revisited,March 1993,Joseph A. Doucet,Michel Roland,,Male,Male,Unknown,Male,,14
5.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01066317,Efficient electricity pricing with self-rationing: Reply,March 1993,Chi-Keung Woo,,,Unknown,Unknown,Unknown,Unknown,,
5.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01065361,Cartelization by regulation,June 1993,Jean-Jacques Laffont,Jean Tirole,"Idei, Gremaq, and Ceras",Unknown,Male,Unknown,Male,,8
5.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01065362,Regulatory incentive policies and abuse,June 1993,David E. M. Sappington,David S. Sibley,,Male,Male,Unknown,Male,,7
5.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01065363,Deregulation and privatization of Britain's local bus industry,June 1993,Ian Savage,,,Male,Unknown,Unknown,Male,,20
5.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01065364,Allocative inefficiency properties of price-cap regulation,June 1993,Werner Neu,,,Male,Unknown,Unknown,Male,,28
5.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01065365,An optimal tax/subsidy for output and pollution control under asymmetric information in oligopoly markets,June 1993,Jae-Cheol Kim,Ki-Bok Chang,,Male,Unknown,Unknown,Male,,31
5.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01065366,Efficiency and regulation in the case of the Swiss Private Railways,June 1993,Massimo Filippini,Rico Maggi,,Male,Male,Unknown,Male,,17
5.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01065367,Should Ramsey-price markups differ?,June 1993,Roger Sherman,,,Male,Unknown,Unknown,Male,,1
5.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01065368,Announcement,June 1993,,,,Unknown,Unknown,Unknown,Unknown,,
5.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01065952,Option value of emission allowances,September 1993,Hung -Po Chao,Robert Wilson,,,Male,Unknown,Mix,,
5.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01065953,Modeling regulatory behavior: The economic theory of regulation versus alternative theories and simple rules of thumb,September 1993,Steven B. Caudill,Bae-Geun Im,David L. Kaserman,Male,Unknown,Male,Male,,12
5.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01065954,Public utility valuation and risk under incentive regulation,September 1993,Wilbur G. Lewellen,David C. Mauer,,Male,Male,Unknown,Male,,6
5.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01065955,Implications for unisex statutes and risk-pooling: The costs of gender and underwriting attributes in the automobile insurance market,September 1993,Robert Puelz,Walter Kemmsies,,Male,Male,Unknown,Male,,8
5.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01065956,"Pollution, public disclosure, and firm behavior",September 1993,Gary Biglaiser,John K. Horowitz,,Male,Male,Unknown,Male,,1
5.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01065957,Welfare-optimal pricing and capacity selection under an ex ante maximum demand charge,September 1993,Seong-Uh Lee,,,Unknown,Unknown,Unknown,Unknown,,
5.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01065958,Price-cap regulation and market definition,September 1993,Ian Bradley,,,Male,Unknown,Unknown,Male,,1
5.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01065959,Calls for papers,September 1993,,,,Unknown,Unknown,Unknown,Unknown,,
5.0,4.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01065402,Superior regulatory regimes in theory and practice,December 1993,Dennis L. Weisman,,,Male,Unknown,Unknown,Male,,46
5.0,4.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01065403,Network costs and the regulation of wholesale competition in electric power,December 1993,Ross Baldick,Edward Kahn,,Male,Male,Unknown,Male,,21
5.0,4.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01065404,Measuring market response to regulation of the cable TV industry,December 1993,Kathleen A. Carroll,Douglas J. Lamdin,,Female,Male,Unknown,Mix,,
5.0,4.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01065405,Competition and the price of municipal cable television services: An empirical study,December 1993,Richard O. Beil Jr.,P. Thomas Dazzio Jr.,John D. Jackson,Male,Unknown,Male,Male,,18
5.0,4.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01065406,"Railroad deregulation, carrier behavior, and shipper response: A disaggregated analysis",December 1993,Mark L. Burton,,,Male,Unknown,Unknown,Male,,28
5.0,4.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01065407,A theoretic reappraisal of the offsetting behavior hypothesis,December 1993,Jon R. Neill,,,Male,Unknown,Unknown,Male,,2
5.0,4.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01065408,Book review,December 1993,Edward P. Kahn,,,Male,Unknown,Unknown,Male,,
5.0,4.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01065409,Editors' report 1993 (volume 5),December 1993,Michael A. Crew,Linda S. Brennan,,Male,Female,Unknown,Mix,,
6.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01065387,Bidder cost revelation in electric power auctions,February 1994,James B. Bushnell,Shmuel S. Oren,,Male,Male,Unknown,Male,,45
6.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01065388,Effects of securities deregulation in underwriting: An Analysis of SEC Rule 415,February 1994,M. Wayne Marr,Jeffry M. Netter,Annette B. Poulsen,Unknown,Male,Female,Mix,,
6.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01065389,Advertising and sales promotion in electricity,February 1994,R. Ashley Lyman,,,Unknown,Unknown,Unknown,Unknown,,
6.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01065390,A welfare anomaly in the rate-of-return regulated monopoly model which creates opportunities for offsetting taxation and regulatory policies,February 1994,Chin W. Yang,John A. Fox,,,Male,Unknown,Mix,,
6.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01065391,The welfare economics of a health plan merger,February 1994,Roger Feldman,,,Male,Unknown,Unknown,Male,,12
6.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01065392,Investment without regulatory commitment: The case of elastic demand,February 1994,Santiago Urbiztondo,,,Male,Unknown,Unknown,Male,,6
6.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01065393,Regulating oligopolistic industries: A generalized incentive scheme,February 1994,Sylvia Schwermer,,,Female,Unknown,Unknown,Female,,6
6.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01065746,Comparing the costs and benefits of diversification by regulated firms,May 1994,Timothy J. Brennan,Karen Palmer,,Male,Female,Unknown,Mix,,
6.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01065747,Should bank branching be regulated? Theory and empirical evidence from four European countries,May 1994,Frank A. Schmid,,,Male,Unknown,Unknown,Male,,5
6.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01065748,Rent extraction and incentives for efficiency in recent regulatory proposals,May 1994,F. Gasmi,M. Ivaldi,J. J. Laffont,Unknown,Unknown,Unknown,Unknown,,
6.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01065749,Regulation of product safety characteristics under imperfect observability,May 1994,Yuk-Shee Chan,Anthony M. Marino,,Unknown,Male,Unknown,Male,,3
6.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01065750,Estimation of household preferences for long distance telecommunications carrier,May 1994,Raymond S. Hartman,Zareen F. Naqvi,,Male,Unknown,Unknown,Male,,7
6.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01064653,Downstream gas pricing in an era of upstream deregulation,September 1994,Daniel R. Hollas,,,Male,Unknown,Unknown,Male,,7
6.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01064654,Self-selecting tariffs under pure preferences among tariffs,September 1994,Kenneth E. Train,,,Male,Unknown,Unknown,Male,,2
6.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01064655,Challenging the enforcement of environmental regulation,September 1994,Clifford Nowell,Jason Shogren,,Male,Male,Unknown,Male,,17
6.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01064656,"Deregulation, competition, and the network size in the market for telecommunication services",September 1994,Benjamin Bental,Menahem Spiegel,,Male,Male,Unknown,Male,,1
6.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01064657,The capital structure and investment of regulated firms under alternative regulatory regimes,September 1994,Yossef Spiegel,,,Male,Unknown,Unknown,Male,,25
6.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01064658,An evaluation of incentive regulation: Corrections,September 1994,Sanford V. Berg,Jinook Jeong,,Male,Unknown,Unknown,Male,,
6.0,4.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01418231,Why less may be more under price-cap regulation,December 1994,Dennis L. Weisman,,,Male,Unknown,Unknown,Male,,19
6.0,4.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01418232,Market access in regulated and unregulated markets: The continuing cost of interstate motor carrier regulation,December 1994,Wesley W. Wilson,Richard Beilock,,Male,Male,Unknown,Male,,7
6.0,4.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01418233,Economies of scope in the local telephone exchange market,December 1994,David Gabel,D. Mark Kennet,,Male,Unknown,Unknown,Male,,26
6.0,4.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01418234,Private ownership form and productive efficiency: Electric cooperatives versus investor-owned utilities,December 1994,Michael Dan Berry,,,Male,Unknown,Unknown,Male,,15
6.0,4.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01418235,The efficiency costs of the postal monopoly: The case of third-class mail,December 1994,Thomas M. Lenard,,,Male,Unknown,Unknown,Male,,1
6.0,4.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01418236,"Regulatory information, market expectations, and the determination of the allowed rate of return",December 1994,Dennis K. Fan,Thomas G. Cowing,,Male,Male,Unknown,Male,,
7.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01062777,Efficient price and capacity choices under uncertain demand: An empirical analysis,January 1995,Martin A. Koschat,Padmanabhan Srinagesh,Linda J. Uhler,Male,Unknown,Female,Mix,,
7.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01062778,Deregulation and the competitive fringe: Owner-operators in the trucking industry,January 1995,James Peoples,Margaret Peteraf,,Male,Female,Unknown,Mix,,
7.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01062779,Impact of regulation on demand side conservation programs,January 1995,Franz Wirl,,,Male,Unknown,Unknown,Male,,21
7.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01062780,Market and regulatory forces in the pricing of legal services,January 1995,Dean Lueck,Reed Olsen,Michael Ransom,Male,Male,Male,Male,,14
7.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01062781,Optimal linear taxation of polluting oligopolists,January 1995,Sherrill Shaffer,,,,Unknown,Unknown,Mix,,
7.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01062782,Letter from the editor,January 1995,Michael A. Crew,,,Male,Unknown,Unknown,Male,,
7.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01062686,Toward a benchmark for optimal prudency policy,March 1995,William E. Encinosa III,David E. M. Sappington,,Male,Male,Unknown,Male,,3
7.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01062687,How many karats is gold: Welfare effects of easing a denomination standard,March 1995,Claude Crampes,Abraham Hollander,,,Male,Unknown,Mix,,
7.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01062688,The CPSC's ATV risk model,March 1995,Edward J. Heiden,Thomas M. Lenard,,Male,Male,Unknown,Male,,4
7.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01062689,Incremental R&D subsidies,March 1995,Martin Richardson,Simon Wilkie,,Male,Male,Unknown,Male,,8
7.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01062690,"Dilution costs, underinvestment, and utility regulation under asymmetric information",March 1995,Jayant R. Kale,Thomas H. Noe,,Unknown,Male,Unknown,Male,,5
7.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01062691,The formation of public utility holding companies and their subsequent diversification activity,March 1995,H. David Robison,Wallace N. Davidson III,John L. Glascock,Unknown,Male,Male,Male,,2
7.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01067096,Regulatory hindsight review and innovation by electric utilities,May 1995,Thomas P. Lyon,,,Male,Unknown,Unknown,Male,,10
7.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01067097,Regulation of product safety design through product testing,May 1995,Anthony M. Marino,,,Male,Unknown,Unknown,Male,,2
7.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01067098,"Auctioning incentive contracts: The common cost, independent types case",May 1995,Fernando Branco,,,Male,Unknown,Unknown,Male,,2
7.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01067099,Why do regulators regulate? The case of the southern California gas market,May 1995,Jerry Ellig,,,Male,Unknown,Unknown,Male,,2
7.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01067100,"Quacks, lemons, and self regulation: A welfare analysis",May 1995,Thomas Gehrig,Peter -J. Jost,,Male,Male,Unknown,Male,,40
8.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01066596,Environmental taxation for environmental regulation and fiscal policy: An analysis of a Clinton-type BTU tax,July 1995,Kerry Krutilla,W. Kip Viscusi,Roy Boyd,,Unknown,Male,Mix,,
8.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01066597,The relationship between the costs and prices of a multi-product monopoly: The role of price-cap regulation,July 1995,Rob Fraser,,,Male,Unknown,Unknown,Male,,12
8.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01066598,Dynamic pollution regulation,July 1995,Gary Biglaiser,John K. Horowitz,John Quiggin,Male,Male,Male,Male,,50
8.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01066599,Conduct effects of gradual entry liberalization in insurance,July 1995,Pedro Pita Barros,,,Male,Unknown,Unknown,Male,,2
8.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01066600,Environmental regulation and international trade,July 1995,Eftichios Sophocles Sartzetakis,Christos Constantatos,,Unknown,Male,Unknown,Male,,6
8.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01066601,Supervision and cost efficiency in banking,July 1995,Joseph A. Newman,Harold A. Black,Ronald E. Shrieves,Male,Male,Male,Male,,1
8.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01066602,Announcement,July 1995,,,,Unknown,Unknown,Unknown,Unknown,,
8.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01072585,A market test for natural monopoly in local exchange,September 1995,Sanford V. Berg,John Tschirhart,,Male,Male,Unknown,Male,,6
8.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01072586,Reevaluating the relationship between transferable property rights and command-and-control regulation,September 1995,Robert W. Hahn,Robert L. Axtell,,Male,Male,Unknown,Male,,15
8.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01072587,The relationship between regulation and prices in the workers' compensation insurance market,September 1995,Anne Carroll,Robert Kaestner,,Female,Male,Unknown,Mix,,
8.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01072588,Are safety and environmental performance standards optimal regulatory instruments?,September 1995,Anthony M. Marino,,,Male,Unknown,Unknown,Male,,4
8.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01072589,Regulation and the market for corporate control: Hostile tender offers for electric and gas utilities,September 1995,Robyn M. Mclaughlin,Hamid Mehran,,Female,Male,Unknown,Mix,,
8.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01070807,The theory of peak-load pricing: A survey,November 1995,Michael A. Crew,Chitru S. Fernando,Paul R. Kleindorfer,Male,Unknown,Male,Male,,223
8.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01070808,Regulation and the vertically integrated firm: The case of RBOC entry into interlata long distance,November 1995,Dennis L. Weisman,,,Male,Unknown,Unknown,Male,,48
8.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01070809,Disentangling regulatory policy: The effects of state regulations on trucking rates,November 1995,Timothy P. Daniel,Andrew N. Kleit,,Male,Male,Unknown,Male,,4
8.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01070810,An analysis of asymmetric demand response to price changes: The case of local telephone calls,November 1995,Miles O. Bidwell Jr.,Bruce X. Wang,J. Douglas Zona,Male,Male,Unknown,Male,,15
8.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF01070811,Regulating a multi-product monopolist,November 1995,Jae-Cheol Kim,Choong-Young Jung,,Male,Unknown,Unknown,Male,,4
9.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00134817,Regulation and administered contracts revisited: Lessons from transaction-cost economics for public utility regulation,January 1996,Keith J. Crocker,Scott E. Masten,,Male,Male,Unknown,Male,,103
9.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00134818,Evaluating the performance of non-Bayesian regulatory mechanisms,January 1996,Thomas P. Lyon,,,Male,Unknown,Unknown,Male,,4
9.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00134819,Scope-of-practice regulation: Physician control and the wages of non-physician health-care professionals,January 1996,Tim R. Sass,Mark W. Nichols,,Male,Male,Unknown,Male,,9
9.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00134820,Taxation and market power when products are durable,January 1996,Gregory E. Goering,John R. Boyce,,Male,Male,Unknown,Male,,10
9.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00134821,Concavity assumptions in regulatory models and the capital waste controversy,January 1996,Larry Robert Blank,,,Male,Unknown,Unknown,Male,,2
9.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00240366,Screening consumers through alternative pricing mechanisms,March 1996,Eugenio J. Miravete,,,Male,Unknown,Unknown,Male,,22
9.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00240367,Why energy transitions matter: A case study of methanol,March 1996,Robert W. Hahn,Matthew S. Borick,,Male,Male,Unknown,Male,,
9.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00240368,Futures trading and fuel adjustment clauses,March 1996,Donald Lien,Lihong Liu,,Male,Unknown,Unknown,Male,,2
9.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00240369,Regulated firms in pollution permit markets with banking,March 1996,Mark B. Cronshaw,Jamie Brown Kruse,,Male,,Unknown,Mix,,
9.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00240370,Regulation by prices and by command,March 1996,Amihai Glazer,Charles Lave,,Male,Male,Unknown,Male,,3
9.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00133474,Incentive regulation in the United Kingdom and the United States: Some lessons,May 1996,Michael A. Crew,Paul R. Kleindorfer,,Male,Male,Unknown,Male,,84
9.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00133475,A model of sliding-scale regulation,May 1996,Thomas P. Lyon,,,Male,Unknown,Unknown,Male,,46
9.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00133476,Balancing multiple interests in regulation: An event study of the English and Welsh water industry,May 1996,John W. Sawkins,,,Male,Unknown,Unknown,Male,,15
9.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00133477,The effects of incentive regulation in the telecommunications industry: A survey,May 1996,Donald J. Kridel,David E. M. Sappington,Dennis L. Weisman,Male,Male,Male,Male,,89
10.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00133356,Folk theorems on transmission access: Proofs and counterexamples,July 1996,Felix Wu,Pravin Varaiya,Shmuel Oren,Male,Unknown,Male,Male,,173
10.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00133357,A market mechanism for electric power transmission,July 1996,Hung-Po Chao,Stephen Peck,,Unknown,Male,Unknown,Male,,289
10.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00133358,Electric grid investment under a contract network regime,July 1996,James B. Bushnell,Steven E. Stoft,,Male,Male,Unknown,Male,,98
10.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00133359,Towards an efficiency interpretation of regulatory implementation lags,July 1996,Anthony G. Heyes,,,Male,Unknown,Unknown,Male,,3
10.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00133360,Incentive effects of rate-of-return regulation: The case of Hong Kong electric utilities,July 1996,Yoram C. Peles,Greg Whittred,,Male,Male,Unknown,Male,,4
10.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00133528,Telephone pools and economic incentives,September 1996,Dale E. Lehman,Dennis L. Weisman,,,Male,Unknown,Mix,,
10.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00133529,The economic possibilities of natural gas conservation: Antithetical results of prorationing regulation,September 1996,Janie M. Chermak,,,Female,Unknown,Unknown,Female,,4
10.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00133530,The role of market forces in EPA enforcement activity,September 1996,S. G. Badrinath,Paul J. Bolster,,Unknown,Male,Unknown,Male,,44
10.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00133531,Repeated auctions of franchises for nonrenewable resources,September 1996,Petter Osmundsen,,,Male,Unknown,Unknown,Male,,4
10.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00133532,The cost of procuring market-inalienable human organs,September 1996,Emanuel D. Thorne,,,Male,Unknown,Unknown,Male,,12
10.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00133533,Revisiting all-terrain vehicle injury risks: Response to critique,September 1996,Gregory B. Rodgers,,,Male,Unknown,Unknown,Male,,3
10.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00157671,Creating competition through interconnection: Theory and practice,November 1996,Jean-Jacques Laffont,Idei Gremaq,MIT,Unknown,Unknown,Unknown,Unknown,,
10.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00157672,Price regulation of drugs: Lessons from Germany,November 1996,Peter Zweifel,Luca Crivelli,,Male,Male,Unknown,Male,,36
10.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00157673,Commercial banks and real estate lending: The Texas experience,November 1996,Robert A. Eisenbeis,Paul M. Horvitz,Rebel A. Cole,Male,Male,Unknown,Male,,3
10.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00157674,The impact of regulation on productivity growth: An application to the transmission sector of the interstate natural gas industry,November 1996,Gerald Granderson,Carl Linvill,,Male,Male,Unknown,Male,,5
10.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00157675,Ramsey pricing and competition: The consequences of myopic regulation,November 1996,James E. Prieger,,,Male,Unknown,Unknown,Male,,10
10.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/BF00157676,A reply to: “Revisiting All-Terrain Injury Risks: Response to Critique”,November 1996,Edward J. Heiden,Thomas M. Lenard,,Male,Male,Unknown,Male,,
11.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1007909927507,"Service Quality, Competition, and Regulatory Policies in the Postal Sector",January 1997,Helmuth Cremer,Marc De Rycke,André Grimaud,Male,Male,Male,Male,,11
11.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1007946111577,Cost Savings and Productivity in the Railroad Industry,January 1997,Wesley W. Wilson,,,Male,Unknown,Unknown,Male,,65
11.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1007998128416,"Stranded Costs, Takings, and the Law and Economics of Implicit Contracts",January 1997,Timothy J. Brennan,James Boyd,,Male,Male,Unknown,Male,,22
11.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1007950212486,Efficiency Wages and the Regulated Firm,January 1997,Jasmin Ansar,Paul Cantor,Roger W. Sparks,Female,Male,Male,Mix,,
11.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1007902329324,Assessing the Impact of FCC Lifeline and Link-Up Programs on Telephone Penetration,January 1997,Christopher Garbacz,Herbert G. Thompson Jr.,,Male,Male,Unknown,Male,,25
11.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1007954314303,Retroactive Liability or the Public Purse?,January 1997,James Boyd,Howard Kunreuther,,Male,Male,Unknown,Male,,10
11.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1007910531141,An Efficient Avoided Cost Pricing Rule for Resale of Local Exchange Telephone Services,January 1997,David L. Kaserman,John W. Mayo,,Male,Male,Unknown,Male,,7
11.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1007989730081,The Effects of Rivalry with Price Regulation of Electric Power Generation,March 1997,Ronald R. Braeutigam,,,Male,Unknown,Unknown,Male,,1
11.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1007945915060,Regulation of Quality and the Ratchet Effect: Does Unverifiability Hurt the Regulator?,March 1997,Dag Morten Dalen,,,Male,Unknown,Unknown,Male,,6
11.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1007902215969,A Welfare Analysis of Local Franchise and Other Types of Regulation: Evidence from the Cable TV Industry,March 1997,Yasuji Otsuka,,,Male,Unknown,Unknown,Male,,15
11.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1007906300039,Effects of Appliance Standards on Product Price and Attributes: An Hedonic Pricing Model,March 1997,Lorna A. Greening,Alan H. Sanstad,James E. McMahon,Female,Male,Male,Mix,,
11.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1007958317786,Using Market Prices to Regulate the Costs of a Utility‘s Inputs,March 1997,Nicholas Crew,,,Male,Unknown,Unknown,Male,,4
11.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1007954105032,An Analysis of the State of Competition in Long-Distance Telephone Markets,May 1997,William E. Taylor,J. Douglas Zona,,Male,Unknown,Unknown,Male,,21
11.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1007927021871,"Entry, Prices, and Investment in Regulated Industries",May 1997,Gianni De Fraja,,,Male,Unknown,Unknown,Male,,3
11.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1007979005941,In the Matter of Weyerhaeuser Company: The Use of a Hold-Separate Order in a Merger with Horizontal and Vertical Effects,May 1997,Laurence Schumann,James D. Reitzes,Robert P. Rogers,Female,Male,Male,Mix,,
11.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1007931122779,"Costs, Productivity, and Firm Heterogeneity in Local Telephone Markets",May 1997,Wesley W. Wilson,Yimin Zhou,,Male,Unknown,Unknown,Male,,4
11.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1007983106850,"Fuel Economy Standards, New Vehicle Sales, and Average Fuel Efficiency",May 1997,Steven G. Thorpe,,,Male,Unknown,Unknown,Male,,24
12.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1007939802271,Incentive Regulation and The Cost Structure of The Local Telephone Exchange Network,July 1997,F. Gasmi,J.J. Laffont,W.W. Sharkey,Unknown,Unknown,Unknown,Unknown,,
12.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1007905819109,Nineteenth Century Urban Market Failure?: Chadwick on Funeral Industry Regulation,July 1997,Robert B. Ekelund Jr.,George S. Ford,,Male,Male,Unknown,Male,,14
12.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1007957803179,Price-Cap Regulation and Inefficiency in Relative Pricing,July 1997,Simon Cowan,,,Male,Unknown,Unknown,Male,,16
12.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1007909920018,"Essentiality, Efficiency, and the Efficient Component-Pricing Rule",July 1997,Alexander C. Larson,Dale E. Lehman,,Male,,Unknown,Mix,,
12.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1007961904088,The Efficiency Gains from Deregulation,July 1997,Marc Poitras,Daniel Sutter,,Male,Male,Unknown,Male,,4
12.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1007914004997,A Note on Regulating Oligopolistic Industries: A Hierarchical Model,July 1997,Sang-Ho Lee,,,Male,Unknown,Unknown,Male,,7
12.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1007976710490,Medical Board Regulation of Physician Licensure: Is Excessive Malpractice Sanctioned?,September 1997,Gary M. Fournier,Melayne Morgan Mcinnes,,Male,Unknown,Unknown,Male,,5
12.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1007949427329,"Monitoring, Appeal, and Investigation: The Enforcement and Legal Process",September 1997,Peter-J. Jost,,,Unknown,Unknown,Unknown,Unknown,,
12.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1007901511399,Econometric Cost Structure Estimates for Cellular Telephony in the United States,September 1997,David J. McKenzie,John P. Small,,Male,Male,Unknown,Male,,27
12.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1007953528237,Must Carry Regulations for Cable Television Systems: An Empirical Analysis,September 1997,Michael G. Vita,,,Male,Unknown,Unknown,Male,,8
12.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1007905612308,Prices and Outputs Under Cable TV Reregulation,September 1997,Thomas W. Hazlett,,,Male,Unknown,Unknown,Male,,8
12.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1007957629146,The United States International Air Route Award Process: Shareholder Wealth Effects and Policy Implications,September 1997,Stephen W. Pruitt,George E. Hoffer,K.S. Maurice Tse,Male,Male,Unknown,Male,,2
12.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1007925111944,Choosing Among Regulatory Options in the United States Telecommunications Industry,November 1997,Stephen G. Donald,David E. M. Sappington,,Male,Male,Unknown,Male,,26
12.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1007901928782,A Model of Product Recalls with Asymmetric Information,November 1997,Anthony M. Marino,,,Male,Unknown,Unknown,Male,,17
12.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1007953912853,"Regulatory Monitoring, Closure Costs and Bank Moral Hazard Behavior",November 1997,Sumon C. Mazumdar,,,Unknown,Unknown,Unknown,Unknown,,
12.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1007906029691,"Non Utility Power, Alternative Regulatory Regimes and Stranded Investment",November 1997,Shiow-Ying Wen,John Tschirhart,,Unknown,Male,Unknown,Male,,6
12.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1007958013761,A Note on Regulating a Multiproduct Monopolist,November 1997,Sang-Ho Lee,,,Male,Unknown,Unknown,Male,,6
12.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1007910130599,Incentive Effects of Rate-of-Return Regulation in Hong Kong,November 1997,Pun-Lee Lam,,,Unknown,Unknown,Unknown,Unknown,,
12.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1007962131508,Incentive Effects of Rate-of-Return Regulation in Hong Kong: Reply,November 1997,Yoram C. Peles,Greg Whittred,,Male,Male,Unknown,Male,,
13.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1007970031068,Monitoring of Pollution Regulation: Do Local Conditions Matter?,January 1998,Catherine Dion,Paul Lanoie,Benoit Laplante,Female,Male,Unknown,Mix,,
13.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1007934515138,Bill Averaging Programs and Consumer Behavior: Theory and Evidence,January 1998,T. Randolph Beard,Daniel M. Gropper,Jennie E. Raymond,Unknown,Male,Female,Mix,,
13.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1007986531977,Cross-Industry Emission Permits Trading,January 1998,Nguyen Manh Hung,Eftichios Sophocles Sartzetakis,,Unknown,Unknown,Unknown,Unknown,,
13.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1007938616047,"Minimum Quality Standards, Entry, and the Timing of the Quality Decision",January 1998,Christos Constantatos,Stylianos Perrakis,,Male,Male,Unknown,Male,,15
13.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1007990600117,"Competition and Diversification Trends in Telecommunications: Regulatory, Technological and Market Pressures",January 1998,Harold Ware,,,Male,Unknown,Unknown,Male,,4
13.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008022331188,"Firms Responses to Effluent Regulations: Pulp and Paper in Ontario, 1985-1989",March 1998,Paul Lanoie,Mark Thomas,Joan Fearnley,Male,Male,Female,Mix,,
13.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008056615258,"Environmental Protection, Agency Motivations, and Rent Extraction: The Regulation of Water Pollution in Louisiana",March 1998,Andrew N. Kleit,Meredith A. Pierce,R. Carter Hill,Male,,Unknown,Mix,,
13.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008008732096,The Economic Effects of Postal Reorganization,March 1998,Rick Geddes,,,Male,Unknown,Unknown,Male,,4
13.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008060716167,Cross-Subsidization in Telecommunications,March 1998,Steve G. Parsons,,,Male,Unknown,Unknown,Male,,13
13.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008012800237,An Analysis of the Welfare Effects of Long-Distance Market Entry by an Integrated Access and Long-Distance Provider,March 1998,Paul J. Hinton,J. Douglas Zona,William E. Taylor,Male,Unknown,Male,Male,,5
13.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008027419553,The Regulation of the United Kingdom Electricity Industry: An Event Study of Price-Capping Measures,May 1998,Antony W. Dnes,Devendra G. Kodwani,Douglas Wood,Male,Female,Male,Mix,,
13.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008077003624,Partial Ownership and Foreclosure: An Empirical Analysis,May 1998,David Reiffen,,,Male,Unknown,Unknown,Male,,11
13.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008029120462,The Simple Welfare Economics of Network Externalities and the Uneasy Case for Subscribership Subsidies,May 1998,A. H. Barnett,David L. Kaserman,,Unknown,Male,Unknown,Male,,9
13.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008081104532,The Impact of Stranded-Cost Risk on Required Rates of Return for Electric Utilities: Theory and an Example,May 1998,A. Lawrence Kolbe,Lynda S. Borucki,,Unknown,Female,Unknown,Female,,6
13.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008033221371,Reliability Differentiation of Electricity Transmission,May 1998,Chi-Keung Woo,Ira Horowitz,Jennifer Martin,Unknown,Female,Female,Female,,24
14.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008042803151,Regulation of Performance Standards versus Equipment Specification with Asymmetric Information,July 1998,Anthony M. Marino,,,Male,Unknown,Unknown,Male,,10
14.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008067504059,Did Open Access Integrate Natural Gas Markets? An Arbitrage Cost Approach,July 1998,Andrew N. Kleit,,,Male,Unknown,Unknown,Male,,24
14.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008071604968,Dominant Firm Pricing with Competitive Entry and Regulation: The Case of IntraLATA Toll,July 1998,Larry Blank,David L. Kaserman,John W. Mayo,Male,Male,Male,Male,,14
14.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008075721806,An Experimental Study of Electronic Bulletin Board Trading for Emission Permits,July 1998,Timothy N. Cason,Lata Gangadharan,,Male,Female,Unknown,Mix,,
14.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008027805876,Market Share Quotas and Community Reinvestment,July 1998,Sherrill Shaffer,,,,Unknown,Unknown,Mix,,
14.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008079822715,A Regulated Firm's Incentive to Discriminate: A Reevaluation and Extension of Weisman's Result,July 1998,David Reiffen,,,Male,Unknown,Unknown,Male,,28
14.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008031906785,The Incentive to Discriminate by a Vertically-Integrated Regulated Firm: A Reply,July 1998,Dennis L. Weisman,,,Male,Unknown,Unknown,Male,,18
14.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008088017364,"Efficient Entry, Monopoly, and the Universal Service Obligation in Postal Service",September 1998,Michael A. Crew,Paul R. Kleindorfer,,Male,Male,Unknown,Male,,30
14.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008005201435,The Impact of Industry Structure and Penalty Policies on Incentives for Compliance and Regulatory Enforcement,September 1998,Kelly Kristen Lear,John W. Maxwell,,,Male,Unknown,Mix,,
14.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008057218273,Regulating Prices to Equal Forward-Looking Costs: Cost-Based Prices or Price-Based Costs?,September 1998,Michael A. Salinger,,,Male,Unknown,Unknown,Male,,21
14.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008009302343,"Stochastic Demand for Hospitals and Optimizing ""Excess"" Bed Capacity",September 1998,Kathleen Carey,,,Female,Unknown,Unknown,Female,,24
14.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008061319181,Reliability Management in Competitive Electricity Markets,September 1998,Hung-Po Chao,Stephen C. Peck,,Unknown,Male,Unknown,Male,,42
14.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008014906195,A Dynamic Model of Incumbent LEC Response to Entry Under the Terms of the Telecommunications Act of 1996,November 1998,Trevor R. Roycroft,,,Male,Unknown,Unknown,Male,,1
14.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008079223033,Pollution Regulation and the Efficiency Gains from Technological Innovation,November 1998,Ian W.H. Parry,,,Male,Unknown,Unknown,Male,,52
14.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008031307103,Penalty Functions for Environmental Violations: Evidence from Water Quality Enforcement,November 1998,Neda Oljaca,Andrew G. Keeler,Jeffrey Dorfman,Female,Male,Male,Mix,,
14.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008083308012,Competition in Payphones: State Regulations and Independent Providers' Shares,November 1998,Amy Erenrich,Richard E. Caves,,Female,Male,Unknown,Mix,,
14.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008087424850,Mergers in Regulated Industries: the Uses and Abuses of Event Studies,November 1998,Alan J. Cox,Jonathan Portes,,Male,Male,Unknown,Male,,25
15.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008093607129,"Deregulation, Mergers, and Employment in the Railroad Industry",January 1999,David E. Davis,Wesley W. Wilson,,Male,Male,Unknown,Male,,14
15.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008044823968,Conservation Incentives for Consumers,January 1999,Franz Wirl,,,Male,Unknown,Unknown,Male,,6
15.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008096808038,On and Off the Liability Bandwagon: Explaining State Adoptions of Strict Liability in Hazardous Waste Programs,January 1999,Anna Alberini,David Austin,,Female,Male,Unknown,Mix,,
15.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008048924876,Does Ownership or Competition Matter? The Effects of Telecommunications Reform on Network Expansion and Efficiency,January 1999,Agustin J. Ros,,,Male,Unknown,Unknown,Male,,143
15.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008001008947,"Electric Utility Restructuring, Regulation of Distribution Utilities, and the Fallacy of ""Avoided Cost"" Rules",January 1999,Jonathan A. Lesser,Charles D. Feinstein,,Male,Male,Unknown,Male,,2
15.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008053125785,"Regulations, Institutions, and Commitment: Comparative Studies of Telecommunications",January 1999,Barbara Cherry,,,Female,Unknown,Unknown,Female,,1
15.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008083026348,Price Dynamics in a Network of Decentralized Power Markets,March 1999,Arthur S. De Vany,W. David Walls,,Male,Unknown,Unknown,Male,,34
15.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008077710419,Franchise Bidding Without Holdups: Utility Regulation with Efficient Pricing and Choice of Provider,March 1999,Ronald M. Harstad,Michael A. Crew,,Male,Male,Unknown,Male,,16
15.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008029827257,On the Economics of Callback Services,March 1999,Hyun-Woo Choi,Kyoung-Lim Yun,Byong-Hun Ahn,Male,Unknown,Unknown,Male,,15
15.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008081828166,The Competitive Impact of Disclosure Requirements in the Credit Card Industry,March 1999,Sherrill Shaffer,,,,Unknown,Unknown,Mix,,
15.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008085912236,Load Profiling: A California Application,March 1999,Carl H. Silsbee,Stathis Kostopoulos,,Male,Male,Unknown,Male,,2
15.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008093229363,Using Market Structure to Regulate a Vertically Integrated Monopolist,May 1999,Sang Hyup Lee,Jonathan H. Hamilton,,,Male,Unknown,Mix,,
15.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008078230272,"Regulation, Profit Variability and Beta",May 1999,John J. Binder,Seth W. Norton,,Male,Male,Unknown,Male,,20
15.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008082314342,"International Telecommunications, Settlement Rates, and the FCC",May 1999,Julian Wright,,,Male,Unknown,Unknown,Male,,21
15.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008034415251,Optimal Taxation for Polluting Oligopolists with Endogenous Market Structure,May 1999,Sang-Ho Lee,,,Male,Unknown,Unknown,Male,,62
15.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008038517068,Consumer Self-Generation and Monopoly Limit-Pricing under Timing Uncertainty of Deregulation in the Electricity Market,May 1999,Chien-Ping Chen,,,Unknown,Unknown,Unknown,Unknown,,
16.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008178112895,Setting the X Factor in Price-Cap Regulation Plans,July 1999,Jeffrey I. Bernstein,David E. M. Sappington,,Male,Male,Unknown,Male,,74
16.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008179629733,The Effect of Privatization on Public Transit Costs,July 1999,Matthew Karlaftis,Patrick McCarthy,,Male,Male,Unknown,Male,,30
16.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008131714712,Calling Patterns and Usage of Residential Toll Service under Self Selecting Tariffs,July 1999,Bosang Lee,,,Unknown,Unknown,Unknown,Unknown,,
16.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008187831550,On Setting Prices and Testing Cross-Subsidy with Accounting Data,July 1999,Michael D. Bradley,Jeff Colvin,John C. Panzar,Male,Male,Male,Male,,10
16.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008139900120,Optimal Regulation of a Fully Insured Deposit Banking System,September 1999,Xavier Freixas,Emmanuelle Gabillon,,Male,Female,Unknown,Mix,,
16.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008188801029,Effects of Risk-Based Capital Requirements and Asymmetric Information on Banks' Portfolio Decisions,September 1999,Sangkyun Park,,,Unknown,Unknown,Unknown,Unknown,,
16.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008192917867,A Voluntary Subsidy Scheme for the Accounting Rate System in International Telecommunications Industries,September 1999,Koji Domon,Kazuharu Kiyono,,Male,Unknown,Unknown,Male,,2
16.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008145001937,Gas Utility Prices in a Restructured Industry,September 1999,Daniel R. Hollas,,,Male,Unknown,Unknown,Male,,6
16.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008197018776,Event Studies of Regulation and New Results on the Effect of the Cigarette Advertising Ban,September 1999,Douglas J. Lamdin,,,Male,Unknown,Unknown,Male,,15
16.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1017253220593,Wesley A. Magat 1948-1999,September 1999,,,,Unknown,Unknown,Unknown,Unknown,,
16.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008149121680,Investment Incentives of a Regulated Dominant Firm,November 1999,Gary Biglaiser,Ching-To Albert Ma,,Male,Unknown,Unknown,Male,,9
16.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008174905751,Optimal Reimbursement and Malpractice Sharing Rules in Health Care Markets,November 1999,Esther Gal-Or,,,Female,Unknown,Unknown,Female,,14
16.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008127022589,"State Accountancy Regulations, Audit Firm Size, and Auditor Quality: An Empirical Investigation",November 1999,Gary Colbert,Dennis Murray,,Male,Male,Unknown,Male,,8
16.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008179006659,Access to an Essential Facility: Efficient Component Pricing Rule or Unrestricted Private Property Rights?,November 1999,Paolo Buccirossi,,,Male,Unknown,Unknown,Male,,2
16.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008131223498,Scale Economies In Cellular Telephony: Size Matters,November 1999,R. Dean Foreman,Edward Beauvais,,Unknown,Male,Unknown,Male,,18
17.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008107103804,Incentive Indexes for Regulated Industries,February 2000,W. Erwin Diewert,Kevin J. Fox,,Unknown,Male,Unknown,Male,,2
17.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008149220642,Railroad Revisionists Revisited: Stock Market Evidence from the Progressive Era,February 2000,Wallace P. Mullin,,,Male,Unknown,Unknown,Male,,10
17.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008101304713,"Deregulation of the Electric Power Industry: The Earnings, Risk, and Return Effects",February 2000,Emeka T. Nwaeze,,,Unknown,Unknown,Unknown,Unknown,,
17.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008153321551,Mergers in the Electric Utility Industry in a Deregulatory Environment,February 2000,Karyl B. Leggio,Donald Lien,,Unknown,Male,Unknown,Male,,22
17.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008105405621,Regulatory Uncertainty and Share Price Volatility: the English and Welsh Water Industry’s Periodic Price Review,February 2000,Claudio Morana,John W. Sawkins,,Male,Male,Unknown,Male,,24
17.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008157410380,Implementing Environmental Regulation: Enforcement and Compliance,March 2000,Anthony Heyes,,,Male,Unknown,Unknown,Male,,141
17.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008139927218,Neighborhood Demographics and the Distribution of Hazardous Waste Risks: An Instrumental Variables Estimation,March 2000,Ted Gayer,,,Male,Unknown,Unknown,Male,,18
17.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008191911289,Killing the Goose That May Have Laid the Golden Egg: Only the Data Know Whether Sabotage Pays,March 2000,David M. Mandy,,,Male,Unknown,Unknown,Male,,69
17.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008144028127,Estimating the Optimal Scale of Public Investments: The Case of Low-Level Radioactive Waste Disposal Facilities,March 2000,Jeffrey Wagner,,,Male,Unknown,Unknown,Male,,
17.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008196131032,Auctions and Regulation: Reengineering of Regulatory Mechanisms**,May 2000,David Salant,,,Male,Unknown,Unknown,Male,,13
17.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008122015102,Mutually Destructive Bidding: The FCC Auction Design Problem,May 2000,Mark M. Bykowsky,Robert J. Cull,John O. Ledyard,Male,Male,Male,Male,,77
17.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008174031940,Collusive Bidding: Lessons from the FCC Spectrum Auctions,May 2000,Peter Cramton,Jesse A. Schwartz,,Male,Male,Unknown,Male,,118
17.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008126116011,An Insiders' View of FCC Spectrum Auctions,May 2000,Evan R. Kwerel,Gregory L. Rosston,,Male,Male,Unknown,Male,,34
18.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008151712010,Evaluation of a Truthful Revelation Auction in the Context of Energy Markets with Nonconcave Benefits,July 2000,Benjamin F. Hobbs,Michael H. Rothkopf,Richard P. O'Neill,Male,Male,Male,Male,,59
18.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008126828848,Auctions for Universal Service Subsidies,July 2000,Valter Sorana,,,Male,Unknown,Unknown,Male,,14
18.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008178812919,Determining the Source of Inter-License Synergies in Two-Way Paging Networks,July 2000,Hal J. Singer,,,Male,Unknown,Unknown,Male,,
18.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008130915939,More is Less? Regulation in a Rent Seeking World,September 2000,James F. Dewey,,,Male,Unknown,Unknown,Male,,2
18.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008160317757,Effective Enforcement of a Transferable Emissions Permit System with a Self-Reporting Requirement,September 2000,John K. Stranlund,Carlos A. Chavez,,Male,Male,Unknown,Male,,29
18.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008168501827,Catching-Up Investment without Regulatory Commitment,September 2000,Dag Morten Dalen,,,Male,Unknown,Unknown,Male,,2
18.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008120618665,Peering and Settlement in the Internet: An Economic Analysis,September 2000,Iain Little,Julian Wright,,Male,Male,Unknown,Male,,15
18.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008172602736,Excess Returns in Electric Utility Mergers During Transition to Competition,September 2000,S. Keith Berry,,,Unknown,Unknown,Unknown,Unknown,,
18.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008124703161,Motorcycle Helmet Laws and Motorcyclist Fatalities,November 2000,Tim R. Sass,Paul R. Zimmerman,,Male,Male,Unknown,Male,,42
18.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008150819999,Regulatory Restrictions on Vertical Integration and Control: The Competitive Impact of Gasoline Divorcement Policies,November 2000,Michael G. Vita,,,Male,Unknown,Unknown,Male,,66
18.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008102904069,Minimum Quality Standards Under Cournot Competition,November 2000,Tommaso M. Valletti,,,Male,Unknown,Unknown,Male,,77
18.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008155020908,The Economic Logic for Conditioning Bell Entry into Long Distance on the Prior Opening of Local Markets,November 2000,Marius Schwartz,,,Male,Unknown,Unknown,Male,,7
19.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008126711411,Political and Regulatory Risk: Beta Sensitivity in U.K. Electricity Distribution*,January 2001,Roger Buckland,Patricia Fraser,,Male,Female,Unknown,Mix,,
19.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008143528249,Transmission Constraints and Imperfect Markets for Power,January 2001,Thomas-Olivier Léautier,,,Unknown,Unknown,Unknown,Unknown,,
19.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008195512319,Environmental Regulation and Substitution Between Sources of Pollution: An Empirical Analysis of Florida’s Storage Tanks,January 2001,Anna Alberini,,,Female,Unknown,Unknown,Female,,14
19.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008147629158,Optimal Worksharing Discounts,January 2001,Roger Sherman,,,Male,Unknown,Unknown,Male,,8
19.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1008199613228,Universal Service Versus Universal Competition: A Review Article of Crandall and Waverman,January 2001,Christopher Garbacz,Herbert G. Thompson Jr.,,Male,Male,Unknown,Male,,1
19.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1011106721301,Entry and Competition in the Postal Market: Foundations for the Construction of Entry Scenarios*,March 2001,Helmuth Cremer,André Grimaud,Joëlle Toledano,Male,Male,Female,Mix,,
19.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1011141105371,Divestiture of Generation Assets in the Electricity Pool of England and Wales: A Computational Approach to Analyzing Market Power,March 2001,Christopher J. Day,Derek W. Bunn,,Male,Male,Unknown,Male,,57
19.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1011193123118,An Empirical Examination of Entry Patterns in Local Telephone Markets*,March 2001,James Zolnierek,James Eisner,Ellen Burton,Male,Male,Female,Mix,,
19.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1011149324027,Density and Integration Effects on Class I U.S. Freight Railroads,March 2001,M. Ivaldi,G. J. Mc Cullough,,Unknown,Unknown,Unknown,Unknown,,
19.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1011153408097,Strategic Reaction of Vertically Integrated Firms to Downstream Entry: Deterrence or Accommodation,March 2001,Jae-Do Song,Jae-Cheol Kim,,Unknown,Male,Unknown,Male,,2
19.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1011161805740,Insurer Profitability in Different Regulatory and Legal Environments,July 2001,Patricia H. Born,,,Female,Unknown,Unknown,Female,,20
19.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1011107106649,Priority Network Access Pricing for Electric Power,July 2001,Shi-Jie Deng,Shmuel S. Oren,,,Male,Unknown,Mix,,
19.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1011111223487,Prosecutorial Discretion at the EPA: Some Evidence on Litigation Strategy,July 2001,Eric Helland,,,Male,Unknown,Unknown,Male,,10
19.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1011163207557,The Design of Regulations Expressed as Ratios or Percentage Quotas,July 2001,Ross McKitrick,,,Male,Unknown,Unknown,Male,,5
20.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1011139630016,Revenue Sharing Rules for International Telephony,July 2001,Gianni De Fraja,Paola Valbonesi,,Male,Female,Unknown,Mix,,
20.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1011158114087,On the Impact of “Callback” Competition on International Telephony,July 2001,Fabio M. Manenti,,,Male,Unknown,Unknown,Male,,3
20.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1011110230925,The Informational Role of the EPA SO2 Permit Auction,July 2001,David S. Brookshire,H. Stuart Burness,,Male,Unknown,Unknown,Male,,
20.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1011162214995,Productivity and Price Performance in the Privatized Water and Sewerage Companies of England and Wales,July 2001,David S. Saal,David Parker,,Male,Male,Unknown,Male,,182
20.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1011114331834,Efficient Cost Passthrough,July 2001,Christian Holzleitner,,,Male,Unknown,Unknown,Male,,
20.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1011124509158,Price-Quality Tradeoffs and Welfare Effects in Cable Television Markets,September 2001,T. Randolph Beard,Robert B. Ekelund,Richard S. Saba,Unknown,Male,Male,Male,,11
20.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1011190911884,Incentives for Discrimination when Upstream Monopolists Participate in Downstream Markets,September 2001,Dennis L. Weisman,Jaesung Kang,,Male,Unknown,Unknown,Male,,40
20.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1011103328722,Price Regulation for Independent Transmission Companies,September 2001,Ingo Vogelsang,,,Male,Unknown,Unknown,Male,,79
20.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1011155312792,Regulating Private Infrastructure Investment: Optimal Pricing for Access to Essential Facilities,September 2001,Joshua S. Gans,,,Male,Unknown,Unknown,Male,,50
20.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1011107413701,The Theory and Practice of Regulation with Multinational Enterprises,September 2001,Giacomo Calzolari,,,Male,Unknown,Unknown,Male,,23
20.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1011151409081,Strategic Pricing when Electricity is Storable,November 2001,Alfredo Garcia,James D. Reitzes,Ennio Stacchetti,Male,Male,Male,Male,,29
20.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1011115025920,Household Response to Optional Peak-Load Pricing of Electricity,November 2001,Isamu Matsukawa,,,Male,Unknown,Unknown,Male,,34
20.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1011167009990,Pricing Implications of U.S.' International Settlements Policy,November 2001,John Agyei Karikari,,,Male,Unknown,Unknown,Male,,2
20.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1011119126828,Telecommunications Regulation and New Services: A Case Study at the State Level,November 2001,James E. Prieger,,,Male,Unknown,Unknown,Male,,7
20.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1011171110899,Telecommunications Investment and Traffic in Developing Countries: The Effects of International Settlement Rate Reforms,November 2001,Scott J. Wallsten,,,Male,Unknown,Unknown,Male,,12
21.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1013661106129,Regulatory Economics: Twenty Years of Progress?,January 2002,Michael A. Crew,Paul R. Kleindorfer,,Male,Male,Unknown,Male,,73
21.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1013622522968,Economic Regulation and the Courts 1982 to 2001: Ten Cases That Made a Difference,January 2002,William E. Kovacic,,,Male,Unknown,Unknown,Male,,4
21.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1013674607038,"The Deregulatory Tar Baby: The Precarious Balance Between Regulation and Deregulation, 1970–2000 and Henceforward",January 2002,Alfred E. Kahn,,,Male,Unknown,Unknown,Male,,14
21.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1013626723876,"What It Was Like, What Happened, and What It's Like Now: Developments in Telecommunications Over Recent Decades",January 2002,Almarin Phillips,,,Male,Unknown,Unknown,Male,,6
21.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1013678724785,A Retrospective Look at Wholesale Gas: Industry Restructuring,January 2002,Jeffrey Leitzinger,Martin Collette,,Male,Male,Unknown,Male,,16
21.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1013682825693,Electricity Market Restructuring: Reforms of Reforms,January 2002,William W. Hogan,,,Male,Unknown,Unknown,Male,,77
21.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1014331206366,Railroad Deregulation and Consumer Welfare,March 2002,Jerry Ellig,,,Male,Unknown,Unknown,Male,,26
21.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1014387707275,Universal Service and Entry: The Role of Uniform Pricing and Coverage Constraints,March 2002,Tommaso M. Valletti,Steffen Hoernig,Pedro P. Barros,Male,Male,Male,Male,,73
21.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1014391824113,International Benchmarking for Monopoly Price Regulation: The Case of Australian Gas Distribution,March 2002,Roger Carrington,Tim Coelli,Eric Groom,Male,Male,Male,Male,,36
21.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1014343908183,"CEO Tenure, Board Composition, and Regulation",March 2002,Rick Geddes,Hrishikesh D. Vinod,,Male,Unknown,Unknown,Male,,5
21.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1015378914995,Rational Buyer Meets Rational Seller: Reserves Market Equilibria under Alternative Auction Designs,May 2002,Rajnish Kamat,Shmuel S. Oren,,Unknown,Male,Unknown,Male,,18
21.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1015312531833,"Price Caps, Rate of Return Constraints and Universal Service Obligations",May 2002,Pio Baake,,,Male,Unknown,Unknown,Male,,2
21.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1015364515904,The Timing of Environmental Policy: A Note on the Role of Product Differentiation,May 2002,Joanna Poyago-Theotoky,Khemarat Teerasuwannajak,,Female,Unknown,Unknown,Female,,36
21.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1015316632742,Estimating Telephone Demand with State Decennial Census Data from 1970–1990,May 2002,Christopher Garbacz,Herbert G. Thompson,,Male,Male,Unknown,Male,,33
22.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1019992018453,Incentive Regulation and Competition in Public Utility Markets: A 20-Year Perspective,July 2002,Ingo Vogelsang,,,Male,Unknown,Unknown,Male,,130
22.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1019951702523,Desperately Seeking θ's: Estimating the Distribution of Consumers Under Increasing Block Rates,July 2002,Fidel Castro-Rodríguez,José María Da-Rocha,Pedro Delicado,Male,Male,Male,Male,,14
22.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1019903819362,"Access Pricing, Quality Degradation, and Foreclosure in the Internet",July 2002,Øystein Foros,Hans Jarle Kind,Lars Sørgard,Male,Male,Male,Male,,14
22.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1019955803432,Rent Extraction by an Unregulated Essential Facility,July 2002,François Boldron,Cyril Hariton,,Male,Male,Unknown,Male,,
22.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1020519010628,Legal Remedies for Breach of the Regulatory “Contract”,September 2002,Thomas P. Lyon,Haizhou Huang,,Male,Unknown,Unknown,Male,,8
22.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1020583427467,The Impact of State Incentive Regulation on the U.S. Telecommunications Industry,September 2002,Chunrong Ai,David E. M. Sappington,,Unknown,Male,Unknown,Male,,87
22.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1020535511537,Multi-Dimensional Procurement Auctions for Power Reserves: Robust Incentive-Compatible Scoring and Settlement Rules,September 2002,Hung-Po Chao,Robert Wilson,,Unknown,Male,Unknown,Male,,73
22.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1020587528375,Stock Market Reaction to Regulatory Price Reviews in the English and Welsh Water Industry,September 2002,Claudio Morana,John W. Sawkins,,Male,Male,Unknown,Male,,1
22.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1020891810899,TELRIC Pricing with Vintage Capital,November 2002,David M. Mandy,,,Male,Unknown,Unknown,Male,,8
22.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1020818127738,Technical Efficiency under Alternative Regulatory Regimes: Evidence from the Inter-war British Gas Industry,November 2002,Christopher J. Hammond,Geraint Johnes,Terry Robinson,Male,Male,,Mix,,
22.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1020870111808,The Union Pacific/Southern Pacific Railroads Merger: Effect of Trackage Rights on Rates,November 2002,John Agyei Karikari,Stephen M. Brown,Mehrzad Nadji,Male,Male,Unknown,Male,,14
22.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1020822228646,Regulating the United States Railroads: The Effects of Sunk Costs and Asymmetric Risk,November 2002,Jerry Hausman,Stewart Myers,,Male,Male,Unknown,Male,,39
22.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1020874212717,Rate Design Arbitrage: The Case for Value-Based Peaking Services,November 2002,Clifford B. Rochlin,,,Male,Unknown,Unknown,Male,,
23.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1021858812744,"Self-Regulation, Innovation, and the Financial Industry",January 2003,Christodoulos Stefanadis,,,Male,Unknown,Unknown,Male,,34
23.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1021827329582,Assessing the Effectiveness of State Regulation and Enforcement of Hazardous Waste,January 2003,Sarah L. Stafford,,,Female,Unknown,Unknown,Female,,32
23.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1021879330491,Cost Heterogeneity and the Potential Savings from Market-Based Policies,January 2003,Richard G. Newell,Robert N. Stavins,,Male,Male,Unknown,Male,,144
23.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1021883431400,Wholesale Spot Price Pass-Through,January 2003,Stephen C. Littlechild,,,Male,Unknown,Unknown,Male,,26
23.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1022208228560,Introduction: What Role Can Experiments Play in Research on Regulation?,March 2003,Catherine Eckel,Nancy Lutz,,Female,Female,Unknown,Female,,11
23.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1022250812631,Discriminatory Price Auctions in Electricity Markets: Low Volatility at the Expense of High Price Levels,March 2003,Stephen J. Rassenti,Vernon L. Smith,Bart J. Wilson,Male,Male,Male,Male,,65
23.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1022202929469,Asymmetric Demand Information in Uniform and Discriminatory Call Auctions: An Experimental Analysis Motivated by Electricity Markets,March 2003,Klaus Abbink,Jordi Brandts,Tanga McDANIEL,Male,Male,Unknown,Male,,21
23.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1022254913539,Transactions Costs in Tradable Permit Markets: An Experimental Study of Pollution Market Designs,March 2003,Timothy N. Cason,Lata Gangadharan,,Male,Female,Unknown,Mix,,
23.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1022207030378,The Demand for Water: Consumer Response to Scarcity,March 2003,Kate Krause,Janie M. Chermak,David S. Brookshire,Female,Female,Male,Mix,,
23.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1022259014448,Using Random nth Price Auctions to Value Non-Market Goods and Services,March 2003,John A. List,,,Male,Unknown,Unknown,Male,,31
23.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1023408025917,"The Broadband Access Market: Competition, Uniform Pricing and Geographical Coverage",May 2003,Øystein Foros,Hans Jarle Kind,,Male,Male,Unknown,Male,,19
23.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1023321309988,How Large are the Welfare Gains from Technological Innovation Induced by Environmental Policies?,May 2003,Ian W. H. Parry,William A. Pizer,Carolyn Fischer,Male,Male,Female,Mix,,
23.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1023412226826,The Effect of Endogenous Regulation on Telecommunications Expansion and Efficiency in Latin America,May 2003,Luis Hernando Gutiérrez,,,Male,Unknown,Unknown,Male,,109
23.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1023364210896,A Bottleneck Input Supplier's Opportunity Cost of Competing Downstream,May 2003,Patrick Degraba,,,Male,Unknown,Unknown,Male,,11
23.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1023368327735,The Post Office vs. Parcel Delivery Companies: Competition Effects on Costs and Productivity,May 2003,Fumitoshi Mizutani,Shuji Uranishi,,Male,Male,Unknown,Male,,31
24.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1023943613605,Access to Pipelines in Competitive Gas Markets,July 2003,Helmuth Cremer,Farid Gasmi,Jean-Jacques Laffont,Male,Male,Unknown,Male,,47
24.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1023995930443,Honesty in Environmental Regulation,July 2003,Roberto Rodríguez-Ibeas,,,Male,Unknown,Unknown,Male,,4
24.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1023948014513,Optimal Pricing and Price-Cap Regulation in the Postal Sector,July 2003,Etienne Billette De Villemeur,Helmuth Cremer,Joëlle Toledano,Male,Male,Female,Mix,,
24.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1023900131352,Regulation through Collaboration: Final Authority and Information Symmetry in Environmental Coasean Bargaining,July 2003,Thomas A. Rhoads,Jason F. Shogren,,Male,Male,Unknown,Male,,16
24.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1023952115422,Punishment in a Regulatory Setting: Experimental Evidence from the VCM,July 2003,Lisa R. Anderson,Sarah L. Stafford,,Female,Female,Unknown,Female,,38
24.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1024714610368,Expert Advice and Regulatory Complexity,September 2003,Anthony G. Heyes,,,Male,Unknown,Unknown,Male,,7
24.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1024734027206,On Intertemporal Subsidy-Free Prices and Economic Depreciation: Constrained Market Pricing Revisited,September 2003,Calum Gunn,,,,Unknown,Unknown,Mix,,
24.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1024786011276,Analyzing Gas and Electric Convergence Mergers: A Supply Curve is Worth a Thousand Words,September 2003,David Hunger,,,Male,Unknown,Unknown,Male,,6
24.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1024738128115,Bidding in an Electricity Pay-as-Bid Auction,September 2003,Giulio Federico,David Rahman,,Male,Male,Unknown,Male,,78
24.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1024790112185,Vertical Integration and Competition Policy,September 2003,Jonas Häckner,,,Male,Unknown,Unknown,Male,,10
24.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1024742229023,Entry and Exchanges of Cost Information,September 2003,Olivier Armantier,Oliver Richard,,Male,Male,Unknown,Male,,4
24.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1024794213093,Pollution Abatement as a Barrier to Entry,September 2003,Eric Helland,Mayumi Matsuno,,Male,Female,Unknown,Mix,,
24.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1025604106080,Collusive Long-Run Investments Under Transmission Price-Caps,November 2003,Christiaan Hogendorn,,,Male,Unknown,Unknown,Male,,4
24.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1025602922918,The Emergence of Market Power in Emission Rights Markets: The Role of Initial Permit Distribution,November 2003,Akira Maeda,,,,Unknown,Unknown,Mix,,
24.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1025654906988,The Effects of Emissions Standards on Industry,November 2003,Y. H. Farzin,,,Unknown,Unknown,Unknown,Unknown,,
24.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1025607023827,Measuring the Impact of Asymmetric Information: An Example from Energy Conservation,November 2003,Chad Settle,John Tschirhart,,Male,Male,Unknown,Male,,2
24.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1025659007897,Business Demand for Broadband Access Capacity,November 2003,Kevin T. Duffy-Deno,,,Male,Unknown,Unknown,Male,,20
24.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1025611124735,Estimating Telephone Demand with State Decennial Census Data from 1970–1990: Update with 2000 Data,November 2003,Christopher Garbacz,Herbert G. Thompson Jr.,,Male,Male,Unknown,Male,,37
24.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/A:1025663108806,Index,November 2003,,,,Unknown,Unknown,Unknown,Unknown,,
25.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/B:REGE.0000008653.08554.81,Two-settlement Systems for Electricity Markets under Network Uncertainty and Market Power,January 2004,Rajnish Kamat,Shmuel S. Oren,,Unknown,Male,Unknown,Male,,56
25.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/B:REGE.0000008654.68169.08,Taking the Lab to the Field: Experimental Tests of Alternative Mechanisms to Procure Multiple Contracts,January 2004,Anders Lunander,Jan-Eric Nilsson,,Male,Unknown,Unknown,Male,,15
25.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/B:REGE.0000008655.66589.0e,The Market Response to Restructuring: A Behavioral Model,January 2004,Faye Steiner,,,Female,Unknown,Unknown,Female,,15
25.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/B:REGE.0000008656.82249.3a,"Optimal Price Rules, Administered Prices and Suboptimal Prevention: Evidence from a Medicare Program",January 2004,Avi Dor,,,Male,Unknown,Unknown,Male,,9
25.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/B:REGE.0000012286.33952.6c,"Regulation, Local Monopolies and Spatial Competition",March 2004,James J. Anton,Paul J. Gertler,,Male,Male,Unknown,Male,,6
25.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/B:REGE.0000012287.80449.97,Theory and Application of Linear Supply Function Equilibrium in Electricity Markets,March 2004,Ross Baldick,Ryan Grant,Edward Kahn,Male,,Male,Mix,,
25.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/B:REGE.0000012288.66438.f5,Regulation and Investment under Uncertainty: An Application to Power Grid Interconnection,March 2004,Jean-Daniel Saphores,Eric Gravel,Jean-Thomas Bernard,Unknown,Male,Unknown,Male,,28
25.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/B:REGE.0000012289.45765.e5,Let's Get Physical! Or Financial? A Study of Electricity Transmission Rights,March 2004,Brian T. Kench,,,Male,Unknown,Unknown,Male,,
25.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/B:REGE.0000017748.93587.78,Competition and Regulation in Franchise Bidding,May 2004,Nicola Doni,,,Female,Unknown,Unknown,Female,,3
25.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/B:REGE.0000017749.84344.62,The Financial and Operational Impacts of FERC Order 636 on the Interstate Natural Gas Pipeline Industry,May 2004,David Finnoff,Curtis Cramer,Sherrill Shaffer,Male,Male,,Mix,,
25.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/B:REGE.0000017750.21982.36,The Case for International Coordination of Electricity Regulation: Evidence from the Measurement of Efficiency in South America,May 2004,Antonio Estache,Martín A. Rossi,Christian A. Ruzzier,Male,Male,Male,Male,,
25.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/B:REGE.0000017751.07079.75,"Privately Owned Railways' Cost Function, Organization Size and Ownership",May 2004,Fumitoshi Mizutani,,,Male,Unknown,Unknown,Male,,
26.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/B:REGE.0000028011.71612.70,Toward a Synthesis of Models of Regulatory Policy Design with Limited Information,July 2004,Mark Armstrong,David E. M. Sappington,,Male,Male,Unknown,Male,,18
26.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/B:REGE.0000028012.31228.ec,Utility Regulation and Risk Allocation: The Roles of Marginal Cost Pricing and Futures Markets,July 2004,Simon Cowan,,,Male,Unknown,Unknown,Male,,3
26.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/B:REGE.0000028013.76488.44,Wild Bids. Gambling for Resurrection in Procurement Contracts,July 2004,Aleix Calveras,Juan-Jose Ganuza,Esther Hauk,Unknown,Unknown,Female,Female,,44
26.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/B:REGE.0000028014.01009.ed,Risk and Capital Structure in the Regulated Firm,July 2004,Gianni De Fraja,Clive Stones,,Male,Male,Unknown,Male,,22
26.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/B:REGE.0000028015.46270.b5,Controlling Pollution with Relaxed Regulations,July 2004,Carmen Arguedas,Hamid Hamoudi,,Female,Male,Unknown,Mix,,
26.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/B:REGE.0000038927.29819.0d,Market Failures in Real-Time Metering,September 2004,Timothy J. Brennan,,,Male,Unknown,Unknown,Male,,13
26.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/B:REGE.0000038928.23500.4c,Settling Utility Rate Cases: An Alternative Ratemaking Procedure,September 2004,Zhongmin Wang,,,Unknown,Unknown,Unknown,Unknown,,
26.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/B:REGE.0000038929.16810.ff,Regulatory Compliance with Costly and Uncertain Litigation,September 2004,Mark Raymond,,,Male,Unknown,Unknown,Male,,7
26.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/B:REGE.0000038930.04585.03,Forced Freebies: A Note on Partial Deregulation with Pro Bono Supply Requirements,September 2004,Maarten Pieter Schinkel,Jan Tuinstra,,Male,Male,Unknown,Male,,2
26.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/B:REGE.0000038931.63101.0d,Minimum Quality Standards under Asymmetric Duopoly with Endogenous Quality Ordering: A Note,September 2004,Naoto Jinji,Tsuyoshi Toshimitsu,,Male,Male,Unknown,Male,,16
26.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1023/B:REGE.0000038932.72922.ef,Default Service Auctions,September 2004,Colin Loxley,David Salant,,Male,Male,Unknown,Male,,19
26.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-004-7550-7,The Case of the Missing Pollution Haven Hypothesis,November 2004,Daniel L. Millimet,John A. List,,Male,Male,Unknown,Male,,51
26.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-004-7551-6,"Incentive Regulation and Telecommunications Service
Quality",November 2004,Chunrong AI,Salvador Martinez,David M. Sappington,Unknown,Male,Male,Male,,33
26.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-004-7552-5,"Optimal Regulation of Private Production Contracts
with Environmental Externalities",November 2004,Philippe Bontems,Pierre Dubois,Tomislav Vukina,Male,Male,Male,Male,,3
26.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-004-7553-4,Privatizing Monopolies in Developing Countries: The Real Effects of Exclusivity Periods in Telecommunications,November 2004,Scott J. Wallsten,,,Male,Unknown,Unknown,Male,,21
26.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-004-7554-3,Price Squeezes in a Regulatory Environment,November 2004,Jan Bouckaert,Frank Verboven,,Male,Male,Unknown,Male,,12
27.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-004-4416-y,"Incentive Contracts for Infrastructure, Litigation and Weak Institutions",January 2005,Alfredo Garcia,James D. Reitzes,Juan Benavides,Male,Male,Male,Male,,8
27.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-004-4417-x,"Price, Programming and Potential Competition in US Cable Television Markets",January 2005,Scott J. Savage,Michael Wirth,,Male,Male,Unknown,Male,,29
27.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-004-4418-9,Sequencing Lifeline Repairs After an Earthquake: An Economic Approach,January 2005,Marco Casari,Simon J. Wilkie,,Male,Male,Unknown,Male,,15
27.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-004-4419-8,Strategic Firm Behavior Under Average-Revenue-Lagged Regulation,January 2005,Kevin M. Currier,,,Male,Unknown,Unknown,Male,,5
27.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-004-4420-2,Mission Impossible !? On the Harmonization of National Allocation Plans under the EU Emissions Trading Directive,January 2005,Christoph Böhringer,Andreas Lange,,Male,Male,Unknown,Male,,28
27.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-004-4421-1,The Financing of Regulatory Agencies,January 2005,Stephan Marette,John M. Crespi,,Male,Male,Unknown,Male,,6
27.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-004-5341-9,Regulating Service Quality: A Survey,March 2005,David E. M. Sappington,,,Male,Unknown,Unknown,Male,,112
27.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-004-5342-8,Self-Sabotage,March 2005,David E. M. Sappington,Dennis L. Weisman,,Male,Male,Unknown,Male,,36
27.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-004-5343-7,How to Turn an Industry Green: Taxes versus Subsidies,March 2005,Susanne Dröge,Philipp J. H. Schröder,,Female,Male,Unknown,Mix,,
27.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-004-5344-6,Optimal Time-of-use Access Charges,March 2005,Poletti Stephen,,,Unknown,Unknown,Unknown,Unknown,,
27.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-005-6623-6,24/7 Hourly Response to Electricity Real-Time Pricing with up to Eight Summers of Experience,May 2005,Thomas N. Taylor,Peter M. Schwarz,James E. Cochell,Male,Male,Male,Male,,80
27.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-005-6624-5,Privately-Negotiated Input Prices,May 2005,David E. M. Sappington,Burcin Unel,,Male,Unknown,Unknown,Male,,
27.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-005-6625-4,Price-Cost Margins and Profit Rates in New Zealand Electricity Distribution Networks Since 1994: the Cost of Light Handed Regulation,May 2005,Geoff Bertram,Dan Twaddle,,Male,Male,Unknown,Male,,27
27.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-005-6626-3,The Practice Boundaries of Advanced Practice Nurses: An Economic and Legal Analysis,May 2005,Michael J. Dueker,Ada K. Jacox,Stephen J. Spurr,Male,Female,Male,Mix,,
27.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-005-6627-2,Deregulation and Productivity: The Case of Spanish Banks,May 2005,Subal C. kumbhakar,Ana Lozano-Vivas,,Unknown,Female,Unknown,Female,,45
28.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-005-2353-z,The Need for Regulating a Bayesian Regulator,July 2005,Semih Koray,Ismail Saglam,,Male,Male,Unknown,Male,,15
28.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-005-2354-y,A Model of Final Offer Arbitration in Regulation,July 2005,JUAN-PABLO MONTERO,,,Unknown,Unknown,Unknown,Unknown,,
28.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-005-2355-x,Regulation of Mobile Telephony across the European Union: An Empirical Analysis,July 2005,Lukasz Grzybowski,,,Unknown,Unknown,Unknown,Unknown,,
28.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-005-2356-9,Efficiency Measurement in Network Industries: Application to the Swiss Railway Companies,July 2005,Mehdi Farsi,Massimo Filippini,William Greene,Male,Male,Male,Male,,84
28.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-005-2357-8,Price Regulation and Public Service Obligations under International Arbitrage,July 2005,Giorgio Matteucci,Pierfrancesco Reverberi,,Male,Male,Unknown,Male,,7
28.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-005-3104-x,Introduction: Environmental Regulation,September 2005,Michael A. Crew,Anthony Heyes,,Male,Male,Unknown,Male,,1
28.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-005-3105-9,On Efficiency of Decentralized Environmental Regulation,September 2005,Mitch Kunce,Jason F. Shogren,,Male,Male,Unknown,Male,,12
28.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-005-3106-8,Environmental Regulation and the Eco-Industry,September 2005,Maia David,Bernard Sinclair-Desgagné,,Female,Male,Unknown,Mix,,
28.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-005-3107-7,Using Revealed Preferences to Infer Environmental Benefits:Evidence from Recreational Fishing Licenses,September 2005,Lori S. Bennear,Robert N. Stavins,Alexander F. Wagner,Female,Male,Male,Mix,,
28.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-005-3108-6,Enforcing Emissions Trading when Emissions Permits are Bankable,September 2005,John K. Stranlund,Christopher Costello,Carlos A. Chávez,Male,Male,Male,Male,,25
28.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-005-3109-5,Optimal Allocation of Tradable Pollution Rights and Market Structures,September 2005,Dafna M. Disegni Eshel,,,Female,Unknown,Unknown,Female,,42
28.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-005-3955-1,Mobile Termination: What is the “Right” Charge?*,November 2005,Tommaso M. Valletti,George Houpis,,Male,Male,Unknown,Male,,36
28.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-005-3957-z,Regulation of State-Owned and Privatized Utilities: Ukraine Electricity Distribution Company Performance*,November 2005,Sanford Berg,Chen Lin,Valeriy Tsaplin,Male,,Male,Mix,,
28.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-005-3959-x,Cost Savings From Generation and Distribution with an Application to Italian Electric Utilities*,November 2005,Giovanni Fraquelli,Massimiliano Piacenza,Davide Vannoni,Male,Male,Male,Male,,49
28.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-005-3961-3,Environmental Externalities in the Presence of Network Effects: Adoption of Low Emission Technologies in the Automobile Market*,November 2005,Eftichios S. Sartzetakis,Panagiotis Tsigaris,,Unknown,Male,Unknown,Male,,13
28.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-005-3963-1,Asymmetric Regulation of Access and Price Discrimination in Telecommunications*,November 2005,Martin Peitz,,,Male,Unknown,Unknown,Male,,31
29.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-005-5124-y,Discrete Choice Analysis of Demand for Broadband in Japan,January 2006,Takanori Ida,Toshifumi Kuroda,,Male,Male,Unknown,Male,,52
29.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-005-5125-x,The Effects of Public Ownership and Regulatory Independence on Regulatory Outcomes,January 2006,Geoff Edwards,Leonard Waverman,,Male,Male,Unknown,Male,,114
29.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-005-5126-9,Worksharing and Access Discounts in the Postal Sector with Asymmetric Information*,January 2006,Joan Calzada,,,Female,Unknown,Unknown,Female,,5
29.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-005-5128-7,Access Regime Design and Required Rates of Return: Pitfalls in Adjusting for Inflation and Tax Effects*,January 2006,Kevin Davis,,,Male,Unknown,Unknown,Male,,5
29.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-006-6032-5,Exceptions to the Rules: Variances from Regulatory Standards,March 2006,Anthony M. Marino,,,Male,Unknown,Unknown,Male,,2
29.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-006-6033-4,Pricing Discretion and Price Regulation in Competitive Industries,March 2006,Alberto Iozzi,Roberta Sestini,Edilio Valentini,Male,Female,Male,Mix,,
29.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-006-6034-3,A Merchant Mechanism for Electricity Transmission Expansion,March 2006,Tarjei Kristiansen,Juan Rosellón,,Unknown,Male,Unknown,Male,,45
29.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-006-6035-2,Assessing the Degree of Spot Market Integration for U.S. Natural Gas: Evidence from Daily Price Data,March 2006,John T. Cuddington,Zhongmin Wang,,Male,Unknown,Unknown,Male,,47
29.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-006-6036-1,"Regulatory Federalism and Workplace Safety: Evidence from OSHA Enforcement, 1981–1995",March 2006,John Charles Bradbury,,,Male,Unknown,Unknown,Male,,21
29.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-006-6037-0,Optimal Environmental Tax and Level of Privatization in an International Duopoly,March 2006,Shuichi Ohori,,,Male,Unknown,Unknown,Male,,56
29.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-006-7398-0,Incentive Regulation of Prices When Costs are Sunk,May 2006,Lewis Evans,Graeme Guthrie,,Male,Male,Unknown,Male,,20
29.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-006-7399-z,A New Approach for Regulating Information Markets,May 2006,Robert W. Hahn,Paul C. Tetlock,,Male,Male,Unknown,Male,,11
29.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-006-7400-x,On Pollution Permit Banking and Market Power,May 2006,Matti Liski,Juan-Pablo Montero,,Male,Unknown,Unknown,Male,,34
29.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-006-7401-9,"Competition and Price Dispersion in International
Long-distance Calling",May 2006,Sean Forrest Ennis,,,Male,Unknown,Unknown,Male,,3
29.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-006-7402-8,Consumer Resistance Against Regulation: The Case of Health Care,May 2006,Peter Zweifel,Harry Telser,Stephan Vaterlaus,Male,Male,Male,Male,,34
29.0,3.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-006-7403-7,Enhancing Vertical Efficiency Through Horizontal Licensing,May 2006,Anil Arya,Brian Mittendorf,,Male,Male,Unknown,Male,,23
30.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-006-0007-4,An Agency Perspective on the Costs and Benefits of Privatization,July 2006,David Martimort,,,Male,Unknown,Unknown,Male,,49
30.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-006-0008-3,Enforcement and Information Strategies,July 2006,Lars Gårn Hansen,Signe Krarup,Clifford S. Russell,Male,Female,Male,Mix,,
30.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-006-0009-2,Strategic Regulation Policy in the Internet,July 2006,Østein Foros,Hans Jarle Kind,Lars Søard,Unknown,Male,Male,Male,,1
30.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-006-0010-9,Price-cap Regulation of Airports: Single-till Versus Dual-till,July 2006,Achim I. Czerny,,,Male,Unknown,Unknown,Male,,81
30.0,1.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-006-0011-8,Deregulating Network Industries: Dealing with Price-quality Tradeoffs,July 2006,Stefan Buehler,Dennis Gärtner,Daniel Halbheer,Male,Male,Male,Male,,17
30.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-006-0017-2,Stability of supply function equilibria implications for daily versus hourly bids in a poolco market,August 2006,Ross Baldick,William W. Hogan,,Male,Male,Unknown,Male,,22
30.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-006-0016-3,Information regulation: Do the victims of externalities pay attention?,August 2006,Felix Oberholzer-Gee,Miki Mitsunari,,Male,Female,Unknown,Mix,,
30.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-006-0015-4,Supply-side effects of the 150-hour educational requirement for CPA licensure,August 2006,John Jacob,Dennis Murray,,Male,Male,Unknown,Male,,9
30.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-006-0014-5,Factors that determine the cost-effectiveness ranking of second-best instruments for environmental regulation,August 2006,Raúl E. O’Ryan,,,Male,Unknown,Unknown,Male,,4
30.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-006-0013-6,Should uniform pricing constraints be imposed on entrants?,August 2006,Steffen H. Hoernig,,,Male,Unknown,Unknown,Male,,13
30.0,2.0,Journal of Regulatory Economics,,https://link.springer.com/article/10.1007/s11149-006-0012-7,Incentive regulation in local telecommunications: The effects on price markups,August 2006,Sarah B. Eckenrod,,,Female,Unknown,Unknown,Female,,11
30.0,3.0,Journal of Regulatory Economics,09 September 2006,https://link.springer.com/article/10.1007/s11149-006-9002-z,Should merchant transmission investment be subject to a must-offer provision?,November 2006,Gert Brunekreeft,David Newbery,,Male,Male,Unknown,Male,,25
30.0,3.0,Journal of Regulatory Economics,09 September 2006,https://link.springer.com/article/10.1007/s11149-006-9003-y,Proactive planning and valuation of transmission investments in restructured electricity markets,November 2006,Enzo E. Sauma,Shmuel S. Oren,,Male,Male,Unknown,Male,,155
30.0,3.0,Journal of Regulatory Economics,05 October 2006,https://link.springer.com/article/10.1007/s11149-006-9005-9,Designing environmental policy: lessons from the regulation of mercury emissions,November 2006,Ted Gayer,Robert W. Hahn,,Male,Male,Unknown,Male,,5
30.0,3.0,Journal of Regulatory Economics,04 October 2006,https://link.springer.com/article/10.1007/s11149-006-9000-1,"X-Factor updating and total factor productivity growth: the case of peruvian telecommunications, 1996–2003",November 2006,Jeffrey I. Bernstein,Juan Hernandez,Agustin J. Ros,Male,Male,Male,Male,,6
30.0,3.0,Journal of Regulatory Economics,04 October 2006,https://link.springer.com/article/10.1007/s11149-006-9004-x,A comparison of embedded and forward-looking local loop cost estimates for small rural telephone companies in Illinois,November 2006,James Zolnierek,,,Male,Unknown,Unknown,Male,,3
30.0,3.0,Journal of Regulatory Economics,08 December 2006,https://link.springer.com/article/10.1007/s11149-006-9012-x,Proactive planning and valuation of transmission investments in restructured electricity markets,November 2006,Enzo E. Sauma,Shmuel S. Oren,,Male,Male,Unknown,Male,,47
31.0,1.0,Journal of Regulatory Economics,02 December 2006,https://link.springer.com/article/10.1007/s11149-006-9008-6,How good are supply function equilibrium models: an empirical analysis of the ERCOT balancing market,February 2007,Ramteen Sioshansi,Shmuel Oren,,Unknown,Male,Unknown,Male,,62
31.0,1.0,Journal of Regulatory Economics,01 December 2006,https://link.springer.com/article/10.1007/s11149-006-9011-y,The potential for underinvestment in internet security: implications for regulatory policy,February 2007,Alfredo Garcia,Barry Horowitz,,Male,Male,Unknown,Male,,17
31.0,1.0,Journal of Regulatory Economics,06 December 2006,https://link.springer.com/article/10.1007/s11149-006-9010-z,Pollution abatement with limited enforcement power and citizen suits,February 2007,Christian Langpap,,,Male,Unknown,Unknown,Male,,16
31.0,1.0,Journal of Regulatory Economics,01 December 2006,https://link.springer.com/article/10.1007/s11149-006-9006-8,Can consumers enforce environmental regulations? The role of the market in hazardous waste compliance,February 2007,Sarah L. Stafford,,,Female,Unknown,Unknown,Female,,13
31.0,1.0,Journal of Regulatory Economics,08 December 2006,https://link.springer.com/article/10.1007/s11149-006-9009-5,Pricing access in network competition,February 2007,Sue H. Mialon,,,Female,Unknown,Unknown,Female,,5
31.0,2.0,Journal of Regulatory Economics,06 February 2007,https://link.springer.com/article/10.1007/s11149-006-9019-3,Nodal pricing of electricity: how much does it cost to get it wrong?,April 2007,Richard Green,,,Male,Unknown,Unknown,Male,,93
31.0,2.0,Journal of Regulatory Economics,30 January 2007,https://link.springer.com/article/10.1007/s11149-006-9022-8,A cost-benefit assessment of wholesale electricity restructuring and competition in New England,April 2007,Matthew Barmack,Edward Kahn,Susan Tierney,Male,Male,Female,Mix,,
31.0,2.0,Journal of Regulatory Economics,24 February 2007,https://link.springer.com/article/10.1007/s11149-006-9021-9,Regulating advertisements: the case of smoking cessation products,April 2007,Rosemary Avery,Donald Kenkel,Alan Mathios,Female,Male,Male,Mix,,
31.0,2.0,Journal of Regulatory Economics,24 February 2007,https://link.springer.com/article/10.1007/s11149-006-9020-x,"Can self regulation work?: a story of corruption, impunity and cover-up",April 2007,Javier Núñez,,,,Unknown,Unknown,Mix,,
31.0,3.0,Journal of Regulatory Economics,02 February 2007,https://link.springer.com/article/10.1007/s11149-006-9015-7,Incentives for sabotage in vertically related industries,June 2007,David M. Mandy,David E. M. Sappington,,Male,Male,Unknown,Male,,61
31.0,3.0,Journal of Regulatory Economics,24 February 2007,https://link.springer.com/article/10.1007/s11149-006-9014-8,The 2001-3 electricity distribution price control review in the Netherlands: regulatory process and consumer welfare,June 2007,Paul H. L. Nillesen,Michael G. Pollitt,,Male,Male,Unknown,Male,,11
31.0,3.0,Journal of Regulatory Economics,27 February 2007,https://link.springer.com/article/10.1007/s11149-006-9017-5,"Deregulation, news releases, and price discovery",June 2007,Manfen W. Chen,Rohan Christie-David,William T. Moore,Unknown,Male,Male,Male,,1
31.0,3.0,Journal of Regulatory Economics,09 February 2007,https://link.springer.com/article/10.1007/s11149-006-9018-4,An experimental analysis of the effects of automated mitigation procedures on investment and prices in wholesale electricity markets,June 2007,Lynne Kiesling,Bart J. Wilson,,Female,Male,Unknown,Mix,,
31.0,3.0,Journal of Regulatory Economics,28 February 2007,https://link.springer.com/article/10.1007/s11149-007-9023-2,The effect of deregulation on environmental research by electric utilities,June 2007,Paroma Sanyal,,,Unknown,Unknown,Unknown,Unknown,,
31.0,3.0,Journal of Regulatory Economics,10 April 2007,https://link.springer.com/article/10.1007/s11149-007-9029-9,"X-factor updating and total factor productivity growth: the case of peruvian telecommunications, 1996–2003",June 2007,Jeffrey I. Bernstein,Juan Hernandez,Agustin J. Ros,Male,Male,Male,Male,,1
32.0,1.0,Journal of Regulatory Economics,10 January 2007,https://link.springer.com/article/10.1007/s11149-006-9007-7,Optimal environmental regulation based on more than just emissions,August 2007,Arun S. Malik,,,Male,Unknown,Unknown,Male,,7
32.0,1.0,Journal of Regulatory Economics,10 January 2007,https://link.springer.com/article/10.1007/s11149-006-9013-9,Timing of environmental inspections: survival of the compliant,August 2007,Sandra Rousseau,,,Female,Unknown,Unknown,Female,,30
32.0,1.0,Journal of Regulatory Economics,24 February 2007,https://link.springer.com/article/10.1007/s11149-006-9016-6,Voluntary development of environmental management systems: motivations and regulatory implications,August 2007,Toshihiro Uchida,Paul J. Ferraro,,Male,Male,Unknown,Male,,34
32.0,1.0,Journal of Regulatory Economics,10 April 2007,https://link.springer.com/article/10.1007/s11149-007-9024-1,"Worksharing, access and bypass: the structure of prices in the postal sector",August 2007,E. Billette de Villemeur,Helmuth Cremer,Joëlle Toledano,Unknown,Male,Female,Mix,,
32.0,1.0,Journal of Regulatory Economics,10 April 2007,https://link.springer.com/article/10.1007/s11149-007-9027-y,An economic analysis of consumer class actions in regulated industries,August 2007,Ingo Vogelsang,Nishal Ramphal,Nicholas M. Pace,Male,Unknown,Male,Male,,2
32.0,2.0,Journal of Regulatory Economics,10 April 2007,https://link.springer.com/article/10.1007/s11149-007-9028-x,"Economic reforms, efficiency and productivity in Chinese banking",October 2007,Subal C. Kumbhakar,Dan Wang,,Unknown,Male,Unknown,Male,,75
32.0,2.0,Journal of Regulatory Economics,10 April 2007,https://link.springer.com/article/10.1007/s11149-007-9025-0,Regulatory and environmental effects on public transit efficiency: a mixed DEA-SFA approach,October 2007,Beniamina Buzzo Margari,Fabrizio Erbetta,Massimiliano Piacenza,Female,Male,Male,Mix,,
32.0,2.0,Journal of Regulatory Economics,03 July 2007,https://link.springer.com/article/10.1007/s11149-007-9032-1,Capacity-based versus time-based access charges in telecommunications,October 2007,Joan Calzada,,,Female,Unknown,Unknown,Female,,7
32.0,2.0,Journal of Regulatory Economics,03 July 2007,https://link.springer.com/article/10.1007/s11149-007-9035-y,Regulating internal markets for hospital care,October 2007,Rosella Levaggi,,,Female,Unknown,Unknown,Female,,12
32.0,2.0,Journal of Regulatory Economics,05 April 2007,https://link.springer.com/article/10.1007/s11149-007-9030-3,Are input prices irrelevant for make-or-buy decisions?,October 2007,Philip G. Gayle,Dennis L. Weisman,,Male,Male,Unknown,Male,,17
32.0,3.0,Journal of Regulatory Economics,14 July 2007,https://link.springer.com/article/10.1007/s11149-007-9037-9,The role of excess capacity in determining market power in natural gas transportation markets,December 2007,R. Preston McAfee,Philip J. Reny,,Unknown,Male,Unknown,Male,,3
32.0,3.0,Journal of Regulatory Economics,18 July 2007,https://link.springer.com/article/10.1007/s11149-007-9031-2,Oligopoly equilibria in electricity contract markets,December 2007,James Bushnell,,,Male,Unknown,Unknown,Male,,93
32.0,3.0,Journal of Regulatory Economics,22 August 2007,https://link.springer.com/article/10.1007/s11149-007-9034-z,Effective regulation versus tacit collusion in the long-distance market: an empirical analysis,December 2007,Simran K. Kahai,David L. Kaserman,,Unknown,Male,Unknown,Male,,1
32.0,3.0,Journal of Regulatory Economics,07 July 2007,https://link.springer.com/article/10.1007/s11149-007-9036-x,"Minimum safety standard, consumers’ information and competition",December 2007,Stéphan Marette,,,Male,Unknown,Unknown,Male,,22
32.0,3.0,Journal of Regulatory Economics,12 July 2007,https://link.springer.com/article/10.1007/s11149-007-9033-0,Regulation—the corridor to liberalization: the experience of the Israeli phone market 1984–2005,December 2007,Reuben Gronau,,,Male,Unknown,Unknown,Male,,
33.0,1.0,Journal of Regulatory Economics,08 November 2007,https://link.springer.com/article/10.1007/s11149-007-9046-8,"Corporate governance, the role of markets and regulation: introduction",February 2008,James L. Bicksler,Michael A. Crew,Jeffrey G. Smith,Male,Male,Male,Male,,
33.0,1.0,Journal of Regulatory Economics,19 October 2007,https://link.springer.com/article/10.1007/s11149-007-9043-y,Regulatory disclosure via the internet: does it make financial markets more efficient?,February 2008,João Duque,Inês Pinto,,,Female,Unknown,Mix,,
33.0,1.0,Journal of Regulatory Economics,17 October 2007,https://link.springer.com/article/10.1007/s11149-007-9047-7,Mergers and acquisitions as a response to the deregulation of the electric power industry: value creation or value destruction?,February 2008,John R. Becker-Blease,Lawrence G. Goldberg,Fred R. Kaen,Male,Male,Male,Male,,27
33.0,1.0,Journal of Regulatory Economics,24 October 2007,https://link.springer.com/article/10.1007/s11149-007-9042-z,Founders versus non-founders in large companies: financial incentives and the call for regulation,February 2008,Darius Palia,S. Abraham Ravid,Chia-Jane Wang,Male,Unknown,Unknown,Male,,31
33.0,1.0,Journal of Regulatory Economics,01 November 2007,https://link.springer.com/article/10.1007/s11149-007-9045-9,"Board monitoring, firm risk, and external regulation",February 2008,Ivan E. Brick,N. K. Chidambaran,,Male,Unknown,Unknown,Male,,42
33.0,1.0,Journal of Regulatory Economics,30 October 2007,https://link.springer.com/article/10.1007/s11149-007-9044-x,Corporate governance as religion,February 2008,Donald G. Kempf Jr.,,,Male,Unknown,Unknown,Male,,3
33.0,2.0,Journal of Regulatory Economics,04 December 2007,https://link.springer.com/article/10.1007/s11149-007-9051-y,Productivity at the post: its drivers and its distribution,April 2008,E. Grifell-Tatjé,C. A. K. Lovell,,Unknown,Unknown,Unknown,Unknown,,
33.0,2.0,Journal of Regulatory Economics,03 October 2007,https://link.springer.com/article/10.1007/s11149-007-9039-7,"Electricity sector reform in developing countries: an econometric assessment of the effects of privatization, competition and regulation",April 2008,Yin-Fang Zhang,David Parker,Colin Kirkpatrick,Unknown,Male,Male,Male,,147
33.0,2.0,Journal of Regulatory Economics,18 October 2007,https://link.springer.com/article/10.1007/s11149-007-9038-8,Downstream price-cap regulation and upstream market power,April 2008,James D. Reitzes,,,Male,Unknown,Unknown,Male,,3
33.0,2.0,Journal of Regulatory Economics,27 October 2007,https://link.springer.com/article/10.1007/s11149-007-9040-1,Business regulation and labor market performance around the world,April 2008,Horst Feldmann,,,Male,Unknown,Unknown,Male,,29
33.0,3.0,Journal of Regulatory Economics,05 February 2008,https://link.springer.com/article/10.1007/s11149-008-9058-z,On the use of labels in credence goods markets,June 2008,Olivier Bonroy,Christos Constantatos,,Male,Male,Unknown,Male,,52
33.0,3.0,Journal of Regulatory Economics,30 October 2007,https://link.springer.com/article/10.1007/s11149-007-9041-0,Regulation and efficiency in transition: the case of Romanian banks,June 2008,Gabriel Asaftei,Subal C. Kumbhakar,,Male,Unknown,Unknown,Male,,25
33.0,3.0,Journal of Regulatory Economics,20 November 2007,https://link.springer.com/article/10.1007/s11149-007-9053-9,Guaranteeing quality in the EU: who gains most?,June 2008,Chris Hudson,John Hudson,,,Male,Unknown,Mix,,
33.0,3.0,Journal of Regulatory Economics,29 November 2007,https://link.springer.com/article/10.1007/s11149-007-9054-8,Efficiency losses from overlapping regulation of EU carbon emissions,June 2008,Christoph Böhringer,Henrike Koschel,Ulf Moslener,Male,Female,Male,Mix,,
33.0,3.0,Journal of Regulatory Economics,10 November 2007,https://link.springer.com/article/10.1007/s11149-007-9050-z,Do elected public utility commissioners behave more politically than appointed ones?,June 2008,Troy Quast,,,Male,Unknown,Unknown,Male,,7
33.0,3.0,Journal of Regulatory Economics,26 February 2008,https://link.springer.com/article/10.1007/s11149-008-9060-5,Obituary,June 2008,,,,Unknown,Unknown,Unknown,Unknown,,
33.0,3.0,Journal of Regulatory Economics,08 March 2008,https://link.springer.com/article/10.1007/s11149-008-9061-4,Obituary,June 2008,,,,Unknown,Unknown,Unknown,Unknown,,
34.0,1.0,Journal of Regulatory Economics,08 February 2008,https://link.springer.com/article/10.1007/s11149-008-9056-1,The effectiveness of FERC’s transmission policy: is transmission used efficiently and when is it scarce?,August 2008,Andrew N. Kleit,James D. Reitzes,,Male,Male,Unknown,Male,,10
34.0,1.0,Journal of Regulatory Economics,24 October 2007,https://link.springer.com/article/10.1007/s11149-007-9048-6,The impact of restructuring and deregulation on gas rates,August 2008,Vladimir Hlasny,,,Male,Unknown,Unknown,Male,,6
34.0,1.0,Journal of Regulatory Economics,29 November 2007,https://link.springer.com/article/10.1007/s11149-007-9055-7,Competition in telecommunication networks with call externalities,August 2008,Edmond Baranes,Laurent Flochel,,Male,Male,Unknown,Male,,
34.0,1.0,Journal of Regulatory Economics,06 February 2008,https://link.springer.com/article/10.1007/s11149-008-9059-y,Regulating a risk-averse firm under incomplete information,August 2008,Chifeng Dai,,,Unknown,Unknown,Unknown,Unknown,,
34.0,1.0,Journal of Regulatory Economics,30 October 2007,https://link.springer.com/article/10.1007/s11149-007-9049-5,Bounding consumer surplus by monopoly profits,August 2008,T. Randolph Beard,Michael L. Stern,,Unknown,Male,Unknown,Male,,1
34.0,2.0,Journal of Regulatory Economics,16 November 2007,https://link.springer.com/article/10.1007/s11149-007-9052-x,"Product innovation, signaling, and endogenous regulatory delay",October 2008,James E. Prieger,,,Male,Unknown,Unknown,Male,,7
34.0,2.0,Journal of Regulatory Economics,21 February 2008,https://link.springer.com/article/10.1007/s11149-008-9057-0,Taxes and subsidies to change eating habits when information is not enough: an application to fish consumption,October 2008,Stéphan Marette,Jutta Roosen,Sandrine Blanchemanche,Male,Female,Female,Mix,,
34.0,2.0,Journal of Regulatory Economics,29 April 2008,https://link.springer.com/article/10.1007/s11149-008-9063-2,"Economies of density, scale and scope in the water supply and sewerage sector: a study of four developing and transition economies",October 2008,Céline Nauges,Caroline van den Berg,,Female,Female,Unknown,Female,,52
34.0,2.0,Journal of Regulatory Economics,10 May 2008,https://link.springer.com/article/10.1007/s11149-008-9067-y,Municipal aggregation and retail competition in the Ohio energy sector,October 2008,Stephen Littlechild,,,Male,Unknown,Unknown,Male,,18
34.0,3.0,Journal of Regulatory Economics,17 May 2008,https://link.springer.com/article/10.1007/s11149-008-9068-x,The regulation of audiovisual content: quotas and conflicting objectives,December 2008,Claude Crampes,Abraham Hollander,,,Male,Unknown,Mix,,
34.0,3.0,Journal of Regulatory Economics,13 May 2008,https://link.springer.com/article/10.1007/s11149-008-9062-3,Towards a complete real-time electricity market design,December 2008,Richard P. O’Neill,Emily Bartholomew Fisher,Ross Baldick,Male,Female,Male,Mix,,
34.0,3.0,Journal of Regulatory Economics,16 May 2008,https://link.springer.com/article/10.1007/s11149-008-9069-9,Implications of CO2 emissions trading for short-run electricity market outcomes in northwest Europe,December 2008,Yihsu Chen,Jos Sijm,Wietze Lise,Unknown,Male,Male,Male,,78
34.0,3.0,Journal of Regulatory Economics,10 May 2008,https://link.springer.com/article/10.1007/s11149-008-9065-0,Strategic incentives under vertical integration: the case of wireline-affiliated wireless carriers and intermodal competition in the US,December 2008,Paul R. Zimmerman,,,Male,Unknown,Unknown,Male,,
35.0,1.0,Journal of Regulatory Economics,27 June 2008,https://link.springer.com/article/10.1007/s11149-008-9072-1,All you can drink: should we worry about quality?,February 2009,Daniel Flores,,,Male,Unknown,Unknown,Male,,
35.0,1.0,Journal of Regulatory Economics,17 May 2008,https://link.springer.com/article/10.1007/s11149-008-9066-z,The deregulation of international trucking in the European Union: form and effect,February 2009,Francine Lafontaine,Laura Malaguzzi Valeri,,Female,Female,Unknown,Female,,
35.0,1.0,Journal of Regulatory Economics,28 May 2008,https://link.springer.com/article/10.1007/s11149-008-9070-3,The impact of license regulation on the number of recreation trips: is it worth considering?,February 2009,Abdulbaki Bilgic,Wojciech J. Florkowski,,Male,Male,Unknown,Male,,2
35.0,1.0,Journal of Regulatory Economics,09 August 2008,https://link.springer.com/article/10.1007/s11149-008-9076-x,Demand estimation and market definition for broadband Internet services,February 2009,Mélisande Cardona,Anton Schwarz,Christine Zulehner,Unknown,Male,Female,Mix,,
35.0,1.0,Journal of Regulatory Economics,17 June 2008,https://link.springer.com/article/10.1007/s11149-008-9071-2,"Stipulated settlements, the consumer advocate and utility regulation in Florida",February 2009,Stephen Littlechild,,,Male,Unknown,Unknown,Male,,27
35.0,2.0,Journal of Regulatory Economics,09 August 2008,https://link.springer.com/article/10.1007/s11149-008-9078-8,Access regulation and the adoption of VoIP,April 2009,Paul W. J. de Bijl,Martin Peitz,,Male,Male,Unknown,Male,,10
35.0,2.0,Journal of Regulatory Economics,09 July 2008,https://link.springer.com/article/10.1007/s11149-008-9073-0,Technology adoption decisions under a mixed regulatory system of tradable permits and air pollution fees for the control of Total Suspended Particulates in Taiwan,April 2009,Chao-Ning Liao,,,Unknown,Unknown,Unknown,Unknown,,
35.0,2.0,Journal of Regulatory Economics,16 July 2008,https://link.springer.com/article/10.1007/s11149-008-9074-z,The threat of regulatory environmental inspection: impact on plant performance,April 2009,Kjetil Telle,,,Male,Unknown,Unknown,Male,,17
35.0,2.0,Journal of Regulatory Economics,22 July 2008,https://link.springer.com/article/10.1007/s11149-008-9075-y,Competition schemes and investment in network infrastructure under uncertainty,April 2009,Keiichi Hori,Keizo Mizuno,,Male,Male,Unknown,Male,,19
35.0,2.0,Journal of Regulatory Economics,01 August 2008,https://link.springer.com/article/10.1007/s11149-008-9077-9,Technology and incentive regulation in the Italian motorways industry,April 2009,Luigi Benfratello,Alberto Iozzi,Paola Valbonesi,Male,Male,Female,Mix,,
35.0,3.0,Journal of Regulatory Economics,16 September 2008,https://link.springer.com/article/10.1007/s11149-008-9079-7,A modified yardstick competition mechanism,June 2009,Georg Meran,Christian von Hirschhausen,,Male,Male,Unknown,Male,,6
35.0,3.0,Journal of Regulatory Economics,24 January 2009,https://link.springer.com/article/10.1007/s11149-009-9087-2,"Mobile termination and collusion, revisited",June 2009,Felix Höffler,,,Male,Unknown,Unknown,Male,,3
35.0,3.0,Journal of Regulatory Economics,16 September 2008,https://link.springer.com/article/10.1007/s11149-008-9080-1,The benefits and costs of ethanol: an evaluation of the government’s analysis,June 2009,Robert Hahn,Caroline Cecot,,Male,Female,Unknown,Mix,,
35.0,3.0,Journal of Regulatory Economics,17 September 2008,https://link.springer.com/article/10.1007/s11149-008-9081-0,Access charges under two-tier pricing,June 2009,Joan Calzada,,,Female,Unknown,Unknown,Female,,3
35.0,3.0,Journal of Regulatory Economics,20 November 2008,https://link.springer.com/article/10.1007/s11149-008-9083-y,The political economy of state-level adoption of natural resource damage programs,June 2009,Amy W. Ando,Wallapak Polasub,,Female,Unknown,Unknown,Female,,8
36.0,1.0,Journal of Regulatory Economics,04 June 2009,https://link.springer.com/article/10.1007/s11149-009-9099-y,Is environmental regulation bad for competition? A survey,August 2009,Anthony Heyes,,,Male,Unknown,Unknown,Male,,43
36.0,1.0,Journal of Regulatory Economics,21 November 2008,https://link.springer.com/article/10.1007/s11149-008-9084-x,Pricing inputs to induce efficient Make-or-Buy decisions,August 2009,David M. Mandy,,,Male,Unknown,Unknown,Male,,12
36.0,1.0,Journal of Regulatory Economics,07 March 2009,https://link.springer.com/article/10.1007/s11149-009-9090-7,An experimental investigation of soft price caps in uniform price auction markets for wholesale electricity,August 2009,Christian A. Vossler,Timothy D. Mount,Ray D. Zimmerman,Male,Male,,Mix,,
36.0,1.0,Journal of Regulatory Economics,04 December 2008,https://link.springer.com/article/10.1007/s11149-008-9085-9,Allowing communities to trade in imperfectly competitive pollution-permit markets,August 2009,Dafna M. DiSegni Eshel,Richard J. Sexton,,Female,Male,Unknown,Mix,,
36.0,1.0,Journal of Regulatory Economics,17 May 2008,https://link.springer.com/article/10.1007/s11149-008-9064-1,The effects of air quality regulations on the location decisions of pollution-intensive manufacturing plants,August 2009,Simon Condliffe,O. Ashton Morgan,,Male,Unknown,Unknown,Male,,23
36.0,1.0,Journal of Regulatory Economics,27 March 2009,https://link.springer.com/article/10.1007/s11149-009-9093-4,Environmental taxes and industry monopolization,August 2009,Lambert Schoonbeek,Frans P. de Vries,,Male,Male,Unknown,Male,,14
36.0,2.0,Journal of Regulatory Economics,11 February 2009,https://link.springer.com/article/10.1007/s11149-009-9088-1,Access pricing and investment: a real options approach,October 2009,Fernando T. Camacho,Flavio M. Menezes,,Male,Male,Unknown,Male,,8
36.0,2.0,Journal of Regulatory Economics,11 January 2009,https://link.springer.com/article/10.1007/s11149-008-9086-8,Optimal expansion of the power transmission grid: why not?,October 2009,Thomas-Olivier Léautier,Véronique Thelen,,Unknown,Female,Unknown,Female,,28
36.0,2.0,Journal of Regulatory Economics,17 March 2009,https://link.springer.com/article/10.1007/s11149-009-9091-6,Supply function equilibria of pay-as-bid auctions,October 2009,Pär Holmberg,,,Male,Unknown,Unknown,Male,,36
36.0,2.0,Journal of Regulatory Economics,28 March 2009,https://link.springer.com/article/10.1007/s11149-009-9092-5,License prices for financially constrained firms,October 2009,Roberto Burguet,R. Preston McAfee,,Male,Unknown,Unknown,Male,,7
36.0,2.0,Journal of Regulatory Economics,11 April 2009,https://link.springer.com/article/10.1007/s11149-009-9094-3,Regulatory effects on the market penetration and capacity of reliability differentiated service,October 2009,Isamu Matsukawa,,,Male,Unknown,Unknown,Male,,
36.0,3.0,Journal of Regulatory Economics,16 September 2008,https://link.springer.com/article/10.1007/s11149-008-9082-z,Standards and the regulation of environmental risk,December 2009,Brent Hueth,Tigran Melkonyan,,Male,Male,Unknown,Male,,11
36.0,3.0,Journal of Regulatory Economics,29 April 2009,https://link.springer.com/article/10.1007/s11149-009-9095-2,The influence of facility characteristics and permit conditions on the effectiveness of environmental regulatory deterrence,December 2009,Dietrich Earnhart,,,Male,Unknown,Unknown,Male,,25
36.0,3.0,Journal of Regulatory Economics,13 February 2009,https://link.springer.com/article/10.1007/s11149-009-9089-0,The complete incremental cost test for cross-subsidies with a sub-modular cost function,December 2009,Edward S. Pearsall,,,Male,Unknown,Unknown,Male,,3
36.0,3.0,Journal of Regulatory Economics,04 June 2009,https://link.springer.com/article/10.1007/s11149-009-9098-z,Market discipline in the Brazilian banking industry: an analysis for the subordinated debt holders,December 2009,Helder Ferreira de Mendonça,Renato Falci Villela Loures,,Male,Male,Unknown,Male,,12
36.0,3.0,Journal of Regulatory Economics,14 May 2009,https://link.springer.com/article/10.1007/s11149-009-9097-0,Does yardstick regulation really work? Empirical evidence from Japan’s rail industry,December 2009,Fumitoshi Mizutani,Hideo Kozumi,Noriaki Matsushima,Male,Male,Male,Male,,19
37.0,1.0,Journal of Regulatory Economics,04 June 2009,https://link.springer.com/article/10.1007/s11149-009-9101-8,The geographic distribution of environmental inspections,February 2010,Heather Eckert,Andrew Eckert,,Female,Male,Unknown,Mix,,
37.0,1.0,Journal of Regulatory Economics,04 June 2009,https://link.springer.com/article/10.1007/s11149-009-9100-9,"Imperfect verification, appeals, and limited liability",February 2010,Chifeng Dai,,,Unknown,Unknown,Unknown,Unknown,,
37.0,1.0,Journal of Regulatory Economics,04 June 2009,https://link.springer.com/article/10.1007/s11149-009-9102-7,Market power in the Spanish electricity auction,February 2010,Aitor Ciarreta,María Paz Espinosa,,Male,,Unknown,Mix,,
37.0,1.0,Journal of Regulatory Economics,21 August 2009,https://link.springer.com/article/10.1007/s11149-009-9106-3,"Deregulation, competition and consumer welfare in a banking market: evidence from Hong Kong",February 2010,Chun-Yu Ho,,,,Unknown,Unknown,Mix,,
37.0,1.0,Journal of Regulatory Economics,10 July 2009,https://link.springer.com/article/10.1007/s11149-009-9105-4,Greenhouse gas policy and California electricity prices,February 2010,Carl Danner,,,Male,Unknown,Unknown,Male,,2
37.0,2.0,Journal of Regulatory Economics,10 September 2009,https://link.springer.com/article/10.1007/s11149-009-9107-2,Option contracting in the California water market,April 2010,Claire D. Tomkins,Thomas A. Weber,,Female,Male,Unknown,Mix,,
37.0,2.0,Journal of Regulatory Economics,10 November 2009,https://link.springer.com/article/10.1007/s11149-009-9110-7,"Privatization, regulation and airport pricing: an empirical analysis for Europe",April 2010,Germà Bel,Xavier Fageda,,Unknown,Male,Unknown,Male,,84
37.0,2.0,Journal of Regulatory Economics,20 October 2009,https://link.springer.com/article/10.1007/s11149-009-9109-0,In or out: efficient inclusion of installations in an emissions trading scheme?,April 2010,Regina Betz,Todd Sanderson,Tihomir Ancev,Female,Male,Male,Mix,,
37.0,2.0,Journal of Regulatory Economics,07 October 2009,https://link.springer.com/article/10.1007/s11149-009-9108-1,How does the design of international environmental agreements affect investment in environmentally-friendly technology?,April 2010,Basak Bayramoglu,,,Unknown,Unknown,Unknown,Unknown,,
37.0,2.0,Journal of Regulatory Economics,24 December 2009,https://link.springer.com/article/10.1007/s11149-009-9113-4,The impact of the judicial objective function on the enforcement of environmental standards,April 2010,Thomas Blondiau,Sandra Rousseau,,Male,Female,Unknown,Mix,,
37.0,2.0,Journal of Regulatory Economics,21 January 2010,https://link.springer.com/article/10.1007/s11149-010-9114-3,Jeffrey Ian Bernstein (1950–2009),April 2010,,,,Unknown,Unknown,Unknown,Unknown,,
37.0,3.0,Journal of Regulatory Economics,12 December 2009,https://link.springer.com/article/10.1007/s11149-009-9112-5,"Is a little sunshine all we need? On the impact of sunshine regulation on profits, productivity and prices in the Dutch drinking water sector",June 2010,Kristof De Witte,David S. Saal,,Male,Male,Unknown,Male,,47
37.0,3.0,Journal of Regulatory Economics,03 July 2009,https://link.springer.com/article/10.1007/s11149-009-9104-5,Inefficient arbitrage in inter-regional electricity transmission,June 2010,Derek Bunn,Georg Zachmann,,Male,Male,Unknown,Male,,37
37.0,3.0,Journal of Regulatory Economics,04 July 2009,https://link.springer.com/article/10.1007/s11149-009-9103-6,Impact of government-sponsored pollution prevention practices on environmental compliance and enforcement: evidence from a sample of US manufacturing facilities,June 2010,Abdoul G. Sam,,,Male,Unknown,Unknown,Male,,26
37.0,3.0,Journal of Regulatory Economics,27 March 2010,https://link.springer.com/article/10.1007/s11149-010-9118-z,EU-type carbon emissions trade and the distributional impact of overlapping emissions taxes,June 2010,Thomas Eichner,Rüdiger Pethig,,Male,Male,Unknown,Male,,8
37.0,3.0,Journal of Regulatory Economics,11 March 2010,https://link.springer.com/article/10.1007/s11149-010-9116-1,Green promotes the dirtiest: on the interaction between black and green quotas in energy markets,June 2010,Christoph Böhringer,Knut Einar Rosendahl,,Male,Male,Unknown,Male,,135
38.0,1.0,Journal of Regulatory Economics,15 November 2009,https://link.springer.com/article/10.1007/s11149-009-9111-6,Incentive regulation and investment: evidence from European energy utilities,August 2010,Carlo Cambini,Laura Rondi,,Male,Female,Unknown,Mix,,
38.0,1.0,Journal of Regulatory Economics,04 February 2010,https://link.springer.com/article/10.1007/s11149-010-9115-2,The productive effect of transport infrastructures: does road transport liberalization matter?,August 2010,Anna Bottasso,Maurizio Conti,,Female,Male,Unknown,Mix,,
38.0,1.0,Journal of Regulatory Economics,25 June 2010,https://link.springer.com/article/10.1007/s11149-010-9120-5,Decoupling in electric utilities,August 2010,Timothy J. Brennan,,,Male,Unknown,Unknown,Male,,33
38.0,1.0,Journal of Regulatory Economics,18 June 2010,https://link.springer.com/article/10.1007/s11149-010-9119-y,An empirical study of broadband diffusion in rural America,August 2010,Victor Glass,Stela K. Stefanova,,Male,Female,Unknown,Mix,,
38.0,1.0,Journal of Regulatory Economics,25 June 2010,https://link.springer.com/article/10.1007/s11149-010-9122-3,Divestiture policy and operating efficiency in U.S. electric power distribution,August 2010,John Kwoka,Michael Pollitt,Sanem Sergici,Male,Male,Female,Mix,,
38.0,1.0,Journal of Regulatory Economics,30 June 2010,https://link.springer.com/article/10.1007/s11149-010-9121-4,Roger Sherman (1930–2010),August 2010,,,,Unknown,Unknown,Unknown,Unknown,,
38.0,2.0,Journal of Regulatory Economics,23 June 2010,https://link.springer.com/article/10.1007/s11149-010-9123-2,Toward a combined merchant-regulatory mechanism for electricity transmission expansion,October 2010,William Hogan,Juan Rosellón,Ingo Vogelsang,Male,Male,Male,Male,,67
38.0,2.0,Journal of Regulatory Economics,09 September 2010,https://link.springer.com/article/10.1007/s11149-010-9128-x,Improving the econometric precision of regulatory models,October 2010,Subal C. Kumbhakar,Alan P. Horncastle,,Unknown,Male,Unknown,Male,,2
38.0,2.0,Journal of Regulatory Economics,22 June 2010,https://link.springer.com/article/10.1007/s11149-010-9124-1,Mandated self-regulation: the danger of cosmetic compliance,October 2010,Paul Calcott,,,Male,Unknown,Unknown,Male,,8
38.0,2.0,Journal of Regulatory Economics,18 March 2010,https://link.springer.com/article/10.1007/s11149-010-9117-0,Technological progress in particulate removal equipment at U.S. coal burning power plants,October 2010,Allen S. Bellas,Ian Lange,,Male,Male,Unknown,Male,,4
38.0,2.0,Journal of Regulatory Economics,31 August 2010,https://link.springer.com/article/10.1007/s11149-010-9127-y,Household response to dynamic pricing of electricity: a survey of 15 experiments,October 2010,Ahmad Faruqui,Sanem Sergici,,Male,Female,Unknown,Mix,,
38.0,3.0,Journal of Regulatory Economics,15 October 2010,https://link.springer.com/article/10.1007/s11149-010-9133-0,Price cap regulation: what have we learned from 25 years of experience in the telecommunications industry?,December 2010,David E. M. Sappington,Dennis L. Weisman,,Male,Male,Unknown,Male,,43
38.0,3.0,Journal of Regulatory Economics,30 July 2010,https://link.springer.com/article/10.1007/s11149-010-9126-z,"Incentive regulation, service quality, and standards in U.S. electricity distribution",December 2010,Anna Ter-Martirosyan,John Kwoka,,Female,Male,Unknown,Mix,,
38.0,3.0,Journal of Regulatory Economics,09 July 2010,https://link.springer.com/article/10.1007/s11149-010-9125-0,On the interaction between imperfect compliance and technology adoption: taxes versus tradable emissions permits,December 2010,Clara Villegas-Palacio,Jessica Coria,,Female,Female,Unknown,Female,,35
38.0,3.0,Journal of Regulatory Economics,29 September 2010,https://link.springer.com/article/10.1007/s11149-010-9129-9,Public interest versus regulatory capture in the Swedish electricity market,December 2010,Russell Smyth,Magnus Söderberg,,Male,Male,Unknown,Male,,8
38.0,3.0,Journal of Regulatory Economics,27 October 2010,https://link.springer.com/article/10.1007/s11149-010-9130-3,Against the stand-alone-cost test in U.S. freight rail regulation,December 2010,Russell Pittman,,,Male,Unknown,Unknown,Male,,13
38.0,3.0,Journal of Regulatory Economics,24 November 2010,https://link.springer.com/article/10.1007/s11149-010-9137-9,Index,December 2010,M. Crew,,,Unknown,Unknown,Unknown,Unknown,,
39.0,1.0,Journal of Regulatory Economics,12 October 2010,https://link.springer.com/article/10.1007/s11149-010-9131-2,Modeling welfare loss asymmetries arising from uncertainty in the regulatory cost of finance,February 2011,Ian M. Dobbs,,,Male,Unknown,Unknown,Male,,4
39.0,1.0,Journal of Regulatory Economics,05 January 2011,https://link.springer.com/article/10.1007/s11149-010-9140-1,A dynamic perspective on minimum quality standards under Cournot competition,February 2011,Stefan Napel,Gunnar Oldehaver,,Male,Male,Unknown,Male,,8
39.0,1.0,Journal of Regulatory Economics,20 October 2010,https://link.springer.com/article/10.1007/s11149-010-9132-1,Is fixed-mobile substitution strong enough to de-regulate fixed voice telephony? Evidence from the Austrian markets,February 2011,Wolfgang Briglauer,Anton Schwarz,Christine Zulehner,Male,Male,Female,Mix,,
39.0,1.0,Journal of Regulatory Economics,10 November 2010,https://link.springer.com/article/10.1007/s11149-010-9135-y,Demand response in wholesale electricity markets: the choice of customer baseline,February 2011,Hung-po Chao,,,Unknown,Unknown,Unknown,Unknown,,
39.0,1.0,Journal of Regulatory Economics,08 December 2010,https://link.springer.com/article/10.1007/s11149-010-9138-8,The interaction between universal service costing and financing in the postal sector: a calibrated approach,February 2011,Christian Jaag,Urs Trinkner,,Male,Male,Unknown,Male,,11
39.0,2.0,Journal of Regulatory Economics,11 November 2010,https://link.springer.com/article/10.1007/s11149-010-9134-z,The design of voluntary agreements in oligopolistic markets,April 2011,Rinaldo Brau,Carlo Carraro,,Male,Male,Unknown,Male,,11
39.0,2.0,Journal of Regulatory Economics,16 November 2010,https://link.springer.com/article/10.1007/s11149-010-9136-x,License scheme: an optimal waste management policy under asymmetric information,April 2011,Takayoshi Shinkuma,Shunsuke Managi,,Male,Male,Unknown,Male,,4
39.0,2.0,Journal of Regulatory Economics,16 December 2010,https://link.springer.com/article/10.1007/s11149-010-9139-7,Life insurer efficiency and state regulation: evidence of optimal firm behavior,April 2011,Steven W. Pottier,,,Male,Unknown,Unknown,Male,,15
39.0,2.0,Journal of Regulatory Economics,19 January 2011,https://link.springer.com/article/10.1007/s11149-010-9141-0,Appropriate contract durations in the German markets for on-line reserve capacity,April 2011,Sebastian Just,,,Male,Unknown,Unknown,Male,,23
39.0,2.0,Journal of Regulatory Economics,15 February 2011,https://link.springer.com/article/10.1007/s11149-011-9143-6,Alfred E. Kahn (1917–2010),April 2011,Timothy J. Tardiff,,,Male,Unknown,Unknown,Male,,
39.0,3.0,Journal of Regulatory Economics,18 March 2011,https://link.springer.com/article/10.1007/s11149-011-9145-4,Locational-based coupling of electricity markets: benefits from coordinating unit commitment and balancing markets,June 2011,Adriaan Hendrik van der Weijde,Benjamin F. Hobbs,,Male,Male,Unknown,Male,,29
39.0,3.0,Journal of Regulatory Economics,22 March 2011,https://link.springer.com/article/10.1007/s11149-011-9146-3,Optimal pricing and capacity choice for a public service under risk of interruption,June 2011,Fred Schroyen,Adekola Oyenuga,,Male,Unknown,Unknown,Male,,1
39.0,3.0,Journal of Regulatory Economics,02 March 2011,https://link.springer.com/article/10.1007/s11149-011-9144-5,Imperfect legal unbundling of monopolistic bottlenecks,June 2011,Felix Höffler,Sebastian Kranz,,Male,Male,Unknown,Male,,26
39.0,3.0,Journal of Regulatory Economics,19 January 2011,https://link.springer.com/article/10.1007/s11149-010-9142-z,Price-cap regulation of congested airports,June 2011,Hangjun Yang,Anming Zhang,,Unknown,Unknown,Unknown,Unknown,,
39.0,3.0,Journal of Regulatory Economics,13 April 2011,https://link.springer.com/article/10.1007/s11149-011-9150-7,Strategic manipulation of a pollution permit market and international trade,June 2011,Julien Bueb,Sonia Schwartz,,Male,Female,Unknown,Mix,,
40.0,1.0,Journal of Regulatory Economics,21 April 2011,https://link.springer.com/article/10.1007/s11149-011-9151-6,Social welfare issues of financial literacy and their implications for regulation,August 2011,Oliver J. Williams,Stephen E. Satchell,,Male,Male,Unknown,Male,,11
40.0,1.0,Journal of Regulatory Economics,22 March 2011,https://link.springer.com/article/10.1007/s11149-011-9147-2,Towards equilibrium offers in unit commitment auctions with nonconvex costs,August 2011,Ramteen Sioshansi,Emma Nicholson,,Unknown,Female,Unknown,Female,,13
40.0,1.0,Journal of Regulatory Economics,13 April 2011,https://link.springer.com/article/10.1007/s11149-011-9148-1,The effect of output specification on the optimal policy design for electric utilities,August 2011,Sergio Jara-Díaz,Francisco Javier Ramos-Real,,Male,Male,Unknown,Male,,6
40.0,1.0,Journal of Regulatory Economics,22 June 2011,https://link.springer.com/article/10.1007/s11149-011-9152-5,Dynamic pricing of electricity in the mid-Atlantic region: econometric results from the Baltimore gas and electric company experiment,August 2011,Ahmad Faruqui,Sanem Sergici,,Male,Female,Unknown,Mix,,
40.0,2.0,Journal of Regulatory Economics,29 June 2011,https://link.springer.com/article/10.1007/s11149-011-9158-z,Optimal transmission switching: economic efficiency and market implications,October 2011,Kory W. Hedman,Shmuel S. Oren,Richard P. O’Neill,Male,Male,Male,Male,,41
40.0,2.0,Journal of Regulatory Economics,21 April 2011,https://link.springer.com/article/10.1007/s11149-011-9153-4,Enforcement and environmental quality in a decentralized emission trading system,October 2011,Alessio D’Amato,Edilio Valentini,,Male,Male,Unknown,Male,,8
40.0,2.0,Journal of Regulatory Economics,12 June 2011,https://link.springer.com/article/10.1007/s11149-011-9154-3,On the sufficiency of regulatory enforcement in combating piracy,October 2011,Dyuti S. Banerjee,,,Unknown,Unknown,Unknown,Unknown,,
40.0,2.0,Journal of Regulatory Economics,04 June 2011,https://link.springer.com/article/10.1007/s11149-011-9155-2,Quality upgrades and bypass under mandatory access,October 2011,João Vareda,,,,Unknown,Unknown,Mix,,
40.0,2.0,Journal of Regulatory Economics,06 July 2011,https://link.springer.com/article/10.1007/s11149-011-9156-1,Fixed-to-mobile call substitution and telephony market definition in Korea,October 2011,Hongjai Rhee,Minsoo Park,,Unknown,Unknown,Unknown,Unknown,,
40.0,3.0,Journal of Regulatory Economics,13 April 2011,https://link.springer.com/article/10.1007/s11149-011-9149-0,Portfolio risk management and carbon emissions valuation in electric power,December 2011,Paul R. Kleindorfer,Lide Li,,Male,Female,Unknown,Mix,,
40.0,3.0,Journal of Regulatory Economics,06 September 2011,https://link.springer.com/article/10.1007/s11149-011-9161-4,The impact of carbon cap and trade regulation on congested electricity market equilibrium,December 2011,Tanachai Limpaitoon,Yihsu Chen,Shmuel S. Oren,Unknown,Unknown,Male,Male,,25
40.0,3.0,Journal of Regulatory Economics,26 August 2011,https://link.springer.com/article/10.1007/s11149-011-9160-5,New approach to estimating the cost of common equity capital for public utilities,December 2011,Pauline M. Ahern,Frank J. Hanley,Richard A. Michelfelder,Female,Male,Male,Mix,,
40.0,3.0,Journal of Regulatory Economics,30 September 2011,https://link.springer.com/article/10.1007/s11149-011-9163-2,Do environmental audits improve long-term compliance? Evidence from manufacturing facilities in Michigan,December 2011,Mary F. Evans,Lirong Liu,Sarah L. Stafford,,Unknown,Female,Mix,,
40.0,3.0,Journal of Regulatory Economics,18 November 2011,https://link.springer.com/article/10.1007/s11149-011-9169-9,Response of industrial customers to hourly pricing in Ontario’s deregulated electricity market,December 2011,Wai Hong Choi,Anindya Sen,Adam White,,Unknown,Male,Mix,,
41.0,1.0,Journal of Regulatory Economics,20 January 2012,https://link.springer.com/article/10.1007/s11149-011-9174-z,Regulatory economics and the journal of regulatory economics: a 30-year retrospective,February 2012,Michael A. Crew,Paul R. Kleindorfer,,Male,Male,Unknown,Male,,4
41.0,1.0,Journal of Regulatory Economics,03 January 2012,https://link.springer.com/article/10.1007/s11149-011-9175-y,Regulating regulators in transitionally competitive markets,February 2012,David E. M. Sappington,Dennis L. Weisman,,Male,Male,Unknown,Male,,9
41.0,1.0,Journal of Regulatory Economics,25 January 2012,https://link.springer.com/article/10.1007/s11149-011-9180-1,Behavioral economics: implications for regulatory behavior,February 2012,James C. Cooper,William E. Kovacic,,Male,Male,Unknown,Male,,50
41.0,1.0,Journal of Regulatory Economics,17 January 2012,https://link.springer.com/article/10.1007/s11149-011-9178-8,The World of Regulatory Influence,February 2012,Jeffrey T. Macher,John W. Mayo,,Male,Male,Unknown,Male,,13
41.0,1.0,Journal of Regulatory Economics,03 January 2012,https://link.springer.com/article/10.1007/s11149-011-9176-x,Pricing the use of capital-intensive infrastructure over time and efficient capacity expansion: illustrations for electric transmission investment,February 2012,Richard E. Schuler,,,Male,Unknown,Unknown,Male,,7
41.0,1.0,Journal of Regulatory Economics,06 January 2012,https://link.springer.com/article/10.1007/s11149-011-9181-0,Economies of scale for broadband in rural United States,February 2012,Victor Glass,Stela K. Stefanova,,Male,Female,Unknown,Mix,,
41.0,1.0,Journal of Regulatory Economics,05 January 2012,https://link.springer.com/article/10.1007/s11149-011-9173-0,Effective monitoring and mitigation in the organized wholesale electric power markets,February 2012,Jeffrey Mayes,Howard Haas,Joseph Bowring,Male,Male,Male,Male,,4
41.0,1.0,Journal of Regulatory Economics,11 January 2012,https://link.springer.com/article/10.1007/s11149-011-9177-9,Evaluating wind-following and ecosystem services for hydroelectric dams in PJM,February 2012,Alisha Fernandez,Seth Blumsack,Patrick Reed,Female,Male,Male,Mix,,
41.0,1.0,Journal of Regulatory Economics,03 January 2012,https://link.springer.com/article/10.1007/s11149-011-9179-7,Competitive electricity markets with consumer subscription service in a smart grid,February 2012,Hung-po Chao,,,Unknown,Unknown,Unknown,Unknown,,
41.0,2.0,Journal of Regulatory Economics,06 July 2011,https://link.springer.com/article/10.1007/s11149-011-9159-y,An empirical analysis of incentive regulation and the allocation of inputs in the US telecommunications industry,April 2012,Nongluk Buranabunyut,James Peoples,,Unknown,Male,Unknown,Male,,3
41.0,2.0,Journal of Regulatory Economics,14 June 2011,https://link.springer.com/article/10.1007/s11149-011-9157-0,Bottleneck co-ownership as a regulatory alternative,April 2012,Federico Boffa,John Panzar,,Male,Male,Unknown,Male,,6
41.0,2.0,Journal of Regulatory Economics,07 September 2011,https://link.springer.com/article/10.1007/s11149-011-9162-3,FDI and environmental regulation: pollution haven or a race to the top?,April 2012,Baomin Dong,Jiong Gong,Xin Zhao,Unknown,,,Mix,,
41.0,2.0,Journal of Regulatory Economics,30 September 2011,https://link.springer.com/article/10.1007/s11149-011-9164-1,On the social optimality of make-or-buy decisions,April 2012,Markos Tselekounis,Dimitris Varoutas,Drakoulis Martakos,Male,Male,Unknown,Male,,3
41.0,2.0,Journal of Regulatory Economics,14 October 2011,https://link.springer.com/article/10.1007/s11149-011-9165-0,Minimum quality standard regulation under imperfect quality observability,April 2012,Min Chen,Konstantinos Serfes,,,Male,Unknown,Mix,,
41.0,2.0,Journal of Regulatory Economics,23 February 2012,https://link.springer.com/article/10.1007/s11149-012-9186-3,Erratum to: Behavioral economics: implications for regulatory behavior,April 2012,James C. Cooper,William E. Kovacic,,Male,Male,Unknown,Male,,
41.0,3.0,Journal of Regulatory Economics,07 March 2012,https://link.springer.com/article/10.1007/s11149-012-9187-2,Sabotaging cost containment,June 2012,Debashis Pal,David E. M. Sappington,Ying Tang,Male,Male,,Mix,,
41.0,3.0,Journal of Regulatory Economics,28 February 2012,https://link.springer.com/article/10.1007/s11149-012-9188-1,Regulatory design and incentives for renewable energy,June 2012,Alfredo Garcia,Juan Manuel Alzate,Jorge Barrera,Male,Male,Male,Male,,32
41.0,3.0,Journal of Regulatory Economics,27 October 2011,https://link.springer.com/article/10.1007/s11149-011-9167-y,"Taxes, minimum-quality standards and/or product labeling to improve environmental quality and welfare: Experiments can provide answers",June 2012,Anne-Célia Disdier,Stéphan Marette,,Unknown,Male,Unknown,Male,,14
41.0,3.0,Journal of Regulatory Economics,04 November 2011,https://link.springer.com/article/10.1007/s11149-011-9168-x,Setting trigger price in emissions permit markets equipped with a safety valve mechanism,June 2012,Akira Maeda,,,,Unknown,Unknown,Mix,,
41.0,3.0,Journal of Regulatory Economics,10 November 2011,https://link.springer.com/article/10.1007/s11149-011-9170-3,When do firms support environmental agreements?,June 2012,Ana Espínola-Arredondo,Félix Muñoz-García,,Female,Male,Unknown,Mix,,
42.0,1.0,Journal of Regulatory Economics,28 February 2012,https://link.springer.com/article/10.1007/s11149-012-9185-4,Regulation of network infrastructure investments: an experimental evaluation,August 2012,Bastian Henze,Charles Noussair,Bert Willems,Male,Male,Male,Male,,13
42.0,1.0,Journal of Regulatory Economics,11 January 2012,https://link.springer.com/article/10.1007/s11149-012-9182-7,Pigouvian taxes and the Varian’s mechanism in dynamic settings,August 2012,Francisco Candel-Sánchez,,,Male,Unknown,Unknown,Male,,2
42.0,1.0,Journal of Regulatory Economics,24 January 2012,https://link.springer.com/article/10.1007/s11149-012-9183-6,The impact of state regulations on nursing home care practices,August 2012,John R. Bowblis,Judith A. Lucas,,Male,Female,Unknown,Mix,,
42.0,1.0,Journal of Regulatory Economics,03 January 2012,https://link.springer.com/article/10.1007/s11149-011-9172-1,"Regulation, privatization, and airport charges: panel data evidence from European airports",August 2012,Volodymyr Bilotkach,Joseph A. Clougherty,Anming Zhang,Male,Male,Unknown,Male,,66
42.0,1.0,Journal of Regulatory Economics,14 October 2011,https://link.springer.com/article/10.1007/s11149-011-9166-z,Economies of scope in electricity supply and the costs of vertical separation for different unbundling scenarios,August 2012,Roland Meyer,,,Male,Unknown,Unknown,Male,,22
42.0,2.0,Journal of Regulatory Economics,06 June 2012,https://link.springer.com/article/10.1007/s11149-012-9194-3,Designing optimal gain sharing plans to promote energy conservation,October 2012,Leon Yang Chu,David E. M. Sappington,,Male,Male,Unknown,Male,,13
42.0,2.0,Journal of Regulatory Economics,06 March 2012,https://link.springer.com/article/10.1007/s11149-012-9190-7,Using real-time electricity data to estimate response to time-of-use and flat rates: an application to emissions,October 2012,James E. Cochell,Peter M. Schwarz,Thomas N. Taylor,Male,Male,Male,Male,,5
42.0,2.0,Journal of Regulatory Economics,22 February 2012,https://link.springer.com/article/10.1007/s11149-012-9184-5,Withholding investments in energy only markets: can contracts make a difference?,October 2012,Frederic Murphy,Yves Smeers,,Male,Male,Unknown,Male,,5
42.0,2.0,Journal of Regulatory Economics,19 June 2012,https://link.springer.com/article/10.1007/s11149-012-9196-1,Optimal monitoring of credit-based emissions trading under asymmetric information,October 2012,Ian A. MacKenzie,Markus Ohndorf,,Male,Male,Unknown,Male,,7
42.0,2.0,Journal of Regulatory Economics,03 January 2012,https://link.springer.com/article/10.1007/s11149-011-9171-2,Competition with asymmetric regulation of mobile termination charges,October 2012,Edmond Baranes,Cuong Hung Vuong,,Male,,Unknown,Mix,,
42.0,2.0,Journal of Regulatory Economics,19 June 2012,https://link.springer.com/article/10.1007/s11149-012-9198-z,Jeff D. Makholm: The political economy of pipelines,October 2012,Hendrik Finger,,,Male,Unknown,Unknown,Male,,
42.0,3.0,Journal of Regulatory Economics,25 July 2012,https://link.springer.com/article/10.1007/s11149-012-9200-9,Capture or contract? The early years of electric utility regulation,December 2012,Thomas P. Lyon,Nathan Wilson,,Male,Male,Unknown,Male,,4
42.0,3.0,Journal of Regulatory Economics,03 July 2012,https://link.springer.com/article/10.1007/s11149-012-9199-y,Does eco-certification boost regulatory compliance in developing countries? ISO 14001 in Mexico,December 2012,Allen Blackman,,,Male,Unknown,Unknown,Male,,23
42.0,3.0,Journal of Regulatory Economics,28 March 2012,https://link.springer.com/article/10.1007/s11149-012-9191-6,Environmental quality and welfare effects of improving the reporting capability of citizen monitoring schemes,December 2012,Timo Goeschl,Ole Jürgens,,Male,Male,Unknown,Male,,12
42.0,3.0,Journal of Regulatory Economics,06 June 2012,https://link.springer.com/article/10.1007/s11149-012-9195-2,Competition and regulation with product differentiation,December 2012,Raffaele Fiocco,,,Male,Unknown,Unknown,Male,,3
42.0,3.0,Journal of Regulatory Economics,01 March 2012,https://link.springer.com/article/10.1007/s11149-012-9189-0,"Merchant and regulated transmission: theory, evidence and policy",December 2012,Stephen Littlechild,,,Male,Unknown,Unknown,Male,,18
43.0,1.0,Journal of Regulatory Economics,03 July 2012,https://link.springer.com/article/10.1007/s11149-012-9197-0,Does industry self-regulation reduce pollution? Responsible Care in the chemical industry,January 2013,Shanti Gamper-Rabindran,Stephen R. Finger,,Female,Male,Unknown,Mix,,
43.0,1.0,Journal of Regulatory Economics,13 April 2012,https://link.springer.com/article/10.1007/s11149-012-9193-4,Does vertical separation reduce cost? An empirical analysis of the rail industry in European and East Asian OECD Countries,January 2013,Fumitoshi Mizutani,Shuji Uranishi,,Male,Male,Unknown,Male,,52
43.0,1.0,Journal of Regulatory Economics,11 April 2012,https://link.springer.com/article/10.1007/s11149-012-9192-5,Access regulation with asymmetric termination costs,January 2013,Torben Stühmeier,,,Male,Unknown,Unknown,Male,,3
43.0,1.0,Journal of Regulatory Economics,17 October 2012,https://link.springer.com/article/10.1007/s11149-012-9202-7,Determinants of the premium in forward contracts,January 2013,Christian Redl,Derek W. Bunn,,Male,Male,Unknown,Male,,28
43.0,1.0,Journal of Regulatory Economics,17 October 2012,https://link.springer.com/article/10.1007/s11149-012-9203-6,Paul Robert Kleindorfer 1940–2012,January 2013,,,,Unknown,Unknown,Unknown,Unknown,,
43.0,2.0,Journal of Regulatory Economics,07 September 2012,https://link.springer.com/article/10.1007/s11149-012-9201-8,Testing the effects of self-regulation on industrial accidents,April 2013,Stephen R. Finger,Shanti Gamper-Rabindran,,Male,Female,Unknown,Mix,,
43.0,2.0,Journal of Regulatory Economics,27 November 2012,https://link.springer.com/article/10.1007/s11149-012-9204-5,Price effects of independent transmission system operators in the United States electricity market,April 2013,Theodore J. Kury,,,Male,Unknown,Unknown,Male,,9
43.0,2.0,Journal of Regulatory Economics,19 December 2012,https://link.springer.com/article/10.1007/s11149-012-9205-4,Competition enhancing regulation and diffusion of innovation: the case of broadband networks,April 2013,Harald Gruber,Pantelis Koutroumpis,,Male,Male,Unknown,Male,,54
43.0,2.0,Journal of Regulatory Economics,19 December 2012,https://link.springer.com/article/10.1007/s11149-012-9206-3,The NOME law: implications for the French electricity market,April 2013,Anna Creti,Jerome Pouyet,María-Eugenia Sanin,Female,Male,Unknown,Mix,,
43.0,2.0,Journal of Regulatory Economics,17 January 2013,https://link.springer.com/article/10.1007/s11149-012-9207-2,Empirical study of broadband adoption using data from the 2009 Residential Energy Consumption Survey,April 2013,Trevor R. Roycroft,,,Male,Unknown,Unknown,Male,"Broadband policy in the United States, as pursued by the Federal Communications Commission (FCC), has recently shifted its focus to offer explicit support for affordable broadband services (FCC 2011). FCC efforts have been directed at expanded availability of broadband facilities, and generally ignore the relationship between a consumer’s purchase of broadband and television services. This study conducts an empirical analysis of the relationship between broadband adoption and a consumer’s selection of pay television services. The results indicate that when controlling for broadband prices and a number of demographic factors, consumers who prefer to utilize pay television services offered by cable television and direct broadcast satellite operators adopt broadband at rates that are higher than consumers who prefer over-the-air television. The results suggest that consumers who do not like pay television services, or who otherwise do not desire bundles, may face a more substantial hurdle to broadband adoption. The paper consists of six sections, including this introduction. Section 2 provides a literature review. Section 3 describes the data sources and summarizes the explanatory variables. Section 4 discusses the random utility and empirical models and the presents the results of the probit regression. Section 5 covers marginal effects associated with the analysis. Section 6 summarizes and offers policy conclusions.",7
43.0,3.0,Journal of Regulatory Economics,20 March 2013,https://link.springer.com/article/10.1007/s11149-013-9215-x,Motivating energy suppliers to promote energy conservation,June 2013,Leon Yang Chu,David E. M. Sappington,,Male,Male,Unknown,Male,"Industry experts have observed that it can be more cost effective to reduce the demand for electricity than to increase its supply (Fox-Penner 2010, pp. 52–53). In response, legislators and regulators around the world have implemented policies to induce electric utilities to reduce electricity consumption by their customers. These policies include educating consumers about ways to conserve energy and encouraging expanded use of energy-efficient appliances, insulation, and weather-stripping (Tanaka 2011). In the US, states routinely set specific targets for reductions in electricity consumption, and twenty states have implemented explicit financial rewards to encourage electric utilities to meet these targets (Institute for Electric Efficiency 2010; Palmer et al. 2012). The explicit financial rewards often accompany or replace revenue decoupling, which insulates the utility against reductions in its revenue as its electricity sales decline (Carter 2001; Brennan 2010a). Although regulators have been designing and implementing reward structures to encourage utilities to reduce electricity consumption by their customers for several years now,Footnote 1 they have been doing so with little formal guidance. Some authors (e.g., Moskovitz 1989; Stoft and Gilbert 1994; Eto et al. 1998) have provided useful policy discussions. However, few scholars have developed rigorous economic models that can be employed to inform the optimal design of policies to reduce electricity consumption.Footnote 2 The purpose of this research is to present one such model and to discuss its policy implications. We analyze a setting in which the utility can deliver energy efficiency effort (\(e\)) that increases the efficacy of electricity consumption (\(q\)) in enhancing what we will call consumer “comfort,” \(x=X(q,e)\). For instance, \(e\) might represent energy conservation information that helps consumers to employ electricity more effectively to secure desired levels of temperature and humidity (i.e., “ comfort”) in their homes. The regulator in our model can observe realized electricity consumption, but she cannot measure accurately consumer comfort or the utility’s supply of \(e\).Footnote 3 Therefore, the regulator must motivate the utility to deliver \(e\) by providing explicit financial rewards for observed reductions in electricity consumption. We examine the properties of the reward structure that induces the utility to deliver the surplus-maximizing level of energy efficiency effort, \(e^{*}\). Formally, \(e^{*}\) is the level of \(e\) that maximizes the difference between the well-being of consumers and the sum of three costs: the utility’s cost of supplying electricity, its cost of delivering energy efficiency effort, and any social (e.g., environmental) cost associated with electricity consumption. We identify conditions under which revenue decoupling provides the utility with precisely the incentive required to induce the delivery of \(e^{*}\). We note, though, that these conditions are unlikely to arise in practice. Typically, revenue decoupling will provide insufficient incentive to induce the utility to deliver \(e^{*}\). Revenue decoupling would provide the requisite incentive in the absence of a “rebound effect” (e.g., Wirl 1995), i.e., if consumers always secured the same level of comfort, \(x\), even as \(e\) changes. However, consumers typically demand greater comfort as \(e\) increases, and the increased demand for comfort limits the amount by which consumers reduce their electricity consumption as \(e\) increases. In light of this induced insensitivity of observed electricity consumption (\(q\)) to \(e\), financial rewards that are more generous than decoupling are required to induce the utility to supply \(e^{*}\). The magnitude of the requisite increase in financial reward is shown to vary with several factors, including the utility’s cost of delivering energy efficiency effort (\(e\)), the rate at which \(e\) increases consumer comfort (\(x\)), and the rate at which \(e\) increases the impact of electricity consumption (\(q\)) on \(x\). The magnitude of the requisite increase in financial reward is also shown to vary with the established price of electricity, the extent of prevailing observable energy efficiency investment (e.g., energy-saving light bulbs that the utility delivers to its customers), and the utility’s objective. In particular, a public enterprise typically will deliver \(e^{*}\) in return for less generous compensation than its profit-maximizing counterpart. Our analysis is most closely related to the work of Eom and Sweeney (2009), which examines the design of linear reward structures to motivate an electric utility to supply unobservable effort that reduces electricity consumption. Eom and Sweeney assume the utility receives a constant fraction of the net benefits that arise from its effort, \(e\). These net benefits are the difference between the value of the cost savings generated by the energy conservation program and program costs. The cost savings are assumed to increase linearly with \(e\), and the utility’s unmeasured costs are assumed to be a quadratic function of \(e\).Footnote 4 We extend Eom and Sweeney’s important analysis by considering more general benefit and cost functions and nonlinear reward structures. We also explicitly model the manner in which electricity enhances consumer well-being. Our approach allows us to explain why revenue decoupling typically is insufficient to induce the surplus-maximizing level of energy efficiency effort, even when the regulator can vary a fixed retail charge for electricity to ensure the utility’s financial integrity. Our approach also allows us to determine how the requisite reward varies with relevant industry parameters. Some studies abstract from the need to motivate the utility to deliver effort that enhances program performance, focusing instead on the complications posed by asymmetric knowledge of industry conditions. For instance, Lewis and Sappington (1992) identify conditions under which a regulator’s limited knowledge of consumers’ preferences is not constraining, provided the regulator can observe the level of energy conservation service the utility provides. Chu and Sappington (2012) illustrate the merits of affording the utility a choice among reward structures when the utility is privately informed about its cost of supplying energy conservation services. We abstract from asymmetric knowledge of program costs, consumer preferences, and potential program performance, focusing instead on how to motivate a utility to deliver effort that enhances the performance of programs designed to reduce electricity consumption. This motivation problem is important because, in the absence of explicit financial rewards for reduced electricity consumption, utility effort that reduces consumption often will reduce utility profit. Consequently, the utility may be reluctant to work diligently to ensure program success. Our analysis of this motivation problem proceeds as follows. Section 2 describes the key elements of the model. Section 3 describes the outcomes in two benchmark settings, one where the surplus-maximizing level of energy efficiency effort (\( e^{*}\)) can simply be dictated rather than motivated, and one where consumers always secure the same level of comfort even as \(e\) changes. Section 4 characterizes the reward structure that motivates the utility to deliver \(e^{*}\) and explains how industry parameters affect this reward structure. Section 5 considers extensions of the basic analysis, demonstrating how the reward structure that induces \(e^{*}\) is affected by the utility’s objective, by energy conservation investments that the utility might provide, and by the operation of an independent energy services company. Section 6 concludes and suggests directions for future research.Footnote 5
",24
43.0,3.0,Journal of Regulatory Economics,12 February 2013,https://link.springer.com/article/10.1007/s11149-013-9210-2,Overriding consumer preferences with energy regulations,June 2013,Ted Gayer,W. Kip Viscusi,,Male,Unknown,Unknown,Male,"This article examines a major class of recent government initiatives by the U.S. Department of Energy (DOE), the U.S. Environmental Protection Agency (EPA), and the U.S. Department of Transportation (DOT) pertaining to energy efficiency (as distinct from economic efficiency). We examine the justification for these energy regulations and show that demonstrable market failures are largely incidental to agencies’ assessment of the merits of these regulations. Rather, the preponderance of the assessed benefits is derived from agencies’ assumption that consumers and firms act irrationally and that government choices therefore better reflect the preferences of consumers and firms than the choices consumers and firms would make themselves. In the absence of these claimed private benefits of the regulation, the costs to society dwarf the estimated benefits. The agencies’ presumption of consumer and firm irrationality is motivated by an unsupported claim that there is an energy-efficiency gap, whereby consumers’ choices for energy-efficiency purchases imply a discount rate much higher than market discount rates. Consequently, consumers underweight the future cost savings stemming from an energy-efficient product compared to the weight they put on the future in other market settings (see, for example, Hausman 1979). As we review in Gayer and Viscusi (2012), the evidence in the economics literature on the existence and magnitude of such an energy efficiency gap is mixed and does not provide a compelling justification for overriding consumer decisions in the absence of supporting evidence. Moreover, as we demonstrate below, the agencies’ regulatory analyses offer little to no evidence of the existence of such a failure for any of the products targeted by the regulations. There are a number of alternative reasons that can explain a purported energy-efficiency gap, many of which are consistent with individual rationality. The observed high discount rates could be rational in the presence of high sunk costs and uncertainty over future conservation savings (Hassett and Metcalf 1993). Also, many of the studies purporting to show that consumers forgo profitable energy decisions are based on engineering studies that calculate the net present value of a set of possible energy-efficiency consumption choices, which requires assumptions for such things as capital costs, current and future energy prices, duration and frequency of appliance use, and discount rates (McKinsey & Company 2009). These studies omit other relevant costs or benefits of the product to consumers that can drive the purchase decision (see, for example, Anderson and Newell 2004). By ignoring these relevant characteristics of the product, and the specifics of the customer’s economic circumstances, the engineering studies can arrive at incorrect findings of personal savings from the products that have higher up-front costs but yield lower operating costs. Since the engineering studies focus only on capital costs and operating costs, they do not allow for any heterogeneity of preferences and use of products across consumers. Engineering estimates of potential energy savings also may misrepresent energy savings because they are based on highly controlled studies that do not directly apply to actual realized savings in a representative house (see, for example, Nadel and Keating 1991; Metcalf and Hassett 1999). A common but potentially misleading approach to measuring the energy-efficiency gap is to use empirical studies of energy-use data to estimate the average returns for the set of consumers that adopt an energy-efficient technology, for example, by comparing natural-gas billing data in the first year after weatherization work is done to the previous year. In addition to the problems associated with the short time horizon of such studies, the findings of such studies may be spurious as they suffer from omitted variable bias in which other key factors affecting the decision are ignored (Allcott and Greenstone 2012). Taken as a whole, the engineering, empirical, and behavioral literature on the energy-efficiency gap does not provide strong, credible evidence of persistent consumer irrationality. In the discussion below we present case studies of recent analyses used to support energy-efficiency regulations promulgated by DOE, EPA, and DOT for which we will show that the undocumented assumption of a fundamental market failure provides the pivotal justification for the claimed regulatory benefits. Section 2 examines the corporate average fuel economy (CAFE) standards for passenger cars and light trucks, and Sect. 3 considers the analogous corporate average fuel economy standards for heavy-duty trucks. Section 4 assesses energy efficiency standards for clothes dryers, room air conditioners, and other appliances. Section 5 examines energy efficiency standards for standard incandescent or halogen-type light bulbs. Section 6 concludes.",49
43.0,3.0,Journal of Regulatory Economics,15 January 2013,https://link.springer.com/article/10.1007/s11149-012-9208-1,Incentive effects of paying demand response in wholesale electricity markets,June 2013,Hung-po Chao,Mario DePillis,,Unknown,Male,Unknown,Male,"The lack of price-elastic demand response has been a defining characteristic of wholesale electricity markets in the US. The lack of price elasticity in the wholesale market is broadly recognized as a significant factor in the California energy crisis of 2000 and 2001 resulting in price spikes and social costs. The California energy crisis highlighted the importance for consumers of having access to wholesale market time-varying prices and providing demand response (CA-ISO 2001). This emphasis on the lack of price responsive demand has been echoed among economists. The proposed framework of competitive markets in electricity, such as described in the seminal work by Vickrey (1971) and Schweppe et al. (1988), includes customer response to spot prices. The lack of price-elastic demand in wholesale market is disappointing to many economists given the wide range of empirical studies and evaluation of pilot programs at the consumer level.Footnote 1 One of the main underlying causes of the absence of price responsive demand in the wholesale market is the prevalence of fixed uniform rate at the retail level. This results in over-consumption when wholesale rates are high and under-consumption when retail rates are low with welfare losses in both cases. At the retail level, for instance, consumers may consume as much as they wish at a fixed price even when the wholesale cost may be multiples of the fixed retail rate. Hence utilities serving the load must purchase the energy even at a loss. Policy makers have responded by encouraging demand response regulation at the wholesale level. The Energy Policy Act of 2005 states “It is the policy of the United States that . . . unnecessary barriers to demand response participation in energy, capacity, and ancillary service markets shall be eliminated”.Footnote 2 Regulators recognized the lack of time-varying retail prices as a barrier to price responsive demand.Footnote 3 The Federal Energy Regulatory Commission’s (FERC) Order 745, from its rulemaking on “Demand Response Compensation in Organized Wholesale Energy Markets,” met the policy mandate of the Energy Policy Act of 2005 (FERC 2012) by paying demand reduction in response to time-varying wholesale prices. The FERC demand response regulation has focused on promoting demand reduction during peak demand periods. There are two design components to FERC’s Order 745 (“Order 745”) that have received attention in the policy debate. First, the order prescribes that demand response resource owners (load that can be reduced) should be allowed to offer their demand reduction as if it were a supply resource rather than a bid to reduce demand. This means that the consumers that reduce demand would be paid the wholesale rate in addition to saving the money for electricity not consumed.Footnote 4 Second, the demand reduction is measured by a customer baseline. This second design component has received less attention than the first. We focus here on the results of these two components of Order 745. Our hypothesis is that the increased compensation for demand reduction creates an incentive to distort the customer baseline. In order to implement the policy of paying for a demand reduction, the market operators must devise an estimate of what the consumption would have been but for the reduction in consumption based on historical consumption levels—the “customer baseline.” However since consumers are paid more for a reduction if their customer baseline is higher relative to their consumption, they have an incentive to raise the customer baseline. This can be done by consuming more energy during normal periods when the consumer is not called to reduce demand. The customer baseline is established during these normal periods, which are also known as non-event periods. The critical task of establishing the customer baseline was recognized by Alfred Kahn, who noted that a flawed baseline design could potentially unravel the policy. (Kahn 2010) While continuing to support the FERC policy, he conditioned his support on resolving the baseline problem. Moreover, empirical studies have found evidence of baseline inflation. (Wolak 2006). This formed one, if not the principal, reason for the opposition of the Market Surveillance Committee of the California ISO’s opposition to demand response program proposed by the California ISO (Wolak et al. 2009). Our model results show that the demand reduction payment will induce consumers to inflate the customer baseline by increasing consumption above the already excessive level during normal peak periods. Moreover, this result is robust, persisting when we apply it in a dynamic model to the two alternative baseline designs that have been considered in the U.S. wholesale markets. The model also confirms a point made previously by other commentators that payment will exaggerate demand reduction by decreasing consumption beyond the efficient level during a demand response event (Borlick 2010; Hogan 2010; Chao 2011). We review three possible policy remedies to the baseline inflation problem. The ideal solution is a financially binding, “contractual baseline,” in which the marginal consumption decision is based on the time-varying wholesale rate. We also examine subtracting the retail from the wholesale rate, as has been proposed in comments to Order 745. The third solution is a new baseline method, which prevents baseline inflation by establishing the customer baseline as a fixed proportion of an aggregate baseline. We show that by separating the individual’s consumption from the baseline level the aggregate baseline approach can significantly weaken or eliminate the incentive to inflate the baseline. We show that the possibility of a net social benefit requires that demand response only be dispatched when the wholesale rate is sufficiently higher than the retail rate. Specifically we illustrate that there is a net social benefit to the payments when the wholesale price would be at least twice the fixed retail rate absent the demand reduction from the demand response policy—as long as the baseline inflation problem has been resolved. Section 2 presents the incentive effects of the wholesale demand response regulation on the consumer behavior. Section 3 presents alternative policy remedies that address the problems identified, including a new approach based on aggregate baseline. Section 4 presents a net benefit analysis of the current policy modified with an aggregate baseline approach. Section  5 provides the conclusion of our analysis. Appendix A presents the reference model without the demand response policy. Appendix B extends the results of the basic model to incorporate dynamic baseline designs that have been considered for actual implementation.",25
43.0,3.0,Journal of Regulatory Economics,19 February 2013,https://link.springer.com/article/10.1007/s11149-013-9212-0,An econometric assessment of telecommunications prices and consumer surplus in Mexico using panel data,June 2013,Jerry A. Hausman,Agustin J. Ros,,Male,Male,Unknown,Male,"The Mexican telecommunications market is generally considered more concentrated than telecommunications markets in other OECD countries. This has led some authors to conclude that consumers in Mexico pay high prices and that there are large losses in consumer surplus.Footnote 1 Moreover, regulators in Mexico are contemplating asymmetric regulation of the dominant mobile operator (including regulation of retail mobile prices) due, in part, to the perception of high prices and concentration. In telecommunications, however, high market share is a necessary but not a sufficient condition for a finding of market power and supra-competitive prices. Because of minimum efficient scale of operation relative to total demand, most countries have few facilities-based operators—three to five facilities-based mobile operators and fewer fixed-line operators. Yet competition in telecommunications markets can be robust with more countries moving further away from active sector regulation and relying more on general antitrust/competition policy laws. In this paper we find that concentration is a poor predictor of performance for the Mexican telecommunications market. We develop econometric demand models that show that mobile and fixed-line prices in Mexico are actually lower than one would expect based on comparable countries. In 2011, mobile prices in Mexico were 32–60 % lower than the model’s prediction—corresponding to additional consumer surplus of $4–$5 billion. Similarly, in 2010, fixed-line prices were about 15 % lower than the model’s predictions—corresponding to additional consumer surplus of $1 billion. Our models together show that, based on comparable countries, low mobile and fixed-line pricing in Mexico resulted in at least an additional $5–$6 billion in consumer surplus in 2010 and 2011. These findings suggest that prior to the imposition of regulations (especially mobile retail price regulations) regulators should examine all economic factors that are important determinants of market power including market share, supply elasticity, and demand elasticity. In Sect. 2 we present our econometric analysis. We begin with a discussion of the methodology and approach used to select a sample of comparable countries used in the econometric analysis as well as a discussion of the underlying data used in the study and the consumer surplus calculations. Section 2 is divided between analysis for the Mexican mobile sector and the Mexican fixed-line sector. In Sect. 3 we present our conclusions and regulatory implications.",22
43.0,3.0,Journal of Regulatory Economics,29 January 2013,https://link.springer.com/article/10.1007/s11149-013-9209-8,Approximations in power transmission planning: implications for the cost and performance of renewable portfolio standards,June 2013,Francisco D. Munoz,Enzo E. Sauma,Benjamin F. Hobbs,Male,Male,Male,Male,"Since the 1990s, electricity markets have experienced major changes worldwide, including restructuring to promote competition and increasingly stringent environmental rules. Public demand for environmental improvement together with a desire to diversify fuel sources have led to ambitious targets for development of renewable electricity generation, along with policies designed to encourage investment to achieve those targets. Specific policies used to promote renewable electricity vary from country to country. They include feed-in tariffs, taxes, subsidies and standards, as well as combinations of these policies (Wiser et al. 2007; Fouquet and Johansson 2008). One type of regulation that has become popular in the U.S. is the Renewable Portfolio Standard (RPS), which is a policy that seeks to create more demand for electricity supplied from renewable energy technologies. The RPS promotes demand for “green” electricity by obligating utilities, retailers, or other load-serving entities (LSEs) to provide a specified fraction of their sales from qualifying renewable technologies. Usually, a tradable credit system is implemented so that entities that have too little renewable production can buy surplus credits from entities that have more than the required minimum. These credits are generally called Renewable Energy Certificates (RECs), which are financial instruments created from the production of one unit of energy from a qualifying renewable energy source. Accordingly, RPSs with tradable RECs are described as market-driven regulations, because the policies specify neither which firm should invest nor which type of renewable technology should be used to fulfill the requirement (e.g. wind or solar). The aim is to promote competition among potential clean energy producers and adoption of the most cost-efficient technologies (Wiser et al. 2007). These mechanisms require specification of certain market features such as target definitions over time, resource eligibility, resource-specific requirements (tiers), who is responsible for compliance, geographic restrictions, and treatment of power imports, among others (Berry and Jaccard 2001). The flexibility provided by tradable RECs is important for minimizing the social cost of meeting the portfolio standard. Allowing banking and/or borrowing of the RECs also enhances flexibility. Banking allows firms to use excess RECs from past years for future compliance. If borrowing is allowed, then LSEs can compensate for a shortfall of RECs in a current period by using RECs from future years. If an LSE cannot acquire sufficient credits by trade, withdrawal of banked allowances, or borrowing, then they will usually pay a non-compliance penalty. In most cases, this penalty is proportional to the amount of the shortfall of renewable energy. To date in the U.S. 30 states and the District of Columbia have implemented various versions of RPSs (AEO 2011). California, for example, set a 20 % obligation by 2013, 25 % by 2016, and a 33 % requirement by 2020 (SB2 2011), with intermediate values for other years; however, compliance is enforced only for multi-year periods.Footnote 1 Hawaii, on the other hand, set specific, and increasing, goals for every year from 2010 until 2030. While in Hawaii there is no banking or borrowing, LSEs in California have flexibility to shift production among years within a multiyear-compliance period. Moreover, in California, banking of RECs is allowed both within a compliance period and for future compliance periods, although borrowing is only allowed within a compliance period. Figure 1 shows the evolution of renewable goals in California, Hawaii, and New Jersey.Footnote 2
 Renewable goal as a percentage of the total electricity demand by year for three states RPS policies have been established in the US in order to induce renewable investments, to promote technology change and jobs, and to reduce emissions. However, in most cases, the renewable energy targets have been chosen without detailed analyses of either the benefits that would result, or their costs. Several authors have performed theoretical economic analyses of the effects of imposing different levels of RPSs (Amundsen and Mortensen 2001; Palmer and Burtraw 2005; Fischer 2010); however, all these studies disregard transmission constraints and the need for transmission reinforcements to access renewable resources. One main difference between renewable and conventional generation is that the former is geographically constrained. Conventional generation can be built strategically near existing high-voltage transmission corridors, water supplies, and fuel networks, whereas the highest quality renewables are only available at certain specific sites that may be located hundreds of miles from the closest interconnection point. Large transmission investments are needed to access the most attractive renewable resources. California, for example, estimates that $16 billion of investment in transmission infrastructure will be needed to meet the 33 % renewable target by 2020 (CPUC 2009), twice the $8.2 billion annual cost of wholesale power in the California ISO market in 2011. More generally, Kahn (2010) estimates that the transmission costs associated with renewables are at least four times the costs of providing frequency regulation and other ancillary services needed to back up variable renewables, even though the expense of such services has received much more attention in the literature than have transmission costs. Hence, disregarding transmission constraints when assessing the cost and feasibility of renewable targets can be a problematic oversight. Historically, transmission planning has been considered a challenging problem for several reasons. First, transmission investments present important economies of scale; therefore, investments in network infrastructure normally come in large lumps (Joskow and Tirole 2005). Although some thermal generation technologies still have significant economies of scale, many renewable generation technologies are modular and tend to have more constant returns to scale.Footnote 3 Second, power flows on electricity networks obey Kirchhoff’s voltage law (KVL), which causes what is known as “loop-flow” externalities (Chao and Peck 1996). A transmission-planning model that ignores KVL can result in investment recommendations that could actually be detrimental for the system (e.g., by increasing rather than decreasing operating costs) (Wu et al. 1996). Third, changes in the topology or capacity of the existing grid have direct implications for the economics of future generation investments of any kind. This can cause inefficiencies in unbundled electricity markets, in which transmission and generation assets are no longer planned by the same authority (Sauma and Oren 2006). In the U.S. stringent state renewable portfolio standards and, more recently FERC order 1000, have motivated regional transmission operators (RTOs), independent system operators (ISOs), and research organizations to perform transmission-planning studies to identify cost-effective strategies to meet renewable goals (Schumacher et al. 2009). Studies by Ela et al. (2009); Hecker et al. (2009), and Gentile et al. (2010), for example, fit in the category of regional studies that develop indicative transmission plans for various scenarios of generation configurations. Others adopt the concept of competitive renewable energy zones (CREZ), first used in Texas (Lasher 2008) and now applied in California (RETI 2010) and the Western Electricity Coordinating Council (WECC) (Pletka and Finn 2009). CREZ-based transmission planning in California and the WECC operates under the assumption that renewable resources can be characterized, or ranked, using levelized or bus-bar costs, the latter including a pro-rata share of the transmission costs needed to deliver the power to the grid (Mills et al. 2011). Although some of these transmission-planning studies use detailed production cost simulations, they do not use formal optimization algorithms to identify the optimal (least-cost) set of generation and transmission investments. Moreover, in contrast to the models proposed in Sauma and Oren (2006), and Sauma and Oren (2007), they ignore the response of generation investors to the location of transmission expansions. There are other examples of resource planning tools and transmission planning studies for renewable integration in the academic literature. In NREL’s Regional Electricity Deployment System (ReEDS), for example, KVLs are enforced on existing lines (constant PTDF matrix), but transmission investments are assumed continuous (Short et al. 2011). Olson et al. (2009), focused on the integration of long HVDC transmission lines across the WECC for different scenarios, without using formal optimization approaches. Pozo et al. (2012) computed the optimal (least-cost) set of generation and transmission investments, but using a static model and assuming that transmission investments are continuous. Morales et al. (2012) also present a static model, but of a more complex Stackelberg game between a risk-averse transmission planner and remote wind developers. Muñoz et al. (2012) proposed a lumpy and dynamic transmission planning model for different levels of penetration of renewable generation, but taking generation investments as exogenous variables. While most of the previous works use static (i.e., single-decision stage) and/or deterministic models, Van der Weijde and Hobbs (2012) and Munoz et al. (2012) propose multi-stage stochastic methodologies to find “here and now” investments to hedge against market uncertainties, while also taking into account generators’ response. However, in all these studies, renewable goals are exogenously specified inputs, and no further analysis of renewable policy design was undertaken, nor were the economic and environmental benefits and costs of different renewable goals quantified. To our knowledge, the only existing study focusing on the interaction between RPS design and transmission planning is (Vajjhala et al. 2008). The authors compared the impacts of state and federal RPSs in the U.S. in terms of costs and infrastructure, concluding that the location of new transmission infrastructure will affect both the location and type of renewable generation investments. However, KVL was ignored and new transmission capacity was exogenously imposed on the generation market using an iterative heuristic until most interregional congestion was eliminated. There are no studies that analyze the interaction between transmission planning and RPS performance using models that optimize transmission expansion taking into account the lumpiness of transmission investments, their effect on generation investments, KVL, and the dynamic nature of investment decisions. In this article we have three objectives. First, we ask: how do simplified transmission models that ignore transmission constraints, transmission lumpiness, or KVL distort conclusions regarding the costs, investments, and degree of compliance with RPS targets? Second, we consider the question: how does the level of noncompliance penalties affect the amount by which renewable generation falls short of RPS targets, accounting for transmission costs? Third, we consider how answers to these questions are affected if we consider the dynamic interaction of transmission investments on renewable policies that change over time. Interactions between flexibility (in terms of both non-compliance penalties and the existence of banking and borrowing policies) and the discrete characteristics of transmission upgrades can have a significant impact on the performance of RPSs. Although many features of RPSs must be considered when designing them, we focus on RPS target levels, noncompliance penalties and banking/borrowing flexibility, and their interactions with lumpy transmission investments. The rest of this article is organized as follows. In Sect. 2, we draw some basic results for simple radial networks to provide the basic economic intuition of transmission planning for renewables and the effects of ignoring transmission indivisibilities. In Sect. 3, we describe the single- and multi-stage models we use for our analyses, generalizing them to meshed networks, including the situation of growing renewable goals over time and the possibility of banking and borrowing RECs. In Sect. 4, we derive some theoretical results for the more general model. In Sect. 5 we describe our case study and results. In Sect. 5.1 we compare the effects of ignoring transmission constraints, lumpiness and KVL; in Sect. 5.2 we study the effects of noncompliance penalties; and in Sect. 5.3 we study how REC banking and borrowing mechanisms interact with transmission planning. Section 6 concludes.",65
44.0,1.0,Journal of Regulatory Economics,25 June 2013,https://link.springer.com/article/10.1007/s11149-013-9226-7,Market-based approaches to environmental regulation: Editors’ introduction,August 2013,Michael A. Crew,Anthony Heyes,,Male,Male,Unknown,Male,,3
44.0,1.0,Journal of Regulatory Economics,05 May 2013,https://link.springer.com/article/10.1007/s11149-013-9221-z,"Vehicle choices, miles driven, and pollution policies",August 2013,Ye Feng,Don Fullerton,Li Gan,,Male,,Mix,,
44.0,1.0,Journal of Regulatory Economics,12 February 2013,https://link.springer.com/article/10.1007/s11149-013-9213-z,Community-based incentives for environmental protection: the case of green electricity,August 2013,Grant D. Jacobsen,Matthew J. Kotchen,Greg Clendenning,Male,Male,Male,Male,"When considering market-based approaches to environmental policy, the instruments that typically come to mind are taxes and subsidies in various forms, along with systems of tradable permits that allow pollution emissions or the right to expropriate a resource. That economists tend to favor market-based approaches over command-and-control regulations, such as emission standards and technology requirements, is well-known. Economic theory tells us that under many circumstances, though not all, market-based approaches can achieve environmental outcomes at lower cost. Because they are generally less prescriptive, market-based approaches allow greater flexibility over the methods of compliance, while simultaneously creating incentives for further innovation. With tradable permits, there are also efficiencies that arise because of gains from trade in the permit markets themselves. The unifying feature of all market-based approaches is to affect price signals in ways that more accurately reflect social costs or benefits, and thereby create incentives for greater environmental protection. Yet, the recent contributions of behavioral economics and studies with greater integration of economics with social psychology emphasize the important influence of social context on decision-making. The “identity economics” of Akerlof and Kranton (2000, 2010), for example, is based on the notion that individual preferences vary with social context, whereby identities and social norms interact to exert powerful influences on behavior. There is also the Nobel Prize winning work of Ostrom (2010) on solutions to the common-pool resource problem. Among the conditions that she finds for successfully solving collective action problems are not only the familiar notions of property rights and economic incentives, but also the need for institutional arrangements that recognize the importance of social networks (Ostrom 1990, 2000). Recent studies in energy and environmental economics reinforce the importance of norms and social context. Allcott (2011) and Ayres et al. (2009) show that social comparisons through home energy reports on utility bills can promote conservation. According to both studies, households are spurred to decrease their energy consumption when they are informed that their consumption is greater than that of other comparable households. In related research, Costa and Kahn (2010) study heterogeneous effects and find that the “nudge” of social norms for household energy conservation works for liberals but can backfire for conservatives. Also with a focus on non-pecuniary incentives and norms, Harding and Hsiaw (2011) find that goal setting is an effective mechanism to induce energy efficiency and conservation in the residential sector. Jacobsen (2012) shows that climate change awareness campaigns that target certain communities lead to increased purchases of carbon offsets within those communities. Moreover, when households voluntarily purchase carbon offsets, different marketing strategies that appeal to either environmental concerns or social preferences for future generations induce different behavioral responses, with the latter more consistent with conservation (Harding and Rapson 2012). Finally, Bollinger and Gillingham (2012) find that social interactions through peer effects play an important causal role in household decisions about the installation of solar photovoltaic (PV) panels.Footnote 1
 In this paper, we study a hybrid policy: a government subsidy of community-level rewards to both mobilize social capital and increase the incentives for households to purchase green electricity, which is electricity generated from renewable sources of energy. The Connecticut Clean Energy Communities (CCEC) program is a statewide initiative designed to incentivize households to voluntarily purchase green electricity at a price premium from one of two state approved providers. The CCEC operates at the municipality level for Connecticut towns that voluntarily join and meet basic qualification criteria (discussed later). Upon joining and qualifying for the program, municipalities receive free PV panels in proportion to the number of households that voluntarily purchase green electricity. The PV panels are then installed at public locations within the municipality, including town halls, schools, and libraries. While the CCEC program takes a somewhat non-traditional approach to environmental protection, the program does aim to improve price signals in the way mentioned previously for market-based environmental policies. In effect, the CCEC program lowers the price of purchasing green electricity because of the additional community benefits associated with each purchase. In practice, this additional social benefit depends to a large degree on social groups mobilizing to inform the community about the existence of the program. Indeed, Connecticut residents and officials familiar with the program indicate that the success of the CCEC program has depended on the formation of community-based recruitment campaigns, often emerging through schools networks and other community organizations, that seek to raise awareness of the CCEC program and meet its eligibility requirements. In what follows, we provide a systematic evaluation of the CCEC program. First, we take advantage of municipality-level data on household purchases of green electricity from June 2005 through December 2011 to determine whether the CCEC program increases household purchases of green electricity. Second, we examine patterns in the rate of new purchases to shed light on whether the CCEC program achieves its results, at least in part, through the mobilization of community-based recruitment campaigns aimed at meeting the program’s primary eligibility threshold. Third, we exploit a change in the CCEC program’s subsidy rate—how household purchases translate into community PV panels—to test whether the actual marginal incentive affects household purchases of green electricity. Finally, we conduct a simple cost-effectiveness analysis of the CCEC impacts on residential demand for green electricity in Connecticut.Footnote 2
 The results of this research contribute to the literature through program evaluation of a new form of market-based environmental policy: subsidizing pro-environmental behavior through community-level rewards. The application to green electricity is related to broader trends in the US economy. More than 1.4 million households voluntarily purchased green electricity in 2009, the same year that demand increased 7 % (Bird and Sumner 2010, 2011). While the percentage of households making these purchases remains very low, state governments and electric utilities are increasingly looking towards green-electricity programs as one way to change the mix of energy sources toward a larger share of renewables, and the potential role of community-based initiatives is now recognized (Berry 2010). Hence the results reported herein evaluate an innovative mechanism for stimulating demand for green electricity, along with providing evidence on acquisition costs of new customers. In doing so, the paper complements other studies on green-electricity programs that focus on the determinants of program participation (Clark et al. 2003; Kotchen and Moore 2007) and behavioral responses (Kotchen and Moore 2008; Jacobsen 2012). We find that the CCEC program causes a 22 % increase in the number of households that purchase green electricity in CCEC municipalities. A strength of this estimate is that identification is based on within municipality variation and comparisons with other municipalities that qualify for the CCEC program but have not enrolled. We find that the CCEC boosts participation around the time of initial qualification—up to 700 %—rather than inducing a sustained level of more new signups. Yet, having the CCEC program itself is the important feature, rather than the precise marginal incentives it creates. The implication for policy is that community-based incentives can be effective, at least in part because they lead to the formation of community recruitment campaigns; and yet the size of the subsidy itself appears less important. Finally, simple calculations based on CCEC up-front costs reveal upper-bound, cost-effectiveness measures of $570 per household signup, for which there is an implied cost of 6.7 \(\not \!\!{c}\) per kilowatt-hour (kWh) of annual green-electricity demand, and $113 per ton of annual carbon-dioxide emission reductions.",17
44.0,1.0,Journal of Regulatory Economics,26 March 2013,https://link.springer.com/article/10.1007/s11149-013-9216-9,Who should bear the administrative costs of an emissions tax?,August 2013,John K. Stranlund,Carlos A. Chávez,,Male,Male,Unknown,Male,"Any environmental policy involves costs beyond what would normally be categorized as abatement costs. These costs include the costs of monitoring polluters for compliance and imposing sanctions when a violation is found. In addition, resources are expended for monitoring policy performance, conducting research, and record keeping and reporting by both regulated firms and regulators. For environmental taxes, these costs include the costs of setting up and maintaining a system for collecting tax revenue. Perhaps for lack of a better term, these costs may be referred to as administrative costs. These are the costs of implementing and managing environmental policies that extend beyond abatement costs. In practice, these costs are typically borne by both regulated firms and regulators. Policy analysts have long known that administrative costs can affect the setting of optimal emissions taxes. Polinsky and Shavell (1982) show how administrative costs can affect the level of a uniform Pigouvian tax. Brock and Evans (1985) examine how the existence of administrative costs can justify setting a lower tax on smaller firms than on larger firms. Cremer and Gahvari (2002) and Stranlund et al. (2009) show that enforcement costs can produce discriminatory emissions taxes. Researchers also understand that administrative costs can affect the relative efficiency of different kinds of environmental taxes. For example, Smulders and Vollebergh (2001) examine how administrative costs, particularly monitoring costs, determine the use of emissions and input taxes with specific reference to the choice between taxing CO\(_{2}\) emissions or taxing energy products. Schmutzler and Goulder (1997) provide another analysis of mixed environmental taxes that is motivated by differences in monitoring costs.Footnote 1
 While it is well known that administrative costs can be important determinants of the design and performance of environmental policies, in the literature on emissions taxes the distribution of administrative costs between the public (via government regulators) and polluting firms is taken for granted. No one to our knowledge has addressed the question of who should bear the administrative costs associated with emissions taxes, the public, regulated pollution sources, or some combination. This is true of other environmental and natural resource policies as well, although some attention has been devoted to the subject in fisheries management.Footnote 2
 Policymakers cannot sidestep the problem of distributing administrative costs and have confronted it in a variety of ways. Many emissions control policies require that regulated firms bear the costs of monitoring and reporting their own emissions while the government takes on the burden of checking emissions reports and sanctioning violations. (The SO\(_{2}\) Allowance Trading Program is a good example). Some programs collect administrative fees from pollution sources to help finance enforcement and other activities. For example, Title V of the 1990 amendments to the U.S. Clean Air Act requires most large sources and some smaller sources of air pollution to obtain operating permits, and to pay an annual fee per ton of each regulated pollutant to cover the costs of administering the permit program. In this paper we examine theoretically the joint determination of an efficient emissions tax and the distribution of administrative costs between the public and regulated firms. We identify three factors that determine whether the distribution of administrative costs affects social welfare. (1) Firm-level emissions may increase administrative costs directly. For example, firms with higher emissions may require more expensive monitoring equipment. (2) Having firms bear a larger part of administrative costs can reduce the size of the industry, holding the emissions tax and the industry’s output price constant. (3) Public funds devoted to administering the emissions tax may be more expensive than private funds due to the deadweight costs of other taxes used to generate government revenue. When these factors are not present the distribution of administrative costs does not affect the social costs and benefits of controlling emissions with an emissions tax, so regulators need not be concerned with specifying an optimal distribution. Even if the distribution of administrative costs does not affect social welfare, a distribution must be chosen (by some criterion unrelated to economic efficiency) and this choice helps determine the optimal emissions tax. Whether the tax should be higher or lower than marginal damage depends on the distribution of administrative costs and how the tax affects equilibrium aggregate administrative costs. These results are relevant when there is not an efficiency consequence of choosing a particular distribution of administrative costs, or when these consequences exist but are not accounted for when specifying the distribution in the regulation. Given that the distribution of administrative costs does impact social welfare, and hence should be specified in a truly optimal tax regulation, the optimal distribution and tax become fairly complex decisions requiring determination on a case-by-case basis. The reason is that, in general, the distribution of administrative costs has ambiguous impacts on equilibrium aggregate emissions and administrative costs. Consequently, in any particular situation the optimal distribution of administrative costs can range from having polluting firms bear all administrative costs, to the firms and government sharing these costs, to having the government take on the entire burden. Moreover, the optimal emissions tax can be less than, greater than, or equal to marginal damage. While it is difficult to reach specific conclusions about the optimal distribution of administrative costs and the tax in the general case, we can obtain insight into the problem by examining special cases. We analyze two of these cases. The first is when the price of the industry’s output is fixed, and hence, is relevant for the emissions control of a domestic (or regional) industry that faces a perfectly elastic demand curve because it is a relatively small part of a much larger international (or national) market. In this case, we demonstrate that it is optimal for the firms to bear all administrative costs and the emissions tax to be below marginal damage if aggregate administrative costs are nondecreasing in the tax. In our second special case, administrative costs do not depend directly on firm-level emissions and the distribution of these costs does not affect the size of an industry. This case is relevant when administrative costs are so “small” that they have a negligible impact on firms’ decisions. If public funds are more expensive than private funds, then it is optimal for firms to bear all administrative costs and the optimal tax is less than marginal damage. Our second special case also covers common assumptions in the theoretical literature on enforcing emissions taxes. These models typically involve a fixed number of firms, enforcement costs that do not depend on firms’ emissions (there are no other administrative costs) and these costs are borne entirely by the government. Examples of such models are found in Montero (2002), Cremer and Gahvari (2002), Macho-Stadler and Perez-Castrillo (2006), Stranlund et al. (2009), and Evans et al. (2009).Footnote 3 We demonstrate that under the first two assumptions, having the government bear all enforcement costs never welfare-dominates having the polluters bear all enforcement costs. Thus the standard assumption that the government takes on all enforcement costs often imposes an inefficient policy design on a model. The rest of the paper proceeds as follows. In the next section we lay out the elements of our model and determine how the policy parameters, an emissions tax and distribution of administrative costs, affect equilibrium market and emissions outcomes. Section 3 contains the main results of our analysis, those concerning the optimal distribution of administrative costs. We conclude in Sect. 4.",4
44.0,1.0,Journal of Regulatory Economics,28 March 2013,https://link.springer.com/article/10.1007/s11149-013-9219-6,Prices versus quantities: environmental regulation and imperfect competition,August 2013,Erin T. Mansur,,,,Unknown,Unknown,Mix,,
44.0,1.0,Journal of Regulatory Economics,26 February 2013,https://link.springer.com/article/10.1007/s11149-013-9211-1,Understanding the effectiveness of environmental offset policies,August 2013,Robert Hahn,Kenneth Richards,,Male,Male,Unknown,Male,"One of the great ideas invented by economists was to suggest using “market mechanisms” to achieve a given environmental outcome at least cost (Pigou 1920;Crocker 1966). The two textbook examples most often presented in economics classes are taxes and cap-and-trade. Taxes are an example of a pricing instrument and cap-and-trade is a quantity instrument. Both of these instruments work by putting a price on pollution, thus encouraging those firms with the least expensive pollution control options to make use of them. In the real world, taxes and cap-and-trade systems are rarely implemented in their pure form. In this paper, we examine a related approach that has been used widely in practice—which we refer to as an “offset.” A key goal of an offset program is to reduce the costs of achieving a particular level of environmental protection. The costs include not only compliance costs, but the additional private transactions costs and public administrative costs associated with the offset program. The idea behind offsets is to get firms or entities that may not be a part of the core regulatory system to produce environmental improvements, which can then be used to offset pollution reduction requirements in the core regulatory system (Liroff 1980). So, for example, if a developer’s activities take away wetlands in one neighborhood, he may be required to provide an equivalent amount of wetlands, or eco-system services in another area. In principle, offsets, like other market mechanisms, have the potential to dramatically lower the costs of achieving a given environmental quality target. For example, U.S. Environmental Protection Agency analysis (EPA) of the 2009 Waxman-Markey climate bill indicated that the abatement cost associated with the bill would be 20 % higher if international offsets had not been incorporated (Environmental Protection Agency 2009). The paper analyzes how offsets are used in practice, and identifies key factors that help explain the use of offsets in certain situations. We analyze the rich array of applications of offsets in environmental and energy regulation. Examples are drawn from offset programs for limiting greenhouse gas emissions, maintaining ecosystem services for wetlands, achieving local air pollution goals, water quality protection, and promoting energy efficiency. We find that while offsets may be theoretically attractive in some applications, there are many obstacles to their effective implementation. In general, there is a tradeoff between the certainty of achieving additional environmental protection, on the one hand, and the potential to lower the cost of regulation, on the other. We argue that the effectiveness of an offset policy depends on the political and institutional context in which it is developed. Section 2 of the paper offers a new definition of offsets, and addresses issues in evaluating and designing these programs. Section 3 assesses the performance of offset programs in practice and presents three case studies. The political economy of offsets is examined in Section 4. Finally, Section 5 presents conclusions and suggests areas for future research.",10
44.0,2.0,Journal of Regulatory Economics,05 April 2013,https://link.springer.com/article/10.1007/s11149-013-9220-0,Flexible mandates for investment in new technology,October 2013,Dalia Patino-Echeverri,Dallas Burtraw,Karen Palmer,Female,,Female,Mix,,
44.0,2.0,Journal of Regulatory Economics,03 April 2013,https://link.springer.com/article/10.1007/s11149-013-9217-8,"Pollution standards, technology investment and fines for non-compliance",October 2013,Carmen Arguedas,,,Female,Unknown,Unknown,Female,"The structure of the fines for non-compliance with environmental rules has been extensively studied by economists in the enforcement literature.Footnote 1 A relevant research topic within this field is to question if regulators should impose maximum fines as a means of inducing compliance with the lowest possible monitoring efforts (Becker 1968), or if fines should be kept low. In fact, an extensive number of papers suggest that optimum fines should not be maximum. Reasons that support this view include the possibility of targeting enforcement in dynamic settings (Harrington 1988; Raymond 1999; Friesen 2003), self-reporting of emission levels (Livernois and Mckenna 1999), penalty evasion (Kambhu 1989), possible inverse relationships between fines and probabilities of conviction (Andreoni 1991), marginal deterrence (Shavell 1992), specific versus general enforcement (Shavell 1991), hierarchical governments (Saha and Poole 2000; Decker 2007), or others. Moreover, in practise fines for non-compliance tend to be relatively low and nevertheless compliance rates are still high, or at least, higher than predicted in theory.Footnote 2
 An interesting feature of some current environmental regulations is that they explicitly include the possibility that fines for non-compliance can be reduced if polluting agents have shown documented evidence of compliance-promoting activities. For example, in the Spanish legislation on hazardous waste (see Law 5/03 on Residuals and Law 10/93 on Liquid Industrial Waste of the Autonomous Community of Madrid), monetary sanctions depend on the degree of non-compliance with the required standards as well as on the efforts of firms to minimize the social pollution effects of their infractions. As a consequence, firms that invest in clean production processes associated with responsible water consumption are rarely inspected and, if inspected, they are rarely punished if found out of compliance. Another example is the EPA’s Audit PolicyFootnote 3, where fines for non-compliance can be reduced up to 100 % of the non-gravity-based part and up to 75 % of the gravity-based component if firms promptly disclose and correct any discovered violations as a result of a self-audit procedure.Footnote 4 These practices generally involve large investment efforts in compliance-promoting activities, including information costs such as training personnel about regulatory requirements. As a result, the likelihood of violations decreases because facilities are able to identify and correct problems before they become violations, see Stafford (2005). Thus, enforcement relief and, in particular, penalty reductions in exchange for investment efforts by polluting firms are specifically included in environmental laws. However, an interesting (but not yet formulated) research question is if those reductions are appropriate from an optimal perspective. The purpose of this paper is then to analyze under what conditions fines should be reduced in relation to firms’ investment efforts. We consider a simple game between a regulator and a polluting firm. We adopt a principal-agent setting where the regulator (principal) sets the environmental standard (or pollution limit), the inspection probability and the fine for non-compliance with the standard. Then, the firm (agent) reacts to this policy by selecting first the technology investment effort and then the pollution level. When choosing the pollution level, the firm automatically selects the degree of non-compliance (if any) with the standard. The fine depends on the degree of violation and can also be contingent on the firm’s investment effort. When designing the policy, the regulator considers the firm’s compliance and investment costs, the pollution damages and the enforcement costs (that is, monitoring and sanctioning costs). Since fines (and possible reductions of the fines) are imposed when the firm is found violating the standard, we first find an intuitive condition that determines when it is optimal to set an environmental policy that induces non-compliance. This condition characterizes the social preference for non-compliance and it balances sanctioning and monitoring costs. Intuitively, the lower the sanctioning costs relative to monitoring costs, the more likely the optimal policy induces non-compliance. Three critical conditions determine the social preference for a fine that offers discounts contingent on the investment effort. First, there must be administrative costs associated with imposing sanctions. Otherwise, decreasing the fine only results in additional monitoring costs. Second, the optimal policy must induce non-compliance with the standard. If to the contrary, the optimal policy induced compliance, the optimal fine should not be reduced, since sanctioning costs would be absent in that case. Then, the only way to save on monitoring costs would be by means of sufficiently large fines. Since the condition that characterizes the social preference for non-compliance is that sanctioning costs relative to monitoring costs must be sufficiently small, this imposes an upper bound on the level of the sanctioning costs for which it is socially desirable that fines are reduced contingent on investment effort. Therefore, combining the first two conditions that characterize the social preference for a fine contingent on investment effort, we find that there must be administrative costs associated with imposing sanctions, but these administrative costs should not be too large. Finally, the third condition considers the progressiveness of the fine with respect to the degree of non-compliance and the effect of the investment effort on marginal abatement costs. This condition is met if either the fine is sufficiently convex in the degree of non-compliance, or the investment effort decreases marginal abatement costs significantly. These two possibilities ensure that pollution cannot increase much in the case of a fine cut. This paper is similar in spirit to those of Stranlund (2007) or Arguedas (2008), in the sense of finding the optimal regulatory policy among the full rank of policies, that is, those that induce compliance and also those that induce non-compliance with the regulation. In these papers, there is also a key condition that determines the desirability of compliance versus non-compliance, although there the firm is not allowed to choose the investment effort. Also, this paper fits within the strand of the economics literature that defends the implementation of non-maximal fines. However, we are not aware of any paper that deals with the optimality of incorporating penalty discounts in the laws as a means of inducing investment efforts by the firms. There are, however, some related papers, such as Arguedas and Hamoudi (2004), who consider fines dependent on both the degree of violation and the environmental technology that the firm employs, but who assume that fines are given (i.e., not a regulator’s choice variable); Arguedas (2005), who considers that regulators and firms negotiate over the stringency of the fines and the possibility of clean technology investment, as opposed to the principal-agent framework adopted here; or Decker (2007), who shows that fines should be lowered as a result of firm’s over-investment due to excessive enforcement effort in the case of responsive regulation. Decker (2007) considers three critical assumptions that are not adopted here: (i) a hierarchical regulatory structure with different objectives (the regulator responsible for setting the fines is a social costs minimizer while the agency responsible for the enforcement minimizes the sum of enforcement costs and the reputation costs related to failures in undertaking proper enforcement efforts); (ii) the existence of reputation costs (otherwise, the enforcer would always exert minimum effort); and (iii) responsive versus unresponsive regulation (i.e., either the enforcer and the firm act simultaneously—choosing respectively the inspection probability and the investment effort—, or the enforcer chooses the inspection probability at a later stage). In this paper, we find that fines should be negatively linked to investment effort, but the explanation is very different to that of Decker (2007). Instead of considering a hierarchical structure, we focus on the characteristics of the optimal policy (a fine, an inspection probability and a standard) from a strictly social cost minimizing point of view. Thus, we consider that enforcement is always taken properly (i.e., failures are not allowed) and, therefore, the assumption of the existence of “reputation costs” is nonsense in our setting. Moreover, instead of considering unresponsive versus responsive regulation, we analyze the case where the regulator sets all the policy parameters in advance and then commits to the regulation afterwards.Footnote 5
 With all these alternative assumptions in mind, our contribution is to show that fines should be lowered when it is socially optimal that the policy induces non-compliance and when there exist social costs of imposing sanctions. Therefore, it is not a matter of reducing fines to reduce excessive investment by firms, as in Decker (2007), but to reduce excessive administrative costs. There are several papers that specifically analyze the EPA’s Audit Policy, that is, the provision of incentives for self-policing through the reduction of penalties for non-compliance, see Stafford (2005) for a critical discussion of the literature. For example, in Mishra et al. (1997) or Pfaff and Sanchirico (2000), penalties are conditioned on the level of self-policing, although compliance is exogenous. Self-policing is also analyzed theoretically in Kaplow and Shavell (1994), who present a model of probabilistic environmental enforcement; Innes (1999) who considers the potential benefits of remediation; Innes (2000), who assumes violators having different probabilities of apprehension; or Innes (2001), who incorporates the possibility of avoidance activities, among others. This paper is also related to the strand of the literature that deals with environmental technology adoption, although adoption incentives under the different policy instruments have been analyzed mainly in the case of perfect compliance (a couple of recent exceptions are Arguedas et al. (2010) and Villegas and Coria (2010)). In general, the ranking of optimal policy instruments when promoting the investment in cleaner technologies depends on the structure of the regulation schemes, such as the timing of the game, the market conditions or the damage function, see, for example, Requate and Unold (2001, 2003) and Requate (2005). The remainder of the paper is organized as follows. In the next section, we present the model. In Sect. 3, we study the optimal behavior of the firm. In Sect. 4, we find the optimal standard and inspection probability when the fine depends both on the degree of non-compliance and the investment effort. In Sect. 5, we characterize the social desirability of such a fine structure. We conclude in Sect. 6. All the proofs are in the Appendix.",19
44.0,2.0,Journal of Regulatory Economics,22 February 2013,https://link.springer.com/article/10.1007/s11149-013-9214-y,Optimal regulation of lumpy investments,October 2013,Peter Broer,Gijsbert Zwart,,Male,Male,Unknown,Male,"Current regulation of natural monopolies in network industries emphasizes price cap schemes and the efficiency gains they bring. But whether such schemes will also succeed in securing the large new investments that network sectors face has been called into question (see Vogelsang 2012, for a discussion). In energy transmission, the regulated monopolists that own the transmission grids will need to make large new investments in their infrastructure to allow new renewable energy sources to be connected to the grid.Footnote 1 Similarly, local regulated electricity distribution grids are expected to make significant investments in their grid capacity, or in smarter grids, if electric vehicles become more wide-spread, or as larger penetration of distributed generation—necessary to achieve lower carbon electricity generation—changes local flow patterns.Footnote 2 And likewise, incumbent fixed-line telecom networks—the regulated natural monopolies controlling the fixed-line connections to final consumers—face costly local network upgrades. Adaptation of their existing urban network architecture, to create so-called Next-generation networks, is required to support new demands on capacity for high speed Internet applications (see e.g. Cambini and Jiang 2009). Timely investment by these regulated natural monopolies will depend on the regulatory schemes these firms are exposed to. In this paper, we explore how regulation can incentivize the monopolist’s efficient timing of large, one-off, irreversible investments (“lumpy investments”) under uncertain demand growth. It is well-known that under demand uncertainty, investments are optimally delayed beyond the point where investment costs equal benefits: by investing, one also gives up a valuable real option to delay investment (McDonald and Siegel 1986) and this constitutes an additional opportunity cost. An unregulated monopolist’s private incentives to invest are typically weaker than social ones, as the firm cannot appropriate all benefits, but does incur all costs. As a result, the monopolist tends to delay investment even longer. Price regulation is an effective instrument for reducing dead-weight loss after investments have taken place. Ex ante, however, price regulation also impacts on the monopolist’s investment timing. Simple price caps can in general not fully restore both optimal investment and optimal post-investment pricing, as was shown in Dobbs (2004) and subsequent papers on regulation under uncertainty (see Guthrie 2006; Cambini and Jiang 2009, for reviews). In case of a single regulated investment, ex-post price caps only reduce surplus available to the monopolist and further undermine its incentives to invest early. The goals of reducing dead-weight loss and speeding up investment are then conflicting and cannot both be achieved with a single instrument. If the regulator also observes realized demand, it may condition its regulatory scheme on this information as well. We analyse optimal regulation in a model involving a single large investment, when the regulator can contract with the monopolist both on ex-post pricing and on the level of demand at the moment investment takes place. When there is no asymmetry of information, the solution is simply to tell the monopolist when to invest, and to set prices optimally. The optimal timing and pricing decisions are related in the relevant case when investment costs have to be recovered through ex post revenues, and we solve for the second-best combination of timing and price. Our main interest is in the situation where the monopolist has an informational advantage over the regulator. Following the seminal Baron and Myerson (1982) model, we consider the case where investment costs \(c\) are private information to the monopolist; the regulator only knows the distribution of these costs, with density \(f(c)\). Optimal regulation in this case has to respect an incentive compatibility constraint in addition to the budget constraint. This requires leaving positive information rents to all monopolist types except for the least efficient one. These rents are socially costly, since they need to be paid for by allowing higher price caps, which in turn introduce higher dead-weight losses. In order to reduce these informational rents, the regulator will optimally delay investment timing for higher-cost firms beyond the second-best timing. This will reduce the present value of mimicking a less efficient firm, and relax the incentive compatibility constraint, resulting in lower information rents and, consequently, lower pricing distortions. Finally, we show that the optimal regulation can be implemented by offering the monopolist a price cap that is decreasing in the demand level at which investment occurs. Such a scheme incentivizes more efficient firms not to delay investment, as the gains of waiting until demand is higher are more than wiped out by the decline in allowed price level. Our approach combines the real options literature on regulation under uncertainty with the mechanism design literature on optimal regulation. The former literature, which builds on Dobbs (2004) , studies how standard price caps interact with investment timing in a stochastic, real options environment. Extensions of this work are, for instance, Evans and Guthrie (2005), who look at the determination of the rate base for setting prices, Guthrie et al. (2006), focussing on stochastic costs, Moretto et al. (2008), who look at profit sharing rules instead of price caps. Evans and Guthrie (2012) consider the effects of economies of scale in Dobbs’ model, and Roques and Savva (2009) study the case of duopoly rather than monopoly. We add to this literature by making explicit the information asymmetry that drives imperfect regulation. Hence we do not have to take the type of regulation as given, but can explore what optimal regulation would be. We build on the theory of optimal regulation under a budget constraint, where the regulator cannot make transfers to the firm and the firm’s costs have to be recovered through linear prices.Footnote 3 We apply this theory to the investment-under-uncertainty problem at hand. In looking at agency conflicts within a real options setting, our work is related to contributions by Grenadier and Wang (2005), Hori and Osano (2009) and Shibata (2009) in the area of corporate finance. These papers study incentive contracts inducing firm managers to make timely investment on behalf of a firm owner. In the present paper, we consider the regulator-monopolist agency relation. One important difference with these corporate finance applications is that in our context, the cost of leaving rents to the monopolist (the agent) is the distortion resulting from prices above marginal cost. Technically, trading off these dead-weight loss distortions against inefficient timing requires solving an additional optimal control problem. In addition, we show how the optimal contract can be straightforwardly implemented in the form of an investment timing dependent price cap. The paper proceeds as follows. We first outline first-best investment under uncertainty, and then study how optimal timing changes if variable prices have to be raised above marginal costs to allow the firm to break even (the second-best benchmark). We demonstrate that a regulator cannot implement the second-best using only a price cap, in which case he has to trade off inefficient timing against ex-post dead-weight loss. In Sect. 3 we study optimal regulation under asymmetric information, and demonstrate that this involves setting a price cap that declines as the firm waits longer. Section 4 concludes.",21
44.0,2.0,Journal of Regulatory Economics,18 June 2013,https://link.springer.com/article/10.1007/s11149-013-9225-8,Inefficiency in Japanese water utility firms: a stochastic frontier approach,October 2013,Michelle Andrea Phillips,,,Female,Unknown,Unknown,Female,"Benchmarking is an important and relevant tool equipping managers and decision makers with powerful information in the form of performance-based rankings. Once performance-based rankings are established, an obvious question arises: What is behind predicted differences in efficiency between firms in an industry? What characterizes firms that perform better than others? What can governments do to increase the efficiency of firms? Efficiency in this context is defined as a firm’s capacity to maximize output given a fixed level of inputs. Specifically, a firm is considered to be efficient when it is producing the maximum amount of output given its input endowment (reflecting past investment and operating decisions). This is a very important policy issue, because the need for water in day-to-day activities must be brought into line with society’s limited resources. Can the supply of water be improved with existing resources by tackling the inefficiencies of firms rather than by increasing expenditures? If yes, the starting point is to figure out where these inefficiencies lie. This could be followed by the establishment of mechanisms to incentivize the “best practices” associated with higher efficiency levels and with policies that motivate firms to emulate efficient entities, thereby encouraging them to obtain more output for a given set of inputs. According to Horn and Saito (2011), several countries have adopted the characteristics of successful water utilities (“best practices”) to promote performance efficiency. Examples abound: the UK imposed incentive-enhancing regulations (price caps), the Netherlands merged small water utilities to form large water utilities, and France allowed for private sector participation. The findings of this paper identify major sources of inefficiency for the Japanese water utility sector. Specifically, water purification (a conditioning variable capturing lower initial water quality), subsidies, and outsourcing are associated with higher inefficiency levels, whereas customer density, average operation rate, and size are associated with less inefficiency. Given that Japan currently has a system that essentially entails self-regulation, this paper provides a quantitative study rather than a benchmarking one. A benchmarking study would focus on reasonable targets for developing regulatory incentives, but this is hard to do in Japan given their current regulatory environment. The pattern of inefficiency presented in this paper provides policy makers information on the range of water utility performance; the framework documents the need to develop a regulatory regime that implements cost-containment as an objective, using benchmarking tools. To my knowledge, this is the first paper to examine factors influencing the inefficiency of Japanese water utility firms using the one-step Stochastic Frontier Analysis (SFA) inefficiency effects model proposed by Battese and Coelli (1995). Other studies have examined Japanese water utilities using several Data Envelopment Analysis and SFA techniques. The majority of these studies are, however, only available in Japanese, had access to less data, and used older datasets. The remainder of this paper is organized as follows. Section 2 presents a brief background of Japanese water utilities and their regulatory environment. Section 3 describes stochastic frontier models. Section 4 discusses the model to be tested and presents the empirical results. Section 5 concludes and discusses policy implications.",9
44.0,2.0,Journal of Regulatory Economics,04 April 2013,https://link.springer.com/article/10.1007/s11149-013-9218-7,Medicare payment generosity and access to care,October 2013,Christopher S. Brunt,Gail A. Jensen,,Male,,Unknown,Mix,,
44.0,3.0,Journal of Regulatory Economics,04 October 2013,https://link.springer.com/article/10.1007/s11149-013-9232-9,On the performance of endogenous access pricing,December 2013,Kenneth Fjell,Debashis Pal,David E. M. Sappington,Male,Male,Male,Male,"Vertically integrated regulated enterprises often sell essential inputs to retail rivals. For instance, owners of telecommunications networks commonly sell network access to rival suppliers of retail telecommunications services. The price at which a regulated vertically integrated provider (VIP) supplies network access is often set equal to the VIP’s expected unit cost of supplying access. This pricing methodology ensures that the VIP’s expected revenue from supplying access (both to itself and to retail rivals) is equal to the VIP’s expected cost of supplying the access. Furthermore, each supplier’s total payment for access is proportional to its consumption of access under such a pricing methodology. As Klumpp and Su (2010, p. 71) observe, such a revenue neutral pricing methodology can thereby reasonably be construed as satisfying the common legal mandate that access charges be fair, reasonable, and nondiscriminatory. Because they strive to match the revenues and costs of supplying access, such revenue neutral pricing methodologies also help to ensure that the regulated enterprise has “a reasonable opportunity to recover the economic costs of long-lived, nonsalvageable investments that it [makes] to serve its customers” (Sidak and Spulber 1998, p. 177).Footnote 1
 Revenue neutral access pricing policies can be implemented in at least two distinct ways. Under what we call exogenous access pricing (EXAP), the regulator sets the access price equal to her ex ante estimate of the VIP’s average cost of supplying access. This access charge, which is set before retail competition takes place, governs all payments to the VIP by retail rivals. Under endogenous access pricing (ENAP), the regulator effectively sets an access charge that reflects the VIP’s actual, realized unit cost of supplying access rather than an estimate of this cost (Fjell et al. 2010). The regulator can readily implement such an access charge via a two stage procedure like the following. Initially, the regulator specifies a fixed, unit access price (\(w_{0}\)) that will prevail throughout the coming period (e.g., a year).Footnote 2 Retail suppliers must pay this price for each unit of access that they secure during the period. Then, a settling up process is implemented at the end of the period. Under this process, the VIP’s actual unit cost of supplying access (\(w_{1}\)) is first established. This cost is the ratio of the VIP’s realized total cost of supplying access to the number of units of access that the VIP supplied during the period. A supplier that purchased \(A_{0}\) units of access during the period is then required to make an additional payment of \(\left[ w_{1}-w_{0} \right] A_{0}\) to the VIP, so that the supplier’s total payment over the entire period for \(A_{0}\) units of access is \(w_{1}A_{0}\).Footnote 3
 The Australian Competition and Consumer Commission (ACCC) employed a settlement process of this type when setting access charges in the Australian telecommunications industry in 2003. The process adjusted payments for a key network element—unconditioned local loop service (ULLS)—to reflect the realized demand for ULLS (ACCC 2003). See Fjell et al. (2010) for further discussion of this policy and other policies that entail similar ex post settling up procedures. We find that ENAP often provides the VIP with stronger incentives to minimize its upstream production costs than does EXAP. This is the case because the VIP does not anticipate under ENAP the same strategic gain from inflating its fixed cost of production that it perceives under EXAP. To explain this difference most simply, suppose the VIP’s only production cost is its upstream fixed cost. Also suppose the only cost a rival incurs is the access charges it pays to the VIP. In this setting, a rival’s marginal cost of expanding output under EXAP is \(\widehat{w}\), the established access price. The VIP’s corresponding perceived marginal cost of increasing its retail output is \(0\). Consequently, the VIP enjoys a perceived unit retail cost advantage of \(\widehat{w}\) under EXAP. This advantage increases as a higher upstream fixed cost of production increases \(\widehat{w}\). The VIP does not perceive the same cost advantage under ENAP. The average cost of supplying access declines as the VIP expands its retail output, and so the equilibrium access price under ENAP declines, ceteris paribus. The corresponding decline in the VIP’s access revenue causes the VIP to perceive a strictly positive cost of expanding its retail output. In fact, as we demonstrate below, a VIP perceives itself to have the same unit cost of expanding retail output that its rivals perceive under ENAP. Therefore, the VIP does not increase its effective cost advantage over its rivals by increasing its upstream fixed cost of production under ENAP. Consequently, ENAP typically provides stronger incentives than does EXAP for the VIP to avoid inefficient increases in upstream fixed costs of production.Footnote 4
 Although ENAP can provide stronger incentives than EXAP to minimize upstream production costs, ENAP may induce a VIP to undertake inefficiently low levels of surplus-enhancing infrastructure investment, including investment that reduces the VIP’s unit variable cost of supplying access. This is the case because investment (and the associated increase in fixed production costs) does not deliver the same strategic advantage under ENAP that it delivers under EXAP. The reduced productive investment that can arise under ENAP can lead to a lower level of welfare than arises under EXAP.Footnote 5
 We develop and present these conclusions as follows. Section 2 describes the primary model that we analyze. Section 3 demonstrates that the VIP typically will avoid inefficient inflation of its cost of supplying access under ENAP. Section 4 identifies conditions under which the VIP will allow such inefficient cost inflation to arise under EXAP. Section 5 identifies conditions under which the smaller amount of productive investment that arises under ENAP can reduce welfare. Section 6 provides concluding observations and discusses extensions of our model. The “Appendix” outlines the proofs of all formal conclusions. Fjell et al. (2013) provide additional proof details. Before proceeding, we explain how our analysis contributes to the literature. To our knowledge, Fjell et al. (2010) is the only systematic study of ENAP to date. The authors demonstrate how ENAP can limit the strategic advantage that a VIP enjoys over its rivals under EXAP in a setting where the VIP’s cost structure is exogenous and immutable. We extend this work in part by demonstrating how ENAP can limit the incentives that can arise under EXAP to allow (endogenous) fixed production costs to rise above their minimum feasible level. Although they do not analyze ENAP explicitly, Boffa and Panzar (2012) demonstrate the merits of an institutional arrangement that delivers incentives similar to those that arise under ENAP. The authors consider a setting in which retail suppliers jointly own an upstream asset (e.g., a telecommunications network). The fraction of the asset that each retail supplier owns is equal to the supplier’s (endogenous) share of equilibrium retail output. This ownership structure provides strong incentives for all suppliers to expand their retail output, in part to reduce the upstream unit cost of production (in light of the prevailing scale economies) and thereby increase upstream profit. Like Fjell et al. (2010), Boffa and Panzar (2012) consider exogenous production technologies and assume that the upstream supplier operates at minimum cost. In contrast, we analyze the technology choices that ENAP induces. 
Klumpp and Su (2010) examine the level of demand-enhancing investment that EXAP induces.Footnote 6 The authors identify conditions under which EXAP induces a VIP to undertake more than the surplus-maximizing level of demand-increasing investment. This over-investment arises because of the strategic advantage that increased investment costs can confer upon the VIP under EXAP. We demonstrate that because the same strategic advantage does not arise under ENAP, a VIP that operates under ENAP may undertake less than the surplus-maximizing level of investment.",
44.0,3.0,Journal of Regulatory Economics,18 June 2013,https://link.springer.com/article/10.1007/s11149-013-9224-9,"Emissions trading, point-of-regulation and facility siting choices in the electric markets",December 2013,Yihsu Chen,Andrew L. Liu,,Unknown,Male,Unknown,Male,"Climate change is an unprecedented challenge faced by our society toady. Numerous resources and policies have been devoted to controlling greenhouse gas emissions (GHG) from the power sector and other energy-intensive sectors. Among many regulatory instruments, cap-and-trade (C&T) program emerges as the widely accepted and preferred approach for controlling greenhouse gas emissions (GHG) from the power sector. Although emissions trading is not a new concept, the economic impact of GHG polices is expected to be more far-reaching than the previous programs that target on other pollutants (e.g., \(\mathrm {SO}_2\) and \(\mathrm {NO}_x\)). This is in part because both base load and peak load units would incur substantial emissions costs. The pioneer European Union Emissions Trading Scheme (EU ETS), which began in 2005 and then expanded to 27 EU member countries in 2007, has produced some encouraging results (Convery and Redmond 2007). In the United States, due to limited federal leadership, a number of states have taken actions to control GHG emissions.Footnote 1 The efforts by the eastern and western states are called the Regional Greenhouse Gas Initiative (RGGI) (2008) and the Western Climate Initiative (WCI) (2008), respectively. RGGI’s policy goal is to reduce \(\mathrm {CO}_2\) emissions ten percent below the current level by 2019. The compliance schedule set forth is that the \(\mathrm {CO}_2\) emissions will be capped at the current level during 2009–2015, followed by a gradual decline to 10 percent below the current level by 2019. Fossil-fueled generating units (e.g., gas, oil and coal) with a name capacity greater than or equal to 25 MW fall under the cap. The permit price of the RGGI in the beginning of the first few years is relatively low due to over allocation of permits, slowdown of the economy or a combination of both. For example, the permits in the recent rounds of auctions were sold in the reserve price of $1.89/ton. The RGGIs benchmark December OTC (over-the-counter) contract for vintage 2010 was bid at $1.85/ton and offered at $1.89/ton, with a closing price of $1.89/ton (Point Carbon 2011).Footnote 2
 Among the WCI states,Footnote 3 California is the first state to adopt legislation limiting multiple types of GHGs.Footnote 4 On September 27 2006, the State of California passed a comprehensive bill—AB32, “The Global Warming Solutions Act”—that aims at reducing in-state GHG emissions from various sectors to 1990 levels by 2020. The initial cap for the year 2013 will be set to 162.8 MMTCO2e, the expected emission of that year. The cap will decrease by approximately 2 % in 2014, and be expanded to 394.5 MMTCO2e in 2015 to account for emissions from fuel suppliers. In the subsequent years, the cap, electric sector and fuel suppliers combined, will then decrease by 12 MMTCO2e annually, which corresponds to a gradually increasing percentage reduction each year, from 3 % in 2016 to 3.5 % in 2020 (California Air Resources Board 2008).Footnote 5 AB32 is the first climate change legislation in the U.S. that would regulate most polluting sectors in an economy. Led by the California Energy Commission (CEC) and the California Air Resources Board (CARB) in consultation with other agencies, a state-wide emission cap is expected to be implemented. This is expected to be accomplished with a suite of instruments such as a low carbon fuel standard for vehicles that would reduce GHGs of transportation fuels by at least 10 % by 2020 (California Energy Commission 2007a). Aside from the legal disputes and the political considerations, the designs of “state” or “regional” emissions trading programs have faced substantial challenges. For instance, while California’s imported electricity accounts for half of the electric sector emissions, such imports represented only 22 % of the electricity demanded in California in 2006 (California Energy Commission 2006).Footnote 6 Thus, imported electricity is significantly dirtier than in-state generation since a significant portion is generated by coal plants located in neighboring states (California Energy Commission 2007b). Precise identification of source-sink relationship and emission intensity of imported electricity poses substantial challenge to regulatory body, as power sales are mainly financial transactions, and the actual power follows with the Kirchhoff laws. Thus, it is possible that the arrangements of financial contracts can meet emission reductions even though no actual emission reduction occurs (contract shuffling) (Burtraw 2007). This issue could become even more daunting in a pool-typed power market under the California MRTU (Market Redesign and Technology Upgrade), in which market outcomes are determined by supply offers and demand bids, instead of bilateral contracts.Footnote 7
\(^{,}\)
Footnote 8 Thus, a central issue in the debate over implementation of regional GHG emissions trading program has been (1) over where along the electricity sector supply chain (i.e., fuel to generation to consumption) should limits be imposed so as to limit the possibility of shuffling contracts; this is the “point-of-regulation” issue. Three proposals are commonly on the table: source-based, load-based and first-deliverer (-seller) approaches.Footnote 9
 Source-based (SB) systems are most popular elsewhere. The conventional point-of-regula- tion in the electric sector cap-and-trade systems (e.g., under the \(\mathrm {SO}_2\) Acid Rain Program under the 1990 CCA Amendments and the USEPA \(\mathrm {NO}_x\) SIP Call) is at the generation. Load-based (LB) systems have received much attention. The basic load-based program requires load serving entities (LSEs) to track the emissions associated with the electricity they purchase from generators (or third parties), and to ensure that the sales-weighted carbon emissions rate of LSEs’ purchases does not exceed a target established by a regulator.Footnote 10
 The final of the three approaches is the first-jurisdictional-deliverer (FJD) proposal (Market Advisory Committee 2007). A first-jurisdictional-deliverer is defined as the entity that first contracts to sell electricity in California. In practice, the schedule coordinators (SCs) that contract with generators in other states to import electricity into California could be designated as the first-deliverer instead of the LSE (Bushnell 2007). More recently, the California Public Utility Commission (CPUC) released a draft report and expressed their support of this approach. Although C&T is the main instrument implemented by the California government to control greenhouse gas emissions in the electricity sector, other policies also explicitly or implicitly discourage or prohibit high-polluting energy sources from importing to the California grid. For example, Senate Bill 1368 (Emission Energy Performance Standards) explicitly prevents LSEs from entering long-term contracts for importing power that has an emission rate higher than natural gas combined cycle (California Energy Commission 2012a). California PUC also in its long-term procurement plan givens the priority to renewables partly in order to meet state RPS (California Energy Commission 2012b). However, although these regulatory features would affect investment decision and emission leakage, fully accounting for them is beyond the scope of the paper. We address some limitations of our approach in the conclusion section. In this paper, to ensure that we compare these three C&T policies of the same scope of coverage, we modify the source-based approach such that electricity imports into a regulated region from an unregulated region are subject to CO\(_2\) regulation. Similarly, electricity sales exported from a regulated region to an unregulated region are subject to regulation in the modified load-based approach. In the remaining of the paper, we will collectively refer to these three proposals as “modified” approaches or proposals (as in Chen et al. 2011). To account for the carbon emissions associated with power sales, we impose a necessary assumption that all the electric sales in the market are through bilateral contracts. This assumption allows us unambiguously identify emission intensity of each transaction. Previous work has established the equivalence among three modified proposals with respect to electricity prices, nodal sales, social welfare, emissions leakage, contract shuffling, etc., when generating asses are fixed (i.e., a short-run analysis) (Chen et al. 2011). When it comes to environmental policies in the electricity sector, the policy goal is to induce producers’ behavioral changes, either by fuel switch or by retrofitting pollution control devices in short-run, or ultimately by providing incentives that lead to timely adoption of cleaner technologies in the long-run. Therefore, examining the long-run implications is undoubtedly crucial to assess the performance of a policy. In this paper we extend the analysis to consider the effects of different emissions trading programs on the amount and the siting of future generating capacities, and how these new capacities might impact the \(\mathrm {CO}_2\) emissions, electricity prices, allowances prices, and the emission leakage etc. To make the comparison with the previous work more meaningful, we assume there is no load growth, and emission cap remains to be the same. The focus of the paper is closely related to testing the pollution haven hypothesis, which states that polluting industries would permanently migrate from locations with a strict to a lessen environmental regulation. Although the current work is motivated by the situation faced by California and RGGI, it can be generalized to other contexts when examining the designs of a regional C&T program or when the program coverage is incomplete.Footnote 11 Our results suggest that the equivalence of market outcomes under the three modified approaches—modified source-based, modified load-based and first-jurisdictional-deliverer—as shown in Chen et al. (2011) still hold with capacity expansion in a perfectly competitive market. The emission leakage could actually be lower than the short-run when expansion is not allowed, owing to producers opt for clean technologies in fear of the emission costs under cap-and-trade programs. When compared to the case without any environmental regulation, a regional \(\mathrm {CO}_2\) cap-and-trade program induces more pollution-intensive facilities to be built in the uncapped regions, where the \(\mathrm {CO}_2\)-emission regulation is less stringent or does not existed. Thus, our conclusion is consistent with some empirical evidence of the pollution haven hypothesis. The stylized model to be presented is certainly subject to a number of limitations. First, we assume electricity sales are through bilateral transactions between producers and load-serving entities. In reality, the three different regional C&T programs would not be equivalent, because there will also be pool-type markets, and the three programs provide different incentives for participating in those markets. Second, the decisions about capacity siting are also driven by factors other than the regulation we discuss here, such as permitting process, proximity to transmission lines, and availability of water resources, none of which is considered in the analysis. We also ignore the fact that new capacity might find it difficult to execute a contract vehicle to deliver or sell power. Third, the analysis does not explicitly model retirement or going-forward decisions. However, the static model we developed herein has partially accounted for the third limitation. In particular, if the level of the output of an existing facility were zero in the solution (so zero profit earned), it implies that the facility will be forced to retire if its going-forward cost is explicitly considered. We believe our central findings in this paper remain robust to this limitation. Our results might actually understate the extent of the pollution haven hypothesis because more capacity will need to be installed when existing capacity is decommissioned. The remainder of the paper is organized as follows. Section 2 reviews the relevant literature on the pollution haven hypothesis. Section 3 gives the mathematical formulation of each proposal, and highlights how it differs from short-run model in our previous work. In Sect. 4, we first present a social planner’s optimization model and show that the optimization would produce the same market equilibrium outcomes as the models introduced in the Sect. 3. In Sect. 5, we present numeric examples of the three proposals that are based on Chen et al. (2011) and are elaborated to account for firms’ investment decisions in new capacity. Detailed discussion of the numerical results, with focuses on economic and emissions outcomes, are also provided in the section. Conclusions and policy implications are addressed in Sect. 6. (The proofs are included in the Appendix.)",5
44.0,3.0,Journal of Regulatory Economics,26 July 2013,https://link.springer.com/article/10.1007/s11149-013-9227-6,Investment coordination in network industries: the case of electricity grid and electricity generation,December 2013,Felix Höffler,Achim Wambach,,Male,Male,Unknown,Male,"In many network industries like rail, gas or electricity, liberalization has led to an “unbundling” of the network as the monopolistic bottleneck from the potentially competitive parts. The rationale for separating the network is to avoid that a vertically integrated firm can use the network access to discriminate against potential downstream competitors. This vertical separation has introduced a new problem, namely, how to coordinate the network investment with investments in the competitive parts. This coordination problem is particularly pronounced in the electricity industry. In an early review article on electricity market liberalization, Joskow noted: The key technical challenge is to expand decentralized competition in the supply of generation in a way that preserves the operating and investment efficiencies that are associated with vertical ...integration...  (Joskow 1997, p. 127) Investment coordination becomes increasingly relevant in countries that restructure their industries towards a larger share of renewable electricity generation. For instance, in the UK, there are technically productive off-shore wind opportunities available in Scotland; however, since the load center is in the South, this requires large North-South network extensions. These could be reduced if less productive locations in the South would be used. In Germany, the same regional pattern holds for renewables. At the same time, new fossil capacities are required in the South of Germany to compensate for the accelerated decommissioning of nuclear power. However, at least for hard coal fired power plants costs are lower in the North than in the South (due to lower transport cost).Footnote 1 Again, private generation investors would prefer Northern locations, which would require an extension of the North-South network connections. While in liberalized electricity industries investments in generation capacity are usually decided by private firms, large network extensions are based on regulatory decisions. In Europe, investors typically apply for so-called investment budgets. These investment budgets are subject to regulatory approval, and, if approved, are financed by increasing the (regulated) network charges.Footnote 2 Although private firms decide on investments in generation, the fear of insufficient investment incentives (due to a “missing money problem”) has led many countries to discuss the introduction of capacity markets, i.e., a mechanism where the regulator grants payments to private firms in order to stimulate investments into generation capacity. Such a mechanism might well affect not only the size but also the location of generation investments. We are therefore interested in the question how to coordinate network extensions with generation investments, without and with a capacity market. In the absence of a capacity market, a welfare maximizing regulator who can decide only on network extensions typically faces two challenges. First, a lack of regulatory commitment. The regulator might want to long-term commit to undertake certain extensions (or she might want to commit not to extend certain network connections), but she might be unable to do so. Second, the regulator might face an asymmetric information problem, e.g., she might not know the cost of generators. If a capacity market is installed, commitment might less be a problem, since the regulator simultaneously can decide on the network extension and the capacity market design. However, asymmetric information and the cost of public funds (in particular for payments to private firms for investing in capacity) will be important. To analyze these issues we use a simple network model with two nodes, North and South. Demand is stochastic at each node, but on average lower in the North than in the South. Without additional investment, there is the danger of undersupply in the South, which can be mitigated linking the two nodes, or it can be avoided by installing one additional unit of generation in the South, or by installing one additional unit in the North and linking the two nodes (it will never happen that more than one unit is added). Private firms decide on generation capacity investments, the government decides on building the link or not. For the sequence of moves, we interpret the outcome in which the regulator moves second (first) as the “no commitment” (“commitment”) outcome. Without a capacity market, even with a fully informed regulator, two types of inefficiencies can occur with “no commitment”. First, an “investment forcing” inefficiency, where private investors invest in the North, to which the regulator’s best response is to hook up the North with the South, since otherwise the South faces the danger of a shortage. Investing in generation and network may be inefficient but preferred by the private firms if the investment in the North is cheap, while the link is expensive. The reason is that the private investor does not have to bear the network costs caused by his locational choice. Second, there might be a network “investment preempting” inefficiency. Investment in the South might be very profitable, but building the link only might be welfare superior (e.g., if the link is very inexpensive). The regulator would like to commit to building the link, but once the private investor invested in the South, adding a link is useless, since the additional generation capacity will not be needed in the North. Both inefficiencies vanish if the regulator moves first, i.e., commitment solves these sorts of opportunistic behavior problems. If the costs of the firms are private information, this no longer holds. Moving second can become preferable to the regulator, in particular, if the asymmetric information problem is very severe. The reason is that from the informed firms’ investment decisions, the regulator can learn something about the state of the world. Commitment would require committing to disregard this additional information. This reflects a trade-off between the aim to avoid opportunistic behavior (which calls for moving first) and the aim to elicit information (which calls for moving second).Footnote 3
 If the regulator can also directly affect the private firms’ investment decisions, the regulator can use a specific form of a capacity market to implement the first best if there are no shadow costs of public funds. She can do so by using a standard auction with a reserve price and a “handicap” (or “malus”). The reserve price determines the amount of capacity to be built, while the handicap steers the generation towards the right location. The handicap depends on where the investor wants to build (North or South), and is added to the respective bids. It is tailored such that it internalizes the externalities the private bidders inflict on the regulator, thereby solving the investment forcing inefficiency. The right choice of the reserve price solves the investment preempting inefficiency. If there are shadow costs of public funds, the first best can no longer be implemented. We find that there will be a distortion towards less investment into generation capacity. If there is investment, the decision where to invest is distorted, too. No simple capacity market exists to implement the second best outcome. That a lack of regulatory commitment can severely affect infrastructure industries is widely acknowledged in the literature. Levy and Spiller (1994) look at the telecommunications industry and argue that the threat of ex post expropriation of private investors might make public ownership of telecommunications firms superior to private ownership. Various papers investigate the topic further for various utility industries (Troesken 1997 for gas, Troesken 2003 and Masten 2011 for water). Our paper complements this strand of literature by analyzing a hybrid industry structure between the two extremes of public and private ownership of an integrated firm: we look at an “unbundled” industry, and we focus on the problems arising from the necessary coordination of the public and the private sector. In addition, we point to possible limitations of long-term commitment in the case asymmetric information. Albeit its importance for regulatory practice, and although the underlying problem is essentially a (hold-up) problem of coordinating complementary investments, there is little literature that directly tackles our research question. The literature on network investment and the (non-) desirability of merchant transmission investment (Chao and Peck 1996; Bushnell and Stoft 1996; Joskow and Tirole 2005) usually takes the generation capacity as given.Footnote 4 The literature on the (non-) desirability of generation capacity markets (Hogan 2005; Cramton and Stoft 2005, 2006; Joskow 2008) usually takes the transmission network as given.Footnote 5
 A few papers take up the issue of coordination of generation and network investments and discuss it in a framework related to ours. Sauma and Oren (2006) investigate a three stage game where first a benevolent regulator decides on network extensions, then private firms decide on generation investments, and in the last stage there is oligopolistic competition. They compare a “pro-active” regulator to a “passive” regulator, where the former optimizes by anticipating the private firms’ reactions to the network decisions, while the latter takes the private investment decisions as given. However, there is no asymmetric information in the model by Sauma and Oren (2006). Hence, their “passive” regulator always does worse in welfare terms by construction, while in our model we show that lacking commitment can be beneficial if the asymmetry of information is large. Rious et al. (2011) take up the idea of a passive and a pro-active regulator. They focus on the issue of timing, pointing out that usually network extension need more time than power plant investments. They therefore ask whether the network-investor should move first, i.e., build the network before the power plant is finished. Being “pro-active” in this sense might be suboptimal if it is not certain that an announced power plant is actually realized. Although this model introduces some form of uncertainty on the side of the regulator, in their model generators do not behave strategically, while one of the research interests in our approach is to investigate opportunistic behavior of the private investors. In Sauma and Oren (2009) the authors change the focus and investigate the investment incentives that private firms, which are also active as generators, might have to invest in network extensions. In this article, they also analyze the effect on investment incentives that are created if generators are equipped with financial transmission rights in case they invest into transmission, or not. Here the main difference to our approach is that we restrict attention to network decisions that are taken by the regulator, while expanding the analysis by also looking at generation investments. Except for a brief discussion of vertical integration and merchant transmission investors in Sect. 3.1, we will restrict attention to the case of a benevolent regulator. Additional problems, which we do not address in this paper, arise from the regulation of a private network firm, or from non-benevolent regulators. Various papers derive regulatory contracts to provide efficient investment incentives for network firms (e.g., Leautier 2000 or Hogan et al. 2010) or deal explicitly with the problem of regulatory capture (Höffler and Kranz 2010). None of these integrate into their analysis the issue of generation investments. To summarize, our contribution is to (i) combine the analysis of generation and network investment, to (ii) do so in a framework where the regulator can decide on the network expansion, with or without the ability to provide incentives for investments into generation, and by (iii) explicitly taking into account asymmetric information problems and commitment problems on the side of the regulator. The remainder of the paper is organized as follows. Section 2 introduces the model. Section 3 analyzes the case where only the network is regulated. Section 4 deals with the option to use a capacity market. Section 5 concludes.",10
44.0,3.0,Journal of Regulatory Economics,07 June 2013,https://link.springer.com/article/10.1007/s11149-013-9222-y,An experiment on emissions trading: the effect of different allocation mechanisms,December 2013,Veronika Grimm,Lyuba Ilieva,,Female,Female,Unknown,Female,"As part of their strategy to curb greenhouse gas emissions, governments are increasingly adopting various forms of emissions trading. The European Union Greenhouse Gas Emission Trading System (EU ETS), the Regional Greenhouse Gas Initiative (RGGI) in the U.S., and the carbon pollution reduction schemes (CPRS) in Australia are just a few examples of its large-scale implementation. The reason behind emissions trading’s increasing popularity is the prevalent belief among economists that it is a highly efficient mechanism to control greenhouse gases.Footnote 1
 The efficiency of a particular emissions trading scheme, however, depends on the details of its market design. One of the most controversial issues is the initial allocation mechanism for allowances. While in theory tradable emission permits allow the regulated industry to efficiently reduce its emissions regardless of the initial allocation (Montgomery 1972), in practice different allocation rules may lead to different outcomes. Two allocation mechanisms are usually discussed—free allocation (often referred to as “grandfathering”) and auctioning. Free allocation is typically preferred by the industry, which makes it more politically feasible. Auctioning is favored by the majority of economists due to its transparency and alleged efficiency (Cramton and Kerr 2002; Hepburn et al. 2006; Ockenfels 2009; Holt et al. 2007), and is increasingly being used in the context of emissions trading,Footnote 2 firing the discussion about a proper auction mechanism. Although in recent years different auction formats have been used to allocate permits in RGGI and EU ETS,Footnote 3 it is hardly feasible to directly compare the success of the different auction formats and of grandfathering using field data. Auctions typically cover only a part of the allocated permits and coexist with grandfathering. Still, most previous and current recommendations for the auction design are based on theoretical argumentation without any systematic empirical evidence from the field or from controlled experiments.Footnote 4 We contribute to filling this gap by running an experiment which investigates market performance under two commonly recommended auction designs, frequent and infrequent sealed-bid, uniform-price auctions (Neuhoff et al. 2008; Lopomo et al. 2011),Footnote 5 and compare them with two different free allocation (or grandfathering) procedures. In the two grandfathering treatments, we implement (i) the initial allocation that is endogenously reached in the “infrequent auctioning” treatment and (ii) an allocation of permits proportional to the firms’ expected needs. In a standard theoretical analysis, we show that our treatment variations should not affect the final allocative efficiency, permit prices, abatement behavior, banking decisions, or compliance. Our experimental design allows us to address several highly relevant questions. First, we investigate the effects of more vs. less frequent auctioning on the efficiency of the final permit allocation after trade at the secondary markets. Second, we assess whether (and how) the initial allocation procedure per se (auctioning vs. grandfathering) affects the efficiency of the final allocation.Footnote 6 Third, we analyze whether a distribution of permits that optimally reflects (ex ante) expected needs leads to more efficient market outcomes. We find that efficiency of the final permit allocation differs across treatments, but not to a large extent. None of our treatments achieves a (nearly) efficient permit allocation, as theory would predict. Efficiency is highest with infrequent auctioning (where 73 % of the permits are allocated in a cost-efficient way) and lowest with frequent auctioning (61 %). We attribute this to strong (initial) overbidding in the small and frequent auctions which persistently leads to inefficiently high permit prices early in the experiment. Interestingly, we find no effect of the allocation procedure per se on efficiency of the final permit allocation. Comparing the (infrequent) auction treatment with the grandfathering treatment where we implemented exactly the same initial allocation, we observe no differences in permit prices and abatement behavior, though a little less banking under grandfathering. Surprisingly, in the treatment where the initial allocation of the permits reflected the (ex ante) expected needs, through secondary market trading the allocative efficiency decreases by 18 % points to 67 %. Our results illustrate that secondary market trading can even decrease allocative efficiency substantially and thus, a nearly efficient initial allocation of permits does not necessarily guarantee high efficiency ex post. A closer look at the permit prices and the trading patterns reveals some systematic differences between the auction and the grandfathering treatments that are present early in the experiment and diminish over time. In particular, under grandfathering participants initially use significantly more permits (and abate less) than under auctioning. In the auction treatments permit prices are initially too high and approach the theoretically predicted level only later in the experiment. This suggests that under auctioning the perceived value of the permits is initially too high, while the cost of using permits seems less salient if permits are allocated for free (i.e. under grandfathering). Moreover, we observe a tendency to over-bank permits in all treatments (but less so under grandfathering), which is in line with the literature and may point to risk averse agents. An analysis of individual behavior reveals that participants base their abatement decisions on the permit prices, as theoretically predicted, but also on individual emission levels as well as their current stock of permits, which is inconsistent with theoretical predictions. In sum, we find some very intuitive behavioral patterns which move behavior away from the equilibrium prediction. Those patterns partly lead to initial differences between auctioning and grandfathering, which vanish over time, as participants become more experienced. Let us briefly review the related literature. The experimental and theoretical literature provides abundant evidence for the effect of different aspects of the market design on the efficiency of emission permit markets.Footnote 7 However, we are aware of only few experiments that study the effect of different initial allocation rules on the performance of a subsequent trading institution. Previous work that also analyzes a secondary market includes experimental comparisons of auctioning and grandfathering by Benz and Ehrhart (2007) and Goeree et al. (2010), as well as a comparison of different types of auctions by Holt et al. (2007) and Burtraw et al. (2009). Results in Benz and Ehrhart (2007) and Goeree et al. (2010) suggest that, at least for relatively stringent emission caps, markets with auctioned permits tend to outperform markets with grandfathered permits. However, in both experiments the initial allocation before trade is endogenous in the auction treatments and (arbitrarily) exogenous in the grandfathering treatments. Hence, the observed differences in the final permit allocation can be due to either the initial allocationFootnote 8 or the allocation procedure. Our experimental approach allows us to disentangle those two factors by using a design that excludes different initial allocations as an explanation.Footnote 9 In an experimental comparison of different auction formats, Holt et al. (2007) find that, in terms of allocative efficiency, sealed-bid and ascending clock auctions perform equally well, while when it comes to preventing collusion, Burtraw et al. (2009) report that sealed bid (uniform-price and discriminatory) auctions outperform ascending clock auctions. For the RGGI, Holt et al. (2007) recommend frequent auctioning for reasons of planing security and liquidity constraints of generators, but do not provide experimental results that support this conjecture. We fill this gap and show that frequent auctioning does not necessarily increase allocative efficiency. Our work differs from the studies above with respect to the design of one of the grandfathering treatments,Footnote 10 the use of increasing (instead of constant) marginal abatement cost functions, and the trading institution at the secondary markets. In an attempt to closely mirror a real trading institution, we use the continuous double auction, which is known for its high efficiency in the lab.Footnote 11 Moreover, while previous literature was mainly concerned with the effect of different allocation mechanisms on permit (and downstream) prices, our main focus is on efficiency of the permit allocation. In this respect we find, similarly to Goeree et al. (2010), that neither the use of auctions as initial allocation mechanism nor the secondary markets manage to deliver (nearly) efficient permit allocations.Footnote 12
 The rest of the paper is structured as follows: in Sect. 2 we give detailed description of our experimental design and procedures. In Sect. 3 we present some theoretical background and derive our hypotheses. The experimental results are reported and discussed in Sect. 4; Sect. 5 concludes.",20
44.0,3.0,Journal of Regulatory Economics,07 June 2013,https://link.springer.com/article/10.1007/s11149-013-9223-x,The warnings puzzle: an upstream explanation,December 2013,Timo Goeschl,Johannes Jarke,,Male,Male,Unknown,Male,"The frequent use of warnings by regulators is an empirical fact in the enforcement of laws and regulations. Research on the activities performed by individual inspectors or by enforcement agencies on a day-to-day basis consistently ranks issuing verbal or written warnings to wrong-doers near the top (see the survey of 160 studies in Kagan 1994). The phenomenon has been documented across widely different regulatory areas, whether in the construction sector (May and Burby 1998), agriculture (May and Winter 2000), mining (Braithwaite 1985), or workplace safety (Gunningham and Johnstone 1999). Similarly, within the same regulatory area, geography does not seem to matter: Environmental regulators embrace warnings regardless of whether they are enforcing pollution control laws in the United States (Downing and Kimball 1982; Russell et al. 1986; Harrington 1988), in Canada (Eckert 2004), in Norway (Nyborg and Telle 2004, 2006), or in Belgium (Rousseau 2009). Despite, or rather because of, their popularity, warnings have presented something of a puzzle to economists. The reason is that it is not at all obvious why it may be in the interest of an enforcer with a compliance objective to respond to a breach of law or regulations with a warning that imposes no cost on the wrong-doer. Imposing a penalty or refraining from pursuit altogether are both responses to wrong-doing that are more obviously in line with rational regulator behavior. As a result, the standard economic model of public enforcement has remained largely silent on the issue of warnings.Footnote 1
 A number of more recent contributions have addressed the warnings puzzle to establish whether an economic rationale for warnings can exist. The rationale demonstrated by these authors arises out of the typical informational imperfections of the regulatory situation and justifies warnings as a device for transmitting information between regulator and regulatee. For example, Eckert (2004) demonstrates theoretically and empirically that warnings may serve as a notification to a violator that he is now “black-listed” and monitored more closely. Since the violator faces a higher expected penalty from that moment on, the incentive to comply in the following periods is increased. Using a similar two-period model of emission standard enforcement, Rousseau (2009) shows that if measurement errors are present (or emissions are stochastic), warnings can reduce the welfare loss of falsely accused firms. Nyborg and Telle (2004) develop a rationale for a budget-constrained regulator to use warnings in order to maintain regulatory control in a setting in which some firms violate accidentally rather than deliberately. Finally, Galbiati (2006) develops warnings as a credible signal that the enforcement agency can use to convey its monitoring intensity to a heterogeneous set of wrong-doers. The common element in this emerging economic theory of warnings is its natural focus on the regulator–regulatee relationship. In this brief paper, we provide a different, complementary explanation for the use of warnings that draws on the empirical public choice literature. This explanation arises not out of informational imperfections in the regulator–regulatee relationship, but out of informational imperfections in the relationship between the regulator and the institution setting the regulator’s budget. In modern regulatory systems, control of regulation agencies by higher-level authorities through a combination of a broad mandate and a hard budget ceiling has emerged as the compromise of choice between the two polar cases of binding instructions and close oversight to align the interests of the higher-level authority (i.e. the principal) and the agency on the one hand and complete independence on the other (Weingast and Moran 1983; Weingast 1984; Shughart et al. 1986; McCubbings et al. 1990; Yandle 1988; Banks 1989, 1991; Macey 1992; Epstein and O’Halloran 1994, 1999; Makris 2006). Indeed, “in the twentieth century, legislative and executive authority over an agency’s budget—the proverbial ‘power of the purse’—has emerged as one of the most forceful and frequently exercised tools of political control” (Carpenter 1996, p. 283). In practice, this compromise means that public enforcement institutions wield some degree of discretion in deciding whether and how to pursue a violation. At the same time, they are exclusively funded by their respective governments and constrained by the limits of budget authority granted in a given fiscal period. What links these two dimensions is the regular review process where the budget is renegotiated on the basis of the availability of public funds on the one hand and agency performance with respect to its mandate on the other.Footnote 2 Many institutions could serve as an example, but a typical case would be the enforcement program of the United States Environmental Protection Agency (USEPA), whose mandate is to “address violations of environmental laws, to ensure that violators come into compliance with Federal laws and regulations and reduce pollution” (United States Environmental Protection Agency 2008, p. 29). Like other agencies, the program enjoys wide discretion of how it accomplishes its mandate, but has to do so under a fixed budget. These agency budgets represent negotiated outcomes between Congress and the agencies over funding and performance and are the observable resolution of the information asymmetries besetting the relationship between the regulator and its political principal. Against the background of this institutional response to information asymmetries in regulation, we argue in this paper that warnings may also be rationalized as a specific signaling device. In contrast to the previous literature, the signal in our paper is targeted upwards to the budget-setting authority, and not downwards to the regulatees. The signal is productive since it remedies an information problem about the productivity of the enforcement agency (i.e. its ’type’). The information problem arises because reductions in the number of documented prosecutions per dollar invested in the enforcement agency can occur for two entirely different reasons. One is that a highly productive enforcement agency successfully deters potential violations: Decreasing prosecutions are therefore evidence of highly effective enforcement agency. The other possible reason is that a less productive agency fails to pursue many of the violations. The budget-setting authority’s observation of an ’idle enforcer’ therefore has ambiguous information value. A typical example is Environment Canada’s enforcement arm, which in 2007 counted just under 200 on-the-ground officers across the country that jointly “produced” six prosecutions for severe violations in FY 2006/07. The Budget 2007 provided additional $22 million “to hire more than 100 officers to bolster enforcement capacity” (Environment Canada 2009, p. 23), bringing the number to more than 320. The increase in enforcement capacity by more than 50 % was associated with a change in prosecutions from six to five the first year and then to seven prosecutions in 2008/2009. These small numbers may be interpreted by outsiders, including the sponsor, either as a case in which there are in fact few serious violations, or as a case in which most violations are not pursued. We show that when enforcement agency productivity is not directly observable, issuing warnings enables a productive agency to prevent a kind of “winner’s curse”, namely that a successful reduction in violations is interpreted by the budget-setting authority as a sign that the marginal gains from enforcement are decreasing and that the budget should therefore be reduced. Using warnings (and similar instruments) for minor violations that would otherwise not be pursued, the agency is able to produce verifiable evidence at low cost that allows the principal to discriminate between the two cases. Warnings, being costly enough to issue, but not too costly to prevent their use, are a plausible candidate for such a signaling device. This device is productive with respect to the agency’s mandate since the maintenance of budgets allows the agency to maintain credibility in the enforcement game vis-a-vis the regulatees. As a corollary result, our model provides additional theoretical support for an existing empirical literature that has examined the link between business cycles and regulatory enforcement activity, finding countercyclical patterns of activity (Amacher et al. 1985; Shughart and Tollison 1985; Ghosal and Gallo 2001). This finding is typically explained on the grounds of interest-group theory (Stigler 1971; Peltzman 1976). Our complementary explanation can lead to empirically equivalent phenomena, but rests on a slightly different mechanism that links the business cycle, the opportunity cost of enforcement budgets, and enforcement activity. Following the literature, we demonstrate our results on the basis of a two-period model in which each period contains a full cycle of budget appropriation and regulatory enforcement. We pick environmental regulation as an illustrative setting, but the model is applicable to similar contexts. To make the insights stark, we assume that warnings themselves, while requiring costly effort, are entirely unproductive in the downstream interaction between enforcer and the regulated agent. This assumption shuts down the causal channels that the literature has shown to operate between regulator and regulatee (Eckert 2004; Rousseau 2009; Nyborg and Telle 2004; Galbiati 2006). The insight is then that, despite being unproductive downstream, warnings may still be part of an equilibrium strategy profile in the upstream interaction between the budget-setting authority and the enforcement agency. The popularity of warnings that is observed in practice can therefore not only be explained as part of the enforcement strategy, but may also be an artifact of the regulatory regime’s organizational structure. The remainder of the paper is organized as follows. In Sect. 2 we set out the model which is subsequently analyzed in Sect. 3. In Sect. 4, we illustrate the theoretical insights with the empirical example of the USEPA enforcement program. Section 5 concludes.",1
44.0,3.0,Journal of Regulatory Economics,04 October 2013,https://link.springer.com/article/10.1007/s11149-013-9234-7,How predictable are environmental compliance inspections?,December 2013,Sarah L. Stafford,,,Female,Unknown,Unknown,Female,"In the U.S. many major environmental regulations are enforced using a deterrence-framework: that is, regulations are enforced through unannounced compliance inspections and fines for any violations discovered during the course of those inspections. According to Gray and Shimshack (2011), most policy-makers and scholars generally believe that effective pollution regulations require an enforcement regime that includes recurrent inspections and sanctions, and survey evidence suggests that a traditional regulatory structure with rigorous monitoring and enforcement is a primary motivator of facilities’ environmental compliance decisions. Numerous empirical studies covering a wide range of environmental regulations and regulated populations provide evidence that deterrence-based enforcement does increase compliance rates. For example, Gray and Deily (1996) and Gray and Shadbegian (2005) examine air pollution compliance for steel mills and pulp and paper mills in the U.S., respectively, and find that both inspections and enforcement actions have a statistically significant positive impact on compliance. Looking at compliance with U.S. water regulations, Earnhart (2004) and Glicksman and Earnhart (2007) similarly find that inspections and sanctions deter violations at water treatment plants and chemical facilities, respectively. Stafford (2002) shows that compliance inspections and penalties for violations have a significant deterrent effect on violations at facilities subject to hazardous waste regulations.Footnote 1
 Most theoretical models of deterrence-based enforcement assume that compliance inspections are probabilistic—that is, a regulated entity knows the likelihood that compliance inspection may occur, but not whether one is or is not going to occur with certainty during any particular period. If compliance inspections are completely predictable, regulated entities would only comply when an inspection was going to occur. By making inspections probabilistic, regulators can deter more violations using fewer resources because as long as the expected cost of violation—that is, the probability of an inspection times the sanction for a violation— exceeds the cost of compliance, facilities will comply. In practice, however, it is not clear whether compliance inspections really are unpredictable. For example, it is reasonable to think that the probability that a facility is inspected may depend on how long it has been since the last inspection, particularly if a regulatory agency’s charge is to inspect each facility at least once every two years.Footnote 2 If the timing of a compliance inspection depends on the length of time since the last inspection, facilities may be able to roughly predict when a compliance inspection will occur and adjust their compliance decisions accordingly, decreasing the deterrent effect of the inspection. The primary objective of this paper is to examine the timing of environmental compliance inspections and determine the extent to which such inspections can be predicted. More specifically, this paper focuses on modeling the timing of compliance inspections conducted at hazardous waste generators using data on individual inspections over an 11 year time period. If compliance inspections have become predictable, policymakers looking to increase environmental compliance may find it effective to redesign their monitoring strategy. A secondary objective of this paper is to determine the extent to which using detailed information on individual inspections can improve empirical predictions of the timing of inspections. Many empirical analyses of enforcement and compliance need to estimate the likelihood of an inspection or the number of inspections for a given time period. For the most part, such studies estimate inspections for a particular time period based on aggregated data (e.g., monthly or annual inspections). However, it may be the case that using detailed information on individual inspections can improve empirical predictions of the likelihood and number of inspections. The remainder of the paper is organized as follows: Sect. 2 provides a theoretical framework for the empirical analysis and discusses the related literature. Section 3 discusses the institutional setting for the analysis, namely the inspection regime for EPA’s hazardous waste program. Section 4 presents the econometric methodology while Sect. 5 describes the data used in the analysis. Section 6 presents the results of the duration models and Sect. 7 compares the duration results to other more common models of inspections. Finally, Sect. 8 concludes.",2
45.0,1.0,Journal of Regulatory Economics,29 August 2013,https://link.springer.com/article/10.1007/s11149-013-9229-4,The determinants of federal and state enforcement of workplace safety regulations: OSHA inspections 1990–2010,February 2014,Juergen Jung,Michael D. Makowsky,,Unknown,Male,Unknown,Male,"Research in market regulation, and the Occupational Safety and Health Agency (OSHA) in particular, tends to focus on the merits of the laws that regulators enforce (Arrow et al. 1996; Viscusi 1996; Gawande and Bohara 2005; Viscusi et al. 2005) and the empirically measurable outcomes that are associated with the regulatory activity (Gray and Jones 1991a, b; Gray and Scholz 1993; Scholz and Gray 1997; Weil 1996; Helland 1998; Gray and Mendeloff 2005; Shimshack and Ward 2005; Bradbury 2006; Hahn and Tetlock 2008; Gray and Shimshack 2011). Less understood is the importance of who is enforcing those laws and how they are enforced (Scholz 1986; Atlas 2007; Kim 2008).Footnote 1 While the manner of legally prescribed enforcement—rules versus discretion—is a well-researched debate, how the two interact and affect the outcomes of enforcement mechanisms often remains murky (Reiss 1984; Makowsky and Stratmann 2009). Using a dataset of over 1.6 million inspections by the OSHA from 1990 through 2010, we are able to explore the determinants of inspection outcomes. The especially high weighting of OSHA laws towards agency (and agent) discretion (Sunstein 2008) makes OSHA inspections an excellent opportunity to explore the determinants of discretionary regulatory enforcement. Further, OSHA is one of several regulatory bodies that embody a doctrine of “partial preemption” (Scicchitano and Hedge 1993; Bradbury 2006; Atlas 2007). Under this doctrine, once the federal regulatory body approves a state program, responsibility for enforcement is ceded to the state, leaving the federal agency to oversee the state agency. The result is a split OSHA enforcement regime with offices of the federal agency conducting inspections in 25 states, and state agencies conducting inspections in the remaining 25 (in four out of these 25 states, the state agency plans cover public sector employment only). This split offers the opportunity to observe how decentralized regulation affects agent and agency discretion.Footnote 2 The geographic variety and range over 21 years allows investigation into political determinants of inspection outcomes, with particular attention given to the decision to issue “warnings” by inspectors, the size of the fines levied, and the ability of firms to negotiate reductions in fines levied upon them. There is an abundant literature that focuses on the outcomes of regulations. In particular, earlier OSHA data has been used to show that inspections increase rates of compliance (Gray and Jones 1991a), that imposing penalties reduces workplace accidents in the following years (Gray and Scholz 1993), and that state-administered OSHA programs are associated with fewer workplace fatalities than states regulated at the federal level (Bradbury 2006). Our paper contributes to this literature, focusing on the determinants of enforcement outcomes and agent discretion. Similar to Bradbury, we look at differences between federal versus state controlled inspections, but differ in that we focus on the determinants of individual inspection outcomes, in terms of violations, penalties issued, and negotiated fine reductions rather than its subsequent effect on aggregate workplace health and safety. Political, economic, and institutional conditions are relevant environmental factors in regulatory enforcement (Scholz 1991; Kim 2008). Scholz and Wei (1986) investigate the influence of political interest groups and economic variables like unemployment on the actions of OSHA. While Scholz and Wei focus on aggregate enforcement measures, our unit of observation is the individual inspection. Focusing on individual inspections allows us to both control for firm characteristics and to investigate their interaction with the political and institutional environment. Discretion enters into the enforcement process at multiple steps. Each of these discretionary moments presents its own unique opportunity for incentives beyond worker and public safety to enter into the inspecting agent’s decision making. We track each step of the assessment process, including the finding of violations, the decision to issue a fine, the amount of the fine assessed, and post-inspection negotiation of reductions of assessed fines. We find patterns of discretionary enforcement that are distinctly different in state and federally conducted inspections. While state agency inspections have a similar probability of finding a firm in violation than federal inspections, the fines they do issue are, ceteris paribus, smaller than the fines issued by federal inspectors. We find that the executive branch exerts greater influence than congress over inspection outcomes in both federal and state agencies. This influence, however, differs across state and federally conducted inspections. Fines issued are smaller under Republican presidencies. This effect is observed for both, state and federal inspections. Union shops are more likely to pass their inspection, but when they are found in violation they are more likely to receive a fine. Firms employing unionized workers are issued larger initial fines by inspectors. Larger companies on average receive larger fines. Quantile regression analysis reveals that political conditions have their greatest impact on the largest negotiated reductions in fines.",9
45.0,1.0,Journal of Regulatory Economics,29 August 2013,https://link.springer.com/article/10.1007/s11149-013-9228-5,Regulated price reforms and unregulated substitutes: the case of residential piped gas in Argentina,February 2014,Ariel A. Casarin,,,Male,Unknown,Unknown,Male,"Regulation has economic and political dimensions. In markets with large fixed costs, typical of network utilities, regulators tend to use price schedules to accommodate distributional goals. Two-part pricing facilitates regulators reducing some divergence between efficiency and equity goals. The conflict between cost recovery and first best then disappears if the unit price is set equal to marginal cost (Coase 1946). In practice, however, two-part tariffs usually depart from this theoretical postulate and typically take the form of low fixed fees and higher than marginal costs’ unit prices (Davis and Muehlegger 2010). Regulators justify setting low fixed fees and high or increasing marginal prices on distributional grounds considering that, absent accompanying subsidies, increasing fixed fees and lowering unit prices would shift the burden of fixed costs from high-usage to low-usage customers (Komives et al. 2005). Consumer protection groups also raise objections against high fixed fees on the notion that they substantially impact the energy bills of low-income users. We argue that the regulatory approach of setting low fixed fees and high unit prices, which is frequently aimed at achieving distributional goals, is in some cases at conflict with the usual regulatory goal of securing further access to the regulated good. This conflict confronts the interest of existing consumers against those that could potentially connect to the regulated good network but do not because of regulated price levels. High or increasing marginal prices are thus commonly blamed for low connection rates. We observe this friction is idiosyncratic of developing countries that privatized utilities in industries with high fixed costs and little technological advance such as water, electricity and natural gas. The regulatory practice in most developing countries was inspired very closely on that of the US and UK, where urban connection rates were a minor regulatory challenge. Such an outright adoption of outside regulatory frameworks potentially creates a mismatch between imported regulation and local regulatory needs (Estache and Wren-Lewis 2009). In fact, much of the high and increasing popular discontent with privatizations in Latin America is associated with little improvement in access to regulated network services (Hall et al. 2005; Checchi et al. 2009). The residential gas market of Argentina exemplifies this regulatory conflict. This market, which was privatized in 1992, presents the particularity that all (urban) homes had historically used gas, though a proportion of households covered by the piped gas network chooses not to connect to the grid but to use bottled gas instead.Footnote 1 Despite the fact that piped gas has advantages over bottled gas, household’s choice of bottled gas changed very little a decade following the reform. We speculate that the rebalancing of regulated piped gas prices against unit prices that occurred with the regulatory reform changed piped and bottled gas’ relative unit prices and consequently reduced households’ utility to connecting to the piped gas grid. As a result, the direction of this tariff rebalancing, frequently claimed on distributional goals, is at conflict with the formal regulatory mandate of securing further diffusion of regulated piped gas. We examine this regulatory trade-off when consumers of a regulated service can opt for an unregulated substitute. In particular, we study the impact of price changes on households’ connection decisions to the piped gas grid and investigate the distributional effect on piped gas users of counterfactual price rebalancing scenarios that would ease further access to the network. Beyond gas type usage, the Argentinean residential market is particular in that piped gas has a different pricing regime than bottled gas. The regulated piped gas schedule takes the form of a fixed fee and single unit price, whereas bottled gas is priced using a single unregulated volumetric charge, which is determined by (imperfectly) competitive markets with cross-border arbitrage. Piped gas rates and bottled gas prices both vary across regions. These market differences make Argentina’s residential gas markets an attractive environment to explore how regulated price changes impact access and welfare when users can opt for an unregulated substitute.Footnote 2
 Previous studies use firm level or national aggregated US data to examine the effects of price reforms in the gas industry. Hollas (1990) finds regulation modifies rate structures in a way that public gas distributors charge lower gas prices than private monopolies. In a related study, Hollas (1999) estimates that industry restructuring impacts on the asymmetry of gas distributors’ residential and industrial gas rates, and that the costs of the disparity shifted to residential users. Davis and Muehlegger (2010) weigh residential users’ welfare costs that result from mark-ups above marginal costs. Studies examining the impact of gas market reforms on households’ welfare using microdata include Hancock and Waddams (1995); Gómez Lobo (1996) and Waddams and Hancock (1998) for the UK, McKenzie et al. (2003) for a few Latin American countries and Miniaci et al. (2008) for Italy. Davis and Kilian (2011) use a household level, discrete-continuous model of natural gas demand to estimate the allocative cost of price-ceilings in the US residential market during 1950–2000. Their household level approach provides insights into the distributional effects of regulation. Giulietti et al. (2005) examine how residential users in the UK exercise choice among competing piped gas suppliers, as it first became available.Footnote 3
 We estimate a gas-type choice model and a short-run demand model using micro data gathered from a household expenditures survey. We build on earlier studies in several ways. First, in contrast to prior work that accounts for the correlation between choice and usage decisions making use of sequential, two-step estimators, we adopt a one-step structural approach based on a simple unified behavioral model that allows for parameterization of the choice and demand models within a single utility-theoretic framework that integrates choices with respect to both gas type and usage.Footnote 4 Second, unlike prior work, the model is able to capture distributional effects across households that differ in terms of income, family size, employment status and region of residence. We thus evaluate distributional impacts along several household features that usually guide regulatory decision making. The analysis is thus of practical relevance for policy makers, for at least two reasons. First, tariff rebalancing typically brings about price changes. Because the unit of interest in our analysis is the household, our model can be used to assess how price changes affect gas consumption and consumer welfare across different household attributes such as income or region of residence. Such an analysis allows exploring the distributional effects of price changes across types of households. Second, the gas-type choice model can be used to predict, for disaggregated segments of the population, the change in penetration rates that might result from a change in both gas prices and household features. Such predictions allows examining the potential for further diffusion of piped gas in the face of relative price changes, an analysis that may be important to avoid perverse post-reform outcomes. The rest of the paper is organized as follows. Section 2 provides background on Argentina’s residential gas market. Section 3 presents a simple model whose predictions allow for examination of both connection decisions and welfare effects at the household level. Section 4 discusses the empirical implementation, while Sect. 5 describes the data used in the analysis. Section 6 examines the econometric results of the choice model. Section 7 then reports results on how access to the piped gas network and household welfare are linked to price changes. The last section concludes.",3
45.0,1.0,Journal of Regulatory Economics,29 August 2013,https://link.springer.com/article/10.1007/s11149-013-9230-y,Fixed-mobile integration,February 2014,Steffen Hoernig,Marc Bourreau,Carlo Cambini,Male,Male,Male,Male,"Nine of the ten largest fixed-line carriers in the world own a controlling stake in a mobile operator (Dippon 2005). Historically, these carriers entered the mobile markets in its early stage and have kept a strong presence ever since: Today, most incumbent operators own 100 % of their mobile arms, which tend to be the largest operator in their market. For example, in Europe 11 out of 14 horizontally-integrated mobile operators were the leaders within their mobile market in 2012 (see the Table in the Appendix). In emerging markets, such as Brazil, China and Russia, fixed-mobile integration has also begun, with significant implications for their telecoms industry.Footnote 1 In a nutshell, today, integration between a mobile network and the fixed-line incumbent is a pervasive and key feature of most communications markets.Footnote 2
 What is the impact of integration between a fixed and a mobile operator on pricing incentives? Does integration provide a competitive disadvantage to non-integrated operators? Notwithstanding the clear relevance of the problem, these questions have received little attention in the economic literature.Footnote 3 Most studies on network competition and interconnection (see the surveys by Armstrong 2002; Vogelsang 2003; Harbord and Pagnozzi 2010) focus on the degree of market competition and the incentives to collude in setting (two-way) access charges in order to relax competition. The role of integration is still unexplored, and our paper aims to fill this gap. Our baseline model has one fixed and two mobile operators. The mobile operators compete to attract one group of consumers who wish to subscribe to a mobile network and will make calls to all networks. The fixed operator provides access to its own group of customers, which is assumed to be separate from those of the mobile networks.Footnote 4 Since calls will be made between the different groups of customers, new call services emerge: Consumers can make fixed-to-mobile and mobile-to-fixed calls, for which fixed and mobile networks provide essential inputs to each other. An important role is played by call externalities which arise when customers obtain a positive utility not only from making but also from receiving calls. In this setting, we analyze the pricing incentives for mobile-to-mobile (MTM), fixed-to-mobile (FTM) and mobile-to-fixed (MTF) calls under both separate ownership, where all three networks are independent of each other, and integration, when a mobile network is integrated with the fixed network. Our results show that in presence of integration, FTM calls to the rival mobile network are priced significantly above marginal cost, while those to the integrated mobile network are priced below cost. This pricing structure creates an additional disadvantage for the non-integrated mobile network, in terms of market shares and profits, and even magnifies any prior asymmetries. Furthermore, we also show that the integrated networks would prefer FTM termination rates to be set at zero, while the non-integrated network would prefer them to be high. We then extend the model to account for fixed-mobile call substitution and competition between fixed operators. Our results show that call prices to rivals of the integrated partners are strategically distorted upwards in both cases, just as in the baseline model. Thus, our conclusions are robust with respect to alternative assumptions about the fixed market. If remedies were to be imposed on retail prices, we find that imposing a uniform pricing constraint on FTM prices eliminates the strategic incentives for excessive FTM prices, while maintaining some of the efficiency gains from integration. The alternative remedy of imposing a functional separation obligation, in order to mimic price setting under separation, also eliminates the incentives for excessive pricing, but foregoes the efficiency gains that are obtained under integration. An important new feature in network competition models is the analysis of retail pricing in the presence of call externalities, i.e. when customers obtain utility from receiving calls (Jeon et al. 2004; Berger 2004, 2005; Cambini and Valletti 2008; Hermalin and Katz 2011). Jeon et al. (2004) show that introducing call externalities strongly modifies pricing incentives for calls between mobile networks: On-net calls are priced below cost in an attempt to internalize the call externality, while off-net prices may be set significantly above cost for strategic reasons, i.e. in order to reduce the number of calls subscribers on rival networks receive, weakening their ability to compete. This increase in retail prices may even lead to “connectivity breakdowns”: In order to discourage subscribers from connecting to the rival, a network has an incentive to charge extremely high off-net call prices or off-net receiver prices. Cambini and Valletti (2008) show that the risk of a connectivity breakdown is however much diluted when return calls are induced (i.e., calls made and received are complements), and that the possibility of a breakdown is completely eliminated if operators can set a jointly profit-maximizing reciprocal access charge. None of these papers however deals with the presence of both mobile and fixed networks, and the impact of integration on pricing incentives. On the other hand, there exists an equally sizeable economic literature on the relationship between fixed and mobile telephony, see e.g. the survey by Vogelsang (2010). Wright (2002) considers FTM calls with a focus on mobile termination rates, while others (e.g. Valletti and Houpis 2005) analyze how socially optimal FTM termination charges would depend on the magnitude of network externalities, the intensity of competition in the mobile sector, and the distribution of customer preferences. Armstrong and Wright (2009) integrate the above two streams of literature into a unifying model and analyze the impact of introducing a uniform (FTM and MTM) termination charge. They show that imposing uniform access charges (set either unilaterally or cooperatively) leads mobile networks to set a termination charge below the monopoly level, but above the level that they would set if MTM termination could be priced separately. They also discuss the choice of termination rates by an integrated fixed and mobile network, and under fixed-to-mobile call substitution, but do not reserve special attention to the competitive implications of integration. To our best knowledge, there is no academic publication considering the strategic impact of integration between fixed and mobile networks and the pricing incentives for on-net and off-net calls. The papers closest to ours are Cambini (2001), who considers vertical integration between local and long-distance communications providers and the resulting problems of one-way wholesale access (there is no corresponding retail pricing analysis, though), and Mu (2008), who analyzes symmetric competition between two pairs of integrated fixed and mobile networks and the necessity of regulating mobile termination rates. The latter paper finds that integrated firms internalize termination payments, i.e. do not take termination rates into account when setting their retail prices for calls between their partners, but neglects the decisive issues of call externalities and asymmetric outcomes in the mobile market. The outline of the paper is as follows. In Sect. 2 we describe the model. Section 3 presents the retail pricing equilibrium in the benchmark case where networks are non-integrated, while in Sect. 4 we study equilibrium outcomes when the fixed network and a mobile network are integrated. In Sect. 5 we propose potential regulatory remedies to limit the negative impact of integration on market outcomes. Section 6 studies the robustness of our main findings when there is competition in the fixed market or fixed-mobile substitution. Section 7 concludes.",3
45.0,1.0,Journal of Regulatory Economics,04 October 2013,https://link.springer.com/article/10.1007/s11149-013-9231-x,Optimal access regulation with downstream competition,February 2014,Tina Kao,Flavio M. Menezes,John Quiggin,Female,Male,Male,Mix,,
45.0,1.0,Journal of Regulatory Economics,12 November 2013,https://link.springer.com/article/10.1007/s11149-013-9236-5,Regulation and financial disclosure: The impact of plain English,February 2014,Tim Loughran,Bill McDonald,,Male,Male,Unknown,Male,"Using a large sample of SEC filings over 1994–2009, we study the direct and indirect effects of regulators’ attempts to guide positive market outcomes by explicit policy and, separately, by their encouragement to apply the policy in a broader setting. Specifically, we examine the SEC’s plain English rule of October 1998. The impetus of the rule is that investors will be better able to assess and more likely to invest in companies whose financial disclosures are not buried in legal jargon and obtuse language. Importantly, the rule is restricted only to prospectus filings, however, SEC documents and speeches by SEC leaders clearly encourage firms to adopt these principles in all their filings and communications with shareholders.Footnote 1
 The plain English rule mandates that firms’ prospectuses “must use plain English principles in the organization, language, and design of the front and back cover pages, the summary, and the risk factors section.” The rule becomes somewhat less precise, however, when it requires that the writing in these sections of the prospectus “substantially complies with” a list of plain English principles. How successful was the SEC in getting firms to improve the readability of the prospectus and, by encouraging managers to conform in all public disclosures to the rule, the 10-K filings?Footnote 2
 Filings covered by the rule include any prospectus or security registration (Forms 424, S-1, F-1, and their variants). We will consider the full sample of 424 filings, which are dominated by debt offerings and, separately, S-1 filings for initial public offerings (IPOs) as our sample of filings mandated by the plain English rule. We also examine all 10-K filings which serve as an important communication channel for managers and provide a form not specifically mandated by the rule. Additionally, the frequency and consistency of 10-K filings allow us to focus on the actions and characteristics of firms in the context of plain English. To evaluate disclosure style, we create a standardized statistic that aggregates a series of writing components specifically identified by the SEC. The six components are average sentence length, average word length, passive voice, legalese, personal pronouns, and negative/superfluous phrases. This standardized statistic may be useful to other researchers examining document readability or plain English enforcement. We find that our measure of plain English does “improve” notably in all of the samples after the regulation is enacted. While the prospectus samples (Form 424s and IPO S-1s) increase their compliance dramatically and immediately, the 10-K sample increases over the 2 years following the rule, stabilizes, and then trends upward for the 3 years following the passage of Sarbanes–Oxley. Throughout this paper we use the term “improve” to denote a rise in the plain English measure. We do not determine if in fact the filings are more effective or more accessible as a result of these stylistic suggestions. Whether the spillover of the rule’s directives to 10-Ks is attributable to simple encouragement by the SEC or more directly by coercion through delays in disclosure approval, the SEC’s plain English mandate appears to have clearly affected both the mandated and non-mandated disclosure documents. After providing descriptive results for the three samples we then focus on the 10-K filings. Using the 10-K sample, we link our plain English measure to firms having seasoned equity offerings (SEOs). In the year preceding an SEO, we find that firms are more likely to improve the plain English components of their 10-K filing after the plain English rule takes effect in October, 1998. This behavioral shift could be attributable to either a firm simply updating the template language of their 10-K in light of the SEO, or to the belief that the SEC’s recommendations for making financial disclosures more accessible could in fact make their equity offering more palatable in the marketplace. When we link the 10-K data to the Gompers et al. (2003) Corporate Governance Index, we find that firms with shareholder-friendly governance structures are more likely to file 10-Ks with high plain English scores under the regulatory regime. Thus, as might be expected, firms with solid corporate governance policies are more likely to comply with the SEC requests. We show that regulators can impact market outcomes both directly and indirectly. The plain English rule requires only changes in prospectus filings, not in 10-Ks. The improvements we observe in our 10-K sample are a result of encouragement by the SEC to adopt the plain English guidelines originally intended for prospectus filings. Section 2 of the paper offers a background on the 1998 Plain English Rule. Section 3 describes our Form 424, IPO S-1, and 10-K samples, data sources, and parsing procedure. Descriptive results for the three samples are presented in Sect. 4. In Sect. 5, we focus on the 10-K filings vis-à-vis SEO offerings and corporate governance. Finally, Sect. 6 presents our conclusions.",52
45.0,2.0,Journal of Regulatory Economics,22 January 2014,https://link.springer.com/article/10.1007/s11149-013-9239-2,Productivity throughout regulatory cycles in gas utilities,April 2014,Ariel A. Casarin,,,Male,Unknown,Unknown,Male,"Price cap regulation has increasingly replaced rate of return regulation largely because of the incentives it provides by separating price setting from cost measurement. The decoupling of prices from costs makes it easier for regulators to commit to relatively infrequent price reviews.Footnote 1 In addition, price caps’ fixed regulatory cycles provide better incentives for firms to operate with no waste and to make capital replacements if technological progress lowers both capital equipment and operating costs. Price cap’s regulatory practice of using a sequence rather than a few test-years also raises social welfare because it reduces the scope for cost manipulation (Pint 1992). These advantages of price cap regulation over rate of return regulation should reveal in total factor productivity (TFP) estimates, which have thus turned into a key input when conducting price reviews. Price cap regulation coexists, however, with incomplete information and uncertain regulatory commitment. These features permit strategic behavior on the part of both firms and regulators that can result in effort and capital distortions. Firms will be able to obtain information rents by signaling little room for technological improvements. Regulators’ attempt at price reviews to reset potential earnings by increases in productivity offsets would be viewed by firms as an appropriation of their gains and undermine their productivity incentives, which the system tries to create (Sappington 1994; Weisman 2002). As a result, if the regulatory cycle is long,Footnote 2 firms’ productivity effort and investment in cost reducing assets will then be stronger soon after a price review and weaker as the new review approaches (Biglaiser and Riordan 2000; Guthrie 2006).Footnote 3 Repeated intervals of price-cap regulation can then be expected to generate cycles in productivity effort—as revealed through technical change—and capacity replacement, with a subsequent effect on regulated prices or firm performance.Footnote 4
 In this paper we study the productivity performance of price cap regulated utilities around price reviews. Our goal is to search for productivity patterns throughout regulatory cycles and to detect whether such patterns, if any, result from the firm’s effort or from factors that exogenously affect technical change. Our empirical setting is the Argentine gas distribution industry from industry privatization in 1992 until 2001, the year prior to the second price review. This industry offers the particularity that, due to conditions imposed at privatization, capital expenditure decisions within the first regulatory cycle were largely exogenous to firms. This peculiarity allows us to investigate whether mandated regulatory investment reduces the ratchet problem by promoting a pooling equilibrium within the industry towards the technology frontier and therefore more effort to reveal efficiency (Dalen 1995). We exploit this feature and model technical change using the generalized index approach first proposed by Baltagi and Griffin (1988). In contrast to the time trend model, this method allows technical change to be non-smooth so that substantial year-to-year variations can occur if they exist in the data. This approach allows us to examine the timing and sources of productivity patterns throughout two regulatory cycles. An important potential benefit to the firm under price-cap regulation is the returns from cost reduction from the replacement of obsolete capacity. This benefit should be reflected in higher productivity growth. However, regulatory intervention in the investment decision process makes it unlikely that investment series reflect the rational behavior described by dynamic factor demand models. This particularity is enhanced by the distinguishing feature of scale economies in infrastructure construction. Exogenously determined new investment therefore causes short-run utilization fluctuations that affect productivity to the extent of short-run scale economies. Our empirical approach explicitly tests for such disequilibrium. We also account for the fact that the price regulation put in place at the moment of the reform gave firms no flexibility in altering the structure of prices. Therefore, it is possible for prices to be non-proportionally related to marginal costs. Firms’ lack of flexibility to alter the structure and level of prices allows us to investigate the contribution of non-marginal cost pricing to the measurement of productivity growth. We contribute to existing empirical literature in several ways. First, we add to the few studies that examine the ratchet effect in regulated utilities (Joskow 2006; Tella and Dyck 2008; Bottasso and Conti 2009). These studies suggest that regulated firms seem to realize most of the efficiency gains in the early part of the regulatory cycle and that cost cutting activity seems to fall as a new price review approaches. We expand on these works by explicitly testing the extent of short-run disequilibrium and the impact of investment on productivity growth. Second, we contribute to the small number of studies examining TFP growth for Latin American utilities, which are almost exclusively regulated on variants of price caps (Estache and Wren-Lewis 2009). The region thus provides a unique but little explored laboratory for examining productivity dynamics in regulated network industries (Megginson and Netter 2001; Chong and Lopez-de-Silanes 2005; Bernstein et al. 2006). Finally, we also add evidence to the very few studies which examine productivity growth in the distribution of piped gas (Waddams Price and Weyman-Jones 1996; Rossi 2001; Hollas et al. 2002; Lowry and Getachew 2009). We find that the pattern of pure technical change differs within and between regulatory cycles. Our estimates provide evidence that exogenous investment reduces the ratchet-problem, that strategic cost cutting behavior is reduced when regulatory cycles are short and that, absent these two features, industry productivity is consistent with strategic cost cutting behavior. We also find that privatization was followed by a poor productivity performance because the sub-utilization of capacity overshadowed the gains of technical change. The rest of the paper is organized as follows. Section 2 provides background on Argentina’s natural gas market. Section 3 presents the methodological framework we use to estimate TFP growth and its source components at the firm level. Section 4 discusses the empirical implementation. Section 5 describes the data, while Section 6 presents econometric results and the productivity estimates. The last section concludes.",2
45.0,2.0,Journal of Regulatory Economics,24 January 2014,https://link.springer.com/article/10.1007/s11149-013-9235-6,The doctor will be with you ... shortly?,April 2014,Lindsey Woodworth,,,,Unknown,Unknown,Mix,,
45.0,2.0,Journal of Regulatory Economics,15 October 2013,https://link.springer.com/article/10.1007/s11149-013-9233-8,The effect of regulatory scrutiny: Asymmetric cost pass-through in power wholesale and its end,April 2014,Frieder Mokinski,Nikolas M. Wölfing,,Male,Male,Unknown,Male,"This paper studies the effect of regulatory scrutiny on firms’ behavior by means of an example from the first years of emissions trading in the European Union. By showing that the pass-through of emission allowance prices to German electricity prices changed significantly in response to a report on the investigations of the competition authority, we provide direct evidence for the deterring effect of regulatory monitoring. Since January 2005, the European Union emissions trading scheme (EU ETS) has obligated the EU’s larger greenhouse gas emitters, such as fossil fuel-fired power plants, to measure their emissions and to surrender a corresponding amount of European emission allowances (EUA) by the end of each year. Until recently, allowances were distributed free of charge across the regulated companies, but the overall amount of allowances is capped. Companies can trade in the allotted allowances, which are thus given a market price and value. Hence, emission allowances are a necessary and costly input to the electricity production process and electricity wholesale prices in several European countries rose in conjunction with the start of emissions trading in 2005. Shortly after the introduction of the EU ETS, some energy-intensive industries in Germany called on the competition authority to monitor the price setting of German power producers. According to their line of argument, charging costs for freely allotted allowances constitutes an abuse of market power and should not be allowed. Power producer argued that, in generating an additional unit of electricity they consumed allowances which could have otherwise been sold for profit, irrespective of whether allowances were bought on the market or part of the initial endowment which they received for free. They claimed only having factored in opportunity costs, which was general practice in the European electricity market. Since producers did not try to cover that they were factoring in emission allowance prices, they seemed to be convinced that the competition authority would agree with their pricing argument. Nonetheless, the competition authority undertook investigations in the matter and issued hearing summons to RWE and E.ON, two electricity companies which together accounted for more than 60 % of installed capacity in Germany. A progress report (BKartA 2006) with the interim findings of the investigations was published ten days prior to the hearings in March 2006. It must have come as a surprise to German power producers that the report clearly documented the authority’s critical position towards their pricing policy. Our main point of interest is not whether the competition authority’s economic assessment of the situation was correct or not. Instead, we analyze the effect of the authority’s communication on the pricing behavior of power producers in the wholesale market for electricity. Our hypothesis is that the authority’s assessment, deviating from expectations, led to a structural break in price formation in the German electricity market. Indeed, we demonstrate that the relation between electricity prices and \(\hbox {CO}_2\) prices changed in spring 2006. Before the publication of the competition authority’s report, emission allowance prices appear to have had an asymmetric effect on the wholesale price for electricity: When EUA prices rose, power prices experienced a sharper increase than the decrease they saw when EUA prices shrank by the same amount. We do not find evidence for an asymmetric pass-through of EUA prices after the publication of the report. Several robustness checks support our findings. Keeping these results in mind and in light of the communication between complainants, defendants, and the competition authority, we conclude that electricity providers did change their pricing behavior due to closer monitoring, despite the fact that asymmetries in the pass-through of costs had not yet been discovered at the time and had not been subject of the competition authority’s proceedings. 
Zachmann and Hirschhausen (2008) (Z&H in the following) were the first to document an asymmetric reaction of the wholesale price for electricity to fluctuations in EUA prices in 2005 and 2006. The analysis of Z&H was inspired by the fact that emission allowance prices decreased sharply in 2006, while there was no comparatively strong reaction in power prices. This poses the question in how far the observed pattern might have been an artefact of the drastic change in the EUA-price series. We substantially reinforce their result with a more subtle identification strategy: Due to our choice of data and the specification of our models, our finding of an asymmetric pass-through does not rely on the heavy price movements in the EUA market in April 2006. In addition, we carefully control for outliers in our data to avoid a disproportionately high influence of unusual observations on parameter estimation. Our empirical strategy therefore allows for a robust identification of the asymmetric pricing pattern, whose prevalence is found to be restricted to the time before spring 2006 when the competition authority published its investigation results. Studies on other European electricity markets confirm a pass-through of emissions allowance prices on power prices. For the first phase of the EU-ETS, Fezzi and Bunn (2009) study day-ahead prices for power in the UK, Fell (2010) studies pass-through on the Scandinavian power market and Kirat and Ahamada (2011) consider power prices for France and Germany. None of these studies, however, takes asymmetric effects into account. The topic has recently enjoyed a renewed interest with more evidence for the second phase of the EU-ETS (Sijm et al. 2012; Fell et al. 2012; Kirat and Ahamada 2012). Lo Prete and Norman (2013) specifically address the puzzle of an asymmetric pass-through posed by Z&H and show that no such pattern is present in power prices for Germany, France, Belgium, and the Netherlands between 2007 and 2010. Asymmetric price adjustment has been empirically observed in a number of commodity markets (see e.g. Peltzman 2000). There is ample evidence, especially for the fuel market (Borenstein et al. 1997; Brown and Yücel 2000, e.g.), that has triggered several contributions to the microeconomic theory of this phenomenon. The theoretical literature studies factors that can induce an asymmetric adjustment of prices such as search costs (Yang and Ye 2008; Lewis 2011; Cabral and Fishman 2012), price adjustment costs (e.g. Kuran 1983), inventories (Reagan and Weitzman 1982) or collusion in heterogeneous commodity markets, with private information about demand shocks (Damania and Yang 1998; Kovenock and Widdows 1998). However, none of these explanations seems to be applicable to the case at hand, where firms trade a homogeneous product through an exchange-based electronic trading mechanism. 
Kolstad and Wolak (2008) (K&W in the following) study a case which appears to be closely related to ours. Their analysis of the Californian electricity market shows how power generating firms exaggerated emissions permit prices to push up electricity prices in 2000 and 2001. The authors infer “that NOx emissions permits were a convenient vehicle for enhancing the ability of suppliers to exercise unilateral market power in the California electricity market.” (Kolstad and Wolak 2008, p. 3). Our case differs from the one of K&W in two respects: First, the Californian permit market differs from the much broader EU ETS with respect to the potential of a single firm influencing the price for emissions permits. Second, K&W argue that firms pushed up permit prices to cost-justify higher bids for the marginal plant with the Federal Energy Regulatory Commission. This is in contrast to the deregulated Central-European electricity markets, where there is no regulator who requires firms to cost-justify their bids. The competition authority, however, intervenes when it finds evidence for anti-competitive behavior of firms, and our results witness a change in the pricing pattern when the competition authority signals that the pass-through of permit prices is under investigation. Despite these differences in the market setting, we take the study of K&W as evidence that the introduction of emission trading can provide a new instrument for electricity generators to implement anti-competitive strategies. There is research on the empirical effect of regulatory monitoring on competitive behavior, mainly focusing on the stability of cartels (see e.g. Harrington 2008, for an overview). McCutcheon (1997) discusses, from a theoretical perspective, to what extent a monitoring competition authority hinders the formation of cartels and thus facilitates collusion. Harrington (2005) analyzes how a cartel would price optimally to prevent suspicions by the competition authority, and in a recent contribution Harrington and Skrzypacz (2011) report on the internal monitoring of cartels when firms have private information about their sales. To the authors’ knowledge, however, there is much less evidence on the effect of regulatory scrutiny for anti-competitive conduct when firms are not explicitly engaged in a cartel (see e.g. OFT 2011). Our research contributes to the literature in three different aspects. First, we confirm the surprising finding of an asymmetric price adjustment for exchange traded power contracts, and we limit the time frame for which this asymmetry appears in the data, thus putting the result of Z&H into perspective. Second, we confirm that the pass-through of costs has been symmetric in recent years; thus, we provide evidence that the price for \(\hbox {CO}_2\) emissions from fuel combustion is now adequately reflected in power prices. Third, we closely link the end of the asymmetric cost pass-through to the time when additional information about regulatory monitoring was released to the market. Even though the competition authority was unaware of an asymmetric pass-through at the time, suppliers decided to refrain from this practice when they learned that the regulator was critically assessing their pricing strategies. We interpret our results as evidence for the response of firms to closer regulatory scrutiny, thus adding to the literature on competition monitoring which currently focuses largely on the detection of cartels. Similar to K&W, we thus provide evidence of a potential abuse of emission prices for the implementation of anti-competitive strategies in electricity markets. The remainder of the paper proceeds as follows. Section 2 briefly describes the communication of the involved parties in the law suit. Section 3 describes our dataset and model specifications. Empirical results are summarized in Section 4. In Section 5, we perform various robustness tests. Section 6 concludes.",12
45.0,2.0,Journal of Regulatory Economics,22 January 2014,https://link.springer.com/article/10.1007/s11149-013-9240-9,Did the introduction of a nodal market structure impact wholesale electricity prices in the Texas (ERCOT) market?,April 2014,J. Zarnikau,C. K. Woo,R. Baldick,Unknown,Unknown,Unknown,Unknown,,
45.0,2.0,Journal of Regulatory Economics,21 January 2014,https://link.springer.com/article/10.1007/s11149-013-9243-6,"Regulation, renegotiation and capital structure: theory and evidence from Latin American transport concessions",April 2014,Alexander Moore,Stéphane Straub,Jean-Jacques Dethier,Male,,Unknown,Mix,,
45.0,3.0,Journal of Regulatory Economics,20 February 2014,https://link.springer.com/article/10.1007/s11149-014-9245-z,Access regulation and the transition from copper to fiber networks in telecoms,June 2014,Marc Bourreau,Carlo Cambini,Pınar Doğan,Male,Male,Female,Mix,,
45.0,3.0,Journal of Regulatory Economics,07 February 2014,https://link.springer.com/article/10.1007/s11149-014-9244-0,Using the allocation of emission permits for strategic trade purposes,June 2014,Christos Constantatos,Eleftherios Filippiadis,Eftichios S. Sartzetakis,Male,Male,Unknown,Male,"Increasing interest in emissions trading schemes (ETS) is based mainly on the expected efficiency gains derived from allocating abatement effort to the lowest cost facilities. These theoretical expectations led to the introduction of ETSs initially at the national level—mainly in the USA—and later, following the positive evaluation of the existing schemes, at the international level, the primary example being the EU-ETS for controlling greenhouse gases. Countries participating in an international ETS receive a number of emission allowances (permits) that may, in turn, either auction or allocate free of charge to their domestic firms (grandfathering). Mixed schemes where some governments use auctioning and other grandfathering of permits may exist even within the same trading block. Actually this was the case in Phase I and II of the EU-ETS, during which, despite the existence of general guidelines, “...permit allocation was not coordinated between the member states, leading to differential treatment of otherwise similar companies and sectors across the EU” (OECD 2011 p. 47). The revised allocation rules in Phase III lead progressively towards auctioning, allowing though grandfathering of permits in selective sectors and participating countries.Footnote 1 Despite substantial efforts to harmonize allocation rules, this is impossible within a mixed allocation scheme.Footnote 2 Furthermore, mixed permit allocation schemes might emerge as more regional or national ETSs for controlling greenhouse gases develop and are connected among them in order to enhance efficiency.Footnote 3
 The emergence of international permit markets, to address mainly climate change challenges, in which the initial permit allocation rules differ among countries, implies that competitors in international product markets may be treated differently by their governments. The main concern with respect to the effect of climate policies on international competitiveness relates to the issue of carbon leakage resulting from differences in environmental standards.Footnote 4 Another concern that has received less attention relates to the effect that an international ETS with mixed allocation rules might have on competitiveness. More precisely, could grandfathered permits affect market performance and provide the recipients with strategic advantage over permit-purchasing rivals? The layman’s presumption is that it does indeed, yet economic theory treats grandfathered permits as pure transfers. A competitive permit market creates an opportunity cost to the use of a permit equal to its market value; therefore a firm uses the same number of permits whether it receives them for free or purchases them. Seen in this way, granting permits to a firm corresponds to a lump sum transfer that, while it may affect entry or exit decisions, it leaves output decisions of existing firms unaffected. This line of argument led to the suggestion that grandfathering cannot create competitive distortions (Woerdman 2003), and that countries should be left free to decide independently the permit allocation scheme (Zhang 1999). Our analysis shows that the above reasoning is limited to frictionless markets, in which transactions bear no additional costs. We show that in the presence of fixed and/or per-unit transaction costs, permits grandfathering affects output decisions and thus, it can be used for strategic trade purposes distorting international competitiveness. If participation in the permit market entails fixed costs, some firms may choose to stay out of the permit market, complying with the regulatory requirements by abating and using any amount of grandfathered permits they receive. Clearly in this case the amount of granted permits affects production choices. If firms enter the market, variable transaction costs drive a wedge between buyers’ and sellers’ opportunity cost of using permits in the production process. Therefore, the marginal cost of a permit seller is less than that of a permit buyer, thus inducing the holder of permits to a more aggressive behavior, assuming strategic substitutability of firms’ choices in the output market. Granting a number of permits to a firm is equivalent to offering that firm a unit cost reduction. While it appears that both grandfathered permits and subsidies may be used strategically to increase domestic firms’ output, there is an important difference. Unless there are quotas restricting the number of units to be subsidized, the subsidy applies to all units and the government’s decision concerns the subsidization rate. In the case of grandfathered emission permits, on the contrary, the amount of subsidy per unit of output is exogenous, determined by the permit price (in case that fixed transaction costs prevent firm’s entry into the market) and the per-unit transactions costs. What the government may affect in this case is the number of subsidized units. Hence, permit grandfathering corresponds to offering firms pre-established capacity and thus, is closer to capacity commitments, in the sense of the Dixit-Spence model (Dixit 1980; Spence 1977). 
Stavins (1995) incorporated transaction costs into the basic permits model to establish that cost efficiency conditions are violated and thus, the full potential of the permit market is not achieved. Furthermore, Stavins shows that, in the presence of transaction costs, the initial distribution of permits affects permit-trading decisions. Cason and Gangadharan (2003) confirm these results in an experimental setting. Montero (1998) incorporates uncertainty in the model with transaction costs and examines their effect on the permit market’s performance and control costs. These papers are concerned with the effect that transaction costs may have on the cost effectiveness of the permit market, while the present paper focuses on their effect on the output market, and in particular whether they allow governments to use permits strategically. Our analysis is based on strategic trade theory demonstrating that, in imperfectly competitive international markets, governments can improve their country’s welfare, relative to free trade, by intervening in these markets. A significant literature developed around this idea based on the initial contributions by Brander and Spencer (1984, 1985) and Dixit (1984). Although the predictions of the theory are sensitive to the mode of oligopolistic competition, Maggi (1996) identifies a single-rate policy, capacity subsidies, and shows that it can be used for strategic trade policy regardless of the mode of competition. Using the strategic trade policy framework it has been argued that countries could use environmental policy to improve their firms’ position, either by affecting the pattern of international trade or the location of firms and industry. Conrad (1993), Barrett (1994), and Kennedy (1994), among others, have suggested that environmental policy can be used to indirectly subsidize exports; Markusen et al. (1995) and Rauscher (1995), among others, discuss the incentives to strategically set emission taxes low to attract polluting industries. More recently Pratlong (2005) and Bueb and Schwartz (2011) examine the regulator’s incentives to use the pollution cap and the initial distribution of permits strategically in order to boost home firms’ position in the international market. Their analysis differs substantially from this paper in that Pratlong (2005) assumes that permits are not traded internationally, while Bueb and Schwartz (2011) assume that only one country implements an ETS. Furthermore, none of these papers deals with transaction costs. The importance of transaction costs in emission permit markets was noticed in a number of theoretical works quite early,Footnote 5 and their concerns were later supported by empirical analysis. Rose (1994) suggests the existence of transaction costs in the \(\hbox {SO}_{2}\) permits program, Kerr and Maré (1998) estimate efficiency losses from the presence of transaction costs in the lead permits program and Gangadharan (2000) shows that transaction costs were significant in the RECLAIM program, influencing the choice of participation in the market. Although not focusing on transaction costs, using data from the same program, Fowlie and Perloff (2013) report that their empirical analysis fails to reject the hypothesis that \(\hbox {NO}_{x}\) emissions were independent of how emissions permits were allocated across firms. More recently, a number of papers empirically examine the existence of transaction costs in the EU-ETS. Jaraite et al. (2009), using data from Irish firms participating in the EU-ETS, find that transaction costs are significant, particularly for smaller firms at the early stages of the program. Heindl (2012), using data from two surveys of German firms participating in the EU-ETS, reports significant transaction costs, which result in welfare losses. Furthermore, it is shown that transaction costs are relatively higher amongst smaller firms. Jaraite and Kazukauskas (2012), using data from all countries participating in the EU-ETS, report significant transaction costs that influence firms’ behavior in the permit market. They also show that small firms were less likely to participate in the market and a number of them did not sell their surplus allowances. Finally, Hahn and Stavins (2011) review and evaluate empirical evidence of potential violation of cost-effectiveness and neutrality of the permits’ allocation due to a number of conditions including transaction costs, in eight cap-and-trade programs. They find that in some programs cost-effectiveness and neutrality hold strong, while in some others these properties are absent due to distortions, among which the most prevalent is the presence of transaction costs. Transaction costs consist of administrative and trading costs which create a margin between the buying and selling price of permits. Taking the EU-ETS as an example, they are incurred first at the stage in which firms prepare their administrative systems to comply with the requirements of the regulation; second, at the stage of trading and they include search, information, bargaining and decision making costs; and finally at the reporting stage, and they include application, registry accounts, monitoring, reporting and verification costs.Footnote 6 The first category includes mainly fixed and sunk costs, the third category, periodic costs, incurred in every reporting period, and the second category, costs that depend on the number of transactions and the volume of permits traded.Footnote 7 Transaction costs differ according to whether firms trade directly at exchanges (in the case of EU-ETS there is a number of exchanges, such as ECX, NordPool and EEX), or use brokers operating in the emissions market for over the counter exchanges. In both cases transaction costs can be split into direct transaction costs (which include exchange membership, brokers’ fees, and financial services) and indirect transaction costs (which include personnel to manage transactions and risk, data/advisory services and financial reporting). In this paper we group transaction costs into fixed and variable (per permit traded) costs and we analyze their effect on firms’ output choice separately. The rest of the paper is structured as follows. Section 2 describes the model. Section 3 examines the effects of emission permits grandfathering on international trade. First, the Cournot equilibrium in the absence of transaction costs is presented and then, variable and fixed transaction costs are introduced separately. The incentives to use grandfathering of permits as a strategic trade instrument are analyzed assuming that only one country grandfathers permits while the other auctions them. The case that both countries grandfather permits is examined at the end of Sect.  3. The last Section concludes the paper and discusses some topics for future research.",1
45.0,3.0,Journal of Regulatory Economics,20 February 2014,https://link.springer.com/article/10.1007/s11149-014-9246-y,Interest group incentives for post-lottery trade restrictions,June 2014,Adrienne M. Ohler,Hayley H. Chouinard,Jonathan K. Yoder,Female,Female,Male,Mix,,
45.0,3.0,Journal of Regulatory Economics,20 February 2014,https://link.springer.com/article/10.1007/s11149-014-9247-x,The costs of zoning regulations in retail chains: the case of the City Planning Act of 1968 in Japan,June 2014,Mitsukuni Nishida,,,Unknown,Unknown,Unknown,Unknown,,
45.0,3.0,Journal of Regulatory Economics,06 March 2014,https://link.springer.com/article/10.1007/s11149-014-9248-9,Progressive entry and the incentives to invest in alternative infrastructures,June 2014,Marc Bourreau,Joeffrey Drouard,,Male,Unknown,Unknown,Male,"In the telecommunications industry, many policy makers view achieving facility-based competition (when new entrants rely on their own infrastructure to compete with the incumbent) as the long-term goal. If competition is to function fully, it is indeed necessary for each operator to control its supply chain to the largest possible extent. Larger benefits in terms of new products and services can moreover be expected under this form of competition than under service-based competition (where new entrants rely on the incumbent’s infrastructure to provide services to end consumers). However, as the deployment of new infrastructures involves large sunk costs, potential entrants are rarely able to build their own facilities from the outset. This is why a large majority of national regulatory authorities have mandated incumbents to offer access to their networks to new entrants, so that service-based competition can develop rapidly.Footnote 1
 Although service-based competition is clearly beneficial in the short term, its longer-term effects on facility-based competition have generated extensive debates. On the one hand, a traditional view is that there is a conflict between these two forms of competition. Indeed, a phase of service-based competition introduces an opportunity cost of building an alternative infrastructure, and hence lowers the entrants’ investment incentives. We refer to this effect as the “replacement effect.” On the other hand, others have argued that a phase of service-based competition allows entrants to step into the market and to acquire market experience progressively, which eventually enhances their investment incentives. In other words, service-based competition and facility-based competition are “complements” rather than “substitutes” in promoting competition. We refer to the effect of market experience acquisition on investment incentives as the “stepping stone effect.” An important assumption from the ladder of investment approachFootnote 2 is that the stepping stone effect facilitates investment. That is, given that the replacement effect is neutralized, service-based and facility-based competition are complements.Footnote 3 In this paper we propose a model in which an entrant acquires market experience progressively as it operates in the market. We then study the impact of a phase of service-based competition, and more specifically of the stepping stone effect, on facility-based entry. We consider two firms, an incumbent and a potential entrant. The entrant can enter the market either by acquiring access to the incumbent’s facilities (which gives rise to service-based competition) and/or by building its own infrastructure (which gives rise to facility-based competition). The access price to the incumbent’s infrastructure is exogenous and set by the regulator. We also assume that the investment cost declines over time and that it is not viable to invest at the outset; therefore, the entrant has to wait before installing its own infrastructure. When it enters the market, on the basis of either services or facilities, the entrant begins to acquire market experience. In our setting, market experience encompasses different phenomenons. For example, consumers could initially perceive the entrant’s service quality as low, but this perceived quality could increase over time as the entrant operates in the market. Prior to entry, consumers might also be unaware of the existence of the entrant. Once the entrant has entered the market, the proportion of informed consumers could gradually increase over time, allowing the entrant to build a customer base. We begin by studying a baseline case where the acquisition of experience depends only on the time spent in the market. We show that the stepping stone effect affects investment incentives in two opposite ways. On the one hand, as it has accumulated experience during the phase of service-based competition, the entrant anticipates higher profits under facility-based competition, which incentivizes investment. On the other, the entrant may benefit from prolonging the phase of service-based competition to acquire more experience, and gain higher profits under facility-based competition, which tends to delay investment. When facility-based entry is a long-term perspective, the former effect dominates and the stepping stone effect accelerates investment. Otherwise, if facility-based entry is a short-term possibility, the latter effect is the strongest and the stepping stone effect delays the entrant’s investment. In other words, taking the replacement effect as given, a process of market experience acquisition does not necessarily make service-based competition and facility-based competition “complements.” We then show that if facility-based entry is possible in the short-term, the phase of service-based competition delays facility-based entry, compared to a benchmark without access. However, if facility-based entry is a long-term possibility and experience has a strong impact on the entrant’s profits, the phase of service-based competition accelerates facility-based entry. In this case only, service-based competition facilitates facility-based entry per se. In this baseline model, since the acquisition of experience depends only on the time spent in the market, increasing the access price always accelerates investment. When it sets the access price, the regulator therefore faces a standard trade-off between static efficiency and investment incentives. We also study the case where the acquisition of market experience depends on the entrant’s current customer base, within a specific model of Cournot competition with quality differentiation. If facility-based entry is a short-term possibility, we obtain the same result than in the baseline case: increasing the access price accelerates investment. However, if facility-based entry is a long-term possibility, a low access price accelerates investment, because it allows the entrant to acquire experience rapidly due to a learning-by-doing effect. In this case, the regulator can achieve both static efficiency and early investment via a low access price. Our paper is related to the literature on access and investment (see Cambini and Jiang 2009 for a recent comprehensive survey).Footnote 4
Bourreau and Doğan (2005, 2006) analyze the effect of access to an incumbent’s infrastructure on an entrant’s incentives to build a network. Gans (2001, 2007), Hori and Mizuno (2006), and Vareda and Hoernig (2010) study the impact of access obligations in investment races between ex-ante symmetric firms. However, these papers do not consider any potential positive impact of the phase of service-based competition on the incentives to enter on the basis of facilities. Therefore, they cannot account for any stepping stone effect. A few papers consider a possible complementarity between the phases of service-based and facility-based competition. Vareda (2010) studies a two-period model, where the entrant learns about the state of demand once it enters the market. Therefore, service-based competition in the first period resolves the uncertainty about demand, after which the entrant decides whether or not to build its infrastructure. Schutz and Trégouët (2008) build a model that follows the same logic but where the entrant is uncertain about its marginal cost. In these two papers, the resolution of uncertainty can be either good news or bad news for infrastructure investment. In our model, on the other hand, the phase of service-based competition always makes the entrant “stronger,” by allowing it to acquire more experience. We show that even in this case, the stepping stone effect can contribute to delaying the entrant’s investment. 
Avenali et al. (2010) also study a setting where an entrant can acquire experience under service-based competition.Footnote 5 Experience transforms into a (perceived) high quality only if the entrant invests in its own facilities. Since they also assume that facility-based entry can take place only if the entrant’s perceived quality is high, it follows that service-based entry is a necessary prerequisite for facility-based entry. By contrast, in our setting, more experience always transforms into a higher quality, whatever the entrant’s current technology (service-based or facility-based). Therefore, service-based entry is not necessary for facility-based entry. However, we show that the existence of a process of experience acquisition is a necessary (but not sufficient) condition for service-based entry to improve the prospects for facility-based entry. Finally, a number of empirical studies have looked at the relationship between service-based competition and facility-based competition. Most (if not all) of them reject the ladder of investment or stepping stone hypothesis that this relation is positive (i.e., that the stepping stone effect dominates the replacement effect).Footnote 6 Our paper contributes to this literature by characterizing under which conditions the stepping stone effect might be effective in accelerating facility-based entry. The rest of the paper is organized as follows. In Sect. 2 we outline the model. In Sect. 3 we solve for the equilibrium when the acquisition of experience depends only on the time spent in the market. In Sect. 4 we study the case in which the entrant’s acquisition of experience depends also on its current sales. In the last section we conclude.",7
46.0,1.0,Journal of Regulatory Economics,24 April 2014,https://link.springer.com/article/10.1007/s11149-014-9254-y,The Desirability of forgiveness in regulatory enforcement,August 2014,Arun S. Malik,,,Male,Unknown,Unknown,Male,"Economic models of regulatory enforcement typically assume that penalties for detected noncompliance are certain and swift. Regulations are rigidly enforced and noncompliance when detected is never forgiven. In the language of the policy literature on regulation, economic models typically embody the “ deterrent approach” to enforcement, first formalized by Becker (1968) and Stigler (1970). Regulatory scholars have argued that this approach has proven ineffective at securing compliance, and needlessly fosters an adversarial relationship between regulators and the regulated (Bardach and Kagan 1982). The approach advocated by a number of scholars is the “ cooperative approach.” This approach favors selective enforcement that takes into account the circumstances of observed violations (Scholz 1984).Footnote 1 In particular, under the cooperative approach, “ regulators are more inclined to interpret rules flexibly, particularly when they believe firms are making good faith efforts to comply” (Harrison 1995). The cooperative approach, it is argued, is more likely to result in cost-effective enforcement and desirable regulatory outcomes (Bardach and Kagan 1982). In the U.S., studies of enforcement find evidence of selective enforcement in a range of regulatory settings. For example, guidelines for enforcement of water pollution regulations explicitly recommend that agencies be willing to forgive short-term violations, and that criminal fines be reserved for willful or negligent violations (Russell et al. 1986, Chap. 3, and Code of Federal Regulations 2004).Footnote 2
 In this paper, I show that a simple deterrence-based model of regulatory enforcement can be extended to allow for selective enforcement that takes into account a firm’s efforts to comply. In the model, the regulator forgives noncompliance if it is able to obtain sufficiently strong evidence that the regulated firm had exerted a high level of compliance effort. This evidence takes the form of an additional signal of the firm’s effort acquired by the regulator at some cost. This, possibly multi-dimensional, signal represents the results of inspections of a firm’s records, interviews with its employees, or evaluations of its processes and procedures for achieving compliance. Collection of such information is a common element of enforcement practices.Footnote 3
 The key benefit of forgiving noncompliance is a reduction in the probability with which the firm needs to be monitored. The additional signal of the firm’s compliance effort, coupled with selective forgiveness, allows for an increase in the power of the regulator’s penalty scheme. Thus, the model provides a simple efficiency-based justification for selective enforcement based on an assessment of a violator’s efforts to comply. This is accomplished in the context of a (noncooperative) principal-agent model with moral hazard. The paper is related to several different strands in the existing literature on regulatory enforcement. To the extent that it provides a justification for selective enforcement, it is related to work by Garvie and Keeler explaining the variation in enforcement styles in the United States. They analyze a model in which fines for noncompliance depend on the budget-constrained regulator’s enforcement effort and on the characteristics of the judicial process. They show that the regulator’s optimal enforcement style depends on the cost of monitoring and on the responsiveness of judicially-determined fines to the regulator’s enforcement effort. The optimal enforcement style resembles the cooperative approach when monitoring is inexpensive and the responsiveness of fines is limited (rendering fines more costly for the regulator); and resembles the deterrent approach when monitoring is expensive and the responsiveness of fines is high. The paper is also related to work by Jost (1997) on optimal enforcement when penalties are subject to judicial appeal. He considers a model with deterministic compliance in which a regulator must allocate its limited budget between two activities: monitoring, which yields an imperfect signal of a firm’s compliance status, and investigations, which reveal compliance status perfectly. Investigations are conducted only when a firm appeals penalties for noncompliance in court. The appeal can result in penalties being waived. The paper is also related, in spirit, to work by Nyborg and Telle (2004) and Rousseau (2009) that offers explanations for the warnings frequently issued by regulators upon detecting noncompliance. Nyborg and Telle (2004) consider a budget-constrained regulator that attempts to control the behavior of firms that may be noncompliant by mistake. Firms detected in noncompliance are issued warnings and can come into compliance by incurring a “ verification cost” in addition to the cost of compliance they would have incurred had they been compliant from the outset. In this setting, warnings can reduce the probability of accidentally switching from a full-compliance equilibrium to a no-compliance equilibrium. In Rousseau’s model, the regulator rather than the firm is susceptible to making mistakes. The technology employed by the regulator to monitor compliance with a pollution standard can erroneously indicate that a firm’s emissions exceed the standard. This induces some firms to overcomply in order to reduce the probability of being unjustly punished for noncompliance. The regulator can reduce this overcompliance and improve social welfare by selectively issuing warnings. The paper is also closely related to a body of literature that attempts to explain the paradox of widespread compliance with environmental regulations despite infrequent punishment of noncompliance. Harrington (1988) shows that this paradox may be explained by a state-dependent enforcement strategy in which penalties depend not only on current noncompliance but also on past noncompliance. Livernois and McKenna (1999) provide an alternative explanation based on a model in which firms must self-report their compliance status. Heyes and Rickman (1999) argue that the paradox may reflect “ regulatory dealing,” with the regulator choosing to forgive a firm’s noncompliance in one context (e.g., air pollution control), in exchange for compliance in another (e.g., water pollution control). In all three of these papers, the optimal penalty for some types of noncompliance may be zero, in other words, some types of noncompliance may be forgiven.Footnote 4
 The model presented here is similar to those in the literature just mentioned in that it yields conditions under which setting the fine for noncompliance equal to zero is optimal. But it differs in a number of important respects. The model explicitly attempts to capture the key principle underlying selective enforcement: that enforcement should take into account the circumstances of a violation, in particular the extent of a violator’s efforts to comply. This is not true of any of the existing literature. The model also differs from those in the existing literature in that it incorporates, and justifies, the practice of collecting information not just on a firm’s compliance status, but also on a variety of other measures.Footnote 5 In the U.S., for example, “ compliance monitoring” by environmental regulators typically includes inspection of production and abatement equipment, review of a firm’s records, and interviews with its employees (Hunter and Waterman 1996, 39–46, Gray and Shimshack 2011). Hawkins (1984), Nyborg and Telle (2004) and Telle (2009) report similar practices in Britain and Norway. This additional information makes selective enforcement possible in the model. Consistent with the notion that firms may be noncompliant despite good faith efforts to comply, compliance is modeled as being probabilistic.Footnote 6 This reflects the fact that a firm’s compliance status often depends not only on its compliance efforts, but also on factors that are inherently difficult for it to control. For example, equipment malfunctions or input quality variations may result in output that does not meet product quality or product safety standards. In the case of pollution control regulations, violations can also occur because of treatment process upsets (Russell et al. 1986, Chap. 3). More generally, compliance can be probabilistic in any setting in which firms can make mistakes. Nyborg and Telle point out that mistakes could arise from agency problems within the firm—the level of compliance effort desired by the firm’s management may not be exerted by subordinates. The firm’s inability to perfectly control its compliance status induces the regulator to consider not only the firm’s compliance status, but also its compliance efforts when determining whether to punish noncompliance. In this setting the variable of underlying interest to the regulator is the firm’s compliance effort. A final feature of the model is that it allows for the possibility that the regulator may only be able to observe the firm’s compliance status imperfectly.Footnote 7 This is true, for example, when compliance with product quality or product safety standards is determined by examining a sample of a firm’s output. In the case of environmental regulations, limitations of pollution measurement techniques can result in a firm’s compliance status being observed imperfectly (Russell et al. 1986, Chap. 3). More generally, if noncompliance is a fugitive event, establishing that it occurred at a later date is likely to be subject to error. For example, a temporary violation of a workplace safety regulation may be difficult to detect after the fact. Similarly, an accidental discharge of pollution into a water body may be difficult to detect, or attribute, once the pollutant has dispersed. The basic model of regulatory enforcement is presented in the next section. In Sect. 3, I then characterize the optimal enforcement policy. I show that forgiveness can reduce the probability with which the firm must be monitored, yielding savings in expected inspection costs. I also identify a sufficient condition for forgiveness to be socially desirable. The basic model is extended in Sect. 4 to incorporate self-reporting by the firm of its compliance status. I show that forgiveness may be even more likely in the presence of self-reporting. The final section contains some concluding remarks.",4
46.0,1.0,Journal of Regulatory Economics,14 January 2014,https://link.springer.com/article/10.1007/s11149-013-9238-3,Experimental comparison between markets on dynamic permit trading and investment in irreversible abatement with and without non-regulated companies,August 2014,Luca Taschini,Marc Chesney,Mei Wang,Male,Male,,Mix,,
46.0,1.0,Journal of Regulatory Economics,14 January 2014,https://link.springer.com/article/10.1007/s11149-013-9237-4,The impact of regulation and competition on the adoption of fiber-based broadband services: recent evidence from the European union member states,August 2014,Wolfgang Briglauer,,,Male,Unknown,Unknown,Male,"The traditional (“first-generation” copper- or coax-based) broadband networks appear to be outdated and it has become necessary to speed up these networks in recent years to account for the growing demand for bandwidth/connection speed. According to “Nielsen’s law”, the broadband connection speed increases every year by 50 % (FTTH Council Europe 2012, p. 12). Next-generation fiber-based access (NGA) networks deployed on the ground provide much more bandwidth capacity. As these networks represent a general purpose technology, they are expected to induce significant productivity improvements and growth across major economic sectors such as health, electricity and transport (e.g. Czernich et al. 2011). However, substituting the traditional infrastructure with fiber-optic networks also involves high risks and massive investment volumes.Footnote 1
 The demand in terms of adoption (penetration) and supply-side activities in terms of investment in fiber-based network infrastructure (coverage) vary significantly in an international comparison. Most European countries lag far behind the leading Asian fiber nations (such as Japan, Korea, Taiwan and Hong Kong), but also behind the development in the US (Briglauer and Gugler 2013). As regards NGA adoption within Europe, Northern and Eastern European economies are leading by a large margin with NGA household adoption levels between \(\sim 10\%\) (Denmark and Latvia) and \(\sim \)26 % (Lithuania) at the end of 2011. Exceptional cases are Belgium and Luxembourg, where the focus on less expensive NGA deployment technologies has facilitated adoption levels of \(\sim 45\) and \(\sim \)85 %, respectively. However, most of the other European countries still show NGA adoption levels (far) below 5 %, including all the major Western and Southern European economies.Footnote 2
 Europe’s gap in NGA deployment was recognized by the European Commission (EC) and explicitly addressed in its “Digital Agenda”, which specifies goals in terms of high-speed broadband coverage and penetration.Footnote 3 In achieving these goals, one of the most controversial regulatory issues in Europe (and elsewhere) is whether the emerging NGA infrastructure should be subjected to sector-specific ex ante access regulation. Former—mostly state-owned—telecommunications monopolists (“incumbents”) argue that sector-specific ex ante regulation would be detrimental to dynamic efficiency in terms of investment incentives and infrastructure innovation. Instead, it would be sufficient to rely on market mechanisms and infrastructure-based competition in particular. Conversely, alternative operators that are dependent on access regulation (“service-based competitors” or “entrants”) as well as some national regulatory authorities (NRAs) fear the rise of NGA networks as another upcoming monopolistic infrastructure and that incumbent firms or other alternative NGA infrastructure operators would gain an essential and long-lasting competitive (“first-mover”) advantage. This implies the need to have appropriate ex ante regulation in place and regulatory-induced service-based competition would also have an immediate effect on static efficiency in terms of lower prices and hence on the adoption of (new) communications technologies on the demand side. Based on an unbalanced panel of the EU27 member states for the years from 2004 to 2012, this paper addresses the following research questions: (i) What is the impact of broadband access regulations on NGA adoption? (ii) How does infrastructure-based competition stemming from wireless (mobile) networks influence the extent of NGA adoption? (iii) To what extent is NGA adoption driven by diffusion dynamics such as network effects or consumer inertia? This paper represents the first (European-based) attempt to quantify econometrically the determinants of NGA adoption with recent EU27 country-level data. A multiplicity of static and dynamic model specifications and a broad set of control variables serve as important robustness checks. Furthermore, we argue that there is no endogeneity problem in terms of reverse causality in the empirical specification, which relates first-generation broadband demand- and supply-side factors to second-generation NGA markets and services. The remainder of the paper is organized as follows. First, we review the recent and most relevant contributions in the empirical literature in Sect. 2. Section 3 briefly provides the necessary background information on the technical context of NGA networks. Section 4 then describes basic hypotheses concerning the role of sector-specific regulation and competition as well as the other main cost and demand factors. Section 5 describes our data set. Section 6 presents the empirical specification and the underlying identification strategy. Section 7 discusses the main empirical results. To conclude, Sect. 8 summarizes and contains some final remarks.",38
46.0,1.0,Journal of Regulatory Economics,23 January 2014,https://link.springer.com/article/10.1007/s11149-013-9241-8,Credit unions and risk,August 2014,David Ely,,,Male,Unknown,Unknown,Male,"The Federal Credit Union Act limits a credit union to groups having a common bond of occupation or association, or to groups within a defined geographic area.Footnote 1 In 1982, the National Credit Union Administration (NCUA) began to interpret the common bond requirement more liberally such that federally-chartered credit unions were allowed to expand their FOM to include multiple groups, provided that members in each new group shared a common bond.credit union has a FOM that “consists of more than one group, each of which has a common bond of occupation or association” while a community credit union has a FOM that consists of persons who “live, work, worship, or attend school in the same well-defined local community, neighborhood, or rural district” (National Credit Union Administration 2003, Appendix A).Footnote 2 The NCUA justified their actions by arguing that their interpretation would allow members to continue to receive services following the loss or downsizing of their credit union’s sponsor, allow employees of small businesses too small to sponsor viable credit unions to gain access to credit union services, allow credit unions to extend fairly-priced financial services in low-income areas, and enhance safety and soundness.Footnote 3
 A decision by the Supreme Court that would have forced NCUA to impose a narrow definition of the common bond requirement was quickly nullified by Congress with the passage of the Credit Union Membership Access Act of 1998 (CUMAA) (Pub.L. 105-219). This legislation specifically allows federally-chartered credit unions to expand beyond one membership group and to serve a “local” area. What constitutes a local area was not defined by CUMAA and NCUA revised its regulations to make it easier for credit unions to expand their reach.Footnote 4 During this time, constraints on state-chartered credit unions were also being relaxed and NCUA policies “appear to have been triggered by concerns about competing with the states to charter credit unions” (US General Accounting Office 2003, p. 29). Expanding the membership base may impact the risk profile of a credit union through diversification effects and changes in informational advantages. During Congressional deliberations on the CUMAA, representatives of the NCUA and the US Treasury argued for legislation granting credit unions greater flexibility to expand their membership bases (D’amours 1998; Bartolomucci 1998; Carnell 1998). The Chair of the NCUA, in testimony before the House Committee on Banking and Financial Services stated that “[t]he recession of the early 1980s fueled massive downsizings, closures and relocations at thousands of companies. Employees were laid off or fired. Since the federal credit unions affiliated with these companies did not have a diverse membership base, they quickly experienced viability problems” (D’amours 1998). Among the reasons for passing legislation to circumvent the Supreme Court ruling, D’amours stated that “Congress now has the opportunity to further the purposes of the Federal Credit Union Act by enacting legislation to codify NCUA’s multiple group interpretation of the common bond. Such legislation would promote the safety and soundness concerns reflected in the original Act by allowing diversification of credit union membership in order to safeguard against economic conditions that affect specific groups or industries” (D’amours 1998). The Assistant Secretary of the Treasury, Rich Carnell, also testified that safety and soundness was one of four market dynamics encouraging credit unions to expand beyond their original membership group (Carnell 1998). He noted that diversifying the membership base can make an institution “more resilient in the face of problems experienced by any one local employer” (Carnell 1998). However, Carnell also noted in his testimony that a tight common bond fosters low default rates “because of the effect that the default would have on friends, neighbors, or coworkers, and because of the shame associated with the default” (Carnell 1998). A 2006 Government Accountability Office (GAO) report also includes a finding that the NCUA justified its approvals of community charter expansion in part by a belief that such expansions would diversify membership bases and enhance safety and soundness (US Government Accountability Office 2006, p 13). Investigations of the impact of expanding membership bases of credit unions also appear in the academic literature. Because of the common-bond requirement for membership in a credit union, information asymmetries should be low relative to financial institutions with diffuse memberships. Kane and Hendershott (1996) note that the extent and quality of private monitoring within credit unions is intensified by sponsors and volunteers who have inside information because they work with or live close to loan applicants. These authors also note that lending decisions may incorporate private information known about borrowers and about the financial condition of a loan applicant’s employer and that defaults may be low because of social pressure to repay loans. It follows that information asymmetries increase with the broadening of the common bond.Footnote 5
 
Frame et al. (2002), Esho et al. (2005), and Goddard et al. (2008) show that diversification through expansion by credit unions can impact risk. With the exception of Frame et al., the relationship between FOM type and credit union risk has not been recently examined.Footnote 6 Using 1997 data, Frame et al. find that occupational credit unions, relative to other single-bond credit unions, have fewer loan delinquencies but hold higher levels of capital. The authors note that these two findings might be explained by informational advantages and a reaction to concentration risk, respectively. Consistent with greater investment opportunities and lower concentration risk, multiple-bond occupational credit unions have higher loan-to-share ratios and lower capital ratios. Finally, Frame et al. find that loan-to-share and delinquency ratios are positively related to the number of select employee groups serviced by multiple-bond occupational credit unions. The latter result may reflect lower informational advantages as the common bond weakens. 
Goddard et al. (2008), find that higher reliance on non-interest income is associated with higher earnings volatility but a more highly diversified revenue portfolio is associated with lower volatility, the net effect being statistically insignificant. Furthermore, credit unions that have diversified into activities that generate non-interest income are found to experience lower performance on both a risk-adjusted and unadjusted basis, except for the largest credit unions. The authors conclude that smaller credit unions should not diversify away from their core business while larger credit unions “should be encouraged to further exploit diversification opportunities around their core expertise in retail financial services” (Goddard et al. 2008, p. 1847). The structure of the credit union industry has been transformed as a result of the regulatory changes that relaxed the field-of-membership constraints. Table 1 presents information on the distribution of federal credit unions by FOM type. Of the 7,078 federally-chartered credit unions in existence in 1996, 2,966 were single-bond credit unions. By 2011, this number had fallen to 1,322, while aggregate assets increased from $33 to $99 billion.Footnote 7 Credit unions with community fields of membership increased in number from 361 in 1996 to 1,162 by 2011, with aggregate assets rising from $10 to $158 billion. Finally, the number of multiple-bond credit unions fell from 3,751 in 1996 to 1,963 by 2011, with aggregate assets increasing from $159 to $268 billion.Footnote 8 While not yet the largest category in terms of number or assets, community credit unions are clearly the fastest growing type of credit union. This study explores the impact of differences in risk across credit unions with different FOM types. These tests provide indirect evidence on the importance of diversification and information advantages across types of credit unions. Since this study examines a later period of time than Frame et al., these relationships can be assessed after the field-of-membership constraint was relaxed. It also includes a time period, 2008–2011, when financial institutions were under significant stress. Findings of risk differences related to FOM type lead to judgments on the benefits and costs of NCUA’s more liberal policy on defining common bond. In tests for differences in risk of bankruptcy and of breaching regulatory standards, credit unions with broader fields of membership: community and multiple-bond credit unions, are generally found to exhibit greater risk than single-bond credit unions. The evidence that community credit unions operate with more risk than multiple-bond credit unions is mixed. However, these differences across credit unions with different FOM types are found to diminish with asset size. This paper is organized as follows. Section 2 introduces the empirical model and discusses the data. Empirical findings are presented in Sect. 3 while Sect. 4 summarizes and presents the conclusions.",19
46.0,1.0,Journal of Regulatory Economics,25 March 2014,https://link.springer.com/article/10.1007/s11149-014-9249-8,Guaranteed return regulation: a case study of regulation of water in California,August 2014,Michael A. Crew,Rami S. Kahlon,,Male,Male,Unknown,Male,"Natural monopoly regulation offers the potential to reap the benefits of overwhelming scale economies while avoiding monopoly exploitation by limiting the price that the monopoly may charge. From the point of view of efficiency and equity, regulation offers considerable advantages. On equity grounds, price controls protect consumers from monopoly exploitation, and a firm earns a competitive return. Efficiency is more complicated. Since average costs exceed marginal cost because of scale economies, price must be set greater than marginal cost. This implies that allocative efficiency cannot be achieved. However, the benefits of scale economies are achieved and, monopoly exploitation is at least attenuated. If this were the end of the story regulation would be a great success story. It would have achieved a second-best solution. In fact, the reality is very different resulting in economists and policymakers continuing attempts to modify regulation. Indeed, there is a long history of dissatisfaction with the operation of the regulatory process that included calls for deregulation. This did not mean the abolition of rate regulation entirely, although there are notable exceptions, e.g., airlines. Concerns over the efficiency of regulation have been raised for many years by economists. Rate-of-return regulation (ROR), also known as cost of service regulation, resulted in excessive use not only of capital but of other inputs. Price cap regulation (PCR) was proposed for its superior efficiency properties PCR was applied extensively in the UK to the newly privatized network industries and is still employed widely in the postal sectors of advanced economies. By contrast PCR is not extensively employed in gas and electric utilities in the United States.Footnote 1 The problem with the application of PCR outside telecommunications and the postal sector arises from the presence of significant monopoly rents and externalities. New forms of regulation are designed to enable public policies to address environmental externalities more effectively than PCR, for example, in the case of conservation and greenhouse gases. The “new model” of regulation takes ROR in a very different direction from PCR. It softens incentives even more than ROR by attempting to guarantee returns. This paper examines what is henceforth referred to as “guaranteed return regulation” (GRR).Footnote 2 It illustrates GRR by means of a case study of its application by the California Public Utilities Commission (CPUC) specifically in the case of water. CPUC is the largest state commission in the United States and is considered to be a leader in regulatory practice. California relies heavily on regulation of its utilities as it pursues multiple objectives. The California case provides insights on the likely direction of regulation not just in California but more generally. This paper proceeds as follows. Section 2 introduces the case of California water and shows how GRR evolved. As the objectives of regulation had become much broader, GRR provided a more effective means of addressing them than ROR or PCR. Section 3 provides the definition and discussion of the properties of GRR, and draws a number of inferences not only for the future direction of regulation but also more generally for regulatory economics. Section 4 provides a brief concluding discussion.",5
46.0,2.0,Journal of Regulatory Economics,22 January 2014,https://link.springer.com/article/10.1007/s11149-013-9242-7,Idiosyncratic risk and the cost of capital: the case of electricity networks,October 2014,Dominik Schober,Stephan Schaeffler,Christoph Weber,Male,Male,Male,Male,"In regulation it is common that the costs of equity capital only include compensation for the systematic rather than also the unsystematic risk incurred by the regulated firm’s shareholders.Footnote 1 They are assumed to diversify their portfolios perfectly, allowing them to ignore the latter type of risk.Footnote 2 Financial distress costs, however, may arise from imminent insolvency or illiquidity caused by unsystematic (or idiosyncratic) risks, making it optimal for a firm to engage in costly hedging. The acknowledgement of resulting costs, in contrast to regulatory practice, is then essential. A major rationale behind this argument is the need for liquidity management to obviate costly insolvency or bankruptcy. An unregulated automobile manufacturer, for example, would include these costs in its overall profit maximization and determine a hurdle rate higher than capital costs to compensate for firm-specific risks eventually incurred. These may equally depend on the riskiness of single projects or portfolio composition. In an unregulated market, a competitive equilibrium outcome would therefore consider costs arising from idiosyncratic risks. It is then a logical consequence to acknowledge occurring transaction costs in a regulated market, compensating firms properly for bearing corresponding risks and related costs. Furthermore, this is independent of the choice between either cost plus or incentive regulation regimes. Under rate of return or total cost based rate regulation, firm-specific risk is usually borne by the customer on the basis of a “used-and-useful” criterion when an actual loss is incurred. In other words, this is a cost rollup, which attenuates visibility to the regulator and disguises risk-induced costs. In contrast, pure price or revenue-based rate regulationFootnote 3 will make idiosyncratic risk directly visible through firms’ additional spending on costly hedging. One classic example for a regulated industry is the operation of electricity networks. An operator faces some important sources of idiosyncratic risks related to uncertainty regarding the unforeseeable, stochastic failure of its production assets. For example, the relative importance of this risk will depend on the firm’s network size.Footnote 4 Given the law of large numbers, bigger network operators will have a relatively lower risk exposure than smaller operators. The latter will consequently have to spend relatively more on their liquidity management activities and suffer an economic disadvantage even when the average cost of thepure operation of the network is the same.Footnote 5 The consequence in this example is that the regulatory process may discriminate against smaller firms in the presence of such idiosyncratic risk. It is also observable in practice that smaller firms typically complain of increased pressure due to the relatively high stochasticity of cash flows after the introduction of incentive regulation. In a broader context, the costs of capital markups linked to size effects (and granted by the market) are found to be significant. For example, Banz (1981) and Fama and French (1995, 1997) find substantial average systematic risk premia for smaller firms in general. Adding to this evidence, in a study focusing on electricity network operators, Schaeffler and Weber (2013) find a significant size-related risk premium. So far, explanations of these empirically observable effects have focused on capital-raising economies through risk reduction in the part of a firm’s equity that covaries with a market portfolio.Footnote 6 In contrast, the focus in this article is on the impact firm size may have on idiosyncratic risk on the production side and the resulting impact on possible financial distress. This is not linked to any covariation with a market portfolio but nevertheless involves additional costs. The aim of this article is therefore to demonstrate the effects of the regulator neglecting idiosyncratic risk. Both the regulatory framework and physical failure are investigated in an analytical model. Resulting capital cost markups are derived. Furthermore, a simulation study based on German electricity network regulation gives insights into differences in idiosyncratic risk exposure and their impact on capital costs. Calculated markups are compared to actual current capital cost and found to be significant. Ignoring these differences is thereby shown to raise implicit discrimination issues. The contributions of this article are fourfold. First, a sound framework is developed to assess the impact of idiosyncratic risk in production on capital cost via an analysis of the liquidity management decision (Sect. 2). In line with Holmström and Tirole (2000), who investigate the nexus of investment optimization, risk and liquidity management, liquidity management here is assumed to take place after investments have been made.Footnote 7 The sequential investment-liquidity management assumption also corresponds to business practice, where two separate organizational units are typically responsible for reinvestment and liquidity management. For liquidity management, the model used in this article notably includes bank lines of creditFootnote 8 as an instrument. As these contain an upfront fee that will later reduce negative cash flows and thereby overall cash flow variation, they have clear similarities to costly hedges. Second, an analytical model of the size-dependent idiosyncratic risk source is used to derive the key result that risk exposure decreases with firm size (Sect. 3). An analytical stochastic stationary state model of network operation with perfect replacement is used to investigate the effects of size on expected costs, standard deviation of costs and the coefficient of variation as a scale-neutral risk measure. Other important cost drivers such as supply conditions (differences in load, density and so forth) are omitted to clearly demonstrate the risk-decreasing effect of firm size. Third, a Monte Carlo simulation based on representative data from more than 800 German electricity network operators is used to estimate the empirical relevance of idiosyncratic risks (Sects. 4, 5). A detailed network representation and empirically estimated failure rates are used to obtain valuable and conservative estimates of risk exposure. Fourth, by coupling the network replacement investments and resulting risk exposures with the previously developed financial and liquidity management models, the impact on capital costs is evaluated (Sect. 6).Footnote 9 This provides clear indications for regulators on how to account for size effects in price, revenue or rate of return regulation. Section 7 concludes the article.",6
46.0,2.0,Journal of Regulatory Economics,27 March 2014,https://link.springer.com/article/10.1007/s11149-014-9250-2,"Service quality, scale economies and ownership: an econometric analysis of water supply costs",October 2014,François Destandau,Serge Garcia,,Male,Male,Unknown,Male,"Many changes in organization, management mode and regulation of water utilities have recently appeared in the US and in European countries such as England and Wales, France and Italy (Ballance and Taylor 2005). The underlying objective was and is to provide better incentives to reduce costs and to save water without negatively affecting service quality. At the same time, an interest in water service quality issues has been increasing both in developed and developing countries.Footnote 1
 The economic literature on the water industry has dealt with efficiency, pricing and regulation of utilities. Many econometric studies are based on cost functions, but models that integrate service quality are not yet systematic (Feigenbaum and Teeples 1983; Saal and Parker 2001; Saal et al. 2007, among others). Nevertheless, the means invested in water network operations must be appraised according to the totality of services provided by the water utility. A more expensive water utility that provides better quality service for the consumer certainly cannot be regarded as less (cost) efficient. Hence, the introduction of quality variables may affect performance comparisons across water utilities Lin (2005). A better understanding of the link between water cost structure and service quality is in fact essential for public regulation authorities when designing policy schemes such as yardstick competition or “sunshine regulation” De Witte and Saal (2010) in order to avoid undermining more expensive services while offering a higher quality of services. This article brings new evidence on water utility costs and the multi-objective demand on regulation issues. New empirical results based on US data are found by modeling endogeneity of service quality. The diversity/heterogeneity of services is interpreted as output characteristics in a cost function with fully interactive quality variables with operating characteristics. Three criteria are considered as crucial in the cost structure of drinking water supply: customer service, network maintenance and drinking water quality, with three respective indicators: customer inquiries, network water losses and an indicator of water quality. Our contribution is not to introduce quality but, instead, to examine whether taking endogeneity more effectively into account modifies conclusions obtained on scale and network economies and, therefore, whether the recommendations suggested to managers and regulators in previous studies remain valid. Different measures of cost economies and their variation depending on network characteristics allow us to compute the efficient size of water utilities (Garcia and Thomas 2001; Torres and Morrison Paul 2006; Bottasso and Conti 2009). Furthermore, several results suggest that improvements in output quality must be accounted for to properly assess economies of scale and to emphasize the importance of quality drivers in the analysis of water industry costs Stone & Webster Consultants (2004). The question arises as to whether the service quality is the same for small utilities and for others that serve a large number of users. Yet, to the best of our knowledge, very few studies are specifically interested in the relationship between quality and economies of scale in the water economics literature. Saal and Parker (2000) estimate a total cost function and compare the measurement of scale and scope economies in the quality-adjusted and unadjusted specifications. In this article, the flexible translog form used for the estimation of the “multi-output-quality” cost function allows us to know how much quality affects cost elasticities and various network-related scale returns in the water supply industry. This paper also addresses the relationship between ownership and quality of service. The choice of ownership (or management mode) has been amply addressed in the empirical literature on water utilities (e.g., Crain and Zardkoohi 1978; Bruggink 1982; Feigenbaum and Teeples 1983; Byrnes et al. 1986; Bhattacharyya et al. 1994; Boyer and Garcia 2008). The majority of studies in the water industry have found that either private operators are less efficient or are unable to find any significant difference between them and their public counterparts Conti (2005). Even if the link between privatization (or public-private partnership) and the quality of service is a subject of debate in professional water service circles,Footnote 2 few empirical studies include this link in econometric models (Hunt and Lynk 1995; Saal and Parker 2000, 2001; Saal et al. 2007). Nevertheless, it is often argued that in competitive industries, public firms are inefficient, whereas private firms are efficient but provide lower quality service. This article does not employ stochastic frontier methods in the analysis of the efficiency of water utilities (Bouscasse et al. 2008). However, the identification of the type of ownership (private vs. publicly-owned utilities) in the variable cost function, and its combination with service quality variables, allows us to identify differences in marginal costs and in quality supply. This article is organized as follows: Sects. 2 and 3 state the assumptions of the economic model of cost and discuss their relevance in relation to the existing literature. We focus on the relationship between cost and quality. We then describe available data and variables used in the empirical application in Sect. 4. Section 5 deals with the model specification and estimation method. Our results are presented and discussed in Sect. 6, before concluding.",9
46.0,2.0,Journal of Regulatory Economics,18 April 2014,https://link.springer.com/article/10.1007/s11149-014-9251-1,The impact of socio-economic background on satisfaction: evidence for policy-makers,October 2014,Judith Clifton,Daniel Díaz-Fuentes,Marcos Fernández-Gutiérrez,Female,Male,Male,Mix,,
46.0,2.0,Journal of Regulatory Economics,06 May 2014,https://link.springer.com/article/10.1007/s11149-014-9252-0,Ownership unbundling of natural gas transmission networks: empirical evidence,October 2014,Christian Growitsch,Marcus Stronzik,,Male,Male,Unknown,Male,"Ownership unbundling has been one of the most important issues in the discussions preceding the third legislative package for European energy markets. With ownership unbundling being the strictest regulatory regime of vertical disintegration, the company that owns and operates the transmission assets is fully separated from the rest of the system, meaning that it does not participate in further business activities in retail or production and import.Footnote 1 On the one hand, the European Commission strongly argued in favor of ownership unbundling for gas and electricity transmission networks, preferring it to legal unbundling, which had been the minimum standard in the previous Directive. After having investigated the gas and electricity sectors, the Commission was dissatisfied with market outcomes, especially in the gas sector. The unbundling of transmission system operators was identified as one major obstacle to a well-functioning market environment (European Commission 2007, 2008). On the other hand, several transmission system operators (TSOs) and countries (e.g., Germany and France) opposed these efforts of the Commission, doubting the economic benefits and raising juridical arguments against ownership unbundling. The package was adopted in the summer of 2009 and entered into force in 2011, allowing now for both legal as well as ownership unbundling and leaving the choice to Member States. Though a final agreement on the package has already been reached, the question as to whether ownership unbundling is superior to legal unbundling remains on the political agenda. Therefore, the problem has not yet been solved. From an economic point of view, ownership unbundling would be preferable if it increased net social welfare. An intuitive indicator of a positive welfare effect is if the introduction of ownership unbundling leads to lower end-user prices.Footnote 2 Economic theory gives little guidance as ambiguous results are reported (cf. e.g., Laffont and Tirole 1993; Vickers 1995; Buehler 2005; Höffler and Kranz 2011). On the one hand, it is argued that the stricter that vertical separation is designed, the less incentive a network operator has to discriminate between affiliated companies and third parties. Thus, competition on down- and upstream markets will be fostered and the risk of vertical foreclosure reduced, inducing lower retail prices. On the other hand, ownership unbundling may lead to a loss of economies of scope and thus of operational efficiency. Moreover, it may decrease upstream output and therefore reduce economic welfare. The net welfare effects, however, are sensitive to model assumptions and depend on, for instance, assumptions about the intensity of competition in the downstream market, on the demand function, on the role of investments or on the design of access price regulation. Thus, the impact of vertical separation remains an empirical question. Since some countries have already established ownership unbundling (e.g., the U.K.) and others have not (e.g., France), the question can be answered empirically. In doing so, we construct a panel of 18 EUFootnote 3 countries spanning a time interval of 19 years. To isolate the effect of ownership unbundling, we gather data from national regulators and introduce a dummy variable to explicitly differentiate ownership unbundling from any other form of vertical integration or separation. In addition, we analyze the effect of other regulatory instruments on the degree of market opening, public or private ownership of the transmission system operator (TSO), negotiated or regulated third-party access (TPA) and whether any restrictions to market entry exist upstream. As regulatory reforms may need some time before becoming price effective (e.g., Joskow 2008), we also calculate the dynamic effects in terms of long-run multipliers. Additionally, we control for differences among countries’ economic performance, the structure of the gas sector (e.g., gas export and import) and the oil price, as gas contracts are indexed to oil prices in several countries. In analyzing the effect of ownership unbundling on retail prices,Footnote 4 we face various econometric challenges, i.e., cluster correlation (I), a potential endogeneity bias (II) and a small sample bias (III). Therefore, we (I) apply a static fixed effects estimator with robust standard errors (Froot 1989; Williams 2000) and the System Generalized Method of Moments estimator (system GMM, Blundell and Bond 1998), which uses lagged variables and out-of-sample variables as instruments (II). A bias-corrected least-squares dummy variable estimator (LSDVC, Bruno 2005) allows us to compensate for the small sample bias (III) in Instrumental Variable estimation. This threefold estimation strategy ensures more robust results than a single estimator strategy. Our paper contributes to the literature analyzing the effects of reforms in energy regulation on final customer prices in three ways. First, this paper is the first to explicitly model ownership unbundling. Second, in contrast to comparable previous studies, we address the potential endogeneity problem of regulatory reforms. Third, our paper is the first to identify the long-run effects of reforms by calculating dynamic multipliers as well as to address the natural lag between the introduction of a regulatory regime and the resulting effect. The remainder of the paper is organized as follows. We start with an overview of existing studies that empirically assess regulatory reforms in the energy sector. Section 3 presents the dataset and some descriptive analyses with a focus on regulatory indicators. The applied econometric approaches and the results are discussed in Sect. 4. Finally, we conclude.",14
46.0,2.0,Journal of Regulatory Economics,02 May 2014,https://link.springer.com/article/10.1007/s11149-014-9255-x,Safe harbor input prices and market exclusion,October 2014,Dennis L. Weisman,,,Male,Unknown,Unknown,Male,"In network industries such as telecommunications, electric power and railroads, it is common for an upstream monopolist to supply an input that is essential for the production of the downstream service.Footnote 1 For example, competition in telecommunications markets may be dependent upon rivals being able to access various elements of the local distribution network of the incumbent provider.Footnote 2 In electricity markets, retail competition requires access to the transmission and distribution networks of regional power companies. In the case of competition for rail services, the essential input takes the form of access to the tracks of competing railroads.Footnote 3
 A principal focus of the recent literature in regulatory economics is that of pricing essential inputs or access so as not to foreclose efficient downstream competition (Armstrong 2002; Kahn and Taylor 1994). A complementary literature explores the incentives of a vertically-integrated provider (VIP) with a monopoly in the upstream (input) market to engage in sabotage or non-price discrimination against its rivals (Mandy and Sappington June 2007; Beard et al. 2001; Mandy 2000; Sibley and Weisman 1998). In essence, these literatures address two different forms of market exclusion. The primary objective of this paper is to establish the connection between these two branches of the literature by exploring the relationship between input prices and market exclusion in a differentiated products setting. A key policy implication of this analysis is that the regulatory authority may choose to complement the common price-floor constraint with a price-ceiling constraint in order to safeguard against both forms of market exclusion. The focus of this paper is therefore not a welfare analysis per se, but rather on delineating regulatory pricing rules that protect against market exclusion to protect the integrity of the competitive process vis-à-vis individual competitors. To properly motivate the analysis, it is important to recognize that allegations of both forms of exclusionary behavior were made against incumbent telecommunications carriers in the course of implementing the 1996 Telecommunications Act. In the first example, incumbent VIPs were accused of engaging in a price squeeze in the market for digital subscriber-line through a combination of high wholesale prices and low retail prices.Footnote 4 In this case, the ratio of the VIP’s retail and wholesale margins is too low. In the second example, the incumbent VIP, Verizon, was accused of degrading the quality of access provided to a rival, thereby making it more difficult (and costly) for that rival to compete against Verizon.Footnote 5 This, of course, is a form of non-price discrimination. In this case, the ratio of the VIP’s retail and wholesale margins is too high. Whereas regulators in the telecommunications sector have recognized the need to be proactive in preventing a price squeeze through price floor constraints,Footnote 6 to date they have not sought to prevent non-price discrimination through price ceiling constraints.Footnote 7 The fact that non-price discrimination is inherently more complicated and can be difficult to detect may explain this disparate treatment. The principal findings of this analysis are fourfold. First, margin ratios that are too low give rise to inefficient market foreclosure and margin ratios that are too high create incentives for non-price discrimination. Second, there is a range of safe harbor margin ratios that simultaneously protects against both inefficient foreclosure and non-price discrimination. Third, the admissible range of the ratio of downstream (retail) margins to upstream (input) margins increases with the degree of product differentiation. Finally, in the limit as the products of the VIP and the rival become perfectly homogenous, the range of safe harbor margin ratios reduces to a single margin ratio. This single margin ratio preserves equality between the VIP’s retail and wholesale margins consistent with one of the earliest formulations of the efficient-component pricing rule. The format for the remainder of this paper is as follows. Section 2 introduces the notation and definitions. The formal model and main findings are developed in Sect. 3. Section 4 concludes. The proofs of all formal results are contained in the Appendix.",3
46.0,3.0,Journal of Regulatory Economics,29 April 2014,https://link.springer.com/article/10.1007/s11149-014-9253-z,Level of access and infrastructure investment in network industries,December 2014,Marc Bourreau,Pınar Doğan,Romain Lestage,Male,Female,Male,Mix,,
46.0,3.0,Journal of Regulatory Economics,06 August 2014,https://link.springer.com/article/10.1007/s11149-014-9256-9,Pipeline congestion and basis differentials,December 2014,Matthew E. Oliver,Charles F. Mason,David Finnoff,Male,Male,Male,Male,"Starting in the late 1970s, deregulatory actions have sought to better facilitate interstate commerce in the U.S. natural gas market. A primary rationale has been that freer markets would accommodate arbitrage opportunities, thereby integrating spot prices across regions.Footnote 1 However, pipeline congestion is not uncommon, and can undermine market efficiency by way of greater transportation costs. This, in turn, adversely impacts opportunities for spot price arbitrage.Footnote 2 An interesting complication is that this increase in costs does not originate from actions taken by the pipeline companies themselves. The Federal Energy Regulatory Commission (FERC) limits the primary market price of capacity, preventing pipeline companies from realizing higher returns from competing bidders (Marmer et al. 2007). There are two consequences. First, there is a potential for infrastructure constraints (i.e. bottlenecks) to emerge or persist.Footnote 3 Second, any scarcity rents that result from congestion are captured by primary purchasers of pipeline capacity via unregulated secondary markets: i.e. spot price-based gas transactions or releases of unused capacity at an unregulated rate. These frictions work counter to an efficient market mechanism. Network congestion is costly, and capacity constraints can magnify congestion problems. Nearly all transportation networks (highways, railroads, gas and electric utilities, etc.) are subject to capacity constraints over specific routes. The idea that congestion on a capacity-constrained network increases transportation costs is not limited to the natural gas pipeline network. De Vany and Walls (1999) investigate spot price co-integration across 11 electricity markets in the Western United States, noting that line losses and congestion imply transportation cost over a given arc on the network is an increasing and convex function of flow. Insufficient capacity relative to transport demand also generates scarcity rents for those with rights to that transport capacity, resulting in wealth transfers from commodity producers and consumers to the owners of scarce capacity. Atkinson and Kerkvliet (1986) found empirical evidence that railroads captured a significant proportion of the potential rents on low-sulfur Wyoming coal, and that rents shifted to the railroads following their deregulation in 1980. These inter-related effects of constrained capacity, congestion costs, and rent extraction limit the ability of spot price arbitrage to integrate prices across geographically distant locations. As interstate pipeline capacity is a key factor in determining the amount of natural gas that can be physically traded between markets, the relationships between capacities, flows, and spot prices are both systematic and measurable. Over the long-run, the trade-off between greater capacity and higher congestion costs is similar to the ‘adequacy problem’ in the market for electrical generation capacity.Footnote 4 In the short-run, however, a pipeline operating at capacity is unable to satisfy short-run transport demand in excess of its capacity limit, leading to potentially severe market distortions. In this paper we model and quantify the impact of pipeline capacity constraints upon natural gas spot price arbitrage. In the U.S. increased reserves, advances in extraction technology, and expanding consumption (Energy Information Administration [EIA] 2010a) have put upward pressure on the demand for pipeline transport. As a result, bottlenecks on certain segments of the pipeline network can constrain deliveries, thereby driving a wedge between the prices at trading hubs on either side of the constraint. Following MacAvoy (2007), we call the difference in spot prices of gas at two trading hubs the ‘basis differential’. To examine the determinants of these differentials, we adapt the hypotheses of existing network models to include the effects of congestion and the influence of storage. We then test the predictions using a unique dataset of price and pipeline data from the Rocky Mountain region. Our results show that as the pipeline route between two hubs becomes congested, the basis differential between their spot prices widens, sometimes dramatically so.Footnote 5
 There are broad implications associated with the persistence of wide basis differentials given the volume of natural gas transactions affected by spot prices. In 2009, of the nearly 56 trillion cubic feet (Tcf) of natural gas physically transacted in the U.S., approximately 22 % of that volume, over 12 Tcf, was transacted at daily index prices (FERC 2010). Our empirical estimates show that over a single transport route in the Rocky Mountain region, a mere 3.5 % increase in flow inflates the basis differential between two local hubs’ spot prices by nearly 23 %, implying an estimated increase in average monthly transport costs between the two hubs of roughly $315,000. The remainder of the paper proceeds as follows. Section 2 provides an overview of the market(s) for interstate natural gas pipeline capacity and transport, including discussion of the current federal regulatory structure. Section 3 describes the theoretical foundation for our analysis and the associated testable hypotheses. The empirics are presented in Sect. 4, along with further discussion of the results and their implications for the natural gas market and pipeline regulation. Section 5 concludes and offers possibilities for continuing research.",34
46.0,3.0,Journal of Regulatory Economics,14 August 2014,https://link.springer.com/article/10.1007/s11149-014-9257-8,Contingent certificate allocation rules and incentives for power plant investment and disinvestment,December 2014,Christoph Weber,Philip Vogel,,Male,Male,Unknown,Male,"Tradable permits have been considered as a first best instrument for cost efficient emission abatement for a long time (cf. Coase 1960; Tietenberg 1985), but various issues of market design have to be carefully investigated when putting this instrument into practice (e.g. Ellerman et al. 2010). The sectors and gases included in the trading system are one key design issue, which may considerably affect the efficiency of the trading system (e.g. Betz et al. 2010; Dijkstra et al. 2011). Yet another key issue are the rules for primary allocation of certificates. Theory clearly indicates that auctioning is efficient and pure (lump-sum) grandfathering schemes are also—at least in a partial equilibrium setting without consideration of distorting taxes (cf. Böhringer and Lange 2005b; Goulder 1995 and others). Yet many schemes proposed so far in practice—notably for the first and second period of the European ETS—foresee cost-free allocation of certificates contingent on various parameters (e.g. Betz et al. 2006). The European Commission prescribed that a maximum of 5 % of all allowances in the first (2005–2007) and 10 % in the second trading period (2008–2012) could be auctioned, the larger part of the allowances had to be distributed for free. For the period after 2012, the European legislation has implemented full auctioning for the electricity industry (cf. EU 2009). Yet other proposals around the world, including the former Waxman–Markey bill in the US (cf. US House of Representatives 2009) and the Californian Cap-and-Trade program, the latter taking effect in 2013, envisage allocations free of charge for future periods. Contingent allocation schemes have been analyzed previously among others by Fischer (2001), Böhringer and Lange (2005b), Ellerman (2008) and Fowlie (2011). Yet the focus here is on the technology contingent allocation of emissions certificates as practiced in a number of EU countries including notably Germany. Here in particular the discrimination between gas and coal power plants in certificate allocation can be seen as an example for contingent allocation of permits based on benchmarks. Another salient feature of the EU ETS certificate allocations has so far been forfeiture of allowances when facilities are closed. The present paper proposes a partial equilibrium model in MCP format with endogenous investment and \(\hbox {CO}_{2}\) prices for analyzing the longer-term impact of these regulations. Analytical insights on the distorting effects of these provisions are derived for the two-technology case. The model also specifically takes into account the merit-order and peak-load pricing mechanisms which are characteristic for the electricity industry. The existence of thresholds is thereby demonstrated, which trigger not only price distortions but also shifts in the operating capacities. Additionally a numerical application compares the impact of typical allocation schemes in an overall European market setting. The main contribution of this article is to show how typical permit allocation rules, applied within an ETS, distort long-term pricing and investment on power markets. In particular it is shown that free allocation of certificates to operating plants is likely to provide distorting incentives for investments. Consequently, marginal abatement costs within the ETS are increased above efficient levels and new power plant investments may crowd out excessively older power plants. Notably any fuel specific benchmark is shifting relative costs of different generation technologies. In Sect. 2 we discuss relevant permit allocation rules for the electricity industry and the existing evidence in the literature. Section 3 develops a partial equilibrium model for the electricity market in connection to the certificate market. Then analytical insights are derived for simple two-technology cases in Sect. 4 followed by a numerical application to the case of the EU at the time horizon 2015 in Sect. 5.",9
46.0,3.0,Journal of Regulatory Economics,26 August 2014,https://link.springer.com/article/10.1007/s11149-014-9258-7,Subsidies for renewable energy in inflexible power markets,December 2014,Orvika Rosnes,,,Unknown,Unknown,Unknown,Unknown,,
47.0,1.0,Journal of Regulatory Economics,25 September 2014,https://link.springer.com/article/10.1007/s11149-014-9260-0,Testing regulatory regimes for power transmission expansion with fluctuating demand and wind generation,February 2015,Wolf-Peter Schill,Jonas Egerer,Juan Rosellón,Unknown,Male,Male,Male,"The European Union (EU) is undergoing a transformation of its energy system toward a highly renewable-based system. The European power system should be largely carbon-neutral by 2050 in order to reach the ambitious two-degree-goal, according to which global average surface temperature should be prevented from rising more than 2 degrees Celsius above pre-industrial levels. Along with substantial energy efficiency improvements, a promising strategy for decarbonizing the electricity sector is the large-scale expansion of renewable energy sources (RES) such as wind and solar power. Wind power has two main characteristics. On the one hand, the geographical distribution of wind power resources is uneven. For example, the best European wind resources are mainly located along shorelines and off-shore. On the other hand, wind has severely fluctuating generation patterns.Footnote 1 Its large-scale integration into electricity systems thus requires substantial upgrades and extension of existing transmission networks in order to connect distant generation sites and to even out regional imbalances due to those fluctuations. Since electricity transmission networks are natural monopolies, they need to be regulated in order to promote expansion in such a way that social welfare is also optimized. Network owners have no incentives for removing transmission bottlenecks if this reduces their profits in the form of congestion rent losses. Thus, incentive compatible network expansion must be ensured through economic regulation. The regulation of transmission operations and expansion is widely discussed by regulatory economists. Finding optimal mechanisms is difficult given the specific physical characteristics of electricity networks such as negative local externalities due to loop flows, i.e., electricity flows obeying Kirchhoff’s laws. A range of different regulatory schemes and mechanisms have been proposed and applied (Léautier 2000; Kristiansen and Rosellón 2006; Tanaka 2007; Léautier and Thelen 2009; Hogan et al. 2010). However, there is little research on optimal transmission regulation when realistic demand patterns and fluctuating renewable power are considered. In this applied paper we aim to enhance the economic understanding of how to regulate and expand transmission networks in the context of realistic demand patterns and large-scale wind power in Europe.Footnote 2 We combine theoretical research on regulation of transmission expansion with an application to Europe while also deriving policy implications. We test the recently designed Hogan–Rosellon–Vogelsang price-cap mechanism (HRV, Hogan et al. 2010), which combines merchant and regulatory structures to promote the expansion of electricity networks. Another approach to transmission expansion is traditional central planning, which may either be carried out within a vertically integrated utility or by a regulatory authority. Another alternative is traditional cost-of-service regulation. In contrast, transmission decisions can also be determined in a totally decentralized, non-regulated way. We are then interested in the relative performance of these various regulatory regimes on transmission network expansion. In all cases, transmission output is defined as financial transmission rights, which are assumed to be auctioned off by a transmission company (Transco). We apply these mechanisms to a stylized model of the Western European transmission network. The transmission model represents real power flows, which allows for the inclusion of specific electricity network characteristics such as loop flows. We explicitly include both an hourly time resolution and fluctuating wind power, which substantially increases the real-world applicability of the approach. We solve the model numerically and compare welfare outcomes and the optimal levels of network expansion for a baseline and some sensitivity analyses. We also examine the drawback of applying a simplified model, which has been used in previous literature, based on average levels of load and wind power. To do so, we solve the simplified model and evaluate its extension outcomes under the actual fluctuations of load and wind power. We find that network extension in Western Europe not only increases social welfare due to diminished congestion, but also leads to price convergence and therefore a large redistribution of social welfare.Footnote 3 Comparing different regulatory approaches, we find that a combined merchant-regulatory regime leads to welfare outcomes that are close to the optimum achieved by a social planner, and far superior to other modelled alternatives. We show that this result is robust over all modelled cases. We also find that the combined merchant-regulatory regime leads to a situation in which a substantial portion of the Transco’s income consists of a fixed tariff part. The intertemporal rebalancing of the two-part tariff carried out by the Transco, so as to expand the network, is such that the fixed fee is considerably higher than the decrease of the variable part. The fixed tariff part also turns out to be relatively large compared to extension costs, a distributive issue that might be addressed through a proper choice of weight of profits in the welfare criterion. Yet exploring these distributive issues in detail is beyond the scope of this article and is left to further research. As for model simplifications, we find that these severely distort results on the relative performance of different regulatory approaches. The remainder of the paper is structured as follows. Section 2 reviews the relevant literature. Sections 3 and 4 introduce the model and its application to a stylized Western European example. Results are presented and discussed in Sect. 5. We start with baseline assumptions (5.1), followed by three sensitivity analyses which reflect different assumptions on extension costs (5.2), increased wind capacity (5.3), and different discount rates (5.4). The drawback of using a simplified model is evaluated in Sect. 5.5. The last section summarizes and concludes.",17
47.0,1.0,Journal of Regulatory Economics,21 August 2014,https://link.springer.com/article/10.1007/s11149-014-9259-6,Overusing a bypass under cost-based access regulation: underinvestment with spillovers,February 2015,Keizo Mizuno,Ichiro Yoshino,,Male,Male,Unknown,Male,"Many theoretical and empirical studies indicate that access regulation reduces the incentive for incumbents to deploy and/or upgrade their telecommunications infrastructure. Hausman (1997, 1999) and Pindyck (2007) suggest that a regulated access price based on a forward-looking cost methodology is one of the main driving forces of underinvestment in infrastructure upgrades because such an approach ignores the irreversibility of capital investments. Chang et al. (2003) report that the total-element long-run incremental cost (TELRIC) method of access pricing has not induced broadband investment in European telecommunications markets. Based on a sample of OECD countries, Bouckaert et al. (2010) find that mandatory access obligations imposed on dominant incumbents have a negative effect on broadband penetration and that the “ladder of investment” approach might not provide good guidance for broadband penetration.Footnote 1
 When considering the effect of access regulation on infrastructure investments, the existence of a bypass (i.e., a substitute for an incumbent’s infrastructure) cannot be ignored, as a bypass confers an alternative way for entrants to provide services to consumers. In access regulation, an incumbent is usually required to provide access to its network at a regulated access price, while competing firms that own bypasses are not subject to the same access regulation. For example, the 1996 Telecommunications Act in the US (the 1996 Act) required incumbent local exchange carriers (ILECs) to unbundle their networks into sets of elements and lease those sets to potential entrants, while cable television companies remained unregulated. Similarly, in the Netherlands, only Digital Subscriber Line (DSL) operators must provide access at a regulated price, whereas cable networks remain unregulated under Significant Market Power (SMP) assessments.Footnote 2
 This paper provides an explanation of how underinvestment in infrastructure upgrades is aggravated under cost-based access regulation. It is shown that although a regulated cost-based access charge encourages an entrant to select productively efficient technology, it also induces an incumbent to underinvest in infrastructure. We then demonstrate that in addition to the efficiency of a bypass technology and an incumbent’s investment cost, the degree of spillover that arises from the access to infrastructure matters with respect to more pronounced underinvestments in infrastructure upgrades. Here, the degree of spillover refers to an entrant’s ability to provide value-added services such as audio, video, and interactive TV through fiber-optic cable networks (i.e., upgraded infrastructures). We show that from a welfare perspective, an incumbent’s underinvestment induces the overuse of a bypass by an entrant that chooses productively efficient technology, when there is a large degree of spillover (i.e., an entrant’s ability to provide value-added services is high), the production cost of the bypass is low and the incumbent’s investment cost is high. Then, the overuse of a bypass aggravates the incumbent’s underinvestment in infrastructure upgrades, which generates a vicious cycle of underinvestment in infrastructure upgrades. Our findings are illustrated as follows. In our model, infrastructure investments contribute to social welfare by upgrading the quality of the final goods supplied not only by a regulated incumbent but also by an entrant through spillovers, whereas bypass technology provides a cost-reducing benefit to the entrant. When a cost-based access charge is set by a regulator, an entrant chooses productively efficient technology because it is a proper signal for productive efficiency under quantity competition in a retail market. However, the incumbent is not sufficiently rewarded for its investment in infrastructure upgrades under a cost-based access charge. Insufficient rewards for investments induce the incumbent to underinvest in infrastructure upgrades. Then, the incumbent’s underinvestment makes the spillover benefit to an entrant small, which is reflected in the productive inefficiency of access. Hence, this small spillover benefit induces the overuse of the bypass by the entrant that chooses productively efficient technology, especially when the production cost of the bypass is lower than the incumbent’s production cost. The overuse of the bypass by the entrant decreases the incumbent’s profits, which in turn further reduces the incumbent’s incentive for investment. This implies a vicious cycle of underinvestment in infrastructure upgrades. Similarly, we provide another story of a vicious cycle of underinvestment when the degree of spillover is small (i.e., an entrant’s ability to provide value-added services is low) in addition to the bypass’ low production cost and the low investment cost. In this case, there is room for an entrant to enter the market by using a bypass technology, because underinvestment due to a cost-based access charge results in the advantage of bypass over access. However, when the degree of spillover is small and the investment cost is low, a large investment by a monopoly (foreclosure) is desirable from a welfare perspective. Thus, excess entry with the overuse of a bypass occurs in this case. Excess entry with the overuse of a bypass reduces the incumbent’s profit further, and the incumbent’s incentive for investment declines even more as long as the degree of spillover remains small. Therefore, this case also produces a vicious cycle of underinvestment. Our analysis indicates that in equilibrium, a vertical market structure (access vs. bypass) and a horizontal market structure (duopoly vs. monopoly) are endogenously determined by the combined effects of the incumbent’s underinvestment and the entrant’s strategy under access regulation. Our research relates to the studies of Sappington (2005), Gayle and Weisman (2007), and Mandy (2009) in that the market structure is determined by the technological choice made by entrants (i.e., access or bypass) under access regulation. Sappington (2005) offers a striking result for the role of a regulated access charge when there is a bypass: given an access charge and an opportunity for entry followed by retail competition, an entrant’s make-or-buy decision (i.e., the entrant’s decision to access an incumbent’s infrastructure or to use its own bypass technology) can always be productively efficient regardless of the level of the access charge, which is a so-called “irrelevance result”. However, Gayle and Weisman (2007) show that the competition mode in the retail market in Sappington’s model (i.e., Hotelling-type competition) is crucial to the irrelevance result. In fact, the authors show that, under Cournot competition, the difference between the access charge and the input production cost associated with bypass matters to the entrant’s choice of productively efficient technology. Mandy (2009) presents the necessary and sufficient conditions for the access charge to induce efficient make-or-buy decisions under retail price competition with general demand and cost structures. More recently, Bloch and Gautier (2012) show that allowing an incumbent to set the access charge revives productive efficiency. However, each of these studies excludes the possibility that an incumbent invests in infrastructure upgrades. In this paper, an incumbent’s investment in infrastructure upgrades affects the opportunities for entry under access regulation with a cost-based access charge. We then show that its underinvestment induces the overuse of a bypass from a welfare perspective, even though an entrant’s make-or-buy decision is productively efficient.Footnote 3
 In addition, our paper differs from the existing literature in that we introduce an upstream firm that provides bypass as an outside option for entrants. Earlier studies have implicitly assumed that entrants themselves own a bypass technology.Footnote 4 However, in the real telecommunications market, we have also found transactions between an upstream firm that owns a bypass and an entrant in the retail market. For example, the Japanese Internet (or broadband) market is a bypass environment in which an upstream firm provides bypass technology to entrants. At the end of June 2006, 64.6 % of fiber cables had been built and were owned by the dominant companies (viz., NTT East and West), but the usage charge for their fiber cables was constrained by access price regulation. KDDI, the second largest telecom company in Japan, which had previously used NTT’s fiber cables to provide Internet services, finalized an agreement with PoweredCom for the use of its fiber cables as a bypass technology. The wholesale price for the use of this bypass technology was unregulated. Ultimately, KDDI and PoweredCom agreed to a vertical merger in October 2005. Our modeling strategy regarding a bypass environment, as illustrated in that example, allows us to examine how a vertical market structure is endogenously determined through an entrant’s incentives not only to use bypass technology but also to merge with an upstream firm that owns the bypass technology. In fact, we concisely discuss in a later section the possibility of a vertical merger between an entrant and an upstream firm that owns the bypass technology. In this paper, we restrict our attention to the case in which a regulator sets a cost-based access charge, and we demonstrate the possibility of an aggravation of underinvestment in infrastructure upgrades. Some candidates for optimal access charges that alleviate underinvestment are already proposed in the existing literature. We therefore discuss those candidates and compare their performance in a later section. The remainder of this paper is structured as follows. Section 2 explains the model framework. Section 3 provides the analysis and our main result that a vicious cycle of underinvestment occurs under access regulation. In Sect. 4, we discuss how underinvestment is alleviated under access regulation. Section 5 concludes the paper.",
47.0,1.0,Journal of Regulatory Economics,17 October 2014,https://link.springer.com/article/10.1007/s11149-014-9262-y,Consumer benefits of reforming a state-dominated industry,February 2015,Heechul Min,,,Unknown,Unknown,Unknown,Unknown,,
47.0,1.0,Journal of Regulatory Economics,05 December 2014,https://link.springer.com/article/10.1007/s11149-014-9264-9,The political economy of energy tax differentiation across industries: theory and empirical evidence,February 2015,Niels Anger,Christoph Böhringer,Andreas Lange,Male,Male,Male,Male,"Over the last decades, energy taxes have played a growing role in environmental policies of OECD countries. As a common feature, energy tax rates are differentiated across industries. Taxation typically discriminates in favor of energy-intensive industries including complete tax exemptions as an extreme case (OECD 2007). The differentiation of tax rates for an energy carrier whose combustion triggers uniformly dispersed pollutants such as \(\hbox {CO}_{2}\) contradicts basic principles of cost-effective environmental regulation. In this paper, we show how political economy considerations may explain the differentiation of energy tax rates across industries. Previous analysis of tax differentiation across industries has focused on the efficiency implications of international spillover effects. Hoel (1996) shows that differentiated taxes may be desirable to counteract emission leakage in the case of unilateral regulation. Tax differentiation across industries might also be motivated by market power of large open economies which strategically exploit terms of trade at the expense of trading partners (Krutilla 1991; Anderson 1992; Rauscher 1994). Quantitative evidence to back these theoretical arguments, however, is rather scant. Drawing on simulations with a computable general equilibrium model based on empirical data, Böhringer et al. (2014) conclude that “in many cases the simple first-best rule of uniform emission pricing remains a practical guideline”. In this vein, Böhringer and Rutherford (1997), Babiker et al. (2000), or Kallbekken (2005) identify substantial efficiency costs from differentiating the tax rate on a fossil energy carrier across sectors. This paper adopts a political economy perspective on energy tax differentiation. We investigate the role of interest groups for energy tax differentiation both in a theoretical as well as an empirical setting. For our theoretical analysis, we adopt the common agency approach by Grossman and Helpman (1994) to explain energy tax differentiation by lobbying efforts when aggregate energy consumption (as a proxy for environmental targets) is fixed.Footnote 1 We demonstrate that, ceteris paribus, a sector with larger lobbying efforts faces lower energy tax rates than sectors with smaller lobbying efforts. More specifically, we find that differences in the ease of energy demand reductions across industrial sectors explain the pattern of tax differentiation: If the government is sufficiently amenable to lobbying efforts, then industries with relatively inelastic energy demands (i.e., a higher incidence from uniform energy taxation) will face lower tax rates. For the empirical testing of our theoretical predictions, we employ a cross-sectional regression analysis of the German environmental tax reform which was implemented between 1999 and 2003. A central feature of Germany’s environmental tax reform is energy tax differentiation in favor of energy-intensive firms. The regression results support the findings of our theoretical analysis on the critical role of energy demand elasticities. Our study is related to previous research on political economy determinants of environmental taxation: Frederiksson (1997) and Aidt (1997, 1998) investigate the implications of international competition and revenue recycling for the design of environmental tax reforms. Cremer et al. (2004) adopt a voting model to analyze how political support for environmental taxes depends on the revenue rebating scheme. Polk and Schmutzler (2005) present a theoretical model where two interest groups can lobby for a general tax rate or sector-specific favors. To our best knowledge, our analysis constitutes the first quantitative assessment of the role of interest groups in energy (environmental) tax differentiation. Previous empirical studies have analyzed the role of lobbying with respect to other environmental policy instruments such as “command and control” regulation or the allocation of emission permits. Fredriksson et al. (2004) assess the effect of corruption and industry size on energy efficiency regulations. They find that higher costs for lobby group coordination (i.e., larger sector size) increase energy policy stringency, while greater corruptibility of policy makers reduces it. Joskow and Schmalensee (1998) investigate how the American Congress, influenced by various special interests, distributed \( \mathrm{SO{_2}} \) allowances among electric utilities under the U.S. acid rain program. A complementary study by Burkey and Durden (1998) on this program confirms that financial contributions significantly influenced the voting patterns of politicians. In a similar vein, Hanoteau (2003) measures the level of rent-seeking efforts by contributions from Political Action Committees and shows that industrial lobbying can influence the allocation of emission allowances. The remainder of this paper is organized as follows. In Sect. 2, we describe our common agency framework and derive differentiated energy taxes under political economy considerations. In Sect. 3, we present our empirical analysis on determinants of energy tax differentiation for the case of Germany. In Sect. 4, we conclude.",6
47.0,1.0,Journal of Regulatory Economics,02 December 2014,https://link.springer.com/article/10.1007/s11149-014-9265-8,Voluntary agreements and private enforcement of environmental regulation,February 2015,Christian Langpap,,,Male,Unknown,Unknown,Male,"During the previous two decades policy makers have increasingly relied on Voluntary Agreements (VAs) to improve environmental quality as a complement to both conventional command-and-control regulation and market-based alternatives such as pollution fees or tradable permits (Alberini and Segerson 2002; Glachant 2007; Dawson and Segerson 2008; McEvoy and Stranlund 2010). This shift has come about for a variety of reasons. First, there is growing recognition of the inflexibility of traditional standard-based regulation and increasing doubts about its effectiveness. At the same time, regulators have recognized the difficulty and cost of designing and implementing incentive-based instruments for large numbers of sources (Khanna 2001). Second, regulatory enforcement is notoriously difficult for a variety of reasons, as documented by a large body of literature (see Heyes 2000 for a review). The Environmental Protection Agency (EPA) is tasked with implementing an increasingly complex body of legislation in an environment characterized by a large number of polluters and growing political resistance to regulation. Furthermore, technological change has rendered pollution abatement equipment increasingly sophisticated and costly. This in turn has generated incentives for regulated firms to further oppose regulatory enforcement, making it more costly and difficult (Lyon and Maxwell 2004). Finally, these mounting enforcement challenges have been accompanied by shrinking real budgets and enforcement staffing levels for the EPA (Lyon and Maxwell 2004; Gray and Shimshack 2011). The combination of these factors led the EPA to promote the use of VAs starting in the early 1990s as an attempt to lower regulatory costs and overcome increasing difficulties in implementing existing environmental laws (Lyon and Maxwell 2004). VAs promise to address these concerns through potential cost savings due to increased flexibility, better cooperation between regulators and polluters, and improved environmental outcomes. However, critics fear that the voluntary nature of the agreements and the fact that they are mostly not enforceable can translate into decreased pollution abatement effort. There is also concern that, by focusing on the firms most willing to participate and hence to abate pollution, VAs can shift the focus of regulators away from more problematic polluters (Alberini and Segerson 2002; Glachant 2007). VAs can take different forms, but a common underlying characteristic is that firms offer to improve their environmental performance without an explicit legal obligation while the regulator corresponds by offering rewards such as public recognition, technical assistance, or regulatory relief. The most common types of VAs are public voluntary programs and negotiated agreements. In a public voluntary program the regulator sets both the requirements and the rewards of the program, and firms can choose whether to participate or not. In a negotiated agreement, abatement targets and rewards are determined by negotiation between the regulator and the firm.Footnote 1
 In this paper I focus on a type of negotiated agreement in which the regulator offers regulatory relief for the participating firm in exchange for environmental improvements. Specifically, as part of the VA the regulator commits to giving up “letter of the law” compliance with an existing environmental statute in return for environmental performance exceeding what traditional regulation, constrained by practical and budgetary limitations in enforcement, is expected to produce. For instance, participating firms may be allowed flexibility in developing pollution abatement strategies in lieu of existing regulatory requisites, even if these strategies lead to noncompliance with a narrowly defined statutory requirement. This may be acceptable to the regulatory agency if costs and practical or political limitations constrain its ability to monitor individual polluters’ compliance with the regulatory standard or to pursue violations.Footnote 2 Under these circumstances, such alternative abatement strategies may lead to better environmental outcomes than can be expected from imperfect regulatory enforcement. The closest example to this type of agreement is Project XL, introduced in 1995, in which the Environmental Protection Agency (EPA) waved existing regulatory requirements for participating firms in return for these firms achieving “superior environmental performance” (Marcus et al. 2005). An important caveat in such an arrangement arises when the regulator does not have explicit statutory authority to provide this kind of regulatory relief. In this case, the VA can leave the firm more vulnerable to legal challenges by environmental advocacy groups, who seek to ensure compliance with statutory requirements through citizen lawsuits (Mank 1998; Delmas and Mazurek 2004).Footnote 3 This is a key characteristic of the institutional context of negotiated VAs, which can have important consequences for the viability of these programs and the environmental outcomes they yield.Footnote 4 In fact, the possibility of citizen enforcement may help explain the relative lack of popularity of these programs in the U.S. (Khanna 2001).Footnote 5 For instance, great expectations were built around Project XL, which was billed as a prototype for a new approach to environmental regulation and as the flagship of the EPA’s regulatory reinvention initiative. Yet, Project XL failed to elicit significant interest from regulated firms and in general fell short of policy makers’ expectations. The threat of citizen lawsuits is often cited, without a formal argument, as one of the main causes for this lack of success (Boyd et al. 1998; Mank 1998; Caldart and Ashford 1999; Blackman and Mazurek 2001; Marcus et al. 2002; Lyon and Maxwell 2004). I use a model of negotiated VAs to examine the impact of citizen enforcement on the likelihood of an agreement and on the outcome of a VA. I build on the framework developed by Segerson and Miceli (1998) and introduce random compliance to allow for the possibility that alternative pollution abatement strategies agreed to as part of a VA may lead to regulatory noncompliance by the participating firm. I assume that the regulator agrees not to enforce the regulation, and that as a result an environmental advocacy group may file a citizen suit when a participant in a VA is noncompliant. I derive conditions for a VA to be an equilibrium outcome of the interaction between the firm and the regulator, conditional on the possibility of citizen enforcement. Then I use a Nash bargaining framework to characterize the abatement level that results when an agreement is reached, as well as to examine how the probabilities of agency enforcement and citizen enforcement affect the outcome of a VA. Introducing private enforcement into the model changes some key results from the received literature. I find that both the probabilities of enforcement by the regulatory agency and of private enforcement through a citizen lawsuit affect the likelihood of a VA, as well as the level of abatement when an agreement is reached. In contrast to the result in the standard model (Segerson and Miceli 1998), an agreement is not necessarily reached for any positive probability of agency enforcement, and a higher probability of agency enforcement does not necessarily increase the abatement level. This is the case only when the probability of a citizen suit in the absence of an agreement is low enough. Finally, I show that the abatement level and the net social benefits resulting from a VA exceed the abatement effort and net benefits attainable from compliance with the regulatory standard if the probability of enforcement is low enough, the expected cost from a citizen suit is high enough, and the bargaining power of the firm is low enough. In the next section I provide background on citizen suits and review the literature. In Sect. 3, I introduce the basic setup of the model. Section 4 identifies conditions for the existence of an agreement, and Sect. 5 examines the effect of agency enforcement and private enforcement on the outcome of a VA. Finally, I discuss the results and conclude in Sect. 6.",2
47.0,2.0,Journal of Regulatory Economics,04 November 2014,https://link.springer.com/article/10.1007/s11149-014-9261-z,Risk and regulation in water utilities: a cross-country comparison of evidence from the CAPM,April 2015,Roger Buckland,Julian Williams,Janice Beecher,Male,Male,Female,Mix,,
47.0,2.0,Journal of Regulatory Economics,06 November 2014,https://link.springer.com/article/10.1007/s11149-014-9263-x,Have customers benefited from electricity retail competition?,April 2015,Xuejuan Su,,,Unknown,Unknown,Unknown,Unknown,,
47.0,2.0,Journal of Regulatory Economics,09 December 2014,https://link.springer.com/article/10.1007/s11149-014-9266-7,Weak versus strong net neutrality,April 2015,Joshua S. Gans,,,Male,Unknown,Unknown,Male,"Net (or network) neutrality has been a concept discussed in the United States for over a decade (Wu 2003; Lee and Wu 2009). It relates to a principle that Internet Service Providers (ISPs) or any other network operator on the Internet should not be able to create conditions under which consumers would be induced to favour some content providers (CPs) over another.Footnote 1 At times, this has evoked the notion that CPs should not pay for access to consumers while at others it is that CPs should not face charges that are discriminatory with respect to one another or related to the quality of the experience their consumers receive. Most recently, this issue has emerged with Netflix (a streaming video supplier) paying Comcast (a large US ISP) for a higher quality route or ‘fast lane’ to its consumers. However, the notion of content-based price discrimination has also emerged with respect to deals with some ISPs (especially outside of the US) to allow consumers to access services such as WikipediaFootnote 2 or Facebook without charge on mobile devices and AT&T considering offering that option too if a CP pays them directly.Footnote 3
 The debate has focussed on numerous dimensions. From the principle of neutrality expressed above to concerns that restricting the ability of ISPs to engage in price discrimination or offer different quality products might impact adversely on infrastructure investment. Finally, there is a concern that ISP discrimination options may lead to barriers to CPs themselves to invest; particularly, in new services. This may come because of a lack of affordable access, consumers shying away from lower quality services or from hold-up whereby ISPs increase charges as CPs become more successful. This is of particular concern where ISPs themselves are integrated CPs perhaps in competing non-Internet services such as cable television or media production. This paper is designed to bring some clarity to the debate. First of all, rather than speculate on what rules might enshrine certain principles of behaviour—namely, can we have a commercial Internet whereby consumers do not internalise ISP pricing when choosing how to allocate their attention?—here I evaluate these issues using economic criteria. Specifically, how do various price regulations impact on consumers’ actual allocation of attention and its comparison to a socially optimal allocation? Finally, how do various regulations impact on ISP or CP investment in their activities? Thus, this paper is as much about the effectiveness of proposed regulations as it is about their expected impact. Second, while there is an existing formal literature that asks questions similar to those just specified, that literature has several difficulties that have made applying it to this debate difficult; let alone comparing alternative claims made in those debates. For one, the starting point for that literature is to assume that CPs do not have a direct monetary relationship with consumers. With respect to recent streaming video issues, this is an unreasonable assumption. Thus, here I start with the situation where CPs set prices to consumers directly.Footnote 4 In addition, that existing literature assumes that consumers do not pay ISPs for services that involve different charges depending upon what type of content they access. While this is an accurate depiction of the initial period of the US commercial Internet, it is not an accurate depiction elsewhere or for the mobile Internet. While ISPs have not engaged in content-specific charging to consumers per se, they have imposed download caps that, for bandwidth intensive content, impact on consumer choices as to what content to consume. Consequently, these prices now and perhaps into the future will impact on the consumers’ allocation of attention. For that reason, it is explicitly considered here. The final aspect where the existing formal literature falls short is that it is complex in its analysis. As is standard in industrial organisation in academic economics, there is a push towards generality of the analysis but, despite abstracting away from consumer charging of the forms described above, the formal models have not been conclusive in their recommendations and, indeed, they have identified a plethora of effects that have made building intuition difficult. This is not to say those models are unimportant or unrealistic. Far from it. My contention here is that a simpler, less realistic model can demonstrate some first-order insights regarding the net neutrality debate. However, the analysis also confirms that such regulations have benefits and costs. The aim here is to more clearly identify these rather than make a definitive policy recommendation per se. To this end, this paper provides an unashamedly simple model with a single ISP, two CPs and a consumer. There is no nuance on demand from the consumer (they can allocate their attention to one CP or another). There is no detailed analysis of network priority rules and there is no close examination of alternative pricing structures and download caps—everything is comprised of a set of simple transfers for services. However, in the process, I believe a number of useful insights can be gathered. First, in this model with a flow of payments between different entities, we can distinguish between weak net neutrality (whereby content-based price discrimination is outlawed in single relationships) and strong net neutrality (whereby it is outlawed altogether). In so doing, I demonstrate that only strong net neutrality leads to real effects; in particular, over the allocation of profits between the ISP and content providers. Moreover, it does not impact at all on the consumer allocation of attention that remains socially optimal regardless of regulatory regime. This is because the price between CPs and consumers mediates this and other payments ultimately do not distort it. Consequently, neutrality regulation is itself neutral in important ways. Second, where there is no price between consumers and content providers, certain forms of neutrality regulation can lead to real effects on the allocation of consumer attention. In this case, strong net neutrality can cause consumers to choose a socially sub-optimal allocation. This is because the socially optimal allocation includes both the consumer’s value on the service and the CPs’ earnings from advertising and the like. In the absence of sufficient pricing flexibility, that latter component does not factor into consumer choice, even indirectly, and hence, they may, under some circumstances, choose a sub-optimal allocation. Moreover, it is shown that this reduces surplus for all parties. Third, when net neutrality regulation is effective (i.e., under strong net neutrality), then there is a transfer for surplus from the ISP to content providers and, moreover, the surplus retained by content providers is related to their marginal value in the market. Hence, we can expect that dynamic efficiency, in terms of content provider investment, will be enhanced by strong net neutrality rules. At the same time, it is demonstrated that net neutrality regulation (of any form) does not impact on the incentives of ISPs to improve network quality. Consequently, this suggests that claims that price flexibility is required to ensure that such investment takes place is not supported by this model. Finally, it is demonstrated that ‘fast lanes’ as a means of counteracting strong net neutrality will only do so imperfectly. There is no first-order prediction that CPs will be unable to capture the surplus they would if a fast lane option did not exist but, at the same time, ISPs will be able to capture the increment from providing a higher quality service. That said, if ISPs were to be compelled to offer fast lanes at the same price as slow lanes, there is an increased likelihood that CPs will appropriate their full marginal value if the value they provide to consumers is complementary with network quality (as it may be for streaming video). Finally, I examine what happens when there is ISP competition. Not surprisingly, such competition allows consumers to appropriate more surplus. However, more subtly, because consumers operate at the edge of the Internet and are, in effect, monopoly suppliers of their own access, net neutrality regulations simply have no effect. The consumer’s chosen ISP becomes their agent in propagating that monopoly power and so CPs appropriate no surplus. This suggests that claims that competition amongst ISP would eliminate the importance of the issue are more nuanced than is generally thought. The paper proceeds as follows. Section 2 presents the baseline model, definitions and the first result that weak net neutrality regulation is itself neutral. Section 3 then relaxes assumptions and considers when such regulation does, in fact, have real effects. Section 4 then looks at dynamic issues including investments by ISPs and CPs. Section 5 adds ISP level competition to the model to see if this changes the earlier results on the effectiveness of net neutrality regulation. A final section concludes.",34
47.0,2.0,Journal of Regulatory Economics,15 January 2015,https://link.springer.com/article/10.1007/s11149-014-9267-6,Prices based on current cost or historical cost: How different are they?,April 2015,Timothy J. Tardiff,,,Male,Unknown,Unknown,Male,"In response to the 1996 Telecommunications Act, the Federal Communications Commission (FCC) ordered that the rates incumbent local exchange carriers (ILECs) could charge for certain wholesale services (unbundled network elements, or UNEs) that they were required to offer to new competitive local exchange carriers (CLECs) be based on a methodology labeled total element long-run incremental cost (TELRIC). That methodology based wholesale prices on a hypothetical incumbent that served the entirety of its current volumes with completely new equipment (as opposed to the mixture of equipment of different vintages in its actual network). As such it was a major departure from the historical (or original) cost basis that had been used for decades to set regulated retail prices and since 1984 as the basis for wholesale inputs (carrier access) provided to long-distance carriers (Tardiff 2000).Footnote 1
 The FCC made two exceptions to its prescription of a current cost methodology for wholesale services used by competitive carriers. First, the Telecommunications Act required total service resale—an arrangement by which a new competitor would essentially rebrand a local exchange service provisioned over the incumbent’s facilities. The wholesale rates for these resold services are determined “on the basis of retail rates charged to subscribers for the telecommunications service requested, excluding the portion thereof attributable to any marketing, billing, collection, and other costs that will be avoided by the local exchange carrier.” (Telecommunications Act 1996, p. 252(d)(3)) Retail rates were typically based on historical costs and the FCC’s rules for determining avoided costs were also based on historical costs.Footnote 2
 Second, while current costs were used for UNEs, e.g., the wires connecting customers and the telecommunications network, the FCC continued to prescribe the use of historical costs for placing wires on utility poles and in conduit owned by ILECs and electric utilities. In addition to differences in legislative history, the FCC’s choice of historical costs for pole attachments appeared to be motivated by the objective of providing potential new entrants with relatively low prices for wholesale inputs in order to promote entry. In particular, since major components of telecommunications networks benefit from cost-reducing technological progress, there was a common belief that prices based on current costs would be lower than costs based on historical costs.Footnote 3 Conversely, because the costs of acquiring, placing, and maintaining utility poles and conduit tend to increase over time (because of their relatively low technology-intensity and relatively high labor-intensity), the use of historical cost pricing was widely believed to produce lower rates than would the use of current cost-based pricing. The FCC’s use of both current cost and historical cost methodologies recalls the debates that preceded the US Supreme Court’s 1944 FPC v Hope decision.Footnote 4 Prior to Hope, there had been fierce debates over whether regulated rates should be based on replacement (current) costs or original (historical costs), with parties advocating low rates favoring replacement costs when equipment costs were expected to decrease, but original costs when such asset prices would be expected to increase (Kahn 1988, Vol. I, pp. 39–40). The Hope decision upheld the Federal Power Commission’s use of original costs, which subsequently were widely used by federal and state regulators, to establish rates for telecommunications and other utility services (Verizon v FCC 2002, p. 484; Makholm 2012, pp. 129–132). While rates proposed (and sometimes adopted) that are based on current costs have indeed differed in the expected way from the corresponding rates based on historical costs,Footnote 5 the purpose of this paper is to demonstrate that (1) the large differences expected by conventional wisdom and often produced in practice result from faulty application of the current cost methodology and (2) proper application—namely, accounting for inflation in asset prices and the difference between current and historical cost levels when calculating annual “out-of-pocket” expenses such as maintenance and administrative costs—substantially narrows the difference between the rates produced by the respective approaches.Footnote 6 Accordingly, practical considerations, particularly the relative costs and resources imposed on the regulatory process, would appear strongly to favor original cost methodologies. The paper is organized as follows. In Sect. 2, the Hope decision (and its descendants) and the FCC’s wholesale rate decisions pursuant to the 1996 Telecommunications Act are reviewed as illustrations of the conventional wisdom that (1) when long-lived asset values are decreasing, rates based on current costs are lower than rates based on original costs, but (2) when asset values are expected to increase, rates based on current costs are expected to be higher. Section 3 reviews economic analyses that (1) identified commonly occurring errors in current cost applications that are the likely source of the different rate outcomes expected under the conventional wisdom and (2) employed current cost calculations to narrow the gap between rates based on current versus original costs. Using this analysis Sect. 4 illustrates that rates based on original and current costs should be very similar if the current cost calculation is correctly applied. Section 5 concludes the paper.",1
47.0,3.0,Journal of Regulatory Economics,01 April 2015,https://link.springer.com/article/10.1007/s11149-015-9273-3,Two-stage auction and subscription pricing for awarding monopoly franchises,June 2015,Hung-po Chao,,,Unknown,Unknown,Unknown,Unknown,,
47.0,3.0,Journal of Regulatory Economics,18 March 2015,https://link.springer.com/article/10.1007/s11149-015-9268-0,Using deferrable demand in a smart grid to reduce the cost of electricity for customers,June 2015,Wooyoung Jeon,Alberto J. Lamadrid,Timothy D. Mount,Unknown,Male,Male,Male,"Traditionally, the system operators who manage operations of the power grid have focused on managing different sources of supply and have treated the demand by customers in a relatively passive way. The daily pattern of the aggregate demand from customers on a distribution network is predictable, and the operating criterion in a typical security constrained optimal power flow (SCOPF) is to minimize the cost of supplying a predicted pattern of demand and cover a specified set of equipment failures (contingencies). Treating demand as an exogenous input for planning expansion of the grid has resulted in a situation in which the peak system load grew faster than the annual demand for electric energy. Consequently, the average capacity factors of generators have decreased over time and some units are only used for a few hours each year. Supply systems in most regions are designed to meet the Summer peak load caused by the demand for air conditioning. There are, however, already signs that conditions are changing. In the 2010 Long-Term Reliability Assessment published by the North American Electric Reliability Corporation (NERC) (NERC 2010), electric energy is forecasted to grow slightly faster than the peak demand over the next 10 years due to the electrification of the transportation sector and increased demand-side management. Hence, the important question addressed in this paper is whether the savings from deferrable demand can offset the costs necessary to bring these resources to market. Technically, it would be feasible to meet the objectives of climate change policy and energy independence and to continue with the established supply-side focus of the electric utility industry. For example, dedicated storage capacity could be installed to mitigate the variability of generation from renewable sources and the charging of electric vehicles could be controlled centrally. However, dedicated supply resources are relatively expensive because their full cost has to be justified by lowering the total cost of supply. In this respect, many deferrable demand devices have a distinct advantage because their high capital cost is largely justified by providing another energy service. This is the case for the batteries in electric vehicles and for deferrable Heating, Ventilation and Air Conditioning (HVAC) used for space conditioning. These are both potentially large sources of deferrable demand. Most of the demand management capabilities currently considered by NERC focus on responding to emergency situations and they are only used infrequently. With higher penetrations of renewable generation, however, there will be a growing need for capabilities that are always available to mitigate the inherent variability of generation from these sources. Managing demand to support the electric delivery system is an important capability that is currently underutilized. Deferrable demand can still provide customers with energy services (e.g., transportation, space conditioning and hot water) when they want them and, at the same time, reduce the overall cost of supply and still maintain the reliability of the grid. These capabilities will also have important effects on the performance of wholesale markets for electricity, by flattening daily load cycles and reducing the peak system load. Given that the capacity of the electric delivery system is designed to meet the peak system load, reducing this peak and the associated capital cost of equipment (e.g., peaking units with low capacity factors) is an important way to reduce the total system costs and the level of congestion on the grid. In contrast, the peak system load is not reduced when only supply-side solutions to problems are considered. Although utility-scale storage can mitigate the variability of generation from renewable sources and flatten the daily pattern of generation for conventional generators, the overall capacity of supply must still be large enough to meet the peak system load. For a given peak load, energy from storage simply substitutes for some conventional generation. Therefore, it is encouraging that there is now an increasing recognition by regulators that demand response and distributed energy resources (DER) are effective but underutilized ways of improving the performance of electricity markets and lowering costs to customers. For example, the State of New York Public Service Commission (NYPSC) issued an order in December, 2013 (CASE 07-M-0548 - 2013) that included the following statement: The Commission and other policy makers can no longer afford to think of energy efficiency and distributed clean energy resources as peripheral elements of the electric system that require continuous government support. Rather, the time has come to manage the capabilities of these customer based technologies as a core source of value to electric customers. In addition, full integration of load management capabilities into energy supply and grid management decisions will improve system wide reliability, efficiency, and resiliency at just and reasonable rates for New Yorkers. This initiative was endorsed by Governor Cuomo in April, 2014 (CUOMO 2014) by issuing a press release to announce a reforming energy vision (REV) initiative that included the following statement about peak demand: The best example of the value of modernizing the electric grid is the current inefficiency of peak demand. Peak demand for electricity happens on the hottest days of the Summer when electricity demand skyrockets, but only temporarily. While it is understandable and prudent to ensure that demand for energy can be met at all times, it is also inefficient and costly. As a result, consumers are now forced to spend hundreds of millions annually to maintain the full capabilities of a system that is needed only on the very hottest days of the Summer. Overall, the expectation of the REV is that utilities will actively manage and coordinate a wide range of distributed resources, or generate electricity from many small energy sources and link them together. (CUOMO 2014) The results from our earlier research in (Jeon et al. 2015) and (Lamadrid et al. 2014) using much simpler models indicates that the main thrust of the REV is a viable way to reduce customer costs. With deferrable demand controlled by a system operator, our research shows that the main savings in operating cost come from the displacement of conventional generation by spilling less wind generation and committing fewer generating units as reserve capacity. The main savings in capital cost come from reducing the amount of installed conventional generating capacity needed to maintain System Adequacy by (1) shifting load from peak to off-peak periods and reducing the peak system load, and (2) by using deferrable demand to provide ramping services and reduce the amount of conventional generating capacity needed for operating reserves. Although these results are consistent with the thrust of the REV, our current research has not considered other important types of DER, such as the effects of generation from solar panels on rooftops, for example. The analysis presented in this paper is based on a new stochastic form of multi-period SCOPF developed at Cornell (the second generation SuperOPF) and a reduced representation of the bulk power network for the Northeast Power Coordinating Council (NPCC) region. The most important features of the SuperOPF for this analysis are that (1) the stochastic characteristics of potential wind generation and load at multiple sites are incorporated, (2) the total amount of conventional generating capacity, dispatched and committed as reserves, that is needed to maintain Operating Reliability is determined endogenously (these amounts depend directly on the stochastic characteristics of potential wind generation and load), and (3) the additional ramping costs caused by wear-and-tear when ramping is delivered are incorporated into the objective function. As an example, if the use of on-site storage offsets the variability of wind generation, ramping costs are reduced and less conventional generating capacity is needed for reserves to maintain reliability. Generally, the capacity of the electric delivery system is designed to meet the peak system load in the Summer, and reducing this peak and the associated capital cost of equipment (e.g., peaking units with low capacity factors) is an important way to reduce the total system costs. The paper has the following structure. Section 2 presents background information and a review of the system development and institutional structure. Section 3 presents a general description of the stochastic multi-period SuperOPF followed in Sect. 4 by a description of the calibration for the SuperOPF, including the modeling of the stochastic inputs (potential wind generation and load) and the representation of deferrable demand (HVAC for space cooling and water heating). The results for centralized control by a system operator in a day-ahead market on a set of representative days for each season are presented in Sect. 5. They show that deferrable demand is an effective way to lower system costs by (1) flattening the daily pattern of dispatch by conventional generating units, (2) spilling less of the potential wind generation, (3) mitigating the ramping costs associated with wind uncertainty, (4) reducing the total amount of conventional generating capacity needed to maintain reliability, and (5) reducing congestion on the grid. The paper ends with the conclusions in Sect. 6 and presents some recommendations for regulatory changes that will be needed to provide incentives for making investments in deferrable demand.",13
47.0,3.0,Journal of Regulatory Economics,25 February 2015,https://link.springer.com/article/10.1007/s11149-015-9271-5,The capital structure of a firm under rate of return regulation: durability and the yield curve,June 2015,G. Kent Fellows,,,Unknown,Unknown,Unknown,Unknown,,
47.0,3.0,Journal of Regulatory Economics,18 March 2015,https://link.springer.com/article/10.1007/s11149-015-9272-4,Using discrete choice experiments to regulate the provision of water services: do status quo choices reflect preferences?,June 2015,Bruno Lanz,Allan Provins,,Male,Male,Unknown,Male,"Well-functioning markets provide a way to aggregate information across firms and consumers. By observing consumer choices, firms make decisions about innovation and quality improvements to existing products, and associated investment priorities. For utility providers operating in regulated industries, such as energy or water and sewerage utilities, the role of consumer choice is typically diminished or non-existent. As a result, decisions about the appropriate level of service and associated price-setting regulation typically cannot be based on observed market behaviour. In England and Wales, where the water industry is comprised of private regional monopolies, discrete choice experiments (DCE) (Louviere and Hensher 1982; Louviere and Woodworth 1983) are now widely applied to assess the value that consumers place on different aspects of services (e.g. the quality and reliability of water supply and sewerage services) and the management of natural resources (e.g. the ecological quality of rivers).Footnote 1 This follows from Willis et al. (2002), who suggested the use of cost-benefit analysis (CBA) to inform investment planning and price regulation.Footnote 2 The ‘exemplar’ study for valuing changes in the provision of water and sewerage services in this context is provided by Willis et al. (2005), who use the DCE approach to estimate marginal willingness to pay (WTP) for individual service attributes. This enables individual component values to be applied within CBA and inform investments across service attributes. In this paper we examine the results of a DCE survey eliciting preferences for services of a water and sewerage company in England in line with the approach demonstrated in Willis et al. (2005). In common with many DCE applications, this requires survey respondents to repeatedly choose between a status quo (SQ) option describing a situation with no changes in the services considered and two alternatives. By definition, the price associated with the SQ is zero, so that it also represents a default alternative or outside good. The treatment of SQ choices, and in particular whether they reveal meaningful preferences from consumers, is an important issue for the regulator when scrutinising business plans that propose service improvements (and associated bill impacts) from already high levels.Footnote 3 In the study we consider, the SQ was selected in 60 % of all DCE choices, and 14 % of respondents selected the SQ in all the choice occasions. As we review below, these patterns of responses are not uncommon in DCE studies.Footnote 4
 Our objective is to determine the extent to which SQ choices reflect the preferences of consumers, or alternatively contextual factors related to information provision and respondent cognition. Our survey instrument has a number of features geared towards identifying potential determinants of SQ choices. First, we elicit preferences for the SQ by recording satisfaction with the current level of service along with the general perception of how the service dimension impacts the household’s daily activities. Second, we use a split sample design to vary the description of the SQ, and test whether information on the ‘baseline’ evolution of services and bills in the future affects the trade-off between the SQ option and the alternatives on offer. Third, we test whether the survey administration mode has an impact on SQ choices by administering the survey online and through face-to-face interviews where information provision can be monitored. Fourth, we define the attribute space to span both positive and negative domains, so that the ‘price’ of the hypothetical alternatives can be both positive (for service improvement) and negative (for a service deterioration). This implies that the SQ is not necessarily the least-cost alternative. Finally, using a number of diagnostic questions, we control for respondents perceptions of the survey (e.g. the complexity of the choice tasks) and potential protest motivations.Footnote 5
 Importantly, evidence of a large number of SQ choices does not necessarily compromise the validity of DCEs as a preference revelation instrument. Indeed, as initially documented in Samuelson and Zeckhauser (1988), a tendency to stick with the SQ arises in many different settings and may thus be part of consumer’s preferences.Footnote 6 In turn, it represents important information for both companies and the regulator. However, SQ choices may also be used as a way to opt out of the exercise because of survey design effects, the cognitive burden imposed by the complexity of the choice task, or ‘protest’ against some aspect of the choice situation. Understanding whether SQ choices represent preferences or not is important because it underpins a utility-theoretic interpretation of stated choices. Given the growing use of DCEs to inform investment planning for the provision of water-related services and associated price regulation, the validity of SQ choices is directly relevant to the ex-post acceptability of company business plans. While the design of the DCE survey is based on Willis et al. (2005), our analysis of SQ choice builds on a wider literature exploring SQ choices in DCEs as initially discussed in Adamowicz et al. (1998).Footnote 7 Boxall et al. (2009) show that choice task complexity and the age of respondent are both positively related to the choice of the SQ. To some extent, Meyerhoff and Liebe (2009) confirm the role of perceived task complexity in determining SQ choices, but they also show that SQ choices reflect protest behaviour (see also Hanley et al. 2006, for a discussion). As in Meyerhoff and Liebe (2009), we use diagnostic questions to control for the perceived complexity and protest motives. In their analyses of DCE SQ choices, both Boxall et al. (2009) and Meyerhoff and Liebe (2009) rely on interacting an alternative specific constant (ASC) with potential determinants of SQ choices, which limits the number of determinants that can be tested.Footnote 8 In our analysis we directly model the probability of SQ choices, which allows us to assess a much wider range of factors. We employ this framework to provide direct evidence on the role of preference for the SQ, as measured by satisfaction with the experience service and importance of attributes in day-to-day activities. The description of the SQ has been shown to impact SQ choices in the paper by Marsh et al. (2011). Allowing respondents to use their own description of the SQ, they find that those respondents who provided their own SQ were more likely to subsequently chose the SQ. This shows that respondents may be reluctant to opt away from outcomes that they know well, but also that perception of the SQ is heterogeneous. One explanation for this feature is that the SQ differs from experimentally defined alternatives in that it has been experienced (Scarpa et al. 2005, 2007; Hess and Rose 2009). In our study, we compare a description of the SQ based on the current situation with a richer description providing detail about future evolution of services and bills, which potentially makes the SQ more comparable to the other alternatives. Finally, while all the studies cited above focus on SQ choices in individual choice tasks, we also consider the determinants of ‘serial’ SQ choices, where a respondent selected the SQ in all choice occasions. The issue of serial SQ choices has been documented in Von Haefen et al. (2005), although to our knowledge there is currently no evidence about the determinants of serial SQ choices. We show that there exist differences between motivations underlying the individual and serial SQ choices, the latter being driven mainly by cognitive factors associated with information and complexity of the tasks. We conclude that individual SQ choices reveal relevant information about customer preferences. Therefore in settings where the SQ is a viable option from a policy or regulatory perspective there should be a way for customer to reveal such preferences. However, our results also suggest that there is a case for identifying serial SQ choices and determining whether they reflect cognitive or contextual factors. Sensitivity analysis on the importance of these respondents for the wider results of the survey should be part of standard validity tests to increase confidence in the welfare estimates. The remainder of this paper is structured as follows. Section 2 describes the experimental design from which our data are derived, provides details about the administration of the survey, and reports WTP-analysis of the DCE. Our empirical analysis of SQ choices is presented in Section 3. Discussion and conclusions are offered in Section 4.",12
47.0,3.0,Journal of Regulatory Economics,17 February 2015,https://link.springer.com/article/10.1007/s11149-015-9269-z,The cost of regulation: More stringent staff regulations and nursing home financial performance,June 2015,John R. Bowblis,,,Male,Unknown,Unknown,Male,"In many instances the consumer is less informed than the firm selling a product. If the asymmetry in the information between the consumer and firm is great enough, the firm can use this informational advantage to exploit the consumer, often by lowering unobservable dimensions of quality. Mechanisms such as guarantees or warranties exist to protect consumers, but in the health care sector warranties and guarantees are not feasible because an ineffective product could result in permanent injury or death. This leaves regulation as the usual mechanism employed to assure quality in the health care sector. While regulation attempts to assure quality, it also can increase the cost of producing care. In the nursing home (NH) industry, a regulatory mechanism implemented to assure quality is the minimum direct care staffing (MDCS) regulation. Direct care is provided by nurses and empirical evidence suggests that higher nurse staffing levels could lead to higher quality of care (Konetzka et al. 2008; Lin 2014). MDCS regulations are a form of input regulation that dictates the minimum levels of nurse staff a NH must employ per resident, hopefully ensuring a minimum level of quality. More stringent MDCS regulations are found to increase nurse staffing levels (Mueller et al. 2006; Kim et al. 2009; Park and Stearns 2009; Bowblis 2011a), decrease non-nurse staffing levels (Thomas et al. 2010; Bowblis and Hyer 2013), and impact the quality of care provided at NHs (Park and Stearns 2009; Bowblis 2011a; Grabowski et al. 2011; Tong 2011). Nurses are the largest cost of providing care, so any regulation that increases the number of nurses also affects costs. While numerous studies examine the impact of more stringent MDCS regulations on staffing and quality, NH financial performance has not been examined. A few studies examine characteristics associated with better financial performance, such as quality of care (Weech-Maldonado et al. 2003), ownership (Weech-Maldonado et al. 2012), racial composition (Chisholm et al. 2013), and private equity ownership (Cadigan et al. 2014), but to my knowledge, none have examined how NH financial performance is impacted by more stringent regulations. This paper is the first to examine if NH financial performance is impacted by more stringent MDCS regulations. Moreover, this paper makes a broader impact on economics by increasing our understanding of how more stringent regulation can affect financial performance in health care industries. In addition, much of the NH literature on financial performance uses cross-sectional statistical techniques, which can lead to biased results if there are unobserved differences across NHs that are correlated with financial performance. This paper uses Medicare Cost Reports from 1999 through 2004 to construct a panel of NHs that can account for this unobserved heterogeneity. The next section of the paper provides a background on NH staffing and presents a conceptual model of staffing regulation. Section 3 outlines the data used and the empirical strategy. Section 4 presents the results while the last section concludes.",5
48.0,1.0,Journal of Regulatory Economics,27 March 2015,https://link.springer.com/article/10.1007/s11149-015-9274-2,Telephony choices and the evolution of cell phones,August 2015,Michael J. Thacker,Wesley W. Wilson,,Male,Male,Unknown,Male,"Over the last three decades, telephony markets have changed dramatically due to the divestiture of the local telephone operations of AT&T, the Telecommunications Act of 1996, and the introduction of cellular telephones. The first cell phone call was made in 1973, and in 1983 cell phones were made commercially available. While growth was initially slow, cell phone usage has expanded rapidly over the last 20 years as a result of lower prices, new service offerings, and network effects. Our primary objective in this paper is to examine the effects of the introduction and adoption of cell phones. We focus on household choices of telephony over time and by market segment. This allows us to identify growth segments and to examine the policy question of substitutability by market segment over time. We employ and extend a substitutability measure developed by Gentzkow (2007). The extension allows a decomposition of the substitutability measure by source. Our research makes two primary contributions to the literature. First, our results point directly to the impact cell phones have had on the broader telephony market and what has driven this impact. Second, we develop and apply a methodology that decomposes substitutability by source and points to the evolution of the market. This methodology can be employed to investigate substitutability in a variety of evolving markets. The landline service market has been highly regulated and the broader telephony market is one that impacts the vast majority of individuals living in the United States. In 1984, there was a divestiture of AT&T’s local landline operations after a landmark antitrust case.Footnote 1 This, along with the Telecommunications Act of 1996, brought significant regulatory effects on the landline market. The simultaneous appearance and evolution of cell phones only propagated further competitive effects on the previously uncompetitive market. One of the primary questions is to what degree the availability of cell phones limits landline pricing. As recently as 2008, the  Department of Justice (2008) reported that “The size of [the] wireless substitution effect is not known...” and “the available evidence does not establish that mobile services currently represent an effective competitive constraint on landline access pricing.” Others disagree, including  Taylor and Ware (2008) who responded that “data on price trends and substitution of cell for landline services show that mobile services currently represent an effective competitive constraint on landline access pricing.” The question needs further investigation and more definitive, quantifiable answers, which we provide. In particular, this issue comes down to the extent to which cell phone services have become effective substitutes for landline services. We estimate demand and substitutability through time and find that developments in cell phone service since the implementation of the Telecommunications Act of 1996 have changed the competitive environment for landline telephony providers. This has happened in ways similar to those discussed by Gentzoglanis and Henten (2010) when discussing intermodal competition; telecommunications networks have converged so that networks originally designed to carry one type of traffic can now carry a variety of traffic types. Indeed, these changes “have made retail markets for telecommunications services effectively competitive” (Gentzoglanis and Henten 2010). All of this points to diminished need for regulation in the landline market. There are a number of studies that examine the demand for telephony services. These studies, e.g. Train et al. (1987), examine the choice between different pricing mechanisms, i.e. measured service versus flat fee service. Rodini et al. (2003) examine the substitution of landline and cell phone service access. Macher et al. (2013) examine household choices among landline and cell phone services using a portfolio approach and data from 2003 to 2010. In our study, we observe data over a more extended period of time (1994–2012) during which cell phone use increased from less than 4 % of U.S. households to nearly 80 %. Observing these data from the Consumer Expenditure Survey (CES), we directly examine the choices made between four options of telephony service. These options are: landline, cell phone, both landline and cell, and no service. We first frame these choices in terms of socio-economic factors. We then develop a procedure to uncover prices from the CES and estimate a fixed coefficient choice model with prices and household attributes. The price proxies from the CES are consistent with the Consumer Price Index categories for the overlapping time-periods.Footnote 2 We then extend the model to allow households to place different levels of importance on prices by estimating a mixed logit. All of our specifications also include alternative-specific dummy variables, which capture effects of unobserved product attributes. We include these multiple specifications to demonstrate the robustness of our results and provide further credibility to our price proxy.Footnote 3
 In an industry that has seen so much change, it is important to understand what has driven the evolution of market demand. The usable data run from 1994 to 2012, which is substantially longer than prior studies and allow estimation that considers evolution. Using the estimates, we develop consumer profiles and trace adoption rates through time. We find that there are dramatic differences across household types in their telephony choice and adoption through time. Indeed, households of young single people are far more likely to choose cell rather than landline, while those of older people or those with larger families are more likely to choose cell phones in addition to landline phones.Footnote 4
 These results also suggest that cell phones and landlines may be substitutes for some households and complements for others. Gentzkow (2007) developed a measure to examine substitutability of hard-copy and online newspaper subscriptions, while  Macher et al. (2013) adopt it for substitutability in the telephony market. We follow Gentzkow (2007) to examine substitutability, then develop and estimate a decomposition of this measure, which extends this literature. An important feature of our innovation is its applicability in understanding changes in the telephony market with the evolution of cell phones and in providing deeper understanding about the level of competition between technologies in the market in the past and present. We provide a framework around this decomposition and its estimation that can be adopted to study other markets in which substitutability is changing through time. As technology continues to evolve across industries, our decomposition may be conducive to understanding the changing competition between firms in related markets in a variety of evolving industries. For example, we suggest the possibility that this could be used to see how mobile technology impacts competition in the cable or broadband internet market, or how evolving infrastructure impacts competition between local transportation methods such as public transit and automobile. Results from applying our decomposition provide strong evidence that the substitutability of cell phone and landline varies over time and by market segment. At the beginning of our sample period, most market segments view these two services as complementary. By the end of our sample period, most of these same market segments view these two services as substitutable, suggesting that the landline telephone market has experienced increasing competition from cell phones; this may guide regulatory-policy decisions based on the level of competition in the entire telephony market. The remainder of this paper is organized as follows. Section 2 introduces further history and details of the telecommunications industry as well as how this paper fits in to the relevant literature. The models are detailed in Sect. 3. The data source and variables for the project are discussed in Sect. 4. Section 5 presents the results of the estimation followed by Sect. 6, which concludes.",3
48.0,1.0,Journal of Regulatory Economics,01 April 2015,https://link.springer.com/article/10.1007/s11149-015-9276-0,Do control rights determine the optimal extension of liability to investors? The case of environmental policy for mines,August 2015,Ben White,,,Male,Unknown,Unknown,Male,"This paper analyses environmental policy for mining where judgement-proof firms are protected from paying environmental damages by limited liability and bankruptcy is a choice that firms and investors can make to avoid rehabilitation costs and a Pigovian tax on damaged land. With the potential for extended liability the key question is what proportion of environmental costs should be socialized (Tirole 2010). The analysis is motivated by a policy innovation in Western Australia that amends an existing environmental bond policy to include a Pigovian tax on damaged land, the Mine Rehabilitation Fund (Western Australian Legislation 2012). The earlier Mining Act WA (1978) requires firms secure an environmental bond (known as an Unconditional Performance Bond) through a major bank (DMP 2010a, b, 2011). The bond can be ‘called-in’ by the Department of Mines and Petroleum (DMP) in the event of firm insolvency or non-compliance (Sommer and Gardiner 2012). A standard policy prescription for pollution problems is to internalize the external cost through a Pigovian tax on emissions (Pigou 1920). The Pigovian tax principle extends to stock pollutants generated by mining such as tailings ponds and damaged land (Farzin 1996). However, apart from Western Australia, a Pigovian tax policy has not applied to mines in Australia. Instead environmental policies are based on environmental bonds, or insurance policies that payout in the event of either non-compliance or bankruptcy (White et al. 2012). Using a case study for a mineral sands mine, White et al. (2012) found that, in most cases, environmental bonds alone, give a sub-optimal incentive for timely rehabilitation and a policy combining a bond with a Pigovian tax is optimal.Footnote 1
 The remainder of the paper is organised as follows. Section 2 gives a brief literature review. Section 3 describes the model and gives the social welfare optimizing tax and liability. It also identifies the loss of efficiency related to regulating a firm without extended liability. Section 4 sets out the regulatory model and derives optimal extended liability where control rights are allocated to either the firm or the investor. Section 5 gives a numerical example which allows us to explore regulatory policy where analytical solutions are intractable. Section 6 discusses the policy implications of the analysis and Sect. 7 concludes.",6
48.0,1.0,Journal of Regulatory Economics,09 April 2015,https://link.springer.com/article/10.1007/s11149-015-9278-y,Work environment and moral hazard,August 2015,Anthony M. Marino,,,Male,Unknown,Unknown,Male,"Work environment is influenced by many factors, including company culture and other psychological elements making up the intangible aspects of how one feels being a part of a particular organization. In addition, work environment is affected by the in-kind physical goods and services supplied to employees apart from monetary compensation. There are at least three general categories of in-kind benefits being used in today’s organizations. First there are technological or directly productive perks that are complementary inputs in conjunction with an agent’s work effort which go into in producing cash flow for the firm. These inputs can be in excess of basic capital inputs necessary to carry out assignments. Examples of technological perks might include high quality computer and communication equipment, certain business machines, a high speed internet connection, and transportation services. A second class of perks take the form of personal services which are indirectly productive in the sense that the provision of these services allows the agent to focus on his or her directly productive activities. Examples include child care services, meal service, the services of a masseuse, hair cutting service, on site laundry and alteration services, and the use of fitness equipment and facilities. The first two categories of benefits typically improve the marginal productivity of the agent’s effort and/or reduce effort cost, and, at the same time, they may provide an increase in the agent’s utility as a function of the amount of effort exerted in the firm. A third category of work environment variables are those which affect the safety, health and general welfare of workers. Examples include safety rails, proper instructions on how to use equipment, creation of safe and comfortable computer workstations, respiratory protection, blood borne pathogen needle stick prevention, good climate control and ventilation, control of chemical exposure, general workplace hazard reduction, elements of employee wellness programs, and information programs meant to improve health, safety and welfare. These costly work environmental inputs can produce many benefits for organizations and their workers. In the United States, this part of work environment is subject to workers’ compensation law as well as direct regulatory constraints (e.g., OSHA requirements.). In this paper, we study the third category of work environment and the incentives for a firm to provide a good work setting as it relates to health, safety, accident avoidance, and the prevention of sickness. We want to examine this topic in the context of an underlying moral hazard agency problem, so that we are able to consider the interaction of optimal work environment with the optimal contract. Our model is designed to be simple and to clearly emphasize the key relationships among the share of expected employee accident costs borne by the firm, employee compensation, and optimal work environment.Footnote 1 While the provision of a better work environment is costly to the firm, there are two key potential benefits associated with providing a more healthy and a safer environment for workers. First, productivity of an agent can be affected, and, second, the probability that damages will accrue to both the firm and to the employee is reduced. Given that work environment as pertains to health and safety is heavily regulated, our model will characterize the share of possible damages internalized by the firm as a parameter and one minus that share will be internalized by the employee. Changes in regulation and/or the legal system would induce changes in that parameter. Our model characterizes effort and working conditions as complements or substitutes in the creation of cash flow by the agent, with the leading example being the case where they are complements. We accomplish this by formulating a commonly used technology where effort and working conditions interact in a multiplicatively separable manner to generate cash flow. This mode of interaction is “neutral” in the sense that a working conditions function scales the marginal and average productivities of effort the same such that the elasticity of cash flow with respect to effort is not affected by working conditions.Footnote 2 In the model, the greater the activity level of the firm, the greater the expected damages from a possible accident. We begin by examining the firm’s optimal contract with consists of monetary compensation based on performance and an allocation of costly working conditions. While effort is unobservable, working conditions are observable and contractible. Our initial results show that, at the firm’s second best optimum and given any damage share parameter, effort and working conditions are under supplied relative to the first best (total surplus optimum), assuming that effort and working conditions are strategic complements in total surplus, while allowing them to be strategic substitutes in cash flow.Footnote 3
 Next, we examine the comparative statics of the firm’s second best equilibrium. Our first concern is with the effects of changes in the damage share parameter facing the firm. In the context of our model, we show that increases in this parameter reduce the firm’s incentive payment to the agent, but such increases leave the level of optimal working conditions and the agent’s effort unchanged. The reasoning behind this result is that increases in the firm’s damage share result in damage savings to the agent which are exactly offset by a decrease in the firm’s optimal payment to the agent. As a result, the marginal revenue to the agent for an extra unit of effort is unchanged and there is no change in effort and working conditions. Welfare of the agent stays the same as does profit and, of course total welfare, but damage costs are shifted from the agent to the firm. A second set of comparative statics parameterizes the hazard level of the agent’s job and the efficiency of the firm’s working conditions in reducing damages and changing cash flow, by taking first order approximations of damage reduction and marginal cost. We show that a greater hazard level worsens working conditions, whereas greater efficiency betters working conditions. The effects of hazard level and efficiency level on the agent’s pay depend on whether the firm or the agent bears a majority of the expected damages from accidents. When the employee bears a majority of the damages, rises in hazard increase the agent’s pay, whereas rising hazard lowers pay, if the firm bears a majority of damages. If the firm bears a majority of damages, then greater efficiency of working conditions leads to greater pay, and the opposite occurs if the employee bears a majority of damages. Our final set of results considers the regulation of working conditions, as with OSHA type regulation, and the direct regulation of damage shares, again in the neutral interaction mode. Direct regulation of working conditions results in increases in effort, working conditions, consumer welfare and total surplus, although profit decreases. Direct regulation of damage share placed on the firm, in addition to working conditions, does not affect welfare but does redistribute expected accident costs between the agent and the firm. All of the above rather provocative results are derived under the fairly common assumption that effort and working conditions interact in a neutral fashion in producing cash flow for the firm. In Sect. 6, we present a classic example of non-neutral interaction, namely the case where effort and working conditions are perfect substitutes (additively separable with constant coefficients) in creation of cash flow in the firm.Footnote 4 Our results are shown to be subject to change in this non-neutral environment. This example points out the important policy lesson that the specific mode of interaction between effort and working conditions in producing cash flow must be identified empirically, before making accurate statements about the effects of regulatory policy. Section 2 discusses related literature and Sect. 3 presents the model and the first best benchmark. Section 4 analyzes the second best equilibrium of the firm and Sect. 5 discusses regulation. Section 6 examines the implications of non-neutral interactions between effort and working conditions, and Sect. 7 concludes.",3
48.0,1.0,Journal of Regulatory Economics,22 May 2015,https://link.springer.com/article/10.1007/s11149-015-9279-x,Interactions of emission caps and renewable electricity support schemes,August 2015,Christoph Böhringer,Manuela Behrens,,Male,Female,Unknown,Mix,,
48.0,1.0,Journal of Regulatory Economics,13 May 2015,https://link.springer.com/article/10.1007/s11149-015-9280-4,State funeral regulations: inside the black box,August 2015,Jerry Ellig,,,Male,Unknown,Unknown,Male,"The cost of death care is a big concern in the United States. Consumers spent approximately $15 billion on death care in 2007, according to the most recent figures available from the US Economic Census. In a 2010 survey, consumers who said they wished they could change something about their recent funeral home experience overwhelmingly named “price” as the factor they would change (FAMIC 2012, 53). The Federal Trade Commission was so concerned about death care costs that it adopted its Funeral Rule in 1982. Among other provisions, the Funeral Rule requires funeral directors to maintain and furnish to consumers an itemized price list that includes the separate charge for the funeral director’s basic services. Since 1994 the rule has prohibited funeral directors from imposing additional charges if consumers purchase funeral merchandise (such as caskets) elsewhere. Courts too have seen their share of activity generated by disputes over death care costs, and particularly regulations that may contribute toward those costs. Federal courts have invalidated several states’ requirements that only funeral directors can sell caskets as violations of the U.S. Constitution’s due process and equal protection clauses.Footnote 1 In these cases, courts declared that naked protectionism of an intrastate economic interest (funeral directors) from the plaintiffs (casket sellers who are not funeral directors) does not quality as a legitimate state interest.Footnote 2 In a recent case successfully challenging a Minnesota statute that required all funeral homes to have embalming rooms, the plaintiffs noted that an embalming room would cost $30,000 or more even if it were never used.Footnote 3 Legal commentators have suggested that some state funeral regulations might be vulnerable to challenge under the dormant Commerce Clause as well, if the regulations affect electronic commerce in funeral goods or have other interstate effects (Agarwal and Ellig 2006). In addition to being of obvious interest to consumers, the effects of state funeral regulations on death care costs could thus be of interest to courts for several reasons. If regulations increase consumer costs, then courts may want to consider seriously whether protection of incumbent firms is the sole motive for the regulation. If consumers are among the plaintiffs challenging the regulations, evidence showing how the regulations affect consumer costs could play a significant role in determining whether consumers are actually harmed. If a state proffers a consumer protection defense in support of a challenged regulation, information about the regulation’s actual effect on consumer costs could help the court determine whether the regulation protects or harms consumers. Finally, if a state’s funeral regulations were to be challenged under the dormant Commerce Clause, then empirical analysis of the regulation’s effects on death care costs and the volume of commerce could help determine the size of any interstate effect, if coupled with evidence that consumers cross state lines to purchase funeral goods and services.Footnote 4
 Published economic research suggests that some, but not all, state funeral regulations have a significant effect on death care costs. Empirical studies find that state funeral regulations can increase consumer costs directly, by limiting competition or raising production costs (Harrington and Treber 2012; Harrington 2007), or indirectly by facilitating funeral directors’ efforts to sell more expensive packages of services (aka “demand inducement;” see Harrington 2007; Harrington and Krynski 2002). On the other hand, death care costs in states that prevent parties other than funeral directors from selling caskets appear to be about the same as death care costs in states with no such restriction (Chevalier and Scott Morton 2008; Sutter 2007). Prior studies, while providing valuable information, nevertheless have several drawbacks. No prior study assesses the effects of major state licensing, business structure, and merchandise sales regulations together. Most research has addressed either individual merchandise restrictions (Sutter 2007, 2005; Chevalier and Scott Morton 2008) or licensing and business structure regulations (Harrington and Treber 2012; Harrington 2007; Harrington and Krynski 2002), but not both. In addition, the only merchandise restriction studied previously is state restrictions on casket sales by parties other than funeral directors. Complete bans on all merchandise sales by cemeteries, the most likely competitor to funeral homes for sales of caskets and other merchandise, have received no attention. Finally, with one exception (Harrington 2007), prior studies do not explicitly account for the possibility that the same regulations might simultaneously affect both death care costs that stem from price increases and costs that stem from demand inducement by funeral directors. This study addresses these issues by including numerous death care regulations that pertain to sales of merchandise, licensing requirements, and business structure. It finds that some regulations of all three types are correlated with death care costs. For example, requiring funeral directors to be embalmers is associated with a $342–390 increase in receipts per death for the death care industry. Because this regulation is so widespread, it is the most expensive regulation, costing consumers an estimated $400 million annually. A direct disposition license, which allows cremators to transport bodies without having to be licensed funeral directors, is associated with a $1246–1251 reduction in receipts per death for the death care industry. These figures imply that if all states offered direct disposition licenses, consumers could save approximately $2.8 billion annually. The prohibition on cemetery sales of funeral goods is associated with a $1268–1547 increase in average receipts per death, costing consumers $255–279 million annually. By examining the potential effects of regulation on funeral industry revenues and cremations, this study considers both major ways funeral regulations might affect consumer costs. The requirement that funeral directors be embalmers and the cemetery goods prohibition are associated with higher receipts per death; direct disposition licenses and the requirement that crematories must be in cemeteries are associated with lower receipts per death. But the first two regulations are also correlated with a lower cremation percentage, and the second two are correlated with a higher cremation percentage. In addition to affecting the prices of services, these regulations may well affect demand inducement by funeral directors, and the demand inducement effects appear to be relatively large. Finally, by examining receipts per death for components of the death care industry, this study finds substantial evidence that funeral directors, rather than cemeteries and crematories, are the primary beneficiaries of most restrictive regulations. Regulations have the quantitatively largest and most statistically significant effects on the revenues of the funeral homes and services segment of the industry. In some cases, restrictive regulations even appear to increase the share of revenues received by funeral homes and services. Section 2 of this paper outlines the economic theories suggesting how funeral regulations may affect death care costs and summarizes prior empirical research on the topic. Section 3 explains the regulations covered in this paper and compares average death care costs in states with and without the regulations. Section 4 presents the econometric analysis and uses the results to calculate the effects of various regulations on death care costs. Section 5 summarizes the paper’s findings, concluding that state funeral regulations may have a larger effect on the cost of dying than previous research indicates.",4
48.0,2.0,Journal of Regulatory Economics,01 April 2015,https://link.springer.com/article/10.1007/s11149-015-9275-1,Obelix vs. Asterix: Size of US commercial banks and its regulatory challenge,October 2015,Diego Restrepo-Tobón,Subal C. Kumbhakar,Kai Sun,Male,Unknown,Male,Male,"After the latest US financial crisis, the optimal size of banks became an important issue for regulators and policymakers. Too-big-to-fail banks seems to enjoy a funding advantage in capital markets over smaller banks mostly due to implicit government guarantees (Gandhi and Lustig, In press). Prominent academics and policymakers have proposed to break up the biggest banks arguing that they pose substantial costs to society in the form of government bailouts and increased systemic risk.Footnote 1 However, policy proposals to break up or to cap the size of the biggest US banks failed to materialize. A plausible explanation for this outcome is that there is no consensus on the desirability or feasibility of capping the size of banks (Stern and Feldman 2009). More recently, the discussion has been reignited and capping the size of banks is again at the center of the regulatory policy debate. Against this backdrop, the existence of economies of scale for the biggest US banks has become a contentious and important issue. Economies of scale (which imply reduction in average costs as firm’s size increases), have been at the center of policy analyses in the regulation/deregulation and reregulation of different industries.Footnote 2 It would be challenging for regulators to promote perfect competition when substantial economies of scale are present (Laudati 1981). As suggested by Borts (1954), the existence of scale economies may lead regulators to favor the emergence and consolidation of large firms while ensuring that customers are served on reasonable terms—even if new entry and competition in the market is reduced. Since Williamson (1968, 1977) economies of scale underlie almost every aspect of antitrust regulation and constitute the basis for the well-known efficiency defense in mergers.Footnote 3 For instance, a merger that lowers competition may bypass antitrust restrictions if the merging parties can demonstrate that the merger is necessary to achieve substantial efficiencies that will enhance consumers’ welfare. DeYoung (1991) shows that the Williamsonian efficiency defense was implemented by the Federal Reserve Board of Governors in deciding over bank mergers even though the US Supreme Court had not recognized offsetting efficiencies as a defense of an anticompetitive merger.Footnote 4
 Conventional wisdom says that as firms get bigger economies of scale tend to shrink towards zero–ultimately reaching a point where the efficient scale size is achieved. Thus, regulating their size is unnecessary. However, if banks enjoy scale economies, regulators and policymakers have to balance the benefits with the costs of further bank growth. Lower average costs may allow banks to offer more competitive prices on their services, benefiting consumers and society as a whole. On the other hand, large scale banks may increase systemic risk and crisis costs. Thus, determining if scale economies exist for banks has important implications for bank regulation (Feldman 2010). The literature on the existence of scale economies for US banks is inconclusive. Early studies find scale economies for small banks only. According to Berger and Humphrey (1994), the conclusion that scale economies were available only to smaller US banks was unshaken at the time. In contrast, more recent studies find scale economies even for the biggest financial institutions (e.g. Wheelock and Wilson 2012; Hughes and Mester 2013; Malikov et al. 2014). However, other studies find no evidence of either scale economies or increasing returns to scale (RTS) for large US commercial banks (e.g. Feng and Zhang 2012; Restrepo-Tobón and Kumbhakar 2014; Davies and Tracey 2014). Thus, the existence of scale economies for the biggest US commercial banks is still a matter of debate. We contribute to this literature by measuring scale economies using a novel nonparametric approach that avoids making restrictive assumptions regarding the functional form of the underlying technology for banks (see Wheelock and Wilson 2011, 2012). Our approach offers two important advantages over the nonparametric methods used in previous studies. First, it gives fully nonparametric estimates of scale economies and total factor productivity (TFP) growth and its components. Previous nonparametric studies did not examine the relation between scale economies and TFP growth and did not allow estimation including some important features of the underlying technology. Many studies did not report measures like cost elasticities of outputs, technical change (TC), cost elasticities of input prices, among others, making it difficult to check the consistency of their results with economic theory. Second, unlike previous studies, our method allows us to partially control for unobserved heterogeneity across banks.Footnote 5 Our empirical findings indicate that failing to control for unobserved heterogeneity may conceal evidence of scale economies. Overall, our findings suggest that most US commercial banks with assets in excess of $1 billion enjoy substantial economies of scale (Obelix is not obese).Footnote 6 However, 35 % of the observations for the top one hundred banks show no evidence of scale economies.Footnote 7 For the top ten banks with assets ranging from $47 billion to $1.5 trillion, only 70 % of the observations are consistent with economies of scale.Footnote 8 In particular, of the four banks with assets above $500 billion, on average, only one bank exhibits economies of scale during the sampling period (only 3 obese Obelix). Thus, capping the size of the biggest banks (converting them to Asterix) may yield limited social losses from the scale economies viewpoint. The rest of the paper is organized as follows. In Sect. 2, we review the literature. In Sect. 3, we describe our model, the estimation strategy, and our data. In Sect. 4, we present our empirical results and compare them with those in the existing literature. Section 6 discusses robustness checks. Policy implications of our study are discussed in Sect. 6. Finally, Sect. 7 concludes.",6
48.0,2.0,Journal of Regulatory Economics,03 June 2015,https://link.springer.com/article/10.1007/s11149-015-9284-0,Demand response in adjustment markets for electricity,October 2015,Claude Crampes,Thomas-Olivier Léautier,,,Unknown,Unknown,Mix,,
48.0,2.0,Journal of Regulatory Economics,08 May 2015,https://link.springer.com/article/10.1007/s11149-015-9283-1,How EU sector-specific regulations and competition affect migration from old to new communications infrastructure: recent evidence from EU27 member states,October 2015,Wolfgang Briglauer,,,Male,Unknown,Unknown,Male,"The Digital Agenda for Europe (DAE) aims to strengthen the competitiveness of Europe’s economy with an explicit focus on digital communications technologies and defines specific policy goals in terms of network deployment, adoption and bandwidth characteristics. The DAE “seeks to ensure that, by 2020, (i) all Europeans have access to much higher internet speeds of above 30 Mbps and (ii) 50 % or more of European households subscribe to internet connections above 100 Mbps” (European Commission 2010a, p. 19). The future central importance of high-speed next generation networks (NGNs) as a key socio-economic factor in any information society is well recognized with reference to the general purpose technology character (Bresnahan and Trajtenberg 1995) of NGNs and related spill-over effects in terms of significant productivity improvements and growth across major economic sectors.Footnote 1
 However, market conditions have so far appeared to be insufficient to induce a broad-scale roll out of fiber infrastructure which is subject to high investment requirements and risks. Therefore, identifying the right regulatory policy measures becomes crucial. In view of the comparatively strict EU access regulation imposed on the existing (“first-generation”) broadband infrastructure and as foreseen for emerging NGNs (Vogelsang 2014; Briglauer and Gugler 2013; European Commission 2010b), this paper examines the following research questions: (i) what is the impact of sector-specific broadband access regulation imposed on first-generation broadband markets and related service-based competition on NGN investment? (ii) what is the impact of infrastructure-based competition from mobile networks and wireline first-generation broadband networks on NGN investment? The empirical investigation utilizes a comprehensive and most recent EU27 panel data set for the years from 2004 to 2013 for incumbent and entrant operatorsFootnote 2 which are all subject to the same EU regulatory framework for electronic communications markets. The econometric estimation techniques explicitly account for the endogeneity bias arising from the dynamic investment specification and from potential endogeneity due to omitted heterogeneity or reverse causality. Furthermore, this paper considers all relevant regulatory and competition variables that only have been used separately in the empirical literature so far. In particular, the paper measures regulation (i) in terms of the so-called “unbundling” charge which is the most relevant wholesale access charge in terms of migration incentives to NGNs as well as (ii) by the extent of service-based competition that expresses the market relevance of all forms of broadband access obligations imposed under the EU regulatory framework. In addition, the paper uses (iii) a formal regulatory density index as a robustness variable. In a similar vein, it simultaneously takes account of the relevant forms of infrastructure-based competition stemming from (i) mobile (wireless) networks (“intermodal”) and (ii) wireline first-generation broadband networks (“intramodal”). A multiplicity of methods in conjunction with a broad set of control variables ensures the robustness of the results. Section 2 reviews the recent and related empirical literature. Section 3 then outlines testable hypotheses concerning the role of access regulation and regulatory induced service-based competition as well as infrastructure-based competition. Section 4 describes the panel data set. Section 5 presents the empirical baseline specification and the identification strategy. Section 6 discusses the main empirical results. Finally, Sect. 7 summarizes and compiles relevant recommendations for future regulatory policies.",33
48.0,2.0,Journal of Regulatory Economics,25 February 2015,https://link.springer.com/article/10.1007/s11149-015-9270-6,"Strategic behavior in the German balancing energy mechanism: incentives, evidence, costs and solutions",October 2015,Sebastian Just,Christoph Weber,,Male,Male,Unknown,Male,"The liberalization and the resulting deconstruction of the integrated electricity value chain brings new coordination requirements for the technical balancing of demand and supply in the electricity system. In Germany and in many other liberalized electricity markets, the crucial balancing task has been separated into two stages: decentralized planning via balancing groups before, and centrally coordinated actual balancing by the transmission system operators (TSOs) via the use of highly flexible reserve capacity after gate closure. The balancing mechanism effectively connects the two stages in the German electricity system. Its core is the pricing of actual imbalances caused by each balancing group. This shall provide the incentive for effective decentralized planning and thus minimize the remaining balancing requirements that are carried out by centrally coordinated reserve capacity in real-time. All market participants have to belong to a balancing group. They need to forecast their load commitments and procure the corresponding electricity volumes. The according load schedules have to be submitted to the TSO before gate closure. Every real-time deviation from this planned schedule, the imbalance, is settled at the balancing price. In Germany, the specific nature of the balancing prices provides predictable arbitrage opportunities between spot and balancing energy. Since balancing energy and reserve capacity is limited, the exploitation of such arbitrage on purpose is prohibited. It would jeopardize the effective coordination at the planning stage and may result in severe system instabilities. Suspected strategic behavior in the German balancing mechanism has recently sparked public attention (see FAZ 2012). During a cold spell with critical system conditions in February 2012, the German electricity system was structurally undersupplied, which nearly caused a blackout. Market participants were suspected to intentionally rely on balancing energy to avoid procuring more expensive spot electricity. Alternatively, unexpected weather conditions may have caused an underestimation of the actual load (see Energate 2012; BNetzA 2012a). For specific moments, it is difficult to determine whether undersupply behavior was intended or merely the result of unavoidable forecasting uncertainty. This paper investigates the incentives in the German balancing mechanism and the empirical evidence for potential strategic behavior, using longer data time series. In Germany, the prices for balancing energy and spot electricity are largely disconnected due to the specific market design. This provides structural opportunities for strategic behavior at one of the most crucial links in the electricity system at times when the system is most vulnerable. As we will show, market participants have an incentive to over and undersupply their expected load commitments depending on the expected spot price. The closely-related German market for reserve capacity has attracted increasing attention in the economic literature, in which the market design and results are debated.Footnote 1 However, the balancing mechanism and the link to spot markets have only been studied selectively. Wawer (2007) shows that balancing groups have an incentive to oversupply in off-peak and undersupply in peak periods. Moeller et al. (2011) apply time series analysis to detect strategic positions taken in the German balancing mechanism. They conclude that the strategies, and the market design that fosters them, contribute to the overall effectiveness of the electricity market. Outside of the specific German context, Boogert and Dupont (2005) study gaming-behavior in the Dutch balancing mechanism, which differs from the market design in Germany. They find that, in the Netherlands, strategic behavior is rarely profitable and comes with large risks. Vandezande et al. (2010) discuss different balancing designs by the use of simplified examples and conclude that a mechanism designed as a one-price system like in Germany without penalties or link to spot prices should be preferred. The aim of this paper is to extend the existing academic literature on strategic behavior in the German market through explicitly studying the incentives created by the specific market design. We show that a broader spectrum of incentives for over and undersupply exists than described by Wawer (2007). This gaming behavior can be observed in aggregated market data. It creates external costs of likely more than €200m that are borne ultimately by the consumer. Solutions to prevent strategic behavior exist and their implications are evaluated. Our analysis leads to different conclusions than Vandezande et al. (2010) and Moeller et al. (2011). The differences are discussed in the conclusions of this paper. The paper is organized as follows: Sect. 2 describes the German electricity market design. The data and analysis horizon are described in Sect. 3. The formation and predictability of balancing prices are studied in Sect. 4. In Sect. 5, the incentives in the balancing mechanism are explored and analyzed with a simplified model. Empirical evidence of strategic behavior is investigated in Sect. 6. The implied costs of this behavior are estimated in Sect. 7 and possible solutions to prevent it are discussed in Sect. 8. Finally, conclusions are drawn.",33
48.0,3.0,Journal of Regulatory Economics,08 May 2015,https://link.springer.com/article/10.1007/s11149-015-9281-3,Efficiency impact of convergence bidding in the california electricity market,December 2015,Ruoyang Li,Alva J. Svoboda,Shmuel S. Oren,Unknown,,Male,Mix,,
48.0,3.0,Journal of Regulatory Economics,24 April 2015,https://link.springer.com/article/10.1007/s11149-015-9277-z,The effects of network regulation on electricity supply security: a European analysis,December 2015,Michael Schmidthaler,Jed Cohen,Stefan Schmidinger,Male,Male,Male,Male,"An uninterrupted and predictable supply of electricity is considered an essential attribute of industrialized countries. Ensuring high levels of supply securityFootnote 1 has thus become an important objective of national and international energy policy.Footnote 2 Being a direct policy tool, the regulation of distribution networks affects the characteristics of power markets substantially. Historically however, regulation of networks primarily aimed at reducing electricity prices. Thus, independent regulatory authorities were established as a consequence of Directive 96/92/EC (European Commission 1996)Footnote 3 which initiated the liberalization of energy markets.Footnote 4
 In the light of increasingly interconnected European electricity markets however, the necessity has grown to harmonize national efforts to enhance supply security and apply best-practice regulatory schemes. The period investigated in this paper and the cross country structure of the European Union are well suited for efficacy assessments since cross-sectional data of regulation and supply security indices are available for a duration of 15 years. Furthermore, the time span was characterized by substantial organizational changes in the relevant electricity markets. These included the vertical disintegration of utilities, the privatization of state-owned firms in various countries, as well as the introduction of regulatory frameworks and independent authorities to monitor network tariffs (as evidenced in Karan and Kazdagli 2011 as well as European Commission 2006 and 2003). Whereas the effects of regulation for transmission and distribution networks on electricity prices are well researched, evidence regarding the ramifications with regards to supply security remains scarce. This paper aims at closing this gap by analyzing the effects that different frameworks for regulating distribution systems have had on duration and frequency of power outages in the EU. Furthermore, the channels of interaction between regulatory authorities, politics and regulated firms are assessed. To do so, novel empirical evidence based on a cross-country data panel of 27 European countries for the period from 1999 until 2013 is assessed with special regard to distribution networks.Footnote 5 The remainder of this paper is structured as follows: Sect. 2 reviews the relevant literature and investigates the current status and differences of regulatory frameworks in the EU. Section 3 describes the utilized data and explains the methodology of the empirical models. Section 4 contains the results of the quantitative analyses, while Sect. 5 summarizes and concludes.",12
48.0,3.0,Journal of Regulatory Economics,13 October 2015,https://link.springer.com/article/10.1007/s11149-015-9288-9,Welfare effects of compulsory licensing,December 2015,Jacob Seifert,,,Male,Unknown,Unknown,Male,"It is well known that the unregulated exploitation by firms of their intellectual property (IP) rights can limit competition.Footnote 1 This paper examines a particular type of anti-competitive conduct relating to a firm’s use of its IP: the unilateral refusal by a dominant firm to license. Particularly in Europe, such a refusal to license is seen as a potential abuse of a dominant position under competition law. Competition bodies may therefore impose a compulsory licence—a legal obligation to share IP in exchange for fair, reasonable and non-discriminatory (FRAND) compensationFootnote 2—on a firm that does not license its innovation voluntarily, in order to promote competition in the market. Of course, the argument against compulsory licensing is that, by undermining the IP protection of innovating firms, it reduces firms’ incentives to innovate (see, e.g., Feldman 2009). The impact of compulsory licensing on welfare is, therefore, ambiguous, since it promotes competition only at the expense of reduced innovation incentives. The aim of this paper is to analyse these conflicting effects, and to derive necessary and sufficient conditions for compulsory licensing to improve welfare. The appropriate legal treatment of refusals to license IP has been a central issue in numerous high-profile competition cases. In the US, the courts have consistently upheld the rights of IP holders and have considered the unilateral refusal by a dominant firm to license a competition violation only if it is accompanied by a secondary harmful action, such as tying or exclusive dealing, or if it violates agreements made as part of membership of a standard setting organisation (SSO) (Coco 2008). In Xerox, the Court of Appeals for the Federal Circuit effectively granted the innovator immunity from Sect. 2 of the Sherman Act for the refusal to license, deeming such a refusal to lie within the scope of patent rights.Footnote 3 Similarly, the 2007 joint report by the US Department of Justice (DOJ) and Federal Trade Commission (FTC) on Antitrust Enforcement and IP Rights states that “[a]ntitrust liability for mere unilateral, unconditional refusals to license patents will not play a meaningful part in the interface between patent rights and antitrust protections.” (DOJ-FTC 2007, p. 6) By contrast, the European competition bodies [collectively, the European Commission, the Court of First Instance (CFI) and the European Court of Justice (ECJ)] do consider the refusal to license IP a potential violation of competition law and have imposed and upheld compulsory licenses in several landmark cases, most notably in Microsoft, but also in IMS Health and Magill.Footnote 4
 It is helpful to consider this divergence in approaches between the US and Europe in terms of the underlying legal standard (or decision rule) by which refusals to license IP are judged, as this is an area in which important analytical work on compulsory licensing exists (Katsoulacos 2009). Legal standards for competition policy may be broadly split between per se rules and discriminating rules. Under a per se rule, an entire class of actions is allowed or disallowed, without attempting to identify sub-classes of actions that might merit exception from the rule. This implies that per se rules are associated only with decision errors of type I (false convictions) or type II (false acquittals), but never both, depending on whether the rule is one of per se illegality or per se legality, respectively. Under a discriminating rule, an investigation is conducted and a decision is arrived at, based on explicit criteria for deeming actions to be pro- or anti-competitive (Katsoulacos and Ulph 2009). In consequence, discriminating rules are generally associated with decision errors of both types. It is therefore natural to distinguish further between discriminating rules according to whether they are relatively more focused on preventing false convictions or on preventing false acquittals. 
Katsoulacos (2009) argues that the US approach in Xerox is equivalent to per se legality,Footnote 5 while the Commission’s legal standard in Microsoft is an example of a low-false-acquittals discriminating rule. The legal standard in the Magill and IMS Health cases, meanwhile, is argued to be a low-false-convictions discriminating rule.Footnote 6 In a welfare framework, the desirability of these competing legal standards is related to the underlying or average degree of harm associated with refusals to license IP. This average harm is, in turn, reflected in the ‘presumption of legality’, formally defined as the ratio of the expected benefit from refusals to license IP that are benign (that is, for which welfare falls if compulsory licensing is imposed) to the expected harm from refusals to license that are truly harmful (that is, for which compulsory licensing would improve welfare). The key insight is that the per se legality standard adopted in the US Xerox case is welfare-preferred to the discriminating rules (be they of the low-false-acquittals or low-false-convictions type) adopted by the Commission only if the presumption of legality is high. However, the extent to which refusals to license IP should actually be viewed as presumptively legal is discussed only informally. This paper therefore also builds on Katsoulacos (2009), by investigating more carefully the presumption of legality that should apply to refusals to license IP. In particular, we take explicit account of innovation effects and investigate when compulsory licensing improves welfare, relative to the case where a dominant firm would refuse to license its innovation voluntarily.Footnote 7 Our innovation results are derived within the framework of a single innovation tournament model of R&D competition, in which the imposition of compulsory licensing (by weakening the IP protection of innovators) always lowers innovation incentives. While several models have shown that weakening IP protection can actually increase innovation rates,Footnote 8 we justify this modelling assumption as follows. The majority of competition authorities around the world, including in the US and EU, follow a consumer surplus standard.Footnote 9 In that context, were innovation rates to rise in response to a compulsory licence, such a policy would represent a win–win situation for consumers. To make the trade-off between innovation and competition real, we must therefore have a reduction in R&D incentives when compulsory licensing is imposed. While this may be achieved in more complex dynamic models,Footnote 10 the simplest such model is a one-shot tournament model.Footnote 11 Our contribution to the literature on the strength of IP protection and innovation incentives more broadly is that, in our framework, we explicitly balance the negative effect that compulsory licensing has on innovation incentives with its pro-competitive impact in the product market to arrive at explicit welfare results. We derive our welfare results on the basis of both a consumer surplus and a total welfare standard, as well as in the case where the competition authority cares about protecting competition per se under a so-called foreclosure standard. We are able to show that, when the risk-free rate is low, consumer surplus is always higher when a dominant firm is forced to license via compulsory licensing, because this guarantees that the most preferred consumer outcome (that associated with technology transfer) is realised. This result therefore contradicts the view that refusals to license IP should be viewed as strongly presumptively legal, and consequently treated under a per se legality standard.Footnote 12 Instead, on the basis of Katsoulacos (2009), the discriminating rules adopted by the Commission appear more reasonable.Footnote 13 The effect of compulsory licensing on total welfare is more complex, but is shown to be positive whenever the underlying degree of competitiveness in the industry is sufficiently low. We also show that compulsory licensing is an effective policy to protect competition per se, since it guarantees that the incumbent cannot foreclose its less-efficient rival. While these results are derived in a baseline model in which the incumbent is the predicted winner of the innovation race—a scenario we refer to as persistent dominance—we also demonstrate their robustness to an alternative setting of action–reaction R&D competition, in which the less-efficient firm is predicted to overtake the incumbent by innovating successfully.Footnote 14 It is important to verify that the incentives for dominant firms to refuse to license and the welfare effects of compulsory licensing carry over to the action–reaction setting, since here the dominance of the incumbent firm is, at least in the dynamic sense, weaker.Footnote 15
 Finally, we relate our welfare results to the debate on compulsory licensing in the context of SSOs and pharmaceutical trade. While both settings contain additional features that go beyond the framework developed in this paper, we argue that our work nevertheless serves as a useful benchmark for the study of compulsory licensing in these cases. This follows because our setting is arguably that in which the a priori arguments for compulsory licensing are weakest, making our results in favour of such a policy, especially under a consumer surplus standard, particularly noteworthy. The remainder of the paper is organised as follows. Section 2 outlines the model. Section 3 discusses the innovation effects of compulsory licensing in the benchmark, persistent dominance case, while Sect. 4 derives the main welfare results. Section 5 discusses the robustness of our results to action–reaction R&D competition, before Sect. 6 discusses the implications of our model for the broader regulatory debate around compulsory licensing. Section 7 concludes. Throughout the paper, all proofs that are not immediate from the context are collected in Appendix 1.",5
48.0,3.0,Journal of Regulatory Economics,19 November 2015,https://link.springer.com/article/10.1007/s11149-015-9286-y,Acknowledgments,December 2015,,,,Unknown,Unknown,Unknown,Unknown,,
49.0,1.0,Journal of Regulatory Economics,08 October 2015,https://link.springer.com/article/10.1007/s11149-015-9287-x,Incentives to quality and investment: evidence from electricity distribution in Italy,February 2016,Carlo Cambini,Elena Fumagalli,Laura Rondi,Male,Female,Female,Mix,,
49.0,1.0,Journal of Regulatory Economics,07 August 2015,https://link.springer.com/article/10.1007/s11149-015-9285-z,The hidden cost of investment: the impact of adjustment costs on firm performance measurement and regulation,February 2016,Sebastian Nick,Heike Wetzel,,Male,Female,Unknown,Mix,,
49.0,1.0,Journal of Regulatory Economics,22 May 2015,https://link.springer.com/article/10.1007/s11149-015-9282-2,Endogenous transactions costs and institutions in the 2007/08 financial crisis,February 2016,Jamus Jerome Lim,Terence Tan,,Unknown,Male,Unknown,Male,"Financial crises are hardly new. Reinhart and Rogoff (2009) document no less than 122 separate incidences of crises since 1800. While such crises are not uncommon, their epicenter has typically centered on developing countries: Of the 50 crises that have occurred in the high-capital mobility period since the 1980s, only a fifth have originated in high-income economies, and—with the exception of the 1992 ERM crisis—their impact has generally been limited to a few countries. Furthermore, the vast majority of financial crises involve relatively simple financial instruments—such as currencies, plain-vanilla bonds or stocks, or basic mortgage assets—operating in a straightforward, if sometimes politically-distorted, institutional environment. What distinguishes the 2007 subprime crisis, and makes it interesting—if not altogether unique—is the concurrent incidence of three elements seldom seen together: Its origin in a high-income country, in possession of a deep and sophisticated financial and regulatory system, and leading to spillover effects that included nominal and real dislocations spread over a global scale.Footnote 1
 How did a two-year-long financial crisis arise with this unusual, and certainly unexpected, set of features? We argue in this paper that understanding the institutional environment is central to a complete explanation. More specifically, our thesis is that transactions costs, which are endogenous to the system, rose due to changes in the institutional structure of financial markets. As an important corollary, we argue that the cycle of feedback between deregulation and financial innovation ultimately increased financial fragility, and ultimately this fragility culminated in a financial crisis. The recognition that the introduction of transactions costs can modify portfolio demand and optimal asset allocation is not new. However, such studies have have typically adopted one of two approaches. One approach begins by embedding transactions costs as a parameter faced by agents within the existing institutional structure, and then examining how the presence of such costs alter resultant equilibrium prices (taking the institutional structure as given) (Constantinides 1986; Merton 1989). The second approach takes this one step further and allows the realized institutional structure to be the consequence of a given distribution of transactions costs (Merton 1987).Footnote 2 What is missing, however, is that these transactions costs are not understood to exist as a function of the institutional setting. While they may change the institutional framework whereby agents operate, they are not allowed to be endogenously determined by the institutions that are currently in operation. The subprime crisis of 2007 is one such case in point. We argue that the proximate causes of the crisis currently entertained in the literature—such as regulatory failure, incentive problems, and complex financial instruments—belie a deeper, more fundamental cause. In particular, we show that institutional changes—led by the regulatory reforms of the 1990s—brought about changes in the structure of financial markets, which in turn altered the transactions costs faced by market participants. This interaction between institutional and market governance set the stage for a financial crisis that would otherwise not have occurred in the deepest, most mature financial market in the world. We conceptualize transactions costs in a fairly broad manner, including not just practical costs such as financial contract origination and sale, but, importantly, the cost of informational imperfections and agency problems—analogous to those identified by Grossman and Stiglitz (1980)—that are introduced along with the marginal financial contract as well. Although this limits the extent to which our definition can be operationalized empirically, the latitude that it offers affords us significant theoretical mileage. There is emerging empirical evidence that such transactions costs—informational costs in particular—were rife in subprime markets, which in turn lead to inefficiencies. Adams et al. (2009) document problems of imperfect information in subprime lending for auto loans. Similarly, Keys et al. (2010) observe that subprime mortgages that were subject to securitization faced a significantly higher probability of default relative to a non-securitized portfolio with a comparable risk profile; they argue that their analyses point to reduced screening incentives on the part of lenders. Mian and Sufi (2009) show, convincingly, that securitization was accompanied by an erosion in subprime lending standards. An important precedent to our theoretical work here is the paper by Akerlof and Romer (1993) who—as far back as 1993—were prescient in their concern that the relaxation of regulations in an environment of widespread informational asymmetries may lead to financial “looting.” Their paper, however, is concerned with problems surrounding failures of informational flows, while our paper links such failures explicitly to the design of the institutional framework and its associated feedback effects. Another piece that relates indirectly to the argument we make here is the influential paper by Shleifer and Vishny (1997). In that paper, agency frictions between arbitrageurs and investors lead to circumstances where arbitrage does not occur. In a similar vein, our paper envisions such frictions as transactions costs, and these costs likewise prevent convergence toward true fundamental values. Probably the closest paper in spirit to the arguments made here is that of Biais et al. (2009), who construct an agency model with learning of the sort that characterizes innovative industries (such as the financial sector). The authors demonstrate that, with uncertainty about profits and informational asymmetry over innovative sector effort, managers extract agency rents due to moral hazard-induced risk taking, and uncertainty can give rise to booms and crashes. However, while the paper employs a sophisticated representation of agent action in the presence of uncertainty and learning, they do not discuss the influence of the institutional environment, as we do. Finally, a recent paper by Eden (2012) demonstrates how welfare may be reduced in an unregulated financial system. Her paper—which envisions transactions costs deriving from financial intermediation as a costly monitoring technology—serves as a nice complement to the arguments that we forward here, although its main focus is on the implications of such costly intermediation for liquidity value in a general equilibrium setting. The recent slew of books and papers dealing with the crisis is too voluminous to address in detail here. In this crowded space, several authors have made arguments along the lines of what we describe here: these include challenges introduced by complex financial innovations and the securitization process (Brender and Pisani 2010; Jaffee et al. 2009; Rajan 2005), changes in the institutional and regulatory environment (Calomiris 2009; Gerding 2010; Tymoigne 2009), and incentive issues due to informational asymmetries (Achrya and Richardson 2009; Faber 2009; Richardson and White 2009; Ritholtz 2009; Sorkin 2009). However, while some among these have certainly made understanding institutional changes or financial market innovations central to their analysis, they generally do not go on and draw explicit connections between the two.Footnote 3 Moreover, while many authors that have highlighted potential incentive problems associated with moral hazard and principal agent problems, they do not embed these concerns into the broader rubric of transactions costs. We focus in this essay on the financial markets, and specifically financial markets operating in the United States in the three decades prior to the 2007/08 crisis. We limit our discussion of the financial market primarily to the securitized paper market, especially the estimated $2 trillion collateralized debt obligations (CDO) component (which in turn are mainly comprised of sub-prime and Alt-A related issues), and the $62 trillion credit (CDS) and equity (EDS) default swap market. While no part of the financial sector was untouched by the crisis—most notably the $32 trillion (and counting) stock market decline and widespread failures of hedge funds—and the crisis is far from limited to the United States—Iceland, Ireland, the United Kingdom, Spain, and much of Easter Europe experienced first-round crisis impacts—there is reason to believe that problems in these two parts of the financial sector both preceded the others, and that the operational heart of these markets was in the United States. One could plausibly argue that if the problems in the two were contained (or prevented), the other parts of the financial sector, as well as other parts of the world, may not have experienced the sorts of violent contractions that they have had. Finally, our discussion of the CDS and EDS market is primarily of interest only to the extent that this market amplified the shocks of the subprime mortgage market (by its enabling role in synthetic CDO creation), not in the many other markets that default swaps have been used as a hedging instrument. Hence, our references to the CDS/EDS market are focused mainly on the subset of the market dealing with CDOs. To the extent that they overlap and are relevant, we also highlight the special purpose vehicles (SPVs) that issue the asset- and mortgage-backed securities (ABS and MBS’s), which in turn form the basis for CDOs, along with related derivatives of CDOs, such as synthetic CDOs constructed from EDS’s.Footnote 4 This does not, however, preclude a discussion of other important elements that were instrumental in a crisis of this magnitude, such as global capital flows, monetary policy, and the exchange rate, insofar as they were contributing factors. But as will become clear, our concern is the financial markets—and more specifically transactions costs inherent in these markets—since we believe that normal market forces would have corrected for these factors, had the financial markets operated efficiently. The rest of the paper is organized as follows. In the following section, we provide a brief sketch of our notion of transactions costs and institutions, within the context of the financial markets examined in this paper. The section goes on to introduce a simple model that demonstrates how transactions costs and institutions are endogenously codetermined. Section 3 then dives deeper into how financial innovation via complex instruments can raise the transactions costs in the financial sector. The next section (Sect. 4) then examines the historical evolution of institutions in the financial sector, and systematically relates the evolution of these institutions to increased transactions costs. A final section concludes.",1
49.0,1.0,Journal of Regulatory Economics,16 November 2015,https://link.springer.com/article/10.1007/s11149-015-9289-8,Risk and risk-based capital of U.S. bank holding companies,February 2016,Thomas L. Hogan,Neil R. Meredith,,Male,Male,Unknown,Male,"The recent financial crisis has reinvigorated the debate over banking regulation and the stability of the banking system. While many factors contributed to the housing boom and bust of the early 2000s,Footnote 1 there remains some mystery as to why financial firms accumulated large quantities of risky assets such as mortgage-backed securities (MBSs), resulting in system-wide liquidity shortages among U.S. commercial banks. Additionally, there are questions as to how the Fed and other regulators failed to identify these risks in advance of the crisis.Footnote 2 This paper examines one potential reason the Fed failed to predict the crisis: Perhaps the measures used to regulate commercial banks are simply poor predictors of bank risk. The core of U.S. banking regulation is the Fed’s system of risk-based capital (RBC) regulations based on the international Basel Accords (or “Basel I”).Footnote 3 The RBC system dictates the minimum amount of equity capital that must be maintained by a bank based on the riskiness of the bank’s asset holdings. Regulators assign a risk weight to each category of bank assets based on its perceived level of risk. High-risk assets require higher levels of equity capital while low-risk assets require less capital. The Fed’s risk-weighting system is based on Basel I and has changed little from its original adoption in 1991. Since the 2008 financial crisis, the Fed has instituted more stringent RBC regulations based on Basel II and Basel III as discussed in the next section, but the foundations of the risk-weighting system remain unchanged. The Basel system of RBC regulation enjoys widespread support among regulators and economists alike. The risk-weighting system has the advantage of requiring banks with more risky assets to maintain higher levels of capital. This idea is logical and intuitively appealing, but there is a potential downside to this method. If regulators are unable to properly assess the riskiness of all asset types, they may unintentionally cause banks to increase rather than decrease their levels of risk. Indeed, properly identifying asset risk is not easy, and mistakes can be quite costly. Any mis-rating by the regulator gives banks an incentive to commit regulatory arbitrage by buying assets whose risks are underrated in the risk-weighting system and selling assets whose risks are overrated. These faulty regulations appear to have contributed to the financial crises in the United States and Europe. As Friedman (2011, p. 54) explains regarding the U.S. crisis, “there is no reason to think that subprime securities (or mortgages) would have been issued in such volume, or that they would have been so highly concentrated in the hands of the banks, in the absence of the Basel rules.” A similar issue occurred in Europe where political pressure led the Basel Committee to treat all sovereign debt equally regardless of risk, causing banks to accumulate large quantities of Greek government debt (Friedman 2011, p. 28). Despite the problem of faulty risk weightings, many economists assume that the RBC system is still the best method of identifying bank risk. The problems of mis-rating have been known since before the adoption of RBC regulations and were discussed by early studies such as Avery and Berger (1991). Yet, most economists support the adoption of increasingly complex RBC regulations as adopted in Basel II and III. As Bernanke (2007) describes, “The advanced risk-based capital framework [of Basel II] is designed to foster good risk measurement and management practices and to significantly improve the risk sensitivity of our existing capital rules.” As discussed in the next section, however, recent studies question the effectiveness of the RBC ratio as a predictor of bank risk (Haldane 2012; Acharya et al. 2014; Hogan 2015). This paper analyzes the capital and RBC ratios as predictors of several measures of the risks of U.S. BHCs. The next section provides a brief background on the Basel system of RBC regulations and the specific methods adopted by the Fed to regulate U.S. BHCs. Section 3 summarizes our dataset of U.S. BHCs’ financial statements and equity prices. Section 4 outlines our regression model. Section 5 discusses the results of our analysis, which finds that the capital ratio is statistically significantly better than the RBC ratio as a predictor of bank risk, especially in the period since and including 2007. Section 6 concludes.",12
49.0,2.0,Journal of Regulatory Economics,06 January 2016,https://link.springer.com/article/10.1007/s11149-015-9290-2,Substitution between fixed-line and mobile access: the role of complementarities,April 2016,Lukasz Grzybowski,Frank Verboven,,Unknown,Male,Unknown,Male,"At the start of the 1990s, telecommunications industries in the European Union were controlled by state monopolies which transmitted phone calls using the fixed-line copper network. There were a small number of mobile phone users via analog networks (1G), which in most of the EU countries were operated by the subsidiaries of the fixed-line incumbents. This situation changed dramatically during the last two decades. First, in the early 1990s several competing mobile operators started to deploy voice services based on second generation (2G) technologies GSM-900 and DCS-1800. Second, after the liberalization in the EU in 1998 a large number of entrants started providing voice services through the incumbents’ fixed infrastructure. Third, in the late 1990s the deployment of Internet broadband services started, which initially also mainly relied on fixed-line copper networks. With the deployment of these new technologies the number of communication options increased. This influenced the way in which people communicate, in particular how they use copper-based fixed-line connections. The rapid increase in the number of mobile users was paralleled with a decline in the number of fixed-line subscribers. At the same time, the effect of broadband deployment on the usage of fixed-line connections is less obvious. Broadband Internet access was first deployed using digital subscriber line technology (DSL). This relied on copper-based networks and required consumers to maintain their fixed-line connections. In most of the EU countries, DSL is still a dominant broadband technology. But there are also countries, especially in Central and Eastern Europe (CEE), where alternative broadband technologies, such as cable, fibre and mobile broadband, obtained significant market shares. In this paper we analyze the substitution between fixed-line and mobile voice services, and the role of several complementarities that may influence this process. In particular, we ask whether and how the incumbent fixed-line operators managed to slow down fixed-to-mobile substitution, and whether they could leverage their position from fixed to the mobile voice services. Furthermore, we ask to what extent broadband Internet slowed down fixed-to-mobile substitution. Addressing these questions is important since fixed-to-mobile substitution affects the financial viability of the incumbent fixed-line operators. It is therefore critical for both the operators and industry regulators to understand the interdependencies between different communication technologies. The question of fixed-to-mobile substitution is also important because of the ongoing consolidation process in telecommunications markets. There is a growing number of mergers between mobile operators which need to be scrutinized by the competition authorities, and substitution between fixed-line and mobile services should play an important role in the market investigations. To address these questions, we make use of a unique micro-level dataset of 160,363 households from 27 EU countries during the period 2005–2011. We adapt the model of Gentzkow (2007) to analyze the situation in which households may choose bundles of different technologies: fixed voice or mobile voice only, or the combination of both services, with or without broadband Internet. We can summarize our results in three main findings. Our first main finding is that households tend to perceive mobile and fixed-line connections as substitutes, and more strongly so in the recent years. In 2006 total fixed-line penetration in the EU was almost 67 %, and it would have been 5.9 % points higher if mobile voice had not been present. At the end of 2011 total fixed-line penetration was about 63 %, and it would have been almost 14.1 % points higher without mobile voice access. At the same time, there is substantial heterogeneity across households and regions. In regions with a higher GDP per capita mobile and fixed-line services tend to be stronger substitutes. After controlling for GDP per capita, there is also a stronger degree of substitution in the CEE countries, as compared to the WE countries. There is not only heterogeneity in fixed-to-mobile substitution across regions, but also across households with different age, education, professional activity, etc. This implies that even within a region, some households may perceive fixed-line and mobile connections as very strong substitutes, whereas other households perceive them as essentially independent. Our finding of strong heterogeneity in the perceived substitutability between fixed-line and mobile voice services provides an explanation for the mixed results found in the previous literature that uses aggregate data.Footnote 1
 Our second main finding relates to the role of the incumbents, i.e., the previous fixed-line monopolists, in slowing down the extent of fixed-to-mobile substitution. To investigate this, we extend our base model and estimate it using data for the years 2005 and 2006. For these years, we observe whether households have fixed and/or mobile voice at the incumbent or at a competitor. This enables us to consider the simultaneous choice of fixed and mobile voice, at the incumbent or a competitor. We confirm the presence of fixed-to-mobile substitution in this model. Furthermore, we find that the decline in fixed-line penetration has been slowed down because of various complementarities: bundled contracts and especially incumbency advantages when fixed-line incumbents are also active in mobile telephony. These incumbency advantages increased the incumbent’s market share by about 2.7 % points in fixed telephony and by up to 5.4 % points in mobile telephony at the end of 2006. Incumbents could thus not only slow down the fixed-to-mobile substitution process, but also leverage their strong position in fixed telephony into the mobile telephony market. These complementarities do not hurt, but actually benefit total fixed and mobile penetration. Our third main finding relates to the impact of broadband Internet on fixed-to-mobile substitution. To assess this, we further extended the model to consider the simultaneous choice of fixed versus mobile voice services and the choice of broadband technology (no broadband, dial-up, DSL, cable, mobile broadband and other). Also in this model specification we confirm the presence of significant fixed-to-mobile substitution, especially in the recent years. In addition, we find that the introduction of mobile broadband slightly strengthens this substitution. But more importantly, broadband Internet (mainly DSL) has been a strong source of complementarity with fixed-line telephony. Hence, the decline of fixed telephony has been slowed down because of the complementarity between the fixed network and broadband Internet. In particular, without DSL fixed-line voice penetration would have been about 6.3 % lower at the end of 2006, and almost 8.7 % points lower at the end of 2011. Most of these complementarities arise from bundling fixed-line and broadband in a single contract (enabling price discounts and convenience). These findings show that the fixed-line incumbent has not only been able to leverage its advantage to mobile voice services, but more importantly also to broadband. There is a growing body of literature on substitution between fixed-line and mobile services, as reviewed in the next section. However, none of this work systematically analyzes substitution with detailed household-level data to account for heterogeneity across households and regions. Furthermore, no work has investigated how complementarities have slowed down fixed-to-mobile substitution, through incumbency advantages and synergies with fixed broadband. The remainder of the article is organized as follows. Section discusses the relevant literature. Section 3 discusses the data used in the estimation. Section 4 introduces the econometric framework. Section 5 presents the estimation results. Finally, Sect. 6 concludes.",25
49.0,2.0,Journal of Regulatory Economics,06 January 2016,https://link.springer.com/article/10.1007/s11149-015-9291-1,Warranty regulation and consumer demand: evidence from China’s automobile market,April 2016,Qi Sun,Fang Wu,,,,Unknown,Mix,,
49.0,2.0,Journal of Regulatory Economics,25 January 2016,https://link.springer.com/article/10.1007/s11149-015-9292-0,"Charter values, bailouts and moral hazard in banking",April 2016,Natalya A. Schenck,John H. Thornton Jr.,,Female,Male,Unknown,Mix,,
49.0,2.0,Journal of Regulatory Economics,13 January 2016,https://link.springer.com/article/10.1007/s11149-016-9293-7,The impact of monitoring and enforcement on air pollutant emissions,April 2016,Jinghui Lim,,,Unknown,Unknown,Unknown,Unknown,,
49.0,2.0,Journal of Regulatory Economics,08 February 2016,https://link.springer.com/article/10.1007/s11149-016-9294-6,Impact of environmental regulation and the 2011 earthquake on the Japanese electricity industry,April 2016,Shigeharu Okajima,Hiroko Okajima,,Unknown,Female,Unknown,Female,"The Japanese government started electricity deregulation nearly two decades ago, yet market competition has been very limited and the electricity price remains expensive. New entrant electricity retailers, which we call entrants hereafter, represent less than 1 % of the total electricity-generating capacity and 2.1 % of electricity retailing. In addition, Japanese electricity prices have remained high compared to other developed countries. For example, Japan’s industrial (residential) electricity price is 45 % (28 %) higher than those in the UK and 190 % (133 %) higher than those in the US (Agency for Natural Resources and Energy 2014). Furthermore, Japan has suffered from electricity shortages and corresponding power price increases since the Great East Japan Earthquake in 2011 because all of the country’s nuclear power plants came to a standstill after the earthquake. Accordingly, the Japanese government is under pressure to revisit electricity deregulation to attract more market entrants, who are considered increasingly important to bridge energy gaps and stabilize electricity prices. Given this situation, there is a growing need to clarify what is preventing new entrants in the market and how this potentially affects electricity prices. Previous studies show that it is generally difficult to enhance competition in retail electricity markets (e.g., Joskow and Tirole 2006; Von Dehr and Hansen 2010; Creti et al. 2013). In this study, we particularly investigate the impact of environmental policies, which might affect the entry of new power suppliers and electricity prices but have been ignored largely by previous studies. In response to concerns about climate change, the Japanese government enacted what is known as the green contract law in 2007. This is an environmental quality threshold regarding \(\hbox {CO}_{2}\) emission factors. As Heyes (2009) points out, an environmental policy can hit small firms disproportionately because per unit regulatory compliance costs will be higher at smaller firms if there are substantial fixed costs associated with compliance. If this is the case, the green contract law may lower entrants’ competitiveness, reduce market competition, and potentially raise electricity prices. At a more macro level, there is a rich body of literature on the impact of environmental policies on the competitiveness of a country, among which Porter (1991) and Porter and Vander Linde (1995), together known as the Porter hypothesis, stand out. In contrast to Heyes (2009), the Porter hypothesis states that strict, well-designed environmental regulations can trigger innovation that partially or more than fully offsets the costs of compliance. If the hypothesis holds for the green contract law, complying with the law may make entrants competitive against electricity utilities, which we call incumbents hereafter, increase market competition, and possibly lower electricity prices. However, many studies that have tested the Porter hypothesis only provide conflicting results, probably because outcomes depend highly on the context and methodologies. For example, Jaffe et al. (1995) review previous studies and find either small or statistically insignificant effects of environmental regulations on competitiveness. Lanoie et al. (2008) examine productivity growth in Quebec’s manufacturing sector and find that the impact of environmental regulations on productivity is contemporaneously negative but becomes positive a few years later. This indicates the importance of capturing the dynamic impact of the green contract law in our analysis. To investigate the impact of the green contract law on market competition and electricity prices, we analyze Japanese electricity procurement auctions in the public sector. These auction data are relatively accessible. In addition, open competitive bidding is likely to reflect a bidder’s true cost, which is otherwise difficult to estimate. In other words, differences, if any, in the winning bids of entrants and incumbents imply differences in the costs of entrants and incumbents. In auction theory, it has been shown that bidder asymmetry potentially reduces competition (e.g. Myerson 1981; Maskin and Riley 2000; Krishna 2009). In addition, there are some empirical studies conducted on asymmetric bidders based on a reduced form. Porter and Zona (1999) examine Ohio milk auctions and find that behavior differs by firm. De Silva et al. (2003) explore differences in the bidding patterns of entrants and incumbents in road construction auctions in Oklahoma. They find that entrants bid more aggressively than incumbents and win auctions with lower bids. Estache and Iimi (2010) investigate asymmetric bidders using procurement data from official development assistance projects. They find that entrants actually submitted aggressive bids in the presence of incumbents. In Japanese electricity procurement auctions, bidder asymmetry is most likely to exist between incumbents and entrants because incumbents exclusively own nuclear power plants, the cheapest sources of low-carbon electricity. We apply the endogenous switching regression model to the auction data to show the asymmetric impacts of the green contract law on the bidding behavior of incumbents and entrants and their winning bids. Overall, our results are encouraging for the Japanese government. The analysis shows that as long as competition is maintained, the green contract law can curb \(\hbox {CO}_{2}\) emissions by eliminating high-carbon entrants from auctions without raising winning bids. Indeed, once entering green auctions, entrants can offset the cost of compliance with the green contract law in a few years, as stated in the Porter hypothesis. On the contrary, the compliance cost did not affect incumbents until the 2011 earthquake, when their operational costs and \(\hbox {CO}_{2}\) emissions were significantly affected by the shutdown of nuclear power plants and increased reliance on fossil fuels. Several studies examine Japanese electricity procurement auctions, although the green contract law is not included in their analysis. Hattori (2010) empirically analyzes the determinants of the number of bidders from 2005 to 2008. He shows that the number of bidders is affected negatively by the load factorFootnote 1 and is affected positively by the voltage level (high or extra-high) and contract demand. Hosoe and Takagi (2012) examine the effectiveness of the auctions by measuring the decline in electricity prices in 2005. Using the endogenous switching regression model to solve the endogeneity of the number of bidders, they show that electricity procurement auctions reduced the electricity price by 0.46 yen/kilowatt hours (kWh) on average. While both Hosoe and Takagi (2012) and this study employ the endogenous switching model, there are several important differences between the two studies. First, Hosoe and Takagi (2012) use data from only 2005 to 2008. Consequently, they do not study the impacts of the green contract law nor the 2011 earthquake on the Japanese retail electricity market. Second, the results in Hosoe and Takagi (2012) may be inconsistent because some of the second-stage regressors are excluded from the first-stage regressors (Wooldridge 2010). Third, for robust identification, our model imposes an exclusion restriction, without which the endogenous switching model suffers from collinearity in the second stage (Nawata 1994). Lastly, our model includes some regressors that are not included in Hosoe and Takagi (2012) in order to avoid omitted variable bias. The remainder of this paper is organized as follows. We explain Japanese electricity procurement auctions and the green contract law in Sect. 2. Section 3 describes our data set. Our models are explained in Sect. 4. Regression results are provided in Sect. 5. We discuss some policy implications in Sect. 6. Finally, Sect. 7 summarizes our findings.",
49.0,2.0,Journal of Regulatory Economics,11 March 2016,https://link.springer.com/article/10.1007/s11149-016-9295-5,The disparate adoption of price cap regulation in the U.S. telecommunications and electricity sectors,April 2016,David E. M. Sappington,Dennis L. Weisman,,Male,Male,Unknown,Male,"Rate of return regulation (RORR) has been roundly criticized by regulators, regulated firms, consumers, and scholars alike. Under RORR, the prices the regulated firm can charge for its services are set to allow the firm to recover its costs and earn a fair return on its investments. Regulators often disfavor RORR because it can weaken the firm’s incentive to reduce its costs and because it can entail substantial regulatory oversight that is both costly and time consuming. Regulated firms often object to RORR on the grounds that it provides little reward for exceptional performance and can invite regulatory micromanagement of its activities.Footnote 1 Consumers dislike the high prices that can accompany high costs under RORR. Numerous scholars have identified additional problems that RORR can introduce, including excessive infrastructure investment, limited innovation, inefficient choice of production technology, welfare-reducing diversification into unregulated markets, and inappropriate shifting of costs from unregulated to regulated operations.Footnote 2
 Dissatisfaction with RORR has led to experimentation with alternative forms of industry governance, often referred to collectively as performance based regulation (PBR) or incentive regulation. Price cap regulation (PCR) is a form of PBR that allows the prices the regulated firm charges for its services to diverge from realized costs during the specified PBR regime. PCR can thereby provide strong incentives for the firm to reduce its operating costs during the PBR regime. Under a form of PCR that is commonly employed in the U.S., the firm’s prices are set to reflect prevailing costs at the start of the PBR regime, and then are permitted to increase, on average, at the rate of economy-wide retail price inflation (I), less an offset (X), called the X factor for the remainder of the regime.Footnote 3 Under this form of PCR, the X factor measures the extent to which productivity in the regulated industry is expected to increase more rapidly and industry input prices are expected to increase less rapidly than in the economy as a whole (Bernstein and Sappington 1999).Footnote 4 Under such PCR, a firm that either increases its productivity growth rate above expected industry norms or reduces its input price growth rate below expected industry norms has the potential to secure extra-normal earnings. In addition to providing strong incentives for the firm to reduce its operating costs and otherwise increase its productivity, such PCR can reduce the need for costly regulatory hearings to measure costs and re-set prices to match costs during the PBR regime. Although PCR has been widely deployed in the U.S. telecommunications industry (e.g., Abel 2000; Sappington and Weisman 2010), its adoption in the U.S. electricity sector has been far less ubiquitous (e.g., Makholm et al. 2012b; Lowry et al. 2013). The PBR that has been adopted in the transmission and distribution segments of the electricity sector often retains explicit linkages between prices and costs.Footnote 5 It also tends to focus incentives on particular performance dimensions, and often explicitly limits authorized earnings. In addition, experiments with incentive regulation have ended with a return to RORR in some jurisdictions. The purpose of this article is to suggest possible explanations for the relatively limited adoption of PCR in the transmission and distribution components of the U.S. electricity sector.Footnote 6 We emphasize three potential explanations. The first pertains to an element of the implementation of PCR, namely the use of historic industry productivity growth data to predict likely future industry productivity growth. Even when this methodology is applied symmetrically across industries, it can differentially disadvantage regulated suppliers in the electricity sector if the potential for increasing productivity growth over time is relatively limited in this sector. The second explanation concerns the expanded scope for “regulatory bargains” in the telecommunications sector. We suggest that suppliers may have accepted relatively stringent PCR of basic communications services in return for limited regulatory oversight of other communications services. The third explanation is the greater potential for competition in the telecommunications sector. PCR can provide useful pricing flexibility and be particularly effective at motivating cost reduction when it serves as a transition to widespread industry competition (Littlechild 1988). The discussion proceeds as follows. Section 2 briefly reviews the distinct trends in the adoption of PCR in the U.S. telecommunications and electricity sectors. Section 3 identifies a standard implementation of PCR in the U.S. Sect. 4 suggests possible reasons for the less rapid and less ubiquitous deployment of PCR in the U.S. electricity sector. Section 5 concludes with suggestions for further research.",10
49.0,3.0,Journal of Regulatory Economics,04 April 2016,https://link.springer.com/article/10.1007/s11149-016-9297-3,On the optimal design of demand response policies,June 2016,David P. Brown,David E. M. Sappington,,Male,Male,Unknown,Male,"The cost of supplying electricity can vary substantially from day to day and even from hour to hour. This is the case because generating units with relatively high operating costs often must be called upon to produce electricity during times of peak demand. In contrast to the ever-changing cost of supplying electricity, the retail price of electricity typically varies little, if at all, for long periods of time. Such time-invariant pricing reflects historic difficulty in measuring the precise time at which electricity is consumed and ongoing consumer resistance to time-sensitive pricing now that smart meters render such pricing feasible. To help overcome the inefficiencies that arise when the retail price of electricity diverges substantially from the marginal cost of supplying electricity (Borenstein and Holland 2005; Joskow and Tirole 2007), US regulators have, at the urging of Congress, implemented demand response (DR) policies.Footnote 1
\(^{,}\)
Footnote 2 In essence, DR policies compensate electricity customers for reducing their purchases of electricity below historic norms during periods of peak electricity demand. Of central concern in the design of DR policies is the compensation that is provided to consumers who reduce their electricity consumption. The Federal Energy Regulatory Commission (FERC)’s Order 745 concludes that compensation for reduced electricity consumption should reflect the utility’s marginal cost of supplying electricity.Footnote 3 Although such marginal-cost compensation may seem natural, it has garnered intense criticism.Footnote 4 Specifically, critics of Order 745 argue that marginal-cost compensation will induce excessive DR. Hogan (2009, 2010) and Chao (2011), for instance, suggest that the unit compensation for DR should be reduced below the utility’s marginal cost of supplying electricity (c) by the prevailing unit retail price of electricity (r).Footnote 5 Under this compensation policy, a consumer is effectively first required to purchase electricity from the utility at price r before being permitted to re-sell the electricity to the utility at price c (Borlick et al. 2012). Although these arguments seem compelling, they typically have not been accompanied by fully-specified formal analyses. We provide such an analysis and employ it to characterize the optimal regulatory policy in several relevant settings. Our formal analysis accounts for the realistic possibility that some consumers who provide DR may offset some or all of their reduced purchase of electricity from the utility with electricity they produce on-site. For example, some industrial customers may produce electricity with combined heat and power (CHP) units powered by natural gas and some residential consumers may produce electricity using rooftop solar panels. Our analysis provides substantial support for the critics of the FERC’s policy. Indeed, the optimal compensation for DR in the streamlined basic model that we analyze is precisely the compensation that the critics recommend. More generally, though, the optimal compensation can differ from both the level specified in FERC Order 745 and from the level that critics have advocated. 
Chao (2011) suggests that a DR policy will play no useful role when retail prices can adjust rapidly to reflect the prevailing marginal cost of supplying electricity.Footnote 6 Our formal analysis of this issue again provides considerable support for this conclusion, but identifies conditions under which an optimally-designed DR policy can enhance welfare even when smart meters and real-time pricing allow retail prices to reflect prevailing marginal costs. The incremental value of a DR policy in this setting arises because the prevailing retail price affects consumption by all consumers whereas the prevailing compensation for DR only affects the actions of consumers who provide DR. The ability to differentially affect the behavior of a subset of consumers can be valuable when consumers employ different technologies for on-site electricity production and such production entails social losses from environmental externalities. In addition to characterizing the optimal DR policy, we investigate the welfare gains that an optimally designed policy can secure. We also examine the welfare losses that can arise when the FERC’s marginal-cost compensation policy is implemented in place of the optimal policy. We find that the welfare gains from an optimal policy can be substantial under arguably plausible conditions, as can the losses from the FERC’s policy. We develop and explain these findings as follows. Section 2 reviews the key elements of our model. Section 3 characterizes the optimal regulatory policy in the streamlined basic setting where: (1) the retail price of electricity does not vary with the realized state of demand for electricity, (2) consumers cannot influence the baseline level of electricity consumption that determines whether they are providing DR, (3) society values symmetrically the welfare of all consumers, including those who can readily replace DR with on-site generation of electricity and those who lack this capability, and (4) electricity production entails no social losses from externalities. Section 4 identifies the changes to the optimal policy that arise when each of these restrictions is relaxed. Section 5 illustrates the welfare gains that an optimally designed DR policy can secure and the welfare losses that arise when the FERC’s marginal-cost compensation policy is implemented in place of the optimal policy. Section 6 concludes and discusses directions for further research. The Appendix outlines the proofs of all formal conclusions. An online Technical Appendix (Brown and Sappington 2016) provides additional details.",4
49.0,3.0,Journal of Regulatory Economics,21 March 2016,https://link.springer.com/article/10.1007/s11149-016-9296-4,Environmental management systems and compliance at small and lightly regulated facilities: evidence from the New Hampshire hazardous waste program,June 2016,Sarah L. Stafford,,,Female,Unknown,Unknown,Female,"Over the last 20 years many researchers have conducted studies and analyses of the incentives for firms to voluntarily adopt better environmental management practices both to increase compliance with environmental regulations and to go “beyond compliance” in improving environmental performance more broadly.Footnote 1 One of the most well-studied voluntary environmental practices is the adoption of an environmental management system (EMS) to assist firms in reducing their environmental impact. Researchers have examined the factors that encourage firms to adopt an EMS (Uchida and Ferraro 2007; Darnall and Edwards 2006; Khanna and Anton 2002), whether adoption of an EMS improves regulatory compliance (Potoski and Prakash 2005a; Dasgupta et al. 2000) or environmental performance more broadly (Darnall and Kim 2012; Potoski and Prakash 2005b; Anton et al. 2004), and whether adoption of an EMS improves business performance (Ferron Vílchez and Nicole 2015). While a large number of these studies focus on U.S. firms, many have also focused on firms in other locations including OECD countries (Darnall and Kim 2012), Mexico (Blackman 2012; Dasgupta et al. 2000), Japan (Arimura et al. 2008; Uchida and Ferraro 2007) and Malaysia (Low et al. 2015). While EMS studies vary significantly in terms of the explanatory variables used and the particular set of firms studied, some common findings are that larger firms and those facing higher regulatory pressure—either because of the relative stringency of the regulations they face or their environmental exposure—are more likely to adopt an EMS. Another consistent finding is that publicly-traded companies and companies with a global focus are more likely to adopt an EMS. However, evidence on the importance of market and community pressures in EMS adoption is mixed. For example, some studies find that proximity between the firm and its customer or the characteristics of the local community play a significant role in adoption while others find no significant effect. Of the studies that have examined the role of EMSs in regulatory compliance, most, but not all, find that compliance is higher at firms that have adopted an EMS. However, it is not clear whether such improvements are lasting. Thus many studies have focused on environmental performance more broadly to determine how it is affected by EMS adoption. Results in these studies also tend toward positive effects of EMSs on environmental performance, although it is difficult to fully measure environmental performance and there is the concern that performance in more easily measured areas could mask negative results in less observed, but potentially more important, areas. By and large, the existing EMS studies have focused on the largest regulated entities either in terms of overall company size [e.g., Khanna and Anton (2002) study S&P 500 firms; Uchida and Ferraro (2007) examine publicly-traded Japanese manufacturing firms] or in terms of the entities’ potential for environmental harm [e.g., Potoski and Prakash (2005a) study CAA-regulated “major sources”]. With a few notable exceptions (e.g., McKeiver and Gadenne 2005; Hillary 2004), smaller and lightly regulated entities are not included in the analyses. In particular, studies that rely on measures of environmental compliance or performance typically require data from regulatory agencies, and often regulatory agencies only collect such data from larger or heavily regulated entities. Additionally, most studies of both EMS adoption and participation in other voluntary programs show that larger firms are much more likely to take up such programs (Borck and Coglianese 2009). Thus researchers wanting to better understand the role of EMS adoption on compliance and performance can more easily obtain a usable dataset for large and heavily regulated entities. The stringency of many environmental regulations depends on the amount of pollution created or hazardous substances used by an entity, thus in many cases small businesses may be less heavily regulated than larger businesses. Of course, there are also less strictly regulated entities that are not small businesses. Under the 1980 Regulatory Flexibility Act (RFA) as amended by the 1996 Small Business Regulatory Enforcement Fairness Act (SBREFA), small businesses must have the opportunity to participate in the development of environmental regulations and may receive reduced penalties for violations. Generally small and less strictly regulated entities are also less likely to be the targets of regulatory inspections. Given that many of EPA’s information collection programs such as the Toxics Release Inventory or the Biennial Reporting System do not apply to smaller or less regulated entities, it is typically very difficult to assess the impact of environmental policies at such facilities. However, understanding the factors that make smaller and less regulated entities adopt particular programs or comply with environmental regulation is an important policy issue as most of the EPA-regulated entities in the U.S. fall into this category. For example, Stafford (2012) reports that only 3 % of the 350,000 hazardous waste generators in the U.S. face the highest level of regulation (as large quantity generators) while almost 48 % are considered “conditionally-exempt” generators and are subject to only minimal regulation. While the role that a single small or lightly regulated entity plays in damaging human health and the environment might be very small, taken as a group these entities do represent a substantial potential for damage—and thus potential for improvement in environmental performance. To add to our understanding of the role of EMS adoption in compliance at smaller and lightly regulated entities, this paper focuses on conditionally-exempt and small hazardous waste generators to determine the extent to which such facilities adopt an EMS and whether the adoption of an EMS has a significant effect on regulatory compliance. I use a unique dataset of randomly selected and surveyed hazardous waste generators in New Hampshire that includes a significant number of such facilities. Both the presence of an EMS and the compliance assessment is determined by independent observers. As Darnall and Kim (2012) point out, it is extremely rare to have independent verification of environmental compliance at less stringent levels of regulation as most of the regulated community in the U.S. is not inspected with any regularity. Thus this unique dataset provides us with new insight into the role that EMSs may play at the large number of smaller and lightly regulated entities in our economy. The remainder of the paper is as follows. Section 2 provides some background information on environmental management systems while Sect. 3 reviews the relevant literature. Section 4 presents the data used in the analysis and the empirical approach. Section 5 discusses the results of the analysis and Sect. 6 describes the policy implications of the findings and provides some concluding thoughts.",
49.0,3.0,Journal of Regulatory Economics,19 April 2016,https://link.springer.com/article/10.1007/s11149-016-9299-1,Uncertainty and speculators in an auction for emissions permits,June 2016,Corina Haita-Falah,,,Female,Unknown,Unknown,Female,"Emissions trading schemes (ETS) are favored as market-based instruments for controlling pollution because they offer compliance flexibility through trade. Their major appeal is that, assuming competitive emissions markets, they direct the emissions reductions towards the most cost-effective emitters, minimizing the social cost of compliance. These considerations have been recognized by several jurisdictions around the world. First, the European Commission (EC) established the European Union Emission Trading Scheme (EU ETS), which is currently the biggest cap-and-trade program in the world. Its operation commenced in 2005, with the purpose of helping the Member States (MS) to comply with the Kyoto Protocol commitments. The first two phases of the scheme (2005–2007 and 2008–2012, respectively) were characterized by the discretionary nature entailed by the free permits allocation method, also called grandfathering. However, in 2013 auctioning was introduced as the default method of distributing permits, being the most important design change implemented in Phase 3 (2013–2020). While co-existing with free allocation, auctioning will become progressively the sole method of initial distribution by the end of the trading phase. Moreover, while in Phases 1 and 2 of the scheme permits were distributed only to the regulated installations, in Phase 3 non-regulated entities,Footnote 1 such as authorized individuals, investment banks or credit institutions, can also purchase permits directly from the EC through the periodic auctions.Footnote 2 These entities seek to make profits by engaging in speculative activity in the emissions permits markets. Second, the Air Resources Board (ARB) established the California ETS, which has been in place since 2013. Although some industrial facilities receive permits free of charge, the ARB implemented auctioning as a rule for allocating permits beginning with the first compliance period. This is in contrast with the EU ETS in which MS had the option but not the obligation to auction a certain proportion of permits in Phases 1 and 2.Footnote 3 However, similar to the EU auctions, non-regulated firms can also submit bids to the ARB auctions, which are held every quarter. Third, the Regional Greenhouse Gas Initiative (RGGI) is an ETS which regulates emissions in the power sector of nine American states.Footnote 4 The scheme runs in three-year long compliance periods, as of January 2009. Unlike the EU and California ETSs, which are currently using a hybrid between auctioning and grandfathering as the allocation method, the RGGI sells virtually all the emissions permits through auctions. The RGGI auctions are organized at quarterly intervals in a sealed-bid uniform price format and, as in the EU and California, entities without compliance obligations can submit bids along with the regulated firms. This paper is motivated by the emergence of auctioning as a popular method of allocating emissions permits in the ETSs around the world, and by the permission of the non-regulated entities to bid in these auctions. The inclusion of the non-regulated entities brings into attention the secondary market which is often disregarded by the ETS policy literature (Demailly and Quirion 2006; Hepburn et al. 2006; Neuhoff 2007; Benz et al. 2010) or even the economics literature (Subramanian et al. 2007). Despite the extensive theoretical literature which derives important results regarding bidders’ strategies in an auction with a resale market (Haile 2000, 2003; Garratt and Troger 2006; Pagnozzi 2007; Bikhchandani and Huang 1989) bidders’ behavior and auction outcome in the context of an ETS has been scarcely considered. Indeed, several experimental studies investigate polluters behavior in ETS auctions with resale (Goeree et al. 2010; Burtraw et al. 2009) but, to the best of my knowledge, only Haita (2014) studies theoretically polluters compliance behavior in an ETS with an auction and a resale market. However, the author fails to incorporate uncertainty, firms’ heterogeneity or the non-regulated entities. The aim of this paper is to characterize the bidding behavior of two fundamentally different types of bidders, the polluters (regulated firms) and the speculators (non-regulated firms), in an ETS with heterogeneous firms and uncertainty. Using numerical examples, I conduct comparative statics to discuss the influence of the speculators on the outcome of the emissions permits markets and polluters’ profits. To this end I build a two-stage game in which a subset
Footnote 5 of the polluters together with the speculators firstly bid in an auction for the distribution of emissions permits. While the speculators gamble on the secondary market price, the rationale for the polluters’ participation in the auction is their increasing marginal abatement cost (see Sect. 2). In the second stage all firms decide on the secondary market trade, which determines polluters’ abatement (emissions reductions) levels. The auction is modeled as a uniform price sealed-bid auctionFootnote 6 of a perfectly divisible asset, whereby bidders submit demand schedules and receive permits according to their bids, at the price where the aggregated demand equates the supply. In this model the supply of permits is perfectly inelastic and exogenously given.Footnote 7 Finally, the secondary market is modeled as a Walrasian exchange, in which the price is found by setting the excess demand to zero. The underlying assumption of the model is that firms face uncertainty at the auctioning stage. The uncertainty is captured by a common shock to polluters’ emissions needs,Footnote 8 to which they respond idiosyncratically. This response can be either positive or negative, hence defining either a pro-cyclical or a counter-cyclical polluter. The resolution of uncertainty occurs after the initial allocation of permits is completed but before the secondary market trade and abatement decisions take place. In the model, both the polluters and the speculators are assumed to be risk averse. This assumption is supported, for instance, by the theory of the firm literature which argues that risk aversion rather than risk neutrality characterizes firms’ decisions under uncertainty (Sandmo 1971; Leland 1972). In the ETS context, risk-averse polluters and speculators are present also in Colla et al. (2012), Aatola et al. (2013), Baldursson and von der Fehr (2004). Moreover, the empirical evidence suggests that the emissions markets participants are indeed risk averse (Chevallier et al. 2009). Finally, the auction with resale literature supports the risk aversion assumption for the speculators in my model (Kyle 1989; Vargas 2003; Keloharju et al. 2005). In this literature, a perfectly divisible risky asset is auctioned off before its liquidation value is realized, as is the case with the emissions permits in the current model. The main results of the paper can be summarized as follows. First, in addition to compliance motives, a polluter also bids according to a speculative componentin her valuation function, which depends on the resale value of the permit and her risk preference. A speculator, on the other hand, values the first permit exactly at its expected secondary market price. Second, numerical simulations show that the participation of the speculators in the permits markets has an adverse effect on the profits of those polluters that participate in the auction. This is due to the fact that the presence of the speculators, on the one hand enhances truthful bidding by the polluters and, on the other hand, decreases polluters’ purchases in the auction. The latter effect may have a positive impact on the auction-participating polluters insuring them in the case of a negative shock, by reducing their speculative purchases. However, the former effect generally hurts their profits because it increases the auction clearing price. The net effect depends on the relative change in prices and permits earned. Hence, the presence of the speculators creates a trade-off between polluters’ welfare and a higher auction revenue. 
Related literature My paper relates to two studies that model either auctions or speculators in markets for emissions permits. First, in Subramanian et al. (2007) permits are distributed in a uniform price auction, but the secondary market is omitted. Although firms do not bid truthfully in their model, the authors argue for an auction equilibrium which allocates the permits efficiently. However, as my model shows, the possibility for resale considerably affects polluters’ bidding behavior and, thus, it cannot be neglected. While also assuming complete information, their model does not incorporate uncertainty or speculators. Subramanian et al. (2007) find that dirtier firms invest less in abatement than cleaner firms and the abatement level increases in permits availability. Both results follow from the fact that, in their model, permits and abatement are strategic complements. By contrast, in my model abatement and permits are strategic substitutes and, therefore, the level of abatement decreases in the emissions cap. Finally, in their two-firm asymmetric auction game, Subramanian et al. (2007) claim a linear equilibrium in which they impose symmetric intercepts. By contrast, I derive the asymmetric unique linear equilibrium for an auction game with more than two firms, without imposing restrictions on the parameters of the bid functions. Second, Colla et al. (2012) build a model with two rounds of permits trade and risk-averse polluters and speculators, assumed to be atomistic. In their model permits are fully grandfathered rather than being auctioned and, thus, only the polluters are endowed with permits, initially. Therefore, in the first trading round the speculators buy the permits from the polluters and unwind their positions in the second round. The trading rounds are separated by the realization of a common productivity shock, which affects all the polluting firms identically. Polluters are assumed to be homogeneous and therefore, the equilibrium is symmetric. Instead, my model allows for heterogeneity in several dimensions, including different levels of risk aversion and idiosyncratic responses to the common shock. In their modeling approach, capital investment (abatement) increases the productivity of the permits and, therefore, similarly to Subramanian et al. (2007), the authors find that the level of capital investment increases in the emissions cap. The authors show that the price of the first round of trade increases in the number of speculators if and only if they are less risk averse than the polluters. By contrast, since in my model the first market (the auction) is a unilateral market, its price increases with the number of speculators regardless of their risk preference relative to that of the polluters. The paper proceeds as follows. The next section develops the model and the assumptions employed. The model is solved and the analytical results are discussed in Sect.3. Section 4 includes numerical comparative statics and Sect.5 concludes.",4
49.0,3.0,Journal of Regulatory Economics,04 May 2016,https://link.springer.com/article/10.1007/s11149-016-9300-z,Regulating networks in decline,June 2016,Christopher Decker,,,Male,Unknown,Unknown,Male,"For much of the industrialized world, the 20th century was a period generally characterized by ever-expanding demand for services provided by traditional network utilities.Footnote 1 Throughout this period, regulation has generally been premised on a number of explicit and implicit assumptions. First, the services are essential and so access should be provided on an affordable and universal basis. Second, the prospects for competition developing for network services are limited, given natural monopoly attributes. Third, demand for network services will grow, or at least remain relatively stable, over the mid to long-term. These assumptions are increasingly being called into question in some jurisdictions, as demand for certain services which utilize the electricity, gas, postal and fixed telecommunications network infrastructure appear to be in a state of sustained and irreversible decline. Expectations are that this trend will continue, and indeed accelerate in the future, which is raising questions about how these services should be regulated. A ‘network in decline’ can be characterized as one experiencing a sustained, non-temporary, reduction in demand, resulting in excess capacity on large parts of the network most of the time.Footnote 2 Stated differently, access to network capacity is available on most parts of the network if needed, there is limited congestion, and generally no capacity constraints.Footnote 3 There are two elements to this definition of decline. First, the demand reduction is not temporary, but has been sustained over a number of years and is expected to continue, and second, that it is not isolated to specific geographic areas or ‘pockets’ on the network, but rather affects a substantial proportion of the network. Utilization of traditional postal network services can be characterized as being in decline in many parts of the world. The total mail volume of the United States Postal Service (USPS) has decreased by 27 % in less than a decade from 213.1 billion units in 2006 to 155.4 billion units in 2014 (Fig. 1).Footnote 4 Similar declines in the transportation of mail items can be observed in many European countries, such as the UK and France (Fig. 2), and in Australia (Fig. 3). United States Postal Service: total mail volume (Billions). Source United States Postal Service ‘Postal Facts – A Decade of Facts and Figures’ Total mail items delivered in France and UK (billions). Source Post NL ‘European Postal Markets: 2015 An Overview’ Australia Post—Domestic reserved letter service (millions). Source Australia Post Annual Report 2014 Demand for fixed line telecommunications subscriptions in a number of jurisdictions has also been steadily declining. This has resulted in excess capacity and the underutilization of large parts of fixed line telephony networks, particularly the local-loop component.Footnote 5 In the USA, the number of fixed line telephone subscriptions per 100 inhabitants has reduced sharply from 67.64 in 2000 to 42.22 in 2013 (Fig. 4). Recent analysis found that the number of fixed voice connections fell in 15 of 18 countries surveyed in the period between 2008 and 2013 (Ofcom 2014).Footnote 6
 Fixed-telephone subscriptions per 100 inhabitants, 2000–2014. Source ITU, statistics 2015 Conventional natural gas production is decreasing in some parts of the world, and this is having an impact on demand for gas transmission services. In the UK and the Netherlands there has been a steady reduction in conventional gas production over the past 15 years, with production in the UK in 2014 less than a third of production in the year 2000 (Fig. 5). Gas demand in Europe has decreased since 2008, and most projections forecast a continuous decline in demand until 2025 (Agency for the Cooperation of Energy Regulators 2015). Forecasts also suggest declining, or flat, demand for gas volumes delivered to US residential customers in aggregate over the long-term (US Energy Information Administration 2015).Footnote 7
 UK total gas net production (million cubic meters). Source Department of Energy and Climate Change, F.2 Gas Production
 Finally, there are projections for a decreasing rate of growth in demand for electricity consumption in some jurisdictions. In the USA there has been a steady decline in electricity demand growth over the last two decades (Fig. 6) and expectations are that, in the period to 2040, demand growth will be at around, or just below, 1 %. Similar projections for declining demand growth exist in Australia, and under some assumptions, for the UK (Wood and Carter 2013; National Grid Company 2013). U.S. electricity demand growth, 1990–2015 (percent, 3-year moving average). Source Adapted from US Energy Information Administration (2013), U.S. Electricity Demand Growth, Figure 75 Notwithstanding the fact that it has long been recognized that sustained decreases in long-run demand can be a cause of great concern in the network utility industries (MacAvoy et al. 1989), there is only a small, but evolving, literature which considers the implications of network services being in decline. Briglauer and Vogelsang (2011) and Jahn and Prüfer (2008) focus on the implications of potential network overcapacity in fixed telecommunications networks. Bourreau et al. (2012), Inderst and Peitz (2014) and Briglauer (2015) examine the related issue of how access regulation affects the incentives of incumbent and entrant firms to invest in alternative new generation networks. Faruqui (2013, 2014) and Hanser and Horn (2014) examine the impacts of declining demand for traditional electricity networks, while Sioshansi (2014) focuses on the wider implications of the growth of distributed generation for the electricity industry. Brennan and Crew (2016), focusing on the US postal industry, consider the effect of price cap regulation when applied to industries facing declining demand. The more general implications of the significant declines in demand for traditional mail volumes are examined extensively in Crew and Kleindorfer (2012, 2013) and Crew and Brennan (2016).Footnote 8 A growing number of regulatory agencies are now engaging with the potential implications of some network services being in decline, particularly in the postal and electricity industries. This paper examines three general issues associated with this decline for regulators and policy makers. The first issue concerns the continued rationale for regulation of those network services facing declining demand. The second issue, if regulation remains appropriate, is how regulators balance short-term and long-term efficiency considerations in these new circumstances. The third issue concerns the distribution of the impacts of declining network services, in particular, how the costs associated with services being in decline are shared between network operators and network users, and as between different types of user (captive and non-captive). The paper is organized into 7 sections. Section 2 sets out some general factors that appear to be associated with declining demand for traditional network services in some parts of the world. Section 3 sets out some general arguments for and against any adaptation of regulation to deal with declining demand for network services. Sections 4 and 5 deal, in turn, with two of the most contentious issues associated with declining demand: whether allowed revenues should permit the full recovery of the costs of past investments in a network, and the efficiency and distributional effects of applying different rate structures. Section 6 examines three specific regulatory policy issues associated with declining network services, and Section 7 presents conclusions.",12
50.0,1.0,Journal of Regulatory Economics,18 May 2016,https://link.springer.com/article/10.1007/s11149-016-9301-y,Firming renewable power with demand response: an end-to-end aggregator business model,August 2016,Clay Campaigne,Shmuel S. Oren,,Male,Male,Unknown,Male,"Environmental concerns regarding global warming and the adverse health effects of emissions produced by fossil fuel generation have led to a greater reliance on renewable sources of generation, such as solar and wind, which are inherently variable and uncertain. This trend is accompanied by increased proliferation of distributed resources, storage, and smart grid technologies for metering and control, which facilitate demand response and greater observability of the grid. As a result, the electric power industry faces new challenges in planning and operation of the power system that require new institutional and regulatory frameworks, along with appropriate market mechanisms to achieve productive and allocative efficiencies. While the conventional approach to mitigating adverse uncertainty and variability on the supply and demand sides has been increased reliance on reserves and flexible generation units, this approach is expensive, and will undermine the economic and environmental goals of renewables integration. Mobilizing demand side flexibility enabled by smart metering and other smart grid technologies to mitigate the uncertainty and variability of renewable resources is a sustainable solution for addressing the operational challenges posed by massive integration of renewables. Alternative approaches to integrate renewable resources into the power grid and facilitate demand response have been proposed and experimented with by policy makers around the world, and have been the subject of numerous academic studies in the economics and power system literature. From an economics perspective, the gold standard approach to achieving production and allocative efficiency is a centralized market where all renewable resources and conventional resources are pooled together with demand side resources, responding to real time marginal prices set through a market clearing mechanism. However, while such an approach may serve as a useful benchmark, it is impractical, as it would require the system operator to collect information and co-optimize the dispatch of a vast number of resources including conventional generation, renewables and participating demand side resources (PDR). The computational and institutional barriers to such a centralized approach calls for more pragmatic second-best alternatives with more manageable scope. Recent regulatory initiatives such as “Reforming the Energy Vision” (REV) initiated by the New York Public Service Commission (PCS) promote a more decentralized approach as a way to facilitate the integration of decentralized renewable resources and demand response (MDPT Working Group 2015). Likewise, the concept of aggregators that can pool demand side resources and act as intermediaries, offering load reduction into the wholesale market, has been popularized by the emergence of commercial entities such as EnerNOC. The scope of such aggregation can be expanded to include behind-the-meter resources and distributed renewable resources. In this paper we propose and analyze an aggregator business model that assembles a portfolio of variable energy resources (VER) such as wind, and of flexible demand response (DR), with the purpose of producing a firm and controllable bundled energy resource that can be offered into the ISO wholesale day ahead market. We presume that the aggregator is in a position to acquire detailed information and enter into contractual arrangements that enables it to mobilize the DR flexibility so as to offset the VER uncertainty and variability. Such a bundled resource will relieve the ISO from having to procure additional reserves or other ancillary service products for the purpose of mitigating renewables intermittency. Our premise in this paper is that future regulatory reforms will provide incentives to VER to firm up their output and induce loads to surrender their flexibility. On the VER side, such incentives will be enabled when subsidies to renewables such as feed in tariffs will be replaced by nondiscriminatory market mechanisms. Under such a mechanism, uncertain resources bear the cost they impute on the system, whereas flexible resources are rewarded for the flexibility. Furthermore, VER will have to schedule their forecasted production and be subject to deviation settlements in the real time market like other resources, whereas firmed up VER will be eligible for capacity payments through resource adequacy mechanisms. On the demand side, ex ante contractual agreements with an aggregator that compensate the customer for forgone consumption and “information rents” should provide incentives for load to reveal and trade their flexibility. The two principal forms of demand response are direct load control, wherein the aggregator physically constrains participants’ consumption during scarcity events, and price-based control, wherein the participants face real-time prices that reflect current system conditions.Footnote 1 Direct load control has been studied in theory (Chao 1983) and implemented in practice, particularly in contexts such as air conditioner cycling (RLW Analytics 2007). It has the advantage in terms of system reliability, because the response is more predictable; as well as with respect to billing simplicity and predictability, because the customer does not face state-dependent prices. On the other hand, price-based control provides customers with more flexibility (Braithwait et al. 2006). According to standard microeconomic models, the most economically efficient form of control is real-time pricing, because it ensures that customers consume exactly when their marginal benefit is greater than the instantaneous marginal cost of power production (Borenstein 2005; Caramanis et al. 1983; Holland and Mansur 2006).Footnote 2 If the consumer’s demand curve for power were constant over time, then a direct load control contract linked to spot prices would result in the same consumption decisions as real time pricing (Chao and Wilson 1987). Restructured electricity markets are premised on treating electricity at the wholesale level as a homogeneous commodity that is produced and traded based on fluctuating price signals. We argue, however, that at the retail level electricity can be offered as a quality differentiated service with predetermined prices and uncertain availability (quantity control). Such uncertainty is realized through direct load control, or customer response to a load control signal subject to a noncompliance penalty. The above perspective, which has been articulated by Oren (2013), is the underlying paradigm explored in this paper and we will not attempt to contrast it with a real time pricing approach, which as we concede, represents the “economic gold standard.” Specifically, we consider a profit-maximizing aggregator contracting ex ante with DR participants for the right to send a curtailment signal with a specified probability (or, more generally, in specified states of the world, as reflected by a publicly observable index). The curtailment signal effectively raises the participant’s price for calling energy from a particular capacity increment from its original retail rate R, to an exogenously determined “penalty price,” \(H > R\). That is, the capacity increment is an option, and curtailment raises the strike price. We assume that demand response load pays a regulated retail rate, and has no other venue for participating in wholesale markets. The case where \(H = \infty \) can be interpreted as direct load control. This generalizes plans like PG&E’s SmartRate plan, which raises the customer’s tariff for 15 days a year or less. In our generalization, different slices of the household’s consumption capacity have different probabilities of facing curtailment/penalty rate signal. Combined with a model of stochastic valuations for service, this approach models two kinds of imperfect or fractional DR yield: DR that fails to materialize because the customer would not have consumed in the first place (the ex post valuation of consumption is less than R), and DR that fails to materialize because the customer’s ex post valuation is higher than the penalty price, H. In either case we assume that the valuations are constant throughout the time interval, and each valuation is for the energy from an infinitesimal capacity slice, so we do not consider the possibility of partial exercise of a capacity increment within a period. However, by “stacking” these increments, the model generalizes to horizontal load slices that can be fractionally utilized, at a constant level during the period. Less-than-infinite penalties may be a happy medium between the intrusiveness of a hard constraint, and the complexity of a real-time price. Our proposed business model is based on a “fuse-control paradigm” (Margellos and Oren 2015) where the aggregator manages the service quality for the aggregate consumption by imposing a capacity constraint, or by signaling a capacity threshold above which the penalty will be imposed, and leaves the decision of allocating the available power to devices behind the meter to the household. This is a less intrusive alternative to direct curtailment of individual devices, such as air-conditioner cycling programs, for instance. Furthermore, delegating the behind-the-meter allocation allows the customer to reflect intertemporal variations in preferences for different electricity uses, and capture the effect of behind-the-meter variable resources such as solar panels, local storage devices, and deferrable energy uses such as electric vehicle charging, HVAC etc. In our model the aggregator is assumed to submit price-contingent hourly offers into the ISO day ahead market and dispatch curtailment signals to its contracted load based on the awarded quantities in the day ahead market, the realized renewable output, and the deviation settlement prices. Our end-to-end approach seeks to co-optimize the contract design on the demand side with the aggregator’s bidding strategy in the ISO day ahead market and the DR deployment strategy. Motivated by the same concern about the subsidization of VERs’ contribution to reserve costs, Bitar et al. (2011, (2012) consider several stylized market models for renewable power. They use a newsvendor-type model to quantify the effect of imbalance charges on the offer behavior and profit of a renewable producer, and to quantify, for example, the value of forecast improvement in this policy environment. Their second model is a market for reliability-differentiated power, originally studied by Tan and Varaiya (1991, (1993). In this model, the producer owns a stochastic power resource, and sells its entire production in advance without using reserves, by offering contracts with imperfect service reliability. Our model can be seen as a synthesis and generalization of these two models. We cast the problem of designing an optimal menu of variable-reliability demand response contracts as a variation on the classic monopsony screening problem from contract theory. Our approach to embedding this screening problem in a wholesale electricity market follows the literature on priority service, particularly Chao and Wilson (1987) and Chao (2012). However, that literature has focused on perfect competition or regulated social welfare maximization,Footnote 3 and abstracts away from the scheduling and recourse decisions of individual producers. Because we are interested in new business models that manage imbalance, we update the priority service approach in a profit maximization setting, where imbalance cost is reflected by imbalance prices. We also consider preliminary extensions of our analysis to competitive settings. Another point of contrast with Chao (2012) is that our stochastic demand model disaggregates the aggregate demand curve along the quantity axis, and then adds post-contracting noise to valuations, in a manner similar to Courty and Li (2000)’s sequential screening model. However, in contrast to most screening environments, including that of Courty and Li (2000), our producer’s contracting problem is embedded in a newsvendor-like problem, with asymmetric linear prices for positive and negative imbalance. As a consequence, the aggregator’s benefit is not linear (i.e. is not an expectation) over a type distribution. The aggregator-cum-producer co-optimizes its demand response menu with a day ahead offer quantity, with the demand response providing recourse in case of real-time imbalance. Recently, Crampes and Léautier (2015) have used contract theory to study the welfare effects of allowing demand response participation in adjustment markets, when DR participants have private information about their utility from consumption. In their setting, vertically integrated producers contract as profit-maximizing monopolyFootnote 4 retailers with consumers in the first stage, where consumers “buy their baseline” on which adjustment is settled, and producers incur the obligation to produce the contracted amount. Then, in the second stage, all producers experience an identical supply shock (capacity failure), and both producers and consumers can participate in a competitive adjustment market. They employ a stylized, two-type model with asymmetric information to show that there exist cases in which allowing consumers to participate in a competitive adjustment market reduces social welfare, by creating sufficiently large distortions in first-stage retail contracting. There are two major points of contrast between our model and that of Crampes and Léautier (2015) worth mentioning. Crampes and Léautier (2015) treat retail contracting as monopolistic, and view the adjustment market as competitive. In contrast, we take both retail and wholesale prices as exogenous, and we consider monopsony contracting in the adjustment market, with a preliminary extension to Cournot oligopsony. This reflects our focus on the medium-term future, in which the aggregation market has few participants, and is small in toto relative to wholesale markets. We view retail rates as administratively determined, in a manner that is exogenous to consumers’ and aggregators’ decision-making. This is because we are interested in the normative business decisions of aggregators. The second point of contrast with Crampes and Léautier (2015) is purely a modeling choice. Crampes and Léautier (2015) consider a two-type demand model, to give the clearest demonstration of a distortion effect. We model a continuous market demand curve, comprising a continuum of types. This provides a more detailed, less stylized account of how an aggregator should optimize a production offer and DR dispatch policy with knowledge of market statistics, renewable output, demand conditions, etc. While a two type demand model may suffice to illustrate welfare implications, our modeling choice is motivated by a market design perspective, addressing the operational question of “how to” construct and utilize a DR contract menu. We consider the profit maximization problem of an aggregator. This aggregator has two sources from which it produces energy: a VER (“wind”) with known probability distribution over production quantities, and a population of DR participants, with whom it signs contracts ex ante (say, at the beginning of the season) giving the aggregator the right to curtail them with specified probabilities. The market system operator treats reductions in participants’ consumption, induced by curtailment, as the aggregator’s production. The DR participants have private information regarding their valuation for service. For simplicity we assume that the aggregator acts as a monopsonist purchaser of rights to curtail increments of their capacity with specified probabilities. The monopsony assumption is obviously questionable from an institutional perspective unless there are regulatory barriers to entry for aggregetors. Our main motivation for this assumption is to focus on the contracting details. We will discuss how this assumption can be relaxed somewhat allowing for a symmetric Cournot oligopsony model of aggregators competing by offering exclusive contracts to DR load, which is used to firm up their VER supply that they offer into the wholesale market. The exclusivity assumption can be justified on technological grounds, since implementing a curtailment policy either through direct load control or penalty signal may require specialized aggregator-owned equipment. We analyze the aggregator’s problem as a “screening problem” (Börgers 2010) in which the aggregator’s benefit function reflects its participation in the wholesale electricity market, as we describe presently. The aggregator bundles the VER and DR production for sale into a wholesale electricity market by choosing an energy offer quantity q into the day-ahead (DA) market, contingent on DA information. If the DA offer is made contingent only on the price p, then this price-contingent offer policy can be interpreted as a supply offer curve. In the day-ahead, the aggregator receives revenue \(p\, q\). In the real time dispatch (RT) stage, it learns the wind outcome s, the prices a and b for positive and negative deviations respectively from the DA commitment quantity q, and chooses a set of DR participants to curtail. Ex post, this results in a net (“aggregated” or “bundled”) production quantity, \(s + DR \). The aggregator then pays \(b(q - s - DR )^+ - a(q - s - DR )^- \), \(a< p < b\), to settle the difference between the ex post production and the DA commitment. The joint probability distribution over all information is known in advance. One might say that from the ex ante perspective, the aggregator’s problem is a probability distribution over newsvendor problems, and in each newsvendor problem, after the initial quantity choice, the aggregator can take recourse actions in response to observed “demand” (here we mean negative wind), by dispatching DR. The DR cost is nonlinear, determined by the economics of the screening problem. In general the probability distribution over DR actions may be constrained to conform to contracts negotiated ex ante, but this advance commitment has no economic effect: assuming the aggregator faces no statistical or computational limitations, DR can be treated purely as scenario-dependent recourse (see Sect. 2.4.1), whose optimal distribution it can foresee and therefore commit to from the ex ante stage. The population of demand response participants is modeled as a continuum of “increments” of capacity—i.e., potential consumption. Ignoring stochasticity of valuations, each increment is a differential, \(\mathrm{d}x\), on the quantity axis of the population aggregate demand curve.Footnote 5 Each infinitesimal increment has private information, indexed by its type \(\tau \in [{\underline{\tau }}, {\overline{\tau }}] \subset \mathbb {R}\), parameterizing the distribution over its “ex post valuation” \(\theta \) for power at the time of consumption. The types of increments are distributed according to a measure with associated distribution function G and density g, with convex compact support \( [{\underline{\tau }}, {\overline{\tau }}] \subset \mathbb {R}\). The measure of a set of increments under G represents the total potential consumption capacity of that set, in MW. Before laying out the microeconomic model of how DR is produced and how much it costs, we can informally write the aggregator’s problem, from the ex ante perspective, asFootnote 6: Here q, \( DR \), and T are policy variables. The \( DR \) dispatch is determined in real time, although in accordance with a policy determined ex ante, and the corresponding payment T is made ex ante. The exogenous random variables areFootnote 7: We generally assume that \(0< a< p < b\). Allowing a penalty for overproduction, i.e. \(a < 0\), reflecting the frequent occurrence of negative real time prices, would involve minor complications.Footnote 8
 The last item is a continuum of random variables: a process, although indexed by the type of the DR participant, rather than by time.Footnote 9 It does not show up in the informal objective, but we will explain how it affects the DR quantity \( DR \), and payment T. In our most general analysis, random variables are realized, and decisions taken, in four temporal stages. As mentioned above, the contracting decision that is made at the ex ante stage is an expectation over scenario-contingent decisions which can be treated, for analytical purposes, as if they are postponed until real time, after all uncertainties affecting aggregator decisions are realized. At each subsequent stage, information from the previous stage is retained, new payoff-relevant random variables are realized, and forecasts of the random variables in future stages may be updated. We denote the tuple of random variables at each time-stage, drawn from the set of possible events, as “\(\omega \in \varOmega \),” with a subscript denoting that time-stage, and we denote the non-payoff-relevant component as \(\xi \) with the same subscript. Ex ante (EA) stage. The aggregator learns all probability distributions. The aggregator offers the same menu of contracts to each member of the population of DR participants, and the DR participants select their preferred plans. The aggregator makes the aggregate payment T from Eq. (1).Footnote 10
 Day-ahead (DA) stage. The aggregator learns the DA price p: \(\omega _{\text {DA}} = (p,\xi _\text {DA}) \in \varOmega _{\text {DA}}\), and chooses its offer quantity, \(q(\omega _\text {DA})\). The function \(\omega _{DA} \mapsto q(\omega _\text {DA})\) can be interpreted as a supply function offered in the ISO DA market, if it is p-measurable.Footnote 11
 Real time dispatch (RT) stage. The aggregator learns the imbalance prices (a, b) and wind outcome s: \( \omega _\text {RT} = \omega _{\text {DA}} \times (a,b,s,\xi _{\text {RT}}) \in \varOmega _{\text {RT}} \), and chooses the set of DR increments to send curtailment signals to: \(\{\tau : k(\tau ,\omega _\text {RT}) = 1\}\).Footnote 12 A general curtailment function is denoted as \(k \, : \, [{\underline{\tau }}, {\overline{\tau }}] \times \varOmega _\text {RT} \rightarrow [0,1]\), where the value \(k(\tau ,\omega _\text {RT})\) is the ex ante probability that type \(\tau \) is curtailed in RT event \(\omega _\text {RT}\). In Assumption 2 below, we restrict attention to curtailment rules of the form \(k(\tau , \omega ) = \mathbbm {1}_{\{\tau \le \hat{\tau }(\omega _\text {RT}) \}}\). Ex post (EP) stage. The participants’ valuations are realized: \(\omega _{\text {EP}} = \omega _{\text {RT}}\times \{\theta _\tau : \tau \in [0,N]\}\); this determines the realized quantity of demand response. We denote the latter random variable (or its realization in event \(\omega _\text {EP}\)) as \( DR (\omega _\text {EP}, \hat{\tau }(\omega _\text {RT}))\). The aggregator’s primary policy variables are thus We alternate between \(\hat{\tau }\) and k notation for the curtailment policy as convenient. The payment T is a decision, but the screening analysis lets us express the optimal T given a curtailment policy k as a functional of that policy. This is a rather general description, which is suitable to our analysis of the DR contract design component of the aggregator’s problem. However, we only solve the aggregator’s whole problem (the “end-to-end problem”), which embeds the DR contracting into a wholesale offer problem, in special cases. In these special cases, some of the information is realized at earlier stages than in the general case, or is never stochastic; that is, certain advance forecasts are assumed to be perfect. We occasionally omit the DA, RT and EP subscripts on random outcomes when the referent is clear from the context. The remainder of the paper proceeds as follows: In Sect. 2, we characterize the class of merit order curtailment policies and their corresponding contracts in our setting. This determines the cost of implementing a curtailment policy. In Sect. 3, we analyze the aggregator’s end-to-end problem, which embeds DR contracting and dispatch into a newsvendor-style wholesale market. In Sect. 3.1, we present the general model of the aggregator’s benefits from demand response. In Sects. 3.2 and 3.3, we consider two specials cases of the end-to-end problem that we can solve to successive degrees of explicitness. These give us insight into the structure of the aggregator’s end-to-end problem. Finally, we conclude and outline extensions and future directions.",18
50.0,1.0,Journal of Regulatory Economics,04 June 2016,https://link.springer.com/article/10.1007/s11149-016-9306-6,Forecasting bank leverage: an alternative to regulatory early warning models,August 2016,Gerhard Hambusch,Sherrill Shaffer,,Male,,Unknown,Mix,,
50.0,1.0,Journal of Regulatory Economics,28 June 2016,https://link.springer.com/article/10.1007/s11149-016-9307-5,Pricing strategies and competition in the mobile broadband market,August 2016,Joan Calzada,Fernando Martínez-Santos,,Female,Male,Unknown,Mix,,
50.0,1.0,Journal of Regulatory Economics,26 May 2016,https://link.springer.com/article/10.1007/s11149-016-9305-7,Weak versus strong net neutrality: correction and clarification,August 2016,Joshua S. Gans,Michael L. Katz,,Male,Male,Unknown,Male,"The effects of net neutrality regulation has been extensively analysed but there remains substantial disagreement regarding its effects. Gans (2015) demonstrated that the effects of net neutrality regulation on equilibrium outcomes can be greatly influenced by whether content providers charge fees for the services that they offer to consumers. In particular, he found that the existence of such fees may create a channel through which pricing decisions render net neutrality regulation ineffective. Specifically, Gans (2015) found that, if content providers charge for their services and an Internet service provider (ISP) can discriminate on the basis of content in setting its charges to consumers, then regulation that prohibits the ISP from discriminating on the basis of content in setting its charges to content providers (what he called weak net neutrality) will have no impact on any agent’s payoffs. He argued that, to be effective, the rules prohibiting content-based discrimination must apply to the ISP’s pricing with respect to both consumers and content providers (what he called strong net neutrality). This is an important insight and extension of the literature because major content providers such as Netflix charge such fees. In the present paper, we identify an error in Gans (2015)’s conclusion regarding the non-neutrality of strong net neutrality. Correcting this error gives rise to several further considerations and a more nuanced result on strong net neutrality. The paper proceeds as follows. After describing the model in Sect. 2, we demonstrate in Sect. 3 that, under the conditions examined by Gans (2015), the ISP has sufficient instruments to extract the entire social surplus when the ISP can choose its prices to content providers and consumers subject only to non-discrimination requirements. In other words, strong net neutrality is ineffective. Section 4 then considers two situations in which the ISP can no longer perfectly extract social surplus under net neutrality: (a) when there is a regulatory cap on the ISP’s charges to content providers, and (b) when consumers have heterogeneous preferences with respect to content providers. We first show that, when net neutrality takes the form of binding limit on the fees the ISP charges to content providers, this policy meaningfully affects the equilibrium outcome but can result in inefficiencies, including the excessive provision of quality by content providers. We then consider the impact of consumer heterogeneity on these results (Gans 2015, had only a single, representative consumer). We demonstrate that strong net neutrality can harm total surplus by inducing the ISP to exclude low-value content providers from the market. This result is a variant of the standard trade-off inherent with heterogeneous consumers and an inability to engage in price discrimination: the ISP compares setting a high price, which excludes low-value transactions, with setting a low price, which results in greater sales. We also examine the effects of net neutrality on investment incentives.Footnote 1 Gans (2015) found that strong net neutrality can enhance content providers’ incentives to invest in quality, but will have no effect on ISP investment. We demonstrate that the conclusion with respect to content providers’ investment incentives extends to the case of consumers with heterogeneous preferences with respect to quality, but the conclusion with respect to the ISP’s investment incentives does not—there are circumstances under which strong net neutrality regulation reduces the ISP’s investment incentives. Section 5 presents brief concluding remarks. Before proceeding with our analysis, we note that, in 2015, the U.S. Federal Communications Commission (FCC) adopted new net neutrality rules that apply to both fixed and wireless ISPs. It is not yet fully clear how the FCC will interpret its rules and, thus, whether the rules constitute weak or strong net neutrality. The rules appear to ban ISPs from discriminating in their charges to content providers and may ban such charges entirely—the rules prohibit ISPs from charging content providers fees to avoid having their content blocked or throttled, or for receiving preferential treatment.Footnote 2 The rules may also prohibit ISPs from discriminating on the basis of content in setting their charges to end users (consumers).Footnote 3 Our analysis sheds light on how the different possible interpretations will affect the efficacy of the rules.",12
50.0,2.0,Journal of Regulatory Economics,29 June 2016,https://link.springer.com/article/10.1007/s11149-016-9304-8,“Effective regulatory stringency” and firms’ profitability: the effects of effluent limits and government monitoring,October 2016,Dietrich Earnhart,Dylan G. Rassier,,Male,,Unknown,Mix,,
50.0,2.0,Journal of Regulatory Economics,15 April 2016,https://link.springer.com/article/10.1007/s11149-016-9298-2,Profit-enhancing environmental policy: uninformed regulation in an entry-deterrence model,October 2016,Ana Espínola-Arredondo,Félix Muñoz-García,,Female,Male,Unknown,Mix,,
50.0,2.0,Journal of Regulatory Economics,16 September 2016,https://link.springer.com/article/10.1007/s11149-016-9309-3,Railway restructuring and organizational choice: network quality and welfare impacts,October 2016,David Besanko,Shana Cui,,Male,Female,Unknown,Mix,,
50.0,2.0,Journal of Regulatory Economics,26 May 2016,https://link.springer.com/article/10.1007/s11149-016-9303-9,Location choice of FDI firms and environmental regulation reforms in China,October 2016,Liguo Lin,Wei Sun,,Unknown,,Unknown,Mix,,
50.0,2.0,Journal of Regulatory Economics,24 May 2016,https://link.springer.com/article/10.1007/s11149-016-9302-x,Health insurance mandates in a model with consumer bankruptcy,October 2016,Gilad Sorek,David Benjamin,,Male,Male,Unknown,Male,"A common argument for universal health insurance in the debate surrounding the ACA (Affordable Care Act) was the prevalence of consumer bankruptcies due to uninsured medical bills.Footnote 1 However, neither the theoretical ground for this argument nor its concrete policy implications were rigorously formalized. This work contributes to filling that lacuna in the theoretical literature. We study the welfare implications of health insurance mandates using a model in which consumers can default on uninsured medical bills by filing for bankruptcy. We explore the total and distributional welfare effects of supporting (enforcing) insurance mandates with different combinations of premium subsidies and penalties for remaining uninsured. The analysis highlights budget-neutral implementations that are Pareto improving (compared with the pre-mandate regime). The ACA aimed to expand insurance coverage to 50 million uninsured Americans. The ACA regulates insurers, mandates individual health insurance for consumers, and expands both Medicaid coverage and employer insurance provision. In essence, regulations on insurers aim to eliminate discriminatory practices (cream skimming) and the consumer mandate aims to prevent adverse selection (free riding). The large number of Americans without health insurance prior to the ACA was widely considered “the problem of the uninsured”. Gruber (2008) explains why a high rate of uninsured might be a public concern: (1) if the uninsured are risk averse, their lack of insurance suggests possible market failures; (2) the uninsured impose cost externalities on the health care system due to the provision of uncompensated medical care; and finally, (3) a paternalistic motive: people consider health care both a necessity and a basic right that would be provided more effectively through health insurance. Gruber (2008) also surveys possible explanations for the high rate of uninsured individuals, covering possible insurance market failures and their corresponding remedies. The latter were implemented in the ACA through the aforementioned regulations. Another possible explanation considered by Gruber (2008) is implicit insurance provided through uncompensated care: hospitals that are reimbursed by Medicare are legally obligated to provide acute medical care, regardless of the patient’s ability to pay.Footnote 2 Other health care providers may also provide such care for charity motives. However, once treated on credit by medical providers, patients with high medical costs can choose to default on their medical bills by declaring personal bankruptcy or use this option as a threat in debt negotiations. Either way, the bankruptcy system enables at least partial discharge of medical bills, thereby providing partial insurance that serves as an imperfect substitute for standard health insurance. Recently, Mahoney (2015) provided the first compelling empirical support for bankruptcy as implicit insurance. He showed that household’s seizable assets are positively correlated with insurance coverage and with out-of-pocket medical payments. Both findings are consistent with the substitution hypothesis: the closer a household’s assets are to the exemption level, the more it benefits from defaulting on medical bills and, thus, the better its bargaining position vis-a-vis hospitals. 
Gross and Notowidigdo (2011) used the expansion of Medicaid to identify the effect of health insurance status on consumer bankruptcy prevalence. They find that medical bills are pivotal to approximately 25 % of low-income household bankruptcies. Their estimate falls between the 17 % reported by Dranove and Millenson (2006) and the 29 % reported by (2009). Mazumder and Miller (2015) find that the insurance mandates imposed by the Massachusetts Health Reform reduced the probability of consumer bankruptcy in the state by 18 %. Hence, effective implementation of the ACA mandate is expected to significantly decrease medical bankruptcies.Footnote 3
 However, the fact that the potentially bankrupted have chosen to rely on bankruptcy for implicit health insurance suggests they may be worse off under mandated insurance. If so, who would benefit from an insurance mandate? What is the overall welfare impact of a mandate? These are the questions we address here by exploring the total and distributional welfare implications of health insurance mandates. Such a welfare analysis is essential to the completeness of any policy evaluation for both theoretical and practical reasons. To this end, we elaborate Mahoney’s (2015) consumer choice model into a stylized market equilibrium framework. We model perfectly competitive providers that load unpaid medical bills (due to bankruptcy) onto their menu prices, thereby increasing insurance premiums. Hence, the bankruptcy system provides a progressive medical care subsidy for the uninsured, which is funded through the full menu prices paid by the insured.Footnote 4
 
Mahoney (2015) identifies this cost externality as a normative argument for insurance mandates that are enforced by Pigovian penalties on the uninsured.Footnote 5 Such Pigovian penalties are set equal to the expected discharged medical bills under the bankruptcy option. However, the ACA defines a combination of positive and negative incentives for insurance take-up that are income dependent. The positive incentives are progressive premium subsidies for those who purchase insurance. The negative incentives are monetary penalties for not buying insurance; see Gruber (2011) for the details. Our analysis will highlight incentive combinations that support full insurance take-up, which are budget neutral and Pareto improving. Our welfare analysis compares individual utilities and aggregate utility in equilibrium in the health care market, with and without insurance mandates. This comparison is surely meaningful for practical reasons, but we argue that it may also have a normative justification. The uninsured are able to externalize the cost of their medical care due to the legal requirement and the willingness of hospitals to provide medical care on credit. To the extent that the legal requirement reflects social preferences, both reasons for providing uncompensated medical care are consistent with the perception of acute medical care as a merit good.Footnote 6 In Coase’s (1960) view of the reciprocal nature of externalities, subsidies that are effectively provided through bankruptcy could also restore efficiency (as the externality cost can be borne by either party). Nonetheless, in this work, we do not model explicit consumption externalities in medical care. Instead, we take the bankruptcy system as given and account for any welfare gains generated by progressive subsidies in the form of discharged medical bills. First, we show that the efficient insurance take-up level is higher than the market equilibrium. Then, we show that the welfare maximizing insurance coverage depends on policy implementation. If insurance mandates are enforced through penalties alone, then the optimal take-up level may be incomplete. However, if insurance take-up can also be supported by premium subsidies, then complete coverage is socially optimal. Moreover, complete insurance take-up that is supported only by subsidies can be weakly Pareto improving, with all welfare gains allocated to the initially uninsured. Our results imply that if health insurance markets are functioning well, relying on the bankruptcy option as partial insurance is Pareto inefficient. We show that it is always Pareto improving to translate the expected (ex post) subsidies on medical care obtained through bankruptcy to (ex ante) premium subsidies. This normative argument for subsidies is missing in Gruber’s (2011) reasoning for subsidizing premiums as part of the ACA. Instead, Gruber (2011) suggests that it makes sense to impose individual mandates only if insurance is “affordable.” In the discussion, we consider the basic characteristics of the ACA that are consistent with Pareto-improving policy. We also find that the expected costs of premium subsidies and the cost externalities of uncompensated care (the pre-ACA scenario) are of similar magnitudes. The intuition behind the results of our welfare analysis is the following. In the pre-mandate market, the uninsured can utilize acute medical on care on credit due to the legal requirement that hospitals provide care. After being treated, the uninsured can rely on the bankruptcy system to reduce their actual payments—below the bill’s value—by either declaring bankruptcy or bargaining with providers using the bankruptcy option as a threat. The uninsured are thus able to utilize subsidized acute medical care. These effective subsidies reflect the cost and utility externalities imposed by the uninsured on insured, we have discussed above. Eliminating these externalities using only penalties makes the initially (i.e. pre-mandates) insured (uninsured) worse off but will not necessarily improve total welfare. However, the ex post subsidy that is given to the uninsured for utilizing medical care can support insurance take-up when translated into ex ante premium subsidy, thereby making the initially uninsured strictly better off. An equivalent subsidy for health insurance premiums provides the initially uninsured with the same expected level of consumption with lower risk exposure. This work relates to previous studies on insurance markets under limited liability laws.Footnote 7
Sinn (1982) showed that limited liabilityFootnote 8 decreases demand for liability insurance. In his concluding remarks, Sinn postulates that mandatory liability insurance in such cases is likely to be welfare improving. Keeton and Kwerel (1984) showed that limited liability decreases drivers’ demand for liability insurance to an insufficient level, compared with the social optimum, and that subsidizing insurance coverage may be Pareto improving. However, Keeton and Kwerel’s analysis of the automobile market is more complicated than the one presented here. In their analysis, each uninsured driver may be both a victim of car accident and a negligent driver causes the accident.Footnote 9 In addition, their analysis includes pedestrians who are exposed to uninsured damage risk by drivers, without imposing such a risk themselves. In our analysis, only a unilateral cost externality is imposed by the uninsured on the insured (through higher medical prices). The simpler nature of the externalities we study yield stronger conclusions regarding the welfare implications of premium subsidies in medical insurance markets. Moreover, motivated by the actual incentives setup of the ACA, we examine the welfare implications of different combinations of subsidies and penalties, whereas Keeton and Kwerel (1984) confined their attention to increases in minimal insurance coverage requirements that are accompanied by subsidies. Furthermore, Keeton and Kwerel (1984) considered subsidizing car insurance premiums to promote insurance coverage as potentially necessary due to political constraints (compared with mandating insurance coverage). In the present work, the requirement that medical providers treat acute medical needs regardless of the patient’s ability to pay enables the uninsured to rely on limited liability, provided by bankruptcy, as implicit insurance. This legal requirement and ethical norm in the medical profession suggests that some level of subsidized medical care for low-income earners is socially desired. We emphasize here that insurance premium subsidies are more efficient than medical care subsidies provided through the bankruptcy system. On a more technical level, Keeton and Kwerel (1984) study the insurance purchase choice on the intensive margin, whereas our analysis focuses on the extensive margin and aggregate insurance take-up choices. We will deliberately abstract away from possible moral hazard induced by the health insurance and bankruptcy systems (as forms of social insurance). Keeton and Kwerel (1984) considered drivers’ choices to drive a car or use other transportation modes. Such a choice is not present in our context. The determination of prevention efforts (self-protection), which is relevant to both health-promoting and driving behaviors, was not considered in either study. However, Shavell (1986) showed that effective liability limitations reduce incentives for prevention efforts, and most recently, Jaspersen and Richter (2015) showed that premium subsidies decrease prevention efforts, thereby amplifying the ex ante moral hazard explored by Ehrlich and Becker (1972). These results suggest that the bankruptcy option decreases the prevention efforts of those without insurance, and the initially uninsured are likely to continue low prevention efforts under subsidized insurance. Nonetheless, Beard (1990) showed that when prevention efforts include pecuniary costs, the bankruptcy option may actually motivate excessive prevention efforts and that the relation between wealth and prevention efforts is indefinite. Hence, a complete analysis of the moral hazard effects in the framework studied here is left for future work. The paper proceeds as follows. Section 2 presents the detailed setup. Section 3 compares market equilibrium insurance take-up to efficient take-up. Section 4 explores the welfare implications of insurance mandates. Section 5 discusses the results and concludes this study.",
50.0,3.0,Journal of Regulatory Economics,18 December 2016,https://link.springer.com/article/10.1007/s11149-016-9312-8,A Leak in the Lifeboat: The effect of Medicaid managed care on the vitality of safety-net hospitals,December 2016,Lindsey Woodworth,,,,Unknown,Unknown,Mix,,
50.0,3.0,Journal of Regulatory Economics,01 December 2016,https://link.springer.com/article/10.1007/s11149-016-9311-9,Negative price spikes at power markets: the role of energy policy,December 2016,Andreas Gerster,,,Male,Unknown,Unknown,Male,"On September 1, 2008, negative bids were allowed for the first time at the day-ahead market of the European Power Exchange (EPEX). Since then, negative price spikes – sometimes quite large – have become a regular phenomenon. For example, on October 4, 2009, the day-ahead price plunged to −500 EUR per megawatt-hour (MWh) in the trading hour between 2 and 3 a.m., a huge drop given that average price levels during that trading hour amounted to about 38 EUR per MWh in 2009. A key reason for this phenomenon is the rapidly growing share of subsidized electricity supply from renewable technologies in Germany that does not respond to price signals. Between 2000, when Germany introduced the Renewable Energy Sources Act to support investments in renewable energy technologies, and 2015, the share of “green” electricity in Germany’s electricity production almost quadrupled, increasing from almost 7 to some 33%. The support regime established by the Renewable Energy Sources Act grants a technology-specific feed-in tariff per kilowatt-hour (kWh) of renewable electricity that is far above the utilities’ production cost of conventionally generated electricity. Furthermore, irrespective of the level of demand, utilities are obliged to preferentially accept the feed-in of renewable electricity onto the grid. When demand is low, this regime is one of a confluence of factors, including the absence of sufficient storage possibilities for electricity as well as costly and long ramp-up times of baseload power plants, that impel producers to accept even negative prices, reflecting the high opportunity costs of a production stop in conventional plants (Andor et al. 2010; Nicolosi 2010). Besides the strong support for renewable energies, another defining feature of Germany’s energy policy in recent years has been the Nuclear Moratorium in response to the catastrophe in Japan’s Fukushima. The moratorium, which was issued by the German government on March 15, 2011, eventually led to the permanent shut-down of 8 out of a total stock of 17 nuclear power plants and, hence, an immediate capacity reduction of 8409 Megawatt (MW) (BNetzA 2016). The remaining nuclear capacities are legally stipulated to be permanently shut down by 2022. This contrasts with Germany’s ambitions to steadily increase the share of renewables in gross electricity consumption to 35% by 2020 and 80% by 2050 (BRD 2010). Drawing on day-ahead prices from the EPEX spanning from November 1, 2009, until October 31, 2012, and using Markov regime-switching models to separate times of both negative and low prices from a normal price regime, this article econometrically investigates the effects of both Germany’s substantial expansion of renewable energy technologies in electricity production and its Nuclear Moratorium of 2011 on day-ahead prices. By specifying a model that endogenously distinguishes a low-price regime with low or even negative prices from a base regime capturing mean price levels, we analyze the impact of both policies on the frequency of low-price events. Furthermore, to investigate the impact of different policy scenarios on the financial viability of conventional plants, we simulate spot prices and compare them to variable cost of modern lignite- and hard coal-fired power plants with 2010 technology. Given the efforts to foster the development of renewable energies all over the world, it is crucial to understand the interplay between increasing shares of renewables and the occurrence of price drops, as the latter may have substantial implications for the functioning of the power sector. Negative prices, in particular, can result in welfare losses if they are caused by renewable energy technologies that do not respond to prices signals because of fixed feed-in tariffs (Andor and Voss 2016). Moreover, even modest price drops can cause “hidden system cost” (Mount et al. 2012) by endangering the profitability of conventional power plants that are needed to maintain reliability of electricity supply when intermittent renewable energy sources are absent. The financial burden of price drops is particularly large for inflexible baseload power plants, because reducing production levels implies large cost, originating from both ramping cost and opportunity cost due to missed trading opportunities in subsequent hours. The present study builds on the literature of electricity spot price models that often presume multiple price regimes to account for positive price spikes. As an early contribution to this literature, Ethier and Mount (1998) propose a model for electricity prices that captures positive price spikes by applying Hamilton’s (1994) Markov regime-switching framework. Building on the same model framework by expanding it to distinguish between mean-reversion in the absence of a price spike and after a spike, Huisman and Mahieu (2003) introduce an additional regime, whereas Huisman and Jong (2003) and Weron et al. (2004) propose to model independent regimes. To take advantage of fundamental data for modeling time-varying switching probabilities, Mount et al. (2006) introduce a model that employs data on capacity utilization, while Huisman (2008) as well as Kosater and Mosler (2006) employ temperature data. Several empirical studies support the adequacy of regime-switching models for modeling electricity prices, such as Higgs and Worthington (2008) for the Australian electricity market, Jong (2006) for eight distinct electricity markets and Bierbrauer et al. (2007) for day-ahead prices at the EEX. As identified by Janczura and Weron (2010), one of the main drawbacks of existing Markov regime-switching models is implausible classifications of observations into regimes. To avoid such misclassifications, these authors propose modeling the spike regime by a shifted lognormal distribution, which prevents prices below or above a certain threshold value from being classified as a spike. By proposing a Markov regime-switching model that captures price drops instead of positive price spikes, we are able to investigate the determinants of price drops and to simulate the impact of different policy scenarios on the profitability of conventional generation technologies. Our estimation results indicate that governmental regulations concerning renewable energies and nuclear capacities influence the occurrence of price drops. More specifically, we find that high electricity infeed from renewable sources increases the probabilities for price drops, while the reduction of nuclear capacities after the Nuclear Moratorium decreased them. Using the estimated Markov regime-switching models to simulate price trajectories, we demonstrate that reaching an 80% share of renewables decreases the profitability of conventional power plants substantially, with prices falling below variable cost in as many as 47 and 77% of the trading hours for modern lignite- and hard coal-fired power plants, respectively. Further simulations indicate that a nuclear phase-out or the construction of additional storage capacities for load-shifting can mitigate the occurrence of low-price events and thus ease the integration of renewables. The remainder of the article is structured as follows. Section 2 describes the data, while Sect. 3 introduces the econometric model. Section 4 presents the estimation results, evaluates the model and discusses results from policy simulations. Section 5 summarizes and concludes.",4
50.0,3.0,Journal of Regulatory Economics,08 December 2016,https://link.springer.com/article/10.1007/s11149-016-9310-x,Congestion management in power systems,December 2016,Joachim Bertsch,Simeon Hagspiel,Lisa Just,Male,Male,Female,Mix,,
50.0,3.0,Journal of Regulatory Economics,25 November 2016,https://link.springer.com/article/10.1007/s11149-016-9308-4,Regulatory design and technical efficiency: public transport in France,December 2016,Guillermo Díaz,Vincent Charles,,Male,Male,Unknown,Male,"Cities are centers of commercial, educational, and labor activities, which require public transportation to allow people to access them in a socially efficient way. At the same time, given its significant impact on the local governments’ budgets, there has been an increasing concern about the operational efficiency of the service. This is reflected in the ownership regimes and types of contract used to regulate the firms in the sector, which differ widely across countries and even within their borders. We study the effect of these features of the regulatory design on the efficiency of the urban transport firms in France. This is an interesting setup because of the variability of ownership regimes and regulatory contracts across metropolitan areas. Regarding ownership, firms can be public (owned by the local government), private, or a mixture of both. On the other hand, contracts can be of the incentive regulation type or not. While incentives for efficient operation are provided internally in public firms (managers are public officers), for private firms, contracts are the main source for incentives. The two aspects are significant from a policy perspective. If regulating is costly, one would want to have clear evidence that private ownership produces concrete efficiency gains and about the type of contract that enhances them. The multiplicity of ownership regimes and contractual arrangements already suggests a non-trivial answer. Although these questions have been studied previously, some aspects remain open. For example, after surveying the literature of productivity analysis in transportation, De Borger et al. (2002) concluded that, while most of the evidence regarding ownership is positive in favor of private firms,Footnote 1 “none of these studies control for the degree of competition and the nature of government regulation in the sector” (p. 33). They hypothesized that these features might be even more relevant than ownership per se in heavily regulated markets such as urban transportation.Footnote 2
 In order to explore this hypothesis, we study a long panel data (1995–2010) of metropolitan areas in France. We review the effect of ownership and regulatory contract type on efficiency, with a closer look at their interaction. We also study in more detail the mixed public-private ownership, an intermediate between the extremes of fully private and public companies. It is not simple to conjecture how incentives for efficiency can be transmitted under mixed ownership. It is likely that the objectives of the firm are affected by the public participation, given that public firms may care about dimensions other than just profits, such as consumer surplus or sharing profits with the employees (Seim and Waldfogel 2013).Footnote 3 In line with these complexities, our results show a differential performance of the mixed firms according to the type of contract. Another contribution is the application of methodological advances to improve the estimation of the effects. Based on the suggestions of Daraio and Simar (2005), we implement a conditional data envelopment analysis (DEA) frontier approach to estimate technical efficiency.Footnote 4 This method takes into account the different contexts in which the firms operate, and is, therefore, useful to separate the effect of a variable on the production set from its effect on efficiency (the distance to the border of the production set). To illustrate this, consider the following example. If a higher population density reduces the input usage requirements for a given output (i.e., it positively affects the production set), then it would be positively correlated with the usual input-oriented DEA scores, even if it does not affect efficiency—the usual DEA calculates efficiency as the distance to the border of a single production set for cities with possibly widely different population densities. This could complicate the estimation of the efficiency effects of our variables of interest, if some of them are correlated with the population density. Neither of these spurious relations would appear with conditional DEA because this estimator calculates efficiency by comparing cities with similar levels of population density (i.e., similar production sets). Previous attempts to control for the different contexts of production considered “environmental variables” as additional, non-discretional inputs. These approaches, however, required the assumptions of free-disposability and convexity of the production set in the environmental variables (Ruggiero 1998), which are not plausible in our application and are not required for the conditional DEA estimator to work. Our study also highlights the role of unobserved heterogeneity. If unobservable factors affect simultaneously both the efficiency and the prevalence of particular ownership regimes or contracting types, a simple correlation analysis could be misleading. For example, cities with geographical features that reduce the productivity of inputs might be the most interested in delegating the service to private firms or using certain type of contracts. Then, we could observe a negative relation between these ownership regimes or contract types and the estimated input efficiency, even if none of the former have an actual effect on efficiency. To control for this, we take advantage of the panel structure of our data, incorporating fixed effects at the city level. We also contribute to the literature by applying a semiparametric method in the second stage. The method, proposed by Honore (1992), estimates the parameters of a censored variable model without assuming a parametric distribution for the unobservables in the model. To the best of our knowledge, it has not been applied before in this kind of studies. Our results show the importance of a finer definition of ownership type, as well as controlling for the observed and unobserved heterogeneity, which corroborates our modelling choices. We find a differential effect of private and mixed public-private companies on input efficiency:Footnote 5 having the performance of public operators as the benchmark, efficiency is relatively higher for fully private firms, but lower when the service is delegated to a mixed public-private firm. Additionally, the effects seem to diverge greatly by contract type when the firm is mixed. Finally, controlling for both types of heterogeneity has a relevant influence on the estimated effects. The remainder of the paper is organized as follows: Sect. 2 describes the main features of the industry, Sect. 3 describes the methods used, Sect. 4 presents the results, and Sect. 5 concludes.",4
51.0,1.0,Journal of Regulatory Economics,11 February 2017,https://link.springer.com/article/10.1007/s11149-017-9317-y,"Consumer perception, information provision, and regulation of insurance markets",February 2017,Kangoh Lee,,,Unknown,Unknown,Unknown,Unknown,,
51.0,1.0,Journal of Regulatory Economics,02 January 2017,https://link.springer.com/article/10.1007/s11149-016-9314-6,“Cleansing the air at the expense of waterways?” Empirical evidence from the toxic releases of coal-fired power plants in the United States,February 2017,Xiang Bi,,,,Unknown,Unknown,Mix,,
51.0,1.0,Journal of Regulatory Economics,23 December 2016,https://link.springer.com/article/10.1007/s11149-016-9313-7,Contracting for the second best in dysfunctional electricity markets,February 2017,Arina Nikandrova,Jevgenijs Steinbuks,,Female,Male,Unknown,Mix,,
51.0,1.0,Journal of Regulatory Economics,17 February 2017,https://link.springer.com/article/10.1007/s11149-017-9316-z,Applying a third party access model for China’s gas pipeline network: an independent pipeline operator and congestion rent transfer,February 2017,Jing Xu,Michelle Hallack,Miguel Vazquez,,Female,Male,Mix,,
51.0,1.0,Journal of Regulatory Economics,09 March 2017,https://link.springer.com/article/10.1007/s11149-017-9320-3,"Quality, remuneration and regulatory framework: some evidence on the European electricity distribution",February 2017,Angel Arcos-Vargas,Fernando Núñez,Juan Antonio Ballesteros,Male,Male,Male,Male,"Since the end of the eighties, an increasing number of European regulatory authorities have been pushing a liberalization process that has involved the privatization of various activities in infrastructure and network industries such as Telecoms, Transport and Energy, including the electrical power industry. In this latter sector, reforms have involved measures such as privatization, the establishment of regulators and the introduction of competition and decentralization in some markets.Footnote 1 The electrical industry’s liberalization unbundled the basic functions of the power supply business into the following activities; generation, transmission, distribution and retail. In particular, generation and retail/supply activities moved towards more competitive markets, whereas transmission and distribution activities are at present regulated markets. These latter activities, due to their natural monopoly condition, require the intervention of a regulator in order to assure their correct performance and remuneration. As Jamasb and Pollitt (2007) indicate, the aim of electrical power reform in general and incentive based regulation of networks in particular, is to provide utilities with incentives to improve their operating and investment efficiency and to ensure that consumers benefit from this. The paper focuses on the Distribution activity, which involves the delivery of electricity from generation or transmission to the customer. The introduction of regulation in the power distribution market must help to achieve efficient results which otherwise could only be obtained in the free market. The paper centers on an essential element for the correct performance of the sector: the quality of the electricity distribution and in particular aims to identify whether there is or not a possible relationship between regulatory models and the quality of electricity distribution. The influence of other variables, such as the basic remuneration or the incentives received by companies, is taken into account in the analysis of this relationship. The data employed has been obtained from different regulatory bodies of the electrical sectors of various EU countries.Footnote 2 It is thought that, this is the first time performance and regulatory information has been compared in such a way as to reach conclusions on levels of efficiency. As data is at country-level, and for the period of 2004–2009, it is feasible to conduct a study using the panel data technique which allows the control of several sources of variation. In order to carry out a complete comparative analysis, only the following nine countries for which adequate information is available have been considered for the panel; Austria, Czech Republic, Finland, France, Italy, Norway, Spain, Sweden and the United Kingdom. It is possible that the number of countries considered is up to a point small, but it is worth bearing in mind that it is not uncommon to find panels with a limited number of elements in International studies, especially when considering a particular sector. Furthermore, the study is possibly the only one of its kind relating supply quality with Companies’ remuneration and regulatory frameworks at country level. Amongst the various regulatory models, a distinction can be made between cost-based (or traditional) models and incentive-based models. At the beginning of the sectors liberalization process, most countries adopted cost-based models—i.e. rate of return or cost plus. However, those countries with an inadequate level of supply quality have been moving towards incentive-based models such as price-cap, revenue-cap or yardstick, where incentives to companies pursue a reduction in costs and an improvement in quality of supply. This type of model must be applied correctly because a significant cost reduction could also imply lower supply quality. It is for this reason that the introduction of specific incentives for quality appears as a necessary measure to balance the cost-reducing incentives. Regulatory reforms have since emerged as an alternative to the traditional regulation of utilities. Although national regulators adopt variants within this scheme of incentive regulation, it is possible to create a primary classification of countries. A common feature is the use of benchmarking, generally defined as a comparison of some measure of actual performance against a reference or benchmarking performance—see the work of Jamasb and Pollitt (2000) on benchmarking and regulation of electricity transmission and distribution utilities. The rest of the paper is organized as follows. Section 2 offers an overview of the European Electrical Regulatory System. The paper briefly describes the remunerative models applied in the analyzed countries, and offers some relevant notes from previous literature on the relationship between these models and quality of service. Section 3 describes the variables of the study, whilst the estimated models and results are shown and commented in Sect. 4. Finally, Sect. 5 offers the papers conclusions.",5
51.0,1.0,Journal of Regulatory Economics,03 March 2017,https://link.springer.com/article/10.1007/s11149-017-9318-x,Erratum to: Railway restructuring and organizational choice: network quality and welfare impacts,February 2017,David Besanko,Shana Cui,,Male,Female,Unknown,Mix,,
51.0,1.0,Journal of Regulatory Economics,27 February 2017,https://link.springer.com/article/10.1007/s11149-017-9315-0,Acknowledgements,February 2017,,,,Unknown,Unknown,Unknown,Unknown,,
51.0,2.0,Journal of Regulatory Economics,05 April 2017,https://link.springer.com/article/10.1007/s11149-017-9324-z,Pricing and capacity provision in electricity markets: an experimental study,April 2017,Chloé Le Coq,Henrik Orzen,Sebastian Schwenen,Female,Male,Male,Mix,,
51.0,2.0,Journal of Regulatory Economics,14 March 2017,https://link.springer.com/article/10.1007/s11149-017-9321-2,Non-uniform implementation of uniform standards,April 2017,Carmen Arguedas,Dietrich Earnhart,Sandra Rousseau,Female,Male,Female,Mix,,
51.0,2.0,Journal of Regulatory Economics,22 March 2017,https://link.springer.com/article/10.1007/s11149-017-9322-1,Regulatory arbitrage and the FERC rate settlement process,April 2017,George Briden,Jonathan Lesser,,Male,Male,Unknown,Male,"Since 1938, the Federal Energy Regulatory Commission (FERC) has regulated interstate natural gas pipeline rates by applying cost-of-service (COS) principles.Footnote 1 In this paper, we demonstrate that FERC’s regulatory procedures, specifically (i) its rate refund policy; and (ii) the protracted time lag between the effectiveness of new rates and the ultimate determination of final, just and reasonable rates, induce various economic distortions which reduce economic efficiency. Specifically, we demonstrate that FERC rules and procedures create what are essentially arbitrage opportunities for natural gas companies filing for rate increases. Because FERC’s rate refund policy is contrary to fundamental finance theory, not only are companies who file rate cases able to effectively “hold ratepayers hostage,” but in the long run FERC’s procedures lead to inefficient reductions in overall pipeline investment below the competitive ideal. Because of the peculiarities of FERC’s version of rate regulation, we show that, even though a pipeline may have an incentive to “pad its rate base” in order to influence a settlement prior to the litigation of a rate case, the resulting distortion leads to under-investment, because settlement rates will be inefficiently high and available capacity commensurately constrained. Using FERC data, we estimate the potential magnitude of this distortion at between $400 and $700 million per year. We also demonstrate that FERC can eliminate this regulatory distortion with a simple adjustment to its refund policy. Specifically, if FERC were to set the refund interest rate to the pipeline’s as-filed weighted average cost of capital (WACC), the distortionary impact vanishes.",
51.0,2.0,Journal of Regulatory Economics,01 April 2017,https://link.springer.com/article/10.1007/s11149-017-9319-9,Fuel inventory and price relationships in the U.S. electric power sector under regulatory and market change,April 2017,Kyle E. Binder,James W. Mjelde,,,Male,Unknown,Mix,,
51.0,2.0,Journal of Regulatory Economics,29 March 2017,https://link.springer.com/article/10.1007/s11149-017-9326-x,Evaluating mobile number portability policy in the Thai mobile telecommunications market,April 2017,Pacharasut Sujarittanonta,,,Unknown,Unknown,Unknown,Unknown,,
51.0,3.0,Journal of Regulatory Economics,16 May 2017,https://link.springer.com/article/10.1007/s11149-017-9330-1,Concealment and verification over environmental regulations: a game-theoretic analysis,June 2017,Dongryul Lee,Kyung Hwan Baik,,Unknown,,Unknown,Mix,,
51.0,3.0,Journal of Regulatory Economics,27 March 2017,https://link.springer.com/article/10.1007/s11149-017-9323-0,Electricity market mergers with endogenous forward contracting,June 2017,David P. Brown,Andrew Eckert,,Male,Male,Unknown,Male,"Worldwide, the electricity industry has been undergoing considerable consolidation through large-scale mergers and acquisitions.Footnote 1 In the United States, recent examples of high profile electricity market merger cases include Exelon and Constellation (MPSC 2012) and Exelon and Public Service Enterprise Group (PSEG) (FERC 2005) valued at $8 and $16 billion, respectively. Analyses of mergers and market structure changes in the electricity industry present distinct challenges for regulatory authorities. While there is strong potential for market power, conventional market concentration measures used to assess market power are poorly suited for electricity markets (Borenstein et al. 1999; Bushnell 2005, 2007). A prominent issue that has arisen in merger and market power analyses in electricity markets is the effect of firms’ fixed-price forward commitments on firm behavior. Forward contracts result in a firm committing to supply output at a fixed price in advance of the spot market. Such contracts can reflect retail commitments for vertically integrated utilities (Bushnell et al. 2008), competitive arrangements between generators and distribution utilities or retailers (Crew and Kleindorfer 2002; Loxley and Salant 2004), or regulatory requirements imposed on dominant generators (Frutos and Fabra 2012). It is well-established that the incentives of firms to exercise market power in wholesale spot markets depend critically on the quantity of electricity that firms have contracted in advance at fixed prices (Wolak 2000, 2007; Bushnell et al. 2008). A firm that withholds a unit of output in order to exercise market power and raise the spot market price will realize increased revenues only on the portion of its output that will earn the spot market price, and is not previously committed under fixed prices. For this reason, the level of forward contracting has been a central issue in several recent electricity merger cases. For example, in the Exelon and Constellation merger analysis, the assumed level of forward contracts in the post-merger equilibrium had large implications on the predicted wholesale market impacts of the merger (MPSC 2011, 2012). Experts raised concerns that the merged firm will have an incentive to reduce its forward contracts post-merger, elevating concerns over market power execution (see MPSC 2012, p. 47).Footnote 2 Recent changes to the U.S. Federal Energy Regulatory Commission’s (FERC) horizontal market power screens that include pivotal supplier tests have been viewed as improvements to the use of concentration measures in part because they account for firms’ existing forward commitments (Bushnell 2005; FERC 2012, 2015).Footnote 3 However, the use of pre-existing forward commitments abstracts from changes in firms’ incentives to sign new forward contracts in the presence of a merger. In response to these concerns, this paper develops a model to analyze the effect of mergers on firms’ incentives to forward contract. Further, we investigate the impact of endogenous forward contracting on post-merger wholesale market outcomes. Our model is an extension of the broad literature that investigates endogenous forward contracting in oligopoly markets. In particular, we build on the seminal contribution of Allaz and Vila (1993), which investigates the impact of endogenous forward contracting on competition in oligopolistic markets when firms are risk-neutral, compete via Cournot, and forward contract for strategic reasons. In this model, firms unilaterally forward contract to pre-commit to a larger wholesale market output, inducing their rivals to reduce their output. The authors find that forward contracting increases competition because all firms attempt to exploit the pre-commitment effect.Footnote 4
 Other studies have looked at how forward contracting is affected by market structure. Bushnell (2007) investigates the relationship between market structure and the degree of forward contracting using a two-stage model with strategic forward contracting and Cournot spot market competition. Firms are risk-neutral and have symmetric linear marginal cost functions. The author shows that the proportion of market quantity that is forward contracted increases in the number of firms, and that forward contracts magnify the effect of concentration.Footnote 5 Miller (2013) extends this analysis by considering the welfare effects of mergers when firms have symmetric constant marginal costs. The author finds that the welfare losses from mergers are mitigated by exogenous forward contracting, but that when the market is highly concentrated, welfare losses can be increased in the presence of endogenous forward contracting. While the insights of these papers regarding the relationship between forward markets and market power are important, their lessons for merger analysis are incomplete. Results that are based on changing the number of symmetric firms with linear and increasing marginal cost curves do not capture the possibility that a merger simultaneously reduces the number of firms and creates a new firm with a different (lower) marginal cost curve. Likewise, a limitation of analysis of a Cournot model that assumes constant average costs is that it is subject to what is sometimes referred to as the “merger paradox”—mergers other than near mergers to monopoly tend not to be profitable (see Salant et al. 1983). Perry and Porter (1985) argue that in such a model, mergers do not make sense conceptually because firms bring no assets into the merger. The authors develop a framework in which a firm’s marginal cost depends on its capital stock; merging firms combine their capital stock, reducing marginal costs. This framework is adapted by McAfee and Williams (1992) to analyze the welfare effects of horizontal mergers.Footnote 6
 In this article, we combine these various areas of the literature to investigate how mergers affect firms’ incentives to forward contract and illustrate the impact this has on wholesale market competition. In particular, we use a two-stage forward contracting and Cournot competition model based on Allaz and Vila (1993) and Bushnell (2007), in which risk-neutral firms with linear marginal cost compete via Cournot competition and forward contract for strategic reasons. Further, we adopt the capital stock interpretation of marginal cost established by Perry and Porter (1985). By considering an environment where firms’ cost depend on their level of capital stock, we avoid the “merger paradox”. This allows us investigate the relationship between endogenous forward contracts and the estimated effects of mergers. Using this model as a foundation, we illustrate our results numerically using data from Alberta’s wholesale electricity market for 2013. We find that firms reduce the proportion of their wholesale market output that is covered by forward contracts in the post-merger equilibrium. This is driven primarily by a reduction in the strategic effect of forward contracting. That is, in the more concentrated post-merger equilibrium, forward contracting’s effect of suppressing rivals’ wholesale output is reduced. In a symmetric environment, we show that endogenous forward contracting elevates the price effects of a merger because of firms’ incentives to reduce their forward contracted quantities compared to a setting where forward contract quantities are held constant at pre-merger levels. In addition, we find that while endogenous forward contracting by all firms yields larger merger price effects, the merging firms’ profits may be larger in the post-merger equilibrium if all firms’ forward contract quantities are held constant at pre-merger levels. Holding forward contract quantities fixed at pre-merger levels commits the merged firm to a larger level of wholesale output, forcing rivals to reduce their wholesale production. This implies that endogenous forward contracting has the potential to erode the merging firms’ profits. Our results suggest that the price effects of mergers are dampened in regions where firms’ forward contracts are held constant post-merger due to regulatory requirements or mandated supply contracts.Footnote 7 Further, our results demonstrate that merger analyses that take firms’ forward positions (either in MWs or as a percentage of output) as given can understate the wholesale market price effects of mergers in electricity markets. This can lead to biased conclusions regarding the impacts of mergers on market competition. These results provide support for the claims of expert testimony in recent electricity market mergers cases which raise concerns over firms’ incentives to alter their forward contracts post-merger (e.g., MPSC 2011, 2012). Further, these results raise concerns over the use of pre-existing forward commitments in FERC’s market power screening tests to analyze the price effects of proposed mergers. We develop and explain these results as follows. Section 2 reviews the key elements of our model with linear marginal cost, characterizes the equilibrium outcome of our two-stage forward contracting model, and investigates the effects of a merger on forward contracting in the general asymmetric environment. Section 3 considers the symmetric oligopoly equilibrium and illustrates the effects of a merger on forward contracting incentives and wholesale market outcomes when symmetric firms merge. Section  4 numerically simulates potential mergers of existing firms in Alberta using a more general model than the previous sections (allowing for 4th order polynomial costs), to illustrate the interacting effects of forward contracting and mergers in realistic cases. Section 5 concludes and discusses directions for further research. The Appendix provides the proofs of all formal conclusions.",11
51.0,3.0,Journal of Regulatory Economics,07 April 2017,https://link.springer.com/article/10.1007/s11149-017-9325-y,Do exclusivity arrangements harm consumers?,June 2017,Jihui Chen,Qiang Fu,,Unknown,,Unknown,Mix,,
51.0,3.0,Journal of Regulatory Economics,29 April 2017,https://link.springer.com/article/10.1007/s11149-017-9328-8,"Consumer misperception of eco-labels, green market structure and welfare",June 2017,Dorothée Brécard,,,Female,Unknown,Unknown,Female,"A product’s environmental impact is part of its life cycle, from cradle to grave, and thus serves as a credence attribute of goods. Eco-labels enable consumers to ‘identify products and services that have a reduced environmental impact throughout their life cycle, from the extraction of raw material through to production, use and disposal’.Footnote 1 However, most consumers have difficulties navigating ‘the increasingly important and complex world of greener products’.Footnote 2 Accordingly, 91% of Europeans believe that current product labels do not provide enough information (59%) or provide unclear information (32%) about their environmental impact (European Commission [EC] 2013). Consumer misperception of eco-labels arises mainly from eco-label proliferation. The Eco-Label IndexFootnote 3 currently identifies 465 eco-labels in 199 countries and 25 industry sectors. Gruère (2013) notes that the proliferation of environmental labeling and information schemes since the 1990s could be contributing to consumer misperception. Harbaugh et al. (2011) show that when consumers are unsure of labeling requirements, the proliferation of eco-labels decreases the informativeness of labels and thereby increases consumer confusion. How does misperception of competing eco-labels affect consumers’ demand for green products and firms’ strategies? What are the ensuing impacts on welfare, through profits, consumer surplus and the quality of the environment? This paper addresses these issues using a model of two-dimensional product differentiation. A wealth of theoretical literature investigates optimal policies and corporate strategies for eco-labeling when a labeled and an unlabeled product compete (Bonroy and Constantatos 2015).Footnote 4 However, these models assume a single eco-label; they do not address consumers’ difficulties in comprehending competing eco-labels. An exception is Fischer and Lyon (2014), who analyze competition between two perfect eco-labels that deliver full information to consumers: a non-governmental organization (NGO) label and an industry label. They show that such a competition may be more damaging for the environment than an NGO label alone. Only a few studies investigate competing imperfect eco-labels that fail to disclose full information to consumers, thereby causing consumer misperception of labels (Ben Youssef and Abderrazak 2009; Harbaugh et al. 2011; Brécard 2014).Footnote 5 Ben Youssef and Abderrazak (2009) consider a situation in which consumers face two eco-labeled products and use product prices to assess the probability that an eco-label will guarantee high environmental quality. They conclude that firms are incentivized to provide products of lower environmental quality than in the perfect information case and that consumers make their purchasing decision by ignoring eco-labels, which then renders the labels useless. By only considering labeled products, Ben Youssef and Abderrazak neglect the crucial role of eco-labels in helping consumers distinguish green products from ‘brown’ products (those that make no environmental claims). Brécard (2014) introduces an unlabeled product in addition to two imperfectly eco-labeled products. She assumes that consumers view eco-labels as signs of environmental quality but do not perceive the difference in the environmental quality they certify. Moreover, they exhibit heterogeneous willingness to pay (WTP) for environmental quality and, according to their moral and social values, heterogeneous tastes toward the eco-labels. Comparing uniform and non-uniform labeling standards, she shows that this consumer confusion weakens the unlabeled and the greenest firms, to the benefit of the firm that provides the eco-labeled product of medium quality. Furthermore, NGOs and regulators have an interest in harmonizing labeling criteria and in adopting an exact standard; in contrast, although firms also have an interest in harmonizing labeling criteria, they prefer an undemanding standard. Brécard (2014) leaves one issue partly unresolved: How does consumer misperception of competing eco-labels change green market structure and welfare from the case of perfect eco-labels, which disclose full information on environmental quality?Footnote 6
 The current study investigates this issue using a model similar to, but more tractable than, Brécard’s (2014).Footnote 7 The uniqueness of this model stems from the assumption that consumers are homogeneous in their WTP for environmental quality but heterogeneous in their perception of an ideal eco-label, depending on their concern with various ethical issues (e.g., health, pollution, working conditions). Therefore, all else being equal, consumer choices crucially depend on the interplay between WTP for the perceived environmental quality and WTP for a specific eco-label, which is contingent on their ideal label. With this framework, the study compares the case of imperfect eco-labels, in terms of consumer misperception of environmental quality, with the textbook case of perfect eco-labels, in which consumers accurately know the environmental impacts of all available eco-labeled products. Imperfect eco-labeling is related to imperfect quality disclosure, a concept widely examined since Akerlof’s (1970) seminal work. In the absence of a certification process enabling sellers to disclose the quality of their product, consumers face Akerlof’s ‘lemons’ problem: the ‘bad’ products tend to drive out the ‘good’. Such an adverse selection effect leads to multiple equilibria, which depend on buyer expectations of the relationship between price and quality (Wilson 1980). Firms can use prices as signals of product quality. Daughety and Reinganum (2008) show that when firms encounter Bayesian consumers, a unique symmetric separating equilibrium occurs in which the representative consumer accurately assesses the quality of each product from its price.Footnote 8 The current model differs from this literature by proposing that prices do not influence consumers’ beliefs, because consumers face two types of product attributes: environmental quality (disclosed by the absence or presence of an eco-label) and the nature of the eco-label (which may be more or less specific). They do not necessarily interpret high price as a signal of high environmental quality, insofar as they may deem the difference in prices simply as reflecting the difference in eco-label types (i.e., horizontal attributes of labeled products). The role of price is then ambiguous.Footnote 9 The purpose of quality certification is to help firms communicate product quality to consumers by helping them avoid adverse selection, but imperfect certification can result from upstream imperfect disclosure of information or from downstream imperfect understanding of information conveyed by a label. In the first case, the certifier or the firm has an interest in not revealing or manipulating quality information.Footnote 10 A wealth of literature (for a review, see Dranove and Jin 2010) focuses on the reasons for the failure of full information disclosure. The current study’s model differs from that literature by restricting analysis to upstream perfect certification, assuming that eco-labels are delivered by honest certifiers using effective product testing. In the second case, downstream quality signaling is imperfect because consumers do not perfectly assess the quality, despite the reliable certification. The current study’s model falls into this category, along with those of Ben Youssef and Abderrazak (2009), Harbaugh et al. (2011) and Brécard (2014). Note that imperfect eco-labeling is likely to arise from both upstream and downstream imperfect processes of information disclosure, as in Marette’s (2010) model, in which firms can select a credible or a non-credible certification and a portion of consumers are confused, mistaking the credible for non-credible certification. Consumer confusion leads to multiple equilibria in which high-quality products are signaled with credible certification and low-quality products are signaled with non-credible certification. The current framework differs from Marette’s (2010) in that consumer confusion does not lead them to reduce the significance of both (credible) eco-labels but rather to wrongly believe that both labeled products are of the same environmental quality and better than the unlabeled one. The current model’s original assumptionsFootnote 11 fit well with empirical findings on the green consumer profile. Empirical studies reveal that most consumers prefer environmentally friendly products to standard ones (Organization for Economic Co-operation and Development [OECD] 2005; EC 2013, 2014). However, several factors affect preferences and consumers’ WTP for eco-labeled products. For example, in their systematic review of the relevant literature, Taufique et al. (2014) identify 10 constructs that influence consumers’ understanding and perception of eco-labels, including environmental awareness, knowledge, involvement and trust, in addition to sociodemographic features (e.g., education, gender, age). These constructs imply some heterogeneity in preferences for eco-labeled products, which can then be viewed as vertically and horizontally differentiated. Furthermore, according to OECD (2015), double-differentiation of eco-labeled products is particularly widespread in the agricultural and apparel sectors, which display many competing environmental labeling and information schemes. For example, coffees are labeled with many differed descriptors (e.g., organic, bird-friendly, fair trade, shade grown, biodiversity) and varying levels of stringency. The current study provides new insights into consumer misperception effects on firms’ pricing strategies and market structure, social welfare and eco-labeling strategies of various certifying organizations. The main results are fourfold. First, consumer misperception can affect market structure by weakening the green firm (the firm that provides the greenest product), to the benefit of not only the ‘blue’ firm (the firm that offers intermediate environmental quality) but also, in some cases, the brown firm, even though consumers know that the green product is of better quality than the brown one. Second, paradoxically, consumer misperception is not always detrimental to social welfare when consumers view eco-labels as a sign of high environmental quality. Third, although firms would likely adopt the same demanding eco-labeling criteria if they faced fully informed consumers, they might resort to greenwashing if they know how consumers form their beliefs about environmental quality. Fourth, NGOs and regulators faced with consumer misperception implement a less stringent standard than in the perfect information case. The rest of the paper proceeds as follows: Section 2 presents the demand side of the model. Section 3 analyzes the price equilibrium in cases of perfect and imperfect eco-labels and compares market structures in both cases. Section 4 infers the consequences of imperfect information on welfare and analyzes eco-labeling strategies of the various instigators of the eco-labels (firms, an NGO and/or the regulator). Section 5 concludes.",26
52.0,1.0,Journal of Regulatory Economics,09 May 2017,https://link.springer.com/article/10.1007/s11149-017-9327-9,Financial storage rights in electric power networks,August 2017,Daniel Muñoz-Álvarez,Eilyan Bitar,,Male,Unknown,Unknown,Male,"The increased penetration of supply derived from variable renewable energy resources, coupled with the recent decline in the cost of electric energy storage technologies, has brought about an opportunity to significantly reduce the cost of managing the electric power system through careful planning, deployment, and operation of storage resources (Hinds and Boyer-Dry 2014). Broadly, the short-run value of energy storage derives from its ability to arbitrage energy forward in time, enabling both the absorption of power imbalances on short time scales and the more substantial reshaping of supply and demand profiles over longer periods of time. The extent to which the deployment of a collection of energy storage devices might benefit the power system depends critically, however, on the collective sizing, placement, and operation of said devices (Bose and Bitar 2014). The challenge resides in the design and implementation of electricity markets and instruments that induce strategic expansion and operation of storage in a manner that is consistent with the maximization of social welfare over both the long and short run, respectively. The coordinated optimal dispatch of a collection of distributed energy storage resources clearly offers the possibility of a sizable reduction in the cost of servicing demand by reshaping it in such a manner as to alleviate both transmission congestion and the reliance on peak power generation (PJM 2012). Of interest then is the characterization of mechanisms for the integration of storage, which encourage its efficient operation. And of critical importance to this effort is the resolution of the question: who commands the storage? Among the variety of possible answers to this question, there are two extremes—differing in terms of the degree of government intervention—which we naturally refer to as competitive and regulated. Each implies a distinct mechanism for both the operation of the physical storage facilities and the remuneration of the services provided. Broadly, the competitive or market-based operation of storage entails a decentralized operating paradigm in which storage owners pursue their own rational (profit maximizing) interests in the spot energy market. A shortcoming of such approach to storage integration derives from the uncertainty in revenue that storage owner-operators might obtain from the spot market. Energy storage is a capital intensive technology. And several recent studies Drury et al. (2011), Sioshansi et al. (2012), U.S. Department of Energy (2013), Rocky Mountain Institute (2015) have indicated that the risk of incomplete capital cost recovery due to such revenue uncertainty may serve to inhibit investment in storage facilities. Sioshansi (2010) also goes on to show that a complete reliance on the spot energy market to guide the integration of storage may lead to its substantial underutilization relative to the social optimum, as strategic owner-operators of storage will naturally endeavor to preserve intertemporal price differences for purposes of arbitrage. The regulated operation of storage, on the other hand, calls for a centralized operating paradigm in which storage is treated as a communal asset that is centrally dispatched by the Independent System Operator (ISO) to maximize social welfare subject to its physical constraints.Footnote 1 The socially optimal dispatch of storage, in concert with conventional generation and transmission, naturally improves upon the welfare of the system in the short run. Accordingly, such an approach to the operation of storage necessitates the creation of a mechanism capable of extracting and redistributing the value added by storage back to the owners of the responsible storage facilities. Towards this end, we propose a market mechanism founded on the definition of tradable financial instruments, which monetize property rights to storage capacity made available to the ISO for centralized operation. Such an approach resembles the regulation and operation of transmission in the majority of US electricity markets, which entails the centrally optimized operation of the transmission network subject to the locational marginal pricing of energy, and the allocation of financial transmission rights that monetize property rights to said transmission capacity (Alsac et al. 2004; Hogan 1992, 2002a; O’Neill et al. 2002, 2013). There has been recent activity in both academia and industry to identify alternative paradigms to support the efficient integration of storage into power system operations (Sioshansi et al. 2012; PJM 2012). One stream of literature centers on an open access approach to the integration of storage; or more simply, open access storage (OAS) (He et al. 2011; Sioshansi et al. 2012; Taylor 2015). Loosely, we refer to OAS as a regulatory framework in which energy storage facilities are treated as communal assets accessible by all participants in the wholesale energy market. To the best of our knowledge, only two concrete approaches to OAS have been proposed. He et al. (2011) proposes a market framework where storage owners sell physically binding rights to their storage capacity through sequential auctions coordinated by the ISO. The collection of physical rights, which are defined as a sequence of nodal power injections within a specified time horizon, determine the actual operation of the storage. As such, the physical rights associated with a particular storage facility must be collectively feasible with respect to the corresponding physical device constraints. While such physical rights might be used by market participants to execute price arbitrage or mitigate the cost of honoring existing contractual energy commitments, there are several important limitations. First, the ability of a market participant to leverage on a physical storage right depends on her location within the network relative to the storage facilities. Such restriction could serve to limit market access. Second, the eventual physical dispatch of storage is determined by a sequence of auctions – the outcome of which is likely to substantially deviate from the socially optimal dispatch, because of strategic interactions between parties bidding for physical storage rights. Closer to our proposal, Taylor (2015) suggests an approach to OAS that centers on a paradigm in which storage owners sell financially binding rights to their storage capacity through an auction coordinated by the ISO. The ISO is charged with the task of operating storage in a socially efficient manner—not unlike its non-discriminatory operation of the transmission network. As financial rights, they do not interfere with the optimal operation of storage, but rather, they represent entitlements to portions of the merchandising surplus collected by the ISO. A central component of the proposal in Taylor (2015) is the definition of the financial rights in terms of the shadow prices associated with the physical constraints on the storage facilities. This is analogous to the definition of flowgate rights (FGRs) (Chao and Peck 1996, 1997; Chao et al. 2000) in the context of open access transmission. And, as a result, such a definition of financial storage rights is naturally endowed with advantages and disadvantages comparable to those of FGRs in the context of transmission. We refer the reader to Sect. 3.4 and Hogan (2000), Oren et al. (1995) for a more detailed discussion on such issues. We propose a regulatory framework to enable open access storage, which centers largely on the concept of financial storage rights (FSRs). Broadly speaking, FSRs can be interpreted as financial property rights to storage capacity; or, more accurately, as financial entitlements (or obligations) to portions of the storage congestion rent collected by the ISO under the socially optimal dispatch of storage capacity. Being defined as such, FSRs enable the complete decoupling of a storage facility’s ownership from its physical operation. Moreover, the specific form of FSRs that we propose—viz. a sequence of nodal power injections and withdrawals that yield its holder a payment according to the corresponding sequence of nodal spot prices—provides market participants the ability to perfectly hedge physical or financial energy positions against intertemporal price risk in the spot market.Footnote 2 Such hedging capabilities represent a natural complement to financial transmission rights (FTRs) and their ability to hedge spatial price risk across the network. What distinguishes such financial instruments from standard forward energy contracts is the fact that they are issued under the physical cover of transmission and storage capacity, and are settled against the merchandising surplus collected by the ISO. Accordingly, in Sect. 3.5, we establish a generalized simultaneous feasibility test (SFT), which constrains the joint allocation of financial transmission and storage rights in such a manner as to guarantee the ISO’s revenue adequacy. Namely, any simultaneously feasible collection of transmission and storage rights are guaranteed to yield a rent that does not exceed the merchandising surplus collected by the ISO. A positive attribute of the proposed SFT is that it enables the allocation (auction) of FSRs at nodes without physical storage capacity—a feature which genuinely democratizes access to storage by all market participants. The remainder of paper is organized as follows. In Sect. 2, we formulate the multi-period economic dispatch problem with storage, and delineate its optimality conditions. In Sect. 3, we formally introduce the concept of financial storage rights, and establish a general test for simultaneous feasibility, which restricts the allocation of both financial transmission and storage rights in such a manner as to ensure the ISO’s revenue adequacy. In Sect. 4, we illustrate with a stylized example the role of FSRs in synthesizing flexible, fully hedged, fixed-price bilateral contracts for energy. We close with a discussion on directions for future research in Sect. 5. All mathematical proofs are included in the “Appendix” to the paper.",17
52.0,1.0,Journal of Regulatory Economics,20 May 2017,https://link.springer.com/article/10.1007/s11149-017-9331-0,Market distortions and optimal environmental policy instruments,August 2017,Daiken Mori,,,Unknown,Unknown,Unknown,Unknown,,
52.0,1.0,Journal of Regulatory Economics,29 May 2017,https://link.springer.com/article/10.1007/s11149-017-9332-z,"Competition, vertical relationship and countervailing power in the UK airport industry",August 2017,Anna Bottasso,Martina Bruno,Claudio Piga,Female,Female,Male,Mix,,
52.0,1.0,Journal of Regulatory Economics,27 June 2017,https://link.springer.com/article/10.1007/s11149-017-9334-x,Lobbying for Regulation Reform by Industry Leaders,August 2017,Toshihiro Matsumura,Atsushi Yamagishi,,Male,Male,Unknown,Male,"Regulations affect an industry’s costs and incumbent firms often try to influence policymakers’ behavior (Lowry 1992; Engel 1997). Electric power companies, steel manufacturers, and automobile manufacturers often face stricter emissions and/or fuel efficiency regulations that raise costs. However, it is not always true that incumbent firms require weaker regulations. ARCO, the largest retailer of gasoline in California, proposed a stricter (greener) gasoline regulation in the 1990s, and DuPont, the largest chlorofluorocarbons (CFCs) producer, played a substantial role in strengthening the international regulation on alternative CFCs in the 1980s (Cai and Li 2016). In 2016, the Japan Vacation Rental Association proposed a stricter regulation as a countermeasure to neighborhood noise at several regulatory reform councils, which might increase future costs for both incumbents and new entrants.Footnote 1
 A natural interpretation of such cost-increasing lobbying is that a stricter regulation raises rivals’ costs more significantly and strengthens the competitive advantage of the incumbent dominant firms. Based on discussions of “raising rivals’ costs” developed by Salop and Scheffman (1983), Cai and Li (2016) formulated a model in which stricter regulation affects costs non-uniformly among firms. The authors showed that firms with improved competitive advantages due to stricter regulation might engage in cost-raising lobbying. We formulate a free-entry market model in which incumbents engage in lobbying to change regulations, which affects costs for all firms equally, and then new entrants enter the market.Footnote 2 First, we investigate a model in which incumbents produce after their lobbying affects common marginal costs and then new entrants enter the market (Stackelberg competition).Footnote 3 We find that incumbents engage in cost-raising (cost-reducing) lobbying when the demand function is strictly convex (concave). Next, we check the robustness of this result. We consider Cournot competition (both incumbents and new entrants produce simultaneously). We show that if incumbents and new entrants share the same cost function, incumbents never engage in lobbying. However, if cost difference exists between incumbents and new entrants, incumbents may engage in cost-raising lobbying. We also consider lobbying that affects common fixed costs under Stackelberg competition. Again, we show that incumbents may engage in cost-raising lobbying depending on the cost and demand conditions. These results indicate that our result that incumbents may engage in cost-raising lobbying in the free-entry market, is fairly robust if the incumbents are Stackelberg leaders, or if cost difference between incumbents and new entrants exists. This study is closely related to the literature on the pass-through rate of tax (Weyl and Fabinger 2013). The pass-through rate is the rate at which consumers’ prices increase when an exogenous parameter changes. Seade (1985) showed that in Cournot competition with no entry, each firm’s profit can rise as the unit tax increases when the pass-through rate of tax is sufficiently high. Since tax is a typical example of a common cost, their result implies that firms may lobby for stricter regulation to increase common costs. We believe that lobbying often has long-run effects on regulations, which makes it important to examine this issue in a free-entry market. 
Besley (1989) extended Seade’s (1985) work by allowing for endogenous entry and showed that the pass-through rate of unit tax has different conditions from those of Seade (1985) and depend only on the demand condition. However, Besley (1989) did not investigate whether each firm’s profit increases as the common cost increases. More importantly, in Besley’s (1989) model, all firms are symmetric. Therefore, no firm benefits from the increase in common costs. In contrast, our model allows for differences between incumbents and new entrants, either in terms of their role (the incumbents are Stackelberg leaders, whereas new entrants are followers) or costs. This heterogeneity creates the potential for cost-raising lobbying. Our study highlights the importance of incumbent leadership and/or cost differences among firms in the lobbying context. This study is organized as follows. Section 2 introduces the model. Section 3 derives the equilibrium and presents our main result. Section 4 considers an alternative timing in the model (Cournot competition) and analyzes the robustness of our main result. Section 5 addresses lobbying for changing fixed costs rather than marginal costs. Section 6 concludes.",7
52.0,1.0,Journal of Regulatory Economics,08 July 2017,https://link.springer.com/article/10.1007/s11149-017-9336-8,From universal service to universal connectivity,August 2017,Jeffrey T. Macher,John W. Mayo,Glenn A. Woroch,Male,Male,Male,Male,"Universal telephone service has been a policy goal in the United States for more than a century, and has varied over this period in three principal ways. First, public policies promoting universal service have evolved from implicit cross-subsidization of local telephone service, to explicit mechanisms that offer targeted support to reduce telephone service prices to low-income households which are at risk of not subscribing.Footnote 1 Second, the service to which “universal” is deemed applicable has changed. Universal service originally focussed on providing dial-tone availability, but over time policymakers’ attention shifted to service subscriptions rather than simply infrastructure deployment. Third, the breadth of universal service has expanded to include not only basic dial tone, but also features such as 911, three-way calling and call-forwarding. The breadth of universal service was further extended to broadband beginning with the Telecommunications Act of 1996, and this broadband goal has been reinforced through subsequent policy initiatives.Footnote 2
 While universal service has proven to be a malleable concept, two notable aspects of the discussion surrounding universal service have been enduring fixtures. First, universal service has until very recently been thought of exclusively in terms of wireline services.Footnote 3 This fixation on a single, wireline technology for achieving connectivity is curious, if not completely anomalous, when juxtaposed with the underlying network externalities rationale for universal service policies. Specifically, individual consumers only consider their private benefits to communications (relative to the price) when making subscription decisions while not accounting for the social benefits of connectivity writ large (i.e., the network externality). These decisions are, however, independent of the technological means (viz., wireline or wireless) for securing that connectivity. Theoretically (and increasingly in practice) mobile telephony meets individual consumers’ communications objectives.Footnote 4 Second, public policy efforts around universal service have consistently focused on access (or deployment) of telephony to the household rather than to the individual. Implicit in this focus has been the belief that the deployment of a wireline telephone (or more recently a wireline broadband connection) provides universal access to all household members for their communications needs and/or that wireless technologies that are utilized by individual consumers are sufficiently inferior that they should not be counted in universal service measures. The rapid emergence and adoption of mobile telephone service by individuals compels an updated discussion of universal service along these two dimensions. In particular, when commercial cellular telephony was introduced in the U.S. in 1983, it was perceived by many as a niche service confined to businesses and wealthy consumers. Subsequent deployment and adoption of mobile has been nothing short of spectacular: today there are more cellphones than U.S. inhabitants by several alternative penetration measures.Footnote 5 And while cellular service was initially unreliable (i.e., poor reception, dropped calls), widespread deployment of mobile infrastructure and greater allocation of radio spectrum have not only improved service quality but also enabled expanded device functionality through voice, data and video capabilities. This diffusion of mobile telephone service both expands communications connectivity beyond what is possible with fixed-line service and permits a reorientation from households to individuals as the proper unit of analysis. For instance, different household members at any moment in time might communicate in different places (i.e., home or away) or in different formats (i.e., voice, data or video) that are not tied in any meaningful way to the household’s fixed service. In light of this evolution, this paper seeks to make three contributions. First, we develop an alternative measure to the historical (viz., household fixed-line) universal service index. We label this alternative measure universal connectivity. By accounting for both the diffusion of mobile telephone service within households and the mobility of household members, we estimate Americans’ communications connectivity at any moment over the course of the day. The findings indicate that universal connectivity has increased significantly over 2003–2013—a result driven by the rapid adoption of mobile telephone service within households. Second, we examine empirically the economic and demographic drivers of intra-household mobile telephone service adoption using a unique micro-level database over 2003–2013 from the National Center for Health Statistics (NCHS) operating within the Center for Disease Control (CDC). Poisson model estimation results indicate that: (1) mobile and fixed prices and income operate in accordance with accepted microeconomic theory; (2) mobile and fixed telephone service are substitutes; and (3) household member mobility needs and other demographic factors are important determinants of intra-household mobile telephony adoption. Third, we develop counter-factual simulations using the estimation results to explore alternative policies to promote universal connectivity. The current Lifeline Program serves as our baseline. We simulate a policy expansion of the Lifeline Program from its current single telephone subsidy per eligible household to multiple telephone subsidies for individuals in eligible households. The simulation results indicate that this policy change would increase mobile subscriptions within eligible households by 2.25 million (i.e., a 23% increase) and increase total Lifeline costs by roughly $250 million. The rest of this paper is organized as follows: Sect. 2 presents the “universal connectivity” index that examines intra-household mobile diffusion and mobility to determine individuals’ average communications connectivity. Section 3 develops a conceptual model of intra-household mobile telephone demand that informs the empirical methodology. Section 4 presents the empirical approach by detailing the estimation framework, describing the data, and providing descriptive statistics and results. Section 5 presents the estimation results. Section 6 develops simulations based on these estimations intended to capture Lifeline Program policy changes from universal service to universal connectivity. Section 7 offers concluding comments.",7
52.0,2.0,Journal of Regulatory Economics,13 October 2017,https://link.springer.com/article/10.1007/s11149-017-9342-x,In memoriam to Michael A. Crew (1942–2016),October 2017,David Sappington,Menahem Spiegel,,Male,Male,Unknown,Male,,
52.0,2.0,Journal of Regulatory Economics,06 May 2017,https://link.springer.com/article/10.1007/s11149-017-9329-7,Lie aversion and self-reporting in optimal law enforcement,October 2017,Robert Innes,,,Male,Unknown,Unknown,Male,"A common feature of regulation, law enforcement and tax collection is to require agents to self-report an outcome to the government. For example, regulations protecting food safety, product safety and the environment require companies to report violations of legal standards and face sanctions for a failure to do so. Economic and legal scholars have identified a variety of societal benefits from these types of self-reporting schemes. The literature starts with Kaplow and Shavell (1994) and Malik (1993), who show that self-reporting can economize on enforcement by enabling regulators to forgo inspections of reporting violators. Subsequent work shows that self-reporting can be advantageous in promoting remediation of harm (Livernois and McKenna 1999; Innes 1999), preventing costly efforts to avoid apprehension (Innes 2001a), encouraging self-auditing (Friesen 2006; Innes 2001b), enabling private enforcement with cost-effective citizen suits (Langpap 2008), better tailoring fines to agents with different probabilities of apprehension (Innes 2000), and eliciting reports in criminal teams (e.g., Motta and Polo 2003; Buccirossi and Spagnola 2006; Aubert et al. 2006; Feess and Walzl 2004).Footnote 1
 In this literature, an optimal design of self-reporting enforcement accounts for agents’ incentives to truthfully report or not report a violation to the government. An agent only reports correctly if the expected cost of doing so is no greater than the expected cost of falsely reporting “no violation” and facing probabilistic inspection and fines from government officials. However, this weighing of expected costs does not account for a feature of individual preferences that recent work has shown to be pervasive in societies around the world, namely, an individual aversion to lies. Building on initial work of Gneezy (2005), a large literature now documents the presence, determinants and effects of lie aversion (see the survey by Rosenbaum et al. 2014).Footnote 2 Recent papers show that there is a particularly strong aversion to lies in the field versus the lab (Abeler et al. 2014) and that the extent of lie aversion varies across individuals (Gibson et al. 2013). In this paper, I study how an aversion to lies affects both the societal benefits from self-reporting schemes and the optimal design of these programs. Self-reporting is shown to enhance social welfare when agents have heterogeneous lie averse preferences even though (i) self-reporting enjoys no advantage when there is no lie aversion, (ii) lie aversion costs are typically borne by some violators/liars in the optimal regime, and (iii) the aversion costs of lies count in measuring social welfare. A corollary to this result is that the presence of lie aversion, versus no lie aversion, enhances welfare by lowering costs of enforcement; that is, lie aversion is an advantageous trait for society, even though it creates costs of lies. A related conclusion is that an increase in lie aversion generally enhances social welfare. For example, if self-reporting is compulsory rather than voluntary, then agents must explicitly lie in order to avoid the report of harm, rather than simply withhold a report. The explicit lie, versus the smaller “withholding” lie, produces a greater lie aversion cost (Friesen and Gangadharan 2013) and thereby enables greater enforcement economies.Footnote 3 The presence of lie aversion also affects the optimal choice of enforcement effort and the extent to which harm is deterred. On both counts, lie aversion is salutary, saving enforcement resources even while producing greater deterrence on average. To illustrate the forces that lie aversion brings to bear, consider a simple illustration. Suppose that a violation causes harm of 100; the government discovers a violation with 50% probability; a maximal fine of 150 can be levied when a violation is uncovered; and agents are risk neutral.Footnote 4 In addition, let us suppose that potential violators are of three types, “high lie aversion” with a monetary equivalent cost of a lie equal to 30, “middle lie aversion” with monetary equivalent cost of lies equal to 11, and zero (“low”) lie aversion. Without self-reporting, all agents face an expected sanction of 75 (150 \(\times \) 0.50) and are under-deterred because the average fine is less than true harm (100). Now suppose that a compulsory self-reporting regime is introduced with a self-reporting sanction equal to 85. The high and middle aversion types then truthfully self-report because the alternative (falsely reporting “no violation”) leads to an equivalent cost of 75 (the average sanction) plus the respective lie aversion penalties of 30 and 11, for total costs of 105 and 86, both higher than the self-reporting alternative (85). The zero/low aversion types do not truthfully report and face the same cost as in the absence of a self-reporting scheme, 75. For the high and middle types, deterrence is improved, because the agent’s cost of a violation (85 with self-reporting vs. 75 without) is closer to true harm. Moreover, no lie aversion costs are actually borne and welfare is, as a result, strictly improved. Suppose instead that the self-reporting fine is raised to equal true harm, 100. The high types still self-report truthfully (and bear no lie aversion costs), but the middle types now face a lower total cost with a false report (86) than with a truthful report (100). Deterrence is improved for the high types who now face true harm. However, for the middle types, deterrence is marginally improved relative to the lower self-reporting fine (from 85 to 86) but at the cost of the resulting lie, 11. If lie aversion costs are considered illicit (so they don’t count in social welfare), then the latter cost is immaterial and welfare is strictly improved due to the gain in deterrence for the high types. However, if aversion costs “count,” then the question is whether the deterrence benefit of the higher self-reporting fine exceeds the resulting cost of lies to the middle types. In a more general model (studied below), this tradeoff produces an interior choice of self-reporting sanction, between the average sanction for a false reporter and true harm. Beyond optimality of self-reporting, one key implication of this logic is that, with heterogeneous lie aversion, an optimal enforcement regime typically elicits truthful self-reporting by some and false reporting (of no violation) by others. A few other studies also find motive for this outcome. With heterogeneous probabilities of apprehension, those with high apprehension risk self-report and those with low risk do not (Innes 2000; Feess and Walzl 2006). When the regulator cannot commit to ex-post enforcement, optimal regimes must produce incentives for enforcement by leaving some “guilty” agents who have not self-reported (Gerlach 2013).Footnote 5 Heterogeneous lie aversion provides a distinct motive for heterogeneous responses to self-reporting incentives, which in turn may serve to relax the constraints on enforcement created by the lack of an ex-ante commitment capability (Gerlach 2013). While implications of lie aversion for self-reporting enforcement are developed in the simplest possible setting, the forces at play also have implications for more complicated environments. For example, an interesting paper by Burlando and Motta (2016) shows that a regime of self-reporting—that legalizes and taxes, versus enforces and fines—combats corruption because taxpayers/self-reporters are no longer in the bribery market. An individual aversion to misreports, as modeled in the present paper, gives rise to an added advantage of the self-reporting regime of Burlando and Motta (2016) by increasing incentives for self-reporting and withdrawing from corrupt exchanges. This paper’s results on the salutary effects of lie aversion relate generally to Kaplow and Shavell’s (2007) description of optimal moral sentiments.Footnote 6 Kaplow and Shavell (2007) show how guilt and virtue can be inculcated to promote virtuous acts, and deter harmful acts, thereby economizing on ex-post regulatory and subsidy mechanisms that otherwise encourage these choices. In their treatment, guilt and virtue affect the evaluation of harm-creating or harm-avoiding actions—in our case, the decision to create harm or to take care to prevent harm. While the spirit of Kaplow and Shavell (2007) on beneficial regulatory consequences of morality surely applies here, the present paper is distinguished by its focus on a prevalent moral sentiment (lie aversion) that concerns communication, rather than harm creation. Section 2 below describes the model and Sect. 3 shows that self-reporting is optimal in the presence of lie aversion. Section 4 characterizes optimal enforcement policy in the baseline model, when costs of lies count. Section 5 considers welfare benefits of lie aversion. Section 6 discusses extensions, including alternative models in which costs of lies are illicit. Section 7 concludes.",3
52.0,2.0,Journal of Regulatory Economics,19 June 2017,https://link.springer.com/article/10.1007/s11149-017-9333-y,Analyzing occupational licensing among the states,October 2017,Morris M. Kleiner,Evgeny Vorotnikov,,Male,Male,Unknown,Male,"The study of occupational regulations has a long and distinguished tradition in economics (Smith 1937). Some economists have viewed such regulations as rent-seeking behavior and have empirically examined the economic effect of occupational licensing within that framework (Friedman and Kuznets 1945; Friedman 1962). In contrast, others have suggested that regulations provide incentives for workers to enhance their human capital through greater investments in their work life by limiting low skilled substitutes (Shapiro 1986). Occupational licensing has become an increasingly important factor in the regulation of services in the United States. The number of occupations that require licenses from government in order to work has grown since the 1970s, and the percentage licensed has been increasing as well (Greene 1969; Kleiner 2006). The number of studies analyzing the labor market institution of occupational regulation, however, has not been growing proportionately. One of the largest barriers standing in the way of analyzing occupational regulation has been the absence of well-organized national data available for the examination of the influence of attaining an occupational license on wages. Since governmental occupational regulations are largely at the state level and vary greatly, the purpose of this study is to examine the level and the influence of occupational regulations across states using a representative sample of occupational licensing attainment of the U.S. population specifically collected for this study. Unlike previous surveys, we were able to obtain a representative sample of the population at the state level which allowed us to estimate the cross-sectional effects of occupational licensing on wage determination for each state for the first time. Initially, we show estimates of licensing attainment on a state by state basis and find that there is considerable variation. Also, we find that licensing raised the earnings of regulated workers in 16 states. Second, the estimates show that the average increase in earnings due to licensing was approximately 11% nationally in 2013. Finally, we show that occupational licensing exacerbates relative income inequality across the wage distribution.",35
52.0,2.0,Journal of Regulatory Economics,07 July 2017,https://link.springer.com/article/10.1007/s11149-017-9335-9,Optimal policies to promote efficient distributed generation of electricity,October 2017,David P. Brown,David E. M. Sappington,,Male,Male,Unknown,Male,"The distributed generation of electricity is already pervasive in many countries and is expanding rapidly throughout the world.Footnote 1 Distributed generation (DG) can take many forms, including roof-top solar panels, wind turbines, and natural gas-based reciprocating engines or turbines. DG is popular in part because it can limit the amount of capacity required at the primary production site, reduce electricity distribution costs (by moving generation sites closer to final consumers), and reduce generation externalities (e.g., carbon emissions).Footnote 2
 In addition to its many potential benefits, DG introduces at least two policy challenges that presently are the subject of heated debate.Footnote 3 First, depending upon the established retail prices for electricity and the terms of compensation for DG investment and production, electricity customers may undertake excessive or insufficient DG investment and production (Wiser et al. 2007; Borenstein 2015). Second, as customers generate some or all of the electricity they consume, the centralized supplier of electricity (“the utility” ) experiences declines in revenue that typically exceed the associated avoided costs, given the large fixed infrastructure costs of the typical utility (Linvill et al. 2013; Lively and Cifuentes 2014; Perez-Arriaga and Bharatkumar 2014). At least three changes have been proposed to help ensure the solvency of electric utilities while encouraging efficient DG investment and production. First, revised retail rate structures have been proposed. Rate structures that entail higher fixed charges for the right to purchase electricity from the utility and lower marginal charges for electricity actually purchased from the utility can better align the utility’s revenues and costs in the presence of widespread DG (Brown and Faruqui 2014; Costello 2015).Footnote 4
 Second, various payments for DG production have been advocated. Under common net metering policies, DG production causes a customer’s electricity meter to run backward, so the consumer is effectively paid the prevailing retail price of electricity for each unit of electricity he produces on-site. Alternatives to such net metering include: (i) “value of production” feed-in tariffs, whereby a DG customer is compensated for the electricity he produces on-site at a rate that reflects the estimated net social value of the electricity (Farrell 2014a, b); and (ii) “avoided-cost” tariffs, whereby payments for DG production reflect the associated reduction in the utility’s production cost. Third, additional charges on DG suppliers have been suggested. Several states have proposed two-part tariffs that would require DG customers to pay a fixed fee (independent of the level of the customer’s installed DG capacity) to the utility. Proposed monthly fees vary from $4.65 in Utah to $25 in Maine.Footnote 5 Three-part tariffs that include a DG charge that increases with a customer’s generating capacity also have been implemented. For example, the Virginia Electric and Power Company imposes a monthly charge of $4.19/kW on DG units with capacities between 10 and 20 kW (VSCC 2011).Footnote 6 Additional (“demand” ) charges on DG customers that increase with their maximum monthly consumption of electricity also have garnered attention (e.g., Hledik 2014; Faruqui and Hledik 2015; Brown and Sappington 2016b). Despite the widespread policy debate and the substantial variety of policies that have been proposed or implemented, formal analysis of the optimal design of DG compensation is limited.Footnote 7 The present research is intended to help fill this void in the literature and to provide some guidance to policymakers on this important matter. We characterize the retail tariffs, payments for DG production, and charges for DG capacity investment that maximize consumer welfare while ensuring the solvency of the regulated utility. Our analysis allows for both intermittent and non-intermittent DG technologies. Solar panels constitute an intermittent technology in the sense that the amount of electricity produced by the installed capacity is largely exogenous, dictated primarily by environmental conditions (especially the prevailing level of sunshine). In contrast, resources such as fuel cells, gas turbines, and reciprocating engines (which employ natural gas as the primary fuel) constitute non-intermittent DG technologies because the amount of electricity produced by the installed capacity is readily controlled.Footnote 8
 We begin by analyzing a setting in which smart meters are deployed ubiquitously and the regulator can set real-time retail prices and DG payments.Footnote 9 In this setting, retail electricity prices and payments for DG production are both set equal to the utility’s prevailing marginal cost of generating electricity under an optimal policy. These retail prices and DG payments ensure the efficient consumption and production of electricity, given installed generating capacities. Charges on installed DG capacity that reflect the associated increase (or decrease) in the utility’s transmission and distribution costs then induce efficient DG capacity investment. The identical retail prices and DG payments imply that net metering as described above is optimal. Furthermore, the ability to set different retail prices or DG payments for different consumers or for different DG technologies would not enhance consumer welfare. We also consider a setting where the regulator can only establish time-of-use retail prices and time-of-production DG payments. These prices and payments can vary across pre-specified time periods each day, but cannot vary within a time period. To induce desired levels of electricity consumption in this setting, the retail prices are set so that a weighted average of expected deviations of price from the utility’s marginal cost of production is zero. In Ramsey-like fashion (Ramsey 1927; Baumol and Bradford 1970), the weights on deviations between price and cost reflect corresponding price sensitivities of the demand for electricity. To induce desired levels of electricity production from non-intermittent DG technologies, payments for such production are set equal to the utility’s expected marginal cost of production during the relevant time period. To induce desired DG capacity investment, DG capacity charges are set to equate the consumer’s marginal expected return from increasing DG capacity with the corresponding net reduction in the utility’s production cost. This net reduction is the difference between the marginal reduction in the utility’s expected generation costs and the marginal increase (or decrease) in the utility’s transmission and distribution costs as DG capacity expands. Because payments for DG production do not affect the amount of electricity produced with a given level of intermittent DG capacity, a regulator who can impose DG capacity charges has considerable flexibility in setting payments for electricity produced with the intermittent DG technology. In particular, the regulator can equate these payments either with the corresponding payments for electricity produced using the non-intermittent DG technology or with the corresponding retail rates for electricity. Consequently, neither a requirement to set the same DG payments for both technologies nor a requirement to implement the common net metering policy for the intermittent technology would, in isolation, constrain the regulator. However, the imposition of both requirements simultaneously would reduce the level of welfare the regulator can secure for consumers. When social losses from externalities associated with electricity production are present, the foregoing findings are modified in intuitive fashion. In particular, retail electricity prices are optimally increased to discourage the purchase of electricity from the utility as the social losses from externalities associated with electricity production by the utility increase. In addition, DG payments for electricity produced using the non-intermittent technology increase as marginal social losses from externalities associated with this production decline relative to the marginal social losses associated with electricity production by the utility. Thus, more generous payments for electricity produced by “cleaner” DG technologies are optimal, ceteris paribus. Overall, our findings imply that there is no single DG compensation policy that is optimal in all settings. The optimal policy varies with the instruments available to the regulator and with the relevant DG production technologies. Our findings also stress the important role of DG capacity charges. When these charges are feasible, the regulator can set them to induce efficient DG capacity investment while employing payments for DG production to induce efficient levels of electricity production. Net metering can be optimal in certain settings when DG capacity charges are feasible. However, when the regulator is unable to impose capacity charges, payments for DG production must serve to induce desired levels of both DG production and DG capacity investment. This dual role of payments for DG production complicates their design, limits the settings in which net metering is optimal, raises industry production costs, and reduces the level of welfare that can be secured for consumers. We develop and explain these findings as follows. Section 2 presents the key features of our formal model. Section 3 characterizes the optimal policy in the setting where the regulator can set real-time retail prices and DG payments. Section 4 examines the changes to the optimal policy that arise in the presence of social losses from externalities. Section 5 identifies the key features of the optimal policy when the regulator can set time-of-use retail prices and time-of-production DG payments. Section 6 describes the optimal policy when the regulator’s instruments are more limited, i.e., when retail rates cannot vary across demand periods or across customers, and when DG capacity charges are not feasible. Section  employs numerical solutions to illustrate how the optimal regulatory policy and industry outcomes change when the regulator is able to set DG capacity charges. Section 8 reviews the policy implications of our findings and suggests directions for further research.",13
52.0,2.0,Journal of Regulatory Economics,29 July 2017,https://link.springer.com/article/10.1007/s11149-017-9337-7,Strategic bypass deterrence,October 2017,Francis Bloch,Axel Gautier,,Male,Male,Unknown,Male,"In liberalized network industries, competitors can choose between service-based and facility-based competition. In the former case, competing firms offer retail products and services using the incumbent’s installed infrastructure for which they pay an access fee (the “buy”or “access”option). In the latter case, firms develop their own infrastructure to compete on the retail market (the “make”or “bypass”option). This choice between access and bypass is illustrated by the broadband service market where the two modes of competition currently coexist. In countries where access to the incumbent’s DSL network is mandatory rival firms either supply services on the incumbent’s network or develop their own platform (cable TV network, fiber network, wireless) to provide broadband services to consumers.Footnote 1
 When the cost of building an alternative network is large, incumbents have an incentive to deny access in order to block entry of competitors.Footnote 2 Faced with this risk of market foreclosure, regulators have taken steps to mandate access to the network of the historical operator and guarantee access at a reasonable price. This regulatory policy which originated in the 1990s—and is still prevalent in Europe—has evolved in the face of increasing competition among network operators, due to a convergence between technologies and a the development of new generation access networks. In the United States, the FCC has lifted in 2003 most of the regulations imposed by the Telecommunications Act of 1996, maintaining access obligations for the legacy copper networks but lifting them for new infrastructures. In Europe, mandatory access and regulated access prices continue to be imposed but only if the incumbent operator holds significant market power on the wholesale broadband market.Footnote 3 In 2006, virtually all countries found the incumbent operator to hold significant market power on the wholesale broadband market and imposed some form of regulation (Schwarz 2007) but more recently, with the development of competition, regulations have started to be lightened or even removed.Footnote 4 In the future, it is expected that regulation of network infrastructures will be partially removed both in the EU and in the US (Vogelsang 2013) though there are exceptions.Footnote 5
 Our objective in this paper is to shed light on the use of (and the necessity to use) regulatory instruments in network industries. We revisit the literature on access in network industries by comparing technological and economic efficiency in regulated and unregulated markets. Our contribution to the literature is twofold. First we analyze both the profit maximizing behavior of an incumbent and the welfare maximizing behavior when the entrant chooses between access and bypass. Second, we extend the baseline model studied in the literature by allowing for fixed costs of network installation. We study how an unregulated incumbent manipulates access prices in order to deter bypass by the incoming firm. By analogy with the literature on entry deterrence (Tirole 1988) we identify three régimes: accommodated bypass, deterred bypass and blockaded bypass and we characterize the threshold cost levels that separate the three régimes.Footnote 6
 Our analysis revolves around the limit access charge—the maximal access charge under which the entrant prefers to access the incumbent’s network than to bypass. If the limit access charge is too low and induces large losses on the access market, the incumbent prefers to let the entrant construct an alternative network (régime of accommodated bypass). If the limit access charge is higher than the profit maximizing level, the incumbent blocks bypass without distorting the access charge (régime of blockaded bypass). For intermediate values of the limit access charge, the incumbent sets access charges at the limit access charge level in order to deter bypass (régime of deterred bypass). The limit access charge may be lower than the incumbent’s marginal cost so that the incumbent sometimes optimally chooses to sell access at a loss. We next draw a comparison between regulated and unregulated markets using two different efficiency criteria: social welfare measured by total surplus and technological efficiency. We consider a regulator setting access charges but leaving the retail market and the entrant’s option between access and bypass unregulated. If access is chosen, the regulator wants to decrease the access charge with respect to the unregulated incumbent’s choice in order to lower the retail prices paid by consumers. In addition, the regulator wants to induce more access than in an unregulated market. There is thus excessive bypass from a welfare point of view when the access charge is unregulated. The analysis of technological efficiency leads to a different conclusion. Reproducing Mandy’s (2009) analysis—but with a positive fixed cost of bypass—we show that the make or buy decision depends on the level of the access charge and may be inefficient. When bypass is chosen, it is always efficient, but access may be chosen even when bypass is cheaper. There is thus excessive access from a technological point of view.Footnote 7
 The choice between service-based and facility-based competition has already been studied in previous papers. In a static setting, Sappington (2005) demonstrates the irrelevance of the access charge for the choice between service- and facility-based competition and shows that the most efficient mode of competition always emerges in an unregulated market. The entrant develops its own infrastructure only if he can provide the network input more efficiently than the incumbent. Sappington’s argument is obtained assuming a Hotelling model with a fully-covered market. Gayle and Weisman (2007) demonstrate that, in more general settings, the access price matters for the choice of a mode of competition. Mandy (2009) identifies a set of access prices that induce productive efficiency which includes pricing access at the incumbent’s or at the entrant’s marginal cost. In dynamic models, facility-based competition is often considered as a long-term objective. The question then is to know whether allowing for service-based competition accelerates the development of facility based competition (the so-called stepping-stone effect identified by Cave and Vogelsang 2003) or delays the installation of new infrastructure (Bourreau and Dog̃an 2005).Footnote 8
 The rest of the paper is organized as follows. We present the model of competition with access in the next Section and the retail price game in Sect. 3. We characterize the profit maximizing behavior of the unregulated incumbent in Sect. 4. In Sect. 5, we discuss efficiency and regulation, analyzing the optimal behavior of a regulator maximizing social welfare. In Sect. 6, we analyze the technological efficiency of the entrant’s make or buy decision. We conclude and discuss possible extensions in Sect. 7. Proofs of the results which are not given in the text are collected in “Appendix A”.",1
52.0,2.0,Journal of Regulatory Economics,05 August 2017,https://link.springer.com/article/10.1007/s11149-017-9338-6,Weakening political connections by means of regulatory reform: Evidence from contracting out water services in Spain,October 2017,Daniel Albalate,Germà Bel,Andrés J. Picazo-Tadeo,Male,Unknown,Male,Male,"The study of rent-seeking has long been a key element in the analysis of the motivations of governments’ decisions. Rent-seeking has been defined as ‘... The quest for privileged benefits from government’ (Aidt 2016: 144). According to Lambsdorff (2002: 101), the focus of rent-seeking is on the interaction between the state and private parties, where the government has the monopoly on allocating property rights. The study of how individuals or firms can benefit from political influence and connections has received attention in the field of economics, ever since the seminal papers of Stigler (1971) and Peltzman (1976). In particular, Stigler (1971) discussed financial support for electoral campaigns, and funding for the bureaucratic tasks of the political party machinery as potential demands that governing parties can make in exchange for regulation in favor of specific industries or firms. In recent years, there has been an accumulation of empirical evidence on the existence of strong, mutually beneficial linkages between firms and politicians (Acemoglu et al. 2016; Akin et al. 2016; Faccio et al. 2006). One of the fields most closely linked to political rent-seeking and favoritism is that of privatization of public services (Hart et al. 1997). In this context, rent-seeking may occur when a company secures public service contracts in exchange for financial donations or board positions, among others. Empirical evidence on the relationship between political connections and financial donations, and the allocation of procurement contracts has been provided for different levels of government: federal (Boas et al. 2014; Goldman et al. 2013; Witko 2011) as well as local (Amore and Bennedsen 2013). This practice is contrary to the public interest, because it does not guarantee that the best-performing company is awarded the contract. This is therefore likely to lead to inefficiency (Dal Bó and Rossi 2007), lower service quality and extra service delivery costs (Dastidar and Mukherjee 2014), which will ultimately be borne by users or by taxpayers (Rose-Ackerman 1999; Tollison 2012). In short, it adversely affects the expected social welfare of a contracting auction (Boehm and Olaya 2006). Furthermore, Hart et al. (1997) contend that the policymakers engaging in rent-seeking in public services delivery are incentivized to create over-employment when public services are delivered in-house, thus engaging in political patronage and obtaining political support. Conversely, if service delivery is contracted out, rent-seeking politicians will tend to obtain financial resources, rather than over-employment, which can be used for personal enrichment, to fund political activities (elections and party machinery), or both. Personal enrichment is closely associated with illegal behavior and corruption; however, the funding of political parties or electoral campaigns by firms is legal in most democracies. Hence, rent-seeking does not necessarily involve illegal practices, and can be seen as different from corruption. In fact, our study does not deal with corruption, but rather with potential favoritism between political parties and firms, based on funding to the party, and revolving doors between governments and firms. According to Ariño (2009), decisions related to the procurement of public services are also one of the main sources of political rent-seeking and favoritism in Spain. On the one hand, scholars and politicians recognize that the rules on the financing of Spanish political parties establish an overly restrictive framework for securing resources—donations are limited to €60,000 per donor, and the contributions by party members are largely insignificant—and create a system that is overly dependent on government subsidies (Pujas and Rhodes 1999; Casal et al. 2014). In fact, this has been used as an argument to explain why Spanish political parties have irregularly obtained resources at some point (Bel et al. 2014); since the 1990s, judiciary courts and the Court of Auditors (Tribunal de Cuentas) have investigated several political parties over events such as the cancellation of parties’ bank debts, corporate donations and bribery. On the other hand, the processes for awarding contracts in Spain are not characterized by transparency and independence. The lack of transparency was partially addressed some years ago by Law 30/2007 on Public Sector Contracts. However, external control is insufficient, and the hiring process is largely under the control of local governments. Besides, an additional problem is the difficulty faced by the judiciary in obtaining evidence of malpractice, and the lengthy judicial processes. An index recently developed by the RAND Corporation (Stanley et al. 2014) assesses aspects such as the expectation of bribes and anti-bribery laws, and ranks Spain as one of the developed countries with the highest risk of bribery. Against this background, our paper focuses on two main research questions, namely, the possible existence of political connections between the main Spanish political parties and major private firms in the urban water delivery industry; and the impact of two laws (Organic Law 8/2007 and Law 30/2007) passed in Spain in 2007, which were aimed at increasing transparency in the funding of political parties, and ensuring objectivity in the procurement of public services. Our first hypothesis is the existence of a systematic relationship between companies that win privatization contests and the political party that holds the municipal government. This is a reasonable suspicion in Spain, judging by the many cases that are currently under judicial investigation for alleged corporate payments in exchange for preferential treatment in the awarding of public contracts for water service management (GWI 2013). Due to the slowness of the judicial system in Spain, most of these cases date back to the past decade. If our study reveals significant relationships, these could be interpreted as indirect evidence of favoritism. Our second and more interesting hypothesis is that the legal reforms implemented in 2007 made it more difficult to engage in favoritism in the awarding to private firms of contracts for urban water delivery. The study centers on 922 agreements to privatize water services management made by local governments in Spain between January 1984 and April 2016. The methodology used is multinomial logistic regression. Our results show evidence of a statistically significant association between the likelihood of specific firms securing (or not) the contracts, and the presence of a specific political party in government in the period before reforms. These significant relationships disappeared in the period after 2007, which may be an indication of how institutional reforms can weaken political connections. In this way, we contribute to the literature in this field of research by providing evidence to suggest bias in the awarding of contracts, depending on the governing political party in the municipality, and pointing to the effectiveness of institutional reforms in ending these practices. The remainder of the paper is organized as follows. Section 2 describes several cases of political connections in contracting out local public services in Spain. Section 3 outlines the legal framework for the privatization of the urban water service in Spain, and the reforms passed in 2007 regarding procurement of public services and funding of political parties. Section 4 describes the data and the methodology. The results are presented in Sect. 5, and the final section summarizes and sets some policy conclusions.",9
52.0,3.0,Journal of Regulatory Economics,25 October 2017,https://link.springer.com/article/10.1007/s11149-017-9343-9,Regulating away competition: the effect of regulation on entrepreneurship and employment,December 2017,James B. Bailey,Diana W. Thomas,,Male,Female,Unknown,Mix,,
52.0,3.0,Journal of Regulatory Economics,20 September 2017,https://link.springer.com/article/10.1007/s11149-017-9341-y,Discretionary enforcement and strategic interactions between enforcement agencies and firms: a theoretical and laboratory investigation,December 2017,Anna Rita Germani,Pasquale Scaramozzino,Piergiuseppe Morone,Female,Male,Male,Mix,,
52.0,3.0,Journal of Regulatory Economics,24 October 2017,https://link.springer.com/article/10.1007/s11149-017-9344-8,Tariff diversity and competition policy: drivers for broadband adoption in the European Union,December 2017,Mirjam R. J. Lange,,,Female,Unknown,Unknown,Female,"Increasing access to and usage of broadband internet has become a national policy priority for most governments since broadband penetration has been identified as a key driver for economic prosperity (e.g., OECD 2008; ITU and UNESCO 2013; Röller and Waverman 2001; Czernich et al. 2011). However, positive economic effects can only materialize if subscribers make use of the deployed infrastructure, which is only partly the case. Notwithstanding substantial efforts, nearly 30% of Europeans had never once used the internet in 2010, and in 2015 still 18% of the EU population aged 16–74 had no usage history (Eurostat 2015). Regarding Next Generation Access (NGA) networks, a recent study reveals that, for instance, in Germany only a small fraction of the deployed fiber infrastructure is actually used.Footnote 1
 As a result, in recent years a large body of empirical literature emerged, carving out determinants of broadband adoption (Denni and Gruber 2007; Gruber and Koutroumpis 2013; Kongaut and Bohlin 2014; Briglauer 2014), but despite a general consensus that the price level plays an important role, neither the determinants of broadband internet access prices nor the resulting pricing structure came under increased scrutiny. However, it is utterly important that both are analyzed in order to ensure sound regulation and competition policy in this sector.Footnote 2
 Broadband customers in the European Union are accustomed to having to choose from a menu of broadband offerings, varying with respect to down- and upload speeds, contract duration, price structure, and possibly bundled services.Footnote 3 Differentiation strategies by Internet service providers (ISPs) on fixed and mobile broadband have broadly been accepted as legitimate business strategies and were generally not a matter of policy concern. However, price discrimination has generated a lively debate in some countries with some public interest groups demanding more uniform tariffs (see, e.g., Odlyzko et al. 2012; Lyons 2013). Critics have claimed that market segmentation leads to consumer confusion and unjustified high prices in the presence of too much variety caused by too many tariffs. Price discrimination in the telecommunications sector, especially usage-based pricing (UBP), is thus seen as a serious threat to consumer welfare. Consequently, different policy actions have aimed at reducing or prohibiting differentiated pricing schemes. For example, the Data Cap Integrity Act of 2012Footnote 4 demands that “an Internet service provider may not impose a data cap on the consumers of the provider” (p. 3) and the more recent merger between the fixed broadband providers Charter Communications, Time Warner Cable, and Bright House Networks in 2016 was subject to the agreement to refrain from differentiated pricing practices by prohibiting usage-based pricing for 7 years.Footnote 5 In addition, universal service obligations sometimes explicitly prohibit differentiating prices geographically and/or between consumer types.Footnote 6
 On the other hand, academics and regulators have argued in favor of tariff diversity and have stressed its positive effect on broadband adoption and network management. Regarding the supply side, Lyons (2013), for example, considers pricing flexibility a useful tool for operators to spread network costs, to promote greater efficiency, and to recover costs that can be used to invest in future network infrastructure. Regarding the demand side, Bauer and Wildman (2012) show that tariff diversity gives consumers more choices to better fit their bandwidth needs by distinguishing between low-volume and high-volume users. Pointing out that especially inexperienced broadband users find it difficult to predict which online activities they will engage in and how much they will value them, low cost-low usage tier options can be used to incentivize broadband subscription for first-timers.Footnote 7 The objective of this paper is to empirically test the relevance of this second effect. So far, related studies have explored the determinants of (a) broadband demand and (b) broadband prices. The first strand examines socio-economic, geographical, and policy factors, such as income, level of urbanization, and the regulatory regime (e.g., Garcia-Murillo 2005; Lin and Wu 2013; Galperin and Ruzzier 2013; Kongaut and Bohlin 2014). Regarding inter- and intra-platform competition, the former is found to be a stimulus to broadband demand, whereas results for intra-platform competition are ambiguous (Distaso et al. 2006; Bouckaert et al. 2010; Gruber and Koutroumpis 2013; Nardotto et al. 2015).Footnote 8 These findings challenge the viability of the existing regulatory framework. It currently targets the effectiveness of wholesale broadband access regulation imposed on the incumbent’s first generation network which, however, might impede the rollout of future ultra-fast networks (Briglauer 2014; European Parliamentary Research Service 2015). The second strand analyzes broadband retail prices and shows that data restrictions lead to lower prices and that increased quality, in terms of increased download speed, drives prices upwards (Wallsten and Riso 2010). Calzada and Martínez-Santos (2014) document that DSL-based offers are the most expensive and incumbents’ prices exceed those of entrants. The latter may stem from their wider coverage, their reputation or the incumbents’ concerns about the price-squeeze tests set by competition authorities.Footnote 9
 Yet, with the exception of Haucap et al. (2016), the empirical literature has been silent on the impact of retail pricing structures on demand, though the effect might be ambiguous. Price discrimination in the retail broadband market might either (a) increase demand by allowing suppliers to serve low-value customers without lowering the price for high-value customers, or (b) decrease demand, as consumers may become confused over the variety of tariffs, potentially intended to obfuscate them, and finally reluctant to sign a contract (Spiegler 2006). The success of easy-to-grasp flat rate tariffs, associated with a rather modest price difference between offerings, may suggest that simple tariffs in fact outclass more diverse and complicated offerings when it comes to fostering broadband demand. In line with the classical industrial economic theory that price discrimination enlarges output and demand, Haucap et al. (2016) provide empirical evidence that an increase in tariff diversity provides a significant impetus to broadband adoption. The authors use an instrumental variable approach to estimate demand for fixed broadband services in 82 countries. To measure tariff diversity on a country-level a dataset comprising over 1000 fixed-line broadband tariffs is used. However, and in comparison to the present study, their analysis is based on a cross-sectional dataset with a relative small number of analyzed fixed broadband plans and a majority of non-OECD countries. Consequently, the authors cannot take into account dynamic developments and their results may not be applicable to more technologically advanced countries like the European Union member states. This paper aims to fill this void. The present paper analyzes how the differentiation of broadband tariffs influences fixed broadband demand including subscriptions to NGA networks. In the following, the term tariff diversity refers to the possibility that each broadband provider may offer potential customers a variety of diverse tariffs to choose from, each associated with a different level of quality. This is often referred to as usage-based pricing when referring to variation in tariffs associated with different bandwidths and data caps. First we account for second-degree price discrimination from selling tariffs with different download speeds, varying contract durations, tiered plans or volume- and time-based pricing, and second, we focus on third-degree price discrimination by selling to different consumer groups, e.g., offering ‘student’ or special ‘internet starter’ plans.Footnote 10 When price variation is associated with bundling, in which case individual prices are not cleanly identified, we are looking at implicit price discrimination which, however, is not the focus of this paper.Footnote 11 The analysis is based on a rich dataset that originally contains 10,200 residential retail broadband offers for 23 European states between 2003 and 2011. The econometric estimation explicitly accounts for endogeneity due to omitted variables or reverse causality. A multiplicity of measures for price dispersion in conjunction with a broad set of control variables ensures the robustness of the analysis. The results indicate that broadband demand is positively related to increased tariff diversity, suggesting that policymakers should be lenient toward price discrimination in broadband markets as reduced price discrimination may come at the cost of lower penetration rates. Moreover, facilities-based competition is found to be a stronger driver of broadband penetration than service-based competition. The intention of the European Commission to promote facilities-based competition therefore seems to be the appropriate policy for regulators in order to further promote broadband adoption. The remainder is structured as follows: Sect. 2 outlines the empirical strategy and provides a detailed description of the dataset. Results are presented in Sects. 3, 4 concludes.",6
52.0,3.0,Journal of Regulatory Economics,26 October 2017,https://link.springer.com/article/10.1007/s11149-017-9345-7,Price mimicking under cost-of-service regulation: the Swedish water sector,December 2017,Erik Lundin,,,Male,Unknown,Unknown,Male,"Ever since Tiebout (1956) pointed out that citizens evaluate the policies of their local governments in relation to the policies of other jurisdictions, the interdependence in policy decisions among local governments has been a major interest in public economics. Especially, the focus has been on tax setting and the provision of public services. This paper extends the existing literature by examining spatial interaction in the pricing decisions of regulated utilities. It also adds to the regulatory literature by noting that yardstick competition may also arise in regulated industries that are not subject to a formal yardstick regulation. Specifically, I examine the pricing decisions of Swedish water utilities over 2002–2012. Publicly owned water utilities in Sweden are governed by a cost-of-service (“c-o-s”) regulation, providing an upper bound on the price. If utilities are entirely financed by payments from customers, prices in neighboring municipalities should not affect the own price other than through spatially correlated cost factors. In contrast, utilities are found to mimic the prices of their neighbors. It should be noted though, that since municipalities are allowed to finance part of the costs using the municipal budget, price mimicking does not necessarily suggest non-compliance with the regulation. The basic setup in a model of yardstick competition typically involves a regulator and a number of local monopolists with identical cost functions. For a seminal contribution, see Shleifer (1985). The cost function is unknown to the regulator. For any given firm, the price that the firm gets is equal to the average self-reported cost of the other firms. If a firm reduces costs when its twin firms do not, it profits. If it fails to reduce costs when other firms do, it incurs a loss. Thus, firms are incentivized to achieve productive efficiency. But if the citizens of a jurisdiction evaluate the performance of the local policy makers by comparing with the surrounding jurisdictions this can also generate a type of yardstick competition even in absence of a central regulator. A presumption is then that citizens can punish the firm, either by lobbying for lower prices or the replacement of managers, or by voting the local policy maker out of office. Informal yardstick competition is not unknown in public economics. For instance, Besley and Case (1995) have adapted Schleifer’s original model to describe a system with asymmetric information between voters and politicians. The latter are assumed to know more about the cost of providing public services than the former. Consonant with the large literature on multiagent incentive schemes (see e.g. Holmström 1982) they show that it makes sense for voters to appraise their incumbent’s relative performance if neighboring jurisdictions face correlated cost shocks. Since tax rates are a proxy for the price of public production, citizens will evaluate the performance of their local policy makers by comparing their tax rates with those of neighboring jurisdictions. This induces local policy makers to mimic their neighbors’ tax policies in order not to look bad in comparison and be voted out of office. Geys (2006) notes that even in absence of correlated cost shocks, informal yardstick competition may arise if neighbors’ tax rates serve as behaviorally based reference prices by which the own tax rate is compared, thereby generating the so-called transaction utility introduced by Thaler (1985). The most important factor for determining the reference price is fairness, and the transaction utility for buying a certain good is positive if the realized price is less than the reference price. Thus, if citizens believe that it is fair that they pay the same tax as their neighbors, the transaction utility will depend on the difference between their own and their neighbors’ taxes. Is informal yardstick competition also at play in utility markets? Theoretically it should be easier for citizens to compare the performance of individual utilities than the total production of public services. First, utilities produce comparatively homogeneous goods, e.g., electricity distribution, water provision, district heating, and telecommunications. By contrast, a bundle of public services, or even a single one, may vary a lot in quality. Therefore, public services are harder to compare both in relation to quality and fairness principles. Further, the tax rate is merely an approximation of the price of public services, while a well-defined price for a utility service serves as a natural benchmark for efficiency. Recently, some studies have found evidence of yardstick competition in the pricing decisions of unregulated utilities, see Klien (2015), and Söderberg and Tanaka (2012). However, to the best of my knowledge, this is the first study to observe informal yardstick competition in a market subject to a c-o-s regulation. Arguably, the Swedish water sector provides an excellent testing ground for the existence of informal yardstick competition among regulated utilities. Water services have for a long time been provided by publicly owned utilities, independently organized by each municipality. They are regulated by a loosely monitored c-o-s regulation, and Haraldsson (2013) notes that 45% of the municipalities do not even fulfill basic legal accounting requirements. Many of the utilities also belong to publicly owned energy conglomerates, facilitating cross-subsidization between divisions. This should make leeway for a fair degree of arbitrariness in the pricing decisions. As of 2012, price differences were substantial, ranging from 3000 to 10,000 SEK (1 SEK \(\approx \) 0.1 EUR) per year for a regular household. Many municipalities have price trends that follow closely the trend of their neighbors, for no apparent reason. As an illustrative example, Fig. 1 shows the price trends in two neighboring municipalities, Ockelbo and Sandviken. In both municipalities, prices have increased by 120% during the last decade, compared to the industry average of 42%. The price increase in Ockelbo could largely be explained by high investments, which are on average 1000 SEK per year and resident for the years when data on investments were available, compared to the industry average of 600 SEK per year. By comparison, the neighboring municipality Sandviken invested only 300 SEK per year, which is well below the industry average. Sandviken’s water utility is both physically and organizationally isolated from every other water system in the region. Further, Sandviken’s water utilities are part of a publicly owned energy conglomerate, which should facilitate cross-subsidization. This raises questions whether Sandviken raised its price in response to the price increases in Ockelbo, and if so, whether such pricing strategies have been adopted on a systematic basis. Trends in water prices for a typical household. Note: This table depicts time trends in the water price for the two neighboring municipalities Ockelbo and Sandviken, as well as the mean across all 288 municipalities in the sample. The unit of measurement is the total cost (fixed plus variable cost) in SEK for a typical stand-alone house consuming 150 \(\mathrm{m}^{3}\) per year Using a fixed effects spatial Durbin model with data from almost all Swedish municipalities during 2002–2012, I estimate the elasticity of the own relative to neighbors’ average price to 0.14. Thus, if the neighboring municipalities raise their prices by on average 10%, the causal increase in the own price due to the neighbors’ increase is 1.4%. Results from cross-sectional data using even more detailed information about the technical characteristics of the utilities suggest an even higher degree of spatial dependence. However, due to the absence of fixed effects these estimates should be interpreted with care. Further, I find that price mimicking is more pronounced in municipalities where voter support for the ruling coalition is weak. This suggests that politicians facing a higher risk of loosing office are more concerned by reduced voter support if voters perceive them as inefficient. The rest of this paper is structured as follows. Section 2 reviews the related literature and discusses some theoretical predictions, Sect. 3 describes the institutional framework and the data, Sect. 4 presents the model, Sect. 5 presents the results, Sect. 6 provides a further discussion on the underlying mechanisms and implications for efficiency, and Sect. 7 concludes.",1
52.0,3.0,Journal of Regulatory Economics,22 August 2017,https://link.springer.com/article/10.1007/s11149-017-9339-5,"Green certification, heterogeneous producers, and green consumers: a welfare analysis of environmental regulations",December 2017,Jason Walter,Yang-Ming Chang,,Male,,Unknown,Mix,,
53.0,1.0,Journal of Regulatory Economics,08 February 2018,https://link.springer.com/article/10.1007/s11149-018-9351-4,State entry regulation and home health agency quality ratings,February 2018,Robert L. Ohsfeldt,Pengxiang Li,,Male,Unknown,Unknown,Male,"In the United States, there has been a trend over the past several decades toward moving the provision of health care services associated with long-term or short-term disability from institutional settings to patients’ homes, provided by home health service providers through home health service agencies (David and Polsky 2014). This trend was fueled by an expectation that provision of certain services in a patient’s home would be less costly than providing the same services in an institutional setting (David and Polsky 2014), which was reinforced by prevailing preference among patients to receive such services at home (Freeman 1995). As a result, expenditures on home health services in the United States, which were $15.1 billion in 1991, grew to $88.8 billion in 2015 (CMS 2017). This represents an annual growth rate of 7.3%; substantially greater than the 5.8% annual growth in total healthcare expenditures over the same period. A growing share of total home health services expenditures has been paid by Medicaid and Children’s Health Insurance Program (CHIP) programs, which are funded by state government tax revenues with additional funding from the federal government. Specifically, the Medicaid/CHIP share of total home health expenditures increased from 16% in 1991 to 36% in 2015, with a 10.8% annual growth rate over this period. Over time, the rapid growth in Medicaid spending stressed state government budgets, which led them to adopt various initiatives to attempt to control Medicaid spending growth (Tudor 1995; Wiener et al. 1999). Among these initiatives was the expansion of state “certificate-of-need” (CON) regulations, which traditionally had focused on controlling expansions in hospital capacity, to also target types of service providers accounting for substantial shares of Medicaid spending, such as nursing home services. The idea was that limiting the supply of nursing home services would limit the use of nursing home services by Medicaid recipients, which was assumed to result in lower expenditure growth (Ching 2015). By 2000, 37 states had CON for nursing home facilities, and 17 states had CON for home health agencies (HHAs). However, since 2000 there has been no change in state CON regulations, with the exception of New Hampshire, where CON was repealed in 2016 (National Conference of State Legislatures 2016). There is a substantial literature focused on assessing the impact of state CON programs on healthcare costs, as well as access to and quality of care. However, most of this literature focuses on state CON programs for hospitals or nursing home facilities. Comparatively little research has focused on the effects of home health CON. The purpose of this paper is to assess the impact of state CON programs for HHAs, and for potential substitute service providers, on quality ratings for HHAs. The conceptual basis for this analysis rests on past research suggesting CON increases structural concentration in regulated health care service markets, coupled with past research suggesting greater competition among health care service providers improves service quality. The results of our empirical model indicated that HHAs in states with CON for home health were less likely to have high quality ratings, and more likely to have medium quality ratings, compared to agencies in states without CON for home health, with no statistically significant difference in the likelihood of low quality ratings.",6
53.0,1.0,Journal of Regulatory Economics,29 November 2017,https://link.springer.com/article/10.1007/s11149-017-9346-6,Trading service quality for safety: a cautionary tale from the French ‘Robien law’ on elevator safety,February 2018,Lisa Chever,Michael Klien,,Female,Male,Unknown,Mix,,
53.0,1.0,Journal of Regulatory Economics,07 September 2017,https://link.springer.com/article/10.1007/s11149-017-9340-z,Does a one-size-fits-all approach to financial regulations alleviate default risk? The case of dual banking systems,February 2018,Muhammad Suhail Rizwan,Muhammad Moinuddin,Dawood Ashraf,Male,Male,Unknown,Male,"Banks engage in numerous activities that are essential for the stability of the financial system. However, a series of recent financial crises highlighted the presence of information asymmetry and moral hazard issues leading to excessive risk-taking among banks. Excessive risk-taking elevates systemic risk that, potentially, can enhance financial and economic fragility (Ashraf and Goddard 2012; Butzbach and Mettenheim 2015; Demsetz and Strahan 1997; Fama and Jensen 1983). Since the potential cost of imprudent risk-taking is systemic in nature, the banking industry around the world is heavily regulated and monitored. The objectives of financial regulations are to curb financial and economic fragility costs without undermining the contributions of banks to economic development. Due to their strong global financial interconnectedness banks are exposed to multiple risks within and beyond their geographical boundaries. Regulators are faced with the challenge of devising a comprehensive regulatory framework to manage issues related to globalization and financial liberalization. The introduction of an alternative business model within the financial system in the form of Islamic banking has increased the challenge for regulators. In almost 15 jurisdictions Islamic banking now accounts for more than 15% of overall banking assets (Islamic Financial Services Board 2017). Today’s complex and dynamic finance industry requires not only an effective and timely financial regulatory framework but also a feedback mechanism that provides empirical evidence on the effectiveness of such regulations. The objective of this paper is to investigate whether financial regulations are effective in reducing the fragility of banks in a dual banking systemFootnote 1. To understand the impact financial regulation has in reducing the financial fragility of banks, we use the probability-of-default (PD) of banks as a proxy for bank failure. By utilizing a novel methodology developed by Dalla Valle et al. (2016) we estimate the PD by using pair-copula constructions (PCC) for 220 banks from 15 jurisdictions with a dual banking system for the period 2000–2015. We used financial regulations data from four different surveys (2000, 2003, 2007, and 2012) conducted by the World Bank. The following nine financial regulatory measures are developed to understand the impact of regulations on default risk: Capital Regulatory Index (CRI), Independence of Supervisory Authority Overall (ISA), Limitations on Foreign Bank Entry or Ownership (FBE), Official Supervisory Power (OSP), Overall Financial Conglomerate Restrictiveness (FCR), Overall Restrictions on Banking Activities (RBA), Private Monitoring Index (PMI), External Governance Index (EGI), and Fraction of Entry Applications Denied (FED). By using a two-part fractional regression model, we found that stringent capital regulations, independence of supervisory agencies, limitations on foreign bank entry or ownership, limitations on forming financial conglomerates, and good external governance mechanisms significantly reduce banks’ default risk. However, granting excessive powers to supervisory agencies, over-reliance on private monitoring, and restrictions on new entrants into the banking industry increases the default risk of banks in our sample countries. Our analysis for any differences in the marginal effects of regulations on IBs revealed considerable differences in the effectiveness of financial regulations for CBs and IBs. Overall, the empirical results indicate that financial regulations that reduce default risk (e.g., CRI, ISA, FBE, EGI, FCR) have a greater impact on IBs while those which increase default risk in the overall sample (e.g., PMI, FED), generally, have a greater impact on CBs. These findings highlight the need for regulators in a dual banking system to consider the different nature of IBs and establish a regulatory framework that caters for the unique needs of IBs. These findings also provide empirical support for the Islamic Financial Services Board (IFSB) to develop a parallel regulatory framework for IBs. This paper contributes to the growing literature on the effectiveness of banking regulations. Previous studiesFootnote 2 used a single survey to test a couple of regulatory dimensions. However, banks face a multitude of financial regulations simultaneously and all should be considered to understand their impact. Besides using the data from four of the World Bank’s financial regulation surveys (2000, 2003, 2007, and 2012) to capture the dynamicity of financial regulations over time, this study estimates the PD by using PCC due to apparent issues with Z-score as a proxy for the risk-taking behavior of banks. Furthermore, we use a fractional regression model to account for the peculiar nature of PD as a dependent variable. To the best of our knowledge this paper is the first to provide empirical evidence related to the difference in the marginal impact of financial regulations on the relative riskiness of IBs and CBs. Our results have policy implications for regulators and bank management alike. First, it is important to consider that not all aspects of financial regulations have risk mitigation benefits and, therefore, a cost-benefit analysis is advisable before the implementation of new regulations. Second, there are differences in the marginal impact of different regulations on the relative riskiness of IBs and CBs. There is a need to account for the unique nature of Islamic banks and, therefore, a cost-benefit analysis of different aspects should be considered for IBs and CBs. Based on our findings, we recommend regulators consider the different nature of IBs and CBs and adjust financial regulations accordingly. The organization of this paper is as follows. Section two describes and develops the numerical computation by which PD is evaluated followed by section three which discusses financial regulations. The empirical methodology that underpins this study is presented in section four. Section five provides a discussion on factors affecting probability-of-default; in section six we present our sample, data, and univariate analysis. Empirical results are discussed in section seven and concluding comments can be found in section eight.",6
53.0,1.0,Journal of Regulatory Economics,12 January 2018,https://link.springer.com/article/10.1007/s11149-017-9349-3,The effect of entry restrictions on price: evidence from the retail gasoline market,February 2018,Valeria Bernardo,,,Female,Unknown,Unknown,Female,"Retail gasoline markets around the world are characterized by imperfect competition and retail gasoline and diesel prices are a source of constant concern for national governments. For example, retail gasoline markets have been under investigation by antitrust authorities in several countries, including the UK, where the Office of Fair Trading conducted a review of the road fuel sector to understand the causes of price rises in 2012–2013. In Spain, the National Competition Commission published a series of reports between 2009 and 2012 expressing concerns about how Spanish prices and trading margins had increased, placing it toward the top of European price and margin rankings. In the United States, the Federal Trade Commission recently conducted an investigation to determine whether increments in retail gasoline prices were attributable to market manipulation or to other kinds of anticompetitive behavior. Similarly, various measures have been introduced to limit control over retail prices in the sector, such as the divorcement laws in some US states and the recently adopted price regulations in Austria. Government concerns for the retail gasoline market are reflected in the vast number of studies undertaken by researchers in the field. In academia, both industry structure and price behavior have been the focus of economic studies undertaken from a wide range of approaches. In an attempt to summarize this literature, Eckert (2013) reviews empirical studies of the retail gasoline markets and identifies over 75 such articles since 2000. One line of study in this empirical literature is to analyze the effects of potential reform measures. Specifically, studies have analyzed the impact of sales below cost regulations (Fenili and Lane 1985; Anderson and Johnson 1999; Johnson 1999; Skidmore et al. 2005; Carranza et al. 2015), bans on self-service stations (Johnson and Romeo 2000), divorcement laws as a means for preventing predation from the refiner-owned service stations against their franchised dealers (Barron and Umbeck 1984; Vita 2000), sales taxes (Doyle and Samphantharak 2008), and auctioning licenses to operate stations (Soetevent et al. 2014). However, to date, no studies have examined the effect of entry restrictions nor their impact on the market once they are lifted. Moreover, though we would expect the lifting of such restrictions to lead to the entry of new firms into the market, the literature does not report an unequivocal effect of new market entry on equilibrium prices. Indeed, theoretical models predict different outcomes with some claiming that entry may lower the equilibrium price and others just the reverse. Increasing prices with entry are explained by search costs (Satterthwaite 1979; Stiglitz 1987; Schulz and Stahl 1996) while decreasing prices are expected in models of spatial competition (Gabszewicz and Thisse 1980; Anderson and Palma 1992). In the middle, more than one paper has reported mixed results (Salop 1979; Chen and Riordan 2007; Janssen and Moraga-González 2004). In the empirical literature, a number of related papers have analyzed the effect of market structure on retail gasoline prices, specifically seeking to determine how the number of competitors in the market impacts prices. Barron et al. (2004) performed a cross-sectional analysis of the one-day price in four different areas of the United States to contrast empirically the relationship between the number of competitors in the market, average price and price dispersion. The authors found that an increase in the seller density decreases both the average equilibrium price and price dispersion. In contrast, using a 3-year panel of stations located in suburban Washington DC, Hosken et al. (2008) found that the number of competitors in the market has no influence on price. Finally, Tappata and Yan (2013), analyzed the relationship between margins and market size with a data set of isolated geographical markets located near entrances to national parks and, therefore, exposed to demand shocks. The authors used the past number of visitors to the park to instrument for market size and entry/exit decisions. Their results show that entry affects equilibrium in a non-monotonic way, leading to a large price reduction in markets with few incumbents, while the effect diminishes in markets with more than six or seven firms. Relaxing entry restrictions constitutes a potential policy for tackling concerns about diesel prices; however, the effects of such a policy remain unexplored. In this paper, I seek to fill this gap by empirically analyzing the effect that entry restrictions have on equilibrium prices. Additionally, I expand on previous related articles by analyzing an external shock generated by a public policy decision in urban areas. This article does not as such attempt to shed light on the relationship between the number of competitors and price, rather its objective is to provide evidence as to the way in which the market responds to an additional entry. In addressing this question, I use a change in Spanish regulations introduced in February 2013. The market entries attributable to this regulatory change provided me with a unique data set to explore the effects of deregulation. I use a difference-in-difference approach applied to retail prices, demand and supply drivers and geographical data for the Metropolitan Area of Barcelona. I identify as treated stations all gasoline stations within a one-mile radius of an area where the deregulation was active and entry took place, and use as a control group all stations located in a one-mile radius of areas that were deregulated, but that did not experience entry. I conclude that removing barriers to entry implies a reduction in retail gasoline price of 1.04%. This result is significant, representing almost one fifth of the average retail margin. The results also show that the equilibrium price reduction is caused by the first entry and that this effect decreases over time. I test the robustness of my results for the estimation techniques, different price measures, heterogeneous response due to pre-existing differences in the treated and control groups and different geographical size markets (one- and two-mile radiuses). Additionally, I perform a placebo test and analyze the dynamic effects of the reform. To the best of my knowledge, this is the first article of its kind to assess the effect on prices of entry barriers to the retail gasoline market. Similarly, it is one of very few empirical contributions to the debate concerned with the effect of entry in a differentiated product market. The rest of the paper is organized as follows. Section 2 offers an overview of the retail gasoline market in Spain and the policy reform. Section 3 provides information on the data set. Section 4 reports the identification strategy. The results and robustness checks are presented in Sects. 5 and 6. Finally, the article ends by drawing a number of conclusions.",10
53.0,1.0,Journal of Regulatory Economics,17 January 2018,https://link.springer.com/article/10.1007/s11149-018-9350-5,The prosumers and the grid,February 2018,Axel Gautier,Julien Jacqmin,Jean-Christophe Poudou,Male,Male,Unknown,Male,"Prosumers are households that are both producers and consumers of electricity. A prosumer has a decentralized production unit (DPU)—a rooftop photovoltaic system (PV) or a small wind turbine—to produce electricity at home and this DPU is grid-connected. A generic auto-consumption profile of a residential DPU is provided in Fig. 1. Part of the electricity produced by a prosumer is consumed at home when production and consumption are simultaneous. Production and consumption, though, are not usually synchronized. When the local production does not match the consumption, the prosumer uses the grid for the balance. If consumption exceeds production then the prosumer draws electricity from the grid, like any other consumer. Conversely, if production exceeds consumption then the excess power is supplied to the grid. There are thus two distinct power exchanges between a prosumer and the grid: imports from and exports to the grid. For a residential consumer installing solar panels on his roof—the main focus of this paper—, less than 30% of the electricity produced is self-consumed and the largest part of their production is exported to the grid. Source: IEA-RETD (2014) Auto-consumption profile.  Source: res-legal.eu Net-metering versus net-purchasing in Europe.  From the consumer’s point of view, decentralized production units substitute traditional generation units (from coal, gas or nuclear plants). From the energy system’s point of view, an increased penetration of decentralized production technologies changes both the total cost of electricity generation (including the environmental cost) and the cost of the network. Power exchanges between prosumers and the grid generate costs for the grid operator as they require additional investments in on-load tap changers to support grid stability, in booster transformers to provide voltage support or in static volt ampere reactive control to improve the reactiveness of the system (IEA-RETD 2014). The interplay between decentralized production and the grid cost is the subject of this paper. Grid costs will be passed through consumers and prosumers via the distribution tariff i.e. the price consumers pay for using the network which accounts for about 20–30% of the total electricity bill. Hence, this tariff, by affecting both the costs and benefits of the DPU, will influence the rate of technology adoption. To measure exchanges with the grid, residential prosumers are equipped with meter(s). There are two alternative metering technologies for residential service: the net metering and the net purchasing systems. With the net metering system,Footnote 1 there is a unique meter that runs backwards when production exceeds consumption. The meter only registers the difference between imports from and exports to the grid i.e. net imports. With the net purchasing system,Footnote 2 there are two meters: a traditional one to measure electricity drawn from the grid and an export meter to measure the power supply to the grid. Whichever the system, the registered consumption is used as a basis for billing. Currently, the two technologies are being used in Europe [see Fig. 2 and Poullikkas et al. (2013) for detailed reviews]. In the US, the net metering system is used in 43 statesFootnote 3. Net metering is a tool to support and finance decentralized energy production (Eid et al. 2014). With net metering local electricity production is valued at a price equal to the electricity retail price plus the unit network fee which represents the avoided cost/price of electricity generated. Net metering is criticized on many grounds. For Brown and Sappington (2017a), it induces an inefficient deployment of distributed generation. Net metering has also important redistributional consequences. As the registered consumption decreases, the grid tariff has to increase so as to cover the network costs. This leads to an important redistribution of income between prosumers and traditional consumers (see Darghouth et al. 2011; Yamamoto 2012; Cai et al. 2013 or Brown and Sappington 2017a). This rate increase makes decentralized production even more profitable and stimulates further the DPU expansion; a death spiral in the words of Borenstein and Bushnell (2015). With net purchasing, prosumers can export electricity to the grid and they are compensated for the power injection (via a feed-in-tariff). Electricity is either valued at retail price or at a premium price. In addition, there might be specific network fees charged by the grid operator for power injection. In this paper, we show that the two metering technologies are not equivalent from an economic point of view. There are at least three differences. First, as the costs for the prosumers may differ, the deployment of DPU is affected by the metering technology. This in turn has an impact on the total cost of both electricity generation and the grid. We will show that net metering will lead to too much “prosumption”. Second, the two technologies differ in terms of income redistribution between the consumer categories. In particular, net metering transfers the burden of the network cost to traditional users. Last, they induce different behavior with respect to self-consumption, i.e. the consumption of self-generated renewable electricity. According to the European Commission (2015), self-consumption can lead to consumer empowerment and a more efficient energy system. There exists complementary technologies (e.g. storage) or demand side management practices (e.g load displacement, orientation of the solar panels) that can increase the synchronization between decentralized production and consumption. With net metering, self-consumption is not encouraged as exports and self-consumption are perfect substitutes from the prosumer’s perspective but not from the system’s perspective. With net purchasing, an increase in self-consumption decreases the prosumers’ bill. Overall, our paper shows that net purchasing is a better way to integrate prosumers in the energy system compared to net metering on these dimensions. These conclusions are further confirmed by looking at various structures for the retail and grid prices and the positive externalities created by a green electricity production. They tend to corroborate the recent trend among regulatory agencies in Europe and the US towards a switch away from net metering policies. Section 2 presents our general framework. The net metering and the net purchasing systems are, respectively, exposed in Sects. 3 and 4. Both are compared in Sect. 5 with respect to the deployment of decentralized production, the contribution to the network financing of consumers and prosumers and the incentives to synchronize production and consumption. The robustness of our results with respect to both different tariff structures and environmental concerns are discussed in Sect. 6. Section 7 concludes in the light of recent regulatory evolutions.",63
53.0,2.0,Journal of Regulatory Economics,21 March 2018,https://link.springer.com/article/10.1007/s11149-018-9354-1,Can capacity markets be designed by democracy?,April 2018,Kyungjin Yoo,Seth Blumsack,,Unknown,Male,Unknown,Male,"Regional Transmission Organizations (RTOs) operate the power grid serving more than two-thirds of electricity customers in the U.S. and are critical organizations for ensuring reliable system operations and facilitating the integration of new technologies and market participants, including renewable power generation, energy storage and demand response. They are also supposed to be stakeholder-driven organizations, with rules and policies crafted through a highly participatory process and ultimately approved by the Federal Energy Regulatory Commission (FERC). While the decisions that RTOs make have implications for industry, society and the environment, their decision processes have not been broadly studied. The environment in which rules and policies are made is important because market rules and regulations have a critical impact on the value of technology (Paine et al. 2014). The preferences of different actors within the regulatory system can impact the scale and scope of technology adoption (Fischlein et al. 2014; Wilson and Stephens 2009), and can even affect system reliability (Carreras et al. 2009). The governance of RTOs and the behavior of RTOs as organizations has been raised a number of times in the literature (Dworkin and Goldwasser 2007; Joskow 1997; O’Neill et al. 2005; Schulman and Roe 2016, 2008; Simeone 2017). While questions have been raised about the outcomes of such stakeholder-driven decision processes, those processes have not, to date, been modeled in any systematic way. Most recently, Johnson et al. (2015) Lenhart et al. (2016) and Stafford and Wilson (2016) have studied qualitatively the functioning of the stakeholder process in various RTOs in the context of specific initiatives to integrate renewable power supplies and energy storage. This paper focuses primarily on decision processes representative of the RTOs in the U.S. Northeast (PJM, the New York ISO and ISO New England), which render considerable authority to stakeholders through voting mechanisms that generally lead directly to FERC filings. We focus our discussion on the PJM RTO (leaving comparisons between the Northeastern RTOs for future work) but acknowledge that the RTOs in PJM, New York and New England all develop policies and rule changes through a process intended to be highly democratic. RTOs in the Midwestern U.S. and in California still seek stakeholder input, but final decisions on filings to FERC are made by the RTO staff and Boards. Our work is inspired primarily by Johnson et al. (2015), Yoo (2016) and Blumsack et al. (2017), which have examined coalitions in the stakeholder process of the PJM Interconnection, an RTO serving all or parts of thirteen states in the Mid-Atlantic U.S. plus the District of Columbia. This work addresses the question of how reliable power grid operations, specifically generation resource adequacy, can be well-designed through a highly participatory process with many competing interests. In this paper, we develop a modeling framework for the PJM stakeholder process that bridges some of the seminal literature from political science and political economy on the theory of voting systems (Arrow 1950; Black 1986; Downs 1957; Plott 1967a, b; Rubinstein 1980). Our model allows for the prediction of the formation of coalitions, analysis of pivotal voting power within the stakeholder process, and assessment of how deviations from expected coalitions through abstention from voting and deviation from a predicted coalition can shift political power in some unexpected ways. We illustrate the insights that this modeling framework can provide a series of votes taken in the PJM stakeholder process in 2011 on capacity market redesign. Section 2 of the paper describes the PJM stakeholder process and the voting structure used in the Members Committee, the construct on which we primarily focus in this work. Section 3 develops a theory of passable proposals that we use as a predictive model of voting outcomes in the PJM stakeholder process, and allows us to a priori anticipate coalitions forming around specific issues. In Sect. 4, we provide a geometric interpretation of the voting system in the PJM stakeholder process that permits analysis of how abstentions and coalition defections shift voting power. Section 5 provides an application of this framework to the capacity market redesign, while Sect. 6 offers some concluding thoughts, policy implications and directions for future research.",10
53.0,2.0,Journal of Regulatory Economics,26 December 2017,https://link.springer.com/article/10.1007/s11149-017-9347-5,Minimum safety standards with asymmetric safety costs,April 2018,Sungho Yun,,,Unknown,Unknown,Unknown,Unknown,,
53.0,2.0,Journal of Regulatory Economics,30 January 2018,https://link.springer.com/article/10.1007/s11149-017-9348-4,Regulation of non-marketed outputs and substitutable inputs,April 2018,Joachim Bertsch,Simeon Hagspiel,,Male,Male,Unknown,Male,"Numerous goods and services are provided by regulated firms with a monopolistic status. For instance, a single firm is usually responsible for grid infrastructures in the electricity or telecommunication sector. The service to be delivered by these firms is typically well-defined and often fixed ex-ante, such that the regulator will be well aware whether or not it has been provided effectively. For instance, it is straightforward to verify the number of blackouts in electricity grids or the speed of the internet in telecommunication networks. In contrast, it is often difficult for the regulator to judge the efficiency of the firm’s measures to provide the output. Technical systems are often highly complex and characterized by a production function with multiple interdependent inputs that are hard to assess. Hence, firms may have an informational advantage on their internal activities, which clearly complicates efficient regulation. In practice, production functions often involve two types of activities or inputs, respectively, that are substitutable to a certain extent: on the one hand, it needs physical assets, such as electricity lines or data cables, whose level of deployment is relatively easy to observe. On the other hand, operational measures are required for the efficient usage of physical infrastructures, such as data routing or line switching, which are more difficult to asses (for instance, the number of newly built lines can simply be counted, while measuring the productivity in using a operational software can be quite ambiguous). From this setting, different sources of information asymmetry may arise: First, caused by substantial changes on the demand side or new technological options, the regulator must assess the necessary level of activity by the firm to provide the observable output. As an example, consider the rapidly increasing deployment of renewable energies in the electricity sector or the use of broadband internet in the telecommunication industry. For instance, in Germany the regulator approves a detailed electricity grid development plan for the transmission system operators (Netzentwicklungsplan 2013), which is elaborated by the operators themselves. There is control by public consultation and model-based studies; however, the complexity of expanding and operating the electricity grid precludes elimination of all information asymmetry about the necessary level of actions. Second, a source of asymmetric information exists if the regulator may be unable to verify the unit costs of one or multiple inputs. As previously stated, this is the case if the effects of operational measures and hence, related costs are difficult to assess. In the given example of the electricity or telecommunication grid, the regulator can hardly assess how physical assets can be (partially) substituted by using efficient operational measures, e.g., intelligent management of redundancies in the grid. In theory as well as in practice, such problems of information asymmetry between the regulator and the firm have been tackled by different forms of regulation. Typical approaches in regulatory practice range from cost-based regulation to widely applied incentive regulation (discussed, e.g., in Joskow 2014), or a linear combination of those two extremes (e.g., Schmalensee 1989). From an academic viewpoint, theoretical approaches suggest that the best theoretical solution consists of the regulator offering the firm a menu of contracts, such that the firm reveals her private information (e.g., Laffont and Tirole 1993). Even though the dichotomy between such Bayesian models of regulation (which tend to dominate the academic discussion) and simpler non-Bayesian models (which are closer to regulatory practice) is well perceived, corresponding explanations are rather vague. For instance, as Armstrong and Sappington (2007) note, “[...] regulatory plans that encompass options are ’complicated’, and therefore prohibitively costly to implement”. Against the above background, the goal of this paper is twofold: First, to identify and investigate the optimal Bayesian regulation for the multi-dimensional problem at hand, and second, to bridge the gap between the theoretically optimal solution and simpler regimes applied in regulatory practice. For the latter, we provide a theoretical as well as computational analysis to identify circumstances under which a simple regime comes near the optimal solution. To derive an optimal regulation strategy, we build on the theory of incentives and contract menus. It is well known that in a simple setting with two types of the firm, the efficient type is incentivized via a contract with first-best (price) levels along with some positive rent, while the inefficient type’s contract includes prices above the first-best and no rent (e.g., Laffont and Tirole 1993). The same logic applies for the case of one-dimensional continuous type spaces (ibid.). By analyzing asymmetric information with respect to total factor productivity in a two-input production function, Besanko (1985) extended this approach and presented a paper with noticeable similarities to ours. Specifically, he presented a result which is congruent with the one we obtain in a reduced version of our model.Footnote 1 However, there remain several important differences: First, Besanko assumed a model with distributional welfare preferences while we consider shadow costs of public funding. Second, the optimal menu in Besanko (1985) consists of the observable input along with a regulated price for the output, while we build on the observable input along with a transfer payment. And third, we study a discrete multi-dimensional type space instead of a univariate continuous distribution. Multi-dimensional problems of adverse selection have been studied, e.g., by Lewis and Sappington (1988b), Dana (1993), Armstrong (1999) or Aguirre and Beitia (2004). While Dana (1993) analyzes a multi-product environment, Lewis and Sappington (1988b), Armstrong (1999) and Aguirre and Beitia (2004) consider two-dimensional adverse selection with only one screening variable. Specifically, the latter three derive optimal regulation strategies in a marketed-good environment (in the sense of Caillaud et al. 1988) with unknown cost and demand functions. In our paper, unlike Lewis and Sappington (1988b) and Armstrong (1999), we consider shadow costs of public funding instead of distributional welfare preferences. Despite technical differences, this is largely in line with the analysis of Aguirre and Beitia (2004).Footnote 2 However, in contrast to all these papers, we solve the two-dimensional adverse selection problem for a non-marketed good environment and a production process that involves two substitutable inputs with an uncertain rate of substitution (i.e., isoquant) and input factor costs.Footnote 3
 With this novel setting of multi-dimensional inputs and a non-marketed output, we contribute to the general insights from the above literature. We find that expected social welfare necessarily includes positive rents for some types of the firm, such that the first-best solution cannot be achieved. While the efficient type is always set to first-best input levels, the other contracts’ (observable) input levels are distorted upwards.Footnote 4 Separation of at least three types is always possible, while bunching of two types may be unavoidable in case of a very asymmetric distribution of costs or very flat isoquants. We then compare the obtained optimal Bayesian regulation to the results of a non-Bayesian regulation that we obtain by restricting our regulation problem to one single pooling contract.Footnote 5 We find that despite the general inferiority, a non-Bayesian cost-based regulatory regime may indeed be close to the optimal Bayesian solution for specific circumstances. This especially holds true if the overall input level is likely to be high, or if the substitutability in the observable input is low (such that its power as contract variable is weak). Meanwhile, in practical applications the specific results will naturally depend on the specification of the functions and parameters. For instance, in our exemplary calculations based on a CES production function, we find an exponential increase in the second-best observable quantities when moving the probability of low isoquants upwards. With respect to welfare, the simple contract performs close to the optimal contract if realizations of high input level requirements as well as costs are likely, if the elasticity of substitution is high, or if the share parameter favors the unobservable input factor. Hence—depending on the prevailing conditions—a simple contract might indeed be a suitable solution in regulatory practice to avoid overly complicated menus of contracts which might even turn out to be inefficient overall (e.g., when adding costly planning and coordination processes to the analysis). For instance, in the above example of electricity networks in Germany, the regulator imposes a cost-based regulation on the responsible firms—and might eventually be close to an efficient regulatory outcome when considering large budgets and ongoing public discussions about grid expansion as an indication for the aforementioned circumstances. The paper is organized as follows: Sect. 2 introduces the model; Sect. 3 presents the optimal regulation strategy; Sect. 4 compares the optimal regulation to simpler regimes; Sect. 5 provides additional insights based on our computational analysis; and Sect. 6 concludes.",
53.0,2.0,Journal of Regulatory Economics,23 March 2018,https://link.springer.com/article/10.1007/s11149-018-9352-3,Bank capital requirements and mandatory deferral of compensation,April 2018,Eberhard Feess,Ansgar Wohlschlegel,,Male,Male,Unknown,Male,"In the aftermath of the financial crisis, tighter capital requirements (e.g. Admati and Hellwig 2014) and mandatory deferral of bankers’ compensation (e.g. Bebchuk and Fried 2010) are the two most prominent suggestions for mitigating the incentives for excessive risk-taking. The European Parliament has released its Capital Requirements Directive IV in April 2013 which increases capital requirements from 2 to 4.5% for Common Equity Tier 1 capital. Bankers’ bonuses are capped to 100% of the fixum, but are allowed to rise to 200% if approved by shareholders. At least 40–60% of variable payments need to be deferred by no less than three to five years. In a similar vein, the Fed established new calculation methods in 2015 for capital ratios, which result in even stricter requirements for global systematically important banks than those mandated under Basel III.Footnote 1 Moreover, although US banks are obliged to achieve a Common Equity Tier 1 capital ratio of 6% only in 2019, the six largest banks have already taken steps to comply with this requirement earlier.Footnote 2 Discretionary bonus payments during any quarter are prohibited if the bank’s eligible retained income is negative and if its capital conservation buffer in the beginning of the quarter was below 2.5%.Footnote 3 These buffer requirements, however, are mandatory only for those large institutions which are seen as critical to avoid globally relevant systemic risks. While the literature so far mainly restricts attention to either deferred compensation (Hoffmann et al. 2016) or capital requirements (Harris et al. 2017), we contribute to the ongoing discussion on how the risk appetite of financial institutions can be reduced by analyzing the interplay of both of these prominent regulatory instruments. As we focus on the incentives of shareholders to accommodate risky rather than safe projects, we consider the so-called external agency problem between shareholders and society (see in a similar vein e.g. Bolton et al. 2012; Bebchuk and Spamann 2010; Jarque and Prescott 2010; Besley and Ghatak 2013) rather than the internal principal-agent problem between shareholders and bank managers. We make three points: First, mandatory deferral of compensation and tight capital requirements are in many respects substitutes for reducing the risk appetite of shareholders. Second, deferred compensation may be superior to capital requirements as it allows for a larger banking sector without increasing the risk of default. Third, deferred compensation may backfire by misallocating safe and risky projects in a heterogenous banking sector when there is competition for safe projects. The main building blocks of our model are as follows: In line with the standard approach on banking regulation (Dewatripont and Tirole 1994), we assume that shareholders can externalize part of the default risk to either depositors who do not fully react by demanding appropriately larger interest rates or, via bail-outs, to society. That this agency cost of debt cannot be completely eliminated by relying exclusively on equity finance is a distinctive feature of banks, whose role as financial intermediaries requires them to raise a large amount of debt in the form of deposits. Furthermore, the regulator cannot (fully) tailor capital requirements to the actual project risk. Without these two assumptions, the shareholders’ and the society’s objective functions would be aligned, so that the external agency problem would disappear. Next, we define mandatory deferral of compensation as the percentage of overall compensation that can only be paid out in case of solvency, i.e. that is junior to all liabilities in case of liquidation.Footnote 4 This ensures that deferred compensation is contingent on success, and this is one of the main purposes of mandatory deferral of compensation (Bebchuk and Spamann (2010)). Finally, we consider a heterogenous banking sector, in which only good banks have screening capabilities to discriminate between safe and risky projects. With these assumptions in mind, we can now describe our results in greater detail. We first show that, by changing the seniority of compensation claims, mandatory deferral of compensation reduces the shareholders’ incentives for risk-shifting.Footnote 5 By contrast to early compensation, bank managers know that they are (fully) paid only in case of solvency, and thus demand a higher salary in the non-bankruptcy state. This reduces the shareholders’ expected return on equity with risky projects. The point we make is that early compensation allows to transfer wealth from society to the coalition of shareholders and bank managers, and this is prevented by deferred compensation. Second, while risk shifting incentives can also be curbed by capital requirements, this comes at the disadvantage of imposing an upper bound on the size of banks. Being strict on the timing of compensation allows the regulator to be softer on capital regulations without inducing risk-shifting (see also Thanassoulis (2014)). Thus, the potential downside of tight capital requirements that even projects with positive net present value will remain unfunded (credit crunch) can be mitigated by mandatory deferral of compensation. In this sense, our basic model makes a point in favor of payment regulation. Third, however, we show that deferred compensation may backfire in a heterogenous banking sector when assuming that the number of safe projects is limited. As deferred compensation reduces the shareholders’ risk appetite, the good bank (which can distinguish between safe and risky projects) may prefer safe instead of risky projects. As this deteriorates the remaining project mix in the economy, the bad bank (which cannot distinguish between project types) funds a larger percentage of risky projects. If the good bank has a comparative advantage in managing risky projects, deferred compensation leads to an inefficient allocation of safe and risky projects within the banking sector. It may then be better to accommodate risk-shifting in the good bank by allowing for early compensation, rather than by allowing for many projects by relaxing the capital equity ratio. We will get back to this from a regulatory point of view in the concluding section.Footnote 6
 Arguing that the legally required timing of compensation affects the shareholders’ incentives for risk-shifting ultimately requires that the effect size is sufficiently large. It is thus important to note that regulations on bonuses an deferred compensation are not limited to CEOs, but extend to e.g. trading and investment banking. One of the main issues in the stockholders’ meeting of Deutsche Bank in May 2015 was the fact that the bonuses paid to managers are five times higher than the dividends paid to shareholders, so that the question which part of remuneration is early or deferred seems clearly relevant not only from the managers’, but also from the shareholders’ point of view. Bell and Reenen (2014) find that two thirds of the large increase in the one percent highest salaries in the UK after 1999 can be attributed to the increase in banker’s bonuses, and that this didn’t even change after the financial crisis. Overall, it is no exception that remuneration exceeds 30% of shareholder equity, and the ratio sometimes exceeds even 80% of shareholder equity; something rarely observed in non-financial firms (Thanassoulis 2014). Our paper is most directly related to literature on the impacts of deferred compensation and capital requirements on risk-shifting incentives, but also to the impact of bank managers’ salaries on the incentives for risk-shifting, and to literature on interdependencies of banks’ decisions in credit markets. As we do, most papers on deferred compensation consider the external agency problem between debtholders or the society on the one hand and shareholders on the other hand. Bolton et al. (2012) show that, while performance-based pay maximizes shareholder value, it is likely to induce excessive risk-taking from the debtholders’ point of view. For mitigating these inefficiencies, they suggest tying bank managers’ compensation not only to performance measures, but also to measures of default risk (see in a similar vein Bebchuk and Spamann 2010 and Edmans and Liu 2011).Footnote 7 Many papers provide detailed suggestions for regulating bankers’ pay, including the timing of deferred compensation schemes (Bebchuk and Fried 2010), tying CEO compensation to the CDS spread to account for the risk perceived by the market (Bolton et al. 2015), and charging deposit insurance premiums depending on the compensation structure (Phelan and Clement 2010). In Hakenes and Schnabel (2014), variable payments are beneficial since they induce effort of bank managers, but may also lead to risk-shifting. In case of potential public bail-outs, they find that a system of capped bonuses optimizes the trade-off between effort incentives and excessive risk-taking. Another string of the literature on deferred compensation emphasizes that useful information may emerge over time, and that postponing payments allows to induce decisions contingent on this information. In Acharya et al. (2016) managers learn their types over time, so that the focus is on uncertainty rather than on asymmetric information. By contrast, deferring compensation allows to infer the agent’s type in Inderst and Pfeil (2013). Learning comes at a cost as bank managers have a higher time preference than shareholders. Also assuming that valuable information may emerge over time and that bank managers are impatient, Hoffmann et al. (2016) find that deferred compensation may even increase risk-shifting. There are mainly two reasons why their findings differ from ours: First, when confronted with a mandated minimum-deferral requirement, shareholders in their model may respond by using other instruments such as higher bonuses, while we consider exclusively early and late compensation. Second, they assume that shareholders need to pay rents to induce managers to exert risk-reducing effort. And as compensation regulation reduces the contract space, implementing high effort becomes more expensive. From a general perspective, Hoffmann et al. (2016) analyze the impact of compensation regulation on the second-best incentive contract in the principal-agent relationship between shareholders and managers (see also Hakenes and Schnabel (2014)). By contrast, our paper focuses on the impact of regulation on the external agency problem. While moral hazard models are appropriate for analyzing the conflict between shareholders and managers, models in the tradition of Aghion and Bolton (1987) are commonly used for investigating situations where two parties (here: shareholders and managers) have incentives to sign contracts that maximize their joint payoff at the expense of third parties (here: creditors or taxpayers). Following this tradition, it is instructive to neglect information problems between managers and shareholders, so that our approach is complementary to papers focusing on internal agency problems.Footnote 8
 In line with our findings, most papers on capital requirements argue that tighter standards reduce the risk appetite of financial institutions, but come at the cost of reduced lending (Thanassoulis 2014; Harris et al. 2017). In a rich model with a heterogeneous banking sector, Harris et al. (2017) show in addition that, by reducing banks’ profits from socially valuable projects, fiercer competition from investors in public markets may increase risk-shifting by banks. In our model, increased competition with good banks increases the risk of the bad bank’s lending portfolio. Recently, the highly influential book by Admati and Hellwig (2014) calls for far higher capital equity ratios and argues that the argument that higher capital equity ratios would ultimately reduce bank lending is flawed. Calibrating a model on the private and social costs and benefit of bank equity, Miles et al. (2013) find that the socially optimal amount of equity is far higher than what is observed, and also far higher than what is required under Basel III.Footnote 9 Current proposals go beyond tighter capital requirements and include mandatory default insurance (Kashyap et al. 2008), reverse convertibles where debt is converted to equity in case the regulator assumes an increased default risk (Squam Lake Group 2009), flexible capital requirements depending on the price of Credit Default Swaps for debt (Hart and Zingales 2011) and so-called “Equity Liability Carriers” which are supposed to guarantee that financial institutions with limited liability can meet their obligations (Admati and Pfleiderer 2010). Bulow and Klemperer (2015) suggest so-called Equity Recourse Notes, which are a kind of debt whose payments are converted into equity in case of a large decrease in share prices. Some papers, however, argue that tight capital ratios may even increase risk-shifting (see the overviews in Bhattacharya et al. 1998 and Allen 2004). In Allen et al. (2011), banks can improve the quality of loans by monitoring and higher equity serves as a commitment device for monitoring. While all papers mentioned so far restrict attention to either deferred compensation or capital regulation, there are only a few papers that analyze the interplay of compensation regulation and capital equity ratios. As we do, Eufinger and Gill (2016) neglect potential agency conflicts between shareholders and managers and focus on the shareholders’ incentives to trigger risk-shifting via compensation schemes for bank managers. Risk-shifting incentives arise since debtholders are protected by deposit insurance if the debt is below a critical threshold. Payment schemes in Eufinger and Gill (2016) are not directly regulated, i.e. shareholders are free to choose between fixed wages (payments in case the safe project is chosen) and bonuses (payments contingent on the actual return of the risky project). But as shareholders anticipate that capital equity ratios are tighter in the latter case, their incentive to implement excessively high-powered compensation schemes disappears. Our model is less rich in this respect as the regulator in our model decides directly on the percentage of compensation that can only be paid out in case of no default. Eufinger and Gill (2016) do not consider a heterogenous banking sector and the possibility of a misallocation of risky project, which is a focus of our paper. As we do, Kolm et al. (2016) also argue that deferred compensation reduces risk-shifting. However, as it does not increase the inefficiently low incentives to search for risk-reducing investment strategies, tight capital regulations remain beneficial. Gete and Gomez (2016) argue that capital regulation is superior to direct compensation regulation as restricting variable pay does not only reduce risk-shifting incentives but also effort. The argument derived in our model that mandatory deferral of compensation outperforms tight capital ratios if and only if there are sufficiently many safe projects is, to the best of our knowledge, novel. In our model, the advantage for shareholders when they pay early instead of deferred compensation for risky projects is that part of the (expected) compensation is effectively externalized to debtholders or society. Hence, risk-shifting incentives increase in the manager’s salary. This relates our paper to a growing literature arguing that fiercer competition for bank managers leads to a more risky banking sector (Acharya et al. 2016; Thanassoulis 2012). The detrimental effects of competition are reinforced when the managers’ talent is private information, as excessively high-powered incentive contracts are then offered to reduce the rents of low types (Bannier et al. 2013; Bijlsma et al. 2012). In our setting with a limited supply of safe projects, the good bank’s portfolio choice influences the portfolio risk of the bad bank. And as the good bank’s behavior depends on the regulation on deferred compensation and capital equity ratios, the regulatory regime leads to an interdependency between the two banks’ portfolio risks. In this sense, our paper extends the literature on the interdependency of default risks from competition among banks (Broecker 1990; Nakamura 1993D; Riordan 1993; Shaffer 1998) and information sharing (Pagano and Jappelli 1993); see Harris et al. (2017) for competition between banks and outside investors. Finally, our modelling of safe and risky projects draws on Feess and Hege (2012) who also assume that safe projects have higher expected returns, and who show that banks may nevertheless have incentives for risk-shifting if and only if the number of projects banks are allowed to fund via capital requirements exceeds a specific threshold. While they focus on the distinction between internal and external rating, they do not consider managers’ compensation schemes, and hence also not the impact of (mandatory) deferral of compensation. The remainder of the paper is organized as follows: Sect. 2 presents the model. In Sect. 3, we show that shareholders strictly prefer early compensation in case of positive default risk. Section 4 considers the scenario with an abundant supply of both project types. When extending the model to a limited number of projects in Sect. 5, we point out a potential drawback of deferred compensation. Our assumptions and the robustness of our model is discussed in Sect. 6. We conclude in Sect. 7.",
53.0,3.0,Journal of Regulatory Economics,11 May 2018,https://link.springer.com/article/10.1007/s11149-018-9356-z,Business regulation and business investment: evidence from US manufacturing 1970–2009,June 2018,Brandon Pizzola,,,Male,Unknown,Unknown,Male,"Regulation is often portrayed as placing a substantial burden on US businesses and the overall US economy. Moreover, policy options of “cutting red tape” and “reducing federal bureaucracy” are often asserted to be a way to stimulate investment and, through this channel, a way to promote economic growth.Footnote 1 The empirical examination of this common assertion, however, has suffered from notable data limitations. Specifically, it has generally relied on either relatively detailed data on a small subset of total business regulation or broad proxy measures aiming to capture total business regulation typically with little—if any—disaggregation below the country level. This paper departs from the previous literature by examining the relationship between business regulation and business investment through use of a novel industry-specific regulation measure that gauges both the size and scope of federal regulation in the United States. In particular, this paper examines the relationship between growth in regulatory restrictions in the Code of Federal Regulations (CFR) and manufacturing investment in the United States over the 1970–2009 period. An industry-level dataset is constructed by mapping the industry-specific RegData dataset from the Mercatus Center at George Mason University to the comprehensive industry-specific manufacturing data in the NBER-CES Manufacturing Industry Database. In total, the constructed dataset includes 337 manufacturing industries. The RegData dataset is unique in two major ways. First, despite being a comprehensive measure of federal business regulation, it is more targeted and accurate than broad proxy measures of regulatory burden (e.g., pages of regulation). That is, the RegData dataset constructs a measure of regulatory restrictions in the CFR through use of a character string matching approach that captures binding constraints (e.g., words and phrases such as “shall,” “must,” “may not,” “prohibited,” and “required”), a quantitative measure much closer to actual regulatory burden than traditional measures in the literature. Second, RegData also relies on a machine-learning algorithm that estimates the probability that these binding constraints are applicable to an industry, thus allowing variation in both cross-section (industry) and time-series (year) dimensions. Theoretically, the impact of business regulation on business investment is ambiguous. The perspective of the public interest view is that regulation exists to ameliorate the market failures of an unregulated market (Pigou 1938). It follows then that increased regulation should be associated with improved social outcomes and potentially increased investment. However, this could be mitigated or reversed given high enough compliance costs or poor implementation. In contrast to the public interest view, the public choice perspective views regulation as potentially socially inefficient for two reasons. First, under the regulatory capture perspective regulating bodies can be captured by industry interests and used to promote the goals of incumbent firms (Tullock 1967; Stigler 1971). An alternative public choice view is that regulation can be created for the benefit of politicians and bureaucrats in the form of rents such as campaign contributions and bribes (McChesney 1987; Shleifer and Vishny 1998). An extensive review of the literature can be found in Djankov et al. (2002). This theoretical ambiguity motivates the need for an empirical examination of the relationship between business investment and business regulation. Moreover, it is noteworthy that the total stock of business regulation does not necessarily need to be neatly contained in any one of the theoretical views above. That is, the total stock of regulation could, for example, contain both regulations that facilitate improved social outcomes as well as regulations that are detrimental to social outcomes. As such, this nuance motivates an examination of the impact of business regulation that is both country-specific and time-specific as the applicable theoretical lens could differ across place and time. Accordingly, this paper, in effect, focuses on the relationship between marginal business regulation and business investment in the modern United States. The results of this paper are therefore generalizable to the extent that the context is similar to the modern United States. Despite the theoretical ambiguity, the economic literature has generally found a negative relationship between regulation and investment. Alesina et al. (2005) examines the impact of product market regulation in the transport, communication, and utilities industries of 21 OECD countries over 1975–1998 period and finds that increased product market regulation leads to decreased investment. Similar results are found in Dawson (2006) over the 1980–2000 period for a broader set of countries using the regulatory index in the Economic Freedom of the World Index. Examining 29 developing countries over the 2003–2007 period, Korutaro and Biekpe (2013) finds that decreased business regulation—as measured by the World Banks’s Doing Business Index—fosters a better investment climate. Looking only at foreign direct investment, Javorcik and Spatareanu (2005), Busse and Groizard (2008), and Corcoran and Gillanders (2015) find that a less regulated business climate attracts foreign direct investment. Other studies have found a negative relationship between regulation and other measures of macroeconomic performance, including Gorgens et al. (2003), Djankov et al. (2006), and Dawson and Seater (2013). The remainder of the paper is as follows. The next section discusses the RegData dataset and the manufacturing industry data that are used in this paper. This is followed by a discussion of the econometric specification and results. Finally, the paper closes with a brief summary and discussion.",4
53.0,3.0,Journal of Regulatory Economics,19 May 2018,https://link.springer.com/article/10.1007/s11149-018-9357-y,Fiber deployment in Spain,June 2018,Joan Calzada,Begoña García-Mariñoso,David Suárez,Female,Female,Male,Mix,,
53.0,3.0,Journal of Regulatory Economics,30 May 2018,https://link.springer.com/article/10.1007/s11149-018-9358-x,Auction design and auction outcomes,June 2018,Pantelis Koutroumpis,Martin Cave,,Male,Male,Unknown,Male,"Auctions are mechanisms that help allocate resources to those that can use them most valuably. Numerous economic transactions are conducted through auctions including treasury bills, foreign exchange, assets under privatization, mineral and spectrum rights among others (Klemperer 1999; Binmore and Klemperer 2002, Salant 2014). The local market conditions, the types of goods auctioned and the priorities faced by the government help shape the overall allocation mechanism and the specific rules of the process. For example spectrum rights represent contracts on rivalrous and scarce natural resources where operators are granted exclusive rights in a band of airwavesFootnote 1 for a specified period of time. In cases where scarce goods under public control are auctioned, regulators and antitrust agencies try to prevent collusive, predatory and entry-deterring behaviors while maximizing the social gains. Auction design, rules and regulatory requirements have been central to the political debate for decades. The rapid adoption of mobile communications and digital technologies has rendered a previously underutilized natural resource—the electromagnetic spectrum—a commodity of major importance. To this end a range of spectrum allocation processes have been used by policy makers in an attempt to maximize the economic and social returns to the local and national economies. The literature suggests that various allocation methods ranging from administrative awards and beauty contests to alternative auction designs, lead to different levels of normalized social returns for the resource in question (Cramton 2013).Footnote 2
 Despite the progress in developing auction mechanisms, auction design “is not ‘one size fits all’ and must be sensitive to the details of the context” (Klemperer 2002a). The context represents the specific market structure and prospects, the regulatory constraints and the overall economic environment in which firms operate. Auction outcomes are affected by less obvious parameters, for example a bidder may feel the thrill of a win over and above her value of receiving the object (Roider and Schmitz 2012). The disclosure of feedback is another novel instrument in design mechanisms resulting in higher revenues (Jehiel 2011). Reserve price levels, the use of absolute auctions (without a minimum price) bid floor or ceiling levels, public or secret reserve prices or even the threat of cancellation have been found to affect outcomes too (Gavious et al. 2002; Che and Gale 1998; Chen and Chiu 2011; Engers and McManus 2007; Rosenkranz and Schmitz 2007). In the recent history of spectrum auctions researchers observed various types of imperfect outcomes both because of the methods used (the actual design of the process) as well as the understanding of the context. Common methodological oversights include the oversupply of licenses compared to the local market needs (Swiss and Italian 3G auctions, 2000),Footnote 3 the lack of adequate provisions to prevent strategic bidding or collusion among operators (tacit or otherwise, including cases of bid signaling in FCC auctions; Cramton and Schwartz 2002; Bajari and Yeo 2009) and high reserve prices for single or packaged lots that end up unsold (Indian auction 2016, for 700, 900 MHz and 2.4 GHz).Footnote 4 An auction may result in suboptimal social returns in other cases, for example when investments are delayed or cancelled due to high—instead of low—prices paid. Typical examples are the UKFootnote 5 and German 3G auctions in the early 2000s where operators paid orders of magnitude more than other operators in similar socioeconomic contexts (Klemperer 2002b). Some argue that elevated costs of entry in mobile services may have an impact on investment for coverage and quality of connections, and lead to higher prices and subsequently lower adoption rates. As we show in Sect. 4 this assertion has often been disputed. The simple question “are auctions socially optimal allocation processes compared to other mechanisms like structured negotiations or beauty contests?” may be hard to answer if other parameters are not taken into account. For example, a competitive mechanism can not directly induce a specific type of behavior to participants but may only provide a framework within which they will be expected to navigate. This oversight is also found in the literature of government security sales where the key aspects that affect an auction’s results are market thickness—the guarantee that there is a large pool of bidders for the auctioned lots—and low entry costs (Klemperer 2002a). Across a range of experiments with different auction designs there are largely inconclusive resultsFootnote 6 regarding external to the design parameters, particularly with the issue of market power as an impediment to efficient outcomes. Other exogenous parameters like the structural imperfections related to market power (like a dominant position or the participation of a new entrant) may also affect the final outcomes (Morey 2001). In this paper we look into the impact of auction design on final prices paid—controlling for many aspects of the context and structure we described. Our focus is the mobile communications market where spectrum auctions have gradually displaced beauty contests as the primary mechanism for assigning high value spectrum. Such auctions combine complexity with far-reaching economic impacts, and have stimulated many of the theoretical developments in the past decade. As a result of this activity we now have records of hundreds of spectrum auctions throughout the world. This makes it possible to address empirical questions about spectrum auction design and auction outcomes. This is a first attempt—to our knowledge—of this kind. We address two key questions: First whether auction design influences the outcome in terms of revenue derived, measured by a standard nominal metric of $ per MHz per unit of population (in the coverage area). And second whether the amount paid for spectrum by an operator is linked to that operator’s legacy spectrum holdings. To address these questions we use a micro-dataset of more than 10,000 lots covering 85 countries and 371 auctions for the period 1994–2015. We find that any auction design is preferable to administrative awards, first come/first serve awards and beauty contests in terms of the normalized returns. This possibility suggests that auctions are better suited to infer true valuations for scarce resources compared to less rigid or transparent processes. Apart from the overall format some specific components of the design have a significant impact on the final price paid. These include the pricing rules (core pricing, “pay as bid”, “highest loser”, etc.), the flexibility to choose among combinations of lots (packaged bids) and the switching of spectrum blocks before the final allocation. The leading combinations in terms of the normalized returns are SMRA auctions with augmented switching and the CCA with core pricing. There is substantial heterogeneity across regional and national licenses while local socioeconomic conditions help explain a substantial proportion of the residual effects. We further look into the market power across regions and its link to the final prices paid. We reconstruct the panel to account for all mergers and acquisitions in the telecommunications industry over the past decades and test the importance of an operator’s customer base, its status as incumbent or entrant and the local regulations concerning dominant firms. Our results show that structural imperfections in local markets combined with local regulations have a major impact on normalized returns. The paper is organized as follows. Section 2 describes our data sources and econometric approach. Section 3 describes the types of spectrum auction, Sect. 4 gives our answer to the first question above, together with a brief attempt to set it in the broader context of spectrum management. Section 5 addresses the second question in a similar framework. Section 6 summarizes and concludes.",7
53.0,3.0,Journal of Regulatory Economics,19 March 2018,https://link.springer.com/article/10.1007/s11149-018-9353-2,Corporate pollution control strategies and labor demand: evidence from China’s manufacturing sector,June 2018,Mengdi Liu,Bing Zhang,Qiang Geng,Unknown,,,Mix,,
53.0,3.0,Journal of Regulatory Economics,10 May 2018,https://link.springer.com/article/10.1007/s11149-018-9355-0,The effects of third party certification on voluntary self-regulation of accidents in the U.S. chemical industry,June 2018,Huan Li,Neha Khanna,Martina Vidovic,,Female,Female,Mix,,
54.0,1.0,Journal of Regulatory Economics,02 July 2018,https://link.springer.com/article/10.1007/s11149-018-9361-2,Regulating monopoly price discrimination,August 2018,Simon Cowan,,,Male,Unknown,Unknown,Male,"Firms with market power that sell their products in several markets often set different profit margins for the same product. What would happen if such a firm was required to set the same profit margin in every market, with the level of this margin being determined by a regulator as an average of the initial margins? This paper presents a general theoretical analysis to address this question. Such a policy would effectively ban price discrimination and would determine the level of profitability of the firm. In the UK the level and the structure of profit margins in domestic energy supply have became an issue for the anti-trust authority and politicians. In 2016 the Competition and Markets Authority found that electricity and natural gas suppliers were over-charging customers on default tariffs compared to those who have signed up for fixed price tariffs and who thus have shown a higher sensitivity to price.Footnote 1 Margins for the supply of the same product differ markedly within each firm. See Waddams Price (2018) for a recent assessment. Similarly a perceived rise in market power has become a matter of general concern to policy-makers. De Loecker and Eeckhout (2017) show that the the average ratio of price to marginal cost in the USA rose from 1.18 in 1980 to 1.67 in 2014, having had no secular trend between 1950 and 1980. Weche and Wambach (2018) perform a similar analysis for European countries, where the recovery of market power after the Great Recession of the late 2000s has been slower than in the USA. The model has a monopolist selling a single product in separated markets. Demand functions and marginal costs can differ across markets. Initially the firm sets its monopoly price in each market. The margin is price minus marginal cost, and the monopoly margins differ. As a result output is inefficiently distributed as far as society is concerned. A given output is allocated efficiently when the profit margins are equal, because the marginal social value of output equals price minus marginal cost. The main aim in this paper is to analyse the implications for consumer surplus and social welfare of requiring a uniform margin. Two levels of the margin are considered: the arithmetic mean of the monopoly margins and the harmonic mean. In each case the weights are the shares of total output. A uniform margin equal to the arithmetic mean benefits consumers in aggregate. The argument for this is general, as it depends only on demand curves sloping downwards, and it does not depend on the initial margins being the monopoly ones. An implication of initial profit maximization, however, is that total output is lower with this uniform margin and the effect on social welfare can be negative or positive. The harmonic mean is below the arithmetic mean, so all consumers are better off with the former. The lower margin has two additional desirable features: it guarantees that total output is above the monopoly level when the demand functions are convex, and it is the profit-maximizing uniform margin if the demand functions are linear (so the firm prefers it to the arithmetic mean). An alternative form of regulation, which equalizes the ratio of price to marginal cost, is also explored. This is particularly relevant when the products differ across markets and thus cannot be directly aggregated. Miravete et al. (2017) analyse the effects of a regulation that requires state-run alcohol retailers in Pennsylvania to set a uniform ratio of price to wholesale cost of 1.3. A regulator with complete information and a full set of instruments would set each price equal to marginal cost and would finance any resulting losses by a lump-sum transfer. If the regulator cannot make transfers then the second-best solution is Ramsey pricing. This equalizes the product of the mark-up (the margin divided by the price) and the price elasticity and yields zero profit to the firm. The focus instead here is on piecemeal reforms to monopoly pricing that have robust welfare properties and can be implemented without a large information requirement. In the analysis of classic price discrimination marginal cost is common across markets. The firm chooses discriminatory prices that vary with demand differences. Alternatively it chooses a uniform price, which implies a uniform margin. In contrast in this paper the level of the uniform margin is determined by a regulator. Classic price discrimination can be negative or positive for social welfare, and knowledge of the shapes of the demand functions is needed to determine the sign of the welfare effect (Aguirre et al. 2010). An important feature of the analysis here is that it makes minimal assumptions about the shapes of the demand functions. When marginal costs differ price discrimination may be said to hold either when margins differ or when price-cost ratios vary. Clerides (2004) discusses and compares these definitions. The analysis here covers both definitions. 
DellaVigna and Gentzkow (2017) show that uniform pricing is very common amongst US retailers, and Cavallo et al. (2014) show that four large global retailers set uniform prices for tens of thousands of products within currency unions. Chen and Schwartz (2015) have a monopolist initially choosing a uniform price while marginal costs differ and demand functions have the same shape. The firm is then allowed to use monopoly pricing in each market. Aggregate consumer surplus is higher with monopoly pricing under mild conditions on the demand function, and social welfare is higher under conditions that are weaker (because profits rise). The techniques used in the main part of this paper are applied to assess the welfare effects of a uniform margin rather than a uniform price. A striking result is that if demand functions are convex a uniform margin equal to an average of the initial margins guarantees that both aggregate consumer surplus and profits are higher than with the uniform price. This works for any initial uniform price provided the implied margin is positive. Uniform margin regulation is examined in Sect. 2. Section 3 assesses a uniform price-cost ratio. In Sect. 4 the uniform margin and uniform price-cost ratio are compared. Section 5 analyses a uniform margin when costs differ and initially the firm is constrained to set a uniform price. Section 6 concludes.",5
54.0,1.0,Journal of Regulatory Economics,12 July 2018,https://link.springer.com/article/10.1007/s11149-018-9363-0,Monopoly regulation when customers need to make sunk investments: evidence from the Swedish district heating sector,August 2018,Darryl Biggar,Matthieu Glachant,Magnus Söderberg,Male,Male,Male,Male,"In addition to usual objectives such as reducing or eliminating deadweight loss (Crew and Kleindorfer 2006), it has been suggested that natural monopoly regulation should also protect and promote sunk complementary investments made by potential and existing customers of the regulated firm (Goldberg 1976; Biggar 2009).Footnote 1 According to this view, a distinguishing feature of certain natural monopoly industries is the need for customers to make sunk, relationship-specific investments in order to extract the most value from the monopoly service.Footnote 2, Footnote 3 These could be investments in specialised customer-premises equipment, human capital, or investment in a particular location, such as investments by an aluminium smelter relying on local electricity supply, household investment in gas appliances relying on the local gas supply, or investment in a coal mine close to a major rail spur. Once these investments are sunk, they are subject to the risk that the monopoly will increase its prices and expropriate the value of the investments. When this hold-up problem cannot be solved through private vertical integration or long-term contracting arrangements, regulation may play a role. According to this view, a rationale for natural monopoly regulation is to protect and thereby promote customers’ sunk investments to ensure that they take up and get the most value out of the monopoly service.Footnote 4 This argument applies to network industries where the market size is not fixed so that attracting new customers is an issue and where connection costs are significant and irreversible. In addition to district heating in Sweden which is examined in this paper, one could think of water or electricity distribution in developing countries or natural gas distribution in many countries where gas heating competes with other heating technologies. To date, no empirical test has been carried out to determine whether there is economic substance in this alternative justification for price control regulation. But what would such a test look like? The key hypothesis is that price regulation, by protecting customers from price increases, promotes customers’ sunk investments and therefore promotes take-up of the monopoly service. Perhaps the ideal test would be a randomised controlled trial in which customers must invest to take up the monopoly service and where service providers are randomly subject to price regulation. We could then observe whether there is a material difference in the take-up rate of the monopoly service in regulated versus unregulated markets. If a material difference was found, we could infer that a key objective of price regulation, through controlling the path of prices, is to promote the take-up of the monopoly service. Such a test is not feasible. However, the Swedish district heating market has a number of desirable features which come close. In Sweden, district heating is provided by a large number of small, independent monopoly firms and, during the period of our study, prices were unregulated. In addition, their networks have expanded considerably since the end of the 1990s. This stands in contrast to most monopolistic network sectors in the developed world, where customers have already made the most of the required sunk investments, and where prices are subject to price control regulation by an independent regulatory agency. Furthermore, customers who wish to make use of district heating must purchase and install customer-premises equipment, which can cost more than ten times the annual consumption expenditure on heating. In Sweden, this has given rise to concerns that customers who have made this investment are locked into the district heating service (EI 2007; Henning 2006) and that, fearing future increases in prices, they might be reluctant to make the necessary investments—potentially choosing environmentally or economically inferior heating alternatives (SOU 2004, p. 15; EI 2007, p. 41).Footnote 5
 In this paper, we use the natural variation in pricing policies of these utilities to explore the impact of pricing decisions on the take-up rate of district heating and to identify the gap with a counterfactual scenario featuring price regulation. The analysis involves three steps. We first develop a model featuring a private monopoly providing a district heating service to customers. The objective is to go deeper into the motivation of the research question by characterizing monopoly pricing behaviour, the hold-up problem, and the potential role of regulation as a commitment mechanism to increase customer incentives to connect to the network. We show that the possibility to commit increases both customer surplus and firms’ profits relative to a scenario without commitment, and that the monopoly then chooses to commit to rigid prices. This commitment is however not credible without third party enforcement. These findings decisively hinge upon the assumptions that customers are forward-looking and risk averse when adopting district heating. In the second step, using data from the Swedish district heating sector from 1998 to 2007, we estimate the fixed-effects demand model developed by Berry (1994) to test these assumptions. The dependent variable is the ratio between residential property owners that invest in district heating and those that are in a position to invest in a new heating system in each local market. Assuming that customers form expectations about future prices based on recent past price outcomes, we construct two variables that measure (1) the slope of the long-term price trend and (2) variations around this long-term trend. In line with the theory, we find that the rate of connections to the district heating network decreases when these variables increase. Since all of the price variables must be considered endogenous, we collect the share of fossil fuel, which is strongly related to the cost of providing district heating, directly from the firms and use that as an instrument. The econometric estimation thus confirms that customer investments are influenced by future price levels and volatility. In the last stage, we use the estimates to simulate a counterfactual scenario with an optimal price regulation. In this scenario, the price is set to the unit production cost averaged over time so that the price is held constant. We find that the market share is 11.3%, which is remarkably close to 9.3%, the predicted market share under the business-as-usual (unregulated) scenario. A look at descriptive statistics suggests that this limited gap is driven by both low mark-ups and a low inter-annual price volatility. One possible reason for this pricing behaviour is the threat of price regulation during the study period. Since the deregulation of the energy sector in 1996, regulation has been a subject of continuous political debate. Public dissatisfaction has brought the market to the brink of regulation several times. The height of the debate was the passing of the District Heating Act (DHA) in 2008, which created a formal procedure through which customers could complain to a national board about the prices they were charged. This paper primarily contributes to the economic literature on natural monopoly regulation pioneered by Goldberg (1976), which stresses the problem of incomplete contracting between buyers and suppliers. A recent example is the work by Chisari and Kessides (2009), who examine the case of developing countries where natural monopoly sectors with low coverage ratios face significant network expansion opportunities. This literature is essentially theoretical and we propose an empirical study to assess the importance of the concern. Our results lend support to the common regulatory practice of promoting price stability—a practice which has no clear rationale under the neoclassical approach to public utility regulation. The results support the view of natural monopoly regulation as a form of long-term contract seeking to protect and promote the sunk relationship-specific investments of the monopoly service provider and its customers. This has important implications for the analysis of regulatory policy and the design of regulatory institutions. The paper is also related to studies which have found that when there is scope for inter-temporal substitution of purchases, past purchases, together with expectations about future price paths, have an effect on present demand. This literature has focused on both the case where goods are storable and customers can hold inventories (Erdem et al. 2003; Sun et al. 2003; Hendel and Nevo 2004, 2006a, b; Su 2010), and the case where goods are durable (Chah et al. 1995; Nair 2007; Chevalier and Goolsbee 2009; Gowrisankaran and Rysman 2012). In the next section we review the more specific literature on customer behaviour in Sweden with respect to investments in district heating, and show that it too strongly supports our fundamental assumption that customers are forward-looking. Our analysis could also be related to the broader literature on ‘price stickiness’ and ‘price rigidity’. An example is the study of customer habit formation by Nakamura and Steinsson (2011). Nakamura and Steinsson emphasise that if the supplier of a habit-forming product cannot commit to a price path, customers face a time-inconsistency problem—the decision to consume in the first period increases their subsequent demand, which the supplying firm may exploit with a higher price in subsequent periods. The paper continues with a description of the Swedish district heating sector. In Sect. 3 we lay out our modelling approach. Section 4 describes the data. Section 5 contains the empirical evaluation where the two key assumptions are tested. Section 6 concludes.",9
54.0,1.0,Journal of Regulatory Economics,18 June 2018,https://link.springer.com/article/10.1007/s11149-018-9360-3,Efficient indirect regulation under Protection for Sale,August 2018,Doron Nisani,,,Male,Unknown,Unknown,Male,"The First Welfare Theorem was developed by Arrow (1951) and Debreu (1951) and it states that a competitive equilibrium is weakly Pareto-Efficient. In addition, the Welfare Theory claims that under market failures regulatory intervention is required. These interventions include direct intervention (Quota) or indirect intervention (Tax) that are required to increase economic market welfare. Buchanan and Tullock (1975) examined the effects of direct and indirect intervention on a regulated market with negative externalities. They concluded that the producers would benefit from a direct intervention, as opposed to an indirect intervention, due to their ability to trade the production quotas among themselves. Zusman (1976) described the political influence of various interest groups on the regulator as a cooperative bargaining game and applied the Zeuthen–Nash solution to demonstrate it. Zusman and Amiad (1977) applied the former methodology on the dairy market, but could not reach a definite result. They concluded that they might be missing another parameter to explain the political interaction. Panagariya and Rodrik (1991) noticed that a uniform price policy has been increasingly applied in various international trade policies, and so they proposed three explanations for this observation: first, a uniform price policy leads to “free-riding”, which leads to less lobbying in comparison to a differential price policy; second, a uniform price policy in input-products might lead to decrease in customs on output-products; third, a uniform price policy may increase the political contributions for regulatory protection in other regulated markets. Bernheim and Whinston (1986) characterised the Nash equilibrium in a Menu-Auction, which can describe markets under political pressures. The solution for this kind of auction is a pricing policy that maximises both the regulator’s and the interest groups’ goals. Grossman and Helpman (1994) applied the Menu-Auction methodology and developed a model (GH Model) that describes the determined trade policy between the regulator and the interest groups. The authors named the interaction between the regulator and the interests groups Protection for Sale, and they explained the key role of the interest groups’ donations in influencing the regulation policy in their favour. Finkelshtain and Kislev (1997) applied the GH Model on a market with either positive or negative externalities in order to examine which regulatory intervention leads to a more efficient resource allocation. The authors assumed that under Uniform Quotas Policy (UQP) the participation ratio in the political game would be partial, whereas under Differential Quotas Policy (DQP) the participation ratio in the political game would be full. These results lead to a regulator that is far more resilient against political pressure in the case of indirect intervention versus direct intervention. Moreover, the authors detailed their results according to positive or negative externalities. In the case of negative externalities, indirect regulation leads to lower contributions, which, in turn, leads to a more efficient allocation than does direct regulation (when the participation ratio is lower than the demand elasticity). On the other hand, in the case of positive externalities, indirect regulation leads to a more efficient allocation than does direct regulation, but the influence of the regulation on market efficiency is inconclusive. In addition, the efficiency of the regulation increases as the regulator tends to favour welfare over political contributions. Bombardini (2008) proposed that given the Protection for Sale conditions and a fixed participation fee, only the large producers will have the incentive to join an interest group and try to influence the regulator. Hence, the small producers will be left out of the political game. Furusawa and Konishi (2011) proved that under public good market conditions the interest group is not empty, meaning the interest group will include at least one producer that donates to the regulator. It is possible to reach this result assuming there is both a corporate and a non-corporate game between the regulator and the interest groups. The GH Model methodology can be used to estimate the political parameters from actual regulated policies in different sectors. Gawande and Hoekman (2006) estimated the welfare-to-political-contribution ratio to be between 48 and 63 in agriculture industries sectors. In a similar research, Gawande et al. (2012) estimated the same ratio to be between 125 and 515 in international trade sectors. Gawande and Magee (2012) combined the influence of the “free-riders” effect in the GH Model, and estimated the welfare-to-political-contribution ratio to be between 4 and 13 in the international trade sectors and the participation ratio in these sectors to be 0.54–0.63. Regulatory intervention is a double-edged sword. On the one hand, it is required to overcome market failures in order to increase market welfare. But on the other hand, it causes the conditions of Protection for Sale, which is another kind of regulatory failure and therefore decreases market welfare. This article examines the effects of indirect intervention and regulatory failure that stem from political lobbying pressures on a regulated market and presents the outcomes of Differential and Uniform Price Policies. Moreover, is seems that a unique combination of these two price policies may yield a new price policy that would reduce welfare-loss to a minimum.",1
54.0,1.0,Journal of Regulatory Economics,17 July 2018,https://link.springer.com/article/10.1007/s11149-018-9362-1,"Regulatory compliance, information disclosure and peer effects: evidence from the Mexican gasoline market",August 2018,Xian Liu,Barrett Kirwan,Andrea Martens,,Male,Female,Mix,,
54.0,1.0,Journal of Regulatory Economics,14 June 2018,https://link.springer.com/article/10.1007/s11149-018-9359-9,Price competition in the market for business telecommunications services,August 2018,Gregory L. Rosston,Scott J. Savage,Bradley S. Wimmer,Male,Male,Male,Male,"The effect of entry and competition on prices is a fundamental line of inquiry in industrial organization. There was significant entry in the provision of business telecommunications services during the Internet boom of the late 1990s and early 2000s. The effect of this entry into what had been a restricted and regulated marketplace can shed light on current regulatory policy decisions regarding business data services (BDS) and other market opening decisions. Consistent estimation of the effects of entry and competition requires that researchers account for the presence of unobserved factors. For example, unobserved positive demand shocks may result in both more entrants and higher prices, while unobserved negative cost shocks may result in more entrants and lower prices. The failure to account empirically for such relationships results in inconsistent estimates of the effects of entry. This paper uses a control-function approach that constructs a correction term from a first-step latent profit equation to investigate the effects of entry on the price of business telecommunication services in the United States. This control-function approach has been used to evaluate, among other things: the price effects from product-differentiated competition between motels (Mazzeo 2002); the price effects of mergers between office supply superstores (Manuszak and Moul 2008); and the effect of entry on the speed of services offered by Internet service providers (ISPs) (Molnar and Savage 2017). Our results shed light on recent Federal Communications Commission (FCC) concern about market power in the provision of BDS (FCC 2016). The FCC’s conclusions are based on an empirical study showing that competition led to lower incumbent BDS prices in areas where the FCC had relaxed its price regulation and provided incumbents with the flexibility to adjust prices, upward or downward, in response to market conditions. This paper shows that the control-function approach may be used to verify the results upon which the FCC bases its policy decisions or may help obtain more accurate results. FCC data show that traditional circuit-based technologies generated about 75% of BDS revenue in 2013 (Rysman 2016). These services include DS1 lines with upload and download speeds of 1.5 megabits per second (Mbps) and DS3 lines with speeds of about 45 Mbps. Other services use packet-based switching delivered over fiber optic cables. BDS providers include incumbent local-exchange carriers (ILECs), such as the former Regional Bell Operating Companies (RBOCs), and their competitors, which include cable companies and other competitive local-exchange carriers (CLECs). Rysman (2016) estimates regressions with census-tract fixed effects and shows that the presence of facilities-based competition in a census block lowers ILEC DS1 and DS3 prices by about 3.2% and 10.9%, respectively. These estimates rise to 5.6% for DS1 lines and 11.4% for DS3 lines when controlling for county fixed effects. He also finds that competition has little effect on prices in markets with price caps and suggests that resale competition based on wholesale access to incumbent unbundled network elements (UNEs) is ineffective. The FCC and other regulators may use the results from pricing studies to develop conditions under which price and other forms of regulation may be relaxed. However, fixed-effects regressions may be misleading when they do not adequately control for endogenous market structure (Sweeting 2016; Valletti 2016). It is impossible to test for endogenous market structure directly in the BDS market because the FCC data used by Rysman are not publicly available. It is possible, however, to shed light on the endogeneity concerns and regulatory policy in the overall market for business services by using a control-function approach to estimate the effects of entry on the price of telecommunications services provided to small businesses with cross-sectional data that is available to the general public. We define a competitor as an entrant that has installed a switch and is providing service to a city or locality. With this definition, we measure the number of facilities-based entrants providing service in 4168 cities across 43 states in 2002. Data on prices and market entry in 2002 are useful for measuring the impact of entry on prices more generally. The Telecommunications Act of 1996 (Telecom Act) had been in place for 6 years, the FCC had issued its initial rules, and state regulators had enough time to implement their rules and new price structures in response. The FCC changed its regulations about the availability of UNEs in 2003 so subsequent data would not reflect the effects of the initial rules and firm entry decisions. The business service we investigate also has similar copper loop technology as the circuit-based BDS services in Rysman (2016). Moreover, as in the case of BDS, most states use price caps to regulate local business services, with prices generally set at the city level, although prices may vary within cities. For example, prices in business districts and areas with high-rise apartments may differ from those offered in residential areas. Because competition has non-linear effects on prices, we use the control-function approach to relate incumbent prices to the number of entrants, cost, demand, regulations, and a correction term for the endogeneity of market structure. Ordinary least squares (OLS) regressions understate the effects of competitive entry on incumbent business prices compared to controlling for the endogeneity of entry and satisfaction of the Telecom Act’s Section 271 market-opening requirements. We estimate that incumbent business prices are about 3.1% lower in markets with a single entrant, and about 5.4% lower in markets with two entrants. These estimates are in line with Rysman’s results for DS1 services. The evidence also shows that facilities-based competition is more important than UNE-based competition and that business prices were more than 10% lower in states where the RBOC had satisfied the Telecom Act’s Section 271 market-opening requirements. Several empirical studies analyze competition in telecommunications markets. Greenstein and Mazzeo (2006) and Xiao and Orazem (2011) show that entry strategies into local markets are based on some product differentiation, demand conditions, and both sunk and non-sunk costs. Their findings are consistent with Economides et al. (2008) who find that while UNE-based entry into local residential telephone markets in New York had little effect on the level of prices, the introduction of new pricing plans generated welfare gains of $0.83 per month for residential consumers. Wallsten and Mallahan (2013) find that the number of ISPs in United States markets are negatively correlated with prices, and positively correlated with advertised downstream speeds, while Molnar and Savage (2017) show a similar result for actual speeds delivered. Nardotto et al. (2015) show a positive relationship between low barriers to entry, measured by local loop unbundling, and download speeds in the United Kingdom. Our paper contributes to this literature by offering evidence from a new measure of facilities-based competition in the provision of small-business telecommunications services. The next section describes the empirical model used to test the price-competition relationship. Section three describes the data. Results are presented in Section four and Section five concludes.",1
54.0,2.0,Journal of Regulatory Economics,24 September 2018,https://link.springer.com/article/10.1007/s11149-018-9368-8,Endogenous timing when a vertically integrated producer supplies a rival,October 2018,Anil Arya,Brian Mittendorf,,Male,Male,Unknown,Male,"Distinct lines of separation between suppliers and retailers characterize the traditional retail landscape: suppliers provide products to retailers who then serve as conduits to reach consumers. However, many markets for whom input production requires substantial initial capacity (such as utilities) are characterized by a dominant vertically integrated producer (VIP) who provides inputs to other retail providers. VIPs serve as both wholesale suppliers and retail competitors, thus upending traditional views of market interactions (see, e.g., Sappington 2006). The burgeoning presence of e-commerce has also brought “dual distribution”—where suppliers continue to reach consumers through traditional retailers but also use their own direct-to-consumer online sales channels as VIPs—into the mainstream of retailing (Tedeschi 2005). As common examples, Nike, Apple, and Microsoft are all VIPs that have online storefronts that tacitly compete over end users with traditional retailers who too sell the producers’ goods to consumers. A distinguishing feature of dual distribution is that a buyer faces retail competition from its own VIP supplier. This introduces the notion of “optimal” supplier encroachment. On the one hand, the VIP wants to encroach aggressively to extract more of the retail profits. On the other hand, such aggression cuts down on its wholesale demand by undercutting the buyer’s willingness to pay for inputs. As a consequence, VIPs want to adopt a “goldilocks” encroachment stance, one that maximizes aggregate profits by balancing successes in the wholesale and retail markets and thereby positions the VIP as both a competitor and partner (see, e.g., Mandy and Sappington 2007). Accounting for VIP encroachment, and the ensuing need to balance profits across wholesale and retail realms, this paper endogenizes firms’ timing of strategic decisions. As we demonstrate, the equilibrium results stand in stark contrast to those obtained under traditional single-channel analysis of the timing problem (e.g., Dixit 1979; Gal-Or 1985; Dowrick 1986; Hamilton and Slutsky 1990). To elaborate, the paper employs the familiar Hamilton and Slutsky (1990) duopoly model of endogenous timing wherein two competing firms, firm A and firm B, have the option to make their quantity choice “early” or “late”. The model is appended to represent a VIP: firm B sells inputs to firm A for a given per-unit wholesale price. In effect, firm B reaches consumers directly (through its own distribution arm) and indirectly (through firm A). Under quantity competition, the result in the traditional setting when firm A either makes inputs or procures them from an independent supplier is well documented: each retail firm races to be a leader and, as a consequence, the equilibrium entails simultaneous early play. This remains the outcome with a regulated industry with a VIP but only as long as the regulated input price is negligible. Roughly stated, at a very low input price, each firm is concerned primarily with retail profits and, when this is the case, the usual thinking is applicable. However, above a modest cutoff value of the wholesale price, there is a reversal: simultaneous play is never an equilibrium, and sequential play is guaranteed. The intuition for the above result is rooted in firm B’s desire to suitably balance profits across its wholesale and retail operations. Simultaneous play, either early or late, is not an equilibrium because with nontrivial wholesale considerations firm B always has incentives to deviate. By deviating from early simultaneous play, firm B becomes a follower and gleans wholesale gains from the emboldened competitive posture of its rival—for firm A to best exploit being a Stackelberg leader, it must purchase substantial inputs and this boosts wholesale profits of the supplier in significant fashion. By deviating from late simultaneous play, firm B becomes a leader and gains from the ability to pre-commit to limited retail encroachment, another means of encouraging firm A’s wholesale purchases. With simultaneous play disabled as an equilibrium, sequential play with firm B moving late is always an equilibrium. The late move by firm B permits it to retain the option to encroach while intentionally also giving an instrument to firm A to curtail its exercise of that option—by purchasing more upfront, firm A can reduce firm B’s incentive to encroach in the retail arena. Firm A is comfortable with this arrangement since it gives it a Stackelberg leader advantage in retail competition. In a sense, the supplying firm B decides to cede competitive advantage, a form of self-sabotage (Sappington and Weisman 2005; Brown and Sappington 2017), in order to improve its input market positioning. In this light, firms opening direct-to-consumer channels often note that they do so with the intent of improving, not eliminating, relationships with retailers and are acutely aware that they must take proactive steps to cultivate the traditional retail channel (Callard 2014); moving late enables firm B to do just that. The fact that sequential play is a “win–win”—both firms are better-off relative to simultaneous play—provides one potential reason for why firm A may prefer to procure inputs from the VIP rather than from an independent supplier for the same wholesale price. By buying from firm B, firm A procures not just the input but also a more favorable strategic response of softened encroachment. Having demonstrated the tie-in between wholesale prices and the equilibrium timing of quantities, we then endogenize the supplier’s wholesale price in cases where VIP input pricing is unregulated. We show that firm B optimally sets price to induce the sequential equilibrium under which it is a late mover. Thus, while the typical view is that each firm prefers to be Stackelberg leader, here firm B has a strict preference to be a late mover: the late move best balances firm B’s wholesale and retail profits. Moreover, such timing can lead to preference alignment in that firm A, solely focused on retail profit, relishes the advantage Stackelberg leadership provides. Interestingly, to the extent preferences for the leader and follower positions are misaligned, it is because each firm may benefit from being the follower. We also derive the timing equilibrium under price competition. Here, the result in unregulated traditional markets prescribes sequential play. The reasoning for this outcome is that, with upward sloping reaction functions, moving in sequence is a coordination device to soften competition. Again, with a regulated VIP in the mix, this traditional result is reversed in that it is early simultaneous play that is now the unique equilibrium of the game. This is because simultaneous play is not quite as “cut throat” as in the single-channel setting. In particular, with dual distribution, firm B is soft in competition even under simultaneous play since setting a high retail price guarantees more wholesale purchases—firm B’s conjectures are that firm A’s retail price, not its quantities, are fixed. In fact, moving early is a strict dominant strategy for each firm. This paper lies at the intersection of the long-standing research on the timing of decisions in models of duopoly competition and the burgeoning research examining the growth and ramifications of multi-channel distribution arrangements with a VIP. In terms of the former, Dixit (1979), Gal-Or (1985), and Dowrick (1986) confirm that in the case of standard quantity (price) competition, firms prefer to be leaders (followers). Hamilton and Slutsky (1990) take this one step further, endogenizing the sequence of play in light of the firms’ timing preferences. Their work demonstrates the existence of an equilibrium that entails simultaneous early play under quantity competition and sequential play under price competition games. Subsequent work has identified circumstances that can support sequential play as an equilibrium outcome under quantity competition, including declining production costs across time, multiple competitors, and/or capacity costs—see Robson (1990a, b), Pal (1991, 1996), and Anderson and Engers (1994). The presence of VIP arrangements is well-documented, particularly in regulated industries (see, e.g., Sappington 2006). The expansion of VIP arrangements even in unregulated markets has been attributed to an ability to better reach consumers with different tastes for brands or distribution channels, more effectively monitor retailers and distributors, and/or convey quality of products (e.g., Gallini and Lutz 1992; Vinhas and Anderson 2005; Chen et al. 2008). These dual distribution arrangements create a tradeoff between wholesale and retail profits for the supplier, which can be difficult to balance (e.g., Kalnins 2004; Tsay and Agrawal 2004; Sappington and Unel 2005). As a consequence, suppliers may even be compelled to lower wholesale prices to encourage purchases (Chiang et al. 2003). Moreover, when the encroaching supplier has the ability to make contingent price adjustments, it can create a circumstance where it gleans benefits from being late (Arya and Mittendorf 2010). The present analysis adds to the literature by incorporating the common practice in regulated markets of dual distribution, and associated concerns of VIP encroachment, to endogenize the timing of the competing firms’ strategic decisions. In doing so, it shows that the timing equilibrium in the presence of a VIP reverses conventional results: the leader–follower sequential equilibrium is the outcome under quantity competition, and the race to be the leader and ensuing simultaneous play is the norm under price competition. The remainder of this paper proceeds as follows. Section 2 presents the basic model of timing in the presence of a VIP. Section 3 derives the results: Sect. 3.1 derives the competitive equilibrium for each timing strategy; Sect. 3.2 derives the timing equilibrium with a regulated input price and also examines the case when the supplier has discretion in setting wholesale price; Sect. 3.3 revisits the results under retail price competition. Section 4 concludes the analysis.",5
54.0,2.0,Journal of Regulatory Economics,08 September 2018,https://link.springer.com/article/10.1007/s11149-018-9366-x,The spatial correlation and interaction between environmental regulation and foreign direct investment,October 2018,Zhonghua Cheng,Lianshui Li,Jun Liu,Unknown,Unknown,,Mix,,
54.0,2.0,Journal of Regulatory Economics,05 September 2018,https://link.springer.com/article/10.1007/s11149-018-9365-y,Product regulations and persistence of profits: OECD evidence,October 2018,Johan E. Eklund,Emma Lappi,,Male,Female,Unknown,Mix,,
54.0,2.0,Journal of Regulatory Economics,22 September 2018,https://link.springer.com/article/10.1007/s11149-018-9367-9,Incentive properties of coincident peak pricing,October 2018,Ross Baldick,,,Male,Unknown,Unknown,Male,"Retail electric customers in restructured electricity markets pay for their consumption under tariffs that are designed to recover the energy, transmission and distribution, and per customer components of costs of delivered electricity. Typically, the energy is purchased by retail customers under a volumetric, that is, per kWh, tariff component that directly or indirectly reflects wholesale energy market prices. On the other hand, the charges for transmission and distribution and per customer costs are recovered in a variety of ways. At one extreme, these charges might be included in a volumetric charge based on the ratio of the total transmission, distribution and per customer costs divided by total energy sales. We will refer to this type of approach as a “volumetric adder per unit energy.” At the other extreme, the charges for transmission and distribution could be unbundled into specific tariff components. For recent discussions of such tariffs, see Abdelmotteleb et al. (2018), Borenstein (2012), Faruqui and Aydin (2017), Haro et al. (2017), Passey et al. (2017). In this context, coincident peak pricing is used in several electricity markets to recover annualized capital costs of electricity assets from end-use consumers. The charge to the end-use consumers is in proportion to their measured consumption at the times of overall system peaks or at the times of the peaks of a particular sub-system. The assets could, in principle, be generation, transmission, or distribution related; however, coincident peak pricing is most typically used for transmission and distribution assets. In the context of transmission, measured consumption at the time of the system peak in one year may be used to set the required payment for transmission that year or for the following year. The total payment is designed to recover the total annual “revenue requirements” of the transmission system to finance the existing capacity and potentially to finance the building of necessary new capacity to meet the peak demand forecast for the following year or years. For example, coincident peak pricing is used for recovering some transmission system costs in the Electric Reliability Council of Texas (ERCOT) for, among others, large commercial and industrial consumers (Zarnikau 2017b). In ERCOT, the transmission charges for each large consumer over a particular calendar year are assessed on the average of its 15-min electrical demands occurring at the time of the four monthly 15-min peak demands of the entire ERCOT system for the months of June, July, August, and September during the prior year (Electric Reliability Council of Texas 2017, Section 9.17.1). The resulting charges are referred to as “four coincident peak” (4CP) charges, and the intervals when these peaks occur are called “4CP events.” In other regions of the United States, several other tariffs are also based on coincident peak consumption, differing in detail but broadly similar to the ERCOT 4CP charges. (See openei.org/wiki/Utility_Rate_Database for a database of tariffs in the United States.) For example, other regions in the United States use a different number of intervals to assess the coincident peak. Coincident peak pricing is also used in the United Kingdom, where the transmission network use of system charges for each large consumer are based on the average of its 30-min electrical demands occurring at the time of the three highest 30-min peak demands of the entire system that are separated by at least 10 days (National Grid 2015). The resulting charges are referred to as “Triad” charges. To summarize, coincident peak pricing is utilized in a variety of electricity markets to recover transmission (and, in some cases, distribution) system costs. In some jurisdictions, customer non-coincident peak demand may be used as a proxy to evaluating the contribution to coincident peak. For a discussion of the relationship between the number of intervals used in evaluating the customer non-coincident peak and the contribution to the coincident peak, see Passey et al. (2017). In this paper, we will assume that the contribution to the coincident peak of each end-user can be directly measured without error. Several researchers have criticized the use of coincident peak pricing and similar charging methods to recover sunk costs. For example, see Borenstein (2012) for a general criticism of such approaches and (Hogan and Pope 2017) for specific criticism in the context of ERCOT. For a numerical simulation of this effect in conjunction with options for self-generation, see Schittekatte et al. (2018). While not disputing the observations in Borenstein (2012), Hogan and Pope (2017), Schittekatte et al. (2018) that capacity-based charges are not appropriate for recovering investments that do not depend on the level of consumption, it should be understood that annual load growth together with necessary replacement and maintenance costs imply that at least some transmission and distribution investment is not sunk and that the necessary annual investments therefore depend on the (forecast) demand levels. That is, continuing investments must be made each year to increase capacity or even to maintain capacity at a fixed level. In these circumstances, some of the investment going forward in transmission is potentially “avoidable” in the sense that the amount of expenditure depends on the forecast peak demand level. For example, in regions with population growth and growth in peak demand, such as in ERCOT, there are ongoing investments in transmission and distribution that could be avoided in the absence of that peak demand growth. A recent case in point is the “Houston Import Project” built for anticipated load growth in the Houston area and to compensate for retirements of generation within Houston (Electric Reliability Council of Texas 2014). The Houston Import Project involves approximately half a billion dollars in transmission investment. The collective value of such incremental investments can add significantly to the annual “revenue requirements” for transmission. This is particularly the case in United States, European, and Australian networks where much of the existing system was built decades ago and the costs of these prior investments have been mostly recovered in the past, so that costs associated with existing transmission are mostly due to maintenance costs, whereas costs associated with new transmission include land and construction costs. Moreover, the real cost of building transmission and distribution has increased significantly compared to past epochs of construction due to the cost of land and environmental restrictions. An important motivation for this paper is therefore that in several markets the transmission and distribution charges are becoming a significant fraction of the total retail bill, prompting concerns that resulting high retail prices may result in inefficient reduction in consumption at the time of the peak or inefficiently high levels of self-generation at the time of the peak. See Hogan and Pope (2017, p. 80) for a discussion of this in the context of ERCOT and Agency for the Cooperation of Energy Regulators (2017, p. 13) for a discussion in the European context. This is particularly of concern in systems where there is significant investment or potential investment in renewables (Schittekatte et al. 2018). A large “wedge” between wholesale and retail prices due to charges for sunk transmission investments embedded in volumetric retail tariffs implies that the avoided wholesale production cost at peak times due to self-generation may be lower than the cost of self-generation, even if this self-generation cost is itself lower than the effective retail price. This situation will tend to result in over-investment in self-generation resources. Such over-investment in self-generation could also potentially occur with coincident peak pricing if used to recover sunk costs. For example in ERCOT, the anticipation of a 4CP event, which typically occurs due to high air-conditioning load during high temperature days, and the implications for the transmission charge in the following year, results in significant reduction in net consumption (Zarnikau 2017b). As discussed in Zarnikau (2017a, b), large market participants in ERCOT are actively and successfully forecasting the times of 4CP events and are able to modulate their demand during these periods to reduce 4CP charges the following year. Effectively, the peak of net consumption is “clipped” (Zarnikau 2017a). At least some of this apparent reduction is likely due to self-generation. To the extent that the 4CP prices send incorrect incentives for net consumption by reflecting sunk costs, they are also distorting the demand side of the market and thereby resulting in poor overall investment decisions, including in self-generation. Although there is a clear concern that 4CP and similar charges will result in inefficient decisions when they are used to recover sunk costs, this paper seeks to understand under what circumstances 4CP and similar charges would actually lead to efficient consumption decisions. A key methodological issue is that the time-varying demand and non-storability of electricity implies that efficiency of capital decisions must be assessed on the basis of the benefits accruing over time, not just at the time of the peak demand. Building on the foregoing, in this paper we will primarily consider the case that is polar opposite to sunk costs and model the transmission capacity as being effectively “rented” on an annual basis. While this assumption, and the opposite assumption of fully sunk costs, is not perfectly realistic, we explore the situation for rentable transmission capacity as applied to coincident peak pricing. In a practical context, the assumed rental cost in this paper could be construed as being based on an estimate of the annualized average incremental cost of building additional transmission capacity to meet forecast demand that is growing over time. In Sect. 5, we return to the consideration of sunk costs in the light of the formulation in this paper, observing that a hybrid approach could be used to recover some of the costs using coincident peak pricing based on the incremental costs and with recovery of the rest of the costs using a non-distorting tariff component. A recent example of this approach is described in Abdelmotteleb et al. (2018). As well as analyzing coincident peak pricing, we will also compare it to other charging methodologies and variations. For example, we will consider the case where some of the transmission costs are recovered on the basis of a volumetric adder per unit energy. Such a volumetric adder tends to increase the on-peak consumption compared to the welfare optimal level, all else equal, which acts in the opposite direction to the effect of 4CP charges. As mentioned above, an important aspect of this work is the consideration of an extended time horizon considering temporal variation of demand to assess welfare. This type of analysis is necessary because considering just a snapshot of time, for example at peak demand conditions, cannot reveal the welfare optimal level of transmission capacity. While models that consider welfare over an extended horizon have antecedents such as Stoft (2003), Klemperer and Meyer (1989), Green and Newbery (1992), Green (1996, 1999), the application to coincident peak pricing is novel. Throughout, the setting will abstract from reality along several dimensions. First, we will consider a single capacitated transmission line, whereas practical transmission systems are meshed and there are multiple limiting elements in the system whose constraints are binding at different times of the day or during different seasons. Second, in meshed systems, locational marginal prices translate transmission limitations and generator marginal costs into time-varying prices to demand that increase when transmission limits are reached, reflecting increasing marginal delivered costs. However, we abstract from this to consider peak levels of demand where, because of transmission limitations, there is no available additional generation capacity that can be delivered, and no storage capacity available at the demand to mitigate peak consumption. Third, both transmission and distribution capacity is required to deliver electricity to consumers, but we conflate all such constraints into a single capacitated transmission line. Fourth, although we will consider variation of demand over time, the analysis will be deterministic. In practice, transmission and distribution capacity is typically built to meet extreme conditions that may occur relatively rarely, requiring some adjustment to our analysis to be utilized in practice. Fifth, we will evaluate equilibria in prices, consumption, and capacities assuming that these are simultaneously determined, although markets such as ERCOT set transmission prices for a given year based on consumption in the prior year. Sixth, we ignore strategic behavior, assuming that the demand-side is a price-taker and that the entity designing and building transmission has welfare optimization as its goal. The contributions of this paper are as follows. We formulate a planning problem in welfare-optimal transmission capacity that considers the variability of underlying demand over time enabling an annualized assessment of welfare contributions in order to balance capital and operating costs with willingness-to-pay. As an ideal for comparison, we first consider energy-only prices that would induce the welfare optimizing consumption over time, assuming price-taking behavior. We highlight the informational difficulty in setting such prices. We then consider how coincident peak pricing for transmission could provide the coordinating signal in a more decentralized fashion. To the best of the author’s knowledge, this is the first demonstration of economic efficiency of coincident peak pricing of capacity with non-sunk costs. A numerical example highlights the issues and comparisons are made to other approaches to charging for capacity under the same underlying formulation. The rest of this paper is organized as follows. Section 2 formulates the basic problem and Sect. 3 considers ideal energy-only prices that provide incentives for welfare optimal behavior and then discusses energy and transmission prices as a model of coincident peak pricing that reproduces the incentives for welfare optimal behavior in a more decentralized fashion. An extended example in Sect. 4 is used to illustrate the results. Section 5 considers several variations, including a comparison to the case where network costs are recovered by an adder to energy prices, as is customary for most small consumers such as residential retail customers in the United States and Europe.Footnote 1 Section 6 concludes.",8
54.0,2.0,Journal of Regulatory Economics,03 September 2018,https://link.springer.com/article/10.1007/s11149-018-9364-z,"The recourse rule, regulatory arbitrage, and the financial crisis",October 2018,Stephen Matteo Miller,,,Male,Unknown,Unknown,Male,"After the Latin American debt crisis of 1982, Congress passed the International Lending Supervision Act of 1983 (Public Law 98-181; 97 Stat. 1278), which encouraged regulators to find a multilateral way to increase capital requirements without putting US banks at a competitive disadvantage (see Kapstein 1991, 1994). That process culminated in the 1988 Basel Accords, i.e. “Basel I”. US banks were expected to comply with Basel I by 1992. However, Basel Committee officials subsequently began fine-tuning regulatory capital requirements in response to the perceived shortcomings of the initial guidelines, culminating in the release of the Basel II guidelines before the crisis. US regulators revised regulatory capital requirements in a way that reflected early Basel II proposals through the so-called “Recourse Rule,” finalized on November 29, 2001 by the Federal Reserve (Fed), the Federal Deposit Insurance Corporation (FDIC), the Office of the Comptroller of the Currency (OCC).Footnote 1 “Recourse” in this context refers to arrangements in which bank holding companies (BHCs) retain any credit risk associated with sales of assets, such as during the asset securitization process. In what follows, using difference-in-differences analysis, I show how the Recourse Rule could have spurred some US BHCs to increase their holdings of some of the very securitized financial products that caused concern during the crisis. The 2001 rule, under development since 1994, lowered risk weights for AAA- and AA-rated “private label” mortgage-backed securities (MBS) and collateralized debt obligation (CDO) tranches originated by firms engaged in securitizing assets to 0.2 in line with government-sponsored enterprise (GSE) originated, or “agency,” MBS. For A-rated tranches, the risk weights equaled 0.5. Lower-rated tranches would be assigned higher risk weights. Mabel (2001) and Friedman and Kraus (2011) point out that the rule was designed to encourage securitization without encouraging risk taking, and that the Recourse Rule risk weights for the highest rated tranches were identical to the 2004 Basel II risk weights. While US regulators did not finalize Basel II regulations until December 2007, by finalizing the Recourse Rule they did adopt Basel II risk weights for private label securitizations well before Basel II guidelines were finalized. Lowering risk weights effectively lowers regulatory capital requirements because the risk weights are multiplied by the regulatory capital requirement. For instance, an 8% capital requirement falls to 4%, 1.6%, and 0% for assets with risk weights of 0.5, 0.2, and 0, respectively. Bankers may wish to increase leverage by relying on more debt and less equity financing, and they might do so by holding assets with lower risk weights. Lower risk weights allow BHCs to operate with less capital than if the capital ratios had been measured relative to total assets or liabilities. This, in turn, reduces the BHC’s ability to withstand reductions in net worth following declines in asset values. The Recourse Rule took effect on January 1, 2002, and BHCs were allowed to delay the application until December 2002. However, the rule also allowed BHCs to apply the new rule immediately on November 29, 2001. As a result, the timing of the effects could have been affected by the way the policy was implemented. Therefore, I design a difference-in-differences strategy that applies Mora and Reggio’s (2017) fully flexible approach to estimate average treatment effects of the Recourse Rule on residual estimates of highly rated, private label tranche holdings proposed by Erel et al. (2014) between Q2 2001 and Q4 2007. As a treatment variable, I assume that BHCs with bank subsidiaries that submitted individually or jointly written comment letters on the 1997 and 2000 notice of proposed rulemakings (NPRs) that preceeded the 2001 final rulemaking would have had reasons to hold more tranches than those that did not submit comment letters. The comment letters were obtained from regulators through the Electronic Freedom of Information Act Amendments of 1996 (Pub. Law 104-231; 110 Stat. 3048) process. I find that treated BHCs (those BHCs with commenting subsidiaries) on average increasingly tilted their portfolios toward holdings of the highly rated tranches; on average, BHCs in the control group (those BHCs with no commenting subsidiaries) did not. At the same time, I find evidence that treated BHCs tilted their portfolios away from lower-rated tranches after the final rulemaking. I also find that the treated BHCs increased their holdings of highly rated tranches relative to their book equity capital leading up to the crisis. Thus, if any highly rated tranches experienced large losses, treated BHCs could have been at greater risk of being insolvent, and those holdings could have been associated with changes in BHC risk. To examine this possibility, I measure changes in risk as quarterly first differences of BHC distance-to-default, computed as the natural log of the z-score (see Roy 1952). The z-score computes the sum of return on assets and the equity-to-asset ratio, divided by the asset return standard deviation, and reflects whether BHC losses exceed the equity buffer (see Laeven and Levine 2009). A higher z-score means it takes a larger loss to make a BHC insolvent. I find that greater holdings of the highly rated tranches were associated with declines in the natural log of the z-score from Q1 2008, when the Fed introduced the Term Securities Lending Facility (TSLF) to purchase the risky assets, through Q1 2009, but not before then. As an alternative measure, I estimate the same models after replacing the outcome variable with changes in the quarterly standard deviation of stock returns calculated from intraquarterly daily stock returns. Consistent with the results for the z-score, I find that greater holdings of the highly rated tranches were associated with increases in the quarterly standard deviation of stock returns. The increased holdings for treated BHCs, together with the positive association between these holdings and BHC risk after 2008 lends support to the view that an unintended consequence of the Recourse Rule was that it encouraged securitizing BHCs on average to hold more of the assets that turned out to be associated with higher risk of distress. That’s even though the rule was intended to lower risk-taking at the outset. Holdings of these assets, therefore, can shed light on why some BHCs experienced an increase in insolvency risk during the financial crisis. I begin by briefly recounting some regulatory changes that could have contributed to the securitization crisis in the US, then show how BHC holdings evolved before and after the Recourse Rule, and offer evidence of how highly rated, private label securitization tranches were associated with changes in risk, before concluding.",6
54.0,3.0,Journal of Regulatory Economics,23 November 2018,https://link.springer.com/article/10.1007/s11149-018-9370-1,A theory of social license when regulatory pressure is jointly produced by an EPA and an NGO,December 2018,Anthony Heyes,Andreas Marcel Oestreich,,Male,Male,Unknown,Male,"Firms are subject to pressure from society to behave well. Respect for the environment, eschewing child labor and exploitative labor practices, treating suppliers fairly, etc. are costly, so profit-motivated firms are tempted to cut corners. However, bad behavior, if detected, can also be hazardous to a firm’s bottom line. In addition to the legal penalties that may result from breaking laws, firms face social or reputational penalties for being exposed as behaving badly. These penalties can be large, which explains recent interest in concepts such as ‘social license’, ‘informal regulation’ and ‘beyond compliance behavior’. There is no universally-agreed definition of social license in the management literature. Broadly speaking a firm is said to hold social license if it enjoys community or public support for its activities. There are many reasons why a business can perform better financially when community attitudes towards it are positive, implying that loss of support imposes a penalty. Firms-particularly those operating in key sectors where social license is critical—will invest substantially to avoid losing it. In mining, Prno and Solocombe (2012, p. 346) note that “a social license exists when a firm is seen as having broad, ongoing approval and acceptance of society to conduct its activities” such that nurturing social license is “... one of the most significant challenges that mining companies face”. Informal regulation is a closely-related concept and can be viewed as follows; “When (formal penalties) are weak or absent, communities can often use other channels to force pollution abatement by local factories in a process of informal regulation” (Pargal and Wheeler 1996: 1314). In most settings social pressure is something that is jointly produced by the actions of state (regulators) and non-state (NGO) actors. Typically the regulator and NGO can be expected to have different objectives (the former pursuing welfare, the latter more focussed on environmental outcomes), as well as access to different instruments. This means that the regulator, NGO and representative firm are in a three-way game, seeking strategically to influence community support to their own ends. In the context of a simple model that captures this interaction strategically, we develop a taxonomy of strategies—in the spirit of Fudenberg and Tirole’s (1984) taxonomy of strategies for businesses in a competitive environment—that characterizes the roles of the state regulator and the NGO as a function of some key underlying parameters. Further, very often citizens do not engage in the application of pressure themselves. Rather, by donating money (or other support) to an NGO or activist organization, they delegate their bidding to a third party. Given this, it is natural to ask the following question: If I am a citizen with a particular set of preferences—defined by how I weigh environmental and non-environmental outcomes - what sort of NGO objectives would I want to support with my donation? One that is sensitive to business interests, or one that attaches little or no weight to them? In our framework we show that a citizen typically will not wish to support an NGO with the same objectives as his or her own. Rather, in general the citizen will understand that the citizen’s ends are better served by delegating the fighting of the battle to an NGO whose preferences over environmental versus non-environmental outcomes are systematically different in comparison to the preferences of the citizen. In terms of the development of knowledge in this area the analysis allows us to speak to two questions. The first is how the roles of state enforcer and NGO fit together in a context in which compliance pressure is jointly produced, for instance settings in which social license to operate is important. The second relates to the question of what is the appropriate objective function with which to endow NGOs in our models. Existing models start with an ad hoc assumption about NGO objectives—usually based either on impact (for example Heyes and Martin 2015) aggregate environmental damage (for example Heyes and Kapur 2012) or a variant there-on. Our approach endogenizes the objective function that the activist group seeks to maximize, deriving it from (but not equating it to) the tastes of donors. The second element fits into a wider literature on strategic delegation in other contexts. In Rogoff (1985) a politician with a particular taste for inflation and unemployment delegates control of monetary policy to a central banker more conservative (inflation-hating) than the politician. In Vickers (1985) and Fershtman and Judd (1987) a profit-maximising shareholder delegates the running of the firm to a chief who’s objective function is not profit-maximization. In Heyes and Kapur (2012) a welfare-maximizing government appoints an EPA chief who is not welfare-oriented. In each case the appointment is instrumental—it makes credible a pattern of responses in a subsequent game that is to the ultimate benefit of the principal. In our setting the donor is the principal, and by donating to a particular NGO, the principal appoints that entity as agent to do the bidding on behalf of the principal. The first complements a number of strands of research on the social behaviors of firms. There is a substantial body of theoretical and empirical research on corporate social responsibility (CSR) and behavior that goes beyond compliance (Arora and Gangopadhyay 1995; Pargal and Wheeler 1996). Related to this is the recent flurry of work on ‘private politics’ (Baron 2001, 2009; Baron and Diermeier 2007). A second literature seeks to use formal methods to understand the organization and strategies of the social advocacy sector (Heyes and Martin 2015, 2017; Aldashev and Verdier 2009). With particular focus on community pressure, Heyes and Kapur (2012) develop a model in which a firm engages in CSR in order to maintain community support and/or to regain the support of the community once it has been lost. They characterize how these incentives interact with formal regulatory interventions. Aldashev et al. (2013) analyze the effect of NGO pressure on industry equilibrium (intensity of competition, market structure, and the share of socially responsible firms) and characterize the impact of industry-level changes (market size, consumer tastes) on NGO activism. Heyes and Maxwell (2004) model the interplay of a hypothetical World Environmental Organization and an NGO and find that lawsuits by private citizens crowd in public monitoring but crowd out public sanctions. Lambertini et al. (2016) and Planer-Friedrich and Sahm (2017) outline a delegation approach to CSR. Walter and Chang (2017) analyse the welfare impacts of environmental regulations in the presence of green consumers. And finally, with an empirical focus (Langpap and Shimshack 2010) present empirical evidence on the extent to which private environmental prosecutions crowd out—or crowd in—public monitoring and public enforcement efforts. The starting point for the analysis that follows is the recognition that the pressure on firms to behave well-informal regulatory pressure—is jointly produced by governmental and non-governmental actors. For the purposes of formal modeling we will treat these as single entities and refer to them generically as an Environmental Protection Agency (EPA) and a Non-governmental Organization (NGO). The EPA and NGO can be expected to have different objectives—the former pursuing welfare, the latter more interested in environmental outcomes—as well as different levers that they can use to further their aims. A central assumption that we will make is that the EPA has the means to identify certain corporate behaviors, while the NGO influences public hostility to exposed bad behavior. Of course this will not be realistic in every setting, but is a reasonable approximation in many settings.Footnote 1 In our model we keep things stark. The EPA will choose the probability that bad behavior by a firm is exposed. It might do this through: (1) conducting inspections and publishing results (NGOs do not have the same rights to access plants and conduct inspections that regulators do); (2) requiring submission of data from polluters and disseminating it; and/or (3) mandating direct disclosure by firms of information about various elements of their social impact, or in other ways. The NGO will influence community attitudes to wrongdoing, including the hostility of the social ‘atmosphere’; and therefore will influence the size of the social penalty a firm suffers if its bad behavior is exposed.Footnote 2 This sort of division has been noted by researchers and practitioners in the environmental field: “Regulators are learning the value ... of NGOs to help achieve environmental goals. Information regulation strategies, for example, are explicitly designed to empower NGOs (give them the information they need) to impose informal sanctions on firms based on their environmental record” , (INECE 2005).Footnote 3 The relationship between the NGO and EPA is symbiotic—they need each other. To summarize the assumption in a phrase: In our model the EPA does the naming, the NGO does the shaming. To take a non-environmental analogue, while the efforts of Mothers Against Drunk Driving (MADD) over the last 30 years have substantially heightened the social vilification faced by people caught driving under the influence of alcohol, it still requires the police to pull-over and breathalyze miscreants. The regulator in the model maximizes welfare (equally-weighted sum of compliance and operating costs and environmental damage), while the NGO usually overweighs environmental outcomes. This implies that there is tension between the two; they are not aligned in their preferred outcomes. The strategic interaction between the regulator and NGO in this set-up, and the properties of the resulting pattern of incentives that they jointly-produce, is our focus. The rest of the paper is set out as follows. In Sect. 2 we develop and solve a stylized model of the game between EPA and NGO. The key assumptions embedded in the model are: (a) formal penalties are limited (in fact zero) so that the state regulator must rely on social penalties (social disapproval) to discourage polluting behavior;Footnote 4 (b) the primary tool available to the regulator is information provision; (c) the hostility of the social atmosphere into which evidence of wrong-doing is published can be influenced by attitude-leadership by an NGO; and (d) the EPA and NGO may have different objectives—in particular the latter overweighs environmental outcomes over industry interests—and are strategic in how they behave. An insight of the model is that in making decisions about how much effort to invest in a hostile social atmosphere, the strategic NGO will have regard not only to the direct effect on firms, but also to the induced changes in the actions of the EPA—it’s ‘partner’ in the creation of social pressure. The efficacy of its own actions to whip-up a more hostile social atmosphere may be off-set if the EPA responds by scaling back the intensity of its own information-provision efforts.Footnote 5 In other circumstances the EPA may be induced to expand that intensity, and the NGO will be motivated to push even harder to exploit such crowding-in effects. In parallel the EPA, as a strategic actor in its own right, will realize that the intensity of the information provision program that it operates will influence the incentive that the NGO has to invest in a hostile community atmosphere. We characterize the reaction functions in the game between EPA and NGO. As in Fudenberg and Tirole (1984), and as the discussion in the previous paragraph suggests, critical to incentives in any given context turn out to be whether EPA and NGO intensity choices are strategic complements or substitutes. This depends in turn on a constellation of parameters. Taxonomic in character, the model generates numerous new insights that are inevitably missing from analyses (the existing literature) that fail to recognize that social pressures are jointly-produced by state and non-governmental actors. While the taxonomy is insightful, providing as it does the first rigorous treatment of the joint production of social pressure, in Sect. 3 we use it as a building block to think about strategic delegation in activism. In particular we treat the NGO’s objective function—the weight that the NGO places on environmental as opposed to non-environmental outcomes—as an institution-design parameter that it can choose in a pre-game. We caricature this as appointing an NGO ‘chief’ of a particular disposition, but the weight can equally be thought of as embedded in the practices and protocols within an NGO that determine its advocacy choices.Footnote 6 The question is: If citizens have a particular set of tastes, what type of objective function must an NGO have to attract their support? Section 4 concludes.",3
54.0,3.0,Journal of Regulatory Economics,06 October 2018,https://link.springer.com/article/10.1007/s11149-018-9369-7,Spillovers from regulating corporate campaign contributions,December 2018,Adam Fremeth,Brian Kelleher Richter,Brandon Schaufele,Male,Male,Male,Male,"Corporate money in US politics generates substantial controversy and a series of Supreme Court decisions has fueled the widespread perception that the regulations governing corporate political activity are inadequate. Many believe that more needs to be done to control the influence of corporate interests in politics—especially the role of corporate money.Footnote 1 Public anxiety over corporate involvement in political campaigns has a long history, however, and the recent decisions are merely the latest in a string of contentious cases. Somewhat surprisingly, there is little empirical analysis of the existing regulations on corporate political involvement. Attempts to prohibit corporate involvement in politics date back more than a century to the Tillman Act of 1907. The Federal Election Campaign Act of 1971 represents the modern formulation of campaign finance regulation and the Supreme Court’s landmark 1976 decision in Buckley v. Valeo reaffirmed the legislated constraints by denying a challenge to the limits on corporate political contributions to candidates. The Court clearly stated the purpose of contribution limits is “the prevention of corruption and the appearance of corruption spawned by the real or imagined coercive influence of large financial contributions on candidates’ positions and on their actions if elected to office” [Buckley v. Valeo, 424 US 1 (1976), p. 25 emphasis added]. Proponents of electoral reform in the 1970s believed that, by regulating corporate campaign contributions, they would simultaneously limit corporate influence in politics. The Court states in Buckley that “contribution ceilings ...prevent attempts to circumvent the [Federal Elections Commission] Act through prearranged or coordinated expenditures amounting to disguised contributions” (p. 26, emphasis added). However, even the campaign finance regulation of the 1970s did little to quell public dissatisfaction with corporate money in politics. This paper demonstrates that, similar to other domains of the economy, regulating specific activities such as corporate campaign contributions leads to unintended effects or spillovers. Importantly, the magnitude of these spillovers are large. Our results highlight that firms constrained by existing campaign contribution regulations spend an additional $549,000 to $1.6M on lobbying per cycle, an amount that is more than 100 times the contribution limit for corporate political action committees (PACs). Likewise, contributions from chief executives also increase when PACs hit a regulatory cap on donations. That these estimates dwarf the prevailing contribution limits suggests that a potential source of the public’s longstanding frustration with existing campaign finance regulation is that it is ineffective in practice. In other words, the persistent disillusionment with corporate political regulations may be that the existing rules do not limit the behavior they are supposed to restrain because firms, seeking to sway the policy-making process, strategically respond to these constraints. There have been many studies that investigate the underlying economics of corporate political activity. Few however empirically examine corporate political regulation directly, let alone the spillovers that result from strategic corporate behavior. For example, Stratmann (1992) looks at the strategies and effectiveness of PAC contributions, finding that PACs time their contributions to have the largest impact. Blanes i Vidal et al. (2012), Bertrand et al. (2014) and Cohen and Malloy (2014) demonstrate the importance of personal connections as a channel linking lobbying and voting behavior. Fremeth et al. (2013) highlight the intra-organizational economic features of political investments. Ovtchinnikov and Pantaleoni (2012) show that contributions flow to politicians who have the greatest discretion over those policies targeted at firms located in specific jurisdictions and Bombardini and Trebbi (2011) relate interest group size to campaign contributions. A theme shared by this research is that corporate political activity has the potential to improve firm outcomes by influencing policy-makers, but none investigate how regulations shape corporate political activity. The legitimacy of corporate political tactics is frequently questioned, but the reality is the vast majority of these activities are legitimate, conducted in plain sight and constrained by regulation. Lobbying expenditures and CEO contributions, among other activities, follow statutory prescriptions. Despite existing oversight, however, calls for campaign finance reform and improved corporate disclosure of all political activities continue (e.g., Bebchuk and Jackson Jr 2012).Footnote 2 What is missing in the literature, and what we contribute, is an empirical analysis of the magnitudes of the potential spillover effects from selectively regulating specific corporate political activities. Rather than adopting a strict statutory interpretation on the supply of corporate political money, this paper focuses on how firms actually respond to the prevailing regulation along several observable and complementary margins. Even though companies adhere to the letter of the law, our results demonstrate distinct patterns that support a populist interpretation of corporate political involvement and emphasizes how many of these channels are connected, even as they are treated independently under US regulation. The papers closest to the present study are Tripathi et al. (2002) and Lake (2015). Exploiting the introduction of lobbying disclosure act Tripathi et al. establish that PAC contributions and lobbying expenditures are connected. Tripathi et al. claim that this link provides support for the “access theory” of corporate political engagement. Lake builds on the Tripathi et al. data, taking the analysis several steps further. He provides a novel decomposition linking the recorded issues in the lobbying disclosure database to PAC contributions. We extend this analysis in two important directions. First, we concentrate on rules governing corporate political involvement, especially the prospect for unintended consequences. We measure how these rules affect the structure of political activity as measured in dollars. As different agencies regulate the distinct activities, understanding the magnitudes of the prospective spillovers is important. Second, we use larger and more detailed datasets that allows us to concentrate on the contribution constraints (i.e., the neighborhood around the precise per cycle contribution limit). By focusing attention on this neighborhood around contribution thresholds, we are able to avoid many of the debates about the motivations for and theories of corporate contributions and lobbying. Of course, this theory-agnostic approach does have a cost: our results apply to the role of regulations on firm behavior and therefore are not tests of the underlying theories of firm political behavior. While we view this rule focused analysis as a benefit, we recognize that it leaves many questions about what firms are actually “buying” with their money unanswered. The motivations of firms’ political activities are clearly important, yet we view the implications of the regulations on corporate political activity as equally important. To evaluate the degree to which these spillovers arise, we exploit the relationship between statutory campaign contribution limits on firms’ PACs and alternative modes of political activity. Marrying information on corporate lobbying and campaign contributions, our data includes over 6.8M firm-candidate observations linked across nine election cycles. This enables us to exploit the institutional details of the United States’ campaign finance laws, isolate a firm’s marginal campaign contribution and employ rich time-varying fixed effects to control for an extensive assortment of unobserved factors. Further, in separate models we apply a regression discontinuity design. Specifically, we measure the response of CEO contributions and lobbying expenditures when a firm’s PAC makes the maximum allowable political contribution to a particular candidate relative to other candidates that receive below limit contributions from the same firm. Intuitively, it would appear that there is an obvious omitted variable in this analysis: firm political strategy. The benefit of having a large dataset and a clearly defined regulatory threshold is that we are able to avoid bias due to this omitted variable as long as two assumptions hold. First, in our models examining the relationship between CEO donations and her firm’s PAC contributions, we allow both candidate political views and overall firm strategy to vary over time. We assume, however, that firm-by-candidate-by-election cycle factors are orthogonal to CEO contributions. Stated differently, firms cannot strategically target specific election candidates within an election cycle in a manner that is positively correlated with CEO contributions. While we believe that this condition is broadly plausible, we take take an additional step in our robustness analysis: we embed the firm-cycle and candidate-cycle fixed effects models within a difference-in-difference specification where we examine the relationship between CEO and her PAC’s contributions before and after the Bipartisan Campaign Finance Act (BCRA) of 2002. Next, to avoid omitted variable problems for our lobbying models, we assume that in the absence of campaign finance regulation contributions would increase smoothly around the limiting threshold. In other words, without the FEC regulations, we would not expect to observe a large discrete jump in a firm’s lobbying expenditures as its PAC transitions from making, say, a $9900 donation compared with the limiting $10,000 donation. In the Online Appendix, this smoothness assumption is tested for alternative variables such as advertising, R&D and dividend expenditures, appearing to hold. As such, we view this assumption as reasonable. Finally, we probe the sensitivity of our models via several placebo tests. Overall, our main conclusion is that statutory limits on corporate PACs are effectively non-binding and that the spillovers can be economically meaningful. Even as advocates call for stricter regulation of corporate political activity in the aftermath of Citizen’s United and McCutcheon—two Supreme Court decisions that created new opportunities for corporate money in politics—they appear to under-emphasize an important point: many of the political activities in which companies engage are challenging to observe and hence difficult to regulate.Footnote 3 Documenting the unintended consequences of existing campaign finance regulation on observable activities, such as lobbying, therefore provides valuable perspective. This is especially true as we demonstrate that the spillovers from imperfect regulation can often be larger than the initial problem that the rules were attempting to remedy. Magnitudes become important especially if corporate political activity is increasingly hidden from view. If the spillover effects are large between lobbying and campaign contribution, they may be equally important along margins that are more difficult to control (e.g., independent expenditures). The remainder of the paper is laid out as follows. Section 2 presents the conceptual framework that we employ to econometrically identify firms’ responses to regulation. Our data are discussed in Sect. 3 and results are in Sect. 4. Section 5 concludes.",3
54.0,3.0,Journal of Regulatory Economics,16 November 2018,https://link.springer.com/article/10.1007/s11149-018-9371-0,Wholesale most-favored-nation clauses and price discrimination with negative consumption externalities: equivalence results,December 2018,Felipe Avilés-Lucero,Andre Boik,,Male,Male,Unknown,Male,"A wholesale most-favored-nation (MFN) clause in a contract is a promise made from an input seller to a buyer that the buyer will receive at least as favorable a price as any other buyer. While such clauses would appear to lead to lower prices and to increase total welfare, the existing literature studying the welfare effects of MFN clauses has demonstrated that welfare reducing outcomes may arise from a reduction in discounting. Concern over these potential welfare reducing effects has led to antitrust action against the use of wholesale MFN clauses and spurred recent scrutiny of MFN clauses (including a joint Department of Justice and Federal Trade Commission conference in 2012), and generated several research articles from leading economic and legal scholars. The same increased scrutiny has occurred in the European Union (see Vandenborre and Frese 2014; Gonzalez-Diax and Bennett 2015). The reason why wholesale MFN clauses may lead to outcomes that reduce total welfare is that once such clauses are in place, a seller may have reduced incentives to offer discounts to any particular buyer because that discount would have to be extended by the seller to all other buyers. In these contracts, the seller is usually a manufacturer or wholesaler and the buyer a small or “discount” retailer or reseller. Without an MFN in place, the seller may offer discounts to such resellers that the seller would not find profitable to offer its other resellers. With an MFN in place, however, discounts made to small resellers must be extended to other larger and more economically relevant resellers. A wholesale MFN may therefore cause a wholesaler to cease discounting and, if small resellers require discounting to remain viable, the MFN causes small resellers to be foreclosed and competition among resellers to be lessened. This story of anti-competitive harm has been articulated by former Deputy Assistant Attorney General for Economic Analysis Fiona Scott Morton, leading antitrust economists (Baker and Chevalier 2013; Salop and Scott Morton 2013) and legal scholars (Baker 1988; Goldberg and Greenberg 1995) and we do not dispute it. Rather, we take a different approach to tackling the welfare effects of this vertical contract that is grounded in the original literature studying third degree price discrimination in final goods markets (Robinson 1933; Schmalensee 1981; Varian 1985). We show that by adding consumption externalities to this entirely “horizontal” framework we are able to assess the welfare effects of wholesale MFNs in a different way that generates new insights into the welfare effects of MFNs that complement those from the existing vertical literature (Katz 1987; O’Brien and Shaffer 1992; McAfee and Schwartz 1994). We prove that this approach is valid by demonstrating the equivalence of the welfare effects of MFNs in our horizontal final goods environment with consumption externalities to those in a standard vertical industrial organization treatment of wholesale MFNs. While it might seem natural that there ought to be such an equivalence since widespread use of wholesale MFNs amounts to a de facto ban on third degree price discrimination, we show that the only equivalence between the two environments is in the change in total welfare arising from a wholesale MFN: there is no equivalence in levels of welfare or in the distribution of that welfare between consumers and firms. The reason is that compared to our final goods environment with consumption externalities, the standard vertical environment has an additional layer of economic agents (“resellers”), and the ban on price discrimination induced by the use of widespread MFNs must arise endogenously since unlike in the final goods environment where uniform pricing is assumed to arise exogenously, buyers in the vertical environment must agree to the wholesale MFNs. Moreover, the nature of consumption externalities in the two environments are different. While consumption generating negative externalities is similar to firms generating negative externalities among themselves through production (by capturing sales from rivals), the nature of those two types of externalities in terms of how they affect welfare is quite different. Consumption externalities (eg. traffic congestion caused by driving or second hand smoke) reduce total welfare, but production externalities across firms is simply competition and raises for total welfare. Our equivalence result is as follows: the change in total welfare from the use of wholesale MFNs in a vertical environment with an input seller, resellers, and final consumers and where MFNs must be implemented endogenously is identical to the change in welfare from an exogenous ban on uniform pricing in a market with only an input seller and final consumers, but non-negligible consumption externalities. We show this result to be useful because it suggests that the standard, well known intuition about price discrimination and uniform pricing from the final goods literature carries over to wholesale MFNs even though the environments are quite different. Our approach also offers a different form of intuition for assessing wholesale MFNs: while the vertical framework would refer to the undesirable outcome of wholesale MFNs as foreclosure or raised costs of small resellers, the final goods price discrimination literature would refer to this as “low types no longer being served”. Since there is a welfare equivalence between the two environments, it must therefore be that endogenously adopted wholesale MFNs can raise welfare since we know that exogenously imposed uniform pricing can raise welfare in final goods markets. While this may not be surprising, we provide several examples in the paper where courts have issued conflicting judgments regarding wholesale MFNs. For example, in the health care industry the use of wholesale MFNs have regularly been struck down while in cable television mergers, the Department of Justice has often insisted on the addition of wholesale MFNs as a merger remedy. While we argue the equivalence result is not obvious ex-ante, we are nevertheless able to use the equivalence result to push forward and generate novel results regarding the welfare effects of wholesale MFNs that are particularly applicable to an antitrust setting. Antitrust courts are typically interested in ex-post analysis given some facts about prior conduct, in contrast to other policy settings where the interest is in making a prediction about the effect of a policy on future conduct. We study whether antitrust authorities or courts should be more or less cautious when assessing the welfare effects of wholesale MFNs knowing that they were endogenously adopted. In other words, given firms endogenously adopted MFNs, should we expect a selection effect that should adjust our prior about whether those MFNs are especially pro-competitive or anti-competitive? We show that there is no selection effect: that the large reseller advocated for the MFN and the input supplier agreed to it does not provide useful information about whether the MFN was pro-competitive or anti-competitive. Secondly, what observed conduct can be determined ex-post to have lowered total welfare? We examine what facts surrounding firm conduct can be used ex-post to inform whether a wholesale MFN that has already implemented has harmed welfare; to our knowledge, we are the first to examine this question and we are able to address it directly by leveraging our equivalence result. We show that whether the small reseller exited after imposition of the wholesale MFN is sufficient to determine whether the wholesale MFN decreased welfare. It also implies that wholesale MFNs might be used by large incumbent resellers to prevent entry in the first place. Of course, a causal link between exit and the enforcement of the wholesale MFN must be demonstrated since in practice there are other factors that might have caused the small reseller to exit. As for whether the wholesale MFN is preventing entry in the first place would also be difficult to establish since it would involve demonstrating that there was a potential entrant who would have entered but for the wholesale MFN. The paper is organized as follows. Section 2 summarizes the literature examining the competitive and welfare consequences of wholesale MFNs and draws parallels with the literature on consumer-facing price discrimination with negative consumption externalities, Sect. 3 presents a standard model of price discrimination with negative consumption externalities, a vertical industrial organization model of wholesale MFNs, and establishes the equivalence result. Section 4 discusses leverages the equivalence result to generate novel results regarding the welfare effects of wholesale MFNs, and in particular how to assess their welfare consequences ex-post.",1
54.0,3.0,Journal of Regulatory Economics,21 November 2018,https://link.springer.com/article/10.1007/s11149-018-9372-z,Information and transparency in wholesale electricity markets: evidence from Alberta,December 2018,David P. Brown,Andrew Eckert,James Lin,Male,Male,Male,Male,"A fundamental question in competition and regulatory policy is the effect of information and data transparency on competitive behaviour and market outcomes. Two general and opposing views suggest that market transparency either enhances competition by promoting consumer search and allowing firms to respond efficiently to market events or facilitates coordination by enhancing communication and allows firms to monitor rivals.Footnote 1 The role of information is particularly important in restructured electricity markets. On one hand, these markets face substantial uncertainty due to unexpected unit outages, intermittent supply from renewables, and demand uncertainty. On the other hand, firms interact repeatedly in often concentrated markets, raising concerns over firms’ abilities to utilize information to elevate prices. An important component in the anti-competitive concerns of market transparency is firms’ abilities to identify rival behavior from market outcomes. Regulators can de-identify data to limit firms’ abilities to monitor rival behavior. However, sophisticated firms may be able to identify rivals’ actions from anonymized data or undertake actions to reveal their identities. In this paper, we utilize a recent case in Alberta’s electricity market to investigate whether firms are able to identify rival behavior from de-identified data and if so, we evaluate if firms act on this information. We add to the limited evidence regarding the effects of information disclosure on bidding behavior in electricity markets by examining the case of Alberta’s wholesale electricity market. Alberta’s electricity market is “energy only”, meaning that firms only earn revenues from electricity sold; as a result, the unilateral exercise of market power is expressly permitted.Footnote 2 In this market, firms submit hourly offer curves made up of price-quantity pairs that reflect the price at which they are willing to supply a specified quantity of electricity. Firms can adjust their offers up to 2 h in advance of the market clearing, allowing them to respond quickly to the disclosure of new information. Until recently, at the end of each hour a list of all offers were released publicly in a report known as the Historical Trading Report (HTR). The identity of the firms and assets were removed in the HTR. In August 2013, Alberta’s Market Surveillance Administrator (MSA) issued a report alleging that “the participating oligopolists have used offer information made available through the Historical Trading Report in near real-time to achieve sharply higher wholesale market prices...”(MSA 2013, p.iii). The MSA supported this conclusion with examples of ten days between August 2011 and April 2013, in which they argued that firms were using the HTR to coordinate. These examples involved claims that firms were “tagging” offers on these days, by bidding using particular patterns (not documented by the MSA) that revealed their identities through the HTR and could be used to send signals to rivals. Following this report and a subsequent hearing, in May 2017 the Alberta Utilities Commission (AUC) ordered that the HTR no longer be published (AUC 2017b). Our paper proceeds in the following stages. First, we document patterns observed in wholesale electricity offer prices and quantities by individual firms that may have revealed their identities to rivals. We investigate to what extent these offer patterns allow firms to identify particular rivals’ bids. More specifically, does a careful examination of the data support the allegation that “tagging” can potentially allow rivals to identify a firm’s bids from the HTR? Second, we establish econometric models to investigate whether firms utilize information provided in the HTR when submitting their price-quantity offers. In these analyses, we allow firms to respond differently to different rivals; this provides insights into whether firms are able to identify a particular rival’s offer behavior through information disclosed in the de-identified HTR.Footnote 3
 We demonstrate that firms are often able to identify, with a high degree of accuracy, the offers of specific rivals in the HTR by the offer patterns adopted by those firms. We also demonstrate that for one firm its unique offer pattern ended abruptly upon the announcement of the MSA’s concerns, and that for another firm there is a strong relationship between the incidence of its unique offer pattern and the price level of its offers. Our econometric results provide evidence suggesting that two large firms respond to information disclosed in the HTR when they submit their price-quantity offers. In particular, for one of these firms, there is evidence it responds differently to changes in offer behavior of particular rivals disclosed in the de-identified HTR. Our findings have implications for regulatory policies regarding information disclosure in electricity markets. While increased transparency and disclosure can assist firms in forming expectations regarding prices, the evidence that firms set offer prices in a way that allowed identities to be revealed, and that rivals responded to that information, suggests a cautious approach to information disclosure. This may be achieved, for example, through the release of near real-time offer information in a aggregated form, such as in price bands as initially proposed by the MSA. This paper will proceed as follows. Section 2 discusses the related literature. Section 3 provides an overview of Alberta’s electricity market and the allegations of the MSA. The data used in our analysis are described in Sect. 4. In Sect. 5, we consider the MSA’s (2013) claim that firms “tag” offers and whether this conduct allows firms to accurately identify the firms submitting particular offers. Section 6 details our econometric methodology used to evaluate whether and how information disclosed through the HTR impacts firms’ offer behavior. Results are presented in Sect. 7. Brown et al. (2018) provide supplementary results. Section 8 concludes.",11
55.0,1.0,Journal of Regulatory Economics,14 February 2019,https://link.springer.com/article/10.1007/s11149-019-09374-z,Regulated versus negotiated access pricing in vertically separated railway systems,February 2019,David Besanko,Shana Cui,,Male,Female,Unknown,Mix,,
55.0,1.0,Journal of Regulatory Economics,06 February 2019,https://link.springer.com/article/10.1007/s11149-019-09376-x,Consumer surplus bias and the welfare effects of price discrimination,February 2019,Francisco Galera,Pedro Garcia-del-Barrio,Pedro Mendi,Male,Male,Male,Male,"A central question in Economics is the welfare consequences of government intervention. In fact, competition authorities and regulators are typically concerned about the welfare of consumers and of society as a whole. This calls for the need of a measure of welfare that may be used to evaluate whether or not society is better off after a given policy is adopted. According to Economic Theory, consumer surplus is an accurate measure of welfare, as it reflects consumers’ willingness-to-pay. However, the validity of this measurement, especially when dealing with aggregate consumer surplus, relies on the assumption of a constant utility of income, typically associated with the assumption of quasilinear preferences. This consideration may have important effects on the evaluation of government policies. Since standard welfare calculations that rely on the concept of consumer surplus may be giving a greater weight to individuals or markets where income levels are higher, these calculations may be distorted, potentially leading to incorrect conclusions. This is precisely the issue that we address in this paper, for the specific case of third-degree price discrimination. Specifically, a well-known result in the literature (Schmalensee 1981; Varian 1985) is that—assuming quasilinear preferences, and therefore a constant marginal utility of income—an output increase is a necessary condition for welfare to increase with price discrimination. Theorists and policy-makers have taken the implications of this result as generally valid for market regulation, which has led to the widespread view that banning price discrimination is desirable unless total output increases with discrimination. For instance, in a recent background note by the OECD’s Directorate for Financial and Enterprise Affairs (OECD 2016), it is argued that “one clear test for identifying the impact of discrimination on consumers is to ask whether the discrimination significantly increases output or not.” In contrast, we propose a theoretical model to show that this result may fail to hold if the marginal utility of income is not constant: consumers may be strictly better off with price discrimination even if output remains constant when the monopolist is allowed to price discriminate. In order for this result to arise, we need to use a utility function where the marginal utility of income is not constant. Our choice of the particular utility function that we use in our model was driven by its simplicity. Given that discrimination never reduces the profits of the producer, we focus on consumer surplus to evaluate whether social welfare increases. We argue that since a greater willingness-to-pay may stem from having higher income rather than a greater utility of consumption, if the marginal utility of income is not constant across consumers then consumer surplus may be a biased measure of how well off consumers in a particular market are. The welfare effects of price discrimination by a monopolist have long been the object of study in the Industrial Organization literature. An early formalization of the argument was included in Schmalensee (1981), who concluded that output increase is a necessary condition for third-degree price discrimination to enhance social welfare, defined as the addition of consumer and producer surplus. Even if the condition was initially established only for the case of independent demands and constant marginal costs, its validity was soon generalized. Building upon quasilinear utility functions, Varian (1985) extended this conclusion also to the case of increasing marginal costs. However, recent contributions have explored the limitations of this result, showing for instance that this proposition cannot be generalized to an oligopoly with asymmetric costs (Galera and Zaratiegui 2006), with convex costs in the presence of demand uncertainty (Galera et al. 2014), externalities (Adachi 2005), quality differences (Galera et al. 2017a), or seasonal demands (Galera et al. 2017b). In all these cases, price discrimination can be welfare-increasing even if output does not increase. In this paper we study the robustness of the fundamental result in Schmalensee (1981) and Varian (1985) if we abandon the usual assumption of quasilinear utility functions. In fact, the use of quasilinear utility functions is the standard procedure for aggregating satisfaction levels of individuals. It is argued in Varian (1985) that “for this class of preferences (...) not only does consumer’s surplus serve as a legitimate measure of individual welfare, but also that the individual consumers’ utility functions can be added up to form a social utility function, so that aggregate consumers’ surplus is also meaningful.” However this approach may bias the welfare calculations. Our main point is therefore that the use of quasilinear utility functions may be analytically convenient, but this modeling assumption necessarily constrains the scope of the analysis and its conclusions to the case of constant marginal utility of income. The concern regarding this issue is not precisely new. Over a century ago, Wright (1917) argued that “in the case of a community whose members differ widely with respect to money income, the demand curve and the price no longer even approximately represent conditions of utility. The utility to the first purchaser, a millionaire, may be low, while the utility to the marginal purchaser, a worker in a sweat-shop, may be very high. The millionaire takes the first unit not because its utility to him is higher than to the worker but because the sacrifice involved in purchasing it is very much less”. This argument, as Wright explicitly mentions, is inspired in Marshall (1890): “A pound’s worth of satisfaction to an ordinary poor man is a much greater thing than a pound’s worth of satisfaction for an ordinary rich man”. Two different problems must be distinguished when using consumer surplus as a measure of consumer satisfaction. The first one refers to the existence of income effects, which makes it difficult to accurately define the consumer surplus. Willig (1976) manages to (partially) solve the problem by approximation: given that income effects are usually small, he claims that the consumer surplus is a good proxy measure of welfare anyway. But we disclose here a different aspect, which arises when comparing utility levels across individuals. For this comparison to be properly done, the marginal utility of money ought to be similar for all the consumers; but this will hardly be the case, as income levels differs substantially across individuals.Footnote 1 Yet, the limitations associated with the consumer surplus to evaluate welfare in real markets, which used to be widely acknowledged a few decades ago, have progressively been forgotten, due presumably to the technical advantages of this tool. Moreover, its validity for economic analysis and policy decision making has generally been taken for granted, as in, for instance, Willig (1976), Pindyck and Rubinfeld (2012), Mankiw (2014). Therefore, we contribute to the literature in two ways. First, we highlight the risk of misunderstanding the scope of Varian (1985), whose findings we claim to depend critically on the assumption of quasilinear utility functions. We then examine the extent to which the current consensus—concerning the requirement that increasing social welfare is not possible unless output increases—can be legitimate in practice. Furthermore, we show that welfare enhancing policies can result from adopting third-degree price discrimination, even if total output does not increase. In line with this conclusion, further research is needed to establish the conditions under which preventing price discrimination may be harmful to society. Second, and more importantly, our paper challenges the validity of the consumer surplus as a definitive way to evaluate welfare. The remainder of the paper is organized as follows. Section 2 introduces the theoretical model that will be used to derive the main result of the paper. Section 3 discusses this result and proposes an alternative interpretation of the model. Finally, Sect. 4 offers some concluding comments.",5
55.0,1.0,Journal of Regulatory Economics,14 February 2019,https://link.springer.com/article/10.1007/s11149-019-09377-w,"Regulations, institutional quality and entrepreneurship",February 2019,Dustin Chambers,Jonathan Munemo,,Male,Male,Unknown,Male,"New business creation is a prominent feature of the entrepreneurial process, and many studies have demonstrated the positive effects of new business creation on growth and development. As noted by Klapper et al. (2006) and Djankov et al. (2002), newly established firms tend to be more efficient, and the competitive pressure that they exert on other firms enhances overall productivity and economic growth. Recently, Aghion (2017) has pointed out that growth is generated by innovations resulting from entrepreneurial investments. Earlier studies, including those by Aghion et al. (2009), Black and Strahan (2002), and Hause and Du Rietz (1984), have also shown that entrepreneurship has a positive impact on economic growth. Additionally, some studies demonstrate that startups and young businesses contribute much more to job creation than more mature firms (Ayyagari et al. 2011; Haltiwanger et al. 2010). From a development perspective, the ability of a country’s business environment to foster new enterprises is therefore important. In this paper, we analyze how entrepreneurship is influenced by two specific aspects of the business environment, namely business entry regulations (i.e., official regulations that affect a new domestically owned, limited liability business), and the quality of a nation’s institutions. To our knowledge, this the first paper to jointly empirically estimate the impact of entry regulations and institutional quality on entrepreneurship. In the literature analyzing the effects of entry regulations on entrepreneurship, entrepreneurship is often measured by the rate of self-employment, the rate of business ownership, and by the rate of new startups (see Naudé 2010; Desai 2009). Following Klapper and Love (2011), we use a World Bank measure of entrepreneurship called entry density, which is defined as the number of newly registered limited liability companies (LLCs) per 1000 people of working-age. This measure is appealing because it captures a key aspect of entrepreneurship (new business creation) and because panel data on this measure have been collected by the World Bank for a very large sample of countries. Also, it is not static or dependent on the level of development like other measures of entrepreneurship based on self-employment. In addition, it overcomes the potential problem of overstating the rate of entrepreneurship that is associated with Global Entrepreneurship Monitor (GEM) measures of entrepreneurship by excluding firms that reregister. To measure entry regulations, we utilize a variable from the World Bank’s Doing Business database which reports the legally required procedures an entrepreneur must complete (e.g., approvals, licenses, permits, etc.) to open and operate a limited liability firm (henceforth referred to as “startup procedures”). This measure, which is based on the methodology of Djankov et al. (2002), only includes procedures if they require “the entrepreneur to interact with outside entities: state and local government offices, lawyers, auditors, company seal manufacturers, notaries, etc.” (pg. 8). As such, a one-step increase in the number of startup procedures represents a non-trivial burden to would-be entrepreneurs. A panel dataset of 119 countries spanning the period 2001–2012 is used to empirically analyze the effects of business entry regulations and institutional quality on new firm creation. We estimate cross-section and panel regressions and control for other important factors that influence new firm formation. Our results clearly demonstrate that a nation’s regulatory and institutional environment play a crucial role in determining the level of entrepreneurship. Specifically, we find robust evidence that new firm creation is significantly lower in countries with greater entry regulations. Specifically, increasing startup procedures by one step is associated with an approximate 3–7% decline in new business activity, which is consistent with the findings of Djankov et al. (2010), who finds that a one-step increase in startup procedures is associated with a 5.3% decline in overall LLC density.Footnote 1 Therefore, stricter regulation of entry is associated with less efficient market outcomes as exemplified by a reduction in entrepreneurship. The importance of the number of startup procedures as a measure of entry regulation is also supported by data from the Doing Business project (http://www.doingbusiness.org), which reports that in 2016, local entrepreneurs in 115 economies spent numerous days satisfying bureaucratic procedures to start a business. Had these business owners been allowed to follow a simplified registration process, they could have instead spent this valuable time focusing on firm growth, boosting productivity, and innovative activities. Moreover, studies have found that regulatory reforms that make it easier to start a business tend to be associated with an increase in new business formation in the formal sector, higher employment, productivity growth, as well as improvement in other social and economic outcomes. For example, greater business formalization expands the tax base, giving the government more resources to spend on important social and economic initiatives. On the other hand, excessive startup regulations are associated with negative outcomes such as greater informality and higher corruption (Audretsch et al. 2006; Klapper et al. 2009; Klapper and Love 2011; Motta et al. 2010). Entrepreneurship is also significantly harmed by a lack of high-quality institutions. This conclusion is obtained by using a comprehensive indicator of institutions, which is measured along six dimensions of governance quality: voice and accountability, political stability and the absence of violence, government effectiveness, regulatory quality, rule of law, and the control of corruption. Three of these measures are shown to be especially important for promoting entrepreneurship —political stability, regulatory quality, and voice and accountability. Overall, a one standard deviation increase in the average of all six measures (i.e., the governance variable) is assocated with a 34% boost in new business activity. As observed by Baumol (1990), Nyström (2008), and Boettke and Coyne (2009), the type of entrepreneurial activity observed can be explained by the payoffs established by the institutional context. Superior quality institutions reward productive entrepreneurship and reduce incentives for rent-seeking behavior, thus diverting resources toward more productive activities, and thereby crowding-in entrepreneurship. The results of this study contribute to a growing strand of the literature in which entry deregulation is generally associated with superior economic outcomes such as higher per capita income, reduction in the size of the unofficial economy, less corruption, and improvement in productivity (see Xu 2011; Freund and Bolaky 2008; Djankov et al. 2002; World Bank 2003). The remainder of this paper proceeds as follows. In Sect. 2, we review related empirical literature. Section 3 provides the empirical framework, beginning with descriptions of the data used to measure entrepreneurship, business startup regulations, institutional quality, and control variables. This is followed by a discussion of country selection, descriptive measures, and our empirical model. Our main empirical findings, as well as robustness tests, are presented and discussed in Sect. 4. Finally, Sect. 5 summarizes the main findings and implications of the paper.",40
55.0,1.0,Journal of Regulatory Economics,08 January 2019,https://link.springer.com/article/10.1007/s11149-018-09373-6,The single supervision mechanism and contagion between bank and sovereign risk,February 2019,María Cantero Sáiz,Sergio Sanfilippo Azofra,Begoña Torre Olmo,,Male,Female,Mix,,
55.0,2.0,Journal of Regulatory Economics,30 March 2019,https://link.springer.com/article/10.1007/s11149-019-09381-0,Promoting competition and protecting customers? Regulation of the GB retail energy market 2008–2016,April 2019,Stephen Littlechild,,,Male,Unknown,Unknown,Male,"By 1999, the electricity and natural gas sector in Great Britain was open to retail competition, including to all residential customers. Over the next decade, the energy regulator Ofgem (Office of Gas and Electricity Markets) removed an initial transitional price cap, addressed a variety of concerns, and reported positively on the evolution of competition. Then in 2008 Ofgem began a series of regulatory interventions—notably a non-discrimination condition and then imposing a restriction to four “simple tariffs”—that reversed its previous policy of minimal intervention in the market. In 2014 Ofgem referred the energy market for investigation by the Competition and Markets Authority (CMA). In its 2016 Final Report the CMA criticised Ofgem’s two regulatory interventions but made recommendations for different interventions. There was a demand for more substantial action. In 2018 an Act of Parliament required Ofgem to introduce a widespread residential energy tariff cap. Retail energy policy has thus reversed. Britain is not alone here. Other jurisdictions including Australia, New Zealand and New York are also taking or contemplating potentially radical interventions. The opening of regulated monopoly markets to competition spurred numerous theoretical analyses of price discrimination, including in markets with switching costs. For early contributions see (e.g.) Borenstein (1985), Klemperer (1987a, b, 1995), Brennan (1990, 2007), Armstrong and Vickers (1993), Borts (1998). There has been increasing study of competitive retail energy markets and their successes and limitations, both in GB e.g. Green and McDaniel (1998), Otero and Waddams Price (2001), Littlechild (2002), Giulietti et al. (2005), Hviid and Price (2012), Waddams Price and Zhu (2016), and elsewhere e.g. Joskow (2005), Littlechild (2006), Simshauser (2018), Simshauser and Whish-Wilson (2017). Some papers have focused on customers’ limitations e.g. Wilson and Waddams Price (2010), Kleit et al. (2012), Giulietti et al. (2014), Hortascu et al. (2017). Others have explored regulatory policy e.g. Joskow (2000), Littlechild (2003, 2014a, 2016, 2018b), Waddams Price (2018). The present paper focuses on retail regulatory policy in Britain, and more precisely the changes and reasons for changes over the second decade compared to the first. The main body of the paper summarises Ofgem’s regulatory interventions after 2008 and the debates about them. Many regulatory economists including myself felt strongly about these policies. The paper draws upon their responses to Ofgem and CMA consultations. The paper conjectures possible factors that might have led Ofgem to change its previous policy. Finally, it examines what the CMA had to say about these interventions and about the regulatory framework that led to what the CMA considered were inappropriate interventions.",14
55.0,2.0,Journal of Regulatory Economics,12 March 2019,https://link.springer.com/article/10.1007/s11149-019-09380-1,Net neutrality and asymmetric platform competition,April 2019,Marc Bourreau,Romain Lestage,,Male,Male,Unknown,Male,"The Internet can be described as a platform that connects end users and Content Providers (CPs). The de facto rule that Internet Service Providers (ISPs) cannot discriminate between the information packets sent by CPs has long prevailed. This rule implies in particular that CPs pay the ISP that hosts their servers, but not the other ISPs carrying their traffic (“zero-pricing rule”), that CPs are all offered the same quality of service (“no-discrimination”), and that ISPs cannot prioritize certain types of traffic (“no-prioritization”). Recently, some ISPs have strayed from these so-called “net neutrality” rules on the grounds that CPs should contribute to the network investment costs incurred to cope with the dramatic increase in Internet traffic. In November 2015, the European Union adopted a basic framework for preserving net neutrality, whereas, in the US, the Federal Communications Commission’s net neutrality rules, which had been put in place in February 2015, were repealed in June 2018. There are still heated debates on both sides of the Atlantic on whether net neutrality rules should be imposed to ISPs. The debates on net neutrality revolve around two main issues: whether a deviation from net neutrality would improve or harm welfare, and whether specific regulations are necessary to keep the Internet neutral. The recent academic literature has addressed the former issue by studying the impact on welfare of various deviations from net neutrality, such as the introduction of termination fees, discrimination between CPs, and prioritization of traffic. Although the literature has analyzed the ISPs’ incentives to deviate from net neutrality, the issue of the regulatory measures that would ensure that the Internet remains neutral has received less attention. One such regulatory instrument is access regulation. In most countries, competition between ISPs is asymmetric: some, vertically-integrated, ISPs own local broadband network infrastructures, and are required to provide access to their infrastructures to non-integrated ISPs on regulated terms. For example, in Europe, access to the “old” (copper-based) as well as the “new” (next-generation access) local networks is regulated.Footnote 1 It has often been argued by policy makers on both sides of the Atlantic that competition among ISPs, which access regulation is meant to promote, contributes to reduce their incentives to deviate from net neutrality (see, for example, Greenstein et al. 2016 for a discussion). This is the key motivation of the Federal Communications Commission’s Internet Freedom transparency rule, which requires ISPs to publicly disclose their network management practices, such as affiliated or paid prioritization, blocking, throttling, and congestion management in order to discourage harmful deviations from net neutrality (Declaration of the Federal Communications Commission, In the Matter of Restoring Internet Freedom, January 4th, 2018). Although transparency and competition may indeed discourage deviations from net neutrality that directly harm Internet users, the argument does not apply to every deviation from net neutrality. For example, Internet users would probably hardly be concerned by deviations from the zero-pricing rule, as long as they do not result in Internet fragmentation. They may even welcome some forms of discrimination towards CPs, such as sponsored data. Besides, in the case of the various fees CPs may be charged by ISPs, basic principles of pricing in two-sided markets suggest that stronger competition for Internet users may raise ISPs’ incentives to shift revenue extraction to the content side, and therefore to charge higher (termination) fees to CPs. Our objective in this paper is thus to investigate whether pro-competitive access regulation can be an effective instrument to keep the Internet neutral, focusing on a specific aspect of net neutrality, the zero-pricing rule. We consider a setting where a vertically-integrated ISP gives access to its local network infrastructure to a non-integrated ISP, and the access price is set by a welfare-maximizing regulator. Both ISPs are platforms that put together Internet users and CPs. Each ISP charges a subscription fee to its end users, and may also charge a termination fee to CPs. We adopt the competitive bottleneck setting introduced by Armstrong (2006) and consider that Internet users single-home, that is, subscribe to a single ISP, whereas CPs multi-home, that is, make their content available at either or both ISPs. CPs are heterogeneous in the fixed cost they incur to deliver their content on the Web. We interpret a positive termination fee as a departure from net neutrality (i.e., from the zero-pricing rule). We then study whether tight access regulation helps keeping the Internet neutral, by analyzing the relationship between the regulated access price and unregulated termination fees. We start by studying a benchmark where the regulator sets both the access price and the termination fees to maximize welfare. In this benchmark, we show that the social optimum is achieved when the access price is cost-based and the termination fees are equal to zero (i.e., the zero-pricing rule is enforced). We then consider the case where the termination fees are left to the market. First, we show that the effect of the access price on the (unregulated) termination fees differ between the two ISPs. Whereas the termination fee of the integrated ISP always decreases with the access price, the termination fee of the non-integrated ISP can either increase or decrease with it. The intuition is as follows: an increase of the access price lowers the demand for the ISPs on their two sides, and the ISPs tend to react by reducing their termination fees for CPs. Because it earns access revenues from the non-integrated ISP, the integrated ISP has higher incentives than its non-integrated rival to increase the number of CPs via a lower termination fee, in order to expand the demand for Internet access. A consequence of this difference in pricing incentives is that in equilibrium the termination fee of the integrated ISP is strictly lower than the termination fee of the non-integrated ISP, unless the access price is cost-based. Therefore, when termination fees are unregulated, a necessary condition for the zero-pricing rule to apply is that the access price is cost-based. However, we also show that a low access price leads to high termination fees. Indeed, there is negative relationship (“waterbed effect”) between the access price and the total termination fee paid by the CPs. From a welfare point of view, this implies that the regulator faces a trade-off between setting a low access price to obtain low prices for Internet access and setting a high access price to induce low termination fees and hence foster entry of CPs. In some cases, it may then be socially optimal to set the access price above marginal cost. We show that a necessary condition for the socially-optimal access price to be above cost is that the number of Internet users or the number of CPs increases with the access price, which may happen if indirect network effects are strong enough. We also provide a numerical example when the socially-optimal access price is indeed above cost. Finally, we study an extension of the baseline model, where CPs can decide to single-home. By decreasing its termination fee, an ISP can then attract a larger number of CPs than the rival ISP, making its service also more attractive to consumers, and leading to Internet fragmentation. The main results of the baseline model remain valid: we show that there exists a range of parameter values for which a higher access price reduces the termination fees and where the socially-optimal access price is above the marginal cost of access. Our paper belongs to the literature on net neutrality (see Krämer et al. 2013; Greenstein et al. 2016 for reviews). The literature has studied how net neutrality (or the absence of it) affects ISPs’ pricing (Economides and Tåg 2012) and screening (Jullien and Sand-Zantman 2018) strategies, network congestion (Choi and Kim 2010; Economides and Hermalin 2012; Choi et al. 2015; Peitz and Schuett 2016), investment by ISPs and/or innovation by CPs (Krämer and Wiewiorra 2012; Bourreau et al. 2015; Reggiani and Valletti 2016), the linking strategies of CPs (Calzada and Tselekounis 2018), the risk of Internet fragmentation (D’Annunzio and Russo 2015; Kourandi et al. 2015), or exclusion of competing ISPs (Broos and Gautier 2017).Footnote 2 Our contribution to this strand of literature is twofold. First, whereas the literature analyzes situations with a monopolistic ISP or symmetric competing ISPs, we consider a market with two asymmetric ISPs.Footnote 3 As we already explained, this is very relevant since in most countries, some ISPs are access providers and others access seekers. We then analyze how this asymmetry, which is due to the access price, affects ISPs’ incentives to charge termination fees to CPs. We show that the access price plays an important role, due a “waterbed effect” between the access price and the termination fees. Second, we determine whether more intense competition between ISPs, via a lower access price, reduces the ISPs’ incentives to deviate from net neutrality. Whether introducing more competition will eliminate the need for net neutrality regulation was briefly discussed by Gans (2015). Nevertheless, as Greenstein et al. (2016) note, it remains “an open question” in the literature. We fill this gap by considering that “more competition” is obtained through a lower access price set by the regulator. Our paper is also related to the literature on access regulation in network industries. The literature has analyzed optimal access rules (see, e.g., Vogelsang 2003), the effect of access prices on the build-or-buy decisions of entrants (Sappington 2005; Gayle and Weisman 2007; Mandy 2009; Avenali et al. 2010), or the impact of access regulation on investments in new infrastructures (Briglauer et al. 2015b). We highlight an effect of access prices that has been overlooked by the literature: access prices can influence the incentives of network operators to deviate from net neutrality by charging termination fees to content providers. The remainder of the paper is organized as follows. We introduce the model in Sect. 2. In Sect. 3, we derive the equilibrium in the market for Internet access. In Sect. 4, we examine the benchmark case where both the termination fees and the access price to the integrated ISP’s infrastructure are regulated. In Sect. 5, we study the relation between a regulated access price and unregulated termination fees. In Sect. 6, we study an extension of the main model where CPs can single-home and Internet fragmentation can arise. Finally, in Sect. 7 we conclude.",5
55.0,2.0,Journal of Regulatory Economics,08 February 2019,https://link.springer.com/article/10.1007/s11149-019-09375-y,Entrepreneurial response to interstate regulatory competition: evidence from a behavioral discrete choice experiment,April 2019,Trey Malone,Antonios M. Koumpias,Per L. Bylund,Male,Male,Male,Male,"Economists have long known that heavy regulatory burdens distort business decision-making (Stigler 1971) as the total consequences of legislation (such as taxation, occupational licensing, and new business regulation) were acknowledged as early as Bastiat (1848, pp. 6)Footnote 1: In the economic sphere an act, a habit, an institution, a law produces not only one effect, but a series of effects. Of these effects, the first alone is immediate; it appears simultaneously with its cause; it is seen. The other effects emerge only subsequently; they are not seen; we are fortunate if we foresee them. 
This is an important matter because of the fierce subnational fiscal competition to attract new firms (Agrawal et al. 2015).Footnote 2 Interstate regulatory competition has the potential to lead to undesirable outcomes (Partridge and Olfert 2011), making it of seminal importance for state governments to understand how entrepreneurs decide between two competing locations. As states compete to induce new businesses to locate in their jurisdiction, fiscal gains from new business formation may be mitigated by generous tax breaks and non-tax incentives offered. In some cases, employers with high bargaining power such as Amazon can secure deals that may largely wipe the net fiscal gains from new business formation.Footnote 3 Many studies have evaluated the influence of government regulations on economic decision-making (Carruthers and Lamoreaux 2016). For example, Aidis et al. (2012) use the Global Entrepreneurship Monitor to display a robust negative association between entrepreneurial entry through the creation of new business start-ups, and the size of the government sector across 47 countries. Furthermore, Sobel et al. (2007) find that politically granted protectionist policies stifle entrepreneurship in developed economies. Using a cross-section of OECD countries, they estimate a negative and significant effect of increased administrative burden for start-ups on productive, market, and non-political entrepreneurship. Similarly, Klapper et al. (2006) identify the role of European market entry regulations in slowing the creation of new limited-liability firms, causing start-ups to be larger when young and to grow more slowly over time. Da Rin et al. (2011) use a panel of 17 European countries from 1997 through 2004 to find a significant negative and concave effect of corporate income taxation on firm entry rates. Bruce and Mohsin (2006) show that the federal top corporate income tax rate and payroll tax rate have a large negative effect on entrepreneurship and self-employment rates. Bailey and Thomas (2017) combine data from the Statistics of US Businesses and RegData, an index that measures the intensity of regulation in 215 separate industries in the US, to find that fewer new firms were created in relatively more regulated industries from 1998 to 2011. Despite this research, the extant literature on the relationship between regulation and entrepreneurship has been limited by the availability of data. Data constraints make observing the total effect of regulations difficult to uncover. Prior research on the impact of the regulatory burden on business location choice has typically employed readily available secondary data such as surveys or administrative data, which are limiting in their ability to observe people who choose not to start a business; thus, suffering from a form of survivorship bias in entrepreneurship (Cassar 2004). As a result, studies have struggled to accurately identify the characteristics of the entrepreneurs who decided against starting a business. Therefore, prior estimates in the empirical literature might be understating the effect of taxation and regulation on entrepreneurship by solely relying on successful business formation. Furthermore, rather than being able to estimate utility functions and make predictions soundly rooted in economic demand theory, most studies of entrepreneurial decision-making have been constrained to drawing inferences about entrepreneurial decision-making without directly observing the choice to start a business. As such, this article utilizes a novel technique to assess how state regulation such as licensing requirements, business registration processing times, and corporate tax rates influence whether and where new businesses choose to locate. Initially, we implement a discrete choice experiment (DCE) that elicits entrepreneurs’ preferences over new business formation in response to changes in the state regulatory and tax burden).Footnote 4 Stated simply, the DCE is a method firmly rooted in random utility theory that allows researchers to test hypotheses against demand theory while avoiding common econometric issues such as endogeneity and confounded variables (Hensher et al. 2015). Using a “branded” orthogonal fractional factorial experimental design, we consider two localities separated by a state border as potential new business formation locations; namely, Kansas City, Missouri (KCMO), and Kansas City, Kansas (KCKS) as well as the option of no new business formation anywhere. The DCE allows us to avoid some of key confounds inherent in many econometric analyses. As an example, consider the decision process for tax rates and the regulatory constraints imposed on entrepreneurs. These are often jointly determined by government expenditures and the incumbent political party. With a DCE, we can avoid any such confounds as we can exogenously determine the characteristics of the marketplace itself. It is important to note that we are posing an institutional question about the firm location choice, not a spatial one. By conducting the analysis within the same metropolitan area, we are abstracting away from discrepancies in firm location attractiveness due to spatial differences and solely examine those due to differences in the regulatory framework between localities. The inclusion of the alternative to not start a business to the choice set of the entrepreneur-respondent is what enables this study to overcome survivorship bias. By assuming that the number of entrepreneurial startups is a function of the demand of entrepreneurs to start a new business, we can estimate entrepreneurs’ indirect utility at each one of the three choices via a latent class logit model. Next, having generated primary data from experimental methods, we derive two policy-relevant statistics that constitute our main findings. First, we estimate the relative probabilities that an entrepreneur would start a business in each of the two states along with the probability that an entrepreneur will not start a business at all under the specified regulatory conditions. This statistic measures the isolated effect of each policy on entrepreneurship separately which allows us to assess the relative importance of the regulatory framework to the tax system in entrepreneurs’ business formation decision. Second, we evaluate the impact of changes in regulation on the likelihood the entrepreneur will choose to start her business in each state or not start a business at all by computing point elasticities of the probability of locating in state with respect to a marginal change in one of the three choice attributes (the two regulatory and the one tax variable). Since these are both “own-price” and “cross-price” in nature, we can infer the impact of policy changes not only within the policy’s jurisdiction but across borders, too. Thus, our second statistic is capturing the feedback loop effects of interstate regulatory and tax competition. The rest of the paper is organized as follows. Section 2 discusses the theoretical background of our experiment, and justifies our rationale for including occupational licensing, corporate taxes, and registration-processing time in our DCE. We develop and analyze a DCE to test how entrepreneurs’ location choice responds to changes in government regulatory and tax burden. This introduces a novel approach in generating credible estimates about key questions in entrepreneurship such as the effect of barriers to entry and taxation to new business formation. It should be noted that even though our DCE estimates are based on hypothetical choices, our findings may still suffer from survivorship bias as the surveyed population is still comprised of existing entrepreneurs. In Sect. 3, we explain the design of the DCE along with the data and methodology we employ. Section 4 presents the results, which suggest that the majority of entrepreneurs respond to changes in public policy in a manner consistent with economic theory. Section 5 concludes with a discussion of the limitations of our study as well as its implications for future research and policy.",9
55.0,2.0,Journal of Regulatory Economics,29 March 2019,https://link.springer.com/article/10.1007/s11149-019-09382-z,Funding natural monopoly infrastructure expansion: auctions versus regulated uniform access prices,April 2019,Peyman Khezr,Flavio M. Menezes,,Male,Male,Unknown,Male,"It is well understood that economic regulation is required to ensure that it is incentive compatible for the owner of a natural monopoly infrastructure to expand capacity. For example, owners of electricity transmission networks may have no incentives to expand capacity if by doing so it eliminates its congestion rents. Indeed, there is a large literature on the design, implementation and performance of proposed and existing regulatory regimes to incentivize the socially optimal expansion of existing natural monopoly networks.Footnote 1 In contrast, this paper assumes that the regulated firm is incentivized to expand capacity, and focuses instead on the impact of different mechanisms to elicit the users’ willingness to pay for the expansion of the natural monopoly infrastructure. We consider two key underlying economic phenomena. First, there is a public good aspect to the decision to build the new facility, as it may require more than one user to seek to access for the facility to be built. Second, users’ values for accessing the facility are private information. In particular, this paper characterizes equilibrium behavior in an auction where firms bid a unit price in order to fund and gain access to a new piece of natural monopoly infrastructure. Firms need access to this new facility to sell their output in a competitive market. For example, a small number of mines need access to rail and port infrastructure to export thermal or metallurgical coal to overseas markets where they are price takers. For simplicity, we consider the case of a new facility. For example this may be the case of a new rail line designed to connect new established mines to an existing port.Footnote 2 The new facility is built only if enough revenue is generated to cover its cost. The facility owner’s revenue is simply the access price times the quantity shipped or transported through the port or railroad. Access services are typically provided to firms via long-term capacity contracts. For example, in the case of rail and ports to transport commodities such as coal, new capacity is underwritten by long-term take-or-pay access contracts between the infrastructure provider and coal shippers (QCA 2013). In many jurisdictions, when access is regulated due to the natural monopoly characteristics of the facility, the service is provided by a monopolist and the price of access is determined by the regulator after the parties have signed long-term contracts. That is, long-term contracts determine quantities, with the price to be set or arbitrated by the economic regulator, with all parties anticipating that the regulator will determine a cost-based access price. In practice, when setting an access price, regulators are required to have regard to a number of factors, including static and dynamic efficiency, and pricing principles that only allow for price discrimination when it aids efficiency. Typically, regulators around the world set uniform prices for each class of users in a non-discriminatory way in order to satisfy these multiple objectives. For example, all coal miners served by a particular rail system, or a port, are likely to pay the same unit price for access. Setting a uniform access price is aimed at limiting the ability of a regulated monopolist provider to exercise market power through price discrimination or to favor particular users in the event the access provider is vertically integrated. Indeed, once a facility is built, setting a uniform price in a way that allows the infrastructure owner to recover its costs can be consistent with efficient outcomes. The focus here, however, is not on the price to be charged once the facility will be built. Instead, the question we address is whether the new facility will be built whenever the firms’ value for accessing it is greater than the cost of provision. While there may be a number of reasons why efficient provision may not occur, such as demand uncertainty, negotiation breakdown due to differences in attitudes towards risk or distinct discount rates, our emphasis is on the role of asymmetric information. This paper examines a situation where firms seeking access have private information about their net values for securing access, and the regulator commits to an access price—or a methodology to calculate such an access price—that does not take into account such private information. In particular, the regulator sets a uniform access price that will allow the infrastructure provider to recover its costs of provision in an ex-ante sense, that is, not accounting for the firms’ private information. Such a uniform access price, however, may be too high for some firms, who will not sign the long-term contract in anticipation of such high price. Thus, even if the firms’ total value for accessing the facility outweighs the cost of provision, such a facility may not be built under a uniform access price regime. The question we address in this paper is whether given the existence of asymmetric information, a decentralized mechanism, where access seekers bid an access price, may do better than the regulated uniform price. The answer to this question is not immediate as it is not clear that the auction will necessarily be more efficient because it reveals information, unlike the uniform-price regime which takes no account of private information. The nature of the trade-off that bidders face in the access rights auctions is different from that bidders face in a standard pay-your-bid auction. In particular, in a pay-your-bid auction with independent private values, bidders bid so as to just outbid the bidder with the second highest valuation, conditional on having the highest valuation. The Bayes Nash equilibrium balances the incentives to bid below one’s value to maximize profits conditional on winning with the incentives to bid as close as possible to one’s value to maximize the probability of winning. In particular, equilibrium behavior implies that as long as the reserve price is equal to the seller’s valuation, the auction is necessarily ex-post efficient; the object is guaranteed to go to the bidder with the highest valuation. In addition to the trade-off above, bidders in the access rights auction face an additional incentive to lower their bids below their willingness to pay due to free riding; a firm can increase its bid by x, the other firm can decrease its bid by x, while at the same time keeping the probability of provision constant. This means that, unlike in the standard auction, there is no presumption that the outcome is efficient, even from an ex-ante viewpoint. It follows that there is no a priori basis to determine which of the two mechanisms leads to more efficient outcomes. The contribution of the paper is to show that it is possible for an auction of access rights to dominate, in terms of ex-post efficiency, arguably the most common regulatory arrangement governing access to infrastructure (i.e., a regulated uniform-price). We note that, under a market mechanism, the auction revenue may exceed the cost of building the facility, which includes a return of and on capital. While we focus exclusively on ex-post efficiency—the probability of completion given that it is efficient to do so, there are regulatory instruments that can be used to eliminate this monopoly rent—for example, the excess auction revenue can be used to reduce the maximum allowable revenue under a revenue cap regime to limit the ability of the infrastructure owner to earn monopoly rents.",
55.0,2.0,Journal of Regulatory Economics,03 April 2019,https://link.springer.com/article/10.1007/s11149-019-09379-8,Has Dodd–Frank affected bank expenses?,April 2019,Thomas L. Hogan,Scott Burns,,Male,Male,Unknown,Male,"The regulation of U.S. commercial banks has been a central topic in the debate surrounding the 2008 financial crisis. Since the crisis, the banking system has experienced a substantial increase in the scale and scope of regulations. The landmark legislation on financial regulation during this period has been the Dodd–Frank Wall Street Reform and Consumer Protection Act of 2010 (the Dodd–Frank Act), “the most comprehensive set of reforms to our financial system since the Great Depression” (U.S. Department of the Treasury 2017). Now a decade since the financial crisis, regulatory reforms remain a topic of controversy, due in part to the lack of quantitative studies of the effects of the Dodd–Frank Act. While the size and scope of regulatory expansion are beyond dispute, the question of whether the act has imposed significant costs on banks remains controversial. In a 2012 survey, the American Bankers Association (ABA) concluded that the act imposed “daunting new compliance, operational, and recordkeeping burdens on all banks” (ABA 2012, p. 4). In his 2012 congressional testimony, chairman of the Community Bankers Council of the ABA William Grant made the “very conservative” estimate that the act raised industry compliance costs by “$50 billion annually, or about 12 percent of total bank operating costs” (Grant 2012, p. 4). Former National Economic Council director Gary Cohn claims that Dodd–Frank costs banks “literally hundreds of billions of dollars of regulatory costs every year” (Bender and Paletta 2017). Another issue is the differential effects of regulation on small and large banks. While the primary rationale for Dodd–Frank was to increase oversight of systemically important financial institutions (SIFIs), critics argue the act has disproportionately affected smaller banks. A survey of more than 200 community banks by Peirce et al. (2014, p. 64) finds “substantially increased compliance costs” due to Dodd–Frank. They report that “more than eighty percent of respondents saw their compliance costs rise by more than five percent since 2010” (p. 3). Despite the increases cited by commercial bankers, studies by financial regulators find little evidence of cost increases following the implementation of the Dodd–Frank Act. Two leading studies, for instance, find no substantial increase in noninterest expenses. McCord and Prescott (2014, p. 42) find that although there was a slight increase in noninterest expenses after Dodd–Frank, “the increase is relatively small and, more importantly, the size of these expenses is just too small to have a big effect on bank profitability.” The Government Accountability Office (GAO 2015, p. 39) similarly finds that “noninterest expenses have decreased or remained flat since the financial crisis.” It also disputes the claim that smaller banks have been disproportionately hurt by higher costs, concluding that “noninterest expenses generally have fallen for banks of all sizes since the third quarter of 2010” (p. 42). What explains this discrepancy between what bankers and regulators believe about the effects of Dodd–Frank? This study attempts to resolve this question by expanding on previous studies in three ways. First, we separate our dataset into large banks with $10 billion or more in total assets and small banks with < $10 billion since banks above and below the $10 billion threshold are subject to different regulations and therefore might be affected differently. Second, we divide total noninterest expenses into two categories: salary and non-salary expenses. We then consider four subcategories of non-salary expenses that might be related to regulatory compliance: legal, data processing, auditing and consulting. Third, we use a measure of regulatory restrictions on the banking industry to assess how changes in regulation affect bank expenses. Our results shed light on why bankers and regulators hold such divergent views on how Dodd–Frank has affected bank expenses. Charts in Sect. 3 show increases in non-salary expenses prior to Dodd–Frank, which is consistent with McCord and Prescott (2014) and GAO (2015), while increases in salary expenses do not occur until the later years of our sample, which are beyond the time periods used in other studies. Using regression analysis, we find non-salary, noninterest expenses typically show a one-time increase following Dodd–Frank. Salary expenses are mostly related to increases in regulations, although they also exhibit a one-time increase for small banks after Dodd–Frank. The results imply increases in total noninterest expenses after the passage of Dodd–Frank in the range of $58.7 billion to $86.1 billion per year.",18
55.0,3.0,Journal of Regulatory Economics,01 June 2019,https://link.springer.com/article/10.1007/s11149-019-09383-y,Maximum entropy: a stochastic frontier approach for electricity distribution regulation,June 2019,Elvira Silva,Pedro Macedo,Isabel Soares,Female,Male,Female,Mix,,
55.0,3.0,Journal of Regulatory Economics,17 June 2019,https://link.springer.com/article/10.1007/s11149-019-09387-8,Does the ban on trans-fats improve public health? In search of the optimal policy response,June 2019,Mitja Kovac,Rok Spruk,,Male,Male,Unknown,Male,"One of the most debated public health concerns across industrialized countries that has triggered the attention of health care agencies, consumer protection authorities and legal and economic scholars is the widespread use of artificially produced trans-fats in food industry. Trans fatty acids (TFA) are unsaturated fatty acids found in the food chain. TFA occur naturally at low levels in dairy products and meat from ruminant animals (e.g. beef, lamb etc.). They are also produced during industrial hydrogenation and deodorization of vegetable oils to produce more solid fats that are sometimes used in the manufacturing of foods (e.g. margarines, biscuits) and for use in catering outlets. Initially, trans-fats were thought to be a healthy alternative to animal fats because they are unsaturated and come primarily from plant oils. However, in 1990 scientists made a startling discovery by showing that trans fats tend to increase LDL (bad) cholesterol and decrease HDL (good) cholesterol (Han et al. 2002; Mozaffarian et al. 2004, 2006). More studies over the years confirmed this finding (Baer et al. 2004; Teegala et al. 2009; Brouwer et al. 2013). So far, we know that trans fats have a strongly deleterious impact on heart and metabolism in general (Lemaitre et al. 2002; Stender and Dyerberg 2003; Oh et al. 2005; Uauy et al. 2009; Missmer et al. 2010; Trevizol et al. 2015). Biological studies have mainly examined the effect of the consumption of trans fatty acids on cardiovascular risk factors, particularly the effect of these on lipoprotein metabolism. Epidemiological studies established a long time ago that high plasma concentrations of total cholesterol (TC) and LDL cholesterol (C-LDL) and low concentrations of HDL cholesterol (C-HDL) were reliable cardiovascular risk markers (Ascherio et al. 1994). In the early 1990s, clinical trials showed that consumption of trans fatty acids led to an increase in plasma cholesterol, particularly LDL, and a fall in HDL cholesterol (C-HDL) was also observed in some cases (Koletzko 1992). A meta-analysis performed by Mensink (2016), involving 60 nutritional interventions, was used to evaluate the effects of different fatty acids, including trans fatty acids, on the total cholesterol/C-HDL ratio. In particular, it was shown that a 1% increase in trans fatty acid consumption at the expense of carbohydrates could lead to an increase in C-LDL of + 0.040 mmol/L; on the other hand, the effect on C-HDL was found to be similar to that of carbohydrates (Mensink 2016; Mensink et al. 2016). The estimated impact on the total cholesterol/C-HDL ratio was found to be + 0.22 mmol/L. When carbohydrates were replaced by palmitic acid, considered to be hypercholesterolemic, the effects observed were identical to those obtained with trans monoenes relative to C-LDL (Mensink et al. 2016). However, the empirical evidence on how the strategies employed worldwide to reduce trans-fats (TFA) levels in food have impacted on health outcomes is limited. Some studies have drawn parallels between the introduction of mandatory TFA labelling and lower levels of plasma TFA or TFA in breast milk (Vesper et al. 2012; Ratnayake et al. 2009). A WHO study estimated that reductions in population TFA intakes of 0.5 and 0.8% of daily energy could result in approximately 3500 and 4700 fewer heart disease-related deaths per year in the UK (O’Flaherty et al. 2012). In addition, Restrepo and Rieger (2016a) investigate TFA ban in New York State and find that the policy caused a 4% reduction in CVD mortality rates, or 12 fewer CVD deaths per 100,000 persons per year. Policymakers have paid much attention to the use of trans fats in dairy products to tackle their harmful effects on public health. A growing awareness of the adverse effects of trans fats on health has triggered extensive discussion on the optimal regulatory intervention by public authorities (Ogus 2004). For example, in 2003 the World Health Organisation recommended that trans fats make up no more than 1% of a person’s diet and in 2013, the United States Food and Drug Administration (FDA) issued a preliminary determination that partially hydrogenated oils (which contain trans fats) are not “generally recognized as safe”, which was expected to lead to a ban on industrially produced trans fats from the American diet. In 2015, the FDA finalized its determination that trans fats are not generally recognized as safe, and set a three-year time limit for their removal from all processed foods. Other policymakers have responded by adopting mandatory labels of trans fats on packaged foods. Such labels comprise a form of information disclosure to consumer without a direct interference in the food supply. Many policymakers in industrialized countries have tried to tackle the harmful effects of trans fats by implementing a multitude of voluntary regulatory measures such as voluntary labelling system, non-mandatory industry guidelines, public campaign against trans fats, pledges to voluntarily reduce trans fats in food outlets, or government-mandated public health responsibility deals (Hendry et al. 2015). Our investigation seeks to evaluate the ban on trans fats versus non-ban trans-fat legislation on public health outcomes empirically. In 2003, Denmark was the first industrialized country to outlaw the use of industrially produced TFAs (Leth et al. 2006). In 2008 and 2009, Switzerland and Austria followed suit by implementing a partial ban on trans fats with numerous exceptions. In 2011, Iceland followed the Danish example and outlawed trans fats while Norway and Hungary only partially banned trans fats in 2014. The empirical evidence overwhelmingly suggests large public health benefits of the trans-fats ban. First, Restrepo and Rieger (2016b) examine the effects of the trans-fats ban on cardiovascular diseases drawing on the Denmark’s ban introduced in 2003. They show that before the trans fat policy was implemented, CVD mortality rates in Denmark closely tracked those of a weighted average of other OECD countries (Restrepo and Rieger (2016b). In the years before the policy, the annual mean was 441.5 deaths per 100,000 people in Denmark and 442.7 in the synthetic control group. In the 3 years after the policy was implemented, mortality attributable to CVD decreased on average by about 14.2 deaths per 100,000 people per year in Denmark relative to the synthetic control group (Restrepo and Rieger 2016b). And second, Restrepo and Rieger (2016a) analyse the impact of trans fats ban in the state of New York on the mortality rate from coronary heart diseases (CHD) by exploiting the within-state variation and differential timing of the ban. Our paper joints this scholarly debate and seeks to provide empirical evidence on how the regulatory strategies employed worldwide to reduce trans-fats levels in food might have affected health outcome and suggest that a wide elimination of trans fats might be the most effective regulatory strategy. Namely, this paper contributes to the existing literature by studying the effect of the ban on the obesity rates and by assessing the impact of trans-fat regulation (other regulatory policies) other than the ban. Particularly, it attempts to offer several marginal contributions to the existing literature. First, while the existing evidence suggests a marked drop in CHD-related mortality in response to the trans-fats ban, the impact of the ban on public health outcomes other than CHD-mortality is less known. And second, the effects of non-ban trans-fats legislation on CHD mortality rates and non-CHD public health outcomes are to the date little known while such an assessment is critical to better understand the effectiveness of ban versus non-ban legislation in influencing health outcomes. We specifically evaluate the effects of the trans-fat ban and voluntary regulation on public health outcomes for a panel of 39 countries in the period 1990–2015 drawing on the ban implemented by Denmark in 2003. To this end, we employ difference-in-differences identification strategy to evaluate the public health benefits of trans-fat legislation, and compare cardiovascular mortality and obesity rates between Denmark and the rest of the OECD countries as a control sample. Our preferred difference-in-differences specification suggests that the ban is associated with 2.9% drop in the coronary heart disease-related mortality rate, and with about 1 percentage point reduction in childhood- and adolescent obesity rate. On the normative note, our results imply that the ban and mandatory labels are preferable to non-ban trans-fats self-regulation and demand-driven trans-fat initiatives such as guidelines and campaigns in terms of public health benefits (Stender et al. 2006; Cohen 2014), and appear to be superior form of “new paternalism” in removing the negative externalities arising from the consumption of trans fats. The rest of the article is organized as follows. Section 2 reviews trans-fat policies, medical literature and legislation, Sect. 3 discusses the identification strategy, Sect. 4 presents the data, and Sect. 5 presents the results and falsification check. Section 6 concludes.",2
55.0,3.0,Journal of Regulatory Economics,12 March 2019,https://link.springer.com/article/10.1007/s11149-019-09378-9,The curse of low-valued recycling,June 2019,Hiroaki Ino,Norimichi Matsueda,,Male,Unknown,Unknown,Male,"In the presence of a household’s incentive to illegally dispose of its waste, a so-called “two-part instrument (2PI)” or “deposit-refund scheme (DRS)” is considered to be a more effective policy tool over others.Footnote 1 To the best of our knowledge, however, most of the previous studies have not paid close attention to the possibility that commercially-transacted recyclable wastes are illegally disposed by firms and do not actually get recycled.Footnote 2 Especially when the government offers a subsidy for simply obtaining wastes in a recycling market, illegal disposal can be the most profitable option for firms just because of the provision of the subsidy. 
Ino (2011) examines the implications of such illicit behaviors by firms in determining the optimal policy structure and respective policy levels,Footnote 3 and finds that a DRS is still reasonably effective as long as the net private benefit of recycling is positive, at least, up to a certain extent. Unfortunately, this condition does not always hold in reality. Recycled materials from used PET bottles and glass containers currently possess very small economic values, as opposed to, say, aluminum cans. In contrast with Ino (2011), which focuses on financially-profitable recyclables, this paper explores whether low-valued recyclables yields qualitatively different economic implications from what holds for non-low-valued recyclables, and, if so, how an optimal policy scheme can be structured. In general, the recycling of containers and packaging have recently seen increasing governmental involvement in the forms of taxes and subsidies in many developed countries. Low-valued recyclables may get recycled solely due to the presence of these policies, and the mere fact of private firms’ participating in residual waste trades does not imply that the recycling is socially desirable. However, it is not necessarily the case that such “low-valued recycling” is inefficient from a society’s perspective, especially when the disposal cost of the waste is large. Recycling can be justified on the social welfare ground even if a recycled material per se has a fairly low market value. For instance, incineration of scrap tires can pose a serious environmental problem as they result in thick smoke which can contain pollutants harmful to human health throughout the surrounding area. Disposing of tires in landfills can also create potentially significant environmental issues as those tires tend to rise to the surface, and they have also been proven to be serious breeding grounds for mosquitoes and can leach toxic chemicals into groundwater.Footnote 4 In order to raise funds to address the current stockpile issue and to prevent future problems by increasing recycling and proper disposal of scrap tires, many states in the U.S. now collect the deposits on tire purchases and they are used to subsidize scrap tire processors or sales of products made from scrap tires (Walls 2013). On the other hand, Kinnaman et al. (2014) report by carefully estimating the net social benefits of recycling household solid wastes that the welfare-maximizing recycling rates would be well below the observed and mandated recycling rates for Japan and perhaps for other developed nations as well. When the recycled materials have very low economic values, this potential “over-encouragement” of recycling can also lead to firms’ illegal disposal of wastes that are initially intended for recycling. In Japan, for instance, numerous midnight dumping cases of cleansed and properly-sorted PET bottles in large chunks have been reported in the news media since the implementation of the Law for the Promotion of Sorted Collection and Recycling of Containers and Packaging (or, the Container and Packaging Recycling Law, in short) in 1997. Given typically enormous volumes of those wastes, it is obvious that they were discarded by firms and not by households. In principle, the law is intended to make the manufacturers of packaging and the retailers of packaged products financially responsible for the disposal of the packaging wastes and also to encourage the recycling of those wastes by providing extra monetary incentives for recyclers. It is suspected, however, that some recyclers have taken advantage of the law and received illegitimate financial benefits for the recycling activities they have not conducted properly. Whereas the law’s administrator, the Japan Containers and Packaging Recycling Association, claims that “recycling fees are paid to recyclers after it has been confirmed that the recycled materials have been sold to the users of these goods” on its own website,Footnote 5 several news media reported cases where the products made of the supposedly “recycled” materials proved to contain very little or effectively no recycled content when they were tested in laboratories.Footnote 6 This paper examines how to deal with low-valued recyclable wastes by using the framework of Ino (2011), which includes disposal and recycling activities and considers the government’s monitoring cost in preventing firms from disposing of collected wastes illicitly. As one of our new contributions, we modify the crucial condition of Ino (2011) and explore the situation where the recycled material has such a small market value that always makes the net private benefit of recycling negative for a recycler (referred to as a low-valued recyclable in this article). Furthermore, in order to examine whether the government should create a recycling market under the possibility of improper disposal options, we analyze the model by covering all the relevant boundary cases for recycling activities as well as for illegal disposal activities. Consequently, our model yields the four distinct equilibrium cases: (i) a “No Market” case where a recycling market does not emerge; (ii) an “Illegal Market” case where all the transacted wastes are disposed of illegally; (iii) a “Mixed Market” case where legal and illegal recycling activities coexist; and (iv) a “Legal Market” case where all the transacted wastes are recycled properly. Moreover, we show that the second-best policy for a low-valued recyclable is either one of the two following schemes: a deposit-refund scheme (DRS) that gives birth to a legal recycling market and an advanced-disposal fee (ADF) that does not create any recycling market. An ADF is often considered to be a socially inferior policy tool compared to a DRS because an ADF provides an insufficient incentive for recycling. In contrast, our result indicates that, when a monitoring cost on a firm is taken into account, it can be quite plausible that an ADF should be favored over a DRS by the government.Footnote 7 We also discuss how an “over-encouragement” of recycling can be easily induced in the process of implementing such a policy set, in particular, when the government intends to launch a recycling market. Scrutinizing the structure of the second-best policy set reveals that information available only in the recycling market is necessary to select the optimal policy scheme, i.e., whether a recycling market should be created by a DRS or it should not be created by an ADF, and to implement it appropriately, i.e., how heavily recycling activities should be encouraged by a DRS. Thus, in the absence of commercially viable recycling market, a policymaker has to face critical information deficiency in its implementation. This is in stark contrast to a DRS for a non-low-valued recyclable as is shown in Ino (2011). This informational challenge associated with a low-valued recyclable makes a policymaker quite clueless to select the policy scheme optimally and could result in the creation of a socially inefficient recycling market.Footnote 8 Policies chosen by such an ill-informed policymaker can lead to substantial illegal waste disposal by firms or to an exorbitant monitoring cost if the government wishes to create a proper recycling market. The paper is organized as follows. The next section describes our economic model and explains the first-best policy under the supposition of an always-compliant firm. Section 3 extends the analysis by considering the possibility of a non-compliant firm and derives the above-mentioned market equilibrium, and Sect. 4 describes the second-best policy set for low-valued recyclables. Then, in Sect. 5, we discuss why it would be quite difficult to actually implement the second-best deposit-refund policy for a low-valued recyclable product without over-encouraging recycling activities. The final section concludes the paper. The mathematical proofs of all the propositions in this paper can be found in the “Appendix”.",2
55.0,3.0,Journal of Regulatory Economics,14 June 2019,https://link.springer.com/article/10.1007/s11149-019-09384-x,Effects of environmental regulation on air pollution control in China: a spatial Durbin econometric analysis,June 2019,Xueping Wu,Ming Gao,Wei Li,Unknown,,,Mix,,
55.0,3.0,Journal of Regulatory Economics,29 June 2019,https://link.springer.com/article/10.1007/s11149-019-09388-7,To favor more or less? Corporate lobbying over preferential treatment to state-owned enterprises,June 2019,Dapeng Cai,Jie Li,,Unknown,,Unknown,Mix,,
56.0,1.0,Journal of Regulatory Economics,05 August 2019,https://link.springer.com/article/10.1007/s11149-019-09386-9,What can deregulators deregulate? The case of electricity,August 2019,Tin Cheuk Leung,Kwok Ping Ping,Kevin K. Tsui,,Unknown,Male,Mix,,
56.0,1.0,Journal of Regulatory Economics,13 June 2019,https://link.springer.com/article/10.1007/s11149-019-09385-w,Incentives for efficient pricing mechanism in markets with non-convexities,August 2019,Hung-po Chao,,,Unknown,Unknown,Unknown,Unknown,,
56.0,1.0,Journal of Regulatory Economics,19 August 2019,https://link.springer.com/article/10.1007/s11149-019-09389-6,On the functioning of a capacity market with an increasing share of renewable energy,August 2019,Sebastian Schäfer,Lisa Altvater,,Male,Female,Unknown,Mix,,
56.0,1.0,Journal of Regulatory Economics,08 October 2019,https://link.springer.com/article/10.1007/s11149-019-09391-y,Mandated sharing and telecom investment in Latin America and the Caribbean,August 2019,Juan Jung,,,Male,Unknown,Unknown,Male,"Forthcoming years are crucial for the future development of Latin America and the Caribbean (LAC). Despite the important advances produced over the past decades, there are still considerable challenges lying ahead for the region. Gross Domestic Product (GDP) has grown considerably since the beginning of the 2000s—mainly driven by high commodity prices-, however, productivity levels have remained almost unchanged (Grazzi et al. 2016). Fostering its digital economy has been widely identified as one of the keys to increase productivity in the region. In that sense, LAC countries face not only the challenge of closing the digital divide, but also to introduce advanced digital technologies through the value chains of its economies. According to McKinsey (2017), if Latin American countries are not able to increase its productivity levels through the introduction of the digitalization, the economic growth of the next 15 years will be 40–50% lower than that of the previous 15 years. To achieve the aim of promoting digitalization, investment in telecommunications networks is crucial, as well as the key task of creating a suitable framework that can stimulate those deployments. A report from Cet.la (2013) found for a sample of eleven countries of Latin America that to achieve European levels of connectivity the region should invest a cumulative amount of USD 355.825 million over a period of 8 years, a 10% over the forecasted tendency. Therefore, it’s a considerable investment effort, which will surely require of a propitious environment to become feasible. Sectoral regulation is a crucial part of this story. Many LAC countries have experienced regulatory reforms in the telecommunications sector in the past decades, implying in most cases some kind of liberalization and privatization. However, the timing, extent and nature of those reforms vary largely across LAC countries. As a result, current regulatory frameworks for the telecommunications sector in the region are far from being homogeneous, as has been the sectoral performance across different countries. One of the main topics usually addressed by the regulatory frameworks is that of infrastructure sharing across telecom operators. The possibility of sharing presents some interesting advantages from a theoretical perspective, particularly towards decreasing costs and making a more efficient use of resources. However, some empirical evidence suggests that this kind of sharing agreements are positive when being done on voluntary grounds by those concerned, while on the contrary, imposing mandates can provide disincentives to those willing to invest in those infrastructures in the first place (Hausman 1999; Jorde et al. 2000; Kim et al. 2011; Grajek and Röller 2012). In consequence, the main objective of this paper is to look at the effects of sharing regulation on investment in the telecommunications sector in the LAC region. Given the relevance of promoting frameworks aligned to stimulate the required investments, a complete revision of current regulatory regimes must be accomplished. Through this paper, we aim to add to the debate by discussing specifically the role of the sectoral sharing regulation on its investment performance. Even if it does not consider further regulatory measures than sharing, or the challenges related to the convergence process, this paper will surely provide useful inputs about the design that future regulatory frameworks should follow, particularly towards the common dilemma of regulatory bodies in determining the optimal levels of intervention. To the best of our knowledge, there are no previous contributions in the literature that use broad measures of sharing regulation in telecommunications analyzing its relationship with investment intensity in a panel context for the LAC region. This paper is structured as follows: next section provides a theoretical background performed after reviewing the literature on regulation and investment in telecommunications, Sect. 3 presents the dataset of LAC countries to be used in the empirical analysis, Sect. 4 provides a descriptive analysis of the data, Sect. 5 presents the empirical specification and the estimation results, and finally Sect. 6 ends with some concluding remarks.",1
56.0,2.0,Journal of Regulatory Economics,18 November 2019,https://link.springer.com/article/10.1007/s11149-019-09394-9,Peak-load pricing with different types of dispatchability,December 2019,Klaus Eisenack,Mathias Mier,,Male,Male,Unknown,Male,"Many goods and services are perishable or not easily storable, but face inelastic demand in the short-term (e.g., electricity, telecommunication, food). Optimally scheduling the production of such goods is thus an important practical problem. This problem is further complicated if (i) some production technologies are not perfectly reliable, and if (ii) technologies differ in their capability to substitute non-reliable ones in cases of demand that cannot be met otherwise. While the first complication has been studied in the peak-load pricing literature (see Crew et al. 1995, for an excellent survey), the implications of the second have not been researched yet to our knowledge. We thus present an extension of the peak-load pricing model where certain standard results fundamentally change. This extension is crucial, for example, in the electricity sector, which will serve as a prime example in the paper. A large share of short-term electricity demand is inelastic (e.g., Borenstein and Holland 2005; Joskow and Tirole 2007; Helm and Mier 2019), and storage is typically very costly (e.g., Luo et al. 2015; Gimeno-Gutiérrez and Lacal-Arántegui 2015; Schmidt et al. 2017; Zerrahn et al. 2018; Neetzow et al. 2018). Today, the share of wind, solar, and other kinds of renewable energy supply in electricity production is rising worldwide (REN21 2018). Capacity costs of renewables are anticipated to fall further in the future (Schröder et al. 2013; IRENA 2016). This trend is primarily driven by the need to reduce the production of conventional power plants that emit greenhouse gases. This poses a major challenge, because generation of crucial renewable technologies like wind turbines or photovoltaic (PV) power stations may fluctuate substantially due to weather conditions in many parts of the world. Thus, reliability of supply poses an increasing challenge, causing additional electricity system costs (Lamont 2008; Hirth 2013; Reichelstein and Sahoo 2015), e.g., to avoid costly outages (Pechan and Eisenack 2014; Eisenack 2016). Differences in the dispatchability of substitutes for renewables make this challenge more difficult. By dispatchability we mean the ability of technologies to adjust production in the short-term if uncertain supply is not sufficient to meet inelastic demand. When renewables produce less output than expected, gas turbines can ramp up quickly, whereas nuclear power plants typically require scheduling several days in advance. Thus, with a rising share of renewables, flexibility options become important, possibly raising the costs of integrating renewables (Lannoye et al. 2012; Kubik et al. 2015; Schmid et al. 2017; Schill et al. 2017). These challenges are well recognized in current policy making (e.g., the EU winter package). There is a heated debate among decision-makers and in the research community on future electricity market designs (Joskow and Tirole 2007; Newbery 2010; Hiroux and Saguan 2010; Fabra et al. 2011; Cramton et al. 2013; Henriot and Glachant 2013), for example, on whether to charge prices on energy supplied or the power of installed capacity (Ito 2014; Borenstein 2016), intraday market design (Borggrefe and Neuhoff 2011), and how to auction balancing power (Hortaçsu and Puller 2008; Müsgens et al. 2014). Another debate centers around the possibility of a missing money problem for remaining conventional power plants or the need of capacity markets, that is, whether power plants will be able to recover their fixed costs in the future (Joskow 2008; Cramton et al. 2013; Newbery 2016; Borenstein 2016; Bushnell et al. 2017; Brown 2018; Fabra 2018; Mier 2018). The deterministic theory of peak-load pricing shows that the optimal price in the peak period is equal to the long-run marginal costs of the peak technology (e.g., Boiteux 1949; Steiner 1957; Williamson 1966; Crew and Kleindorfer 1971). The zero-profit condition holds, i.e., all technologies exactly recover their capacity costs from short-term profits. With demand uncertainty, the costs of excess demand or rationing need to be considered (e.g., Brown and Johnson 1969; Crew and Kleindorfer 1976; Carlton 1977; Allcott et al. 2016). Supply uncertainty has been studied by Chao (1983) and Kleindorfer and Fernando (1993). They assume stochastically independent generating units with an identical availability factor. In their model, after each technology’s capacity is determined, demand is scheduled. Then, the capacities realize their uncertain output. There is thus a positive probability that scheduled demand will not be completely met. In the optimum, all available technologies are employed with a positive capacity (except for those technologies that are strictly dominated by other technologies in both lower capacity and operating costs). Since then, there have been few contributions to the theory of peak-load pricing, despite the vast literature on important applications (e.g., to the electricity sector, transportation, airport, airline and hotel pricing, telecommunication). The main innovation of our theoretical paper is a novel time structure of short-term decisions that account for differences in dispatchability. We are only aware of two related theoretical studies by Green and Léautier (2017) and Crampes and Renault (2019), and of related engineering dispatch models (e.g., Wang and Shahidehpour 1995; Kumano 2011). In contrast to these, our model distinguishes three technology types by reliability and dispatchability. Output from non-dispatchable technologies is uncertain and cannot be adjusted at all. Partially dispatchable technologies need to be scheduled ahead of non-dispatchable production, but are assumed to be perfectly reliable. Highly dispatchable technologies are so flexible that they can be scheduled after the non-dispatchable technology’s random output has been realized. Our paper shows that the competition between technologies with different types of dispatchability is much fiercer than suggested by the standard peak-load pricing model, which neglects dispatchability. In our case, it is either optimal to just employ partially dispatchable technologies, or to just employ a composite of non- and highly dispatchable technologies. We derive a specific condition for the costs that determines which case is optimal. We also find a condition for more costly highly dispatchable technologies leading to more or less non-dispatchable capacity. The probability of excess demand is independent of the costs of non-dispatchable technologies. In the standard model, capacity costs are mainly re-financed during peak load. When dispatchability matters, partially dispatchable technologies can recover their capacity cost, but highly dispatchable and non-dispatchable technologies are not able to do so. This poses crucial challenges for designing markets that decentralize optimal prices. The following text is organized as follows. Section 2 introduces the assumptions, whereas Sect. 3 solves the model. We continue with the comparative statics in Sect. 4, followed by the results on cost recovery (Sect. 5). Section 6 compares our results to the standard model and presents extensions, followed by conclusions in Sect. 7. Most of the mathematical proofs are delegated to a Technical Appendix (see Eisenack and Mier 2019), which can be downloaded as supplementary material.",8
56.0,2.0,Journal of Regulatory Economics,23 October 2019,https://link.springer.com/article/10.1007/s11149-019-09392-x,The power of regulatory regimes reexamined,December 2019,Dennis L. Weisman,,,Male,Unknown,Unknown,Male,"Pure price cap regulation (PCR) which entails no ex post earnings sharing is considered a high-powered regulatory regime because the regulated firm is the residual claimant for its efficiency gains and has ideal incentives to invest in cost-reducing innovation. It is therefore puzzling that the empirical evidence is mixed as to whether pure PCR has yielded significant efficiency gains (Ai and Sappington 2002; Resende 2000; Sappington 2002, pp. 278–282). This article offers a possible explanation for the apparent disconnect between the theory and the empirics. Under pure PCR, the price cap faced by the regulated firm is supposed to be invariant to the regulated firm’s behavior (Shleifer 1985; Brennan 1989). This “invariance property” is fundamental to the superior incentive properties of pure PCR. We contend that accommodative competitive entry (ACE) policies enable the regulator to (1) establish a “shadow price cap” that is lower (tighter) than the stipulated price cap; and (2) calibrate this shadow price cap to appropriate the regulated firm’s “excess earnings” ex post. This is problematic because the invariance property is violated, and the regulated firm is no longer the residual claimant for its efficiency gains. It follows that what appears to be pure PCR in theory may not be pure PCR in practice because the effective price cap is no longer exogenous to the regulated firm’s behavior. Because ACE policies play a central role in the analysis, it important to be clear as to precisely what these policies entail. The 1996 Telecommunications Act requires incumbent local exchange telephone companies to supply unbundled network elements—the inputs required to assemble competing local telephone service offerings—to rivals at “cost-based” rates (Kahn et al. 1999; Laffont and Tirole 2000; Robinson and Nachbar 2008; Robinson and Weisman 2008). A key observation is that ACE policies essentially enable regulators to control the degree of competitive entry. Regulators have other policy instruments to accommodate competitive entry. These include various restrictions imposed on incumbent providers, such as artificially high price floors, cross-subsidization, constraints on rate deaveraging and non-compensatory carrier-of-last resort obligations (Sappington and Weisman 2012). ACE policies go beyond merely enabling competition to propagating competition artificially. The regulator has broad, but not unlimited discretion, in its use of ACE polices. Specifically, whereas the regulator can employ such policies to appropriate “excess earnings,” the regulated firm must remain a financially viable enterprise under the Hope standard. Under this standard, a regulated firm is entitled to a “return … sufficient to assure confidence in the financial integrity of the enterprise, so as to maintain its credit and attract capital” and to “enable the company to operate successfully…” The regulator is granted broad discretion under Hope to adopt the lowest rates for the regulated firm consistent with the above standard being met even though it may produce only a meager return.Footnote 1 The Hope standard in combination with ACE policies enables the regulator to reestablish the linkage between the firm’s costs and revenues so that it is no longer the residual claimant for its efficiency gains even under pure PCR.Footnote 2 The Hope standard is potentially problematic for the incentives properties of PCR when it transcends its original intent and is used to establish both a floor and a ceiling on the regulated firm’s earnings. The regulator’s incentives to accommodate competitive entry may be particularly strong under pure PCR because it does not share in the regulated firm’s earnings and bears little or no risk for increases in politically costly basic service rates that could arise under PCR with earnings sharing.Footnote 3 Pure PCR can therefore create a problem of regulatory moral hazard. The extant theory suggests that when earnings sharing is coupled with PCR, the power of the PCR regime is reduced because the regulated firm bears the full cost of cost-reducing effort but retains only a share of the resulting efficiency gains (Laffont and Tirole 1993, p. 11). This article contends that there is another effect associated with earnings sharing that may not have been fully appreciated heretofore. This concerns the effect of earnings sharing on decreasing the regulator’s incentives to accommodate competitive entry. Specifically, because earnings sharing can reduce the regulator’s incentives to reflect efficiency gains in lower prices, it can serve to temper the “ratchet effect.” This suggests that earnings sharing gives rise to countervailing effects in terms of the regulated firm’s investment in cost-reducing innovation. We construct a stylized model in which the regulated firm chooses the level of cost-reducing effort and the regulator chooses the degree of entry accommodation. The regulator’s choice of entry accommodation in combination with the degree of earnings sharing determines the market price. The findings of the literature are reversed in this setting. The regulated firm’s investment in cost-reducing effort may be higher under PCR with earnings sharing than under pure PCR. In fact, unless there is regulatory capture, the regulated firm may have no incentive to invest in cost-reducing effort under pure PCR. The format for the remainder of this article is as follows. Section 2 introduces the definitions and notation. The formal model and key findings are presented in Sect. 3. The numerical simulations are reported in Sect. 4 (with supplemental simulations available at https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3456230). The policy implications are discussed in Sect. 5. Section 6 concludes. The formal proofs of all key findings are contained in the Appendix.",3
56.0,2.0,Journal of Regulatory Economics,19 November 2019,https://link.springer.com/article/10.1007/s11149-019-09393-w,Risk of window dressing: quarter-end spikes in the Japanese yen Libor-OIS spread,December 2019,Mayu Kikuchi,Alfred Wong,Jiayue Zhang,Female,Male,Unknown,Mix,,
56.0,2.0,Journal of Regulatory Economics,21 November 2019,https://link.springer.com/article/10.1007/s11149-019-09395-8,Extraterritoriality of swaps regulation and regulatory arbitrage,December 2019,Carmela D’Avino,,,Female,Unknown,Unknown,Female,"Title VII of the Dodd–Frank Wall Street and Consumer Protection Act (DFA), enacted by the Commodity Futures Trading Commission (CFTC), is the latest regulatory framework for over-the-counter (OTC) derivative products introduced in the US in 2010. The reform outlines an entire range of rules applicable to swaps, including most notably, dealers’ registration, central clearing, centralized order books, trade reporting, regulatory margins, documentation requirements and the application of business conduct standards. The lack of a supranational global regulatory regime for OTC derivatives has compelled US regulators to extend, under some circumstances, the applicability of the reform across the borders to protect domestic financial stability. In particular, Title VII is extended to all counterparties of transactions involving at least one US financial institution worldwideFootnote 1 (CFTC 2013). This regulatory overseas reach on the activities of foreign offices of US banks was deemed necessary to protect US taxpayers and prevent them from financing bailouts caused by banks’ excessive risk-taking overseas and/or excessive exposure to risky foreign counterparties. Largely unpopular among US financial industry players, who trade most OTC derivatives offshore, the extraterritorial reach of the regulation was introduced by the CFCT in 2013 as an add-on provision to Title VII. Existing literature has focused on the effects on OTC derivatives markets, rather than on the off-balance sheets exposure of US banks. A bank-focused analysis, as opposed to a market-focused one, remains unexplored despite crucial regulatory implications that can be drawn upon. The main objective of Title VII is, indeed, to make US banks sounder not only by improving transparency and reducing counterparty risk in derivatives positions but also by limiting their ability to engage in excessive expansion in this market. In particular, the imposition of minimum capital and margin requirements on derivatives transactions was directly aimed at decreasing the exposure of US banks to derivatives and, in particular, swaps markets. This paper aims to fill this gap by analyzing the impact of Title VII implementation on the off-balance sheet of foreign branches of US banks, which have complied with the extraterritorial reach of the regulation since 2013-end. First, our empirical analysis investigates the extent to which the extraterritorial reach of the OTC regulation has curbed foreign OTC derivative exposures of US banks. Second, we explore whether this eventual regulatory-induced reduction in exposure has altered the composition of off-balance sheet activities of US banks’ foreign branches. Market fragmentation, cross-border and cross-product arbitrage provide a rationale for these investigations. First, OTC derivatives market fragmentation may result from the fact that third-country counterparties shy away from US banks in order to circumvent the DFA, triggering a fall in overall exposures of this latter to OTC derivatives markets. While US regulators may welcome this effect, extraterritoriality may also prompt alterations in the geography and the composition of the off-balance sheet activities of foreign branches of US banks due to regulatory arbitrage across borders and products respectively. Cross-border regulatory arbitrage may be stimulated by the substitute compliance framework available under Title VII, which waives some DFA requirements in favour of US banks’ foreign branches (and their counterparties) in some jurisdictions. Cross-product arbitrage, on the other hand, can take the form of futurization, that is, the process of converting swaps into futures holding equivalent contract terms. This may be triggered by less stringent regulation in futures markets, most notably on margin requirements. The focus of our analysis is on the interest rate swaps (IRS) positions of US banks’ foreign branches using data geographically segmented by country of residence. Understanding the implications of activities of the foreign branches of global banks is of foremost importance for domestic financial stability considerations, as the headquarters have unlimited liability for their offshore branches. This holds true to a lesser extent for foreign subsidiaries on which parent banks have only limited liability. Foreign branches allow banks to establish a global network of operations that are typically managed centrally at the parent level. Although this type of centralized business model can permit banks to enhance risk diversification (Markowitz 1952) and intra-institution liquidity management (Cetorelli and Goldberg 2012; de Haas and van Lelyveld 2010), it is more vulnerable to foreign shocks than a decentralized model grounded on a subsidiary-based foreign ownership structure (Fiechter et al. 2011). US global banks play a prominent role in derivatives trading and in particular in the IRS segment of the market. At the outset of the global financial crisis, the foreign branches of US banks had an off-balance notional exposure of $230 trillion of IRS, equivalent to approximately 90% of the total global outstanding IRS.Footnote 2 The estimates stemming from our empirical analysis point to two main results. First, we find evidence of a reduction in IRS positions of foreign branches of US banks for jurisdictions in which extraterritoriality applies. On the other hand, IRS positions in those jurisdictions in which extraterritoriality does not fully apply due to a substitute compliance framework have increased. Second, we advance evidence in support of a regulatory-induced reorganisation of off-balance sheet activities. Title VII, we find, has stimulated the increase in exposures to forwards and futures markets in those jurisdictions in which extraterritoriality fully applies, a result consistent with the futurization hypothesis. The results make it possible to draw, we believe, interesting normative recommendations. The geographical reallocation of OTC derivatives positions can have destabilising effects on global financial stability as contagion risk and correlations across locations and markets raise in balkanized settings (Calomiris 2000; Gart 1994; Hubbard 1994). In addition, this may thwart the efforts of policymakers to discourage geographically concentrated risk-taking by US banks via the DFA implementation. The near-collapse of the American International Group (AIG) played a central role in the post-crisis financial reform discussions in the US and in shaping the new regulatory framework for OTC derivative products. In particular, the extraterritorial reach of the reform was primarily motivated by the large losses accrued by AIG’s London-based office due to the excessive exposure to derivative products. The episode revealed how the offshore risk exposures of global institutions can have systemic repercussions domestically.Footnote 3 Given that potential, a substitute compliance framework embedded in the extraterritoriality of the DFA that stimulates regulatory arbitrage and the creation of geographical hubs for swap trading by global banks could run counter to one of the main rationales of the regulatory framework: reduce excessive localized swaps exposure. As highlighted by Artamonov (2015, p. 219), “the global derivatives markets is not global anymore; rather, it has become a fragmented system of ring-fenced liquidity pools, where risk is concentrated rather than being dispersed evenly throughout the global system”. The documented increase in the exposure of other off-balance sheet activities in countries where extraterritoriality of swaps applies raises concerns about the sustainability of increased volumes in the concerned markets. Notwithstanding that futures are centrally cleared and standardized, which is certainly welcomed by regulators, huge increases in volumes may increase the systemic risk of central counterparties clearing houses (CCPs). Although this paper does not explicitly address those implications for financial stability, it highlights the importance of undertaking future research to better understand the significance of these shifts in the off-balance sheet activities of global banks. This paper builds on recent empirical literature examining the effects of the DFA on swap markets. This includes Loon and Zhong (2016), who investigate the effect of the DFA on transaction costs and liquidity in CDS markets and find an overall improvement in market liquidity since the outset of the reform. Benos et al. (2018) show that the OTC trade requirements implied by the DFA have improved liquidity across swap markets, using transaction data on plain vanilla IRS. Inferring the geographical location of traders, they also provide empirical evidence to support the fragmentation of swap markets resulting from traders being less willing to engage in transactions with US counterparties. While these two studies examine global transaction data, this paper focuses on the off-balance sheet exposure of US banks abroad. The results obtained by this change in perspective are particularly informative for US financial regulators, allowing us to single out the effect of the DFA on domestic institutions. This work, in particular, builds on the paper by D’Avino (2017) in which the effect of the extraterritoriality of the DFA on swaps exposure of foreign branches of US banks is evaluated for a number of geographical areas, including some jurisdictions in which substitute compliance was available. The present paper narrows the focus on the latter group of countries using an estimation technique that allows for policy evaluation. In addition, the results of D’Avino (2017) are extended by examining the effect of DFA on other off-balance sheet activities outside the extraterritorial scope of the DFA of US banks abroad in order to evaluate eventual cross-product exposure migration. This paper is also informed by a broader strand of literature on regulatory arbitrage by banks. Carbo-Valverde et al. (2012) and Karolyi and Taboada (2015) show that cross-border regulatory arbitrage explains the geographical pattern of banks’ merger and acquisitions activities. Using a large global panel of institutions, Houston et al. (2012) show that regulatory arbitrage explains banks’ cross-border flows toward countries with a resilient institutional environment. Cerutti et al. (2007) demonstrate that regulatory arbitrage helps to explain the type of legal entity that global banks (i.e., subsidiaries or affiliates) establish abroad with branches favored in jurisdictions with lower regulations. Acharya et al. (2009) argue that banks’ cross-border regulatory arbitrage stimulates risk-taking both domestically and in concerned foreign jurisdictions. The paper is structured as follows. Section 2 provides an overview of the off-balance sheet activities of foreign branches of US banks and discusses the implications of Title VII and of its extraterritorial reach. Section 3 presents our empirical methodology, the hypotheses tested and the results. Section 4 concludes.",1
56.0,2.0,Journal of Regulatory Economics,09 October 2019,https://link.springer.com/article/10.1007/s11149-019-09390-z,Voluntary climate action and credible regulatory threat: evidence from the carbon disclosure project,December 2019,Lily Hsueh,,,Female,Unknown,Unknown,Female,"Over 2000 companies from 145 countries representing close to $40 trillion USD in revenue—roughly equivalent to the combined GDPs of the U.S., China, Japan, and Germany—have pledged proactive climate action (Hsu et al. 2016), despite the fact that climate change mitigation or adaptation imposes substantial costs on firms. Proactive climate action by corporations is a case of industry self-regulation, which includes voluntary commitments to reduce greenhouse gas (GHG) emissions, increase energy efficiency, invest in renewable energy sources, and disclose information about carbon management, among other activities that go beyond the law. Unlike existing studies, this paper investigates both the extensive and intensive margins of industry self-regulation in the climate change area using a quasi-experimental research design to bolster causal claims. The empirical focus of this paper is voluntary carbon disclosure: Many businesses “talk a good game,” but under what conditions are they compelled to participate and participate at higher levels in carbon disclosure? This paper draws on the private provision of public goods, corporate social responsibility, and business management literatures to form hypotheses based on a rational political economy argument that there is a disparity in the willingness of companies to engage in voluntary climate action at different levels because of firm heterogeneity with respect to external political economy dynamics, firm management factors, and their interactions. In particular, this paper emphasizes the role of regulatory pressure—namely, the U.S. Environmental Protection Agency’s (EPA) introduction of the Clean Power Plan (CPP) (Section 111(d) of the Clean Air Act)—and its interaction with senior and executive management inside the firm in motivating voluntary carbon disclosure by businesses.Footnote 1 This paper argues and shows empirically that businesses will act preemptively in anticipation of a more stringent regulatory environment, and they will more likely do so, and at higher levels, when there are favorable management structures and practices involving the agency of corporate management. While existing research asserts that changing expectations about regulatory threats may be a mechanism for difficult-to-explain changes in prosocial environmental behavior, empirical evidence on the efficacy of firm management have been limited. Buchanan (1965) was the first scholar to define the joint provision of a public and private good as an “impure public good”. In the equilibrium, firms sometime produce a public good or an externality jointly with their main task of providing private goods or services for consumption. Given incomplete contracts, in the absence ex post bargaining frictions, a public good will be owned by the party that values the benefits generated by the related investments relatively more (Schmitz 2015; Andreoni and Kanbur 2007; Besley and Ghatak 2001; Hart and Moore 1990; Bergstrom et al. 1986). In this setup, Besley and Ghatak (2007) and Kitzmueller and Shimshack (2012) explicitly link the private provision of public goods to corporate social responsibility (CSR). According to Besley and Ghatak (2007), CSR is the corporate provision of public goods or curtailment of public bads independent of legal benchmarks. CSR has also been referred to in the literature as “industry self-regulation,” and as “corporate environmentalism” in the environmental area. CSR arises in a “political economy” context with imperfect and asymmetric information (Kitzmueller and Shimshack 2012). This theoretical framework presupposes a broader set of attitudes, preferences, and calculations for considering prosocial or altruistic behavior by firms or individuals (Bénabou and Tirole 2003, 2006; Besley and Ghatak 2005; Graff and Small 2005; Arora and Gangopadhyay 1995). It is in this framework of CSR, as it is linked to the standard treatment of the private provision of public goods, that this paper considers proactive climate action by firms. This paper’s empirical analysis is based on panel data of the Fortune Global 500 (henceforth, Global 500) firms’ participation in the CDP (formerly the Carbon Disclosure Project) and their level of carbon disclosure over the period 2011–2015. The CDP is an ideal case study for examining the extensive and intensive margins of industry self-regulation because, founded in 2000, the CDP is the oldest and largest nonprofit organization in the world that houses voluntary carbon disclosure by corporations (Winston 2010). At the behest of over 650 institutional investors with $87 trillion in assets, the CDP invites all Global 500 companies across industries to disclose their entity-wide plans for measuring, reporting, and reducing GHG emissions, including the adoption of science-based, quantitative emissions targets. To isolate the causal impact of regulatory pressure on corporations’ participation and intensity of participation in voluntary carbon disclosure, and the interaction between regulatory pressure and firm management, this paper employs a quasi-experimental research design: First, the difference-in-differences (DD) estimator is employed in the Ordinary Least Squares (OLS) framework to establish the causal link between regulatory pressure and the level of carbon disclosure. Second, the DD estimator and the difference-in-difference-in-differences (DDD) estimator are nested in a two-stage endogenous binary-variable (EBV) model. Unlike the extant literature, which typically models carbon disclosure as either a binary or continuous variable, this paper’s nested two-stage EBV model allows for correlation between the unobservables that affect a firm’s participation in voluntary carbon disclosure and the unobservables that affect the level of carbon disclosure. In doing so, this paper underscores that in order to fully understand, in an unbiased way, the drivers of higher level of participation, it is important to account for the non-random nature of participation in the first place, the factors of which are not often fully observed; this includes any learning-by-doing effects on the extent of carbon disclosure from prior year’s participation. A vector of controls, including corporate revenues, natural gas prices, and emissions targets are included. Sector and year fixed effects control for time invariant sector and time variant macro-economic and macro-political developments, respectively, in order to better isolate the effects of the CPP and the role of senior and executive management dedicated to climate change. Overall, this paper’s empirical findings show that once we account for the role of the agency of corporate management, regulatory pressure is a driver of both the extensive and intensive margins of voluntary carbon disclosure. By contrast, when firm management is not taken into account, the conventional DD models yield no statistically significant relationship between regulatory pressure and firms’ participation and the intensity of participation. According to the paper’s nested DDD estimator in the EBV model, during 2011–2015, U.S. companies were close to 10% more likely to participate in voluntary carbon disclosure than non-U.S. firms in response to EPA’s introduction of the CPP. In the post-CPP period, U.S. firms with an executive officer responsible for climate risks were close to 55% more likely to participate in the CDP than firms without one. Moreover, there is suggestive evidence that regardless of country of origin, companies that have installed in-house champions of climate change at the managerial and executive levels, notably those operating in GHG-intensive sectors (namely, energy, utilities, and materials), responded to the threat of impending climate change regulation in the U.S. by not only participating more but disclosing at higher levels (8–18 points out of 100 points) their existing practices and plans for managing climate change risks. The responsiveness of multinational companies towards a U.S. government promulgated rule was likely because the policy action by the EPA and President Obama’s related proclamations and activities about increased U.S. engagement on climate change, signaled during 2014 and 2015 the significant role that the U.S. would play in the Paris Climate Agreement.Footnote 2 The paper’s findings are robust to a series of alternative specifications, including a trimmed matching sample, the Heckman selection model, and sector-specific regressions.",10
57.0,1.0,Journal of Regulatory Economics,07 February 2020,https://link.springer.com/article/10.1007/s11149-020-09399-9,Restoring vision to consumers and competition to the marketplace: analyzing the effects of required prescription release,February 2020,Conor Norris,Edward J. Timmons,,Male,Male,Unknown,Male,"According to 2017 data on certifications and licenses published by the Bureau of Labor Statistics, more than 22% of employed Americans held an occupational license.Footnote 1 The Obama administration (White House 2015) documented the costs and benefits of occupational licensing and recommended that states weigh the costs and benefits of new regulations. In the Trump administration, both the Department of Labor and the Federal Trade Commission have voiced interest in promoting occupational licensing reform,Footnote 2 continuing the FTC’s longstanding interest in occupational licensing reform.Footnote 3 In the market for vision services, consumers may obtain eyeglasses or contact lenses from opticians, optometrists, or ophthalmologists. Consumers also generally have the option of purchasing eyeglasses and contact lenses from eye care professionals, brick and mortar retail stores, or online outlets. In 2004, landmark legislation titled The Fairness to Contact Lens Consumers Act (FCLCA) was passed that required vision service providers to release contact lens prescription information to patients. With this information, patients would have the ability to shop and compare prices for contact lenses. In 2016, bills were introduced that would allow providers the ability to stall the process and potentially block prescription sharing (de Rugy 2016). Both the House bill (H.R. 6157) and the Senate bill (S. 2777, The Contact Lens Consumer Health Protection Act of 2016) died in committee. The bills were presented as a means of promoting consumer safety and preventing fraud. One of the cosponsors of the Senate bill, Senator John Boozman of Arkansas, was an optometrist before assuming his Senate position. Using data from the US Census for 1990 and 2000 and American Community Survey (ACS) for 2001–2013, we estimated the effect that requiring providers to release prescription information to patients has had on the earnings of optometrists. We utilized a two-way fixed effects estimation strategy that takes advantage of state-to-state differences in policy on prescription release before the federal legislation. We also report triple-difference estimations including similar healthcare professionals in the sample to control for national trends in demand for healthcare services. We performed a simple placebo test using opticians as a control group. Our results suggest that requiring optometrists to release contact lens prescription information to patients is associated with as much as a 13% reduction in optometrists’ earnings. This result is consistent with reports in the existing occupational licensing literature that licensing laws provide professionals with an opportunity to extract economic rents. Our results should provide some guidance to policymakers on the potential negative implications of scaling back the FCLCA.",
57.0,1.0,Journal of Regulatory Economics,21 December 2019,https://link.springer.com/article/10.1007/s11149-019-09396-7,Operational risk management and regulatory investment constraints on portfolio allocation: evidence from property and casualty insurers,February 2020,M. Martin Boyer,Elicia P. Cowins,Willie D. Reddic,Unknown,Unknown,,Mix,,
57.0,1.0,Journal of Regulatory Economics,24 December 2019,https://link.springer.com/article/10.1007/s11149-019-09397-6,PV adoption: the role of distribution tariffs under net metering,February 2020,Axel Gautier,Julien Jacqmin,,Male,Male,Unknown,Male,"The traditional electricity system faces many challenges with the transition towards greener energy sources. New modes of production do not only have an impact at the production stage. A key issue for the distribution system operators (DSO) is to integrate distributed production units (DPU), like residential solar panels, that are connected to the low voltage grid. By installing solar panels, households do not only produce the green energy that they consume, they are also using the grid to make power exchanges. Indeed, a grid-connected DPU can import electricity when the production is insufficient to cover its consumption and export the excessive power when production exceeds consumption. Regulation of these exchanges is of prime importance to provide adequate incentives for investment and to ensure the financial viability of the distribution grid. The regulated grid tariff has to reconcile these two dimensions. There are different methods to price these power exchanges between a DPU and the grid. The two main systems to measure power exchanges with the grid are the net metering scheme where there is a single price for both imports and exports and a net purchasing scheme where the prices are differentiated. Several EU countries (like Denmark, Poland, Austria, Cyprus, Greece, Hungary, Latvia, Netherlands and Belgium) and 43 US States use a net metering system. From Brown and Sappington (2017a, b), Gautier et al. (2018), and Schittekatte et al. (2018), we know that net metering and net purchasing provide different incentives to invest in DPU and share the burden of network costs differently. Net metering has been criticized for providing inadequate incentives for investment in DPU, leading to overinvestment compared to the social optimum. Furthermore, the system fails to provide incentives for autoconsumption or storage. Following the suggestions from the European Commission (2015a) and the IEA (2014), some countries are phasing out their net metering system and switch to a net purchasing system. In a net metering system, the solar production is implicitly valued at the retail price of electricity. Consequently, the return on investment is higher in areas where the retail price is higher and we should expect a larger deployment of DPU in those places. Our objective is to measure this relationship. Currently, many authors, such as Cai et al. (2013) or Schittekatte et al. (2018), use simulation models to estimate the optimal grid tariff for the distribution grid, taking into account the impact on investments in DPU. Our paper provides an empirical estimation of the impact of the grid tariff on investment. Such an estimation is of prime importance as it can be used to better calibrate tariff simulators that provide enlightened recommandations to regulators. We use municipality-level data from 2008 to 2016 from the Walloon region, the southern region of Belgium. We focus on residential PV investments, which, as of today, have been done by close to \(10\%\) of the households. PV panels are integrated to the energy system via a net metering system. Hence, this electricity produced by the PV is valued at the retail price, which is made by about \(40\%\) of distribution tariffs, and the remaining \(60\%\) is composed of other, mostly commodity-related, costs and taxes. Our estimation strategy takes advantage of one peculiar institutional feature of Wallonia: Tariffs are set differently according to 13 different geographical zones, while other components of the retail price depend on market forces, policies and regulations impacting homogeneously the region. One key additional advantage of our setting is that the tariff-related part of the bill is almost fully dependent on the amount of electricity consumed. Hence, in this peculiar context, investing in PV helps reduce to close to zero an annual energy bill that for an average household would range between 700€ and 1100€ depending on the municipality where the household lives. These savings accrue for the lifetime of the PV installation and of the net metering system. Overall, using a two-way fixed effects model, we do find that higher energy prices due to the prevalence of higher consumption-based tariffs provide a significant incentive to invest in residential PVs. Using various estimation approaches taking advantage of our cross sectional and temporal variation in tariffs, we find that an increase in the distribution tariff by one eurocent per kWh leads to an increase of around \(8\%\) in the amount of new PVs installed yearly. Hence, regulated grid tariffs strongly influence the residential investment in solar PV. The determinants of the emergence of renewable energy sources in the energy system have already received much attention from the literature since the first analysis from Menz and Vachon (2006). Interests in investments in solar panels by residential households are much more recent.Footnote 1
Our analysis is directly linked to the literature looking at the effectiveness of the various policy implemented to boost PV adoption like up front subsidies and production subsidies. For example, Hughes and Podolefsky (2015) find using Californian data that upfront rebates have had a large and significant impact on residential PV adoption.Footnote 2 Using U.S. state-level data, Matisoff and Johnson (2017) study whether the presence of a net-metering policy, as measured by a dummy variable, has had an impact as well. They find that a net metering scheme, on a stand-alone base, is ineffective in encouraging households to invest in PVs. However, coupled with financial incentives, especially in the form of upfront cash incentives, net metering does have a positive and significant impact. Hence, financial incentives and net metering policies complement each others. We contribute to this literature by looking at a setting where a net metering system is generalized but where the generosity of the system varies with respect to the energy bill saving implied due to the heterogenous distribution tariffs in place.Footnote 3 Hence, our work is also closely linked with the one of Germeshausen (2018) who study, using German data, the impact of a feed-in tariff system where the generosity varies depending on the PV installation size. The paper is organized as follows. Section 2 provides a background of the energy sector in Wallonia, and more precisely about the policy context surrounding residential PV investments and tariff regulations. Section 3 discusses our empirical strategy while Sect. 4 presents the data. Our results are presented in Sect. 5. In Sect. 6, we conclude.",13
57.0,1.0,Journal of Regulatory Economics,20 February 2020,https://link.springer.com/article/10.1007/s11149-020-09400-5,Compliance and competition with heterogeneous service providers: the federal Lifeline program,February 2020,Thomas S. Conkling,,,Male,Unknown,Unknown,Male,"Many government benefits and services are provided through private markets, either by direct contract or subsidy. This arrangement is motivated by the idea that competition and industry expertise can reduce the costs of provision and improve outcomes. However, when oversight is imperfect, providers have an incentive to cut costs on compliance or other difficult-to-monitor aspects of service. Such non-compliance or waste can reduce the gains of privately provided services (Hart et al. 1997; Levin and Tadelis 2010). In markets where providers may vary in their compliance behavior, this paper asks whether enlarging the set of competing providers improves program outcomes. Within the context of the federal Lifeline program, I first document substantial variation in compliance across providers. I then estimate that while additional providers generally improve program outcomes, non-compliance weakens the competitive forces that could otherwise winnow out less productive providers. Since 1984, the Lifeline program has subsidized phone service for low-income households, traditionally through discounted monthly service sold by approved private providers.Footnote 1 Beginning in 2008, program enrollment expanded substantially as providers with a new business model offering free cell phone service were first approved. Annual program spending, after leveling off near $800 million prior to 2008, exceeded $2 billion by 2012. Alongside this growth came evidence of program rule violations—households received service for which they were ineligible.Footnote 2 By law, providers must determine eligibility before enrolling a household. The Federal Communications Commission (FCC) responded to evidence of these violations with its 2012 Reform Order, which required a one-time verification of all enrolled subscribers, removing ineligible households and households with multiple enrollments. The expansion and reform of Lifeline demonstrate policymakers’ competing goals: the program aims to provide service to as many eligible households as possible, while avoiding wasteful or inefficient spending on ineligible enrollments. The data in this study is particularly suited to studying the role of competing providers, as providers’ compliance with the eligibility rules and their program enrollments can be directly measured due to three key institutional features. First, both the enforcement of eligibility rules and the set of providers admitted varies at the state-level, as determined by state regulators. Second, providers compete to enroll subscribers across multiple separate state markets. Third, the 2012 federal reform removed ineligible subscribers nationwide, reducing program enrollment by 35%. In my primary empirical analysis, I document that compliance varies greatly across providers, and this across-provider variation is much larger than the within-provider variation observed across states. For example, several providers had over 80% of subscribers removed in every state they operated in, while others retained a majority of subscribers in every state. As a result, state-level differences in compliance are strongly influenced by the presence or absence of particular providers. The composition of providers in a market influences not only the level of compliance in a state, but also the number of eligible subscribers. States with more providers had both higher eligible enrollment and higher ineligible enrollment (lower compliance). This highlights the potential trade-off of competition and compliance: additional competing providers may bring more eligible enrollments, but also more waste. To estimate the balance of this trade-off, the second part of my empirical analysis uses the post-reform enrollment data to estimate a nested logit model of consumer demand, quantifying the substantial heterogeneity between firms in their ability to enroll eligible subscribers, and the degree to which additional providers increase total program enrollment. Based on the patterns of compliance revealed from the initial analysis, I then model and estimate how compliance behavior varies across firms and states using the drop in enrollments due to the reform. These estimates are combined to simulate the effects of simple counterfactuals restricting the number of providers admitted into each market. The results suggest that while additional providers take some market share from their competitors, they do improve program outcomes by increasing total eligible enrollments. However, as with compliance, individual providers’ ability to enroll eligible subscribers varies more across-firm than within-firm, with a minority of low compliance firms enrolling very few eligible subscribers in any market. Furthermore, these providers with few eligible enrollees and poor compliance appear to select into markets which, qualitatively, have looser enforcement and oversight of program rules. In the counterfactual simulations, excluding the lowest compliance providers reduces ineligible enrollments by 500,000, while only preventing 100,000 eligible enrollments. However, the balance of the trade-off depends on the compliance and service quality offered by the marginal admitted provider. Simulations further restricting the number of providers prevent additional ineligible enrollments, but these come at an increased cost as firms offering higher service quality—and the more numerous eligible enrollments these firms generate—are excluded. I provide a stylized model of these forces in Sect. 3.1. To profitably participate in a given state market, Lifeline providers must be able to enroll enough subscribers to cover their costs. Providers compete through advertising, outreach, and service quality to attract eligible potential subscribers. All else equal, additional competitors will lower the number of subscribers a given firm can enroll. This will require the heterogeneous firms to have some minimum productivity—which can be thought of as a combination of offered service quality, marketing ability, and costs—to operate.Footnote 3 Given imperfect enforcement, however, firms can reduce these competitive pressures through non-compliance, by enrolling additional ineligible customers and likely reducing operating costs. I contribute to previous work by providing empirical results showing how compliance behavior varies across firms and states, and how it affects program outcomes through the margin of firm participation.Footnote 4 Why don’t all firms cut costs on compliance and offer low quality service? Competition rewards firms for providing higher quality (Beard et al. 2015), which explains some of the story.Footnote 5 Additionally, more productive firms have a continued benefit of remaining in the market, since they can remain profitable even when non-compliance may be limited by more rigorous enforcement.Footnote 6 These incentives are in line with those highlighted in early literature on firm contracts and fraud, in which the expected benefit of the continued business relationship is the main deterrent to deviations from contracts (Darby and Karni 1973; Klein et al. 1978). Anecdotally, the largest providers participating in the Lifeline program (TracFone and Virgin Mobile) publicly advocated for stricter oversight of low compliance providers.Footnote 7 As long as profitable firms perceive some threat of removal or fines for non-compliance with program rules, they may generally adhere to higher standards. This incentive does not hold for less productive firms. For them, removal from the program or strict compliance with program rules both yield zero profits. A number of recent empirical papers have used government policy shifts to study aspects of the trade-off between competition and compliance in consumer-facing markets. Polsky et al. (2014) study state-level entry regulations in the home healthcare market, finding that regulated states have more concentrated markets, but that health outcomes do not differ substantially from those in unregulated states. The authors note the possibility that negative outcomes in a few unregulated states with anecdotal evidence of fraud may “cancel out” with any negative effects of reduced competition in regulated states. In a study of a disclosure enforcement change in consumer lending markets, Stango and Zinman (2011) find that looser enforcement increased price discrimination but also lowered overall prices, potentially due to an increase in supply and reduced compliance costs for providers.Footnote 8 These papers make note of possible provider heterogeneity in compliance, but unlike in the Lifeline program, they cannot observe it directly. Outside the context of government enforcement changes, recent empirical studies find evidence of heterogeneity in willingness to commit fraud by financial firms (Egan et al. 2019; Griffin and Maturana 2016) and restaurants (Luca and Zervas 2016). In line with the results of this paper, Egan et al. (2019) find that some firms specialize in hiring employees who were disciplined for violations in their prior employment, and Luca and Zervas (2016) find a negative correlation between a firm’s reputation and its willingness to commit fraud, as well as a higher incidence of fraud under increased competitive pressures. I contribute to and bridge these literatures by documenting variation in compliance across competing providers in the context of a government benefit program, and highlighting how oversight may be leveraged to improve outcomes. Finally, the patterns documented in this paper add to our understanding of competition and demand in the Lifeline program. Previous research has found that consumers are unlikely to have full information about the set of Lifeline services available, attributing low take-up rates during the pre-expansion period to lack of information, unstable living situations among eligible households, and preference for wireless phones (Burton et al. 2007; Hauge et al. 2007, 2008). Lifeline’s expansion to providers offering free wireless service increased enrollment substantially, reducing household expenditures on phone service (Conkling 2018) while only marginally increasing the share of the population with telephone access (Ukhaneva 2015). These findings may reflect the already high rates of telephone access prior to the expansion, alongside strong demand for wireless service and multiple phone lines within households (Macher et al. 2017). The estimates from this paper suggest additional admitted providers increase enrollment rates, consistent with consumers potentially learning of program offerings from the outreach of new providers. Given imperfect enforcement and a lack of out-of-pocket costs to consumers, providers may be seeking out consumers as much as consumers are seeking out services. In this context, competition is unlikely to be a substitute for oversight in deterring the participation of low compliance providers.Footnote 9 Given these conditions, restricting Lifeline participation to providers with ongoing business in the broader unsubsidized market—and thus a higher opportunity cost of non-compliance—may be warranted. Evidence of these dynamics is presented here for the Lifeline program, but this interplay between compliance and competition could be important in many markets. Similar incentives are likely to exist whenever the government pays the bill, firms compete to enroll customers, quality or prices are imperfectly known, and enforcement is costly. In the conclusion, I discuss parallels in markets for healthcare, education, and consumer financial services. Section 2 provides background on the Lifeline program and the data. Section 3 presents descriptive evidence on the importance of firm heterogeneity, the forces driving enrollment and compliance, and a stylized model. Based on this evidence, Sect. 4 lays out the estimation equations used to quantify demand and compliance. Section 5 presents and discusses the estimation results, and Sect. 6 simulates counterfactuals restricting the set of participating providers. Section 7 concludes.",
57.0,2.0,Journal of Regulatory Economics,12 March 2020,https://link.springer.com/article/10.1007/s11149-020-09402-3,"Fiber investment and access under uncertainty: long-term contracts, risk premia, and access options",April 2020,Marc Bourreau,Carlo Cambini,Ingo Vogelsang,Male,Male,Male,Male,"In many countries, including those of the European Union, owners of fixed telecommunications networks are obliged to give access to alternative operators providing competing retail services such as voice communications, broadband access and even subscription television. The pricing of this access is a thorny issue, and several different approaches have been used over time. The standard regulatory mechanism adopted by both the EU and other regulators worldwide is the “cost orientation” principle, according to which the access charge should fully cover access costs. Cost orientation can be seen as a natural obligation in cases involving access to an essential facility held by an incumbent operator, but its implementation might differ considerably. The most prominent method is the long-run incremental cost (LRIC) approach to define access charges. Since the mid-1990s it has been used widely by regulators, especially in the EU. This method has been very successful in generating low prices and creating service competition that allowed for some product differentiation. It worked well for legacy networks that required no or little new investment: Incumbents earned good returns and were shielded from expropriation tendencies of regulators, while maintaining retail market competition. Still, early on LRIC access charges were criticized as hindering investments in new, to-be-sunk networks, in particular in the presence of uncertainty about future demand and willingness to pay. The strongest advocate of this critique was Hausman (1997) based on the work of (his MIT colleague) Pindyck and others, who developed “real option” theory (see Dixit and Pindyck 1994; Pindyck 2007). Empirical evidence by many authors, surveyed first by Cambini and Jiang (2009); later by Briglauer et al. (2015), confirms Hausman’s conjecture. While these criticisms of the LRIC approach arose already when legacy copper networks were opened to access, they have gained a new urgency due to the perceived necessity of investment in dense fiber networks, in fiber-to-the-home and in increased capacity to serve the infrastructure for mobile broadband. Incentives for network coverage, while maintaining a suitable level of competition and entry, are now at the forefront of regulatory policy concerns as broadband markets face a rather slow transition from traditional copper to high-capacity fiber networks, even though these investments are considered essential for economic growth.Footnote 1 Indeed, the new EU regulatory framework for telecommunications of 2018 (EECC) explicitly introduces investment in ultra-fast coverage as an additional main policy goal besides enhanced competition, in order to achieve the European broadband coverage goals for 2020 and 2025 (European Commission 2010, 2016, respectively). As a result, regulators need to adapt existing network access schemes to simultaneously guarantee competition and network roll-out, in particular when future demand for high-capacity services is still quite uncertain. Hausman (1997, 1999) suggested additional mark-ups on LRIC prices (also called “risk premia”) as a remedy for the investment problem. We consider this proposal, as well as ex ante option payments for the right to buy access at LRIC without mark-up, and long-term contracts. Our goal is to contribute to the current policy debate about how to achieve sufficient network coverage in Europe, where LRIC access charges have been used in almost all countries and also where risk premia are being evaluated in order to provide incentives for investment in ultra-fast broadband networks. Therefore, in order to capture both goals of coverage and competition for the benefit of consumers, we concentrate on total coverage and entry thresholds as performance measures, while also keeping track of the effect of access schemes on consumer and total surplus. We analyze a model that focuses on geographic coverage of a next generation network, i. e., ultra-fast broadband based on fiber-optic technology. The incumbent firm chooses which areas to cover before knowing the level of demand. The latter becomes publicly known when the investment has been undertaken. Since entrants ask for access after demand is observed, they can cherry-pick the markets to enter, which in turn affects investment incentives. Different regions will need different types of access schemes, and thus we consider separately how well these schemes fare for each specific area that lacks coverage under standard access regulation. Standard access schemes make entrants pay by usage and let them choose when and where to enter. As pointed out by Hausman (1997) and others, this affords the entrants a free “access option”, i.e. the choice to only ask for access when demand turns out to be high. The option value arises by protecting the entrant against potential downsides, as discussed in the real-options literature. But what really matters for our purpose is the “option externality” imposed on the incumbent by the exercise of the entrant’s option, which consists in the curtailing of the incumbent’s returns if demand is high. It is this option externality that reduces the incumbent’s incentives for investment, and what we are investigating are different schemes to compensate the incumbent. The maximum coverage that can possibly be achieved, at least without government subsidies, is the coverage chosen by a monopolist: Entry and competition dissipate profits, and therefore, irrespectively of how investment costs are shared, total profits under competition cannot cover the investment cost for the most outlying areas. Therefore we take monopoly coverage as the benchmark. Second, the observed levels of demand for which the entrant asks for access in different areas depend on the access scheme. We characterize the minimum level of demand for which entry happens under the different access schemes. Our results are as follows: As a first extension to standard access charges we consider the imposition of an additional margin just set high enough to make the incumbent invest in uncovered areas. This can be understood as a risk premium that compensates the incumbent partially for the risk it is subjected to ex post by the uncertain entry decision. We find that this margin can be set at a level that both makes the incumbent invest and safeguards some (though less) entry. This margin increases with the level of investment cost, which raises retail prices and leads to lower consumer surplus compared to the case where area could have been covered without a risk premium. We then consider access options, which involve an up-front payment from the entrant to the incumbent plus access at standard rates ex post. We determine the minimum up-front payment that just makes the incumbent invest, and find that coverage can increase substantially as compared to standard access, while ex post market outcomes are not distorted. Still, due to profit dissipation full monopoly coverage cannot be achieved while maintaining entry. Finally, we look at long-term contracts, where the entrant commits ex ante to buying a certain wholesale quantity. While this type of contract reduces uncertainty for the investing firm, it has the drawback that ex post competition will be fiercer, reducing returns on investment and potentially even lowering coverage instead of increasing it. A key point of our analysis is that different types of access schemes need to be used in different types of areas. If the aim of the regulator is to guarantee coverage with a minimum distortion of the local retail market equilibrium, access options should be the first choice. Yet, these are not feasible in the most expensive and outlying areas. In the latter, it is necessary to increase the incumbent’s returns by adding a risk premium over the access charge. Any accompanying reduction in achievable surplus due to the risk premium will be limited to this specific area. The literature on access regulation is quite extensive (Vogelsang 2003), but it is scant when it comes to setting access charges in the presence of demand uncertainty. Authors in some early papers analyze the investment incentives in the presence of demand uncertainty with different forms of regulation and market competition. Guthrie et al. (2006) compare backward-looking (historical cost) vs forward-looking (current cost) access pricing rules under cost uncertainty with a decreasing trend. Similar to us they conclude that setting access prices ex post retards investment. Hori and Mizuno (2006) analyze the effect of access charges on firms’ (both incumbent and entrant) incentives to invest in a network facility with a stochastically growing demand. They show that in the presence of an increasing access charge, the incumbent may have the incentive to preempt the market and therefore invest first in areas where an entrant may find it profitable to invest, too. In a companion paper (Hori and Mizuno 2009), the authors compare the impact of facility based competition and service based competition on the incentive to invest in a new advanced network. They show that, when the monopoly rent due to uncertainty is large, the initial introduction of the new infrastructure is made earlier under facility-based competition than under service-based competition, while the opposite emerges when the degree of uncertainty and thus the monopoly rent is relative small. Note that these papers all assume that uncertainty never actually resolves, implying that the firms face the same uncertain future at every instant. This approach is different from ours since we assume that demand uncertainty resolves and access seekers might thus have an incentive to wait to reduce demand risk. 
Klumpp and Su (2010) are the first to consider a LRIC access pricing rule and its effect on (quality) investment. Under certainty, they show that the level of investment increases with the number of access seekers. Klumpp and Su (2015) acknowledge that this result is not robust and empirically show that in US electricity markets the opposite holds. They also consider forward-looking LRIC under demand uncertainty and conclude that access truncates returns in the good state, while in the bad state the incumbent is a monopolist if the investment cost is high. Contrary to the case of certainty, investment is lower than under monopoly if there are many entrants. 
Nitsche and Wiethaus (2011) compare different access pricing schemes. In particular, they compare LRIC access regulation and a risk sharing agreement—where the incumbent and the entrant operators decide to invest jointly (i.e. to co-invest) rather than individually. They show that risk sharing can lead to both stronger investment incentives and higher consumer welfare than standard LRIC access regulation. Their framework differs from ours in several important respects: First, they assume that investment increases quality, while we model and determine equilibrium coverage explicitly. Second, they assume guaranteed access to the copper network as the entrant’s outside option and only two demand states, while we consider a continuum of states and are therefore able to determine entry thresholds. Third, their ex post LRIC charge is determined retroactively as a function of realized (rather than expected equilibrium) quantities, which changes the strategic interaction and puts both incumbent and entrant in a symmetric position. We follow regulatory practice and assume that firms take the access charge as given when they choose their retail strategies, subjecting the entrant to a higher perceived marginal cost than the incumbent. 
Inderst and Peitz (2014) provide a high-level discussion of many (mostly unregulated) access schemes, listing their advantages and disadvantages. They consider mostly fixed fees including options, but also touch on usage-based prices and conclude that while the latter reduce competitive intensity (if above marginal cost) they increase incentives for investment as compared to fixed fees.Footnote 2 While they carefully model firms’ decisions both to invest in quality and to enter, they do not consider coverage as such, which is the important policy issue at the center of the present paper. Moreover, we provide a direct comparison of access schemes in the pursuit of this coverage goal. Using a similar coverage game, Bourreau et al. (2018) analyze co-investment schemes and show that the presence of uncertainty reduces total coverage. A recent companion paper, Bourreau et al. (2020), focuses on how to make entrants co-invest early rather than wait (e.g., in France first investors are required to allow later co-investment of other companies), using some related policy measures. These papers deal with the impact of co-investment arrangements on the incentives to invest in ultra-fast broadband networks but they do not consider explicitly the role of access regulation. 
Briglauer et al. (2015) and Abrardi and Cambini (2019) review the empirical literature and conclude that, while policy conclusions tend to be ambiguous, there is a strong indication that access obligations negatively affect investment incentives. In a recent empirical paper, Briglauer et al. (2018) study how access regulation of legacy and fiber networks affects the incentives to invest in ultra-fast broadband networks. They show that fiber access obligations lead to a large reduction of the incumbents’ investments.",2
57.0,2.0,Journal of Regulatory Economics,22 January 2020,https://link.springer.com/article/10.1007/s11149-019-09398-5,The effect of environmental enforcement on labor: environmental workers and production workers,April 2020,Zach Raff,Dietrich Earnhart,,Male,Male,Unknown,Male,"The relationship between environmental protection and employment has been the source of a lively debate amongst policymakers for some time. This debate has become increasingly contentious in today’s political climate, as environmental protection in general has come under attack. The empirical literature that informs policymakers has produced ambiguous conclusions and failed to distinguish between different types of employment, which undermines the usefulness of the conclusions. In this literature, almost all empirical studies find no effect (Berman and Bui 2001; Morgenstern et al. 2002; Ferris et al. 2014) or a negative effect (Greenstone 2002; Walker 2011; Sheriff et al. 2018) on the number of employees in an industry or at an individual facility as a result of environmental regulation. However, these studies only mention in passing the possibility that environmental regulation may impact different types of workers in different ways. To contribute to this policy debate, our study examines the effects of environmental regulation, specifically its enforcement, on labor employed by facilities regulated under environmental protection laws. Our study offers a richer assessment than previous studies by distinguishing between two types of labor: (1) labor dedicated to compliance with environmental regulations (“environmental labor”) and (2) labor dedicated to production (“production labor”). Environmental employees are professionally trained workers, such as wastewater treatment engineers, who engage in environmental management, which includes any method used by facilities to control pollution, e.g., environmental self-audits, end-of-pipe treatment technologies. In contrast, production employees engage in production activities, e.g., assembly, marketing, accounting. Environmental enforcement seeks to ensure compliance with environmental restrictions by prompting actions to reduce pollution levels.Footnote 1 However, environmental labor and production labor play different roles regarding the level of pollution at regulated facilities. While greater environmental labor improves environmental management and, by extension, environmental compliance, greater production labor generally stems from a higher production level, which increases the generation of pollution, thus reducing environmental compliance. This differential implies contrasting effects of environmental enforcement on environmental and production labor.Footnote 2,Footnote 3 Our exploration also contributes to a broader literature. Several studies explore the effect of environmental enforcement on regulated facilities’ environmental management, e.g., environmental employment, or environmental performance, e.g., pollution levels (Gray and Deily 1996; Shimshack and Ward 2005; Earnhart and Leonard 2013; Earnhart and Harrington 2014; Raff and Earnhart 2018). Other studies examine the effects of environmental enforcement on facilities’ operational choices, e.g., production, or financial outcomes, e.g., profitability (Rassier and Earnhart 2016). However, no previous study examines the effects of environmental enforcement on both environmental management and operational choices, such as production labor. As important, no previous study examines the effects of enforcement on production labor. Instead, previous studies exploiting disaggregated micro-level data on employment examine only environmental employment (Raff and Earnhart 2018, 2019).Footnote 4 Our study fills this void by examining the effects of Clean Water Act enforcement on labor employed by regulated facilities operating within the U.S. chemical manufacturing sector, while distinguishing between environmental labor and production labor, using data from an original survey.Footnote 5 Empirical results reveal that enforcement generally does not affect the amount of environmental labor employed at regulated facilities, while enforcement decreases the employment of production workers.",10
57.0,2.0,Journal of Regulatory Economics,06 March 2020,https://link.springer.com/article/10.1007/s11149-020-09401-4,The impact of regulatory review time on incremental and radical innovation: evidence from the high-risk medical device market,April 2020,Ilke Onur,Magnus Söderberg,,,Male,Unknown,Mix,,
57.0,2.0,Journal of Regulatory Economics,01 April 2020,https://link.springer.com/article/10.1007/s11149-020-09403-2,"Command-and-control regulation, incentive for pollution abatement, and market structure",April 2020,Ping Lin,Yu Pang,,,,Unknown,Mix,,
57.0,3.0,Journal of Regulatory Economics,13 June 2020,https://link.springer.com/article/10.1007/s11149-020-09405-0,Regulatory compliance under enforcement gaps,June 2020,Tihitina Andarge,Erik Lichtenberg,,Unknown,Male,Unknown,Male,"The effectiveness of regulation depends on the extent to which regulated firms comply, which depends in turn on how firms perceive the benefits and costs of compliance. Some of those benefits and costs are transmitted through markets, e.g., via changes in stock prices or reputational influences on demand for a firm’s products. Most of those benefits and costs, though, come from enforcement actions by regulatory agencies. Regulators typically have limited resources for enforcement but the literature to date has shown that even with those limitations a wide variety of instruments—including inspections, warnings, penalties, and sanctions—can be effective in inducing compliance (for reviews see Cohen 1999; Heyes 2000; Polinsky and Shavell 2007; Gray and Shimshack 2011; Shimshack 2014). One aspect of enforcement that has been largely overlooked in the literature to date is the fact that regulators may not know of all of the firms in an industry that are subject to regulation. A recent study by the United States Environmental Protection Agency’s (EPA’s) Office of Inspector General, for example, found significant gaps in the Agency’s enforcement arm’s knowledge of entities regulated under most major environmental legislation (USEPA 2005). The existence of such enforcement gaps should not be a surprise. Exit of old firms and entry of new ones is a standard feature of competitive economies. Turnover of firms is widely understood to be a key mechanism of the process of “creative destruction” driving innovation and growth. Keeping up to date on industry composition requires devoting regulatory resources to monitoring entry and exit. Updating registries of regulated firms may not be a priority in light of budgetary and personnel constraints. These enforcement gaps may be quite large, as changes in the composition of firms in an industry are quite common. Exit and entry rates in manufacturing, for instance, are 7–8% annually and the 5-year survival rate of new startups is only 55%. Exit and entry rates of mining firms are higher, around 11–12% annually, with a 5-year survival rate of startups correspondingly lower at only around 45%. Exit and entry are substantial even in agriculture, where the image of the family farm passed down through generations is a staple of public imagination: Exit and entry rates of farming, fishing, and forestry businesses run around 9% annually, with a 5-year survival rate of new startups around 65% (Bureau of Labor Statistics 2019; Deutsch 2017). Industry turnover tends to create gaps in regulators’ knowledge of the universe of firms subject to regulation. For example, in 2005, when the US EPA’s Office of Inspector General (OIG) compared current data with the official registry of regulated entities used by the Agency’s Office of Enforcement and Compliance Assurance (OECA), it found that the number of entities that ought to have been regulated under six major regulatory programs was 35% greater than the number in OECA’s database containing the universe of regulated entities under those programs (USEPA 2005).Footnote 1 A subsequent analysis of the Lead-Based Paint Renovation, Repair, and Painting Rule came to a similar conclusion (USEPA 2019). This paper conducts a theoretical and empirical analysis of a firm’s compliance strategy when such enforcement gaps are present. We develop a theoretical model of a firm’s compliance decision in a setting typical of regulations in a variety of health and safety contexts, including HACCP regulations governing food safety, quality of care in nursing facilities, workplace occupational safety, Affordable Care Act regulations governing health data security, and conservation compliance in agricultural subsidy programs (wetlands and highly erodible land protection requirements). These regulations depend heavily on record keeping. The compliance decision consists of two components: (1) developing a formal compliance protocol and (2) implementing and adhering to that compliance protocol. Determining whether a firm has developed a compliance protocol involves checking whether the firm has developed a set of written procedures that meet regulatory standards. Periodic inspections of firms’ records and facilities are then used to determine whether the firm has followed those protocols. Failure to comply with either component initially results in a warning, with subsequent violations resulting in fines. We show that in the absence of enforcement gaps (i.e., if the regulator has a complete census of the regulated industry), the firm’s optimal strategy will be to develop a compliance protocol but not implement it until inspected and warned. However, the optimal strategy for a firm believing it has a sufficiently low probability of being subject to enforcement will be to delay developing a protocol until warned and then delay implementation until being inspected and warned. We analyze the effect of enforcement gaps on the compliance protocol development component of regulations empirically in the context of the Maryland Water Quality Improvement Act of 1998 (WQIA). The WQIA requires farms meeting certain criteria to develop, file, and implement a nutrient management plan (NMP). The registry of farms used by the Maryland Department of Agriculture (MDA), which enforces this regulation, includes only a subset of the farm operations in Maryland that are required to comply with this regulation. Our econometric model indicates that the probability of being included in the MDA farm registry is associated with a statistically significant and economically meaningful increase in the probability of filing a NMP for farms required to have a NMP. This result is robust to a variety of specifications of the probability of inclusion in the MDA farm registry and the inclusion of covariates. Additionally, we present suggestive evidence that farms delay compliance with the implementation requirement of the WQIA until inspected and warned. The rest of the paper is organized as follows. Section 2 reviews the relevant literature. Section 3 presents a theoretical analysis of the impact of enforcement gaps on firm compliance strategy. Section 4 discusses the institutional background of the WQIA. Sections 5 and 6 present the data and econometric model used in the empirical analysis. Section 7 discusses the results of our econometric analysis. Section 8 concludes.",3
57.0,3.0,Journal of Regulatory Economics,19 June 2020,https://link.springer.com/article/10.1007/s11149-020-09408-x,The CMA’s assessment of customer detriment in the UK retail energy market,June 2020,Stephen Littlechild,,,Male,Unknown,Unknown,Male,"Following concerns about rising energy prices and about its own regulatory policy, the Office of Gas and Electricity Markets (Ofgem) in 2014 asked the Competition and Markets Authority (CMA) to review the UK energy market.Footnote 1 It specified five issues for particular examination, including “weak customer response”. In its Final Report, the CMA (2016) found “an overarching feature of weak customer response” in the domestic (i.e. residential) retail market which had an “adverse effect on competition”. This gave market power to the six large former-incumbent suppliers, enabling them to engage in price discrimination against less engaged customers (elsewhere called a “two-tier market” or a “loyalty penalty”) and to make excess profits and/or to operate inefficiently. The CMA’s “preferred estimate” of customer detriment in the form of higher prices was an average of £1.4 bn per year over 2012–2015, rising to almost £2 bn in 2015 (where £1 = US$1.33 in June 2016). On average, £1.4 bn represented 9% of the bill of a dual fuel customer. The CMA considered but rejected the remedy of a widespread price cap, and recommended instead that Ofgem should experiment with different ways of promoting greater customer engagement and switching. However, in a note of dissent, one member of the CMA panel recommended in addition a temporary widespread price cap because of the size of the customer detriment and the limited effectiveness to date of measures to promote customer engagement. After considerable political debate, often citing the magnitude of this detriment, in July 2018 the Tariff Cap Act required Ofgem to impose a cap on most domestic energy tariffs. Meanwhile, the CMA has since found “loyalty penalties” of £4 bn in other consumer markets and proposed various interventions there including the possibility of price controls. Several aspects of the CMA report and methodology have been critically appraised by the present author and others.Footnote 2 Given the impact that the CMA’s calculation of customer detriment has had on policy, the present paper seeks to better understand and appraise that calculation, in the context of previous investigations by UK competition authorities. Section 2 looks at how previous UK competition authority investigations of other markets, particularly the cement market, have used two different approaches (which the CMA called ‘direct’ and ‘indirect’) to estimate customer detriment. Section 3 examines the CMA’s preferred so-called ‘direct approach’, involving the characterisation of a ‘well-functioning retail energy market’ that it used as a benchmark against which it calculated customer detriment. The paper argues that the CMA’s benchmark was a long-run equilibrium concept inconsistent with the CMA’s own Guidelines, quite different from the method used earlier to calculate detriment in the cement market; it was also based on unrealistic assumptions. Section 4 explores some arguably more realistic assumptions about customer response and the costs and capacities of different suppliers, which suggest a much smaller detriment. Section 5 briefly examines the CMA’s ‘indirect approach’, showing that adding inefficient cost to excess profit, which previous investigations have not done, greatly increases the size of the detriment. Section 6 summarises the findings and raises some questions about the future conduct of CMA investigations. Further background on the UK energy sector, and discussion of the CMA’s ‘indirect approach’, are available elsewhere.Footnote 3",3
57.0,3.0,Journal of Regulatory Economics,11 June 2020,https://link.springer.com/article/10.1007/s11149-020-09407-y,The effects of stringent capital requirements on large financial institutions,June 2020,Asako Chiba,,,Female,Unknown,Unknown,Female,"Capital adequacy requirements have a long history and their importance in maintaining financial stability has been widely recognized. The first global capital standards considered by the Basel Committee of Banking Supervision in the early 1980s were intended to enable financial institutions to absorb losses from credit exposures. Theoretical justification for the introduction of capital requirements was provided by Kareken and Wallace (1978) and Sharpe (1978): given that under a deposit insurance scheme banks have an incentive to take excessive risk since they would be protected from the risk of bank run, they showed that such risk taking can be curtailed by imposing capital regulations on banks. However, recent comprehensive models have shown that capital regulations reduce banks’ credit supply (Dagher 2016). As noted in Kashyap et al. (2008), Brunnermeier et al. (2009), and other studies, during a crisis, banks subject to leverage restrictions have to sell assets due to difficulties in raising additional capital, leading to a credit crunch spiral. Reflecting the havoc wreaked by the global financial crisis a decade ago, regulatory reforms as well as theoretical work aimed at improving financial stability have been ongoing (see e.g., Duffie 2017 for an overview). In this context, given the growing size of the interbank financial market, one argument is that capital regulations for large wholesale banks should be more stringent than for small retail banks (Hanson et al. 2011). As highlighted by Borio (2011), the global financial crisis revealed the need to understand financial markets as a system composed of different types of intermediaries. Traditionally, banks have taken deposits from households and lent the funds to firms or individuals in the form of loans. However, with the spread of asset securitization, some banks have shifted their business from the conventional banking business to investment in securitized assets. Investment in securitized assets not only by banks but also via investment vehicles that hold assets and issue bonds backed by assets has been growing rapidly. Although not regarded as financial institutions, in practice such investment vehicles function as intermediaries in borrowing and lending. These developments mean that the wholesale business, which involves interbank lending and securitization, has become a major component of the banking sector, regardless of the legal form, suggesting that it should be treated differently from commercial banking business. All else being equal, capital requirements, as a fraction of either total assets or risk-adjusted assets, should be higher for larger banks (French et al. 2010). In particular, the latest version of the Basel Accord imposes high capital adequacy requirements on so-called “Systemically Important Financial Institutions” (SIFIs) and “Systemically Important Banks” (SIBs), which need to comply with strict capital requirements to ensure the functioning of the financial system. In 2016, the partial implementation of higher capital buffers for financial institutions judged to be systemically important began, and full implementation was planned to be achieved in 2019 (Financial Stability Board 2017). Yet, there seems to be little theoretical research explaining why supervisory authorities should impose stricter capital adequacy requirements on large influential banks than on small local banks. Examining developments in supervisory regimes around the world, Repullo and Suarez (2012) analyze the impact of risk-based capital requirements and show that they lower the probability of default in recessions and, on a net basis, improve welfare. In contrast, Slovik (2012) cautions that the strengthened risk-weighted capital regulations might force banks to increase their engagement in non-traditional business. He highlights that banks’ risk-weighted assets calculated on the basis of regulatory standards to their total assets have been decreasing over the past few decades. These existing studies mentioning the terms “systemic” and “systemically important” mainly focus on the risk of default, but from a practical perspective, the size and content of a bank’s business are more obvious and suitable variables for policy-makers to focus on when judging systemic risk. As Laeven et al. (2016) empirically show, size does matter for the systemic risk that individual financial institutions pose. These findings suggest that more attention should be paid to the heterogeneity in financial intermediaries when considering the effects of macroprudential regulation. Against this background, the present study seeks to investigate the effects of capital regulations that require large, influential banks to maintain higher capital-to-asset ratios than smaller banks. To this end, a model featuring perfect foresight in a general equilibrium setting following Gertler and Kiyotaki (2015) and Gertler et al. (2016) is employed. Gertler and Kiyotaki (2015) and Gertler et al. (2016) distinguish two types of banks in terms of their costs of asset management, which measure the proficiency in holding assets: banks with low asset costs, which become net borrowers in the interbank market, and banks with high asset costs, which become net lenders. In the steady state, net borrower banks hold more capital than net lender banks, because of this cost advantage. Thus, the model describes a banking sector composed of large net-borrower banks and small net-lender banks. Net borrower banks can be regarded as wholesale banks, because they finance their borrowings in the interbank market and purchase assets. On the other hand, net lender banks can be regarded as retail banks, because they issue deposits and lend to the other banks. Hereafter, the terms “large banks” and “wholesale banks” on the one hand and “small banks” and “retail banks” will be used interchangeably. The present paper introduces capital regulations in the form of an upper bound on the leverage that banks are allowed to assume. Moreover, the model assumes two types of bank runs. The first consists of run on wholesale banks, but retail banks continue to operate normally. In this case, retail banks choose to freeze interbank lending to wholesale banks, while households choose to maintain their deposits (Panel (a) in Fig. 1). The second type consists of a run on both wholesale and retail banks (Panel (b)). In this type of run, retail banks stop rolling over interbank lending and households withdraw their deposits from retail banks. Although one could think of another type of bank run in which only deposits freeze (Panel (c)), this is not considered here since it has been numerically shown that this type of run cannot occur. When measuring the degree of tightening of capital regulations on wholesale and retail banks, the analysis mostly focuses on the price of capital and the probability of the two types of bank run, since the issue of interest is the effects of capital regulations on both the real economy and the financial sector. The main results of the analysis can be summarized as follows.  When agents ignore the probability of a future bank-run, capital regulations on both wholesale and retail banks improve financial stability after a negative productivity shock but result in a slow recovery from the shock. More specifically, the capital regulations make a run on wholesale banks in which retail banks remain solvent impossible. On the other hand, although the probability is reduced by regulation, a run on both wholesale and retail banks is still possible. However, a side effect of capital regulation is that the recovery of the price of capital, output, and consumption in the wake of the assumed negative productivity shock will be slow. Since banks’ capital investment is limited due to the upper bound on the leverage they can assume, a large amount of capital is allocated to households, which are less proficient at asset management than banks, depressing the price of capital. When agents do not anticipate a future bank-run, imposing capital regulations only on wholesale banks has a similar stabilizing effect, but it involves a smaller degree of inefficiency than imposing regulations on both types of banks. When capital regulations are imposed only on wholesale banks, this makes a run on wholesale banks impossible; however, the possibility of a run on the banking sector as a whole still remains. However, compared to the case where capital regulations are imposed on both wholesalers and retailers, the fall in the price of capital and in output is smaller. The intuition is as follows: as capital regulations essentially can only eliminate a sudden stop in interbank lending, it is sufficient to regulate wholesale banks. The inclusion of retail banks in tight capital regulation cannot prevent the collapse of the entire interbank market and deposits; it only worsens the economic slump without reducing the probability of a bank run. When agents anticipate a future bank-run, capital regulations targeting both wholesalers and retailers decrease stability. The reason is that a large drop in asset prices reduces expectations that wholesale banks will be able to meet their obligations. In contrast, imposing capital regulations only on wholesale banks improves stability, even if agents take into account the probability of a future bank-run. The reason is that the stabilizing effects of leverage restrictions lead to a moderate drop in asset prices, which enhances wholesale banks’ expected recovery rate. In addition to the two regimes, i.e., capital regulations on both wholesale and retail banks, and capital regulations on wholesale banks only, the paper also tests a regime in which capital regulations are imposed on retail banks only, even though such regulations are unlikely to be implemented in practice. The simulation results for this regime are similar to those for capital regulations on both types of banks: under perfect foresight, where agents rationally expect bank runs in the future, such regulations lead to a deterioration in financial stability. The results provide theoretical support for the recent regulatory reforms imposing tighter capital regulations on large influential banks than on smaller local banks. One thing to be noted is that the assessment of the different regulatory regimes does not consider the distortion of incentives if agents expect that the government might intervene. In the debate regarding financial regulation, one aspect that has gained considerable attention is the too-big-to-fail (TBTF) issue. This debate focuses on how to guarantee financial stability in a situation where banks have an incentive to take on large leverage in the expectation that they will be bailed out by the government in case of a crisis (Chari and Kehoe 2016). The present paper takes a different approach from the TBTF literature in that it examines how financial regulation affects the banking sector and the real economy once a recession has started. More specifically, the analysis provides a more detailed understanding of possible strategies to mitigate the TBTF problem. That is, the model presented in this paper shows that in equilibrium wholesale banks never suffer a run when capital regulations are imposed only on them. This finding suggests that appropriately designed capital regulation can have beneficial social outcomes in the presence of TBTF banks. While the concept of TBTF banks was previously understood at a broad level, the analysis here models those banks as large, influential wholesale banks and distinguishes them from retail banks. Moreover, the finding suggests that capital regulations targeting SIFIs contribute to reducing the TBTF problem. Equally importantly, by showing that the social benefit is reduced when capital regulations are expanded to include retail banks, the finding highlights that “more is not always better” in the design and application of financial stability measures. Three types of default",1
57.0,3.0,Journal of Regulatory Economics,06 June 2020,https://link.springer.com/article/10.1007/s11149-020-09406-z,The regulation of merchant fees in credit card markets,June 2020,Hongru Tan,,,Unknown,Unknown,Unknown,Unknown,,
57.0,3.0,Journal of Regulatory Economics,22 May 2020,https://link.springer.com/article/10.1007/s11149-020-09404-1,Correction to: What can deregulators deregulate? The case of electricity,June 2020,Tin Cheuk Leung,Kwok Ping Tsang,Kevin K. Tsui,,Unknown,Male,Mix,,
58.0,1.0,Journal of Regulatory Economics,30 July 2020,https://link.springer.com/article/10.1007/s11149-020-09412-1,Does electricity competition work for residential consumers? Evidence from demand models for default and competitive residential electricity services,August 2020,Agustin J. Ros,,,Male,Unknown,Unknown,Male,"In the United States, retail electricity competition has been operating in more than a dozen states since the late 1990s. These states embarked on significant reforms of their electricity sector including divesting electricity generation from transmission and distribution, transferring operational control of transmission to Independent System Operators and permitting retail electricity customers—residential, commercial and industrial—to choose (“retail choice”) a competitive retail electricity provider (“REP”) to supply them with competitive generation and retail electricity services. To date, there have been a number of studies examining whether retail choice has resulted in economic efficiency gains through lower prices than would otherwise have been the case—i.e., improvements in allocative efficiencies—and whether retail choice has resulted in improvements in service quality, innovation and overall dynamic efficiency—Ros (2017), Su (2015), Swadley and Yucel (2011), Kwoka (2008), Joskow (2006) and Zarnikau and Whitworth (2006). In my opinion, a consensus seems to have emerged from that literature and from the market—retail choice has worked reasonably well and is achieving economic efficiency gains for the larger customer classes. In fact, in the more than a dozen retail choice states, there are few examples of policymakers seriously questioning whether retail choice for the larger customer classes should be eliminated or severely constrained, nor is it likely, in my opinion, that such policy proposals would have a serious chance of passing in state legislatures. There is no consensus, however, for whether retail choice has “worked” and is achieving economic efficiency gains for residential and smaller commercial classes of customers. As I show in the review of the literature below, the economic evidence on the effects of retail competition on the residential customer class is mixed and some states have attempted to restrict and even eliminate residential retail choice altogether. In New York, for example, retail choice for residential customers has been under investigation since 2012 with policymakers examining whether it has produced sufficient benefits and whether it has actually been harmful to consumers. Indeed, in 2016 policymakers in New York restricted REPs from serving low-income customers, and required that REP prices be at least as low as those offered by the regulated distribution utility through the regulated default service—also known as the standard offer service—or provide at least 30% renewable electricity.Footnote 1 In 2019, the Massachusetts Attorney General’s Office published a report criticizing retail choice for residential customers by showing that customers served by REPs paid significantly more for generation service than if they had remained on the regulated default service and recommended the elimination of REP service to all residential customers.Footnote 2 There are additional examples throughout the retail choice states of policymakers contemplating and showing an interest in scaling back or even eliminating retail choice for residential customers. At the heart of policymakers’ critiques of residential retail choice is the belief that many residential customers have overpaid for REP service and would have been better off—presumably from a utility-maximizing perspective—by staying on the regulated default or standard offer service offered by the incumbent distribution utility. The default and standard offer services are energy supply services that the incumbent distribution offers in competition with REP services but at rates that are regulated and thus acts as a backstop for consumers if the competitive offerings are not providing sufficient value to the consumer. The motivation for this paper is to investigate empirically a question that implicitly arises in the investigations and conclusions reached by policymakers that REP customers overpay for electricity service: why would a rational, utility-maximizing consumer consistently pay a higher price for an identical service? An implicit argument that policymakers who seek to constrain or eliminate retail choice for residential consumers are making is that residential electricity consumers are not making rational, cost-minimizing choices, and they would be better off remaining on the regulated default service. This seems like a logical conclusion of these policymakers’ beliefs given that some are calling for a complete elimination of residential electricity competition and not just calling for reforms and modifications to remove whatever market failures and imperfections may exist while allowing the continuation of residential retail choice for those customers who believe they have benefitted from it. In order to empirically assess this issue, I estimate demand models for the regulated default and the competitive REP services. My default and REP service demand models examine and test whether residential electricity customers in one state in particular, Illinois, are acting in a manner that is in accordance with standard consumer demand theory and behavior and to estimate demand parameters and compare and contrast them to those in the literature, especially the own and cross price elasticity of demand. To do so, I use publicly available data from Illinois to create a monthly panel data from 2011 to 2017 and estimate demand models for default and REP services and obtain parameters for the main determinants of demand such as deflated price and deflated income, heating degree-days, cooling degree-days, and other important control variables. Importantly, the data permit for an examination of residential electricity competition and consumer behavior and decision-making. Specifically, I examine residential electricity consumer behavior and estimate the strength of competition between the REP and default services by estimating cross-price elasticities of demand which provides information on how sensitive the demand for REP services is to the default service price and vice versa. I also have data on the number of Community Choice Aggregation (“CCAs”), a form of retail electricity competition that occurs when a city or municipality decides to procure energy on behalf of its citizens, either on an opt-in basis or an opt-out basis. I use these data as well in my demand models and examine the impact that CCAs have had to date on the demand for default service usage, default service customers and REP customers. The paper proceeds as follows. Section 2 discusses the key elements of retail competition in those states that permit competition and highlights the two models of competition that have emerged—the “Texas model” and the “Default Service model”. This section also discusses another form of retail competition that has emerged, the CCA model, whereby residential consumers are signed up for a competing generation service by their city or municipality. Section 2 also summarizes the analysis and methodology of policymakers comparing the regulated default service price and the REP prices and points out some alternative explanations for observed price differences and policy implications. Section 3 provides a review of the literature on electricity demand and summarizes the main results of the price and income elasticity literature of electricity demand as well as a review of the literature on the effects of residential retail electricity competition. Section 4 presents background information on the econometric model and hypotheses to be tested while Sect. 5 presents a description of the data and sources, the econometric models and specifications and the model results. Section 6 presents conclusions and highlights areas for further research.",5
58.0,1.0,Journal of Regulatory Economics,16 July 2020,https://link.springer.com/article/10.1007/s11149-020-09410-3,Banning information in hiring decisions,August 2020,Anthony M. Marino,,,Male,Unknown,Unknown,Male,"Employers gather a host of information when screening job applicants and when promoting existing employees. Information that organizations might desire to collect in such inquiries includes but is not limited to criminal records, checks of social media and internet postings, credit records, drug test results, salary history, past employment history, past workers compensation claims, education history, military records, court records, character references and property ownership. Technology has allowed organizations to access much of this data at low monetary and time costs. Previous to laws limiting access to such data, many firms screening job applicants conducted background checks which collected much of this information on prospective employees. In the last decade, Federal, State and local laws have limited both the access to and the use of many of the above types of information. For example, the “ban the box” (BTB) movement calls for employers to delay viewing data on criminal records until late in the hiring process. As of April 2018, 31 states, the District of Columbia and over 150 cities adopted ban the box policies.Footnote 1 Moreover, 11 states passed laws limiting the use of credit reports in job screening.Footnote 2 Further, as of 2016, 28 states limited or were considering limiting the ability of potential employers to ask for passwords to private social media accounts.Footnote 3 Ten states and 8 localities prohibited hiring firms from asking for the salary history of job applicants.Footnote 4 Law makers in New York State are considering legislation to prohibit pre-employment testing for marijuana use.Footnote 5 Some of these laws are motivated by the unequal undesirable effects that information acquisition has on different groups of people, the social cost of unemployed workers, or the privacy rights of individuals. In any case, there is a clear trend towards banning information in the job application process. There is a growing empirical literature which focuses on the effects of such information banning on labor markets. The key hypothesis in these papers is that if the government bans the use of one type of information such as criminal record or credit score for job applicants, then the firm will use correlated non-banned information to try to guess whether the applicant has an undesirable characteristic (e.g., a criminal record or a bad credit rating). If the firm really believes that the latter characteristics decrease the marginal valuation of the worker, then the firm will avoid hiring workers who they think have the bad characteristic. Unfortunately, workers who have these characteristics are the intended beneficiaries of the banning legislation. Many papers have documented such unintended consequences of the banning laws. Agan and Starr (2017) use a field study to show that banning criminal records causes discrimination because employers believe that black applicants are more likely to have criminal records. After banning, black applicants were shown to receive significantly less call backs for interviews. Likewise, Doleac and Hansen (2016) demonstrate that there is a decrease in employment in young low skill black and Hispanic men after criminal record banning. Sabia et al. (2018) show that BTB laws also increase certain types of crimes, demonstrating negative spillover effects from BTB. In addition to the results documenting the unintended consequences of BTB laws, Bartik and Nelson (2016) show that credit history bans (CB) greatly reduced job finding rates and increased job separation rates for blacks. Ballance et al. (2016) also find that minorities are hurt relatively by credit history bans. Cortes et al. (2016) show that credit score bans increase vacancy rates and that they do so more in districts in which subprime individuals reside. In addition, as in Sabia et al. (2018), they show that credit information banning results in more delinquencies among subprime borrowers. That is, a negative spillover, just as in the BTB cases. The BTB empirical papers have focused on the effects of the BTB laws on minority groups and the negative spillover effects on crime. The CB papers have documented bad effects on overall vacancy rates as well as the deleterious effects on employment of minorities. As in the BTB, papers negative feedback on credit scores has also been verified. For the most part, the banning literature has concentrated on the effects of the ban on the group with an undesirable characteristic being banned.Footnote 6 In each of these categories of bans, there are constituents outside those with the banned undesirable characteristic who are affected by the bans. Our paper will contribute to literature on information bans by characterizing the effects on all parties affected by a ban. In particular, we will study the effects of information banning on (i) those workers with a given set of observable characteristics under the ban; (ii) those workers who have a given set of observable characteristics but have the bad banned characteristic; (iii) those workers who have a given set of observable characteristics but have the good banned characteristic; (iv) a firm hiring a worker with the bad banned characteristic; and (v) a firm hiring a worker with the good banned characteristic. For workers, we will determine the effects of the ban on utility, employment, and the wage. For firms, we will examine profit. The effect of the ban on total surplus will be considered, and we will provide a simple model of negative spillover as documented in Sabia et al. (2018) and Cortes et al. (2016). The banning equilibrium will then be compared on all of the above dimensions to the alternative policy of subsidizing firms for hiring workers with the undesirable characteristic. We develop a very simple microeconomic model which is used to outline the key effects of information banning and then compare these to the effects of an alternative monetary incentive policy. We adopt the approach of considering a complete ban on one dimension of information as opposed to considering a partial ban with limitations on the use of that information. Further, we abstract from the central assumptions of the vast statistical discrimination literature (For example, including, but not limited to, the static papers by Arrow (1973), Phelps (1972), Aigner and Cain (1977) and the newer dynamic literature Kim and Loury (2018)) and assume that the firm knows the characteristics of the potential worker in the absence of banning. Uncertainty about certain characteristics arises, because the government bans the organization from gathering information on these characteristics. Thus, it is the banning of information that can cause statistical discrimination in this paper. Whereas, in the previous literature, it is the inability of firms to perfectly see prospective worker characteristics which can cause statistical discrimination.Footnote 7 The core pooling results induced by the banning of information will then be analogous to those of the statistical discrimination literature, but our examination of the micro distributional effects on different agents (firms and workers), when banning is compared to full information, will provide new insights. We take this approach because we want start with a clean slate and isolate the pure effects of banning relative to a full information solution, and we wish to compare the effects of this deliberate government policy, without other distortions, to the effects of a policy of directly subsidizing firms hiring those with the undesirable characteristic. We also use this pure approach to analyze the feedback effects of information banning on the behavior of workers with an undesirable characteristic and how this feedback affects the firm’s assessment of productivity. The main setting is a competitive labor market where each worker type has a unique productivity in the eyes of the firm. The only distortions will be those imposed by the government’s information banning. Worker type is identified as a vector of two characteristics and such characteristics help determine the optimal allocation of each labor type. We consider the competitive equilibrium in a labor market where the firm has full information on worker type and contrast that equilibrium with one in which the government bans information on some one of the characteristics that determine type. With a ban on the observation of one characteristic, perfect information is replaced with the firm’s expectation regarding type, conditional on the observable characteristic. Because the typical firm must now pool labor types in making decisions, allocative inefficiency results. We consider two cases regarding the observable characteristic. In the first case, the observable characteristic does not affect the worker’s productivity in the eyes of the firm and, in the second, it does. An example of the first case is the situation where membership in a minority group versus majority group is observable and information on possession of a criminal record is banned. Under empirically documented assumptions, we show that the following key results hold.  Relative to the full information solution, the ban decreases total surplus, profit and utility of minority and majority groups. In minority and non-minority groups, the ban increases utility, wages and employment of workers with criminal records, and it decreases utility, wages and employment for those without records, relative to full information. The ban gives equal skill non-minority workers greater utility than minority workers. A firm hiring a worker with a criminal record is better off under full information relative to the ban, whereas a firm hiring a worker without a record can be better or worse off under full information relative to the ban. Under the ban, ex ante expected employment of each of minority or majority groups can be less or greater than expected employment of that group without the ban, depending on specified sufficiency conditions. Key results for the second case where the observable characteristic (skill) does affect productivity are similar. Results (ii) are analogous to those of the statistical discrimination literature, and, along with (i), these point out that while information banning serves the policy goal of improving the lot of types with an undesirable characteristic, there is a trade-off between this improvement and allocative inefficiency. Results (iii) through (v) give new insight into the distributional effects of a ban. In particular result (v) says that if the ban has the objective of improving the expected employment of a group with the same observable characteristic (say a minority group), it surprisingly may not achieve that goal. We show in an “Appendix” that all of these basic results for a competitive market carry over to the case where the hiring firm is a monopsony. Next, we consider a rationale for regulation stemming from the observation that the government and the firm may disagree on the firm’s marginal value of workers with an undesirable characteristic. The firm employs its perception of the worker’s true marginal private value in hiring, and such use results in less employment than the government would like for workers with the undesirable characteristic. The government attaches a greater marginal valuation to such workers, due to the high social cost caused by the underemployment of these workers. An information ban on the undesirable characteristic increases the marginal valuation of undesirable workers by moving their valuation to the average. However, it also lowers the marginal valuation of those workers with the good characteristic. Using the banning equilibrium as a benchmark, we consider, as an alternative, a direct subsidy for workers with the undesirable characteristic along with full information.Footnote 8 The subsidy raises the marginal valuation of workers with the undesirable characteristic to the average valuation, without affecting the marginal valuation of workers with the desirable characteristic. This scheme has the advantage of directly increasing the firm’s valuation of undesirable types while not decreasing the marginal valuation of desirable workers. However, there is a trade off, because this benefit comes with the cost of funding the direct subsidy, whereas the ban involves negligible cost in comparison. Funding of the subsidy is accomplished with a nondistortionary lump-sum tax on firms hiring workers of the desirable types. We compare total surplus and the distribution of total surplus at each of these regulated solutions in order to determine whether to ban or to directly subsidize. In a final analysis section, we consider the case where the ban has negative feedback into the firm’s assessment of worker productivities. This situation can arise where banning information on a bad type can increase the gain from that type of worker engaging in bad behavior. This effect then has, in turn, an adverse impact on the firm’s assessment of the productivities of workers with the bad characteristic. Such feedback is shown to exacerbate all of the above undesirable implications and diminish the desirable implications of the ban. Section 2 presents the model and analyzes the social optimum with perfect information on the part of the firm. Section 3 presents the results on the banning equilibria. Section 4 discusses the alternative policies of banning information versus implementing a direct subsidy. Section 5 considers the case where bans cause changes in perceived productivities in the eyes of firms. Section 6 concludes.",
58.0,1.0,Journal of Regulatory Economics,16 June 2020,https://link.springer.com/article/10.1007/s11149-020-09409-w,Effect of public procurement regulation on competition and cost-effectiveness,August 2020,Bedri Kamil Onur Tas,,,Male,Unknown,Unknown,Male,"Effective public procurement is essential for the productive use of public resources and economic growth. The World Bank (2012) emphasizes that “… poor governance of public procurement systems can turn public investments into major political and economic liabilities, hinder development goals and outcomes, and result in additional costs and waste public funds” (Page 7). Wittig (2002) states that improved management of public procurement systems leads to benefits such as enhanced competition, better administrative services, and cost-effectiveness. Although policymakers and researchers (Campos and Sanjay 2007; Knack et al. 2017) promote improved public procurement regulation, empirical research about the effect of public procurement quality on economic outcomes is limited. In this paper, I examine the impact of public procurement quality on competition for tenders and the cost-effectiveness of contracts awarded. The Tenders Electronic Daily (TED) dataset of the European Union (EU) contains information on 5,303,219 public procurement contracts for the European Economic Area, Switzerland, and the Former Yugoslav Republic of Macedonia during 2006–2017. The cross-country structure of the TED dataset allows identification of the effect of public procurement regulation quality. I employ measures of public procurement regulation quality compiled by the World Bank in its Benchmarking Public Procurement (BPP) database, and by EuroPAM, a data collection effort that assesses the transparency of public administration. Specifically, I investigate the effect of public procurement quality measures on the level of competition, the procurement method used, and the cost-effectiveness of procurement contract awards in European public procurement processes. The measures of regulatory quality used from the BPP dataset are the bid preparation score, the bid and contract management score, an indicator of the timeliness of payment of suppliers, and the overall BPP index. EuroPAM reports the procurement evaluation, open competition, institutional arrangements, and overall country scores. The empirical analyses find that the number of bidders is significantly higher for countries with higher public procurement quality scores; countries with better procurement regulation are more likely to implement the competitive (open) procurement procedure; and cost effectiveness improves substantially as the public procurement score of a country rises. A closely related strand of literature investigates the effect of public procurement practices on firm-level characteristics. Hoekman and Sanfilippo (2018) use a surveyFootnote 1 of 6700 firms based in 19 Sub-Saharan African countries to investigate the effect of “the share of total sales to the Government” on firm performance. They find that higher government demand enhances firm performance. Djankov et al. (2017) show that better public procurement regulation promotes the quality of trade and transport infrastructure. They employ the Logistics Performance Index of the World Bank based on a survey of 1000 logistics professionals in 143 countries to measure road quality. Knack et al. (Knack et al. 2017) examine the survey answers of 33,385 firms from the World Bank Enterprise Survey (WBES). They find that the probability that a firm participates in public procurement is higher in countries with more transparent procurement procedures. Additionally, the percentage of kickbacks to officials is significantly lower in countries with better regulation quality. Finally, Ghossein et al. (2018) combine BPP and WBES to examine public procurement quality on firm-level outcomes. They find that better quality is correlated with higher firm engagement, innovation, and internet connectivity. Several studies use the cross-country dimension of the TED dataset to study cross-border procurement. Kutlina-Dimitrova and Lakatos (2016) analyze the determinants of the probability of directly awarding cross-border public procurement contracts by using a multivariate logit model. Gourdon and Messent (2017) show that a country’s membership of the WTO Government Procurement Agreement (GPA) increases the probability of firms being awarded a procurement contract in the EU through the cross-border mode of supply. Herz and Varela-Irimia (2017) employ a gravity model to study cross-national border effects in the award of European Single Market (ESM) public contracts. The remainder of this paper is organized as follows. Section 2 describes the theoretical motivation. Section 3 summarizes the EU TED and public procurement regulation data. Section 4 examines the effect of public procurement quality on the level of competition, procurement procedure, and cost-effectiveness. Finally, Sect. 5 concludes the paper.",7
58.0,1.0,Journal of Regulatory Economics,23 July 2020,https://link.springer.com/article/10.1007/s11149-020-09411-2,TOTEX Malmquist index for CPI-X regulation: Does it correctly estimate the true frontier shift?,August 2020,Roland Meyer,Gert Brunekreeft,George Elias,Male,Male,Male,Male,"The basic formula of price-based monopoly regulation is known as CPI-X (Littlechild 1983). This type of regulation aims to set efficiency incentives by decoupling output prices temporarily from actual cost levels of the regulated firms. During a predefined regulatory period, prices or revenues are adjusted yearly according to CPI-X. While the first term, the consumer price index CPI, is published in official statistics, the critical task for the regulator is to determine X. But what is X and how can it be accurately measured? CPI-X-regulation aims to mimic competition (Bernstein and Sappington 1999): the zero-profit condition requires that the change in regulated prices is equal to the change in input price minus the change in total factor productivity. The main important point of X is the estimate of the expected productivity increase: the frontier shift.Footnote 1 A common regulatory practice to calculate the productivity changes relies on Törnqvist quantity indices (Törnqvist 1936; Coelli et al. 2005), while the input price changes are determined separately based on statistical price index data. The weakness of the Törnqvist index, however, is that it cannot distinguish between a frontier shift and catch-up effects. The former reflects the change in productivity, and the latter captures changes in technical or allocative efficiency of individual firms as compared to the efficiency frontier. If some firms have increased their efficiency over time—which CPI-X aims to achieve—the Törnqvist index will overestimate the past productivity change and thereby impose an excessive productivity target for the near future. As an alternative, the Malmquist index (Malmquist 1953; Coelli et al. 2005) precisely addresses this distinction between frontier shift and catch-up effects by applying benchmarking techniques like data envelopment analysis. The Malmquist index is a well-established method that is used in various forms for productivity analysis but is rarely utilized for monopoly regulation in practice.Footnote 2 In order to apply the Malmquist index, regulators can make use of the data collected in the cost reviews. However, availability and quality of these data differ, and regulators typically lack specific information on input prices and quantities but only have total cost data (TOTEX). In this case, neither the traditional production Malmquist index (Malmquist 1953), nor the cost Malmquist index (Maniadakis and Thanassoulis 2004) will be unbiased. This paper examines whether and how the Malmquist index can be usefully applied in setting the X-factor in CPI-X regulation of a monopoly. For this purpose, a TOTEX Malmquist indexFootnote 3 will we derived that can be applied in cases the regulator only has TOTEX information. We analyse the theoretical accuracy of the TOTEX Malmquist index in determining the productivity and input price change in combination. Which information on the frontier shift gets lost, if we do not have input price and quantity data but only TOTEX? We identify two sets of assumptions under which no biases occur. The first case addresses technical and allocative inefficiency. The TOTEX Malmquist index is undistorted if the efficiency frontier is set by firms which are either technically and allocatively efficient in both periods or if inefficiencies of these frontier firms stay constant over time. The second case considers firms facing different input prices. The TOTEX Malmquist index is undistorted if input prices either stay constant or change by the same proportion for all firms. The remainder of this paper is organized as follows. Section 2 reviews the economic target of price-based regulation and derives the relevant components of CPI-X. The analysis shows that the term CPI-X is theoretically equivalent to the (unobserved) efficient cost change of a regulated firm. Section 3 defines and explains the three variants of the Malmquist index: while the production Malmquist index only measures the technical frontier shift, the cost Malmquist index captures the cost frontier shift, which is exactly the efficient cost change representing CPI-X. Lastly, the TOTEX Malmquist approximates the cost frontier shift. Section 4 analyses the accuracy of the TOTEX Malmquist and derives assumptions, under which it is unbiased. Section 5 concludes.",
58.0,2.0,Journal of Regulatory Economics,26 August 2020,https://link.springer.com/article/10.1007/s11149-020-09413-0,Does locational marginal pricing impact generation investment location decisions? An analysis of Texas’s wholesale electricity market,December 2020,David P. Brown,Jay Zarnikau,Chi-Keung Woo,Male,Male,Unknown,Male,"A fundamental component of a restructured electricity market is the establishment of competitive prices. Real-time market clearing price formation is especially important for the electricity industry because of the inability to store electricity at low-cost, the need to instantaneously balance supply and demand, and the high outage costs associated with supply shortfalls. Wholesale electricity trading at locational marginal prices (LMPs) based on real-time marginal costs of generation that account for the network’s physical and operational constraints has been a long-standing foundation of competitive electricity markets (Schweppe et al. 1988). LMPs are commonly used in restructured markets in the United States (FERC 2014). Absent transmission congestion, line-loss adjusted LMPs converge across all nodes within a jurisdiction. When there is congestion, however, low-cost energy cannot freely flow to high-cost nodes, thus elevating the LMPs at these nodes. The theoretical benefits of LMPs are well-established (Schweppe et al. 1988; Baughman et al. 1997). In addition, there are numerous empirical studies that evaluate the benefits of transitioning from postage or zonal pricing to the more granular nodal pricing, including Texas (CRA 2008; Zarnikau et al. 2014), England and Wales (Green 2007), Pennsylvania-Jersey-Maryland (PJM) Interconnection (Synapse Energy Economics 2006), and New York (Tierney and Kahn 2007).Footnote 1 These studies primarily focus on the cost savings from reduced congestion, improved dispatch of resources, reduced operation reserve requirement, and increased trading. Another often cited benefit of nodal pricing is its price signals for generation investment location decisions (Schweppe et al. 1988; Green 2007). While this idea has been widely accepted, there is limited empirical evidence to support the hypothesis that generators tend to locate in electric network pockets with high nodal prices.Footnote 2 We test this hypothesis using detailed LMP data and recent generation investment decisions in Texas’s wholesale electricity market. Texas is an ideal testing ground because of its energy-only market design under which power plant investment incentives are mainly energy-price-based sans centralized capacity markets that now exist in PJM, New York, and New England (Spees et al. 2013) or procurement auctions that occur under California’s resource adequacy requirement (Woo et al. 2016). Our analysis is made possible by the 15-min real-time market (RTM) nodal price data from the Electric Reliability Council of Texas (ERCOT) for the period 2011–2019 and data from the Energy Information Administration (EIA) on all constructed and planned generation capacity investments in ERCOT since 2011. We focus on investment in wind, natural gas, and solar technologies that constitute most of the observed investments. We carry out three empirical tests to evaluate the relationship between LMPs and generation investment location decisions. First, we decompose observed generation investment into various pricing tiers based on lagged nodal prices to assess whether new investments arise in regions that have experienced higher LMPs prior to entry, thus informing if LMPs signal investment location decisions. Second, we compare LMPs at nodes with and without recent nearby entry to investigate if new generation resources receive a price premium post-entry. If generators locate in a region in response to the expectation of higher LMPs, nodes with nearby entry should have higher RTM prices post-entry than nodes without recent nearby entry. Third, we use an illustrative two-stage investment model and its related regression analysis to test if firms are more likely to locate in a region with higher expected LMP levels. The investment model’s second stage assumes a generation investor forecasts each node’s RTM prices that impact a new plant’s expected operating profits. The first stage assumes the investor decides the plant’s most profitable location based on the RTM price forecast. To evaluate if this relationship is empirically significant, we estimate a binary logit model to explain the probability of generation capacity investment at a particular node as a function of expected forward-looking RTM price levels. Our three key findings are as follows. First, while RTM prices have been declining, we observe substantial investment in wind (20,000 + MWs) and natural gas (14,000 + MWs) capacity over our sample period. Further, we document increased price dispersion across nodes starting in 2014, suggesting rising opportunities for LMP-driven investment location decisions. Using descriptive statistics, we find some evidence that generation resources tend to locate near nodes with higher average LMPs in recent years. However, we also find the lowest two price quartiles have more new capacity than the highest two price quartiles. Second, nodes with nearby entry do not offer a price premium post-entry compared to nodes that have not observed recent nearby entry. In certain model specifications, we instead find statistically significant lower average LMPs at nodes with recent nearby entry of large combined cycle gas turbines (CCGTs), reflecting a large capacity addition’s suppression of post-entry LMPs. Third, our logit regression results find limited consistent and statistically significant evidence that new resources locate to target higher average nodal prices. In particular, location decisions for combustion turbines (CTs) are related to higher average LMPs in the peak hours. However, these results are sensitive to the model specification and of minimal economic significance. Large CCGTs are more likely to locate near major transmission lines with nodes that have more stable LMPs. Investment locations of wind and solar are mainly driven by other factors such as renewable resource potential, rather than being driven to target higher expected nodal prices. When taken together, our key findings form limited evidence that expected LMPs are a primary driver of investment location decisions of large-scale generation assets. This is understandable because a generation investment’s location is a complex long-run decision shaped by additional factors such as site availability, transmission access, interconnection costs, fuel availability or renewable resource potential, etc. Further, nodal prices are volatile and may decline after the entry of a large power plant, making it difficult for a new power plant’s long-term financing and profitability to be based on the expectation of higher nodal prices. Our paper proceeds as follows. Section 2 describes Texas’s wholesale electricity market. Section 3 presents the data used in our empirical analysis detailed in Sect. 4. Section 5 presents our empirics. Section 6 concludes.",12
58.0,2.0,Journal of Regulatory Economics,29 August 2020,https://link.springer.com/article/10.1007/s11149-020-09414-z,Competition under revenue-cap regulation with efficiency benchmarking: tariff related incentives for gas transmission system operators in merged markets,December 2020,Jann T. Keller,Gerard H. Kuper,Machiel Mulder,Male,Male,Male,Male,"According to economic theory, the absence of effective competition requires regulation of natural monopolies. Such monopolists are often infrastructure operators. In gas markets, transmission and distribution networks are natural monopolies, and hence they are regulated. Transmissions networks, operated by transmissions system operators (hereafter: TSOs), connect all major players and infrastructures of gas markets. Therefore, they are the backbone of gas markets that facilitate wholesale markets.Footnote 1 In Europe, there are gas market areas organised as so-called entry-exit systems, which also allows for cross-border trade. To reduce barriers to trade, and to increase wholesale market liquidity and competition, several European gas markets have already merged with more mergers to be expected. Market mergers facilitate market integration. Barriers, like tariffs, between markets disappear, so that single markets are joined to become one market, resulting in a single price on the wholesale market for gas (ACER and CEER 2015). Besides the impact on wholesale markets, market mergers can also have an impact on the behaviour of gas TSOs. If, after a merger of market areas, two TSOs operating in the same market area are both connected to another adjacent market area, network users obtain transport alternatives; network users must choose between different TSOs (Keller et al. 2019). Thus, market mergers may imply inter-TSO competition. However, such a competition may only be possible if the demand side makes its choices efficiently. Keller et al. (2019) analysed the efficiency of network users’ booking capacity and found their booking behaviour is sensitive to differences tariffs. Price-sensitive booking behaviour is a prerequisite for inter-TSO competition. However, it is not a sufficient condition for inter-TSO competition. Since TSOs are regulated entities, the possibilities, and the incentives to engage in tariff competition, are determined by the regulatory regime applied. Therefore, it is necessary to analyse how TSOs in merged market areas set tariffs assuming efficient booking behaviour on the demand side, and considering the regulatory regime applied. The literature describes several regulatory regimes applied to energy networks, which differ in the incentive power, and the level of profits allowed (Arcos-Vargas et al. 2017). Armstrong and Sappington (2006) examine how to introduce competition in regulated industries and find that an optimal liberalisation process highly depends on the institutional setting. In the case of the liberalisation of the British gas market, they show that allowing for competition in regulated industries often refers to activities such as production and supply of utilities, and not directly to infrastructure competition. Vogelsang (2002) assesses the competitive role of price-cap regulation and horizontal competition and concludes that price-caps allow for regulation cum competition given the flexibility they offer in setting prices for regulated output of a firm. However, the presence of (potential) competitors is required to introduce competition to a monopolist, which requires a contestable market and free market entry (Baumol 1982). Cave (2004, 2014) examines potential competition between an integrated incumbent owning telecommunication networks and new entrants. Laffont and Tirole (1996) claim a duplication of a network, noting that this is associated with high costs, may be justified as it may allow for competition. Studies and research intending to contribute explicitly to the future of tariff regulation in European gas markets do not take into account the role of market mergers with regard to the potential for inter-TSO competition on tariffs (Cervigni et al. 2019; EY and REKK 2018; Hecking 2015). Our paper extends the literature on (de-)regulation of natural monopolists. Our focus is on the impact of market mergers on inter-TSO competition on tariffs. We contribute to the future of tariff regulation in European gas markets, but unlike other work the potential competition arises from merging markets with regulated monopolists and does not arise from unregulated new entrants into market. This paper investigates tariff related incentives for TSOs that are regulated by a revenue-cap regime, which is the most common regulatory regime applied in European gas markets. In that case, TSOs may face competition because of market mergers. The first step in the investigation is the theoretical analysis of incentives for TSOs setting their tariffs considering market mergers. Next, it explores empirically whether regulated TSOs in Germany, who operate under a revenue-cap regulation and have experienced several market mergers, consider the presence of other TSOs in setting their tariffs. According to theory, TSOs operating under revenue-cap regulation have an incentive to change tariffs to maximise profits. However, the incentive is not based on capping the maximum revenues but is due to efficiency benchmarking. The result of efficiency benchmarking, i.e. the efficiency score, is influenced by a TSO’s level of capacity bookings.Footnote 2 As the efficiency score is considered by the regulator determining the allowed revenues, ultimately the level of capacity bookings impacts the TSO’s revenues and profits. To obtain higher capacity bookings, a TSO has the incentive to charge lower tariffs. In an unmerged market, TSOs compete by reducing their costs per unit of output compared to their peer group. In a merged market, TSOs have an additional incentive as they also compete directly for the same demand at borders where more than one TSO offers capacity. Therefore, we expect lower tariffs at network points at borders where different TSOs offer capacity compared to borders where only one TSO offers capacity. We test this hypothesis by applying a panel data analysis to tariffs charged between 2015 and 2018 at German border points by German TSOs that operate under a revenue-cap regulation with efficiency benchmarking. In line with our hypothesis, we find that the tariffs are up to 52% lower in case more than one TSO offers capacity at a border. An additional sensitivity analysis shows that this result is robust to a differentiation between transit and meshed networks. Hence, we conclude that German TSOs, operating in merged markets, and under a revenue-cap regime with efficiency benchmarking, have an incentive to reduce tariffs at competitive network points, where they compete for demand. Our empirical analysis confirms TSO act accordingly. Following this introduction, the paper describes in Sect. 2 how European gas markets are designed, how transmission networks are commercially operated, and how market mergers affect gas markets and market players and ends with describing the principles of tariff regulation. Section 3 continues with the theoretical framework analysing tariff related incentives for TSOs under a revenue-cap regulation also considering market mergers. In Sect. 4, we present our empirical model, the data used to test our hypothesis, and the results obtained. Section 5 concludes with summarising the main results and discussing the implications for further research and regulation.",1
58.0,2.0,Journal of Regulatory Economics,09 September 2020,https://link.springer.com/article/10.1007/s11149-020-09415-y,Self-regulation versus government regulation: an externality view,December 2020,Chang Ma,,,,Unknown,Unknown,Mix,,
58.0,2.0,Journal of Regulatory Economics,01 October 2020,https://link.springer.com/article/10.1007/s11149-020-09416-x,An alternative to natural monopoly,December 2020,Oriol Carbonell-Nicolau,,,Male,Unknown,Unknown,Male,"According to a standard argument within the neoclassical economics tradition, an exclusive franchise to serve a market should be granted to a single firm in the presence of decreasing average costs of production (or, more generally, subadditive costs)—a situation commonly known as the case of a natural monopoly.Footnote 1 This argument has undoubtedly contributed to the growing concentration of market power observed in the U.S. over the last forty years.Footnote 2 Traditionally, the case for natural monopolies has focused on the potential welfare gains derived from low production costs at large-scale output levels from a sole vendor.Footnote 3 Using a different approach, this paper makes a case against natural monopolies, based on the observation that decentralized choices under a joint ownership rule are welfare improving. While we abstract from institutional details on the implementation of shared ownership—and focus instead on its effects—some authors have suggested similar arrangements of local public ownership. For example, Ostrom (2010) advocates so-called “polycentric governance” as a way to escape the market-state dichotomy, emphasizing community-governed common-pool resources. Comparing private, community, and state governed common-pool resources, Grafton (2000) finds that “a common factor in ensuring successful governance of common-pool resources is the active participation of resource users in the management of the flow of benefits from the resource.” Some authors have argued that privatization of public utilities transfers public value to private interests, whose profit motive is not necessarily aligned with the needs of a broad base of customers.Footnote 4 These and other considerations have led some to propose alternative structures for utility companies aimed at strengthening local public ownership, giving power back to communities (see, e.g., Milburn and Russell 2019). But perhaps the best example of joint ownership is that of a cooperative. The unique organizational structure of cooperatives ensures a more equitable distribution of resources and, at the same time, prioritizes social value over pure profit maximization and growth (see, e.g., Cato 2012; Cumbers 2012).Footnote 5 Some authors (e.g., Lamoreaux et al. 2004; Brown 2004) have also described cooperatives as catalyzers of productivity and innovation. In our setting, when consumers share ownership of the monopoly, they recognize the effect of their consumption choices on the value of the ownership shares. We first consider a sharing rule for which the “effective” price paid by each consumer/owner for each unit of output (i.e., the unit price net of the consumer’s ownership share of profits) is precisely the average production cost. In the presence of decreasing average costs, this generates an externality whereby each agent benefits from her own consumption—both in terms of a direct utility effect and an indirect effect acting on the price—as well as from the other agents’ consumption, via the price effect. Because consumers internalize the effect of their consumption on the price, the joint ownership rule improves welfare relative to the standard monopoly allocation. However, since, in the neoclassical framework, consumers care only about their own utility, they do not take account of the benefits other consumers derive from a lower price. Consequently, the shared ownership arrangement does not generally achieve the first best. Nevertheless, alternative joint ownership rules for which the “effective” price (net of profit ownership shares) lies below the average cost of production mitigate the externality problem and lead to a welfare improvement. In some cases, the “effective” price schedule coincides with the marginal cost function, and the resulting output allocation is efficient. The property rights approach to the problem of natural monopoly consists in conducting an ex-ante bidding competition to award an exclusive franchise to serve the market (see, e.g., Demsetz 1968). We comment on the (tangential) relationship between this approach and the analysis in this paper at the end of Sect. 2.",
58.0,2.0,Journal of Regulatory Economics,15 October 2020,https://link.springer.com/article/10.1007/s11149-020-09417-w,Has the affordable care act affected health care efficiency?,December 2020,Russ Kashian,Nicholas Lovett,Yuhan Xue,Male,Male,Unknown,Male,"American per capita health care expenditures are the highest of all OECD countries, with mean per capita expenditures of nearly $8000, while Norway, the next highest OECD country by expenditures, averaged only $5300.Footnote 1 Despite spending so heavily, American health care outcomes are often viewed as mediocre, with OECD data reporting a US ranking of 26th in life expectancy and 31st in infant mortality. At the heart of many criticisms is the assertion that American health care systems are inherently inefficient with as much as 30% of spending, or 5% of GDP, essentially wasted (Fisher et al. 2009; Cutler 2010). In the face of these apparent disparities between spending and health outcomes, there have been considerable efforts and reforms that have sought to improve health care outcomes, access, and efficiency. Paramount among these reforms was the Affordable Care Act (ACA), which has considerably altered American health care, and fundamentally changed the regulatory landscape in which health care choices are made. Throughout the proposal, passage, implementation and aftermath of the ACA, its efficacy has been actively debated, with a host of different conclusions that stem from a variety of different perspectives. It is within the context of state-level differences and passage of the ACA that this study contributes to, and informs, the debate revolving around inefficiencies in American health care. The analysis seeks to further inform active research and policy communities, as well as to assess the efficiency impacts of the ACA across, and between states. Additionally, the analysis allows researchers and policy makers to consider differing regulatory environments and approaches to health care, and also to explicitly recognize that simple comparisons of health care outcomes across states overlook considerable variation in health care inputs. A Stochastic Frontier Analysis (SFA) framework is used to generate efficiency estimates from the perspectives of both technical and cost efficiency. This is accomplished by parsing state-level data representing a wide array of health inputs and outputs to compute efficiency scores for all 50 states, as well as the District of Columbia. This approach builds on an extensive body of SFA research where efficiencies are modeled at area-levels. Within the context of health care efficiency, Hollingsworth and Wildman (2003), Greene (2004, (2005a), and Kathuria and Sankar (2005) have studied geography-based efficiency differences in health care systems, and our study builds on this literature.Footnote 2 These efficiency estimates allow policy makers to more deeply understand how efficiency has varied over time with the implementation of the ACA. In addition to the main efficiency score results surrounding passage of the ACA, the efficiency scores are also leveraged to carry out a difference-in-difference (DID) analysis of the Medicaid expansion that was funded by the ACA. Doing so allows for a greater understanding of the expansion’s effect on health care efficiency, and sheds light on the efficiency effects of expanding health care access to large numbers of low-income Americans. The results are informative and potentially relevant to vibrant debates regarding optimal health care policy in the United States. The results of the analysis provide meaningful contributions to health care researchers and policy makers. First, results indicate that since the ACA’s inception measures of technical efficiency for state health care systems have increased, while measures of cost efficiency have declined. Second, the ACA has led to state-level convergence in technical efficiency. Prior to the ACA, state-level differences in technical efficiency scores were larger than in the post-ACA landscape. Third, results indicate that Medicaid expansion led to a deterioration in cost efficiency scores, but likely led to increased measures of technical efficiency. Finally, findings indicate that the Medicaid expansion led to convergence across states with respect to technical efficiency scores, but resulted in a divergence with respect to cost efficiency scores. Our paper proceeds as follows. Section 2 provides relevant background information regarding the ACA and efficiency, Sect. 3 discusses the data, Sect. 4 motivates a state-level study and presents the methodology, Sect. 5 reveals results and findings, Sect. 6 considers robustness, while Sect. 7 concludes.",1
59.0,1.0,Journal of Regulatory Economics,23 November 2020,https://link.springer.com/article/10.1007/s11149-020-09418-9,Loyalty taxes in retail electricity markets: not as they seem?,February 2021,Bruce Mountain,Kelly Burns,,Male,,Unknown,Mix,,
59.0,1.0,Journal of Regulatory Economics,05 January 2021,https://link.springer.com/article/10.1007/s11149-020-09423-y,Cost efficiency and endogenous regulatory choices: evidence from the transport industry in France,February 2021,Joanna Piechucka,,,Female,Unknown,Unknown,Female,"In the last decades, the European market has experienced several episodes of deregulation. In this respect, in many industries, competition for the market is increasingly used by public authorities. Once the ‘best’ operator is selected via a competitive bidding procedure, the key question is how to design good regulatory rules. Determining the impact of different regulatory designs on the cost efficiency of operators responsible for providing a public service is an important issue, with public procurement currently representing 14% of EU GDP (see EC 2017). While there are studies attempting to tackle this issue, they often ignore the endogeneity of contractual choices. Comparing different regulatory designs without taking into account that contracts are not necessarily randomly assigned may lead to false conclusions. The objective of this study is to assess the impact of different contractual choices (fixed-price versus cost-plus) on cost efficiency by exploiting data from the French urban public transport industry. The distinctive feature of our study is that it addresses the endogeneity of contractual arrangements, by accounting for economic, institutional, and political issues put forward in the literature related to the design of regulatory contracts. Thus, the approach leans on a positive analysis to study the determinants of regulatory contract choices, which, in turn, affects the costs of operating urban public transport. While our paper is closely related to Gagnepain and Ivaldi (2017), it focuses on a more comprehensive and sophisticated analysis of the role of political aspects. Following a reduced form approach, we do not rely on (often unstable) structural assumptions. We also consider a more flexible representation of operators’ costs and cover a more up-to-date and extended database covering the years 1995–2010. To our knowledge, there has been no papers that allow a more up-to-date assessment od the industry. The French urban public transport industry is particularly well suited for this study. In France, local public authorities are responsible for organizing urban public transport in their respective regions by defining, financing, and organizing regular public passenger transport within its urban network (composed of a city or group of cities). Each authority is given the choice to organize and provide the service itself or to delegate the relevant responsibilities to a transport operator (90% of networks, see GART 2015). The key feature of the French model is that the operation of the network is attributed to only one operator. The selected operator has the responsibility of providing the relevant service across the whole transport area throughout the duration of the contract. The relationship between the operator and the local authority is then regulated through an agreement. Regulatory contracts observed in the industry can be classified into two main categories: cost-plus and fixed-price. The choice of regulation translates into the division of risk-taking between the contracting parties (see Laffont and Tirole 1993), thus potentially affecting the cost efficiency of local transport operators. The characteristics of the industry also seem to suggest that contracts may not necessarily be randomly assigned. The organizing authorities are politicians representing the municipal council elected for approximately a six year period. The municipal council is governed by the mayor and has the legislative authority to manage the affairs of the municipality through its decisions. In this context, local authorities responsible for organizing transport services may be interested in re-election and, thus, will undertake actions to maximize political support favoring votes or campaign contributions in the next election. Those who leave the government may attempt to find high-level jobs in the industry they were previously responsible for regulating. Further, contractual choices may be explained by actions undertaken to prevent opportunistic behavior by their opponents. The opportunistic behavior could be understood as an action undertaken by the political opponent exposing or accusing the public manager to bad management with the purpose of replacing this opponent (see Moszoro and Spiller 2019). In line with this, the public manager, subject to elections, may increase the rigidity of a contract (opt for a fixed-price rather than cost-plus contract), the fiercer the electoral competition. In addition, most operators belong to major groups that may want to maximize profits aggressively and, therefore, may have a preference for fixed-price contracts. These operators may be willing to affect the regulatory decision in favor of their preferred contract. The French model of regulation, combining competitive tendering with negotiation, gives room for subjective selection criteria. Thereby, operators seem to have significant bargaining power when facing the regulator. Taking into account the characteristics of the actors involved in providing the service seems to be of particular importance when studying the French urban transport industry. From a methodological standpoint, the industry is a good field for studying contractual choices and their impact on cost efficiency, as we can easily exploit variations in the conditions across local networks. First, we observe many local authorities making decisions about service provision at different points in time. These transport networks differ in a variety of interesting ways—by contract type in place, financial conditions, complexity, transport group to which the local operator belongs to, political color of local authority, etc. Second, contracts typically last seven to eight years. Consequently, when conducting an analysis of 1995 to 2010, we will observe several contractual periods for each network. Understanding the rationale underlying regulatory choices in the industry that, in turn, affect the operating costs of the networks is of particular importance. In 2015, the financing needs of urban transport in France amounted to 8.9 billion Euros (see GART 2015). At the same time, the industry is facing strong financial constraints. While the industry has seen a significant increase in the supply of transport, this is not accompanied by a sufficiently strong demand for its services. As a result, the ratio of commercial receipts to operating costs is deteriorating. This situation further reinforces the need to improve the management of these services. The contribution of the study to the existing literature is twofold. First, it analyzes the cost efficiency of transport operators as a function of regulatory schemes. There are few empirical papers analyzing the impact of regulatory schemes on cost efficiencies in the transport network (Gagnepain and Ivaldi 2002b; Piacenza 2006; Gautier and Yvrande-Billon 2013). However, these studies do not take into account that contracts are not necessarily randomly assigned, thus leading to potentially false conclusions. Secondly, and most importantly, it addresses the gap in the literature with respect to the endogeneity of regulatory contract types that is, to our knowledge, extremely scarce and limited to few industries. Guasch et al. (2007) introduce an original instrumental variable strategy to address contract endogeneity in their study of government-led renegotiations in infrastructure concession contracts in Latin America. In explaining contractual choices, they include, among others, political and institutional factors, such as the degree of political capture of specific regulatory institutions, the tradition to expropriate investments in certain sectors, and political culture leading to different degrees of political interference with state-operators interactions. They also consider operator-specific variables, including the strategic skills of a firm to renegotiate contract clauses or the propensity to incur strategic underbidding and renegotiate later on. Chong et al. (2006) account for the endogeneity of organizational choices taken by local authorities on the performance of water services in France. They introduce a switching regressions model to account for the organizational choice of the local authority between direct public management and lease contracts. Their results show that local public authorities do not make their organizational choices randomly. Gagnepain and Ivaldi (2017) build a structural model of political regulation, including social and private concerns that the regulator has when choosing a regulatory scheme. In their model, the regulator is not only concerned by social welfare, but is also incentivized by the possibility of being elected or re-elected. Therefore, it may account in its decision of contract type for the profit of the operator and/or the wage of operator’s workers. The operator’s choice of cost-reducing effort level conditional on the contract it faces is also described by the model. Other empirical studies concentrate on the determinants of organizational choices, without assessing its impact on costs. For instance, Levin and Tadelis (2010) study the drivers of US city government privatization decisions, suggesting an important role played not only by economic efficiency concerns, but also by politics. Among others, they find that cities run by mayors are less likely to privatize services than cities run by appointed managers. Further, cities with higher ratios of long-term debt to revenue privatize more than those with lower levels of debt. In this respect, they argue that high debt levels constrain political opportunism and force city governments to focus on costs. State laws are shown to also affect the privatization decision. This is in line with the study of de Silanes et al. (1997), which shows state clean-government laws and state laws restricting county spending encourage privatization, while strong public unions discourage it. Finally, Duso (2005) focuses on the effects and determinants of price regulation on the US mobile phone industry and provides empirical evidence that the choice of regulatory regime strongly depends on political as well as regulatory environments. The existing literature clearly suggests that contractual and organizational choices are not random. In our study, we assess the impact of contractual choices on cost efficiency by considering that regulatory choices are endogenously determined decisions. While a full welfare analysis is beyond the scope of this article, our findings allow us to assess whether the move toward fixed-price contracts observed in the industry is justified in order to recover efficiency. Furthermore, we are able to identify the determinants of regulatory choices and directly test the bias associated to treating contracts as randomly assigned. The paper is organized as follows. Section 2 describes the French urban public industry in France. In particular, the organizational background and the types of regulatory schemes observed in the industry are discussed. Section 3 introduces the theoretical motivation behind our empirical approach. Section 4 presents our empirical strategy, as well as the data and variables used. Section 5 then presents the estimation results of our empirical model. Section 6 concludes.",2
59.0,1.0,Journal of Regulatory Economics,22 November 2020,https://link.springer.com/article/10.1007/s11149-020-09420-1,The relationship between capital and liquidity prudential instruments,February 2021,Martin Hodula,Zlatuše Komárková,Lukáš Pfeifer,Male,Female,Male,Mix,,
59.0,1.0,Journal of Regulatory Economics,03 January 2021,https://link.springer.com/article/10.1007/s11149-020-09422-z,Measuring technical efficiency and shadow price of water pollutants for the leather industry in India: a directional distance function approach,February 2021,Aparajita Singh,Haripriya Gundimeda,,Female,Unknown,Unknown,Female,"Developing countries often face tough trade-offs in achieving the desired growth versus controlling the undesirable pollution that it jointly produces as part of the production processes. Controlling pollution (bad output) requires stringent regulations, such as command and control (CAC) policies or market-based instruments (MBIs). The CAC approach levies uniform permissible limits on the discharge of pollutants and is often criticized for providing little incentives to the regulated firms to invest in pollution abatement technologies. The MBIs like pollution taxes or tradable permits, however, allow firms to minimize their compliance costs by choosing the optimal discharge from their units. The effectiveness of MBIs over CAC regulation in reducing pollution has been well recognized in developed countries (Murty et al. 1999). Under the market-based regulation, regulated firm equates the marginal benefits from production of marketable output to marginal costs of the associated pollution and production. The MBIs particularly result in higher cost savings in reducing pollution when there is heterogeneity in marginal abatement cost across firms (Newell and Stavins 2003). The key is to choose an optimal tax or permit price so that the firms internalize the negative externality at minimum cost. According to the environmental economics theory, an efficient regulation should equate the marginal abatement cost across firms to reduce pollution cost effectively (Baumol and Oates 1988). Thus, the estimates of marginal abatement cost become critical for designing effective regulation. However, the estimation of abatement cost is difficult due to the absence of pollutant markets or their prices (Gunawardena et al. 2016). Studies have estimated marginal abatement cost (often called shadow price) using two approaches: cost based approach or distance function approach (Lee et al. 2002; Lee 2005). The cost function approach requires information on the price of the factors of production, which are not readily available. The distance function approach measures the firm’s potential in expanding good output or reducing inputs while ignoring their efforts in reducing undesirable outputFootnote 1 and thus, underestimates the efficiency of polluting firms (Murty et al. 2007). The directional distance function (DDF) approach, proposed by Färe et al. (2006), overcomes the limitations of the existing approaches of estimating the shadow price. The DDF is a generalization of Shephard’s (1970) output distance functionFootnote 2 which allows for non-proportional changes in the outputs through simultaneous expansion of the good output and contraction of the bad output. DDF is commonly used to describe the technology of polluting firms, since environmental regulations require firms to reduce bad outputs (Färe et al. 2006). Zhou et al. (2014) provides an exhaustive review of studies on shadow price estimates of various pollutants for industries in different countries. Our study is conducted with the following two objectives. The first objective is to estimate the efficiency of leather firms in abating the undesirable outputs of total suspended solids (TSS) and chromium (Cr) and second objective is to estimate the shadow price of the two undesirable outputs using the directional output distance function approach. The analysis is based on the primary data collection of 61 firms operating in the Jajmau region and Unnao-Banthar leather cluster of Kanpur city in the state of Uttar Pradesh of India. We specify the distance function using a parametric form that jointly models the production of desirable output (leather sales) and two undesirable outputs (TSS and chromium) using three inputs (labor, capital and intermediate inputs). Our study further investigates the factors determining the variation in shadow price of the pollutants by regressing shadow prices against firm specific characteristics. Leather industry has been chosen for analysis as it contributes to the generation of employment, exports and growth in the Indian economy at significant environmental cost. The leather industry ranks among the top ten foreign exchange earning sectors of India and employs more than 3 million people from the weaker sections of the society (Department of Industrial Policy and Promotion 2016). Globally, India is the second largest producer of footwear and third largest exporter of leather garments (EXIM Bank 2015). However, the Kanpur leather cluster is recognized as one of the most polluting leather clusters of India and the primary source of pollution in India’s largest river basin of Ganges (Ansari et al. 2000; Sinha et al. 2006; CLRI 2012; Koshy 2018). The tanneries significantly contribute to Ganges pollution by discharging effluents characterized by high biological oxygen demand (BOD) and high dissolved solids containing toxic metals especially chromiumFootnote 3 (Beg and Ali 2008; Tewari et al. 2012). Many studies indicate that workers exposed to tanning chemicals in Kanpur industry have increased morbidity attributed to high respiratory illness, gastrointestinal and dermal problems (Rastogi et al. 2008; Sharma et al. 2012). Environmental regulations in the Indian leather industry have been restricted to CAC policies, with mandatory uniform pollution control norms across all the tanneries. The Government of India constructed a common effluent treatment plant (CETP) to treat wastewater discharge from Kanpur tanneries in 1989 under the Ganga Action Plan.Footnote 4 The state pollution control board mandated the tanneries to install primary effluent treatment plant to pre-treat the discharge of TSS and chromium within the daily limits of 600 mg/l and 2 mg/l respectively before discharging them to the CETP. Since 1989, the number of tanneries have increased from 151 to 400 and the pollution load has increased from 6 MLD (million litres a day) to 50 MLD (CLRI 2012). However, the regulatory ceilings on the discharge of pollutants from the tanneries remain unchanged since 1990s. The current tannery pollution loads of 50 MLD exceeds the current capacity limit of 36 MLD for effluent treatment (CLRI 2012). 100 tanneries in Kanpur have been closed due to their repeated non-compliance with the regulatory standards (Personal communication, Kanpur Central Pollution Control Board officer 2018). The high rate of non-compliance is due to the low penalty of INR 10,000 which is independent of the actual discharge of pollutants. The uniformity of CAC policy along with high monitoring and enforcement cost has failed to effectively control pollution from Kanpur leather cluster (Singh and Gundimeda 2020a). Our study is unique as very few studies have estimated shadow price of pollutants in Indian context due to unavailability of required data at the firm level.Footnote 5 Some studies that have estimated shadow price using output distance function approach include Kumar and Rao (2002) for particulate matter \(\left( {\rm{PM}_{10} } \right)\) for 33 thermal power plants, Murty and Kumar (2002) for BOD and chemical oxygen demand (COD) of 60 water polluting Indian manufacturing firms, and Gupta (2006) for carbon dioxide \(({\text{CO}}_{2} )\) emissions for 9 thermal power plants in India. The output distance function allows for simultaneous expansion of the good and bad output and the welfare gain/loss depends on whether the gains from expanding the good output outweighs the damages from increased bad output, making the overall welfare change ambiguous (Murty et al. 2006). Another set of studies based on the input distance function are Kumar (2006) that estimated the shadow price of water for 92 water polluting firms and Murty et al. (2006) that estimated the shadow prices of BOD, COD and suspended solids (SS) for 36 sugar firms. The input-based approach allows for proportional reduction in inputs taking the good and bad outputs as constant and therefore results in more unambiguous welfare change (Murty et al. 2006). The recent strand of literature has applied DDF approach to estimate the environmental efficiency and the shadow price of pollutants. Some of the studies that estimated shadow prices based on the DDF approach are Murty et al. (2007) for suspended particulate matter (SPM), sulfur dioxide \(({\text{SO}}_{2} )\) and nitrous oxide \({\text{(NO}}_{x} )\) for 5 thermal power plants in Andhra Pradesh; Kumar and Managi (2011) for BOD, COD and SS of 92 Indian water polluting firms, and Jain and Kumar (2018) for \({\text{CO}}_{2} \) from 56 Indian power plants. This study contributes to the existing literature on measuring shadow price for industries in India in the following ways. Firstly, to the best of our knowledge, studies measuring shadow price in water polluting industries (including leather industry) are very few. This study provides the most updated shadow price measure using a unique dataset collected from a field study of Kanpur region of India for the year 2016. Secondly, the existing studies have shown that selection of directional vectors (DVs) in DDF approach plays a crucial role in estimating the shadow price of pollutants (Molinos-Senante et al. 2015; Wang et al. 2017; Jain and Kumar 2018). Therefore, we provide a robust estimate of the shadow prices using three DVs that represent different production and pollution abatement strategies. Thirdly, we determine the causes of variations in the shadow price of pollutants based on factors such as age, size, capital intensity, labor intensity and pollution intensity of firms. Finally, we examine the potential cost savings in pollution abatement if discharge trading is allowed among firms. Our study finds that the firms are inefficient in jointly increasing the leather output and decreasing the bad outputs of TSS and chromium. The leather firms in Kanpur face high pollution abatement cost under CAC regulations and the shadow prices also differ across the firms, indicating the potential of MBIs in reducing pollution from the industry. Our study shows that higher pollution abatement burden should be borne by small, old and relatively more pollution intensive firms. The study also finds significant cost savings from the use of MBIs if discharge trading is allowed between firms. The paper is organized as follows. Section 2 describes the methodology used for the estimation of shadow price of bad outputs. Section 3 describes the data and variables used for the estimation. Section 4 provides the empirical results and discussion and Sect. 5 presents the conclusion.",8
59.0,1.0,Journal of Regulatory Economics,12 November 2020,https://link.springer.com/article/10.1007/s11149-020-09419-8,The strategic impact of voluntary vs. mandated vertical restraints and termination restrictions on exclusion of rivals,February 2021,Jacob Burgdorf,,,Male,Unknown,Unknown,Male,"Many models explore how exclusivity in contracts may be employed to foreclose entry of rivals into markets.Footnote 1 Outside of work examining the use of exclusive contracts, relatively little theoretical work examines how other vertical practices and restraints relate to entry, with Asker and Bar-Isaac (2014) being a notable exception. Additionally, public policy often puts restrictions on vertical practices by mandating conduct regarding these vertical restraints or restrictions. These mandates may come in the form of franchise termination laws (which restrict firms from terminating, altering or non-renewal of contracts), vertical divestiture or divorcement laws [such as in Vita (2000) and Kwoka et al. (2010)], or bans of certain vertical practices (such as banning the use of slotting fees, resale price maintenance, or exclusive territories). Alternatively, some public policies come in the form of mandates that require the use of a vertical restraint such as exclusive territories (see Sass and Saurman 1993; Lafontaine and Scott Morton 2010; Burgdorf 2019), resale price maintenance (Ornstein and Hanssens 1987), and other policies.Footnote 2 The ambiguous nature of the impact of vertical practices and restraints is well known in the economic literature and was noted in the Leegin case, which overturned the per-se illegality of minimum resale price maintenance (RPM) established by the Dr. Miles case.Footnote 3 The majority ruling wrote, Vertical agreements establishing minimum resale prices can have either procompetitive or anticompetitive effects, depending upon the circumstances in which they are formed.Footnote 4 This paper addresses some of these circumstances and presents a model that incorporates both anti- and pro-competitive uses of vertical restraints, including but not limited to RPM. The model considers under which equilibrium conditions the use of vertical practices may be used to foreclose entry or promote efficiency and how public mandates may alter this behavior. Using the baseline model of Asker and Bar-Isaac (2014), I first consider the setting in which entry may be prevented due to the use of vertical restraints. I then extend the model to consider mandates of vertical restraints which restrict firms from threatening termination of the contract or contractual provision and the effects this has on downstream product investment. The baseline model of Asker and Bar-Isaac considers a setting in which an incumbent monopolist sells to many downstream retailers. An upstream rival wishes to enter the market, but in order to do so, it must be accommodated by a downstream retailer. The monopolist may be able to prevent entry by using a vertical restraint to transfer a stream of quasi-rents to the retailers downstream (via RPM, slotting fees, etc.) thus raising the retailers’ profits. This transfer enables the monopolist to credibly threaten that if entry is accommodated by retailers, they will terminate this stream of quasi-rents and lower retailers’ profits. If the quasi-rent stream the monopolist is willing to pay to the retailers to prevent entry is greater than what the entrant is willing to pay to enter, retailers will not accommodate new manufacturers in order to ensure that the payment of quasi-rents from the incumbent continues, and entry can be deterred. This model is then extended in two dimensions that are applicable to industry settings and complementary to the baseline. First, vertical restraints that provide a stream of quasi-rents to downstream firms may be used to induce non-contractible downstream product investments, promotions, or services. This has both theoretical and empirical support; see for examples Telser (1960), Marvel and McCafferty (1984), Klein and Murphy (1988), Klein and Wright (2007), and Zanarone (2009). In these settings, vertical restraints are used to align incentives between upstream and downstream firms. For example, an exclusive territory assigned to a downstream retailer by an upstream manufacturer may prevent other retailers from free-riding off of costly services and investments that improve the products. I incorporate this into the model, so the use of restraints could serve either pro- or anti-competitive purposes. Asker and Bar-Isaac suggest that when such services are relevant, the elimination of the restraint, if it is associated with lower services, would result in a trade-off similar to Williamson (1968) between efficiency gains of entry of a more efficient producer and efficiency losses of lower services. However, I show that under some conditions, when downstream product investment is sufficiently important for the monopolist, the threat that prevented entry in the baseline model is not credible. In these cases, elimination of the restraint would not result in a trade-off as entry deterrence would not occur—thus only efficiency losses would occur. I characterize equilibrium conditions for when this threat is credible. Additionally, I consider mandates that apply to all firms in the industry, as is common in many cases. These mandates restrict the legality of termination of the contract or restraint and remove the threat that the monopolist employs to prevent entry in the baseline model. The mandates in the baseline setting would thus increase entry. However, a mandate also removes the threat to terminate the stream of quasi-rents if downstream firms shirk on investments for both the monopolist and the entrant. If a mandate sufficiently reduces downstream product investment, entry may become less profitable and decrease, which impacts the trade-off discussed above. Thus mandates have an ambiguous effect on entry, and I examine equilibrium conditions that would make mandates more likely to increase or decrease entry. This paper also addresses a point raised in Cooper et al. (2005a). They argue that “...it is difficult to distinguish welfare-enhancing from welfare-reducing vertical practices based on evidence because the theory of vertical control tells us only that anticompetitive effects are possible. Until theory can be used to determine how likely it is that a restraint will lead to an anticompetitive outcome, it does not give us a way to interpret evidence in most cases.” Understanding when vertical restraints are likely to have a pro- or anti-competitive effect is of importance, especially given a lack of consensus with regard to antitrust treatment regarding vertical restraints.Footnote 5 One goal of this paper is to bridge some of this gap by examining a theoretical basis for when vertical restraints are likely to be pro- or anti-competitive when downstream services are important and they can be used to prevent entry. Section 2 details the baseline model of Asker and Bar-Isaac (2014), Sect. 3 extends the model to include downstream product investment, Sect. 4 describes the legal restrictions regarding vertical contracts considered in this paper and incorporates them into the model, Sect. 5 includes a discussion, and Sect. 6 concludes.",2
59.0,2.0,Journal of Regulatory Economics,20 March 2021,https://link.springer.com/article/10.1007/s11149-021-09426-3,Regulating corruptible certifier behavior,April 2021,Sungho Yun,,,Unknown,Unknown,Unknown,Unknown,,
59.0,2.0,Journal of Regulatory Economics,16 January 2021,https://link.springer.com/article/10.1007/s11149-021-09424-5,Macroprudential regulations and bank profit efficiency: international evidence,April 2021,Chrysovalantis Gaganis,Emilios Galariotis,Christos Staikouras,Unknown,Unknown,Male,Male,"The banking industry has long been one of the most highly regulated industries, and it is not surprising that there exist many studies in the regulatory economics literature stimulated by the debate on the role of the government in the economy and the associated two broad approaches to regulation. On the one polar of the approaches to regulations is the public interest view, that dominated thinking on regulation during much of the twentieth century (Barth et al. 2006). This view asserts that governments will use regulations and supervisory agencies to boost the performance and efficient functioning of banks by ameliorating market failures, for the benefit of broad civil society (Barth et al. 2006). In contrast, according to the private interest view, efficiency may be distorted because banking firms are constrained as to where they allocate scarce capital (Ayadi et al. 2016). More generally, the private interest view asserts that because of political/regulatory capture (Stigler 1971) politicians and government supervisors do not maximize social welfare; they maximize their own welfare. Consequently, the private interest school would expect the promotion of regulations that enhance the power or well-being of bankers and the politically well-connected (Barth et al. 2006). Given the above, regulations may have conflicting effects on the efficiency of the banking system, and it is not surprising that over the last decade an increasing number of studies have used cross-country datasets to explore this relationship. However, most of these studies focus on microprudential regulations, like capital requirements and restrictions on bank activities (e.g. Pasiouras 2008; Delis et al. 2011; Barth et al. 2013b), and there is also some evidence on the association between bank efficiency and microprudential regulators’ characteristics (Gaganis and Pasiouras 2013), and most recently financial consumer protection policies (Gaganis et al. 2020a). To our knowledge, there is no study exploring the association between macroprudential policies and bank efficiency. In the present study, we use a large sample of commercial banks from over 130 countries and information from the Cerutti et al. (2017) database on macroprudential policies, and we aim to close this gap in the literature.
 Our work is motivated by the enhanced interest in macroprudential policies in recent years. While the first references to the term macroprudential date back to 1979 (Clement 2010), it was not until after the wake of the financial crisis that the attention of regulators and academics across the world shifted from a microprudential framework to a macroprudential one. Despite this recent interest on macroprudential policies, numerous scholars emphasize that our understanding of these policies remains limited, empirical research on their effectiveness is preliminary, and further work is necessary (e.g. Cerutti et al. 2017; Akinci and Olmstead-Rumsey 2018; Gambacorta and Murcia 2020; Poghosya 2020; Gómez et al. 2020). In general, as in the case of microprudential regulations and consumer protection policies, macroprudential regulatory policies may have an ambiguous impact on bank efficiency. On the one hand, they can decrease risk, enhance the trust and confidence of consumers and the public to banking institutions. This could lead to lower contagion risk and better expectations about financial stability, with implications for the demand of bank services and their pricing. Additionally, the lower risk of contagion could translate into lower bank funding costs. All these could have positive implications for bank efficiency. On the other hand, macroprudential policies can be a burden that will decrease bank efficiency, because of limitations to business expansion, the enhancement of compliance costs, or direct costs. Example of policies that could constrain business expansion are: (a) the imposition of a debt-to-income ratio that constrains household indebtedness by enforcing or encouraging a limit, (b) limitations on domestic currency loans to constrain credit growth, and (c) loan-to-value ratio caps. To comply with macroprudential regulations, banks might have to increase the number of employees to handle the new rules, pay overtime hours for existing staff, or experience an increase in technological expenditures if banks shift to technology to handle regulatory compliance. Therefore, macroprudential regulations can influence the decisions of banks for the mix and pricing of inputs and outputs that enter the financial intermediation production process. Cyree (2016) mentions for example that: “If banks are reallocating time and resources away from managing the banking organization and implementing the strategy of the bank, these effects should be apparent in bank costs and profits and in reduced loan production, all else equal. In other words, if new regulation is burdensome, either banks need to hire additional employees to produce the same output, or output will fall with the same number of employees, or some combination of the two. Or, if regulation mitigates the negative effects of crises through increasing confidence in banks or providing low-cost financing of deposits, costs and productivity could improve, or at least not decline” (p. 217). Therefore, the net impact of macroprudential regulations on bank efficiency depends on which (if any) effect prevails. To shed more light on this issue we use a production frontier function and estimate bank profit efficiency (Gaganis and Pasiouras 2013; Luo et al. 2016; Gaganis et al. 2020a), that is the most informative measure of efficiency since it considers simultaneously the aims of revenue maximization (i.e. revenue efficiency) and cost minimization (i.e. cost efficiency), thereby accounting for the effects of the choice of the production vector on both costs and revenues (Maudos et al. 2002). Using a sample of more than 3200 banks from over 130 countries, we find that macroprudential policies decrease bank profit efficiency. This finding holds for both borrower-targeted policies and financial institution-targeted ones, and while controlling for microprudential regulations and financial consumer protection policies. The rest of the paper is as follows. Section 2 provides a brief discussion of the related literature. Section 3 presents the methodology and the data. Section 4 discusses the results. Section 5 concludes.",9
59.0,2.0,Journal of Regulatory Economics,03 January 2021,https://link.springer.com/article/10.1007/s11149-020-09421-0,Self-regulation and governmental oversight: a theoretical and experimental study,April 2021,Silvester van Koten,,,Male,Unknown,Unknown,Male,"Self-Regulatory Organizations (SROs) can be found in many sectors, such as the financial sector, education, healthcare, and accounting and legal professions (Carson 2011). A prominent example of an SRO in the securities industry is the US Financial Industry Regulatory Authority (DeMarzo et al. 2005; FINRA 2018). The main advantage of SROs is that they are often capable of conducting regulatory investigations at lower costs than governments (Braithwaite 1982; DeMarzo et al. 2005).Footnote 1 Conversely, a disadvantage is that theoretical models indicate SROs are often afflicted by incentive-incompatibility problems (DeMarzo et al. 2005; Núñez 2001, 2007). Indeed, SROs have mixed records when it comes to actually curbing market abuse by SRO members. Consequently, oversight by an SRO is usually supplemented by forms of governmental oversight (Carson 2011). However, the optimal form of supplemental governmental regulation remains an open question. Two basic types are governmental oversight of SRO members and governmental oversight of the SRO itself. The first type, coined “public parallel regulation”, involves a duplication of effort as SRO members are overseen not only by the SRO, but also by the government. The second type, known as “meta-regulation”,Footnote 2 involves the government checking whether the SRO fulfills its task correctly (Carson 2011; Aguilar 2013).Footnote 3 So far, no clear consensus exists as to how invasive meta-regulation of an SRO should be. On one hand, regulation should be stringent enough to ensure the SRO does not use its capacities to the detriment of consumers, e.g. by implementing lax standards or concealing fraud (Carson 2011); on the other hand, the SRO should have sufficient freedom and flexibility to capitalize on its knowledge and expertise to pursue effective and cost-efficient regulation policies.Footnote 4 In this paper, I extend a prominent financial sector model by DeMarzo et al. (2005) and show that public parallel regulation may not be sufficient when the SRO is not able to commit to its announced oversight policy. Their model is otherwise particularly well-suited to address self-regulation and supplemental governmental oversight for financial sectors in which customers use investor or brokerage services to invest. Using sequential games with the SRO moving first, the model implies that a favorable outcome can be achieved with public parallel regulation alone. In equilibrium, the SRO sets high investigation standards and all investigations are conducted by the SRO and none by the relatively costly governmental regulator (GOV), while no meta-regulation is needed. However, in contrast to DeMarzo et al. (2005), I argue that an SRO, even when it moves first and announces high investigation standards, may not be able to commit itself to implementing them. The lack of commitment turns the interaction between SRO and GOV into a simultaneous game. I show that, in equilibrium, the SRO relinquishes all investigations to the GOV, resulting in an inferior outcome. However, my analysis also suggests that supplemental meta-regulation that enforces the SRO to implement its announced standards would re-establish the efficient equilibrium presented in DeMarzo et al. (2005). To test the theoretical equilibrium, I perform economic experiments, the results of which support the theoretical predictions and show that public parallel regulation alone is indeed not sufficient in this setting. The rest of the paper is structured as follows. Section 2 reviews relevant studies. Section 3 describes and solves the model. Section 4 presents experimental evidence. Finally, I conclude in Sect. 5.",1
59.0,2.0,Journal of Regulatory Economics,23 February 2021,https://link.springer.com/article/10.1007/s11149-021-09425-4,Optimal destabilization of cartels,April 2021,Ludwig von Auer,Tu Anh Pham,,Male,,Unknown,Mix,,
59.0,3.0,Journal of Regulatory Economics,03 May 2021,https://link.springer.com/article/10.1007/s11149-021-09427-2,Access pricing in network industries with mixed oligopoly,June 2021,Shana Cui,David E. M. Sappington,,Female,Male,Unknown,Mix,,
59.0,3.0,Journal of Regulatory Economics,30 June 2021,https://link.springer.com/article/10.1007/s11149-021-09431-6,Input price discrimination and non-controlling vertical shareholding,June 2021,Romain Lestage,,,Male,Unknown,Unknown,Male,"Non-controlling shareholding, in which publicly traded corporations own shares in one another, is a widespread practice in continental Europe and Northeast Asia. Firms then hold minority shares in their rivals, suppliers, or clients, which does not result in formal control, but aligns firms’ interests. Unlike mergers, non-controlling shareholding is not under strict regulatory scrutiny, although it is likely to facilitate coordination among horizontally and vertically related firms. The issue has been intensely debated in Europe (see, for example, European Commission 2014, 2016) and similar concerns have emerged in the US about common ownership, in which product market competitors are held by the same institutional investors (see Azar et al. 2018, and subsequent research). Non-controlling vertical shareholding refers to market structures where downstream firms own minority shares in their suppliers (backward shareholding), or vice versa (forward shareholding). It is frequently encountered in deregulated network industries such as railways, electricity, or telecommunications, where previously integrated incumbents were vertically separated. It has also been documented in the cable TV industry, where operators own shares in television networks, or between banks and payment systems. Besides, conglomerates, such as Keiretsus, in Japan, and Chaebols, in South Korea, form webs of horizontally and vertically related firms linked by minority cross-participation. Non-controlling vertical shareholding is likely to be a foundation for input price discrimination. Chaebols are known for offering preferential treatment to affiliated companies, which is a major issue for competition policy in South Korea (see, e.g., Shin 2002). Such discrimination is also an important concern in the European Union and a key point in the discussions on regulation of minority shareholding.Footnote 1 Finally, in deregulated network industries, it has often been argued that functional separation of essential facilities would not eliminate the incentives for access price discrimination, and that only full legal separation could achieve this goal (see OFCOM 2018, on the case of telecommunications in the UK). The first question addressed in this paper refers to such discrimination strategies: Is it optimal for an upstream monopolist to discriminate against or in favor of its downstream affiliates? From a theoretical perspective, the case of forward shareholding is elementary: An input provider that owns shares in downstream firms will offer them discounted input prices, because its bears a share of their costs. In this paper, we focus on the more intricate case of backward shareholding and show that a monopolistic input provider always discriminates against its downstream shareholders. Second, we analyze the welfare effects of discriminatory input pricing, for any given asymmetric ownership structure. Price discrimination in business-to-business relations has been an important topic in industrial organization and antitrust economics since the Robinson–Patman Act of 1936. However, little is known about input price discrimination based on non-controlling, vertical shareholding. We show that, unlike other forms of third-degree price discrimination studied in the literature, input price discrimination based on backward shareholding entails a consumption reallocation effect that is always positive. Indeed, a monopolistic input provider discriminates against its own downstream shareholders, and the latter set lower retail prices in equilibrium. Discrimination therefore reallocates consumption from low-price to high-price retail markets, thereby improving welfare. It follows that a non-decreasing total output is a sufficient condition for input price discrimination to improve welfare. Finally, we study how ownership structures are affected by input price discrimination in the long term. If downstream firms compete in prices and demands are linear, we find that uniform input pricing yields a symmetric ownership structure, where downstream firms own equals shares of the input provider. By contrast, input price discrimination prompts an asymmetric ownership structure, which in turn improves welfare. It follows that input price discrimination yields higher welfare gains in the long term than in the short term. For similar reasons, input price discrimination may hurt consumer surplus in the short term, but improve it in the long term, which yields potential regulatory commitment issues. An important aspect of our paper is that the presence of a double marginalization problem constitutes the motive for non-controlling shareholding.Footnote 2 Although, in theory, nonlinear pricing eliminates or alleviates double marginalization, it is not always implementable, and linear vertical contracts are very common in practice. We therefore believe that double marginalization remains an essential dimension of vertical relations.Footnote 3 The remainder of the paper is organized as follows. In Sect. 2, we review the literature and present our contribution more in detail. As a preamble, we study the case of independent downstream markets in Sect. 3. Then, we analyze the main case of interest, price competition, in Sect. 4. In Sect. 5, we extend our model to quantity competition and forward shareholding, and discuss controlling shareholding, cross-shareholding, and two-part tariffs. We conclude in Sect. 6.",5
59.0,3.0,Journal of Regulatory Economics,08 June 2021,https://link.springer.com/article/10.1007/s11149-021-09429-0,Optimal risk regulation of monopolists with subjective risk assessment,June 2021,Daiki Kishishita,Susumu Sato,,Male,Male,Unknown,Male,"During business operations, firms often engage in risky activities, resulting in significant negative externalities in the case of an accident. Typical examples of accidents include environmental accidents, such as oil spills, nuclear accidents, and the contamination of air and water. Although firms should put in more effort into safety care to prevent accidents, their provision tends to be insufficient. This makes public intervention indispensable. This study contributes to the literature on the design of public policies for risk regulation.Footnote 1 In designing regulations, we encounter the nature of risky activities that all stakeholders face uncertainty in the probability of an accident; this is called ambiguity (Knightian uncertainty). While the probability assessment is a critical determinant of the optimal level of preventive effort for each stakeholder (Aven 2011), its precise estimation is difficult because accidents are, by nature, rare events, and scientific knowledge is also limited. Consequently, risk assessment is subjective (Stirling 1998).Footnote 2 Therefore, risk regulation should be designed based on this nature of risky activities. The empirical literature in both economics and psychology has extensively examined the subjectivity of risk assessment. For instance, in the psychology literature, some identify people’s optimism about their own risks compared with other people’s risks (e.g.,Pahl et al. 2005). Additionally, subjective risk perceptions are recognized as a cause of accidents. After some major accidents, it is often pointed out that the optimistic attitudes of stakeholders have triggered accidents. For instance, a report on the Fukushima nuclear plant accident in 2011, which is made by an independent investigation commission, argues that optimistic attitudes toward the risks of nuclear plants led to a bad governance system where all the stakeholders, including regulators, electricity companies, as well as the residents around nuclear plants, accepted the “security myths,” making it hard to discuss the possibility of accidents (Bricker 2014). Another example is the 2011 Deepwater Horizon oil spill. Abrahm (2012) argues that British Petroleum’s underestimation of the risk of accidents led to inefficient investment into safety care, resulting in the oil spill. Among the stakeholders, the most important actor should be firms that engage in risky activities because they are directly responsible for the operation.Footnote 3 Given the extensive discussion on subjective risk assessment and its relationship with excessively low investment in safety care, it is indispensable to design a public policy that considers the optimistic risk perceptions of firms. However, the theoretical literature on this topic is limited. Therefore, this study derives an optimal regulation when a firm’s optimistic attitude results in an optimistic evaluation of the probability of an accident. For this purpose, we consider a natural monopoly model where the monopolist chooses the level of effort to prevent an accident, which is unobservable to the regulator. The product price is regulated by the government. Further, in the case of successful business operations, the monopolist realizes profits based on the regulated price and marginal cost of production, which depends on the level of preventive effort. Additionally, the regulator designs an incentive regulation; she chooses fine and ex-ante transfers. However, imposing a huge fine is infeasible because the monopolist is protected by limited liability. We introduce a subjective risk assessment into this standard model. To model heterogeneous beliefs about the probability of an accident, we employ the Choquet expected utility with a neo-additive capacity (Chateauneuf et al. 2007). This yields a tractable characterization of the subjective risk assessment.Footnote 4 In this setup, the subjective attitude toward ambiguity is governed by one parameter (the degree of optimism). Further, each person’s subjective probability of an accident depends on this parameter in a specific way. This nature, which has a nice axiomatic foundation, enables us to conduct comparative statics regarding the degree of optimism. We first examine the monopolist’s incentive to make preventive effort under a given regulation policy. In this environment, the more optimistic the monopolist is, the less the level of effort given a regulation policy. Preventive efforts increase production costs and reduce business-as-usual profits in the absence of an accident. Furthermore, because the optimistic monopolist subjectively believes that the probability of an accident is low, it does not care for the possibility of an accident and rather puts much weight on the business-as-usual profit. Consequently, the optimistic monopolist’s subjective cost of preventive effort is high. This implies that its effort level decreases. This effect is in sharp contrast to the effect of risk-aversion found in the literature (e.g., Dionne and Eeckhoudt 1985; Jullien et al. 1999). Because the monopolist’s optimism lowers its incentive to put in preventive efforts, it would be expected that higher optimism would reduce safety investment despite optimally designing the regulation. Further, because low safety investment implies low production cost, the optimal regulated price seems to decrease with the degree of the monopolist’s optimism; in other words, when risk regulation is unsuccessful, the optimal price regulation should be strict. However, these intuitions do not hold because of the interaction between price and risk regulation. First, we show that increasing the price stimulates preventive efforts through a reduction in the scale of demand. That is, not only fine but also price regulation can serve as instruments for risk regulation. Furthermore, the more optimistic the monopolist is, the more effective an increasing price is as a tool for inducing preventive efforts. Therefore, in contrast to the typical view, the optimal regulated price increases as the monopolist becomes optimistic. Regarding the optimal fine level, we do not have analytical results. However, our numerical results indicate that the optimal fine level increases in the degree of optimism because the regulator counteracts the reduction in the preventive efforts caused by optimism. In addition, we demonstrate that under this optimal regulation, the monopolist’s optimism does not necessarily reduce the effort level. While the monopolist’s incentive to exert effort becomes smaller, increasing the price becomes a more effective tool to stimulate effort. If the latter positive effect dominates the former negative effect, the monopolist’s optimism would increase the equilibrium level of preventive effort. It is shown that the effort level is U-shaped in relation with the monopolist’s degree of optimism: moderate optimism minimizes the equilibrium effort level. In summary, the monopolist’s optimism is not necessarily harmful, as long as the regulator can design the regulation appropriately. Our numerical examples further suggest that optimism is likely to be better when the market size is small. These results have important policy implications for the risk and price regulations of imperfectly competitive markets under disaster risk. When a huge disaster occurs, regulated utility companies often ask regulators to allow for an increase in prices, in return for increasing safety investments. While it is reasonable to justify the price increase accompanying the increase in costs, our result suggests that if such an investment arises from an increase in the firm’s pessimism, the government should reduce the price in response to such changes. Related literature Since Strand (1994), various studies have analyzed the optimal risk regulation for the moral hazard problem with limited liability. Similar to our study, some analyze the interaction between product market regulation and risk regulation (e.g., Laffont 1995; Hiriart and Martimort 2006a, b; Hiriart et al. 2011; Hiriart and Martimort 2012; Hiriart and Thomas 2017). The difference lies in the focus. While existing studies emphasize the adverse selection problem on cost reduction or the effects of institutions on the inefficiency caused by limited liability, our model has neither of these two aspects. Instead, we emphasize the effect of firms’ optimistic attitudes. The literature has examined heterogeneous beliefs in the context of risk assessment from two distinct approaches. The first strand introduces ambiguity as a source of heterogeneous beliefs.Footnote 5 Regarding the design of tort law, Teitelbaum (2007) shows that negligence is more robust to ambiguity than strict liability rule is in unilateral accident cases. Chakravarty and Kelsey (2017) extend the model to bilateral accident cases. By adopting the Choquet expected utility with a neo-additive capacity, they introduce heterogeneous beliefs in a tractable manner like ours.Footnote 6 The second approach does not explicitly model a source of heterogeneous beliefs; rather, it directly assumes that the subjective probability of an accident is different across players.Footnote 7 Salanié and Treich (2009) consider a society in which citizens wrongly believe that the drinking water supply is contaminated. In this environment, they show that it could be optimal to incur unnecessary safety investment when people’s responses to risk regulation are taken into account. These two approaches are related to ours, but neither analyzes the optimal regulation design in the presence of a moral hazard problem. Ours is the first study to examine heterogeneous beliefs in the optimal regulation design of a moral hazard problem. The remainder of this paper is organized as follows. Section 2 presents our model. Section 3 derives the monopolist’s decision given the regulation. Section 4 characterizes the optimal regulation and analyzes the effect of optimism. Section 5 provides additional discussion. Section 6 outlines our conclusions.",
59.0,3.0,Journal of Regulatory Economics,01 May 2021,https://link.springer.com/article/10.1007/s11149-021-09428-1,Forward-looking distribution network charges considering lumpy investments,June 2021,Niels Govaerts,Kenneth Bruninx,Erik Delarue,Male,Male,Male,Male,"The practice of electricity distribution network expansion and pricing is currently undergoing a paradigm-shift. In the past, network operators took a ‘fit-and-forget’ approach, installing over-dimensioned feeders that could accommodate the growing peak demand for at least several decades. The network charges, determined via accounting approaches based on historic network costs, were mostly flat and volumetric, with a fixed kWh charge. Simplicity and perceived fairness, rather than cost-reflectivity, were the main concerns of regulators, since electricity consumers had limited means to react to charges. The emergence of solar photovoltaics, batteries, heat pumps and electric vehicles, completely changes the picture. On one hand, uncoordinated use of these technologies will increase peak loads, requiring a significant increase of network investments and costs. On the other hand, these technologies may be employed in a flexible manner, reducing the corresponding network investments and costs. In order to preserve and perhaps increase the economic efficiency of network operation and planning, network operators and regulators are starting to combine traditional measures, e.g., network expansion, with novel approaches involving consumer flexibility. Cost-reflective network tariffs, that charge consumers according to the network costs they inflict, are an important tool for leveraging this flexibility. In search of cost-reflective charges, and in order to enable consumers to react to those charges, academics and policymakers have suggested forward-looking tariffs, signaling future network investments (MIT Energy Initiative 2016; Abdelmotteleb et al. 2018; CEER 2020). The logic behind the forward-looking aspect is the fact that reduction of network utilization cannot reduce the costs of the current network infrastructure, which are sunk, but only defer future network investments. As such, a forward-looking charge should signal the long-run marginal costs (LRMC) of the network to consumers.Footnote 1 These are the investment and operating costs associated with transporting an additional unit of electric power over the network at the time of the simultaneous or coincident peak load. Since coincident peak loads, which drive network investments, are encapsulated in the LRMC definition, the price signal is ideally transmitted through a coincident peak network tariff, charging consumers based on their contribution to the system peak load. In recent years, several regulators have also implemented LRMC based network charging approaches, e.g., in Australia and the UK (AEMC 2014; OFGEM 2019). The practical implementation is challenging, however, considering that network capacity expansion planning is a highly non-convex problem, exhibiting capital indivisibility or investment lumpiness. As a result, the network cost functions are discontinuous and LRMCs are difficult to define. In this paper, we investigate forward-looking distribution network charges with an analytical model, mimicking a social welfare maximizing regulator that sets a coincident peak network charge based on a forward-looking network cost model. The regulator considers future investments and anticipates consumer response. The model is stochastic to account for the significant uncertainty that follows from the considered look-ahead horizon. We derive an analytical expression for the optimal network charge under a staircase network cost function, reflecting investment lumpiness, and compare it to the optimal charge under linear network costs, serving as benchmark. We thereby combine two strands of literature. First, there is a strand of literature that computes forward-looking network charges, using engineering models to estimate marginal costs, recognizing real-world complexities such as investment lumpiness (Turvey 2000). These so-called forward-looking cost models (e.g., Lima et al. 2002; Li and Tolley 2007) combine peak load forecasts and network expansion planning problems. Marginal costs are approximated by analyzing how a perturbation of current peak demand changes the extent and timing of future network investments. A variety of models has been proposed, differing in set-up of the network expansion planning model, load assumptions, derivation of marginal cost, time horizon, etc. (Meeus et al. 2020).Footnote 2 While most models are deterministic, uncertain load (growth) has been incorporated in recent years (Gu et al. 2016; Yang et al. 2020). None of these papers, however, endogenously considers consumer reaction. In other words, peak demand elasticity, and the subsequent feedback effect of network charges on the peak load forecast, is not considered. Additionally, these papers demonstrate the functioning of forward-looking charges by means of case studies, but do not provide a supporting fundamental analysis of their properties. Second, there is a strand of economic literature presenting more fundamental analyses of distribution network charges (e.g., Gautier et al. 2018; Brown and Sappington 2018; Schittekatte and Meeus 2020). Coincident peak network charges, equal to the LRMC, are regarded as the benchmark in this context, with a proof of their efficiency provided by Baldick (2018).Footnote 3 Recognizing that coincident peak charges are challenging to implement for regulators, and to understand for consumers, this strand of literature mainly focuses on the investment incentives and welfare effects of alternative charge designs.Footnote 4 However, the network cost structure receives less attention, as infinitely divisible network investments and convex, often linear, network cost functions are assumed, i.e., network costs proportional to peak demand. In other words, LRMC is assumed to be a known parameter, and its practical computation via forward-looking cost methods, including the complexity resulting from the underlying lumpy network cost structure, is not captured in these studies. As our main contribution, we provide the first formal analysis of a forward-looking, coincident peak network charge considering lumpy network investments. Our model represents an idealized forward-looking cost model. As such, we balance the abstraction of economic models, endogenously accounting for uncertain consumer response, and the detail of engineering models, accounting for lumpy investments and the forward-looking perspective. In the benchmark setting, considering linear network costs, our findings are similar to current state-of-the-art literature, as the optimal network charge is equal to the LRMC. Considering investment lumpiness, we find that the optimal network charge, despite equaling marginal network costs, is significantly more complex to determine, as it depends on characteristics of both the network and the consumers. We also show that average incremental cost is a reasonable approximation for the optimal network charge in some settings. These results indicate that current forward-looking cost models, which calculate the LRMC without considering the consumers’ reaction to network charges, do not provide optimal network charges. The remainder of the paper is organized as follows. Section 2 introduces the model. In Sect. 3, we analytically derive the optimal network charge under linear and lumpy, single step network costs, presented in two propositions. In Sect. 4, we extend our analysis to multi-step network costs. We conclude in Sect. 5.",3
59.0,3.0,Journal of Regulatory Economics,24 July 2021,https://link.springer.com/article/10.1007/s11149-021-09432-5,Correction to: Forward-looking distribution network charges considering lumpy investments,June 2021,Niels Govaerts,Kenneth Bruninx,Erik Delarue,Male,Male,Male,Male,"The original version of this article unfortunately contained a mistake in one of the co-author name Hélène Le Cadre. During production process, the name was in-completed. The author name is corrected with this correction. The original article has been corrected.",
60.0,1.0,Journal of Regulatory Economics,03 August 2021,https://link.springer.com/article/10.1007/s11149-021-09434-3,Product recall with symmetric uncertainty and multiunit purchases,August 2021,Anthony M. Marino,,,Male,Unknown,Unknown,Male,"Product recall is prevalent in the many markets. In the United States, the key agencies conducting recalls are the Consumer Product Safety Commission (CPSC) which recalls consumer products, the National Highway Traffic and Safety Administration (NHTSA) which recalls motor vehicles, the Food and Drug Administration (FDA) and United States Department of Agriculture (USDA) which recall drugs, cosmetics and food items, the US Coast Guard (USCG) which recalls boats and related equipment, and the Environmental Protection Agency (EPA) which recalls pesticides and other outdoor chemicals. Recalls of motor vehicles by NHTSA, boats by USCG and other complex durable goods by other agencies such as the CPSC, typically entail an announcement of the defective component and a retrofit so as to correct the defect. This retrofit process can be thought of as an in kind remedy. Recalls involving consumer products and food and drugs (CPSC, FDA, and USDA) tend to involve the following remedy: withdrawal of the product from the market and a refund of the consumer’s expenditure on the item to the buyer of the product. In recent years, the CPSC alone has recalled over 400 products and the FDA and the USDA recalled over 450 items per annum.Footnote 1 Some of these recalls are voluntary and some are involuntary, but in all cases consumers are typically involved in the process through their reports of defective products to both the relevant regulatory agency and the firm. This paper will study the economics of the latter recall procedure. Over the past three decades there have been several theoretical economics papers analyzing the efficiency properties of product recall and its interface with products liability. The paper by Welling (1991) considers firms that worry about their reputation which is affected by their disclosure concerning the risks associated with their products. Firms have the incentive to voluntarily recall products and disclose risks in order to increase future demand for their product. Marino (1997) considers involuntary recall after sale and forced retrofit of a defective durable (e.g., motor vehicles or boats), after a probabilistic regulatory audit. This is the in kind recall strategy discussed above. The threat of being audited and forced to retrofit then incentivizes the manufacturer to take more safety effort ex ante. In this paper, an imperfect strict liability system motivates regulation, and the second best regulatory mechanism depends on the degree of imperfection in the liability system and the extent of market power. Ben-Shahar (2005) considers a manufacturer who continues to sell a harmful product when consumers are unaware of the danger that the product poses. This is motivated by the fact that a strict liability system and risk disclosure could make consumers more likely to sue the firm. Spier (2007) studies the incentives for a firm to solicit recall and offer voluntary buyback from the consumer, after privately learning that the product could cause harm, under different liability rules. Under strict liability, the firm’s incentives to recall are not sufficient so that the buy back price is too low and consumers over use the product. Strict liability with a warning defense (liability is released if the firm discloses the risk) induces over supply of recalls and optimal consumer usage after recall. She finds that a post duty to warn liability rule implements the relevant social optimum. Hua (2011) examines the liability rules of strict liability and negligence and the firm’s incentive to recall a defective product after learning of its likelihood to cause harm. He characterizes consumers’ incentives to return a dangerous product and he determines whether the court should protect consumers who do not return the product. Chen and Hua (2012) present a model where the firm invests in ex ante safety effort and also engages in ex post retrofit as in Marino (1997). They show that an increase in the strictness of liability leads to greater ex ante investment in safety, but that it also can affect the investment incentive because it generates more ex post repair. This trade off then allows them to identify conditions under which full versus partial liability is optimal. All of the above papers, with the exception of Marino (1997), model the case where each consumer in the set of consumers consumes exactly one unit of the good under consideration for possible recall. For many consumer products, food items and medicines, the one unit assumption is not descriptive. For example in 2019, Fisher-Price recalled 4.7 million of its Rock’n Play sleepers due to infant deaths caused by babies rolling from back to stomach. Many families had purchased multiple units to use in different locations. Rite Aid recalled 18,800 folding patio chairs due to fall hazard. Many customers purchased sets of chairs. The same is true of the recall of carabiners by Decathlon USA, the recall of infant bibs by IKEA, the recall of stools by Varidesk, and the recall of aerosol water proofing spray cans by Thompson’s Company. There are hundreds of examples of multiunit purchases of this type in recent years. By assuming one unit of consumption, the effects of consuming infra-marginal units are then ignored. This paper will alter the one unit assumption by considering a representative consumer with quasi-linear utility who chooses units of consumption of a product which can cause harm in the course of consumption. Thus, we will allow for infra-marginal consumption. Later we extend the analysis to heterogeneous consumers. The product is produced by a monopoly firm which the legal system holds strictly liable should harm occur through consumption. In addition to the assumption of quasi-linear utility, we assume that the consumer and the firm have ex ante symmetric uncertainty over the firm’s safety effort which stochastically determines the riskiness of the product, as in Chen and Hua (2012). Ex ante, the firm and the consumer share a common prior on riskiness as in this paper. However, Chen and Hua allow the firm to privately learn the true riskiness of the product ex post. This knowledge can trigger ex post remedial retrofit as in Marino (1997). The present paper considers products for which retrofit is not feasible. Ex post, harm is realized and all that remains to be done is recall the product and possibly compensate the consumer through the liability system or through refunds or penalties. Such ex ante symmetry can be generated from a situation of private information on the part of the firm combined with low disclosure cost and the inclination of the firm to disclose information so as to not be perceived as the firm with the most dangerous product. Our basic model assumes that strict liability is in place and that if, after sale, the product is found to be unsafe, the regulator orders the product to be taken off the market. No other financial remedy is imposed on the firm. This base case then allows us to study the pure incremental effect of ordering the producer of an unsafe banned product to remit to the consumer a full refund and, possibly, an additional penalty fee per unit of the product purchased. We call this financial penalty policy a recall procedure. In this base model, we find that the firm under supplies output, given safety effort, due to monopoly power. The firm also under supplies safety effort, given output, because of an interesting externality first discovered by Spence (1975) in the context of a monopoly choosing quality as well as quantity. Spence’s quality variable is equivalent to our safety effort. The firm’s marginal private benefit of safety effort per unit of output is price, whereas the social marginal benefit per unit of output is average total valuation. The former under measures the latter by the amount of consumer surplus per unit. That is, infra-marginal units should be evaluated at individual demand prices per unit as opposed to the uniform equilibrium price per unit. Given these distortions, we ask how the recall procedure affects the private optimum. We find that the procedure, including the regulatory penalty per unit of output, does not change the allocation, consumer utility or producer profit. In particular, producer safety effort is unaffected by the refund and the penalty per unit. This process only raises nominal equilibrium price. The procedure then is considered ""neutral"" in our terminology. Next, consider the comparative static effects of increases in the cost of recall implementation and increases in damage costs, for the firm. These changes do not alter the above neutral impact of the procedure. Each of these comparative static changes has the same effect in that they decrease equilibrium output and raise equilibrium safety effort, where each of these variables is under supplied given the other. Consequently, we show that the effect on consumer surplus is indeterminate, due to an interesting trade off. Rising damage costs or recall costs do lead to more safety which increases consumer surplus, but there is a countervailing decrease in output and this market effect reduces consumer surplus. Such cost changes always reduce profit as would be expected. Following this analysis, we consider the implementation of a fine as a corrective device. With the fine, the recall procedure remains neutral, and, whether it be per unit or lump sum, it increases the firm’s safety effort and decreases the firm’s output. The overall effect on welfare of a fine alone is indeterminate. We then show that first best implementation is possible through a per unit or lump sum fine combined with an output excise tax, for units supplied below the social optimum output. Call the latter tax a minimum output tax. Intuitively, the fine increases safety effort and the minimum output tax curbs the firm’s desire to reduce output and, thus, welfare. In a final section, we extend the model in three directions to account for empirically observed phenomena with regard to the recall process and then ask how the firm’s decision making is affected. First, a fairly high percentage of consumers do not return a recalled product, so we modify the model to account for this effect.Footnote 2 Second, some consumers do not sue when damage is done. Thus, we consider the case where there is a distribution of different damage amounts depending on consumer type, and we endogenize the decision to sue depending on damages versus the cost of suit. Third, some consumers tend to under estimate the risk of harm, so we examine an overly optimistic consumer who under estimates the probability of suffering high damages.Footnote 3 The first two alterations make no difference in our basic results and the neutrality of the procedure. The only change is that the firm’s expected damages are altered. The overly optimistic consumer alteration again does not change the neutrality of the procedure, but it does cause the firm to endogenously under internalize expected liability costs, the effect of which is to decrease safety and increase output, other things equal. In equilibrium, the firm under supplies safety given output, but may over or under supply output given safety. We discuss first best implementation in this extended framework. Section 2 presents the model, and Sect. 3 studies the properties of the procedure and the comparative statics of cost changes. Section 4 considers regulatory fines and implementation of the first best with fines and output taxes. Section 5 extends the basic model. Finally, Sect. 6 concludes. All proofs are provided in the “Appendix”.",
60.0,1.0,Journal of Regulatory Economics,13 August 2021,https://link.springer.com/article/10.1007/s11149-021-09435-2,Labor market outcomes of granting full professional independence to nurse practitioners,August 2021,Tianyuan Luo,Cesar L. Escalante,Carmina E. Taylor,Unknown,Male,Female,Mix,,
60.0,1.0,Journal of Regulatory Economics,11 June 2021,https://link.springer.com/article/10.1007/s11149-021-09430-7,Design and regulation of balancing power auctions: an integrated market model approach,August 2021,Karl-Martin Ehrhart,Fabian Ocker,,Unknown,Male,Unknown,Male,"To ensure a proper working of the electricity system, ancillary services are used. The most important short-term service is balancing power (henceforth abbreviated as BP, see AppendixFootnote 1): it balances demand and supply deviations in real-time. This ensures a stable grid frequency in alternating current grids. BP procurement is carried out by the system operator entity, e.g. transmission system operators (TSO) in Europe (ENTSO-E 2020). The mechanism on the BP markets are procurement auctions, i.e., prequalified suppliers compete for BP provision (Ocker et al. 2016). Prequalified suppliers can act on different electricity markets (wholesale market and BP markets), and the suppliers, who provide BP, must run their plant at a minimal load and sell this electricity on the wholesale market. This causes interdependencies between the wholesale market and the BP markets (Just and Weber 2008). This is a major focus of our research. We provide a stylized integrated market model to identify and examine the characteristics of the different markets and their interdependencies. This approach does not only foster the understanding of the interdependent markets, but it also allows to examine and evaluate elements and changes of the market designs. Thus, our paper contributes to the field of electricity regulation. In Europe, the “Electricity Balancing Guideline” states the framework conditions for a pan-European BP market with a harmonized structure (European Commission 2017a). This includes a harmonized settlement rule (uniform pricing) to incentivize truthful bidding and increase efficiency, and market flexibilization (“free energy bids”) to ease the integration of volatile renewable energy sources. With the same intention, the “System Operation Guideline” sets requirements for prequalification (European Commission 2017b). In addition, there were changes in the auction design stipulated by the regulatory authority “Bundesnetzagentur” in Germany. In 2018, the scoring rule (rule for winner determination) changed to the so-called “mixed-price rule,” aiming at BP cost reduction (Bundesnetzagentur 2018). While the intentions of these design changes are clear, so far, their effects on the interlinked wholesale and BP markets have not been assessed. We close this gap by applying our model to examine and evaluate these design changes. The theoretical foundations for BP auction design are laid by Bushnell and Oren (1994) who analyze bidding strategies for different scoring rules and settlement rules. They derive conditions for efficient equilibria. Chao and Wilson (2002) show that a scoring rule consisting only of the capacity bid suffices the efficiency condition if incentive compatibility is imposed. The latter yields that suppliers energy bids reveal their variable cost, and energy bids are paid the wholesale market price. Müsgens et al. (2014) transfer this to the German BP markets. Here, the proposed scoring rule of Chao and Wilson (2002) is applied, but energy pricing is based on bids. They argue that a switch from pay-as-bid to uniform pricing ensures efficient activation. We relate to these contributions and present an equilibrium model for the wholesale and BP markets, considering different scoring and settlement rules.Footnote 2 The distinguishing feature of our model is that we consider the dependencies between the markets endogenously: prices are not exogenously given, but the result of the interplay between the markets. In contrast, Müsgens et al. (2014) assume an exogenous wholesale market price, which yields two classes of suppliers: suppliers with production units which have variable cost below the wholesale market price (inframarginal), and suppliers with variable cost above the wholesale market price (extramarginal). This distinction is crucial for the cost of BP provision: inframarginals include opportunity costs of not trading at the wholesale market, extramarginals cover their expenses by BP profits. In our model, the market interplay induces a specific assignment of the suppliers to the different markets according to their production costs and their ability to provide BP. Thus, inframarginality and extramarginality are endogenously determined.Footnote 3 Building on our market model, we prove the existence of an equilibrium and analyze its allocation, costs and prices. A central result is that all suppliers of negative BP are inframarginal, while in the positive market suppliers are inframarginal and extramarginal, depending on their production cost. We also consider empirical market data by comparing our theoretical results with German market results of 2015. Furthermore, we prove that lowering BP prequalification criteria is a promising means to reduce total costs. The mixed-price rule, however, does not impact the market equilibrium, although it may incentivize suppliers to change their bidding behavior. We also show that energy bids are not expected to foster competition, and that a switch of the settlement rule to uniform pricing does not incentivize truthful bidding in general. The paper is structured as follows. Section 2 discusses related literature, Sect. 3 illustrates the electricity market design and Sect. 4 introduces our model. Section 5 presents equilibrium results, and Sect. 6 analyzes market design changes. Finally, Sect. 7 concludes.",7
60.0,1.0,Journal of Regulatory Economics,22 July 2021,https://link.springer.com/article/10.1007/s11149-021-09433-4,Threshold effects in the regulation-innovation nexus: evidence from the telecommunications industry,August 2021,Michael L. Polemis,Markos Tselekounis,,Male,Male,Unknown,Male,"In many network industries, such as electricity and telecommunications, the existing demand and cost conditions lead to significant market failures. Their natural monopolistic structure, combined with high levels of vertical integration and network externalities, results in the inability of market forces to achieve the desired competitive outcome (Buckley, 2003). In such cases, sector-specific regulators establish the conditions under which firms compete for and in the market, thus affecting the market structure and firms' profits. It is therefore obvious that regulation dictates the intensity of competition, which in turn determines the industry performance in terms of static and dynamic efficiency. Although it is widely acknowledged that static efficiency improves as the market approaches the perfectly competitive structure, the impact of competition intensity on firms' incentives to innovate has been one of the most fiercely debated topics among economists, academics, and policymakers. The beginning of this dispute dates to the early 1940s. Schumpeter (1942) argues that innovation activity is positively correlated with large firms and market power since competition stifles innovation profits. On the other hand, Arrow (1962) points out that market power induces firms to protect the status quo, thus discourages them from engaging in developing costly disruptive technologies. Although there is a sizeable literature studying the link between market structure and innovation, no clear consensus has been reached by combining prior theoretical findings with recent empirical results.Footnote 1 However, the reconciliation of the “Schumpeterian effect” and the “escape competition effect”, which encompass the arguments of Schumpeter and Arrow respectively, seems to gain more ground as an increasing number of empirical studies find an inverted U-shaped relationship between competition and innovation in the sample of industries they analyze. For instance, this competition–innovation nexus is present when the sample is composed either by UK firms listed in the London Stock Exchange (Aghion et al., 2005) or by the largest (mainly manufacturing) French firms in terms of capital stock (Askenazy et al., 2013). The hitherto discussion leads to the deduction that it is unclear whether more stringent regulation (which usually leads to more concentrated markets) or more light regulation (which usually results in more intense competition) stimulates higher levels of innovation initiatives.Footnote 2 We contribute to this literature by empirically studying the relationship between regulation and innovation in the telecommunications industry by deploying an efficient panel threshold model. We use a yearly balanced panel data set for 32 OECD countries over the period 1995–2012. The empirical results unveil that beyond a certain threshold, a further increase in the (de)regulatory intensity leads to a decrease of the sectoral innovation activity, thus giving rise to an inverted U-shaped relationship. This finding draws significant implications for policymakers since it is related to the common regulatory trade-off between static and dynamic efficiency. The rest of this study proceeds as follows. Section 2 highlights the contribution of this research analysis by discussing some specifications of the model employed and the market studied. Section 3 describes the deregulatory and innovation process in the OECD telecommunications sector. Section 4 presents the data and empirical methodology. Section 5 discusses the empirical findings, performs the necessary robustness checks, and presents the theoretical underpinnings of the relationship between regulation and upstream innovation. Finally, Sect. 6 concludes and draws some policy implications.",4
60.0,2.0,Journal of Regulatory Economics,22 October 2021,https://link.springer.com/article/10.1007/s11149-021-09439-y,Price cap regulation and water quality,December 2021,Thomas Bue Bjørner,Jacob Victor Hansen,Astrid Fanger Jakobsen,Male,Male,Female,Mix,,
60.0,2.0,Journal of Regulatory Economics,24 August 2021,https://link.springer.com/article/10.1007/s11149-021-09437-0,Effects of interest rate caps on credit access,December 2021,Juan Sebastian Cubillos-Rocha,Juliana Gamboa-Arbelaez,Mauricio Villamizar-Villegas,Male,Female,Male,Mix,,
60.0,2.0,Journal of Regulatory Economics,25 August 2021,https://link.springer.com/article/10.1007/s11149-021-09436-1,Effects of different environmental regulations and their heterogeneity on air pollution control in China,December 2021,Xueping Wu,Ming Gao,,Unknown,,Unknown,Mix,,
60.0,2.0,Journal of Regulatory Economics,27 August 2021,https://link.springer.com/article/10.1007/s11149-021-09438-z,"Capital requirements, risk-taking and welfare in a growing economy",December 2021,Pierre-Richard Agénor,Luiz A. Pereira da Silva,,Unknown,Unknown,Unknown,Unknown,,
60.0,2.0,Journal of Regulatory Economics,09 November 2021,https://link.springer.com/article/10.1007/s11149-021-09440-5,Is real-time pricing smart for consumers?,December 2021,Anette Boom,Sebastian Schwenen,,Female,Male,Unknown,Mix,,
61.0,1.0,Journal of Regulatory Economics,15 January 2022,https://link.springer.com/article/10.1007/s11149-021-09441-4,Investment in quality upgrade and regulation of the internet,February 2022,Edmond Baranes,Cuong Hung Vuong,,Male,,Unknown,Mix,,
61.0,1.0,Journal of Regulatory Economics,04 January 2022,https://link.springer.com/article/10.1007/s11149-021-09443-2,Regulatory independence and thermal power plant performance: evidence from India,February 2022,Abhinav Jindal,Rahul Nilakantan,,Unknown,Male,Unknown,Male,"In a federal setup, both national (central) and sub-national governments (i.e., states) are empowered to undertake legislations to attract investment and provide a favourable business environment such as ease of doing business regulation, fiscal incentives like tax concessions, liberalising land laws and tariff rationalization (Bajpai & Sachs, 1999). The above dual system of regulation (national and sub-national) applies to the Indian electricity sector since electricity is a concurrent subject, where both national and sub-national governments have legislative jurisdictions in their respective domains (Sarangi et al., 2019). The electricity sector in India is characterised by dominance of fossil fuels, with 50–55% of total generation capacity under coal fired plants producing more than 65% of total electricity generated (MOP, 2020) and emitting nearly half of the country’s CO2 emissions (Kumar & Jain, 2019). In India, separate regulatory commissions at the central and state level regulate and oversee electricity generation, transmission and distribution; known as Central Electricity Regulatory Commission (CERC) and State Electricity Regulatory Commissions (SERCs) respectively (TR-UK, 2020). The CERC and the SERCs exercise jurisdiction over all interstate and intra-state electricity regulatory issues respectively, and are entrusted with the function of notifying regulations and acting as the independent regulators in their respective jurisdictions i.e., centrally and privately owned plants; and state-owned plants respectively. However, the SERC regulatory environment is at variance from that of CERC due to lack of independence in their functioning, leading to lax regulatory practices. Table 1 summarizes the differences between the regulatory practices of CERC and SERCs, capturing the lack of independence of the latter group of regulators. The information asymmetry between SERCs and their regulated plants (Fabrizio et al., 2007) due to lack of public hearings or technical validation efforts (Dubash & Rao, 2008), and data being withheld by state utilities under political patronage act as constraints in devising performance enhancing operational norms by SERCs (Chikkatur et al., 2007). For SERC regulated plants, day to day operation is influenced by bureaucratic and political considerations due to state ownership (Chauhan and Singh 2020), which can run counter to commercial considerations (Kumar & Jain, 2019). This is in contrast with the relatively depoliticized operational environment and commercial orientation of central and privately owned plants under the regulatory purview of CERC. Limited scholarly efforts have been undertaken to examine different facets of regulation including regulatory independence on the performance of Indian electricity generation sector. While existing literature looks at regulation in terms of regulatory composition (Dubash & Rao, 2008; Ghosh & Kathuria, 2016), governance (Ghosh & Kathuria, 2016), and regulatory practices (Malik et al, 2015), an explicit consideration of regulatory independence in evaluation of electricity generation and emissions performance has not been explored in the Indian context, which we attempt in this study. Using a comprehensive dataset on Indian coal fired power plants for the period 2005–2014, we perform a two-stage data envelopment analysis in a meta-frontier framework taking into account regulatory environment as the grouping criteria, thereby allowing us to incorporate the effect of differing regulatory environments in performance measurement. In the first stage of the analysis, we use the non-radial directional distance function model in a meta-frontier framework to ascertain whether there is any efficiency penalty due to regulatory differences. Along with environmental inefficiency, we investigate inefficiencies in major areas of plant operations (electricity generation, CO2 emissions, and coal consumption), and find all of these worsening over the study period, suggesting that the regulatory environment has not sufficiently pushed plants to improve their performance. In the second stage of the analysis, we use regression techniques to investigate how regulatory independence and other factors such as plant technical characteristics (vintage, size, units, and equipment make) and location characteristics (coal mine adjacent or otherwise) affect both overall inefficiency levels as well as those for each input / output. This enables us to investigate the channels through which regulatory independence affects power plant performance, a novel contribution to the literature. We then propose a regulatory reform agenda for the electricity generation industry.",
61.0,1.0,Journal of Regulatory Economics,28 January 2022,https://link.springer.com/article/10.1007/s11149-021-09444-1,Input price discrimination and horizontal shareholding,February 2022,Youping Li,Jie Shuai,,Unknown,,Unknown,Mix,,
61.0,1.0,Journal of Regulatory Economics,31 January 2022,https://link.springer.com/article/10.1007/s11149-021-09442-3,Access price structure and entrant build-or-buy incentives in mobile markets,February 2022,Malin Arve,Øystein Foros,Hans Jarle Kind,Female,Male,Male,Mix,,
61.0,2.0,Journal of Regulatory Economics,29 March 2022,https://link.springer.com/article/10.1007/s11149-022-09447-6,Optimal WACC in tariff regulation under uncertainty,April 2022,Ward Romeijnders,Machiel Mulder,,Male,Male,Unknown,Male,"Operators of networks for the transport of electricity, gas and heat are generally subject to regulation because of the presence of natural monopolies which make it impossible to realize competition. The objectives of this regulation are directed at both the tariffs these network operators are allowed to charge and the quality of the performance of the networks (Viscusi et al. 2005; Mulder 2021). Hence, users of these networks should not pay more than needed to compensate for the required costs while the quality of the network services should be sufficiently high. In energy-policy terms, the first objective refers to the affordability of energy, while the latter refers to the reliability. The third policy objective of the so-called Energy Trilemma refers to the sustainability, but this objective is more realized through measures regarding the production and consumption of energy than through regulation of the network operators (World Energy Council 2018). Nevertheless, investments in networks may be required to facilitate, for instance, investments in renewable production. To realize the affordability and the reliability objectives regarding energy transport, the regulator faces a fundamental trade-off. This trade-off results from the impact of the regulated tariffs on the financeability of investments. Because of the affordability of network use, the network tariffs should be reduced as far as possible, but every reduction in tariffs reduces the revenues of the network operator which may make it difficult to finance investments in order to maintain or improve the reliability of network services (Mulder 2021). The presence of this trade-off implies that the value of grid reliability has to be weighed against the value of having low tariffs for network users. The societal importance of grid reliability follows from literature on the value of loss load, which gives estimates in the range of 10,000 to 25,000 euro per MWh (Schröder and Kuckshinrichs 2015). The societal importance of having low tariffs follows directly from the impact of these tariffs on the financial position of grid users. The contribution of this paper is that we determine for a key variable in the tariff setting how to deal with the trade-off between these policy objectives. This key variable in the tariff regulation is the so-called Weighted Average Costs of Capital (WACC). The importance of the WACC for the ability of network operators to invest follows from the fact that external financial means play a crucial role in these investments. The Dutch high-voltage grid operator TenneT, for instance, reports that it invested about 3.5 billion euro in 2020, which was financed through 2.75 billion (net) new loans and 0.4 billion net new contribution by equity and hybrid providers (TenneT 2021), and the remaining through internal sources. The challenge here is to find the optimal level of the WACC. If the WACC is set at a level that is lower than what is required by investors, grid operators may face difficulties in financing their investment, while when the WACC exceeds that level, grid users pay more than what is needed. Finding the appropriate WACC level is problematic because of the uncertainty about the future conditions of capital markets, while a regulator has to set the WACC in advance of a regulatory period. This holds in particular in the case of a tariff regulation which is based on a price-cap scheme in which allowed revenues are set for all future years of the new regulatory period of about three to five years. The WACC depends on many variables, such as the risk-free interest, the market-risk premium, the equity beta and the debt premium, which may fluctuate strongly (Dimson et al. 2000; Oxera 2015). Hence, the WACC is a stochastic variable. Generally, however, regulators use a deterministic approach in setting the WACC for the future regulatory period of 3 to 5 years (Council of European Energy Regulators 2019). They typically use historical data in order to set the value of the various parameters of the WACC. These values are generally determined on the basis of the mean values of historical distributions. Hence, implicitly, regulators assume symmetric economic consequences of deviations between the actual WACC during a regulatory period and the level that is assumed in the tariff regulation at the start of a regulatory period. After all, by setting the future WACC on the basis of the historical mean, the impact of a too high WACC for network users (i.e. they pay too much) are (implicitly) equally valued as the impact of a too low WACC (e.g. a higher probability of disturbances in network services). A few authors have addressed the impact of uncertainty regarding the WACC. Dobbs (2011) applies a Monte-Carlo model of a network operator which investment’ decisions depend on the actual cost of capital versus the rate set by the regulator. For sunk investments, the optimal WACC appears to be about equal to the mean of the distribution, but for new investments, the optimal WACC appears to be significantly larger. Schober et al. (2014) analyze the spread in the risks among regulated companies subject to the same regulatory scheme. This variation in risks among these companies are related to the failure probabilities of assets which result in different cash flows for the regulated companies. When a regulator takes these individual circumstances into account, the WACC can be significantly higher for some regulated companies. Our paper differentiates from these papers since we explicitly include the impact of investments on the reliability of network services. In this paper, we analyze to what extent the optimal WACC in tariff regulation deviates from the distribution mean if we control for the impact of the allowed return on capital on grid investments and consequently on the quality of network services. We develop a stylized model of a network operator subject to price-cap regulation. This network operator has as objective to maintain the quality of its services. In order to realize that objective, it regularly replaces a part of the network infrastructure because of aging. It is assumed that the likelihood of network disturbances quadratically increases with the average age of the infrastructure. The ability to realize these investments depends on the allowed level of revenues, in particular the level of the WACC. The regulator determines the allowed level of revenues for every regulatory period, pursuing the objective to maximize consumer welfare. The latter objective, which does not include firm profits, is generally chosen by regulators of natural monopolies. Afterall, a general objective of tariff regulation is to redistribute welfare from the monopolistic grid operators to grid users (see Viscusi et al. (2005); Mulder (2021)). This welfare depends on two components: the consumer surplus resulting from the actual usage of the network in relation to the tariffs which consumers have to pay as well as the value of lost load resulting from network disturbances. The optimum level of allowed revenues depends not only on the expected values for the costs of capital, but also on its standard deviations. This optimum level is determined by maximizing a Monte Carlo approximation of consumers’ expected welfare. We find that the optimum level of the WACC, which is the level that maximizes the expected social welfare, is higher than the WACC which is determined as the mean of the historical data. Only in case of high uncertainty about the true costs of capital while grid operators are able to quickly increase investment levels, the optimal WACC is below the historical mean. The explanation for that is that in such cases it is less likely that the WACC is constantly insufficient to cover actual costs of capital. Of course, the results are sensitive to the assumption regarding the value of lost load. In particular, we find that the optimal level of the WACC exceeds the historical average WACC if the value of lost load exceeds 7,500 euro per MWh. In general, the higher the value of lost load, the more the optimal WACC exceeds the historical average WACC. The outline of this paper is as follows. Section 2 briefly discusses literature about tariff regulation, investments and quality of network services. Section 3 presents our stochastic regulatory model, while Sect. 4 describes the data and assumption. The findings are discussed in Sect. 5, while Sect. 6 concludes.",1
61.0,2.0,Journal of Regulatory Economics,11 April 2022,https://link.springer.com/article/10.1007/s11149-022-09446-7,"Regulation, entrepreneurship, and firm size",April 2022,Dustin Chambers,Patrick A. McLaughlin,Tyler Richards,Male,Male,,Mix,,
61.0,2.0,Journal of Regulatory Economics,09 April 2022,https://link.springer.com/article/10.1007/s11149-022-09448-5,Does capital-based regulation affect bank pricing policy?,April 2022,Dominika Ehrenbergerová,Martin Hodula,Zuzana Gric,Female,Male,Female,Mix,,
61.0,2.0,Journal of Regulatory Economics,20 March 2022,https://link.springer.com/article/10.1007/s11149-022-09445-8,Correction to: Input price discrimination and horizontal shareholding,April 2022,Youping Li,Jie Shuai,,Unknown,,Unknown,Mix,,
61.0,3.0,Journal of Regulatory Economics,27 July 2022,https://link.springer.com/article/10.1007/s11149-022-09450-x,Size control or intensity control: a comparative study of two Common Environmental Regulations,June 2022,Hongyu Nian,Chunhua Wang,Haitao Yin,Unknown,Unknown,Unknown,Unknown,,
61.0,3.0,Journal of Regulatory Economics,21 July 2022,https://link.springer.com/article/10.1007/s11149-022-09451-w,Can regulation enhancing the shareholder franchise increase firm value?,June 2022,Anne-Marie Anderson,Nandu Nayar,,Female,Unknown,Unknown,Female,"Prior research (see Larcker et al., 2011, p. 433) questions the relevance of, and by extension, the need for corporate governance regulation. Specifically, the main thrust of their research is that corporate governance regulations generally reduce shareholder wealth. Additionally, where regulations do not reduce equity value, they find no reaction whatsoever. Importantly, none of the corporate governance regulatory events they examined were shown to increase equity value. The natural inference is that companies should be able to choose their own corporate governance mechanisms without any interference from regulatory bodies. Specifically, in an environment unfettered by regulation, corporate governance practices will evolve such that only optimal policies will survive in equilibrium. Consequently, any regulation involving corporate governance will perturb that purportedly optimal equilibrium, and thereby not create any additional firm value, and even possibly destroy value.Footnote 1 Therefore, corporate governance regulation is perceived as not beneficial for firm value. We re-examine this issue by focusing on corporate governance regulation that increases the shareholder franchise. Specifically, we focus primarily on regulation that repealed discretionary broker voting for the election of board directorsFootnote 2. Eliminating broker voting permits computation of an approval rate for directors that more accurately reflects shareholder opinion because the contaminating effect of broker-votes is removed, thus strengthening the shareholder mandate. Prima facie, this regulation may not be expected to produce any value-change since board of director election results are not binding; they are merely advisory in nature (e.g., see Aggarwal et al., 2019). The question that arises is—Does the knowledge regarding investor opinion of director candidates in uncontested elections really matter when the outcome is a foregone conclusion? In this context, the literature provides insights into how transparency in corporate voting is important. For example, low votes received by candidates may cause embarrassment and negative publicity for directors and companies involved (e.g., Grundfest, 2003; Masulis & Mobbs, 2011). Fischer et al. (2009) document that low approval rates have negative implications for the firm following the outcome of elections. Ertimur et al. (2018) find that shareholders employ low approval rates to force firms to address specific problems identified by proxy advisors. Importantly, Aggarwal et al. (2019) report that while uncontested elections are a routine matter, the directors themselves are not immune from low voting results. Specifically, there are negative consequences for the directors who face a low approval rate, which include removal from important board committees, or from the board altogether, and reduced demand in the market for external directors. Fischer et al. (2009), Ertimur et al. (2018) and Aggarwal et al. (2019) thus demonstrate strongly that the vote-approval rate is a uniquely meaningful measure for the firms themselves, and for the director candidates, respectively, even though the outcomes of those uncontested elections are a foregone conclusion. Since the approval rate has informational value, it should ideally capture actual shareholder opinion on directors in an unambiguous fashion. However, prior to 2010, brokers could vote shares on behalf of shareholders who did not actually submit their proxy vote. Such discretionary broker voting can contaminate the “true” approval rate because it has been claimed that brokers typically vote in accordance with managements’ recommendation (see Dixon & Thomas, 1998; Bethel & Gillan, 2002). In 2009, the SEC enacted regulations to eliminate discretionary broker voting for director elections held in 2010 and thereafter. The subsequent vote-approval rate should therefore more accurately capture true shareholder opinion without the contaminating effect of brokers voting for shareholders who do not tender their voting instructions. Given the results in Fischer et al. (2009), Ertimur et al. (2018) and Aggarwal et al. (2019), the heightened visibility of shareholder opinion via the elimination of broker voting should strengthen the shareholder franchise. In turn, strengthening the shareholder franchise should be associated with increased shareholder value. Specifically, when shareholders have greater “voice” in the firm in which they have invested, incumbent management will realize that they cannot slack off since their reputation and job security will be at peril. The reduced agency costs under this perspective should lead to more efforts by incumbent management to maximize shareholder value, leading to an increased stock price. This regulatory change thus constitutes an ideal exogenous event to see whether corporate governance regulation strengthening the shareholder franchise increases firm value. Indeed, we find a strong positive stock price reaction to the passage of this regulatory rule eliminating discretionary broker voting on July 1st, 2009. This positive valuation effect unambiguously supports the view that enhancing the shareholder franchise via a transparent voter approval rate is beneficial to firm value. Our study, contrary to Larcker et al. (2011), thus demonstrates that corporate governance regulation can affect firm value positively. Additionally, in this paper, we explore the importance of the shareholder vote approval rate reported by Fischer et al. (2009), Ertimur et al. (2018) and Aggarwal et al. (2019) via a different empirical approach. Specifically, we observe whether the market actually assigns economic value to the prospect of obtaining accurate approval rates from regulatory change, and not through any transaction initiated by the firm in question (Fischer et al., 2009), or by advice from proxy advisors (Ertimur et al., 2018) or to director-specific issues (Aggarwal et al., 2019) in the affected firm. Since these events are firm-specific or director-specific, respectively, our empirical setting which is based on an exogenous event provides relief from any self-selection issues that may have affected these prior studies. Specifically, the use of a regulatory event alleviates endogeneity concerns and self-selection bias which may affect inferences. Further, we examine whether the economic value underlying enhancing the shareholder franchise is associated with firm-specific characteristics. We focus on corporate governance metrics to determine whether the regulation is differentially beneficial to firms with inferior corporate governance. The results also add to the evidence on the importance of transparency in corporate voting, and the relevance of corporate governance regulations in establishing that transparency. Our results show that strengthening the shareholder franchise is more beneficial for firms with inferior corporate governance. Ours is the first study to document this cross-sectional relationship.",
61.0,3.0,Journal of Regulatory Economics,21 July 2022,https://link.springer.com/article/10.1007/s11149-022-09449-4,Optimal pricing and investment for resources with alternative uses and capacity limits,June 2022,Alessandro Avenali,Tiziana D’Alfonso,Pierfrancesco Reverberi,Male,Female,Male,Mix,,
62.0,1.0,Journal of Regulatory Economics,22 August 2022,https://link.springer.com/article/10.1007/s11149-022-09452-9,Differences in NPI strategies against COVID-19,December 2022,Margarete Redlin,,,Female,Unknown,Unknown,Female,"With the outbreak of the COVID-19 pandemic, many countries began implementing contact restrictions to reduce contacts and thus counteract the spread of the virus. Non-pharmaceutical interventions (NPIs) have been and continue to be used as an important tool against Corona. However, the lockdown strategies pursued are not homogeneous across countries. While some countries attempted to counteract the virus with very strict lockdown strategies and measures such as travel bans, school closures, and curfew restrictions even at quite low incidences, other countries largely refrained from imposing mandatory restrictions and merely issued recommendations for action. Countries in Southeast Asia as well as Australia tried to pursue a zero covid strategy with early border closures, entry barriers, and isolation by imposing a strict lockdown in entire regions even at low incidence levels and trying to eliminate the virus through extensive testing and tracking. Western European countries also show relatively high restrictions. For example, countries such as Germany, France, Italy, and Greece have made vaccination compulsory in certain professions or age levels, and Austria has made it compulsory for the entire adult population. In France, for example, participation in public life is only possible with a health passport, in Austria introduced a lockdown for the unvaccinated, and Germany has been in lockdown several times and the 2G or 2G plus rule applies to participation in public life (2G = only vaccinated or recovered, 2G plus with additional test). Sweden, on the other hand-unlike most of its European neighbors-relied more on voluntarism. And so there were, and still are, primarily only recommendations on how to behave, rather than regulations whose disregard would entail consequences or penalties. And the U.S. version was accompanied by regionally different and in part very strict restrictions. However, these were relaxed early on so as not to harm the economy in the long-term. Thus, it is evident that lockdown strategies across countries were not defined by infection incidence alone. Regional, economic, and institutional factors also appear to be important and thus are the focus of this study. Our empirical investigation examines the determinants that played a role in setting the lockdown course and analyze country characteristics associated with strict and less strict lockdown strategies. Based on daily panel data for 173 countries and the period from January 1, 2020 to October 23, 2021, we identify the factors that were driving the stringency of the lockdowns. Using GMM and IV techniques to account for a potential endogeneity between the stringency level of NPIs and the spread of the virus and taking into account the actual development of infection and the respective vaccination coverage, our results show that less developed countries and countries with less established institutions and autocratic regimes have adopted harsher lockdown measures. We also identify significant regional differences in the adoption of NPIs. All in all, our findings offer a fruitful contribution to the debate on determinants of NPIs. The remainder of this paper is organized as follows. Section 2 provides an overview of recent studies and forms the hypotheses for the empirical examination. Section 3 presents the empirical model, the data and our result, and Sect. 4 concludes.",3
62.0,1.0,Journal of Regulatory Economics,03 October 2022,https://link.springer.com/article/10.1007/s11149-022-09453-8,Access pricing regulation in the U.S. domestic aviation industry,December 2022,Douglas C. Turner,,,Male,Unknown,Unknown,Male,"In many industries, downstream firms require access to upstream infrastructure for the production of a final good. The fee that downstream firms pay for access to infrastructure, termed an access charge, is often regulated. In the aviation industry, airlines require access to airport facilities to provide passenger service. Airlines pay airports a per-passenger fee for the right to use the airport.Footnote 1 When setting an access charge, a regulator implicitly places an importance on each component of social surplus.Footnote 2 Regulatory preferences determine observed regulation and are central to the analysis of a regulatory policy. A substantial empirical literature explores the preferences of regulators when the final price is regulated.Footnote 3 The present research contributes to the literature by examining regulatory preferences in the setting of access prices, not final prices. First, I develop a methodology for inferring regulatory preferences in the access pricing setting. Second, I apply this methodology to the U.S. domestic aviation industry, exploring the evolution of regulatory preference over time.Footnote 4 In the U.S. domestic aviation industry, a per-passenger access charge is referred to as a passenger facility charge (PFC). PFCs were introduced in 1992 and are subject to price cap regulation. Despite protestation from airports, this price cap has not been raised since 2001, even to keep pace with inflation. Airports contend that an increase is necessary to build sufficient infrastructure capacity to meet growing air travel demand. Appeals to raise the cap face fierce opposition from passenger airlines and their lobbyists. An unchanged or reduced price cap does not imply regulators have placed less importance on airports. Changes in consumer preferences or downstream market structure can raise the incremental cost, in terms of airline profit and consumer surplus, of an existing price cap. To determine if current regulatory policy represents an increased preference for airports relative to airlines and/or consumers, it is necessary to uncover the relative importance placed on airports by the regulator. I assume a regulator acts to maximize a weighted sum of consumer surplus, downstream firm profit, and airport surplus in both periods. I define airport surplus to be total airport access charge revenue because PFC revenue helps airports achieve their stated goals of improving airport quality and safety.Footnote 5 Demand estimates and an assumption of Bertrand Nash competition allow for the estimation of consumer surplus, downstream profit, and airport PFC revenue. However, the weights that a regulator places on each component are unknown. I use observed access prices to infer the weight on airport revenue which rationalizes the observed regulatory decision. This weight represents the importance the regulator placed on airports at a given time.Footnote 6 The current study estimates this weight, in both 2000 and 2018, to determine whether regulatory preferences have shifted in favor of airlines or airports.Footnote 7 My findings suggest that the weight regulators placed on airports increased between 2000 and 2018. In other words, regulatory decision-making in 2018 is consistent with the maximization of a social welfare function that places greater weight on airports than in 2000. This is despite the PFC cap declining in real terms. This result is caused by an increase in the price elasticity of passenger travel demand. More consumers are making purchases directly, rather than through travel agents, due to the introduction of online booking. Because consumers are more price-sensitive than travel agents, who tend to choose the shortest route rather than the cheapest, consumer demand is more elastic. Additionally, a greater portion of consumers travelled for leisure purposes in 2018 than in 2000. Leisure travelers are typically more price-sensitive than business travelers. Because demand is more elastic in 2018, the elevated downstream prices due to access charges caused more consumers to substitute away from air travel. This results in diminished consumer surplus and airline profits. Even though access charges have declined in real terms, the burden of those charges on both consumers and airlines has increased. The current regulatory policy represents a shift in preference towards airports and away from airlines and/or consumers.Footnote 8 An understanding of how implied regulatory preference has evolved over time is helpful when evaluating recent proposals to increase the PFC cap.Footnote 9 For example, a recent RAND report commissioned by Congress (Miller et al., 2020) argues the price cap should be increased back to 2001 levels in real terms (recall that the PFC cap is not indexed for inflation and therefore has declined in real terms since 2001). If the decline in the PFC cap since 2001 (in real terms) is consistent with a reduction in regulatory preference for airports, this proposal would represent a return toward 2001 regulatory preferences. In contrast, if regulatory preference for airports has increased since 2001, this proposal would represent a further reduction in preference for consumers and airlines relative to airports. The current study addresses this question and finds that regulatory preference for airports has increased over time. Thus, recent proposals to increase the cap would represent a further shift in preference towards airports. Determining how implied regulatory preference has evolved over the past 20 years is also informative for regulators setting the cap. For example, suppose Congress wishes to maintain its regulatory preference for airports over time and give the same weight to airports, airlines and consumers as in 2001. To implement these preferences, one may believe that the price cap should be increased back to 2001 levels (in real terms) as the PFC has declined in real terms between 2001 and 2018.Footnote 10 However, the results of this study suggest that this is not the case. Due to changes in consumer demand, a reduction, rather than increase, in the price cap would be necessary to restore prior levels of regulatory preference. More generally, the results of this study stress the importance of accounting for changes in factors such as demand, cost, market structure when making regulatory decisions. The next section provides background on passenger facility charges in the U.S. domestic aviation industry. Section 3 introduces the methodology, air travel demand, airline competition, airport pricing, and the regulator’s problem. Section 4 discusses data and Sect. 5 discusses estimation of the demand model. Section 6 presents demand estimation results and presents estimates of regulatory preference. Section 7 contains counterfactual simulations that demonstrate the effects of regulatory preferences in detail. Section 8 concludes. Additional details and analyses are available in the Online Appendix.Footnote 11",
62.0,1.0,Journal of Regulatory Economics,31 October 2022,https://link.springer.com/article/10.1007/s11149-022-09454-7,Welfare optimal reliability and reserve provision in electricity markets with increasing shares of renewable energy sources,December 2022,Fridrik Mar Baldursson,Julia Bellenbaum,Christoph Weber,Unknown,Female,Male,Mix,,
63.0,1.0,Journal of Regulatory Economics,06 March 2023,https://link.springer.com/article/10.1007/s11149-022-09455-6,Environmental regulation and energy efficiency: evidence from daily penalty policy in China,April 2023,Kai Hu,Dandan Li,Wenli Xu,Male,Unknown,Unknown,Male,"Scientific development and technological progress in recent decades have contributed to incredible economic growth as well as an increase in energy consumption and pollution emissions (Fouquet, 2016; Nasrollahi et al., 2020). To achieve a dynamic balance between economic growth and environmental pollution, many countries have adjusted and optimised their economic structures, and enacted a series of environmental regulations (Hashmi & Alam, 2019; Ringel et al., 2016; Saidel & Alves, 2003). The associations between environmental regulations, productivity and energy efficiency have been studied for many years (Gillingham et al., 2009; Jaffe & Palmer, 1997; Zhang et al., 2020a, 2020b). Generally, there is a consensus in these studies that strong environmental regulations can promote innovation so as to solve environmental problems and maintain economic growth (Ambec et al., 2013; Porter, 1991), identified as the ‘Porter effect’ (Porter & Van Der Linde, 1995). Furthermore, Jaffe and Palmer (1997) explore the difference in the levels of the ‘Porter effect’ by observing whether or to what extent environmental regulations can increase a firm’s profits and reduce environmental pollution. Based on their study, environmental regulations can be divided into two types. The first is the command-and-control regulations (CAC), which aims to reduce environmental pollution and requires that governments should stringently supervise and enforce these environmental regulations (Zhang et al., 2020a, 2020b). Second, if the environmental regulations are to maximise firms’ profits that may offset the cost of environmental management, they are called as market-based instruments (MBI) (Zhang et al., 2019a, 2019b). The dual purpose of strong environmental regulations is that pollution reduction coincides with the improvement of energy efficiency or energy conservation (Hampf & Rødseth, 2019; Wang et al., 2016; Zhang et al., 2015). Although previous studies suggest that various environmental regulations have different levels of effects on energy efficiency, they all find that there is an association between environmental regulations and energy efficiency (Bi et al., 2014; Boardman, 2004; Guo & Yuan, 2020; Zhang et al., 2020a, 2020b). Generally, although environmental regulations increase the cost of environmental management, the advantage of these regulations forces firms to invest more capital in technological innovation and pollution reduction, which improves energy efficiency (Mandal, 2010). However, evidence shows that the effects of environmental regulations on energy efficiency are not linear but U-shaped, and dependent on the types of regulations and governments’ supervision (Wu et al., 2020; Yuan & Xiang, 2018). The impact of environmental regulations on pollution emissions has received a lot of attention in the literature. A large number of studies have examined the effectiveness of environmental regulations in reducing emissions, indicating that environmental regulations can optimize resource allocation to improve production and reduce pollution emissions (Cole et al., 2005; Liu et al., 2020). Furthermore, evidence shows that both formal and informal environmental regulations can reduce pollution emissions (Cole et al., 2005; Han et al., 2018), but the effectiveness of environmental regulations depends on the politically and categorically variable role of regulations (Shen et al., 2017). Specifically, MBI regulations are costly to monitor and difficult to achieve an optimal state if the market mechanism is the only force to solve environmental problems (Hirose & Matsumura, 2020). Additionally, some studies show that most CAC regulations are often less effective than expected since these regulations do not take into account the differences among firms but enforce uniform regulations for all of them (Li et al., 2016; Muller & Mendelsohn, 2009). In terms of the ‘Porter effect’ of environmental regulations, some studies show that MBI regulations can empower firms to adjust their market strategies and innovate without massive fixed conditions and hence are more likely to achieve sustainable development (Gillingham et al., 2009; López-Gamero et al., 2010). Overall, MBI regulations hypothesise that firms can upgrade their technologies and use more clean energy to improve energy efficiency. The benefits from efficiency improvement can in turn offset the cost of investment in technologies and clean energy. However, if firms assess the marginal profits of environmental management as negative (extra revenues more than extra costs), they have no motivation to make environmental management due to the lack of a forced and fixed regulation (Rasti-Barzoki & Moon, 2020). Thus, considering that the demand for energy is inelastic, the small incentive over tax might be a reason why the effects of some MBIs are not significant in some countries, such as China. Indeed, CAC regulations are increasingly implemented in China and most of them have achieved substantial effects on environmental improvement (Huang & Zou, 2020). Nevertheless, some studies criticise CAC regulations increase the cost of supervision and can only impose restrictions on highly polluting firms (Kathuria, 2006; Zhang et al., 2019a, 2019b). Therefore, it is necessary to design and implement a new environmental regulation to overcome these disadvantages. Fortunately, to better address environmental issues, many cities have tried to adjust their environmental regulations (Nie et al., 2020). For example, Chongqing, one of the municipalities in China, implemented a stringent environmental regulation, Daily Penalty Policy (DPP) in 2008. Compared with previous environmental regulations, DPP emphasizes daily fines for pollution which dramatically increases the cost of violating environmental regulations (Bu & Shi, 2021). In this context, we investigate whether cumulative fines of DPP can improve energy efficiency as well as lead to pollution reduction. The main purpose of this paper is to evaluate the energy effect of DPP. Compared with previous studies, this study makes three contributions. First, DPP provides a specific lens to observe the effects of stringent environmental regulation. Compared with traditional regulations, the cost of environmental pollution significantly soars with the implementation of DPP for all firms (Bu & Shi, 2021). Although previous studies show that environmental regulations can affect energy efficiency (Bi et al., 2014; Guo & Yuan, 2020; Zhang et al., 2020a, 2020b), their cases are not based on an extremely stringent environmental regulation. Thus, this study can provide a special case to assess the effect of a stringent environmental regulation on energy efficiency. Second, this study offers new evidence for the effect of environmental policies. By estimating the effects of DPP, we can examine whether CAC regulations can achieve substantial effects on environmental improvement in China (Huang & Zou, 2020), and then offer suggestions on environmental management about how to achieve pollution reduction and win–win economic progress. Third, this study includes a series of robustness, mechanisms and heterogeneity checks which reveal the influencing mechanism and heterogeneous effects of DPP. While this study uses a case of China, the findings about the stringent environmental regulation may be used to improve energy efficiency and environmental pollution in other countries. ﻿The rest of this paper is organized as follows. Section 2 introduces the context of DPP and a theoretical framework. Section 3 describes the methodology used, and Sect. 4 presents the estimation results of DPP on energy efficiency in China. In Sect. 5, we summarise the main findings in this study, make a discussion in relation to previous studies, and then conclude this study.",1
63.0,1.0,Journal of Regulatory Economics,09 January 2023,https://link.springer.com/article/10.1007/s11149-022-09456-5,Employing gain-sharing regulation to promote forward contracting in the electricity sector,April 2023,David P. Brown,David E. M. Sappington,,Male,Male,Unknown,Male,"It is well known that forward contracting can motivate electricity generators to compete more aggressively and thereby reduce the expected wholesale price of electricity (e.g., Allaz & Vila, 1993; Bushnell et al., 2008). However, it has also been noted that regulated load serving entities (LSEs)—large buyers of electricity that deliver electricity to retail customers—often are reluctant to engage in forward contracting. The reluctance arises in part because forward contracting can expose LSEs to significant risk of financial penalties with limited potential for financial rewards. In practice, LSEs seldom are awarded a portion of the gains from forward contracting, but often are held financially responsible for the “ overpayments” they are perceived to have made when the cost of electricity secured via forward contract exceeds the wholesale price of electricity (Costello, 2012; Cicchetti, 2017; Gettings, 2017). The present research investigates two elements of this problem. First, we examine the magnitude of the problem that can arise in restructured electricity markets by analyzing the amount by which electricity procurement costs increase when LSEs decline to implement the levels of forward contracting preferred by generators. Second, we examine how gain-sharing regulation can be employed to avoid these elevated procurement costs. Specifically, we examine the share of realized gains from forward contracting an LSE must anticipate before it will undertake forward contracting in settings where the LSE faces significant risk of financial penalties should the forward price of electricity ultimately exceed the realized wholesale price. Employing data from electricity markets in Alberta, Canada to calibrate our model, we find that forward contracting can reduce electricity procurement costs substantially (e.g., more than \(25\%\)) under arguably plausible conditions. We also find that relatively modest gain sharing (often less than \(10\%\)) can induce LSEs to agree to the levels of forward contracting preferred by generators even in the presence of substantial risk of penalties for perceived overpayments. Only modest gain sharing is required because the amount by which forward contracting reduces the expected wholesale price of electricity often substantially exceeds likely differences between the forward price and the wholesale price of electricity. A well-established literature (e.g., Allaz & Vila, 1993; Bushnell, 2007; Bushnell et al., 2008; Holmberg, 2011) examines many elements of forward contracting, including the role it can play in reducing equilibrium wholesale prices.Footnote 1 Although we contribute some new analytic findings to this literature, this contribution is modest because our findings reflect standard principles. Our primary contribution is to examine how the risk of financial penalties associated with forward contracting in restructured electricity markets can render LSEs reluctant to undertake such contracting, and to demonstrate how standard (and relatively modest) forms of gain-sharing regulation can overcome this reluctance, thereby facilitating the realization of the substantial gains that forward contracting can engender.Footnote 2 The analysis proceeds as follows. Section 2 describes the key elements of our model. Section 3 characterizes equilibrium outcomes both in the presence of forward contracting and in its absence. Section 4 examines the potential gains from forward contracting in a setting designed to reflect conditions that prevail in Alberta’s electricity sector. Section 5 considers the risk of financial penalties that forward contracting can impose on LSEs and examines the extent of gain sharing that will motivate an LSE to undertake forward contracting despite the risk it entails.Footnote 3 Section 6 provides concluding observations. The Appendix provides the proofs of all formal conclusions.",
63.0,1.0,Journal of Regulatory Economics,14 February 2023,https://link.springer.com/article/10.1007/s11149-023-09457-y,One size fits all? The differential impact of federal regulation on early-stage entrepreneurial activity across US states,April 2023,John A. Dove,,,Male,Unknown,Unknown,Male,"Entrepreneurship and entrepreneurial activity tend to be a driving force behind economic growth and development (Kirzner, 1978; Schumpeter, 1942). Where opportunities are provided that allow entrepreneurial endeavors to capitalize on growth-enhancing and productive opportunities, then this can stimulate economic activity and development in general. Thus, it is the “rules of the game” and existing institutional structures and frameworks that will either incentivize or disincentivize individuals from pursuing such activities (See North, 1989 on the relationship between institutions and economic growth).Footnote 1 Importantly, it may not be so much that the institutional environment will impact the stock of entrepreneurs and entrepreneurial effort, however it does directly impact the type of entrepreneurial effort put forth—relatively speaking (Baumol, 1990). Specifically, entrepreneurial efforts and opportunities are those that can be productive (and growth enhancing), unproductive (leading to net transfers, with no real accompanying growth), or destructive (which actively undermines existing capital stocks) (Baumol, 1990). The institutional environment, then, will directly influence how entrepreneurs—both existing and would-be—devote their resources and efforts. It is through these mechanisms that the institutional environment can affect entrepreneurial efforts and with it economic growth in general. Tied to this is the regulatory environment that exists within a given jurisdiction, how it is enforced, and how the relative burden falls on various groups or industries within an economy. Where market failures exist and result in an inefficient allocation of resources, then public regulation can be applied to correct those failures. This would promote economic efficiency thereby directing entrepreneurial endeavors toward efficient, growth-enhancing activity. On the other hand, it is possible—be it through rent-seeking, regulatory capture, or some other means—for regulation itself to generate greater inefficiencies and impose inefficiently high costs on pursuing productive and growth-enhancing economic activities. This study develops these considerations by evaluating how or even if the relative burden that federal regulations impose ultimately impact entrepreneurial efforts across all 50 US states. Given geographical, jurisdictional, and market concentration differentials, federal regulations do not tend to have a uniform impact across states. Thus, a federal regulation that uniformly applies across all states may have a disproportionate impact within those states, which may also differentially impact entrepreneurial activity across states. To evaluate these possibilities, I use a recently developed measure of federal regulations’ impact across states: the FRASE index (to be discussed in greater detail below). This measure is evaluated against various measures of early-stage entrepreneurship specifically taken from the Kauffman Index of Entrepreneurship. Included here, along with an index measure of early-stage entrepreneurship, this study also considers how rates of new entrepreneurship, opportunity entrepreneurship, early-startup job creation, and early-startup survival rates might be impacted by the relative burden that federal regulations have across US states with data from 1998 to 2017. Overall, after controlling for a number of factors, the results suggest that opportunity entrepreneurship along with early-stage job creation, and early-stage entrepreneurship as a whole are all negatively associated with disproportionately more burdensome federal regulatory environment. Finally, the rate of new entrepreneurship and early startup survival rates do not show a strong association with the federal regulatory burden in a given state. Implications are discussed. The paper is structured as follows: a review of the relevant literature and theoretical considerations are presented in Sect. 2. A detailed discussion of the data employed and empirical specifications are provided in Sect. 3. The results and possible explanation of the results are found in Sect. 4, while Sect. 5 contains concluding remarks.",
63.0,1.0,Journal of Regulatory Economics,08 March 2023,https://link.springer.com/article/10.1007/s11149-023-09458-x,Does an effective bankruptcy reform increases collateralized borrowing? Evidence from a quasi-natural experiment in India,April 2023,Ranjeet Singh,Yogesh Chauhan,Nemiraja Jadiyappa,,Male,Unknown,Mix,,
63.0,1.0,Journal of Regulatory Economics,21 March 2023,https://link.springer.com/article/10.1007/s11149-023-09459-w,Price freezes and gas pass-through: an estimation of the price impact of electricity market restructuring,April 2023,Alexander Hill,,,Male,Unknown,Unknown,Male,"The welfare effects of industry deregulation have received considerable amount of attention in the economics literature.Footnote 1 Deregulation often occurs in industries with high retail prices, with advocates arguing that a liberalized market structure will lead to greater innovation, improved efficiency in production and distribution, and, ultimately, lower retail prices. Yet evidence of these overall price effects is limited across industries, typically because of the difficulty in estimating the counterfactual price path. Recognizing the difficulty that previous methods and case studies have encountered, this paper applies the synthetic control methodology to the electricity industry to estimate the retail price effect of full industry restructuring. The electricity industry, due to its size and the staggered and incomplete nature of its deregulation, is an ideal case study in determining the effects of market liberalization on retail prices. It was widely expected that electricity market liberalization, commonly referred to as restructuring, would lead to reduced prices. This was, in fact, a major motivating factor for states to restructure, with the first states (California and the Northeast) traditionally having higher electricity prices than the rest of the country. Joskow (1997) notes that, while this effect was unlikely to be observed in the short run, improvements in operational and build efficiency would reduce prices in the medium to long-term. However, that price gap never closed (Fig. 1) and, during the years of high natural gas prices, actually widened. Source: EIA (2021) Electricity prices by market regulation. Notes: ElecReg is the weighted average electricity retail price across all states that did not restructure. ElecRestruct is the weighted average electricity retail price of all states that currently have retail competition. Gas is the real price of natural gas delivered to the electricity sector. The failure of market liberalization to close this price gap has been puzzling, particularly as a number of papers found restructuring led to increases in generating and cost efficiency (Fabrizio et al., 2007; Zhang, 2007; Craig & Savage, 2013; Cicala, 2015; Chan et al., 2017; Cicala, 2022) while not compromising safety (Hausman, 2014). However, there is also evidence of market power leading to non-optimal market outcomes (Borenstein et al., 2002; Hortacsu & Puller, 2008; Joskow & Kahn, 2002; Mansur, 2008; Wolfram, 1999) as well as overinvestment (Hill, 2021). These opposing effects leave the total impact unclear, with attempts to measure the impact directly also having mixed results. Apt (2005) and Fagan (2006) find insignificant effects for industrial consumers, Su (2015) finds effects only for residential customers in the short run, and Borenstein and Bushnell (2015) find no significant effect after controlling for gas prices.Footnote 2 A significant obstacle for these papers is the construction of a valid counterfactual price outcome for restructured states. Previous studies rely on states that didn’t restructure as a counterfactual, using either OLS or synthetic control as an empirical strategy and controlling for factors which might bias the result.Footnote 3These approaches must confront significant differences in supply and demand factors between states that can create poor estimation of counterfactual outcomes.Footnote 4 In particular, the Northeast is included in these studies, despite its climate, reliance on oil and legacy electricity costs resulting in no valid counterfactual observations.Footnote 5 This paper addresses this challenge in four ways. First, synthetic control is used as an estimation method to construct a counterfactual for each restructured state.Footnote 6 This technique is useful in constructing accurate counterfactual outcomes through weighted, unique factors, consisting of combinations of multiple states that match the pre-treatment price trend. The difference between each state’s outcome and its synthetic counterfactual is calculated and the average effect reported. Second, the Northeastern states and DC are eliminated from the analysis. While this limits the sample, it’s necessary in order to obtain a valid counterfactual. Third, specific factors that influence electricity prices are included as matching variables for synthetic control, particularly fuel used for generation. Finally, this paper uses electricity prices differenced from 1990 as the primary outcome variable, allowing for counterfactual observations that match trends in restructured-state prices closer to the restructuring date. Using the staggered adoption of full restructuring to identify the effect, this paper finds full restructuring reduced retail electricity prices overall by $1.5/megawatt hour (MWh), relative to the counterfactual.Footnote 7 This effect is small, as the average restructured state electricity price during this period was $135.6/MWh. It also varies significantly by sector, with residential (− $5.1/MWh) experiencing a price drop, commercial mostly breaking even (− $0.4/MWh) and industrial ($1.6/MWh) facing higher prices. For the average residential customer, this translated into an average saving of approximately $55 per year. However, these gains are influenced by price cuts and freezes in the 2000s, as retail electricity prices rose compared to the counterfactual, on average, in the decade following the removal of price controls. This paper also finds that natural gas prices, which peaked in 2008 and subsequently fell by over 50%, had an effect on the price differential between fully-restructured states and their counterfactual. This effect is attributed to a higher pass-through rate of gas prices in restructured states, a finding consistent with other papers in the literature (Knittel et al., 2019). These results highlight three important facets of the impact of restructuring on electricity prices. First, the previously identified residential price effect was heavily influenced by state price freezes, with prices rising significantly post-freeze. Second, the restructuring impact on price is heterogeneous, with industrial users losing some of their price advantage. Third, electricity prices in fully-restructured states are linked to wholesale markets, which was a goal (Bushnell et al., 2017). Section 2 provides further information on restructuring. Section 3 explains the empirical methodology. Section 4 introduces the data and provides summary statistics. Section 5 presents the main results of this paper. Section 6 analyzes the impact of prices freezes and natural gas prices on the results. Section 7 concludes and provides policy recommendations.",
