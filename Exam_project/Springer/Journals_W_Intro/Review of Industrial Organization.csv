Volume,Issue,Journal Name,Published Date,Link,Title,Journal Year,Author 1,Author 2,Author 3,Gender_Author 1,Gender_Author 2,Gender_Author 3,Article_Gender,Intro,Citations
1.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02354131,Changes in market concentration of manufacturing industries,March 1984,Willard F. Mueller,Richard T. Rogers,,Male,Male,Unknown,Male,,20
1.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02354132,"Collusion, entry, and market shares",March 1984,John P. Formby,W. James Smith,,Male,Unknown,Unknown,Male,,1
1.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02354133,The new merger guidelines of the department of justice,March 1984,Lucile S. Keyes,,,Female,Unknown,Unknown,Female,,2
1.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02354134,"Size, efficiency, and fortune nagazine",March 1984,Douglas F. Greer,,,Male,Unknown,Unknown,Male,,
1.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02354135,An examination of industry exit patterns,March 1984,Larry L. Duetsch,,,Male,Unknown,Unknown,Male,,10
1.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02354136,Neglected elements in vertical integration analysis: The case of retail price preticketing,March 1984,Stanley E. Boyle,Michael J. Piette,,Male,Male,Unknown,Male,,
1.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02354137,P. David Qualls,March 1984,Joe S. Bain,,,Male,Unknown,Unknown,Male,,
1.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02354345,Merger statistics and merger policy,June 1984,Druce T. Allen,,,Unknown,Unknown,Unknown,Unknown,,
1.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02354346,The impact of government purchases on market performance in Australia,June 1984,David K. Round,,,Male,Unknown,Unknown,Male,,
1.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02354347,Testing the interaction between concentration and barriers to entry,June 1984,Stephen Martin,,,Male,Unknown,Unknown,Male,,3
1.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02354348,Conglomerate mergers and subsequent industry effects,June 1984,Robert M. Feinberg,,,Male,Unknown,Unknown,Male,,1
1.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02354349,Crossownership and media concentration,June 1984,Allen Parkman,,,Male,Unknown,Unknown,Male,,1
1.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02354350,A note on dominant firm market share and economic performance,June 1984,Raymond L. Raab,,,Male,Unknown,Unknown,Male,,4
1.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02354351,Revised guidelines-1984,June 1984,Lucile Keyes,,,Female,Unknown,Unknown,Female,,2
1.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02457062,Price behavior in tight oligopoly,September 1984,Robert C. Dolan,,,Male,Unknown,Unknown,Male,,
1.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02457063,"Economies of scale, strategic advertising and fully credible entry deterrence",September 1984,Jeffrey Baldani,Robert T. Masson,,Male,Male,Unknown,Male,,2
1.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02457064,A flat-kinded demand function for oligopolistic sellers of homogeneous products,September 1984,David O. Whitten,,,Male,Unknown,Unknown,Male,,
1.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02457065,Impact of regulation on vertical integration in the electric industry,September 1984,John E. Filer,Robert S. Herren,Paul K. Zebe,Male,Male,Male,Male,,3
1.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02457066,Concentration and the returns to R&D,September 1984,Albert N. Link,John Lunn,,Male,Male,Unknown,Male,,6
1.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02457067,Selective cost-reducing innovation,September 1984,Sherrill Shaffer,,,,Unknown,Unknown,Mix,,
1.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02354125,To which fiddle does the reculator dance? some empirical evidence,December 1984,David L. Kaserman,L. Roy Kavanaugii,Richard C. Tepel,Male,Unknown,Male,Male,,4
1.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02354126,Some determinants of entry into the rapeutic drug markets,December 1984,Sillrley S. Yu,,,Unknown,Unknown,Unknown,Unknown,,
1.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02354127,The social loss from private monopoly and optimal antitrust enforcement,December 1984,Timothy J. Perri,,,Male,Unknown,Unknown,Male,,
1.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02354128,"Strategy, structure and performance of major U. S. Oil companles: Evidence from line of business data",December 1984,Arthur T. Andersen,Carlisle E. Moody Jr.,Jon A. Rasmussen,Male,Unknown,Male,Male,,1
1.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02354129,An intertemporal analysis of the welfare cost of monopoly power: U. S. Hanufacturing 1967–1981,December 1984,Dennis O. Olson,Donald L. Bumpass,,Male,Male,Unknown,Male,,4
1.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02354130,Competition and the performance of hospital markets,December 1984,Philip L. Hersch,,,Male,Unknown,Unknown,Male,,12
2.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02354363,Variations in antitrust enforcement activity,March 1985,Phillip A. Cartwright,David R. Kamerschen,,Male,Male,Unknown,Male,,4
2.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02354364,Learning by doing and dominant firm pricing strategy,March 1985,Ronald S. Saunders,,,Male,Unknown,Unknown,Male,,1
2.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02354365,The influence of market structure on technological performance in the food-manufacturing industries,March 1985,John D. Culbertson,Willard F. Mueller,,Male,Male,Unknown,Male,,7
2.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02354366,Regulatory inertia and risk reduction,March 1985,Sherrill Shaffer,,,,Unknown,Unknown,Mix,,
2.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02354367,II Crizontal integration of the natural gas pipeline industry: An exercise in gas pooling,March 1985,Curtis A. Cramer,,,Male,Unknown,Unknown,Male,,1
2.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02354368,A measurement of the welfare loss in the terminal equiphint makket,March 1985,Joseph P. Fuiir Jr.,,,Male,Unknown,Unknown,Male,,
2.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02354215,Potential competition and the factors influencing banking concentration,June 1985,Thomas G. Watkins,Kenneth R. Spong,Mark J. Eichholz,Male,Male,Male,Male,,
2.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02354216,Guess who came to dinner,June 1985,Joseph C. Gallo,Joseph L. Craycraft,Steven C. Bush,Male,Male,Male,Male,,16
2.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02354217,Three problems in applying contestability to regulated markets,June 1985,Ann Helwege,Ann Hendricks,,Female,Female,Unknown,Female,,
2.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02354218,On scale economies and exhaustible resource markets,June 1985,Charles F. Mason,,,Male,Unknown,Unknown,Male,,
2.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02354219,Dynamic limit pricing a refcmulation,June 1985,Kenneth L. Judd,Bruce C. Petersen,,Male,Male,Unknown,Male,,2
2.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02354220,The averch and Johnson analysis of public utility regulation twenty years later,June 1985,Roger Sherman,,,Male,Unknown,Unknown,Male,,22
2.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02354221,Industrial organization in oil markets since the embargo,June 1985,Arthur T. Andersen,,,Male,Unknown,Unknown,Male,,
2.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02464946,Contestability and creative destruction: Two approaches to monopoly,September 1985,Ann Helwege,Ann Hendricks,,Female,Female,Unknown,Female,,1
2.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02464947,The impact of international intra-firm trade on domestic concentration ratios,September 1985,Cletus C. Coughlin,Thomas G. Watkins,,Male,Male,Unknown,Male,,2
2.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02464948,On whether to prosecute suspected price-fixing conspi racies: A hypothesis-testing approach,September 1985,Ira Horowitz,,,Female,Unknown,Unknown,Female,,
2.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02464949,Earnings behavior in food and tobacco manufacturing,September 1985,Christina M. L. Kelton,,,Female,Unknown,Unknown,Female,,
2.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02464950,Measuring the interrelationships between concentration and price cost margins,September 1985,Raymond Raab,Shee Q. Wonc,,Male,Unknown,Unknown,Male,,1
2.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02464951,"Market boundaries between coal, oil, and natural gas",September 1985,Naliapu N. Reddy,,,Unknown,Unknown,Unknown,Unknown,,
2.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02418919,Industry risk and market structure,December 1985,Frances Ferguson Esposito,,,Female,Unknown,Unknown,Female,,2
2.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02418920,The celler kefauver act and the deterrent effect,December 1985,David B. Audretsch,,,Male,Unknown,Unknown,Male,,2
2.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02418921,Attorney advertising and the quality of routine legal services,December 1985,Steven R. Cox,John R. Schroeter,Scott L. Smith,Male,Male,Male,Male,,4
2.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02418922,The vertical restraints guidelines of the department of justice,December 1985,Lucile Keyes,,,Female,Unknown,Unknown,Female,,
2.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02418923,Anote on second degree price discrimination and its implications,December 1985,Allan C. Deserpa,,,Male,Unknown,Unknown,Male,,1
2.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02418924,"Trademarks, market power, and information",December 1985,Robert Feinberg,,,Male,Unknown,Unknown,Male,,
3.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02261553,Predatory intent under uncertainty,March 1986,Sanford V. Berg,Richard E. Romano,,Male,Male,Unknown,Male,,
3.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02261554,"Efficiencies, market power and horizontal merger",March 1986,V. A. Dickson,,,Unknown,Unknown,Unknown,Unknown,,
3.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02261555,On the economics of nonprofit sellers: Output policies in community hospitals,March 1986,Richard L. Ernst,Mahmood A. Zaidi,,Male,Male,Unknown,Male,,
3.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02261556,Diversification and market performance,March 1986,Donald L. Alexander,,,Male,Unknown,Unknown,Male,,
3.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02261557,The 1984 justice department guidelines toward horizontal mergers,March 1986,Donald L. Bumpass,Patricia J. Nichol,,Male,Female,Unknown,Mix,,
3.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02261558,Predation by noisy advertising,March 1986,Charles F. Mason,,,Male,Unknown,Unknown,Male,,1
3.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02230834,Stanley E. Boyle in memoriam,June 1986,Willard Fritz Mueller,,,Male,Unknown,Unknown,Male,,
3.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02230835,Management motives for takeovers in the petroleum industry,June 1986,Arthur T. Andersen,T. Crawford Honeycutt,,Male,Unknown,Unknown,Male,,1
3.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02230836,Concentration and non-price competition in the recording industry,June 1986,Michael Black,Douglas Greer,,Male,Male,Unknown,Male,,14
3.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02230837,Incarceration and fines: An empirical study of antitrust sanctions,June 1986,Joseph C. Gallo,Jos L. Craycraft,Shantanu Dutta,Male,Male,Unknown,Male,,4
3.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02230838,Civil antitrust sanctions and cartel stability,June 1986,Philip L. Hersch,Jeffry M. Netter,,Male,Male,Unknown,Male,,
3.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02230839,"Profits and ""contestability"" in highly concentrated banking markets",June 1986,Jim Burke,Stephen A. Rhoades,,Male,Male,Unknown,Male,,5
3.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02230840,An interindustry analysis of merger activity 1960 – 1983,June 1986,Stanley E. Boyle,Michael J. Piette,,Male,Male,Unknown,Male,,
3.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02229563,M-form organization and firm profitability,March 1988,Edgar Norton,Russell Pittman,,Male,Male,Unknown,Male,,2
3.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02229564,Rule of reason versus mechanical tests in the adjudication of price predation,March 1988,Charles W. McCall,,,Male,Unknown,Unknown,Male,,
3.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02229565,A note on causality and the structure-performance controversy,March 1988,Raymond L. Raab,Shee Q. Wong,,Male,Unknown,Unknown,Male,,
3.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02229566,Pricing of related products by a multiproduct monopolist,March 1988,Kevin F. Forbes,,,Male,Unknown,Unknown,Male,,3
3.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02229567,"Regulatory risk, investment, and welfare",March 1988,Glenn A. Woroch,,,Male,Unknown,Unknown,Male,,5
3.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02229568,Antitrust and regulation: Forestalling competition in the telecommunications terminal equipment market,March 1988,Joseph P. Fuhr Jr.,,,Male,Unknown,Unknown,Male,,
3.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02229569,Book reviews,March 1988,Stephen A. Rhoades,William G. Shepherd,R. W. Kling,Male,Male,Unknown,Male,,
3.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02229570,Errata Sheet,March 1988,,,,Unknown,Unknown,Unknown,Unknown,,
3.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02284682,"Excess market value, market power, and inside ownership structure",September 1988,Wi-Saeng Kim,Esmeralda O. Lyn,,Unknown,Female,Unknown,Female,,3
3.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02284683,Rent seeking and the allowed rate of return: A recursive model,September 1988,Bae-Geun Im,David L. Kaserman,Francois Melese,Unknown,Male,Unknown,Male,,3
3.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02284684,Price and margin rigidity in deflation: The great depression,September 1988,Howard N. Ross,,,Male,Unknown,Unknown,Male,,1
3.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02284685,An examination of the economic efficiency of class I railroads: A profit function analysis,September 1988,Stanley R. Stansell,Daniel R. Hollas,,Male,Male,Unknown,Male,,7
3.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02284686,Industrial concentration and fringe benefits,September 1988,John S. Heywood,,,Male,Unknown,Unknown,Male,,6
3.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02284687,Could a score of industrial organization economists agree on competition?,September 1988,John J. Siegfried,,,Male,Unknown,Unknown,Male,,5
3.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02284688,Book reviews,September 1988,Kenneth D. Boyer,Victor J. Tremblay,Gena F. Hampton,Male,Male,Female,Mix,,
4.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02284659,On the sources of scope economies in U.S. manufacturing firms,March 1989,Len M. Nichols,,,Male,Unknown,Unknown,Male,,1
4.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02284660,The extent of single firm dominance in U.S. manufacturing industries,March 1989,E. Woodrow Eckard Jr.,,,Unknown,Unknown,Unknown,Unknown,,
4.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02284661,The measurement of conjectural variations in an oligopoly industry,March 1989,Robert P. Rogers,,,Male,Unknown,Unknown,Male,,5
4.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02284662,The publishing performance of U.S. economics departments in industrial economics,March 1989,Victor J. Tremblay,Carol Horton Tremblay,Byunglak Lee,Male,,Unknown,Mix,,
4.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02284663,Proof of nonparticipation in a price fixing conspiracy,March 1989,Roger D. Blair,Richard E. Romano,,Male,Male,Unknown,Male,,2
4.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02284664,On the comparative statics of the dominant-firm model,March 1989,John Hoftyzer,Edward L. Millner,J. Wilson Mixon Jr.,Male,Male,Unknown,Male,,1
4.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02284665,An empirical note from case documents on the economies of network television advertising,March 1989,John C. Hilke,Philip B. Nelson,,Male,Male,Unknown,Male,,2
4.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02284666,Book reviews,March 1989,Mark B. Schupack,Don E. Waldman,James W. Brock,Male,Male,Male,Male,,
4.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02284667,"Returns to R&D, and regulation of the U.S. pharmaceutical industry",September 1989,Douglas D. Evanoff,,,Male,Unknown,Unknown,Male,,
4.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02284668,Price reaction functions and conjectural variations,September 1989,J. Nellie Liang,,,Unknown,Unknown,Unknown,Unknown,,
4.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02284669,"Profits and ""contestability"": state-by-state evidence from banking markets",September 1989,Jim Burke,Stephen A. Rhoades,,Male,Male,Unknown,Male,,
4.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02284670,Price correlation and granger causality tests for market definition,September 1989,Phillip A. Cartwright,David R. Kamerschen,Mei-Ying Huang,Male,Male,,Mix,,
4.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02284671,Input market definition under department of Justice Merger Guidelines,September 1989,Richard S. Higgins,William F. Shughart II,,Male,Male,Unknown,Male,,2
4.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02284672,Dissecting divestiture: A telecommunications book review article,September 1989,Christopher C. Klein,,,Male,Unknown,Unknown,Male,,1
4.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02284673,Book reviews,September 1989,James W. Brock,Frances F. Esposito,Raymond L. Raab,Male,Female,Male,Mix,,
5.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02284674,"Market structure, opportunity costs, and tax avoidance",March 1990,Jeffrey P. Baldani,Don E. Waldman,,Male,Male,Unknown,Male,,
5.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02284675,Increasing product variety and rising prices,March 1990,Bruce L. Benson,,,Male,Unknown,Unknown,Male,,9
5.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02284676,Interindustry differences in advertising in U.S. manufacturing: 1963–1977,March 1990,Frances F. Esposito,Louis Esposito,William V. Hogan,Female,Male,Male,Mix,,
5.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02284677,Insights into the contestability and sustainability of the U.S. petroleum refining industry,March 1990,Gary L. Shoesmith,,,Male,Unknown,Unknown,Male,,2
5.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02284678,Entry deterrence: The case of a buyer with market power,March 1990,Ram Mudambi,,,Male,Unknown,Unknown,Male,,3
5.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02284679,Publishing performance in industrial organization: A comment,March 1990,William G. Shepherd,,,Male,Unknown,Unknown,Male,,1
5.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02284680,Publishing performance in industrial organization: A reply,March 1990,Victor J. Tremblay,Carol Horton Tremblay,Byunglak Lee,Male,,Unknown,Mix,,
5.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02284681,Book reviews,March 1990,David K. Round,J. Douglass Klein,Arthur S. Leahy,Male,Unknown,Male,Male,,
5.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02229744,Editor's introduction,June 1990,,,,Unknown,Unknown,Unknown,Unknown,,
5.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02229745,Measuring market shares for the analysis of a consummated merger,June 1990,John J. Siegfried,Emmett H. Miller III,,Male,Male,Unknown,Male,,
5.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02229746,Efficiency in nuclear power pricing,June 1990,Herbert G. Thompson Jr.,David R. Kamerschen,Albert L. Danielsen,Male,Male,Male,Male,,3
5.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02229747,Discussion of efficiency in nuclear power pricing,June 1990,Arnold A. Heggestad,,,Male,Unknown,Unknown,Male,,
5.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02229748,A note on vertical market foreclosure,June 1990,Roger D. Blair,James M. Fesmire,Richard E. Romano,Male,Male,Male,Male,,1
5.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02229749,Exports and antitrust: Complements or substitutes?,June 1990,Don P. Clark,Jay Creswell,David L. Kaserman,Male,Male,Male,Male,,2
5.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02229750,Discussion of exports and antitrust: Complements or substitutes?,June 1990,John M. Connor,,,Male,Unknown,Unknown,Male,,
5.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02229751,"Economic efficiency, antitrust and rate-of-return",June 1990,John P. Formby,W. James Smith,Paul D. Thistle,Male,Unknown,Male,Male,,1
5.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02229752,"Discussion of economic efficiency, antitrust and rate-of-return",June 1990,David C. Rose,,,Male,Unknown,Unknown,Male,,1
5.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02229753,The FTC in the 1980s,June 1990,James Langenfeld,David T. Scheffman,,Male,Male,Unknown,Male,,4
5.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02229754,The two economics of vertical restraints,June 1990,William S. Comanor,,,Male,Unknown,Unknown,Male,,3
5.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02229755,The treatment of market dominance,June 1990,William G. Shepherd,,,Male,Unknown,Unknown,Male,,3
5.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02229756,Antitrust policy in the 1980s and beyond session comment,June 1990,David B. Audretsch,,,Male,Unknown,Unknown,Male,,1
5.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02229757,Efficiency and competition: The reagan administration's legacy in merger policy,June 1990,William L. Baldwin,,,Male,Unknown,Unknown,Male,,3
5.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02229758,Mergers and economic performance: The experience abroad,June 1990,Walter Adams,James W. Brock,,Male,Male,Unknown,Male,,2
5.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02229759,Food mergers: Implications for performance and policy,June 1990,Ronald W. Cotterill,,,Male,Unknown,Unknown,Male,,4
5.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02229760,"Mergers: Significance for structure, performance and public policy session comment",June 1990,Robert H. McGuckin,,,Male,Unknown,Unknown,Male,,
5.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02229761,"Mergers: Significance for structure, performance and public policy session comment",June 1990,Charles E. Helppie,,,Male,Unknown,Unknown,Male,,1
5.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02229762,The determinants of entry and exit rates into U.S. manufacturing industries,June 1990,John S. Austin,David I. Rosenbaum,,Male,Male,Unknown,Male,,35
5.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02229584,Imports and domestic entry: an empirical study,September 1990,Joseph Shaanan,,,Male,Unknown,Unknown,Male,,1
5.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02229585,"Economies of scale in petroleum refining, 1947–1984: A survivor principle - time series analysis",September 1990,James E. Hibdon,Michael J. Mueller,,Male,Male,Unknown,Male,,5
5.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02229586,Does purely predatory advertising exist?,September 1990,Barry J. Seldon,Khosrow Doroodian,,Male,Male,Unknown,Male,,5
5.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02229587,Modeling oligopolistic interaction,September 1990,Stephen Martin,,,Male,Unknown,Unknown,Male,,
5.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02229588,The extent of single firm dominance in U.S. manufacturing industries: Comment,September 1990,Alan J. Daskin,,,Male,Unknown,Unknown,Male,,1
5.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02229589,The extent of single firm dominance in U.S. manufacturing industries: Reply,September 1990,E. Woodrow Eckard Jr.,,,Unknown,Unknown,Unknown,Unknown,,
5.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF02229590,Book reviews,September 1990,Ira Horowitz,Richard A. Miller,Arthur S. Leahy,Female,Male,Male,Mix,,
6.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00427995,Editorial statement,January 1991,,,,Unknown,Unknown,Unknown,Unknown,,
6.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00427996,Special editorial note,January 1991,,,,Unknown,Unknown,Unknown,Unknown,,
6.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00427997,The takeover market in Europe: Control structures and the performance of large companies compared,January 1991,Henry W. De Jong,,,Male,Unknown,Unknown,Male,,13
6.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00427998,How did the wealthiest Britons get so rich?,January 1991,John J. Siegfried,Alison Roberts,,Male,Female,Unknown,Mix,,
6.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00427999,Residual demand estimation for market delineation: Complications and limitations,January 1991,Luke M. Froeb,Gregory J. Werden,,Male,Male,Unknown,Male,,19
6.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00428000,"Asset diversification, firm risk, and risk-based capital requirements in banking",January 1991,J. Nellie Liang,Stephen A. Rhoades,,Unknown,Male,Unknown,Male,,22
6.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00428001,The determinants of aggregate-merger activity—Before and after Celler-Kefauver,January 1991,Cynthia Benzing,,,Female,Unknown,Unknown,Female,,18
6.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00428002,"Depreciation, investor compensation, and welfare under rate-of-return regulation",January 1991,Timothy J. Brennan,,,Male,Unknown,Unknown,Male,,4
6.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00428003,Rural telephony since divestiture,January 1991,Joseph P. Fuhr Jr.,,,Male,Unknown,Unknown,Male,,1
6.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00428004,Book reviews,January 1991,Lydia D. Ortega,Sanford V. Berg,William G. Shepherd,Female,Male,Male,Mix,,
6.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00364534,Introduction,January 1991,,,,Unknown,Unknown,Unknown,Unknown,,
6.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00364535,Remarks,January 1991,Walter Adams,,,Male,Unknown,Unknown,Male,,
6.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00364536,Walter Adams and Chicago,January 1991,Kenneth G. Elzinga,,,Male,Unknown,Unknown,Male,,
6.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00364537,Discussion,January 1991,F. M. Scherer,,,Unknown,Unknown,Unknown,Unknown,,
6.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00364538,Thinking about predation — A personal diary,January 1991,Alfred E. Kahn,,,Male,Unknown,Unknown,Male,,
6.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00364539,The new EEC Merger Control System,January 1991,Ingo L. O. Schmidt,,,Male,Unknown,Unknown,Male,,
6.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00364540,Market dominance under U.S. antitrust,January 1991,William G. Shepherd,,,Male,Unknown,Unknown,Male,,
6.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00364541,Discussion,January 1991,Almarin Phillips,,,Male,Unknown,Unknown,Male,,
6.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00364542,"Freedom, power and Adams: An ode to the professor",January 1991,Eleanor M. Fox,,,Female,Unknown,Unknown,Female,,
6.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00364543,Walter Adams and the Sherman Act,January 1991,John Dibiaggio,,,Male,Unknown,Unknown,Male,,
6.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00378120,Publisher's notice,January 1991,,,,Unknown,Unknown,Unknown,Unknown,,
6.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00378121,Competition and structural change in Eastern Europe,January 1991,Martin C. Spechler,,,Male,Unknown,Unknown,Male,,
6.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00378122,An investment model of durable good diffusion,January 1991,Jerry R. Jackson,David L. Kaserman,,Male,Male,Unknown,Male,,2
6.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00378123,"Profitability, concentration and trade flows: Issues of non-linearity and exogeneity",January 1991,George Zaralis,,,Male,Unknown,Unknown,Male,,4
6.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00378124,Patent protection through discriminatory exclusion of imports,January 1991,Marius Schwartz,,,Male,Unknown,Unknown,Male,,7
6.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00378125,Intellectual property rights: An international economics perspective,January 1991,Martin Richardson,,,Male,Unknown,Unknown,Male,,2
6.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00378126,The efficiencies defense and commercial bank merger regulation,January 1991,Robert E. DeYoung,,,Male,Unknown,Unknown,Male,,2
6.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00378127,The diffusion of television advertising,January 1991,Michael R. Butler,,,Male,Unknown,Unknown,Male,,55
6.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00378128,How did the wealthiest Britons get so rich?: Comment,January 1991,Don E. Waldman,,,Male,Unknown,Unknown,Male,,5
6.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00378129,Efficiency in nuclear power pricing: A comment,January 1991,Joseph Kile,,,Male,Unknown,Unknown,Male,,
6.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00378130,Efficiency in nuclear power pricing: A reply,January 1991,Albert L. Danielsen,David R. Kamerschen,Herbert G. Thompson Jr,Male,Male,Male,Male,,1
6.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00378131,Handbook of industrial organization: A review,January 1991,T. Y. Shen,,,Unknown,Unknown,Unknown,Unknown,,
6.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00378132,Innovation and small firms: A review,January 1991,William L. Baldwin,,,Male,Unknown,Unknown,Male,,
6.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00378133,Games and information: A review,January 1991,Charles F. Mason,,,Male,Unknown,Unknown,Male,,
7.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00354842,The use of stock market returns in antitrust analysis of mergers,March 1992,Robert H. McGuckin,Fredrick R. Warren-Boulton,Peter Waldstein,Male,Male,Male,Male,,22
7.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00354843,Falling margins and rising costs,March 1992,Eban Goodstein,,,Unknown,Unknown,Unknown,Unknown,,
7.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00354844,Input substitutability and vertical integration,March 1992,James L. Hamilton,,,Male,Unknown,Unknown,Male,,
7.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00354845,A note on the market share-profitability relationship,March 1992,Robert D. Kurtz,Stephen A. Rhoades,,Male,Male,Unknown,Male,,16
7.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00354846,Financial aspects of motor carrier safety inspection performance,March 1992,T. Randolph Beard,,,Unknown,Unknown,Unknown,Unknown,,
7.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00354847,"Bankruptcy risk, firm-specific managerial human capital, and diversification",March 1992,David C. Rose,,,Male,Unknown,Unknown,Male,,9
7.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00354848,The bakers of Washington cartel: Twenty-five years later,March 1992,Willard F. Mueller,Russell C. Parker,,Male,Male,Unknown,Male,,8
7.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00354849,Industry performance indices and the economics of information: New perspectives and caveats,March 1992,Michael R. Baye,Dennis W. Jansen,,Male,Male,Unknown,Male,,
7.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00354850,Book review,March 1992,Russell Pittman,,,Male,Unknown,Unknown,Male,,
7.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00354851,Book review,March 1992,Robert M. Feinberg,,,Male,Unknown,Unknown,Male,,
7.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00158134,Editor's introduction,June 1992,,,,Unknown,Unknown,Unknown,Unknown,,
7.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00158135,To Carl Kaysen — in appreciation,June 1992,Franklin M. Fisher,,,Male,Unknown,Unknown,Male,,
7.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00158136,Market power or efficiency: A review of antitrust standards,June 1992,William S. Comanor,Lawrence J. White,,Male,Male,Unknown,Male,,5
7.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00158137,Due diligence and the demand for electricity: A cautionary tale,June 1992,Franklin M. Fisher,Peter S. Fox-Penner,Almarin Phillips,Male,Male,Male,Male,,12
7.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00158138,An analysis of the profitability of businesses of diversified companies,June 1992,Thomas A. Wilson,,,Male,Unknown,Unknown,Male,,2
7.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00158139,Discussion,June 1992,Merton J. Peck,,,Male,Unknown,Unknown,Male,,
7.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00158140,Mergers that harm competitors,June 1992,Kenneth D. Boyer,,,Male,Unknown,Unknown,Male,,5
7.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00158141,An analysis of production cost inefficiency,June 1992,Janet M. Thomas,Scott J. Callan,,Female,Male,Unknown,Mix,,
7.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00158142,Exclusive dealing and the pullman sleeping car corporation,June 1992,Gregg P. Frasco,,,Male,Unknown,Unknown,Male,,2
7.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00158143,The reverse Cellophane fallacy in market delineation,June 1992,Luke M. Froeb,Gregory J. Werden,,Male,Male,Unknown,Male,,18
7.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00158144,Book reviews,June 1992,David McQueen,Manley R. Irwin,Irene Powell,Male,Unknown,Female,Mix,,
7.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00353395,Publisher's notice,September 1992,,,,Unknown,Unknown,Unknown,Unknown,,
7.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00353396,Introduction,September 1992,Clement G. Krouse,,,Male,Unknown,Unknown,Male,,
7.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00353397,Manufacturing and firm performance in technology-intensive industries: U.S. and Japanese DRAM experience,September 1992,M. Therese Flaherty,,,Unknown,Unknown,Unknown,Unknown,,
7.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00353398,Strategic arguments for semiconductor trade policy,September 1992,Kenneth Flamm,,,Male,Unknown,Unknown,Male,,
7.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00353399,The economics of flexible integrated circuit manufacturing technology,September 1992,W. Edward Steinmueller,,,Unknown,Unknown,Unknown,Unknown,,
7.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00353400,Comment on semiconductor session papers,September 1992,F. M. Scherer,,,Unknown,Unknown,Unknown,Unknown,,
7.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00353401,Comment on semiconductor session papers,September 1992,Philip Webre,,,Male,Unknown,Unknown,Male,,
7.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00353402,Industrial structures components of finance theory's CAPM,September 1992,John G. Greenhut,Melvin L. Greenhut,,Male,Male,Unknown,Male,,1
7.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00353403,On the vertical integration of successive monopolies,September 1992,Thomas W. Ross,,,Male,Unknown,Unknown,Male,,
7.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00353404,Book review,September 1992,Alfred E. Kahn,Thomas A. Boylan,John J. Siegfried,Male,Male,Male,Male,,
7.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00353405,List of referees during 1990–1992,September 1992,,,,Unknown,Unknown,Unknown,Unknown,,
7.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00353406,"Sessions organized by the Industrial Organization Society at the ASSA Meetings, New Orleans, January 5–7, 1993",September 1992,,,,Unknown,Unknown,Unknown,Unknown,,
8.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01029762,Pricing of telecommunications services,January 1993,David Gabel,Mark D. Kennet,,Male,Male,Unknown,Male,,10
8.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01029763,Pricing of telecommunications services: Comment on Gabel and Kennet,January 1993,Lester D. Taylor,,,Male,Unknown,Unknown,Male,,1
8.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01029764,Efficient pricing of telecommunications services: The state of the debate,January 1993,William E. Taylor,,,Male,Unknown,Unknown,Male,,4
8.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01029765,Pricing of telecommunication services: A comment,January 1993,Alfred E. Kahn,,,Male,Unknown,Unknown,Male,,1
8.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01029766,Pricing of telecommunications services: a reply to comments,January 1993,David J. Gabel,Mark D. Kennet,,Male,Male,Unknown,Male,,1
8.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01029767,"The effects of divestiture, privatization, and competition on productivity in U.S. and U.K. telecommunications",January 1993,John E. Kwoka Jr.,,,Male,Unknown,Unknown,Male,,26
8.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01029768,"The effects of divestiture, privatization, and competition on productivity in U.S. and U.K. telecommunications: a brief note",January 1993,David Gabel,,,Male,Unknown,Unknown,Male,,
8.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01029769,"The effects of divestiture, privatization, and competition on productivity in U.S. and U.K. telecommunications: a briefer reply",January 1993,John E. Kwoka Jr.,,,Male,Unknown,Unknown,Male,,
8.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01029770,The effects of mergers in markets for differentiated products,January 1993,F. W. Mcelroy,,,Unknown,Unknown,Unknown,Unknown,,
8.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01029771,Multimarket competition and business strategy,January 1993,Arjen van Witteloostuijn,,,Male,Unknown,Unknown,Male,,14
8.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01029772,The benefits of being small: Duopolistic competition with market segmentation,January 1993,Chaim Fershtman,Eitan Muller,,Male,Male,Unknown,Male,,14
8.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01029773,A risk-adjusted approach for assessing factors that determine utilities' allowed returns on equity,January 1993,S. Keith Berry,Timothy Mason,,Unknown,Male,Unknown,Male,,1
8.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01029774,Book reviews,January 1993,Albert N. Link,,,Male,Unknown,Unknown,Male,,
8.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01029775,Book reviews,January 1993,Howard P. Marvel,Erwin A. Blackstone,,Male,Male,Unknown,Male,,
8.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01034172,Editor's introduction,March 1993,William G. Shepherd,,,Male,Unknown,Unknown,Male,,1
8.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01034173,Economics and the 1992 Merger Guidelines: A brief survey,March 1993,Janusz A. Ordover,Robert D. Willig,,Male,Male,Unknown,Male,,11
8.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01034174,U.S. merger policy and the 1992 Merger Guidelines,March 1993,Dennis C. Mueller,,,Male,Unknown,Unknown,Male,,8
8.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01034175,The 1992 Horizontal Merger Guidelines: A brief critique,March 1993,Willard F. Mueller,Kevin J. O'Connor,,Male,Male,Unknown,Male,,3
8.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01034176,"Ten years of Merger Guidelines: A retrospective, critique, and prediction",March 1993,David T. Scheffman,,,Male,Unknown,Unknown,Male,,8
8.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01034177,"Merger law, policy, and enforcement guidelines in Canada",March 1993,Christopher Green,,,Male,Unknown,Unknown,Male,,7
8.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01034178,Reliable guidelines? A European comment,March 1993,H. W. de Jong,,,Unknown,Unknown,Unknown,Unknown,,
8.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01034179,The Australian merger guidelines: A comparison with the U.S. merger guidelines,March 1993,David K. Round,Richard A. Miller,,Male,Male,Unknown,Male,,3
8.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01034180,Department of justice and federal trade commission: Horizontal Merger Guidelines,March 1993,,,,Unknown,Unknown,Unknown,Unknown,,
8.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024234,Monopoly regulation: From legal unrealism to unreal legalism and beyond,June 1993,Roger Sherman,,,Male,Unknown,Unknown,Male,,
8.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024235,Cyclical variation in the profit-concentration relationship,June 1993,Willard F. Mueller,Maqbool H. Sial,,Male,Unknown,Unknown,Male,,3
8.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024236,Technological capabilities and international competitiveness in the engineering industries,June 1993,Bo Carlsson,Erol Taymaz,,Male,Male,Unknown,Male,,7
8.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024237,"Market share, advertising, R&D, and profitability: An empirical analysis of leading industrial firms in Japan",June 1993,Takeo Nakao,,,Male,Unknown,Unknown,Male,,13
8.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024238,"Correlation, causality, and all that jazz: The inherent shortcomings of price tests for antitrust market delineation",June 1993,Gregory J. Werden,Luke M. Froeb,,Male,Male,Unknown,Male,,45
8.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024239,"Comments on Werden and Froeb — Correlation, causality, and all that jazz",June 1993,Robert A. Sherwin,,,Male,Unknown,Unknown,Male,,3
8.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024240,Book review,June 1993,James W. Brock,,,Male,Unknown,Unknown,Male,,
8.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024241,Book review,June 1993,Henry B. McFarland,,,Male,Unknown,Unknown,Male,,
8.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024242,Book review,June 1993,Kenneth G. Elzinga,John Adams,,Male,Male,Unknown,Male,,
8.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024276,Editor's introduction,August 1993,,,,Unknown,Unknown,Unknown,Unknown,,
8.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024277,The competitive consequences of hub dominance: A case study,August 1993,Alfred E. Kahn,,,Male,Unknown,Unknown,Male,,14
8.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024278,Airline hubs in the Single European Market: A benchmark analysis,August 1993,John H. Huston,Richard V. Butler,,Male,Male,Unknown,Male,,1
8.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024279,Market share and price determination in the contemporary airline industry,August 1993,Amy D. Abramowitz,Stephen M. Brown,,Female,Male,Unknown,Mix,,
8.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024280,Airline fleet composition and deregulation,August 1993,John Howard Brown,,,Male,Unknown,Unknown,Male,,3
8.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024281,Price dispersion in a market with advance-purchases,August 1993,Ian Gale,,,Male,Unknown,Unknown,Male,,24
8.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024282,Telephone company ownership of rural cable television companies,August 1993,Stanford L. Levin,John B. Meisel,,Male,Male,Unknown,Male,,3
8.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024283,An antitrust analysis of non-profit hospital mergers,August 1993,Erwin A. Blackstone,Joseph P. Fuhr Jr.,,Male,Male,Unknown,Male,,8
8.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024284,On the persistence of business alliances: the case of Major League Baseball trading patterns,August 1993,Ira Horowitz,,,Female,Unknown,Unknown,Female,,2
8.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024285,Indifference to profit-sharing is consistent,August 1993,Sherrill Shaffer,,,,Unknown,Unknown,Mix,,
8.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024286,Book review,August 1993,Gregory J. Werden,,,Male,Unknown,Unknown,Male,,
8.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024287,Book review,August 1993,Douglas F. Greer,,,Male,Unknown,Unknown,Male,,
8.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024288,Book review,August 1993,Gerald W. Brock,,,Male,Unknown,Unknown,Male,,
8.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024289,Book review,August 1993,Bruce W. Marion,,,Male,Unknown,Unknown,Male,,
8.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024243,The demand for first-class mail: An econometric analysis,October 1993,Lester D. Taylor,,,Male,Unknown,Unknown,Male,,
8.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024244,Micro-dispersion of performance across industry lines,October 1993,Frank Schohl,,,Male,Unknown,Unknown,Male,,
8.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024245,Contestability and two-part pricing,October 1993,John S. Heywood,Debashis Pal,,Male,Male,Unknown,Male,,3
8.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024246,Firm entry and firm growth,October 1993,José Mata,,,Male,Unknown,Unknown,Male,,4
8.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024247,Rethinking shipments asymmetries,October 1993,Steven E. Crane,Patrick J. Welch,,Male,Male,Unknown,Male,,
8.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024248,"The extent of the market in the liquor industry: An empirical test of localized brand rivalry, 1970–1988",October 1993,Mark Paul Gius,,,Male,Unknown,Unknown,Male,,2
8.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024249,R&D and product obsolescence,October 1993,Gregory E. Goering,John R. Boyce,James M. Collins,Male,Male,Male,Male,,6
8.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024250,For-profit and non-profit firms: Limits of the simple theory of attenuated property rights,October 1993,Lon L. Peters,,,,Unknown,Unknown,Mix,,
8.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024251,Book review,October 1993,Gerald B. Wetlaufer,E. Scott Maynes,,Male,Unknown,Unknown,Male,,
8.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024252,Book reviews,October 1993,John C. Hilke,,,Male,Unknown,Unknown,Male,,
8.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024253,"Sessions organized by the Industrial Organization Society at the ASSA meetings, New Orleans, January 3–5, 1994",October 1993,,,,Unknown,Unknown,Unknown,Unknown,,
8.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024254,"Sessions organized by the Southern Economic Association Meetings, November 21–23, 1993",October 1993,,,,Unknown,Unknown,Unknown,Unknown,,
8.0,6.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024290,Testing theories of regulatory behavior,December 1993,Clifford Nowell,John Tschirhart,,Male,Male,Unknown,Male,,10
8.0,6.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024291,The medical community's opposition to organ markets: Ethics or economics?,December 1993,A. H. Barnett,T. Randolph Beard,David L. Kaserman,Unknown,Unknown,Male,Male,,27
8.0,6.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024292,Patterns of abnormal returns and the competitive effects of horizontal mergers,December 1993,Laurence Schumann,,,Female,Unknown,Unknown,Female,,21
8.0,6.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024293,"Foreign owners and American cement: Old cartel hands, or new kids on the block?",December 1993,Bruce T. Allen,,,Male,Unknown,Unknown,Male,,1
8.0,6.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024294,The inverse association between the margins of manufacturers and retailers,December 1993,Robert L. Steiner,,,Male,Unknown,Unknown,Male,,53
8.0,6.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024295,Biases in optimal pricing with network externalities,December 1993,Michael A. Einhorn,,,Male,Unknown,Unknown,Male,,4
8.0,6.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024296,Mergers — What the “Grimm” data tell us,December 1993,Cynthia Benzing,,,Female,Unknown,Unknown,Female,,7
8.0,6.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024297,The choice between resale price maintenance and exclusive territories: Evidence from litigation,December 1993,David W. Boyd,,,Male,Unknown,Unknown,Male,,8
8.0,6.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024298,Book review,December 1993,Peter Alexander,Gerard Rosegger,,Male,Male,Unknown,Male,,1
9.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024216,First-mover advantages from pioneering new markets: A survey of empirical evidence,February 1994,William T. Robinson,Gurumurthy Kalyanaram,Glen L. Urban,Male,Unknown,Male,Male,,80
9.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024217,"Joint oligopsony-oligopoly in the U.S. leaf tobacco market, 1924–39",February 1994,James L. Hamilton,,,Male,Unknown,Unknown,Male,,2
9.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024218,The rate of hazard confronting new firms and plants in U.S. manufacturing,February 1994,David B. Audretsch,Talat Mahmood,,Male,Male,Unknown,Male,,104
9.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024219,Matsushita v. Zenith: An economic analysis,February 1994,David Schwartzman,,,Male,Unknown,Unknown,Male,,1
9.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024220,Sample-selection procedures for estimating the relationship between concentration and profitability from cross-industry data,February 1994,Harry Bloch,,,Male,Unknown,Unknown,Male,,7
9.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024221,"Entry barriers, release behavior, and multi-product firms in the music recording industry",February 1994,Peter J. Alexander,,,Male,Unknown,Unknown,Male,,33
9.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024222,Asymmetry of information and contestability theory,February 1994,Robert D. Cairns,,,Male,Unknown,Unknown,Male,,1
9.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024223,Book review,February 1994,F. W. McElroy,,,Unknown,Unknown,Unknown,Unknown,,
9.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024224,Book review,February 1994,Janet M. Thomas,,,Female,Unknown,Unknown,Female,,1
9.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01035654,Empirical studies of entry and exit: A survey of the evidence,April 1994,John J. Siegfried,Laurie Beth Evans,,Male,Female,Unknown,Mix,,
9.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01035655,Private and social incentives to form R & D joint ventures,April 1994,Stephen Martin,,,Male,Unknown,Unknown,Male,,18
9.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01035656,First-mover advantages from pioneering new markets: Comment,April 1994,F. M. Scherer,,,Unknown,Unknown,Unknown,Unknown,,
9.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01035657,First-mover advantages from pioneering new markets: Comment,April 1994,David F. Lean,,,Male,Unknown,Unknown,Male,,1
9.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01035658,A cointegration rank test of market linkages with an application to the U.S. natural gas industry,April 1994,W. David Walls,,,Unknown,Unknown,Unknown,Unknown,,
9.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01035659,The intertemporal stability of the concentration-margins relationship in Dutch and U.S. manufacturing,April 1994,Yvonne Prince,Roy Thurik,,Female,Male,Unknown,Mix,,
9.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01035660,The relative price discipline of domestic versus foreign entry,April 1994,Robert M. Feinberg,Joseph Shaanan,,Male,Male,Unknown,Male,,8
9.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01035661,The social costs of monopoly?,April 1994,Donald C. Wellington,Joseph C. Gallo,,Male,Male,Unknown,Male,,1
9.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01035662,Getting straight on monopoly and rent: A dissent from Wellington and Gallo,April 1994,Donald Dewey,,,Male,Unknown,Unknown,Male,,
9.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01035663,The social costs of monopoly? Reply,April 1994,Donald C. Wellington,Joseph C. Gallo,,Male,Male,Unknown,Male,,
9.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01035664,Book review,April 1994,Ralph Bradburd,,,Male,Unknown,Unknown,Male,,
9.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01035665,Book review,April 1994,David I. Rosenbaum,,,Male,Unknown,Unknown,Male,,
9.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01025724,Designing incentive regulation,June 1994,David E. M. Sappington,,,Male,Unknown,Unknown,Male,,22
9.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01025725,Local competition for telephone services,June 1994,Curtis A. Cramer,,,Male,Unknown,Unknown,Male,,3
9.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01025726,An analysis of intrabrand competition in the franchise industry,June 1994,Torsten Schmidt,,,Male,Unknown,Unknown,Male,,14
9.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01025727,Vertical integration versus vertical separation: An equilibrium model,June 1994,Philippe Cyrenne,,,Male,Unknown,Unknown,Male,,9
9.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01025728,A note on incentive incompatibility under franchising,June 1994,Roger D. Blair,David L. Kaserman,,Male,Male,Unknown,Male,,25
9.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01025729,Life expectancy of international cartels: An empirical analysis,June 1994,Jaime Marquez,,,Male,Unknown,Unknown,Male,,26
9.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01025730,An oligopoly model of ocean liner shipping,June 1994,Nancy Ruth Fox,,,Female,Unknown,Unknown,Female,,13
9.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01025731,Book review,June 1994,John E. Kwoka Jr.,,,Male,Unknown,Unknown,Male,,
9.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01025732,Book review,June 1994,Larry L. Duetsch,,,Male,Unknown,Unknown,Male,,
9.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01029511,Symbiotic production: The case of telecommunication pricing,August 1994,Michael Carter,Julian Wright,,Male,Male,Unknown,Male,,21
9.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01029512,Efficiencyv. collusion: Evidence cast in cement,August 1994,David I. Rosenbaum,,,Male,Unknown,Unknown,Male,,13
9.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01029513,Mergers of not-for-profit hospitals in the 1980s: Who were the most likely targets?,August 1994,Avi Dor,Bernard Friedman,,Male,Male,Unknown,Male,,3
9.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01029514,Asset specificity and vertical integration in franchising,August 1994,Alanson P. Minkler,Timothy A. Park,,Unknown,Male,Unknown,Male,,67
9.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01029515,On monopoly power in a differentiated product industry,August 1994,Chao-Shun Hung,,,Unknown,Unknown,Unknown,Unknown,,
9.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01029516,"Structure, conduct, performance, and welfare",August 1994,Sherrill Shaffer,,,,Unknown,Unknown,Mix,,
9.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01029517,Book review,August 1994,John S. Heywood,,,Male,Unknown,Unknown,Male,,
9.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01029518,Book review,August 1994,Gregory E. Goering,,,Male,Unknown,Unknown,Male,,
9.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01029973,"Twenty years of modern antitrust in Australia: She'll be right, mate",October 1994,David K. Round,,,Male,Unknown,Unknown,Male,,
9.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01029974,A minister's perspective on twenty years of the Trade Practices Act,October 1994,George Gear,,,Male,Unknown,Unknown,Male,,
9.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01029975,The Australian antitrust law after 20 years — a stocktake,October 1994,Maureen Brunt,,,Female,Unknown,Unknown,Female,,6
9.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01029976,Progress under pressure: The evolution of antitrust policy in Australia,October 1994,Neville R. Norman,,,Male,Unknown,Unknown,Male,,5
9.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01029977,Judicial approaches to economic analysis in Australia,October 1994,Justice R. S. French,,,,Unknown,Unknown,Mix,,
9.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01029978,Horizontal price agreements in Australian antitrust: Combatting anti-competitive corporate conspiracies of complicity and connivance,October 1994,David K. Round,John J. Siegfried,,Male,Male,Unknown,Male,,3
9.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01029979,The exercise of market power: Its treatment under the Australian and New Zealand statutes,October 1994,Philip L. Williams,,,Male,Unknown,Unknown,Male,,1
9.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01029980,Vertical restraints in the Australian Trade Practices Act,October 1994,R. Ian Mcewin,,,Unknown,Unknown,Unknown,Unknown,,
9.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01029981,Threshold tests for the control of mergers: The Australian experience,October 1994,Brian L. Johns,,,Male,Unknown,Unknown,Male,,1
9.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01029982,The role of antitrust in a small open economy: The Commerce Act in New Zealand,October 1994,Alan E. Bollard,,,Male,Unknown,Unknown,Male,,1
9.0,6.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01026580,The evolution of competition in U.S. manufacturing,December 1994,Frederic L. Pryor,,,Male,Unknown,Unknown,Male,,8
9.0,6.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01026581,Sunk costs and resource mobility: An empirical study,December 1994,Joseph Shaanan,,,Male,Unknown,Unknown,Male,,6
9.0,6.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01026582,"Copy watches, tailored clothes, and the structure→conduct→performance paradigm",December 1994,Ira Horowitz,,,Female,Unknown,Unknown,Female,,
9.0,6.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01026583,Pricing behavior in United States manufacturing industries: A statistical study using disaggregated data,December 1994,Elizabeth M. Caucutt,Mrinal Ghosh,Christina M. L. Kelton,Female,Female,Female,Female,,8
9.0,6.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01026584,Are margins more procyclical in concentrated industries?,December 1994,E. B. Goodstein,,,Unknown,Unknown,Unknown,Unknown,,
9.0,6.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01026585,"Market choice, entry regulation, and joint production: Market access and market service in motor carrier markets",December 1994,Wesley W. Wilson,,,Male,Unknown,Unknown,Male,,4
9.0,6.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01026586,Price convergence in contestable market structures: The impact of time and price-caps on intercity telecommunications rates,December 1994,Yu Hsing,Franklin G. Mixon Jr.,,,Male,Unknown,Mix,,
9.0,6.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01026587,CooperationV. Rivalry and factors facilitating collusion,December 1994,David I. Rosenbaum,Leslie D. Manns,,Male,,Unknown,Mix,,
9.0,6.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01026588,"Sessions organized by the Industrial Organization Society at the ASSA Meetings, Washington D.C., January 6–8, 1995",December 1994,,,,Unknown,Unknown,Unknown,Unknown,,
10.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024255,Concentration-price relations in regional fed cattle markets,February 1995,Bruce W. Marion,Frederick E. Geithman,,Male,Male,Unknown,Male,,21
10.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024256,Alternative profitability measures and tests of the structure-performance relationship,February 1995,Louis Amato,Ronald P. Wilder,,Male,Male,Unknown,Male,,3
10.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024257,Diffusion of a durable good innovation: The case of high bypass turbojet engines,February 1995,John Howard Brown,,,Male,Unknown,Unknown,Male,,
10.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024258,The degree of competition in the advertising industry,February 1995,Chulho Jung,Barry J. Seldon,,Unknown,Male,Unknown,Male,,14
10.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024259,The effect of merger and acquisition activity on the safety and soundness of a banking system,February 1995,Jacob Paroush,,,Male,Unknown,Unknown,Male,,12
10.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024260,Franchising vs. company ownership as a decision variable of the firm,February 1995,Frank A. Scott Jr.,,,Male,Unknown,Unknown,Male,,107
10.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024261,Reflections on Learner's index of monopoly power,February 1995,Robert D. Cairns,,,Male,Unknown,Unknown,Male,,7
10.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024262,Book review,February 1995,Theodore E. Keeler,,,Male,Unknown,Unknown,Male,,
10.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024263,Book review,February 1995,Thomas P. Lyon,,,Male,Unknown,Unknown,Male,,
10.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024264,Book review,February 1995,Gregg P. Frasco,,,Male,Unknown,Unknown,Male,,
10.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024265,Book review,February 1995,David R. Ross,,,Male,Unknown,Unknown,Male,,
10.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024266,Call for papers,February 1995,,,,Unknown,Unknown,Unknown,Unknown,,
10.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01029669,In honor of Leonard W. Weiss,April 1995,,,,Unknown,Unknown,Unknown,Unknown,,
10.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01029670,Leonard W. Weiss and industrial organization,April 1995,David B. Audretsch,John J. Siegfried,,Male,Male,Unknown,Male,,
10.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01029671,Leonard Weiss' contributions to research in industrial organization,April 1995,F. M. Scherer,,,Unknown,Unknown,Unknown,Unknown,,
10.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01029672,"Remarks at memorial service for Leonard W. Weiss, March 11, 1994",April 1995,John J. Siegfried,,,Male,Unknown,Unknown,Male,,
10.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01029673,The Horizontal Merger Guidelines of 1992,April 1995,Lucile S. Keyes,,,Female,Unknown,Unknown,Female,,7
10.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01029674,Technological change and multinational growth in international telecommunications services,April 1995,Cristiano Antonelli,,,Male,Unknown,Unknown,Male,,7
10.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01029675,The effects of the business cycle on oligopoly coordination: Evidence from the U.S. rayon industry,April 1995,Craig A. Gallet,John R. Schroeter,,Male,Male,Unknown,Male,,16
10.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01029676,"Innovation, R&D productivity, and global market share in the pharmaceutical industry",April 1995,Donald L. Alexander,Joseph E. Flynn,Linda A. Linkins,Male,Male,Female,Mix,,
10.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01029677,Durable goods and horizontal merger analysis,April 1995,Jack A. Nickerson,,,Male,Unknown,Unknown,Male,,2
10.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01029678,Industry structure and the choice of product reliability,April 1995,Greg Goering,Colin Read,,Male,Male,Unknown,Male,,4
10.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01029679,Book review,April 1995,Ingo Vogelsang,,,Male,Unknown,Unknown,Male,,
10.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01027074,Privatization of natural monopoly public enterprises: The regulation issue,June 1995,Ralph Bradburd,,,Male,Unknown,Unknown,Male,,13
10.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01027075,Oligopoly and behavioral uncertainty: An application of fuzzy set theory,June 1995,John G. Greenhut,M. L. Greenhut,Yusuf Mansur,Male,Unknown,Male,Male,,10
10.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01027076,"Sunk costs, contestability and airline monopoly power",June 1995,Margaret A. Peteraf,,,Female,Unknown,Unknown,Female,,7
10.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01027077,Measuring oligopsony power,June 1995,Mats A. Bergman,Runar Brännlund,,Male,Male,Unknown,Male,,32
10.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01027078,Marginal cost and second-best pricing for water services,June 1995,H. Youn Kim,,,Unknown,Unknown,Unknown,Unknown,,
10.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01027079,Rationalizing the International Coffee Agreement virtually,June 1995,Jay S. Coggins,,,Male,Unknown,Unknown,Male,,2
10.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01027080,Entry and product quality under price regulation,June 1995,Richard O. Beil,David L. Kaserman,Jon M. Ford,Male,Male,Male,Male,,4
10.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01027081,Product improvement and leadership in differentiated markets,June 1995,Timothy L. Sorenson,,,Male,Unknown,Unknown,Male,,2
10.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01027082,Book reviews,June 1995,Robert A. Sinclair,Stephen Martin,,Male,Male,Unknown,Male,,
10.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024225,Introduction,August 1995,,,,Unknown,Unknown,Unknown,Unknown,,
10.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024226,European capitalism: Between freedom and social justice,August 1995,H. W. de Jong,,,Unknown,Unknown,Unknown,Unknown,,
10.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024227,Comment on De Jong's ‘European capitalism: Between freedom and social justice’,August 1995,Ronald Dore,,,Male,Unknown,Unknown,Male,,
10.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024228,Comment on De Jong's ‘European capitalism: Between freedom and social justice’,August 1995,Michael Ellman,,,Male,Unknown,Unknown,Male,,
10.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024229,Comment on De Jong's ‘European capitalism: Between freedom and social justice’,August 1995,Pieter W. Moerland,,,Male,Unknown,Unknown,Male,,
10.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024230,Corporate ownership and control structures: An international comparison,August 1995,Pieter W. Moerland,,,Male,Unknown,Unknown,Male,,45
10.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024231,Can market power be estimated?,August 1995,Charles E. Hyde,Jeffrey M. Perloff,,Male,Male,Unknown,Male,,37
10.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024232,Power in the market for Medi-Cal services,August 1995,Lee Rivers Mobley,,,,Unknown,Unknown,Mix,,
10.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024233,The effects of a relative value reimbursement scheme on the medical market: Lessons from medicaid,August 1995,W. David Bradford,,,Unknown,Unknown,Unknown,Unknown,,
10.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01026879,Vertical mergers and selective price cutting,October 1995,Ronald N. Johnson,Allen M. Parkman,,Male,Male,Unknown,Male,,1
10.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01026880,An empirical model of entry and exit in airline markets,October 1995,Robert A. Sinclair,,,Male,Unknown,Unknown,Male,,28
10.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01026881,Testing for market power in the U.S. motor carrier industry,October 1995,William Nebesky,B. Starr McMullen,Man-Keung Lee,Male,Unknown,Unknown,Male,,19
10.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01026882,Editor's introduction,October 1995,,,,Unknown,Unknown,Unknown,Unknown,,
10.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01026883,"Firm profitability, growth, and innovation",October 1995,David B. Audretsch,,,Male,Unknown,Unknown,Male,,55
10.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01026884,The propensity to exit and innovation,October 1995,David B. Audretsch,,,Male,Unknown,Unknown,Male,,15
10.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01026885,Diversification and industry evolution,October 1995,John T. Scott,,,Male,Unknown,Unknown,Male,,
10.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01026886,Competition vs. monopoly in Greek large-scale manufacturing industries,October 1995,Persefoni Tsaliki,Lefteris Tsoulfidis,,Female,Unknown,Unknown,Female,,2
10.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01026887,Deregulation without apology: A truncated survivor analysis of long-run efficiency gains in the U.S. trucking industry,October 1995,James N. Giordano,,,Male,Unknown,Unknown,Male,,3
10.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01026888,"Sessions planned for the ASSA Meetings of the Industrial Organization Society, San Francisco, January 5–7, 1996",October 1995,,,,Unknown,Unknown,Unknown,Unknown,,
10.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01026889,Call for papers,October 1995,,,,Unknown,Unknown,Unknown,Unknown,,
10.0,6.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024299,Announcement,December 1995,,,,Unknown,Unknown,Unknown,Unknown,,
10.0,6.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024300,"Market share inequality, the HHI, and other measures of the firm-composition of a market",December 1995,Stephen A. Rhoades,,,Male,Unknown,Unknown,Male,,76
10.0,6.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024301,The economics of advertising: Where's the data?,December 1995,Richard T. Rogers,Robert J. Tokle,,Male,Male,Unknown,Male,,7
10.0,6.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024302,Caveat! Some unrecognized pitfalls in Census economic data and the Input-Output Accounts,December 1995,Robert L. Steiner,,,Male,Unknown,Unknown,Male,,2
10.0,6.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024303,Qualitative constraints as a tool of economic analysis,December 1995,Maria Petychaki-Henze,Kyprianos P. Prodromidis,,Female,Unknown,Unknown,Female,,1
10.0,6.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024304,Bargaining over employment as a firm strategic choice,December 1995,Jacques Bughin,,,Male,Unknown,Unknown,Male,,11
10.0,6.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024305,Beta distributed market shares in a spatial model with an application to the market for audit services,December 1995,Morten Hviid,Bente Villadsen,,Male,Female,Unknown,Mix,,
10.0,6.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024306,Price uncertainty and output concentration,December 1995,Vivek Ghosal,,,Male,Unknown,Unknown,Male,,6
10.0,6.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF01024307,Price communications in a multimarket context: An experimental investigation,December 1995,Timothy N. Cason,Douglas D. Davis,,Male,Male,Unknown,Male,,29
11.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00163594,"Profitability, productivity and price recovery patterns in the U.S. telecommunications industry",February 1996,R. D. Banker,H.-H. Chang,S. K. Majumdar,Unknown,Unknown,Unknown,Unknown,,
11.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00163595,Business services: Markets and transactions,February 1996,Jacques De Bandt,,,Male,Unknown,Unknown,Male,,8
11.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00163596,When e-mail becomes junk mail: The welfare implications of the advancement of communications technology,February 1996,Daniel R. Shiman,,,Male,Unknown,Unknown,Male,,15
11.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00163597,Performance of Japanese firms in patented inventions; an analysis of patents granted in the U.S.,February 1996,Noriyuki Doi,,,Male,Unknown,Unknown,Male,,2
11.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00163598,"Dynamic effects in Greek manufacturing: The changing shares of SMES, 1983–1990",February 1996,Stavros B. Thomadakis,Vassilis Droucopoulos,,Male,Unknown,Unknown,Male,,3
11.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00163599,Exchange rate regimes and import pricing,February 1996,Yves Bourdet,,,Male,Unknown,Unknown,Male,,1
11.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00163600,Brand versus generic advertising and the decision to advertise collectively,February 1996,Catherine Carey,Dawn Langkamp Bolton,,Female,Female,Unknown,Female,,7
11.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00163601,Market structure and the impact of imports on price cost margins,February 1996,Elena Lopez,Rigoberto A. Lopez,,Female,Male,Unknown,Mix,,
11.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00163602,Can market power really be estimated?,February 1996,Kenneth D. Boyer,,,Male,Unknown,Unknown,Male,,9
11.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00163603,Toward measuring monopoly power,February 1996,Robert D. Cairns,,,Male,Unknown,Unknown,Male,,
11.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00163604,Book review,February 1996,John J. Siegfried,Randall E. Waldron,,Male,Male,Unknown,Male,,
11.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00157663,The dynamics of industrial organization,April 1996,A. Roy Thurik,David B. Audretsch,,Unknown,Male,Unknown,Male,,4
11.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00157664,"Entry and exit in retailing: Incentives, barriers, displacement and replacement",April 1996,Martin Carree,Roy Thurik,,Male,Male,Unknown,Male,,44
11.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00157665,Small firm births and macroeconomic fluctuations,April 1996,José Mata,,,Male,Unknown,Unknown,Male,,15
11.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00157666,Economic integration and new firm formation: Britain's impact on Irish enterprise,April 1996,Andrew E. Burke,,,Male,Unknown,Unknown,Male,,5
11.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00157667,"Firm size, firm age and job duration",April 1996,Joachim Wagner,,,Male,Unknown,Unknown,Male,,1
11.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00157668,The survival and non survival of micro firms in the UK,April 1996,D. J. Storey,P. Wynarczyk,,Unknown,Unknown,Unknown,Unknown,,
11.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00157669,Turbulence and growth in West Germany: A comparison of evidence by regions and industries,April 1996,Michael Fritsch,,,Male,Unknown,Unknown,Male,,36
11.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00157670,Innovative clusters and the industry life cycle,April 1996,David B. Audretsch,Maryann P. Feldman,,Male,Female,Unknown,Mix,,
11.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00414399,Firm heterogeneity and worker turnover,June 1996,Julia I. Lane,Alan G. Isaac,David W. Stevens,Female,Male,Male,Mix,,
11.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00414400,Evaluating traditional share—Price and residual demand measures of market power in the catsup industry,June 1996,Lawrence E. Haller,Ronald W. Cotterill,,Male,Male,Unknown,Male,,9
11.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00414401,Short and long run movements in U.S. merger activity,June 1996,Jonathan Crook,,,Male,Unknown,Unknown,Male,,5
11.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00414402,Industrial policy and the restructuring of firms in post-socialist Slovenia,June 1996,Tea Petrin,,,Female,Unknown,Unknown,Female,,2
11.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00414403,Restraints of trade by durable good producers,June 1996,Roger D. Blair,Jill Boylston Herndon,,Male,Female,Unknown,Mix,,
11.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00414404,Industrial policy and duopolistic trade with dynamic demand,June 1996,Robert Driskill,Stephen McCafferty,,Male,Male,Unknown,Male,,8
11.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00414405,Entry and exit in Dutch manufacturing industries,June 1996,Aad J. M. Kleijweg,Marcel H. C. Lever,,Male,Male,Unknown,Male,,16
11.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00414406,Firm-specific learning-by-doing in semiconductor production: Some evidence from the 1986 Trade Agreement,June 1996,William W. Nye,,,Male,Unknown,Unknown,Male,,12
11.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00414407,Merger policy greatly simplified: Building on keyes,June 1996,Donald Dewey,,,Male,Unknown,Unknown,Male,,8
11.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00414408,The ineffectiveness of R&D subsidies—An oligopoly theoretic insight,June 1996,Karlo Kauko,,,Male,Unknown,Unknown,Male,,3
11.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00157771,Editorial note,August 1996,,,,Unknown,Unknown,Unknown,Unknown,,
11.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00157772,The great school milk conspiracies of the 1980s,August 1996,Robert F. Lanzillotti,,,Male,Unknown,Unknown,Male,,23
11.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00157773,A note on price cap regulation and competition,August 1996,Lester D. Taylor,Dennis L. Weisman,,Male,Male,Unknown,Male,,3
11.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00157774,Concentration change and countervailing power in the U.S. food manufacturing industries,August 1996,John M. Connor,Richard T. Rogers,Vijay Bhagavan,Male,Male,,Mix,,
11.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00157775,Measuring changes in multiproduct market structure: An application to U.S. airlines,August 1996,Kathy J. Hayes,Leola B. Ross,,Female,Female,Unknown,Female,,2
11.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00157776,Alternatives to the U.S. Antitrust Agency approach to market definition,August 1996,F. William McElroy,,,Unknown,Unknown,Unknown,Unknown,,
11.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00157777,Using relative profit incentives to prevent collusion,August 1996,Carl Lundgren,,,Male,Unknown,Unknown,Male,,20
11.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00157778,Optimal cartel trigger strategies and the number of firms,August 1996,Hugh Briggs III,,,Male,Unknown,Unknown,Male,,6
11.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00157779,Book reviews,August 1996,Dennis L. Weisman,Don E. Waldman,Donald L. Alexander,Male,Male,Male,Male,,
11.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00214823,Introduction,October 1996,Albert N. Link,John T. Scott,,Male,Male,Unknown,Male,,
11.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00214824,Choosing government R&D policies: Tax incentives vs. direct funding,October 1996,Gregory Tassey,,,Male,Unknown,Unknown,Male,,24
11.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00214825,Trends and patterns in strategic technology partnering since the early seventies,October 1996,John Hagedoorn,,,Male,Unknown,Unknown,Male,,120
11.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00214826,Research joint ventures: Patterns from Federal Register filings,October 1996,Albert N. Link,,,Male,Unknown,Unknown,Male,,48
11.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00214827,The U.S. research university and the joint venture: Evolution of an institution,October 1996,William L. Baldwin,,,Male,Unknown,Unknown,Male,,7
11.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00214828,Environmental research joint ventures among manufactures,October 1996,John T. Scott,,,Male,Unknown,Unknown,Male,,36
11.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00214829,The welfare effects of cooperative R&D in oligopoly with spillovers,October 1996,Sang-Seung Yi,,,Unknown,Unknown,Unknown,Unknown,,
11.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00214830,Interfirm cooperation and structural change in the European automobile industry,October 1996,Gerhard Rosegger,,,Male,Unknown,Unknown,Male,,5
11.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00214831,"Protection, promotion and cooperation in the European semiconductor industry",October 1996,Stephen Martin,,,Male,Unknown,Unknown,Male,,14
11.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00214832,Estimating the benefits from collaboration: The case of SEMATECH,October 1996,Albert N. Link,David J. Teece,William F. Finan,Male,Male,Male,Male,,32
11.0,6.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00174401,Announcement,December 1996,,,,Unknown,Unknown,Unknown,Unknown,,
11.0,6.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00174402,Is predation rational? Is it profitable?,December 1996,Walter Adams,James W. Brock,Norman P. Obst,Male,Male,Male,Male,,1
11.0,6.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00174403,"Comment to Adams, Brock and Obst: ‘Is predation rational? Is it profitable?’",December 1996,Kenneth G. Elzinga,David E. Mills,,Male,Male,Unknown,Male,,
11.0,6.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00174404,"Comment to Adams, Brock and Obst: “Is predation rational? Is it profitable?”",December 1996,David I. Rosenbaum,,,Male,Unknown,Unknown,Male,,
11.0,6.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00174405,Is predation rational? Is it profitable? — A reply,December 1996,Walter Adams,James W. Brock,Norman P. Obst,Male,Male,Male,Male,,
11.0,6.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00174406,"Firm success, national status, and product line diversification: An empirical examination",December 1996,Carol Horton Tremblay,Victor J. Tremblay,,,Male,Unknown,Mix,,
11.0,6.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00174407,Prospective payments and hospital efficiency,December 1996,W. David Bradford,Catherine Craycraft,,Unknown,Female,Unknown,Female,,1
11.0,6.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00174408,Pure vs. mixed commodity bundling,December 1996,Brooks Pierce,Harold Winter,,Male,Male,Unknown,Male,,17
11.0,6.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00174409,A note on the implementation of cable TV rate caps,December 1996,Jith Jayaratne,,,Unknown,Unknown,Unknown,Unknown,,
11.0,6.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00174410,Has pharmaceutical research become more scientific?,December 1996,David Schwartzman,Antonio Cognato,,Male,Male,Unknown,Male,,3
11.0,6.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00174411,"Mixed duopoly, inefficiency, and public ownership",December 1996,Kenneth George,Manfredi M. A. La Manna,,Male,Male,Unknown,Male,,31
11.0,6.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00174412,Expense preference behavior in trucking: An empirical note,December 1996,Franklin G. Mixon Jr.,Kamal P. Upadhyaya,,Male,Male,Unknown,Male,,7
11.0,6.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00174413,A comment on Bradburd: “Privatisation of natural monopolies”,December 1996,Johan Willner,,,Male,Unknown,Unknown,Male,,10
11.0,6.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00174414,Privatization of natural monopoly public enterprises: A reply,December 1996,Ralph Bradburg,,,Male,Unknown,Unknown,Male,,1
11.0,6.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/BF00174415,"Sessions scheduled at the ASSA meetings, January 4–6, 1997, New Orleans",December 1996,,,,Unknown,Unknown,Unknown,Unknown,,
12.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007769127555,Research on IO Topics in Banking: An Introduction and Overview,February 1997,Stephen A. Rhoades,,,Male,Unknown,Unknown,Male,,17
12.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007798618469,The Profit-Structure Relationship in Legally Protected Banking Markets Using Efficiency Measures,February 1997,W. Scott Frame,David R. Kamerschen,,Unknown,Male,Unknown,Male,,16
12.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007744119377,"Market Share Inequality, the Number of Competitors, and the HHI: An Examination of Bank Pricing",February 1997,Timothy H. Hannan,,,Male,Unknown,Unknown,Male,,100
12.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007700703448,Market Structure and the Speed of Price Adjustments: Evidence Of Non-Monotonicity,February 1997,William E. Jackson III,,,Male,Unknown,Unknown,Male,,40
12.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007796520286,Determinants of Entry and Profits in Local Banking Markets,February 1997,Dean F. Amel,J. Nellie Liang,,Male,Unknown,Unknown,Male,,73
12.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007748623012,The Effect of Consumer Switching Costs on Prices: A Theory and its Application to the Bank Deposit Market,February 1997,Steven A. Sharpe,,,Male,Unknown,Unknown,Male,,116
12.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007760924829,The Effects of Megamergers on Efficiency and Prices: Evidence from a Bank Profit Function,February 1997,JALAL D. Akhavein,Allen N. Berger,David B. Humphrey,Unknown,Male,Male,Male,,244
12.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007754801740,Price Leadership on the National Cheese Exchange,April 1997,Willard F. Mueller,Bruce W. Marion,Maqbool H. Sial,Male,Male,Unknown,Male,,5
12.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007718618005,Antitrust Sanctions and a Firm's Ability to Pay,April 1997,Catherine Craycraft,Joseph L. Craycraft,Joseph C. Gallo,Female,Male,Male,Mix,,
12.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007747713353,Multihospital Chain Acquisitions and Competition in Local Health Care Markets,April 1997,Lee Rivers Mobley,,,,Unknown,Unknown,Mix,,
12.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007744519391,Testing the Competitive Environment and the Persistence of Profits Hypotheses,April 1997,Constantine A. Bourlakis,,,,Unknown,Unknown,Mix,,
12.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007710622023,Specification and Testing the Profit-Concentration Relationship in Australian Manufacturing,April 1997,Mita Bhattacharya,Harry Bloch,,Female,Male,Unknown,Mix,,
12.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007766324749,The Impact of Size and Age on Firm-Level Performance: Some Evidence from India,April 1997,Sumit K. Majumdar,,,Male,Unknown,Unknown,Male,,232
12.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007781501147,From Which Source Do Small Firms Derive Their Innovative Inputs? Some Evidence from Italian Industry,April 1997,Roberta Piergiovanni,Enrico Santarelli,Marco Vivarelli,Female,Male,Male,Mix,,
12.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007762402056,"Cost Reduction, Competitive Pressure and Firms' Optimal R&D Strategies in a Duopolistic Industry",April 1997,Domenico Campisi,Paolo Mancuso,Alberto Nastasi,Male,Male,Male,Male,,6
12.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007710417985,License to Be More Innovative,April 1997,Ping Lin,,,,Unknown,Unknown,Mix,,
12.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007774525678,Identifying Participants in a Price-fixing Conspiracy: Output & Market Share Tests Reexamined,April 1997,Mehmet E. Karaaslan,,,Male,Unknown,Unknown,Male,,2
12.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007728122498,Identifying Participants in a Price-fixing Conspiracy: Output & Market Share Tests Reexamined – Reply,April 1997,Roger D. Blair,Richard E. Romano,,Male,Male,Unknown,Male,,1
12.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007740324571,Book Review,April 1997,John C. Hilke,,,Male,Unknown,Unknown,Male,,
12.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1017197016399,Editor's Introduction,June 1997,,,,Unknown,Unknown,Unknown,Unknown,,
12.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007799726490,Confessions of a Telephone Regulator: The FCC's AT&T Investigation of 1972–1977,June 1997,Manley R. Irwin,,,Unknown,Unknown,Unknown,Unknown,,
12.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007726012218,The Pin Factory Revisited: Product Diversification and Productivity Growth,June 1997,Frank M. Gollop,,,Male,Unknown,Unknown,Male,,90
12.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007776312444,Domestic Market Structure and Performance in Global Markets: Theory and Empirical Evidence from U.S. Food Manufacturing Industries,June 1997,Donghwan Kim,Bruce W. Marion,,Unknown,Male,Unknown,Male,,21
12.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007704421589,An Empirical Study of the Effect of Brand Proliferation on Private Label – National Brand Pricing Behavior,June 1997,William P. Putsis Jr.,,,Male,Unknown,Unknown,Male,,61
12.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007799730191,The Increasing Competitive Balance in Major League Baseball,June 1997,Ira Horowitz,,,Female,Unknown,Unknown,Female,,69
12.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007773415419,Do Firms Diversify Because Managers Shirk? A Reinterpretation of the Principal-Agent Model of Diversification,June 1997,David C. Rose,,,Male,Unknown,Unknown,Male,,1
12.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007799732257,Product Durability and Moral Hazard,June 1997,Gregory E. Goering,,,Male,Unknown,Unknown,Male,,11
12.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007751816327,Ramsey Pricing and Regulator's Social Welfare Weights: An Empirical Application,June 1997,Marcelo Resende,,,Male,Unknown,Unknown,Male,,6
12.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007795629282,Spatial Price Discrimination: The Use of Parking Coupons by Downtown Retailers,June 1997,C. Robin Lindsey,Douglas S. West,,Unknown,Male,Unknown,Male,,7
12.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007748414948,Comment on Dewey's “Merger Policy Greatly Simplified/Building on Keyes”,June 1997,LUCILE S. Keyes,,,Unknown,Unknown,Unknown,Unknown,,
12.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007749710230,Still Seeking Common Ground: A Response to Keyes,June 1997,Donald Dewey,,,Male,Unknown,Unknown,Male,,1
12.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1017169004276,Book Reviews,June 1997,,,,Unknown,Unknown,Unknown,Unknown,,
12.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007733206595,"Fuly Distributed Cost Pricing, Ramsey Pricing, and Shapley Value Pricing: A Simulated Welfare Analysis for the Telephone Exchange",August 1997,D. Mark Kennet,David J. Gabel,,Unknown,Male,Unknown,Male,,
12.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007742414944,Horizontal Concentration and Vertical Integration in the Cable Television Industry,August 1997,George S. Ford,John D. Jackson,,Male,Male,Unknown,Male,,41
12.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007785307504,"Interstate Long Distance Rates: Search Costs, Switching Costs, and Market Power",August 1997,Christopher R. Knittel,,,Male,Unknown,Unknown,Male,,50
12.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007769726331,"The FCC and the Decline in AT & T's Long Distance Residential Rates, 1980–1992: Did Price Caps Do It?",August 1997,Susan A. Edelman,,,Female,Unknown,Unknown,Female,,5
12.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007789424342,Magazine Subscription Discounts in Australia,August 1997,David K. Round,Teresita G. Bentick,,Male,Female,Unknown,Mix,,
12.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007786229965,"The Characteristics of Takeover Target Firms: The Case of the English Brewing Industry, 1945–1960",August 1997,Alison Dean,,,Female,Unknown,Unknown,Female,,5
12.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007798532691,New Information Technology and the Knowledge-Based Economy. The Italian Evidence,August 1997,Cristiano Antonelli,,,Male,Unknown,Unknown,Male,,19
12.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007713608584,Diagonal Merger,August 1997,Richard S. Higgins,,,Male,Unknown,Unknown,Male,,5
12.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007719221189,Price Leadership on the National Cheese Exchange,August 1997,Willard F. Mueller,Bruce W. Marion,Maqbool H. Sial,Male,Male,Unknown,Male,,1
12.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007797626160,Merger Policy in the United States: A Reconsideration,December 1997,Dennis C. Mueller,,,Male,Unknown,Unknown,Male,,41
12.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007702324969,Comment on “Merger Policy in the United States”,December 1997,F. M. Scherer,,,Unknown,Unknown,Unknown,Unknown,,
12.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007786804342,The Tenacity of Antitrust Mythology: Dissenting from Mueller,December 1997,Donald Dewey,,,Male,Unknown,Unknown,Male,,1
12.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007728029593,Further Comment on the Social Benefits from an Effective Antimerger Policy,December 1997,Dennis C. Mueller,,,Male,Unknown,Unknown,Male,,
12.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007796610203,New Evidence on the Performance Advantages of Multihospital Systems,December 1997,Gary M. Fournier,Jean M. Mitchell,,Male,Male,Unknown,Male,,5
12.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007714502964,Optimal Concentration and Deadweight Losses in Canadian Manufacturing,December 1997,Vaughan Dickson,Jian He,,,,Unknown,Mix,,
12.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007762222932,Technological Change and the Production of Ocean Shipping Services,December 1997,Christopher C. Klein,Reuben Kyle,,Male,Male,Unknown,Male,,6
12.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007763019487,Raising Rivals' Costs Strategies via Emission Permits Markets,December 1997,Eftichios Sophocles Sartzetakis,,,Unknown,Unknown,Unknown,Unknown,,
12.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007752812928,CEO Age and Outside Directors: A Hazard Analysis,December 1997,R. Richard Geddes,Hrishikesh D. Vinod,,Unknown,Unknown,Unknown,Unknown,,
12.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007732209294,Strategic Substitutes and Strategic Complements With Interdependent Demands,December 1997,David G. Loomis,,,Male,Unknown,Unknown,Male,,2
12.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007700827041,Airport Concentration and Market Power: An Events Study Approach,December 1997,Matthew J. Hergott,,,Male,Unknown,Unknown,Male,,12
12.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007779422525,"Search Costs and Price Dispersion in a Localized, Homogeneous Product Market: Some Empirical Evidence",December 1997,A. Frank Adams III,,,Unknown,Unknown,Unknown,Unknown,,
12.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007769919319,The “Own-Brand Marketer” Debuts in the 1997 Census,December 1997,Robert L. Steiner,,,Male,Unknown,Unknown,Male,,2
12.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007709700663,Multiproduct Firms' Pricing Behaviour in the Italian Grocery Trade,December 1997,Monica Giulietti,Michael Waterson,,Female,Male,Unknown,Mix,,
12.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007726610390,"Networks, Infrastructure and the New Task for Regulation. Werner Sichel and Donald L. Alexander, editors.",December 1997,Craig Gallet,,,Male,Unknown,Unknown,Male,,
12.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007791314413,Telecommunications Competition: The Last Ten Miles. Ingo Vogelsang and Bridger Mitchell.,December 1997,David E. M. Sappington,,,Male,Unknown,Unknown,Male,,
12.0,5.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1017135115052,"Sessions Planned for the Industrial Organization Society at the ASSA Meetings, at Chicago, January 3–5, 1998",December 1997,,,,Unknown,Unknown,Unknown,Unknown,,
13.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1017126109381,Editor’s Note,April 1998,,,,Unknown,Unknown,Unknown,Unknown,,
13.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007752731450,Introduction: The Evolution of Competition Law in Canada,April 1998,Thomas W. Ross,,,Male,Unknown,Unknown,Male,,26
13.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007714517338,Merger Enforcement under the Competition Act after Ten Years,April 1998,Donald G. McFetridge,,,Male,Unknown,Unknown,Male,,7
13.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007774803225,The Law and Economics of Resale Price Maintenance,April 1998,Frank Mathewson,Ralph Winter,,Male,Male,Unknown,Male,,73
13.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007735104134,Abuse of Dominance under the 1986 Canadian Competition Act,April 1998,Jeffrey Church,Roger Ware,,Male,Male,Unknown,Male,,9
13.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007739221881,Refusals to Deal and Aftermarkets,April 1998,Zhiqi Chen,Thomas W. Ross,W. T. Stanbury,Unknown,Male,Unknown,Male,,21
13.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007795305951,Conspiracy Law and Jurisprudence in Canada: Towards an Economic Approach,April 1998,Patrick Hughes,Margaret Sanderson,,Male,Female,Unknown,Mix,,
13.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007747423698,"Competition Policy and Regulatory Reform in Canada, 1986–1997",April 1998,Robert D. Anderson,Abraham Hollander,W. T. Stanbury,Male,Male,Unknown,Male,,6
13.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007703624607,"Expanding Responsibilities and Declining Resources: The Strategic Responses of the Competition Bureau, 1986–1996",April 1998,W. T. Stanbury,,,Unknown,Unknown,Unknown,Unknown,,
13.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007707808677,Rationalism Rebuffed? Lessons from Modern Canadian and New Zealand Competition Policy,April 1998,Tim Hazledine,,,Male,Unknown,Unknown,Male,,2
13.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1017157826219,Call for Papers,April 1998,,,,Unknown,Unknown,Unknown,Unknown,,
14.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007715215394,Interconnection in Network Industries,February 1999,Michael Carter,Julian Wright,,Male,Male,Unknown,Male,,90
14.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007723912369,Durability Versus Concentration as an Explanation for Price Inflexibility,February 1999,Elizabeth M. Caucutt,Mrinal Ghosh,Christina M.L. Kelton,Female,Female,Female,Female,,23
14.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007764008391,The Meaning of Size: Output? Scope? Capacity? The Case of Airline Hubs,February 1999,Richard V. Butler,John H. Huston,,Male,Male,Unknown,Male,,3
14.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007719609300,The Effect of U.S. Antidumping Law on Firms' Market Power: An Empirical Test,February 1999,James F. Nieberding,,,Male,Unknown,Unknown,Male,,14
14.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007744517821,"A Note on Public Sector Integration: The Decline of British Naval Aviation, 1914–1945",February 1999,Manley R. Irwin,,,Unknown,Unknown,Unknown,Unknown,,
14.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007738908237,"Industrial Concentration and Performance: A Study of the Structure, Conduct, and Performance of Indian Industry.",February 1999,Lydia Ortega,,,Female,Unknown,Unknown,Female,,
14.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1017178701557,Editor's Introduction,March 1999,,,,Unknown,Unknown,Unknown,Unknown,,
14.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007748424330,Senator John Sherman Meets Professor John Rawls: A Fortuitous Encounter for Justice,March 1999,William J. Curran III,,,Male,Unknown,Unknown,Male,,1
14.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007789816578,"Antitrust, the Rule of Reason, and Democracy",March 1999,David W. Barnes,,,Male,Unknown,Unknown,Male,,1
14.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007738203915,The Obfuscation of the Common Good,March 1999,Daniel J. Gifford,,,Male,Unknown,Unknown,Male,,
14.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007723726138,The Cash Recovery Method of Calculating Profitability: An Application to Pharmaceutical Firms,March 1999,Christopher T. Taylor,,,Male,Unknown,Unknown,Male,,6
14.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007709006733,Publication of Information and Market Response: The Case of Airline on Time Performance Reports,March 1999,Stephen Earl Foreman,,,Male,Unknown,Unknown,Male,,18
14.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007779814751,Multimarket Contact in Banking,March 1999,Steven J. Pilloff,,,Male,Unknown,Unknown,Male,,65
14.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007748914733,Transaction Cost Economics: Recent Developments,March 1999,,,,Unknown,Unknown,Unknown,Unknown,,
14.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1017186725691,Announcement,May 1999,,,,Unknown,Unknown,Unknown,Unknown,,
14.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007728100373,Antitrust and Sales-Below-Cost Laws: The Case of Retail Gasoline,May 1999,Rod W. Anderson,Ronald N. Johnson,,Male,Male,Unknown,Male,,35
14.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007788303098,Free-Agency and the Competitiveness of Major League Baseball,May 1999,Craig A. Depken II,,,Male,Unknown,Unknown,Male,,86
14.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007744520845,Does Microelectronics Reduce Economies of Scale? A Case Study in the Turkish Chemical Industry,May 1999,Dilek Cetindamar Karaomerlioglu,,,Female,Unknown,Unknown,Female,,
14.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007700822663,Is Radio Advertising a Distinct Local Market? An Empirical Analysis,May 1999,Robert B. Ekelund Jr.,George S. Ford,John D. Jackson,Male,Male,Male,Male,,15
14.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007714728676,On Antitrust Enforcement and the Deterrence of Collusive Behaviour,May 1999,Philippe Cyrenne,,,Male,Unknown,Unknown,Male,,33
14.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007796320753,Public Policy Toward Cable Television: the Economics of Rate Controls. Thomas w. Hazlett and Matthew l. Spitzer.,May 1999,Elizabeth J. Jensen,,,Female,Unknown,Unknown,Female,,
14.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007713213852,Designing Incentive Regulation for the Telecommunications Industry.DavidE. M. Sappington and Dennis L. Weisman.,May 1999,John S. Ying,,,Male,Unknown,Unknown,Male,,
14.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007725929850,Product Location with Foresight,May 1999,Timothy L. Sorenson,,,Male,Unknown,Unknown,Male,,1
14.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1017144409762,Call for Papers,May 1999,,,,Unknown,Unknown,Unknown,Unknown,,
14.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007768507753,Commitment to Competition: An Assessment of Antitrust Agency Budgets since 1970,June 1999,John E. Kwoka Jr.,,,Male,Unknown,Unknown,Male,,11
14.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007762511838,Open Entry and Local Telephone Rates: The Economics of IntraLATA Toll Competition,June 1999,David L. Kaserman,John W. Mayo,Simran K. Kahai,Male,Male,Unknown,Male,,4
14.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007717513689,Upstream-Downstream Specialization by Integrated Firms in a Partially Integrated Industry,June 1999,Gérard Gaudet,Ngo Van Long,Antoine Soubeyran,Male,Unknown,Male,Male,,3
14.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007713412780,Vertical Integration in International Telecommunication System,June 1999,Livio Cricelli,Massimo Mastaldi,Nathan Levialdi,Male,Male,Male,Male,,34
14.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007728013278,The Economic Performance of State-owned Enterprises in Argentina an Empirical Assessment,June 1999,Zhenhui Xu,Melissa H. Birch,,Unknown,Female,Unknown,Female,,9
14.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007721630527,"Market Power, Efficiency and the Dispersion of Systematic Risk",June 1999,Donald L. Alexander,Paul D. Thistle,,Male,Male,Unknown,Male,,12
14.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007758410930,A Doodles Theory of Economic Growth,June 1999,Donald C. Wellington,,,Male,Unknown,Unknown,Male,,
15.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007753010055,"The Characteristics, Performance and Strategic Behaviour of Merged Versus Non-Merged Establishments in Britain",August 1999,Grazia Ietto-Gillies,Meloria Meschi,,Female,Unknown,Unknown,Female,,1
15.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007748909146,Increasingly Marginal Utilities: Diversification and Free Cash Flow in Newly Privatized UK Utilities,August 1999,Steve Thompson,,,Male,Unknown,Unknown,Male,,9
15.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007757110963,"The Determinants of Innovation: R & D, Technology Transfer and Networking Effects",August 1999,James H. Love,Stephen Roper,,Male,Male,Unknown,Male,,174
15.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007761311872,Multiproduct Outputs and Scale Economies in Electric Power Production: Some New Estimates,August 1999,Dan M. Berry,Franklin G. Mixon Jr.,,Male,Male,Unknown,Male,,9
15.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007709227801,The Effects of Market Structure and Technology on Airline Fleet Composition after Deregulation,August 1999,Bahram Adrangi,Garland Chow,Kambiz Raffiee,Male,Male,Male,Male,,6
15.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007766010906,Technology and Market Structure. Theory and History. John Sutton.,August 1999,,,,Unknown,Unknown,Unknown,Unknown,,
15.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007787725018,Opening Networks to Competition: The Regulation and Pricing of Access. David Gabel and David Weiman,August 1999,,,,Unknown,Unknown,Unknown,Unknown,,
15.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007858331569,"Asking About Prices: A New Approach to Understanding Price Stickiness. Alan S. Blinder, Elie R. D. Canetti, David F. Lebow, and Jeremy B. Rudd.",August 1999,,,,Unknown,Unknown,Unknown,Unknown,,
15.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007796825076,NAFTA as a Means of Raising Rivals' Costs,September 1999,Craig A. Depken II,Jon M. Ford,,Male,Male,Unknown,Male,,7
15.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007705126893,"Non-cooperative Tacit Collusion, Complementary Bidding and Incumbency Premium",September 1999,In K. Lee,,,,Unknown,Unknown,Mix,,
15.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007701025984,Regulation and the Development of Competition in the U.K. Gas Supply Industry,September 1999,Charlie Weir,,,,Unknown,Unknown,Mix,,
15.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007732110007,The Measurement of Firm Information About Product Demand,September 1999,John Robst,Kimmarie McGOLDRICK,,Male,Unknown,Unknown,Male,,1
15.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007710527768,Comparative Organizational Characteristics of Indian State-Owned Enterprises,September 1999,Sumit K. Majumdar,,,Male,Unknown,Unknown,Male,,1
15.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007734700418,The Spillover Effects of Industrial Action on Firm Profitability,September 1999,James Ted McDonald,Harry Bloch,,Male,Male,Unknown,Male,,7
15.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1017274825290,"Sessions Planned for the Industrial Organization Society at the ASSA Meetings, at Boston, January 7–9, 2001",September 1999,,,,Unknown,Unknown,Unknown,Unknown,,
15.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1017269509360,"Session Planned for the Industrial Organization Society at the Southern Economic Association Meetings, at New Orleans, November 21–23, 2000",September 1999,,,,Unknown,Unknown,Unknown,Unknown,,
15.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007730632277,Effects of Assumed Demand Form on Simulated Postmerger Equilibria,November 1999,Philip Crooke,Luke Froeb,Gregory J Werden,Male,Male,Male,Male,,61
15.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007708612713,The Survival of New Products,November 1999,Marcus Asplund,Rickard Sandin,,Male,Male,Unknown,Male,,25
15.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007722415439,The Industry Component of Regional New Firm Formation Processes,November 1999,David B. Audretsch,Michael Fritsch,,Male,Male,Unknown,Male,,51
15.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007732218120,A Note on Endogenous Spillovers in a Non-Tournament R & D Duopoly,November 1999,Joanna Poyago-Theotoky,,,Female,Unknown,Unknown,Female,,81
15.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007751210412,How do Participants in Research Joint Ventures Diversify?,November 1999,Nicholas S. Vonortas,,,Male,Unknown,Unknown,Male,,5
15.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007786719982,Microeconomic and Macroeconomic Influences on Entry and Exit of Firms,November 1999,Pekka Ilmakunnas,Jukka Topi,,Male,Male,Unknown,Male,,57
15.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007775731338,Heterogeneities within Industries and Structure-Performance Models,December 1999,Dennis C. Mueller,Burkhard Raunig,,Male,Male,Unknown,Male,,15
15.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007747813591,Economic Capacity Utilization and its Determinants: Theory and Evidence,December 1999,H. Youn Kim,,,Unknown,Unknown,Unknown,Unknown,,
15.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007771630429,Another Look at Local Franchise Regulation and State Commission Regulation: Do They Really Matter?,December 1999,Yasuji Otsuka,,,Male,Unknown,Unknown,Male,,
15.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007723714499,Regime Effects of EU Market Integration Policies on the UK Financial Sector,December 1999,Robert M. Feinberg,Richard K. Harper,,Male,Male,Unknown,Male,,4
15.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007727815408,"Market Power, Industrial Concentration and Innovative Activity",December 1999,Robert W. Vossen,,,Male,Unknown,Unknown,Male,,33
15.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007779832246,"Ownership Advantages, Foreign Production and Productivity: Evidence from Austrian Manufacturing Firms",December 1999,Michael Pfaffermayr,,,Male,Unknown,Unknown,Male,,16
16.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007824501527,Firm Survival in the Netherlands,February 2000,David B. Audretsch,Patrick Houweling,A. Roy Thurik,Male,Male,Unknown,Male,,95
16.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007731916317,Buyer Market Power and Innovative Activities,February 2000,Jürgen Peters,,,Male,Unknown,Unknown,Male,,20
16.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007827307510,Industry Update: Airlines,February 2000,James W. Brock,,,Male,Unknown,Unknown,Male,,7
16.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007783900387,The Positive Effect of Industrial District on the Export Performance of Italian Firms,February 2000,Leonardo Becchetti,Stefania P. S. Rossi,,Male,Female,Unknown,Mix,,
16.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007864132477,"Capacity Utilisation and Excess Capacity: Theory, Evidence, and Policy",February 2000,Ciaran Driver,,,Male,Unknown,Unknown,Male,,16
16.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007782616347,The Dominant Firm Model Revisited,February 2000,Robert Cherry,,,Male,Unknown,Unknown,Male,,2
16.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1017257713741,Call for Papers,February 2000,,,,Unknown,Unknown,Unknown,Unknown,,
16.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007816904229,Foreword,March 2000,William S. Comanor,,,Male,Unknown,Unknown,Male,,2
16.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007888810687,General Editor's Introduction,March 2000,William G. Shepherd,,,Male,Unknown,Unknown,Male,,1
16.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007875328337,The Meaning of ``Agreement'' under the Sherman Act: Thoughts from the ``Facilitating Practices'' Experience,March 2000,George A. Hay,,,Male,Unknown,Unknown,Male,,13
16.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007860329245,Present at the Beginning of a New Era for Antitrust: Reflections on 1982–1983,March 2000,Lawrence J. White,,,Male,Unknown,Unknown,Male,,11
16.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007864431971,Bank Mergers and the 1992 Merger Guidelines: The BankAmerica/Security Pacific Transaction,March 2000,Janusz A. Ordover,Margaret E. Guerin-Calvert,,Male,Female,Unknown,Mix,,
16.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007876801020,"Exclusive Dealing, Preferential Dealing, and Dynamic Efficiency",March 2000,Richard J. Gilbert,,,Male,Unknown,Unknown,Male,,6
16.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007885001929,Potential Competition: The Bell Atlantic/NYNEX Merger,March 2000,Andrew S. Joskow,,,Male,Unknown,Unknown,Male,,1
16.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007889118767,The Primestar Acquisition of the News Corp./MCI Direct Broadcast Satellite Assets,March 2000,Daniel L. Rubinfeld,,,Male,Unknown,Unknown,Male,,5
16.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007841203746,Market Delineation under the Merger Guidelines: Monopoly Cases and Alternative Approaches,March 2000,Gregory J. Werden,,,Male,Unknown,Unknown,Male,,15
16.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007883428434,"Discussant Comments on Papers by Andrew Joskow, Daniel Rubinfeld, and Janusz Ordover and Margaret Guerin-Calvert",March 2000,Marius Schwartz,,,Male,Unknown,Unknown,Male,,
16.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007817706987,The Aggregate Relation between Profits and Concentration is Consistent with Cournot Behavior,May 2000,Micha Gisser,Raymond D. Sauer,,,Male,Unknown,Mix,,
16.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007878024734,"Market Structure and Profits, Market Power and Cournot: A Comment",May 2000,William G. Shepherd,,,Male,Unknown,Unknown,Male,,1
16.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007884704252,"Regulation, Open-Access Transportation, and Productive Efficiency",May 2000,Gerald Granderson,,,Male,Unknown,Unknown,Male,,10
16.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007868317456,Fifty Years of U.K. Competition Policy,May 2000,Michael Utton,,,Male,Unknown,Unknown,Male,,2
16.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007805424725,"Do Large, Diversified Banking Organizations Have Competitive Advantages?",May 2000,Steven J. Pilloff,Stephen A. Rhoades,,Male,Male,Unknown,Male,,10
16.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007853307887,Dominance in Hong Kong's Gas Industry,May 2000,Pun-Lee Lam,,,Unknown,Unknown,Unknown,Unknown,,
16.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007718213621,Correlation Tests for Competitive and Cournot Equilibria,May 2000,Sherrill Shaffer,,,,Unknown,Unknown,Mix,,
16.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007806713840,Paths of Innovation: Technological Change in 20th Century America. David Mowery and Nathan Rosenberg.,May 2000,Peter J. Alexander,,,Male,Unknown,Unknown,Male,,
16.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007852020644,Letting Go: Deregulating the Process of Deregulation. Alfred E. Kahn.,May 2000,Kenneth G. Elzinga,,,Male,Unknown,Unknown,Male,,
16.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007800121100,The Impact of High Tech Production Techniques on Productivity and Profitability in Selected U.S. Manufacturing Industries,June 2000,Louis H. Amato,Christie H. Amato,,Male,,Unknown,Mix,,
16.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007845023817,The Political Economy of Price Cap Regulation,June 2000,Dale E. Lehman,Dennis L. Weisman,,,Male,Unknown,Mix,,
16.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007840809257,Retail Commercial Banking: An Update on a Period of Extraordinary Change,June 2000,Stephen A. Rhoades,,,Male,Unknown,Unknown,Male,,7
16.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007888821999,An Empirical Analysis of Global Airline Alliances: Cases in North Atlantic Markets,June 2000,Jong-Hun Park,Anming Zhang,,Unknown,Unknown,Unknown,Unknown,,
16.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007811001052,"R & D, Foreign Direct Investment and Technology Sourcing?",June 2000,Catherine Y. Co,,,Female,Unknown,Unknown,Female,,11
16.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007876503344,Double Marginalization and Privatization in Liquor Retailing,June 2000,Douglas S. West,,,Male,Unknown,Unknown,Male,,11
16.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007857421244,"Market Dominance: How Firms Gain, Hold, or Lose It and the Impact on Economic Performance David I. Rosenbaum, editor.",June 2000,Douglas F. Greer,,,Male,Unknown,Unknown,Male,,
16.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007861822153,"Designing Competitive Electricity Markets, Hung-po Chao and Hillard G. Huntington, editors.",June 2000,Robert A. Sinclair,,,Male,Unknown,Unknown,Male,,
16.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007878201781,"Money for Nothing: Politicians, Rent Extraction, and Political Extortion. Fred S. McChesney.",June 2000,Russell Pittman,,,Male,Unknown,Unknown,Male,,1
17.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007875415472,The Directions for Technological Change: Alternative Economic Majorities and Opportunity Costs,August 2000,John T. Scott,,,Male,Unknown,Unknown,Male,,12
17.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007875302869,Market Share and Price Setting Behavior for Private Labels and National Brands,August 2000,Ronald W. Cotterill,William P. Putsis Jr.,,Male,Male,Unknown,Male,,76
17.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007870816171,Increased Buyer Concentration and Its Effects on Profitability in the Manufacturing Sector,August 2000,Trish Kelly,Martin L. Gosman,,Female,Male,Unknown,Mix,,
17.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007826230122,Electricity: Changes and Issues,August 2000,Harry M. Trebing,,,Male,Unknown,Unknown,Male,,2
17.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007865923061,"Department of Justice Antitrust Enforcement, 1955—1997: An Empirical Study",August 2000,Joseph C. Gallo,Kenneth Dau-Schmidt,Charles J. Parker,Male,Male,Male,Male,,40
17.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007857709649,Vertical Restraints and the Market Power of Large Distributors,September 2000,William S. Comanor,Patrick Rey,,Male,Male,Unknown,Male,,25
17.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007809813284,Reducing Structural Dominance and Entry Barriers in Russian Industry,September 2000,Harry G. Broadman,,,Male,Unknown,Unknown,Male,,26
17.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007860230708,Market Power in the Cheese Industry: Further Evidence,September 2000,Willard F. Mueller,Bruce W. Marion,,Male,Male,Unknown,Male,,6
17.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007894428368,"Partnerships, Profit Sharing, and Quality Competition in the Medical Profession",September 2000,W. David Bradford,Robert E. Martin,,Unknown,Male,Unknown,Male,,9
17.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007850614256,Defining Market Dominance: A Study of Antitrust Decisions on Business Acquisitions in New Zealand,September 2000,Nathan Strong,Alan Bollard,Michael Pickford,Male,Male,Male,Male,,8
17.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007887626165,Theories of Firms' Growth and the Generation of Jobs,November 2000,P. E. Hart,,,Unknown,Unknown,Unknown,Unknown,,
17.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007834210622,"Firms' Growth, Size and Age: A Nonparametric Approach",November 2000,José C. Fariñas,Lourdes Moreno,,Male,Female,Unknown,Mix,,
17.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007898402967,A Time Series Analysis of Private College Closures and Mergers,November 2000,Laurie J. Bates,Rexford E. Santerre,,Female,Unknown,Unknown,Female,,13
17.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007804129800,Cournot Oligopoly Conditions under which Any Horizontal Merger Is Profitable,November 2000,David A. Hennessy,,,Male,Unknown,Unknown,Male,,18
17.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007862922531,Determinants of Hazard Confronting New Entry: Does Financial Structure Matter?,November 2000,Georgios Fotopoulos,Helen Louri,,Male,Female,Unknown,Mix,,
17.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007883408418,United Shoe Machineryand the Antitrust Significance of “Free” Service,November 2000,Jill Boylston Herndon,,,Female,Unknown,Unknown,Female,,3
17.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007883519708,EU Commission versus Volkswagen: New Evidence on Price Differentiation in the European Car Market,November 2000,Matthias G. Lutz,,,Male,Unknown,Unknown,Male,,12
17.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007879516381,Great School Milk Conspiracies Revisited,November 2000,Frank A. Scott Jr.,,,Male,Unknown,Unknown,Male,,8
17.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007863007832,Great School Milk Conspiracies Revisited: Rejoinder,November 2000,Robert F. Lanzillotti,,,Male,Unknown,Unknown,Male,,3
17.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1017312924837,"Sessions Planned for the Industrial Organization Society at the ASSA Meetings, at New Orleans, January 5–7, 2001",November 2000,,,,Unknown,Unknown,Unknown,Unknown,,
17.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007864315687,The Determinants of R & D Expenditures: A Study of the Canadian Biotechnology Industry,December 2000,Douglas J. Cumming,Jeffrey G. MacIntosh,,Male,Male,Unknown,Male,,31
17.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007898402413,Do Economic Journals Obey Economic Prescriptions?,December 2000,Craig Freeman,,,Male,Unknown,Unknown,Male,,6
17.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007846400596,The Impact of Product Market Competition on Employment Determination in Unionised and Non-Unionised Firms: Firm Level Evidence for the U.K.,December 2000,Jozef Konings,Patrick Paul Walsh,,Male,Male,Unknown,Male,,2
17.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007813411983,Switching Costs in Vertically Related Markets,December 2000,Tommaso M. Valletti,,,Male,Unknown,Unknown,Male,,6
17.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007843812053,Corporate Political Activities and Oligopoly Welfare Loss,December 2000,Sanjib Bhuyan,,,Unknown,Unknown,Unknown,Unknown,,
17.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007894216526,The Influence of Credit Union and Savings and Loan Competition on Bank Deposit Rates in Idaho and Montana,December 2000,Robert J. Tokle,Joanne G. Tokle,,Male,Female,Unknown,Mix,,
17.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007825831547,Why Do Established Firms Enter Some Industries and Exit Others? Empirical Evidence on Italian Business Groups,December 2000,Alessandro Sembenelli,Davide Vannoni,,Male,Male,Unknown,Male,,12
17.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007890132456,Measuring the Economic Rate of Return on Assets,December 2000,J. K. Kapler,,,Unknown,Unknown,Unknown,Unknown,,
17.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007820616596,A Note on Elasticity and Price Dispersions in the Music Recording Industry,December 2000,Franklin G. Mixon Jr.,Rand W. Ressler,,Male,Female,Unknown,Mix,,
17.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007873324913,Book Review,December 2000,Donald L Alexander,,,Male,Unknown,Unknown,Male,,
18.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1026553610558,Preface – Forensic Economics in Action: The Lysine Cartel,February 2001,John M. Connor,,,Male,Unknown,Unknown,Male,,3
18.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1026513927396,“Our Customers Are Our Enemies”: The Lysine Cartel of 1992–1995,February 2001,John M. Connor,,,Male,Unknown,Unknown,Male,,47
18.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1026565911466,Lysine and Price Fixing: How Long? How Severe?,February 2001,Lawrence J. White,,,Male,Unknown,Unknown,Male,,27
18.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1026518028305,Indirect Damages from Price Fixing: The Alabama Lysine Case,February 2001,C. Robert Taylor,,,Unknown,Unknown,Unknown,Unknown,,
18.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1026570012375,Beyond Illinois Brick: The Law and Economics of Cost Pass-Through in the ADM Price Fixing Case,February 2001,Ronald Cotterill,Leonard Egan,William Buckhold,Male,Male,Male,Male,,8
18.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1026597323762,Price-Performance Competition and the Merger Guidelines,February 2001,Raymond S. Hartman,,,Male,Unknown,Unknown,Male,,
18.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1026485426095,R&D Cooperation in a Transaction Cost Perspective,February 2001,Leon A. G. Oerlemans,Marius T. H. Meeus,,Male,Male,Unknown,Male,,21
18.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1026560322853,Examining Industry Effects for Truck Drivers,February 2001,Kristen Monaco,,,Female,Unknown,Unknown,Female,,3
18.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1026545306923,A Law of Large Numbers: Bidding and Compulsory Competitive Tendering for Refuse Collection Contracts,February 2001,AndréS GóMez-Lobo,Stefan Szymanski,,Unknown,Male,Unknown,Male,,47
18.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1026549424670,Profitability and Media Advertising in Greek Food Manufacturing Industries,February 2001,Ourania Notta,Kostas Oustapassidis,,Female,Male,Unknown,Mix,,
18.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1026522129213,NAFTA as a Means of Raising Rivals' Costs: A Comment,February 2001,W. Charles Sawyer,,,Unknown,Unknown,Unknown,Unknown,,
18.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1026741828693,"Industry Structure and Pricing. The New Rivalry in Infrastructure, Mark A. Jamison.",February 2001,Rajiv Sharma,,,Male,Unknown,Unknown,Male,,
18.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1026785027784,"The Theory of Innovation, Jon Sundbo.",February 2001,Jim Love,,,Male,Unknown,Unknown,Male,,
18.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007801608741,The Welfare Effect of Advertising Restrictions in the U.S. Cigarette Industry,March 2001,Stephen J. Farr,Carol Horton Tremblay,Victor J. Tremblay,Male,,Male,Mix,,
18.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007805725579,The Effects of ATM Surcharges on Small Banking Organizations,March 2001,Robin A. Prager,,,,Unknown,Unknown,Mix,,
18.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007823231402,Regulation and Cost Inefficiency,March 2001,Van Kolpin,,,,Unknown,Unknown,Mix,,
18.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007853922900,Firms' Cost Functions: A Reconstruction,March 2001,Richard A. Miller,,,Male,Unknown,Unknown,Male,,9
18.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007827532310,Allocating Control over Firms: Stock Markets versus Membership Markets,March 2001,Gregory K. Dow,,,Male,Unknown,Unknown,Male,,22
18.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007839802268,Economies of Scale and Scope in Australian Telecommunications,March 2001,Harry Bloch,Gary Madden,Scott J. Savage,Male,Male,Male,Male,,28
18.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007831600451,U.S. Financial Services Consolidation: The Case of Corporate Credit Unions,March 2001,W. Scott Frame,Tim J. Coelli,,Unknown,Male,Unknown,Male,,32
18.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007883617289,"Contributions in Industrial Organization, by Linguistic Groups, in Selected Journals",March 2001,Jean Mirucki,,,Male,Unknown,Unknown,Male,,2
18.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007859017076,Microsoft's Pricing of Windows and the Economics of Derived Demand Monopoly,May 2001,Gregory J. Werden,,,Male,Unknown,Unknown,Male,,10
18.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007851001146,A Monopolist Would Still Charge More for Windows: A Comment on Werden,May 2001,Bernard Reddy,David Evans,Richard Schmalensee,Male,Male,Male,Male,,7
18.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007803117984,"Microsoft's Pricing of Windows: A Reply to Reddy, Evans, Nichols, and Schmalensee",May 2001,Gregory J. Werden,,,Male,Unknown,Unknown,Male,,3
18.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007855102055,A Monopolist Would Still Charge More for Windows: A Comment on Werden's Reply,May 2001,Bernard Reddy,David Evans,Richard Schmalensee,Male,Male,Male,Male,,1
18.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007862225626,The Costs and Benefits of Long-Distance Entry: Regulation and Non-Price Discrimination,May 2001,Dennis L. Weisman,Michael A. Williams,,Male,Male,Unknown,Male,,5
18.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007822509696,"Productivity Change, Technical Progress, and Efficiency Improvement in Telecommunications",May 2001,Noel D. Uri,,,Male,Unknown,Unknown,Male,,18
18.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007888323241,New Trends in U.S. Industrial Concentration,May 2001,Frederic L. Pryor,,,Male,Unknown,Unknown,Male,,48
18.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007830515972,The Gradual Response of Market Power to Mergers in the U.S. Steel Industry,May 2001,Craig A. Gallet,,,Male,Unknown,Unknown,Male,,6
18.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007887718198,Price Effects of Across-State Regulation of U.S. Electric Utilities,May 2001,David W. Savitski,,,Male,Unknown,Unknown,Male,,
18.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007810106970,Did May Company's Acquisition of Associated Dry Goods Corporation Reduce Competition? An Event Study Analysis,June 2001,John David Simpsom,,,Male,Unknown,Unknown,Male,,7
18.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007874526535,Inward Investment and Host Country Market Structure: The Case of the U.K.,June 2001,Nigel Driffield,,,Male,Unknown,Unknown,Male,,8
18.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007835701360,Strategic Responses to Regulatory Policies: What Lessons Can Be Learned from the U.K. Contract Gas Market?,June 2001,Huw Dixon,Joshy Easaw,,Male,Unknown,Unknown,Male,,3
18.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007826627443,The Size and Frequency of Price Changes: Evidence from Grocery Stores,June 2001,Elizabeth T. Powers,Nicholas J. Powers,,Female,Male,Unknown,Mix,,
18.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007819604245,A Cointegration Analysis of Advertising and Sales Data,June 2001,Caroline Elliott,,,Female,Unknown,Unknown,Female,,19
18.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1007849805153,Market Leadership Volatility in Japanese Industries,June 2001,Noriyuki Doi,,,Male,Unknown,Unknown,Male,,5
19.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1011182120124,Editor's Introduction: Symposium on Free-Market Competitive Goals and Antitrust Policies,August 2001,W. G. Shepherd,,,Unknown,Unknown,Unknown,Unknown,,
19.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1011152105045,"Markets, Morals, or Wealth? Delusions of a Standardized Antitrust Value",August 2001,William J. Curran III,,,Male,Unknown,Unknown,Male,,3
19.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1011156521884,Economists as a Human Herd,August 2001,Donald C. Wellington,,,Male,Unknown,Unknown,Male,,
19.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1011108605954,Delusions Regarding the Proper Role of Markets and Antitrust Policy,August 2001,Dennis C. Mueller,,,Male,Unknown,Unknown,Male,,2
19.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1011160622792,Is Competition Such a Good Thing? Static Efficiency versus Dynamic Efficiency,August 2001,Mark Blaug,,,Male,Unknown,Unknown,Male,,39
19.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1011193429134,The Decline of Antitrust Enforcement,August 2001,Sam Peltzman,,,,Unknown,Unknown,Mix,,
19.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1011199821043,Automobiles: The Old Economy Collides with the New,August 2001,John E. Kwoka Jr.,,,Male,Unknown,Unknown,Male,,9
19.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1011172505113,The Magnesium Industry in Transition,August 2001,Marvin B. Lieberman,,,Male,Unknown,Unknown,Male,,7
19.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1011112032430,The U.S. Motion Pictures Industry: An Empirical Approach,August 2001,E. RayY Canterbery,A. Marvasti,,Unknown,Unknown,Unknown,Unknown,,
19.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1011148618698,Pricing over the Cycle,August 2001,Harry Bloch,Michael Olive,,Male,Male,Unknown,Male,,14
19.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1011117710166,The Impact of Foreign Competition and New Technologies on the Demand for Heterogeneous Labor,August 2001,Ulrich Kaiser,,,Male,Unknown,Unknown,Male,,12
19.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1011124621952,"Sources of Industrial Leadership: Studies of Seven Industries, David C. Mowery and Richard R. Nelson, editors.",August 2001,Rochelle Ruffer,,,Female,Unknown,Unknown,Female,,1
19.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1011111329176,How Much Will Consumers Pay? A Hedonic Analysis of the Cable Television Industry,September 2001,Diane Bruce Anstine,,,Female,Unknown,Unknown,Female,,19
19.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1011123915064,The Effects of Rate Regulation on Mean Returns and Non-Diversifiable Risk: The Case of Cable Television,September 2001,Arthur Havenner,Thomas W. Hazlett,Zhiqiang Leng,Male,Male,Unknown,Male,,7
19.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1011140400951,Economies and Diseconomies: Estimating Electricity Cost Functions,September 2001,Michael T. Maloney,,,Male,Unknown,Unknown,Male,,25
19.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1011144517789,Innovation and Merger Decisions in the Pharmaceutical Industry,September 2001,Eleanor J. Morgan,,,Female,Unknown,Unknown,Female,,17
19.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1011196501860,Entry through Acquisition: Determinants of Multinational Firm Choices,September 2001,Helen Louri,,,Female,Unknown,Unknown,Female,,6
19.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1011100703677,One Monopoly Is Better Than Two: Antitrust Policy and Microsoft,September 2001,Micha Gisser,Mark S. Allen,,,Male,Unknown,Mix,,
19.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1011184100043,Entry under Asymmetric Regulation,September 2001,Jaison R Abel,Michael E. Clements,,Unknown,Male,Unknown,Male,,17
19.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1011146910605,"Creating a Public Good to Fight Monopolization: The Formation of Broadcast Music, Inc.",September 2001,Andrew N. Kleit,,,Male,Unknown,Unknown,Male,,2
19.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1011158305665,"The Economics of Sports, William S. Kern, editor.",September 2001,Lawrence Hadley,,,Male,Unknown,Unknown,Male,,
19.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1011896025338,"Editor's Announcement: Advent of a New General Editor: John E. Kwoka, Jr.",November 2001,William G. Shephard,,,Male,Unknown,Unknown,Male,,1
19.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1011828216881,Monopoly Rents and Price Fixing in Betting Markets,November 2001,David Paton,Leighton Vaughan Williams,,Male,Male,Unknown,Male,,4
19.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1011892421424,The Effects of Acuity and Utilization on Nursing Home Costs,November 2001,David I. Rosenbaum,Charles F. Lamphear,Ken Rebeck,Male,Male,Male,Male,,1
19.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1011813009129,The Effect of Industry Concentration on Free Riding,November 2001,Wen Mao,Peter Zaleski,,,Male,Unknown,Mix,,
19.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1011881516500,The Determinants of Technology Adoption in Italian Manufacturing Industries,November 2001,Eleonora Bartoloni,Maurizio Baussola,,Female,Male,Unknown,Mix,,
19.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1011851917409,After The Fall: Stock Price Movements and the Deterrent Effect of Antitrust Enforcement,November 2001,John S. Thompson,David L. Kaserman,,Male,Male,Unknown,Male,,20
19.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1011856020135,"Product Innovation, Process Innovation, and Size",November 2001,Michael Fritsch,Monika Meschede,,Male,Female,Unknown,Mix,,
19.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1011868404205,Entry and the Number of Firms in the Swedish Pharmaceuticals Market,November 2001,Nikas Rudholm,,,Unknown,Unknown,Unknown,Unknown,,
19.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1011820525065,Measuring Market Power in the U.S. Aluminum Industry: A Residual Demand Approach,November 2001,Sheng-Peng Yang,,,Unknown,Unknown,Unknown,Unknown,,
19.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1017484009409,"Sessions Planned for the Industrial Organization Society at the ASSA Meetings, at Atlanta, January 4–6, 2002",November 2001,,,,Unknown,Unknown,Unknown,Unknown,,
19.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1012552226882,Do American and European Industrial Organization Economists Differ?,December 2001,Karl Aiginger,Mark McCabe,Christoph Weiss,Male,Male,Male,Male,,20
19.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1012508411861,The Effects of Global Competition on Total Factor Productivity in U.S. Manufacturing,December 2001,Louis H. Amato,Christie H. Amato,,Male,,Unknown,Mix,,
19.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1012504310953,The Impact of Generic Drug Competition on Brand Name Market Shares – Evidence from Micro Data,December 2001,Thomas Aronsson,Mats A. Bergman,Niklas Rudholm,Male,Male,Male,Male,,74
19.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1012556327791,Does Local Competition Impact Interest Rates Charged on Small Business Loans? Empirical Evidence from Canada,December 2001,Ted Mallett,Anindya Sen,,Male,Unknown,Unknown,Male,,8
19.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1012568509136,The Effect of Bid Rigging on Prices: A Study of the Highway Construction Industry,December 2001,Srabana Gupta,,,Unknown,Unknown,Unknown,Unknown,,
19.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1012548125974,Staples and Office Depot: An Event-Probability Case Study,December 2001,Frederick R. Warren-Boulton,Serdar Dalkir,,Male,Male,Unknown,Male,,12
19.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1012500210044,Efficiency and Firm Ownership: Some New Evidence,December 2001,Zhiqiang Liu,,,Unknown,Unknown,Unknown,Unknown,,
19.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1012560412155,"Privatization, Restructuring, and Regulation of Network Utilities, David M. Newbery.",December 2001,Dale E Lehman,,,,Unknown,Unknown,Mix,,
19.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1012506831720,"THE BANK MERGER WAVE: The Economic Causes and Social Consequences of Financial Consolidation, Gary A. Dymski. Armonk, NY: M.E. Sharpe",December 2001,Edward Nissan,,,Male,Unknown,Unknown,Male,,1
19.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1012571215790,"Productivity, Innovation and Economic Performance, Ray Barrell, Geoff Mason, and May O'Mahoney, editors.",December 2001,Louis H. Amato,,,Male,Unknown,Unknown,Male,,
19.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1017497012083,Table of Contents Volume 19 2001,December 2001,,,,Unknown,Unknown,Unknown,Unknown,,
19.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1017345429729,Instructions for Authors,December 2001,,,,Unknown,Unknown,Unknown,Unknown,,
20.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1013309928700,New Firms' Survival and Market Turbulence: New Evidence from Spain,February 2002,Agustí Segarra,Maria Callejón,,Unknown,Female,Unknown,Female,,99
20.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1013312512770,Multinational Companies and Entrant Start-up Size: Evidence from Quantile Regressions,February 2002,Holger Görg,Eric Strobl,,Male,Male,Unknown,Male,,23
20.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1013364513064,"Search Costs, Lags and Prices at the Pump",February 2002,Ronald N. Johnson,,,Male,Unknown,Unknown,Male,,96
20.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1013315132628,Rolling Seas in Liner Shipping,February 2002,James D. Reitzes,Kelli L. Sheran,,Male,Female,Unknown,Mix,,
20.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1013310929902,Impact of Vertical Mergers on Industry Profitability: An Empirical Evaluation,February 2002,Sanjib Bhuyan,,,Unknown,Unknown,Unknown,Unknown,,
20.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1013362913973,Structure and Profitability in Banking Markets,February 2002,Steven J. Pilloff,Stephen A. Rhoades,,Male,Male,Unknown,Male,,49
20.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1017474105913,Instructions For Authors,February 2002,,,,Unknown,Unknown,Unknown,Unknown,,
20.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1013858830811,Credit Unions: Fringe Suppliers or Cournot Competitors?,March 2002,Robert M. Feinberg,,,Male,Unknown,Unknown,Male,,16
20.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1013867114881,Market Power and/or Efficiency: A Structural Approach,March 2002,Rigoberto A. Lopez,Azzeddine M. Azzam,Carmen Lirón-España,Male,Unknown,Female,Mix,,
20.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1013828420609,Barriers to Mobility in Europe's Civil Aviation Markets: Theory and New Evidence,March 2002,Christos N. Pitelis,Mirko C. A. Schnell,,Male,Male,Unknown,Male,,9
20.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1013819218792,Peer-to-Peer File Sharing: The Case of the Music Recording Industry,March 2002,Peter J. Alexander,,,Male,Unknown,Unknown,Male,,43
20.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1013836604679,Cost Efficiency and Product Mix Clusters across the Spanish Banking Industry,March 2002,Emili Tortosa-Ausina,,,Female,Unknown,Unknown,Female,,8
20.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1013843228994,"News from the Monopoly Front: Changes in Industrial Concentration, 1992–1997",March 2002,Frederic L. Pryor,,,Male,Unknown,Unknown,Male,,12
20.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1013888621518,"Group Profit, Market Share and Efficiency: Evidence from Australian Manufacturing",March 2002,Mita Bhattacharya,,,Female,Unknown,Unknown,Female,,
20.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1017465827523,Industrial Organization Society's Fourth Annual Awards: Distinguished Fellow Award To. William G. Shepherd,May 2002,,,,Unknown,Unknown,Unknown,Unknown,,
20.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1017490511594,Industrial Organization Society's Fourth Annual Awards: Younger Scholar Best Paper Award To Jozef Konings and Patrick Paul Walsh,May 2002,,,,Unknown,Unknown,Unknown,Unknown,,
20.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1015069023770,Generic Advertising of Intermediate Goods: Theory and Evidence on Free Riding,May 2002,Craig A. Depken II,David R. Kamerschen,Arthur Snow,Male,Male,Male,Male,,5
20.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1015091407841,Conduct in a Banking Monopoly,May 2002,Sherrill Shaffer,,,,Unknown,Unknown,Mix,,
20.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1015043524679,Optimal Size in the Waste Collection Sector,May 2002,Barbara Antonioli,Massimo Filippini,,Female,Male,Unknown,Mix,,
20.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1015095508749,Advertising with Subjective Horizontal and Vertical Product Differentiation,May 2002,Victor J. Tremblay,Stephen Polasky,,Male,Male,Unknown,Male,,40
20.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1015047625588,Debt and Firms' Relationships: The Italian Evidence,May 2002,Claudio A. G. Piga,,,Male,Unknown,Unknown,Male,,18
20.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1015099709658,Price Dispersion and Price Discrimination: Empirical Evidence from a Spot Market for Water,May 2002,David W. Yoskowitz,,,Male,Unknown,Unknown,Male,,13
20.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1015603909368,Sunk Cost and Entry,June 2002,Stephen Martin,,,Male,Unknown,Unknown,Male,,2
20.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1015677626496,Effects of R & D Spillovers on the Profitability of Firms,June 2002,Petr Hanel,Alain St-Pierre,,Male,Male,Unknown,Male,,53
20.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1015653227386,Intermedia Substitutability and Market Demand by National Advertisers,June 2002,Alvin J. Silk,Lisa R. Klein,Ernst R. Berndt,Male,Female,Male,Mix,,
20.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1015692910277,Predicting Household Switching Behavior and Switching Costs at Depository Institutions,June 2002,Elizabeth K. Kiser,,,Female,Unknown,Unknown,Female,,70
20.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1015649128024,Substitution between Mobile and Fixed Telephones in Korea,June 2002,Nakil Sung,Yong-Hun Lee,,Unknown,Unknown,Unknown,Unknown,,
20.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1015697027115,Predatory Pricing and the Speed of Antitrust Enforcement,June 2002,Andrew Eckert,,,Male,Unknown,Unknown,Male,,5
20.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1017460614091,Table of Contents Volume 20 2002,June 2002,,,,Unknown,Unknown,Unknown,Unknown,,
21.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1016078702735,Letter from the Editor,August 2002,,,,Unknown,Unknown,Unknown,Unknown,,
21.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1016014320951,Vertical Industry Linkages: Sources of Productivity Gains and Cumulative Causation?,August 2002,Frode Steen,,,Male,Unknown,Unknown,Male,,3
21.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1016010220042,Taxation by Regulation and Regulation by Taxation: The Case of Local Cable TV Regulation,August 2002,Yasuji Otsuka,Bradley M. Braun,,Male,Male,Unknown,Male,,2
21.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1016045011186,Competitive Balance and Market Size in Major League Baseball: A Response to Baseball's Blue Ribbon Panel,August 2002,Martin B. Schmidt,David J. Berri,,Male,Male,Unknown,Male,,20
21.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1016001219134,How Much Do Strategic Groups Matter?,August 2002,Eduardo González-Fidalgo,Juan Ventura-Victoria,,Male,Male,Unknown,Male,,21
21.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1016018505021,Bid-Rigging in Auctions for Korean Public-Works Contracts and Potential Damage,August 2002,In Kwon Lee,Kyungdong Hahn,,,Unknown,Unknown,Mix,,
21.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1016020026207,"Advertising, Its Determinants, and Market Structure",August 2002,Chang-Yang Lee,,,Unknown,Unknown,Unknown,Unknown,,
21.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1016070506839,Structure–Conduct–Performance: A Comment on Blaug's ``Is Competition Such a Good Thing? Static Efficiency versus Dynamic Efficiency'',August 2002,John Howard Brown,,,Male,Unknown,Unknown,Male,,4
21.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1019615008901,Editorial Introduction: Market Power in East Asian Economies,September 2002,David K. Round,,,Male,Unknown,Unknown,Male,,2
21.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1019617325739,The Treatment of Market Power in Korea,September 2002,Kwangshik Shin,,,Unknown,Unknown,Unknown,Unknown,,
21.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1019669309809,"Market Power in Chinese Taipei: Laws, Policies and Treatments",September 2002,Kung-Chung Liu,Yun-Peng Chu,,Unknown,,Unknown,Mix,,
21.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1019621426648,Competition Policy under Laissez-Faireism: Market Power and its Treatment in Hong Kong,September 2002,Edward K. Y. Chen,Ping Lin,,Male,,Unknown,Mix,,
21.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1019677511627,"Market Power in China: Manifestations, Effects and Legislation",September 2002,Jijian Yang,,,Unknown,Unknown,Unknown,Unknown,,
21.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1019681612535,The New Competition Law in Thailand: Lessons for Institution Building,September 2002,Nipon Poapongsakorn,,,Unknown,Unknown,Unknown,Unknown,,
21.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1019633829374,The Evolution of Competition Policy in Indonesia,September 2002,Mari Pangestu,Haryo Aswicahyono,Dionisius Ardyanto,Female,Unknown,Unknown,Female,,13
21.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1019631100361,Review of Industrial Organization,September 2002,,,,Unknown,Unknown,Unknown,Unknown,,
21.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1020445804113,Measuring the Impact of Regulation: A Study of Canadian Basic Cable Television,November 2002,Stephen M. Law,James F. Nolan,,Male,Male,Unknown,Male,,2
21.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1020452001789,"Privatization, City Residency, and Black-White Earnings Differentials: Evidence from the Public Transit Sector",November 2002,James Peoples Jr.,Wayne K. Talley,,Male,Male,Unknown,Male,,1
21.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1020454902697,"Diversification, Concentration and Economic Performance: Korean Business Groups",November 2002,Jeong-Pyo Choi,Thomas G. Cowing,,Unknown,Male,Unknown,Male,,18
21.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1020459120444,Exit and Survival in a Concentrating Industry: The Case of Daily Newspapers in the Netherlands,November 2002,H. L. Van Kranenburg,F. C. Palm,G. A. Pfann,Unknown,Unknown,Unknown,Unknown,,
21.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1020415304514,Price Dispersion on the Internet: Good Firms and Bad Firms,November 2002,Kathy Baylis,Jeffrey M. Perloff,,Female,Male,Unknown,Mix,,
21.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1020467305423,"Global Price Fixing: Our Customers are the Enemy, John M. Connor.",November 2002,Douglas F. Greer,,,Male,Unknown,Unknown,Male,,
21.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1020471422261,"Pricing in Competitive Electricity Markets, A. Faruqui and K. Eakin, editors. Forward by J. Robert Malko.",November 2002,David W. Savitski,,,Male,Unknown,Unknown,Male,,1
21.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1021199718807,Introduction: Antitrust and Regulatory Update,December 2002,Lawrence J. White,,,Male,Unknown,Unknown,Male,,1
21.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1021118714514,Economic Issues at the Federal Communications Commission,December 2002,Evan Kwerel,Johathan Levy,John Williams,Male,Unknown,Male,Male,,5
21.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1021118430444,Current Economic Issues at the FTC,December 2002,David T. Scheffman,Mary T. Coleman,,Male,,Unknown,Mix,,
21.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1021139400151,Recent Antitrust Enforcement Actions by the U.S. Department of Justice: A Selective Survey of Economic Issues,December 2002,Michael L. Katz,,,Male,Unknown,Unknown,Male,,11
21.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1021122815423,The Effect of the Repsol-YPF Merger on the Argentine Gasoline Market,December 2002,Germán Coloma,,,Male,Unknown,Unknown,Male,,14
21.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1021170731353,Technological Opportunity and Economies of Scale in Research Productivity: A Study on Three Global Industries,December 2002,Michael K. Fung,,,Male,Unknown,Unknown,Male,,10
21.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1021157405430,Table of Contents Volume 21 2002,December 2002,,,,Unknown,Unknown,Unknown,Unknown,,
22.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1022184014407,"Advertising Bans, Monopoly, and Alcohol Demand: Testing for Substitution Effects using State Panel Data",February 2003,Jon P. Nelson,,,Male,Unknown,Unknown,Male,,51
22.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1022199902266,Asymmetric Network Interconnection,February 2003,Michael Carter,Julian Wright,,Male,Male,Unknown,Male,,82
22.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1022191701357,Is Mobile Telephony a Natural Oligopoly?,February 2003,Tommaso M. Valletti,,,Male,Unknown,Unknown,Male,,28
22.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1022180317898,Does Foreign Direct Investment Crowd Out Domestic Entrepreneurship?,February 2003,Koen De Backer,Leo Sleuwaegen,,Male,Male,Unknown,Male,,207
22.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1022106432261,"The Japanese Pharmaceutical Industry, L. G. Thomas, III.",February 2003,Larry L. Duetsch,,,Male,Unknown,Unknown,Male,,
22.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1022149132308,"The Telecommunications Act of 1996: The ``Costs'' of Managed Competition, Dale E. Lehman and Dennis Weisman, editors.",February 2003,Noel D. Uri,,,Male,Unknown,Unknown,Male,,
22.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1022126916331,"Risk and Return in Transportation and Other U.S. and Global Industries, Manolis G. Kavussanos and Stelios N. Marcoulis.",February 2003,Kristen A. Monaco,,,Female,Unknown,Unknown,Female,,
22.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1022155923660,Review of Industrial Organization,February 2003,,,,Unknown,Unknown,Unknown,Unknown,,
22.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1022903018196,"Industrial Concentration, Output, and Trade: An Empirical Exploration",March 2003,Aidan Hollis,,,Male,Unknown,Unknown,Male,,12
22.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1022920018376,Do Newspaper JOAs Charge Monopoly Advertising Rates?,March 2003,Charles Romeo,Russell Pittman,Norman Familant,Male,Male,Male,Male,,4
22.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1022965830769,Firm Density and Industry R & D Intensity: Theory and Evidence,March 2003,Chang-Yang Lee,,,Unknown,Unknown,Unknown,Unknown,,
22.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1022905102446,Is R & D Financially Constrained? Theory and Evidence from Irish Manufacturing,March 2003,Spiros Bougheas,Holger Görg,Eric Strobl,Male,Male,Male,Male,,70
22.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1022957119284,"The Economics of Football, Stephen Dobson and John Goddard.",March 2003,Rodney Fort,,,Male,Unknown,Unknown,Male,,
22.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1022909203355,"The Impact of Rate-of-Return Regulation on Technological Innovation, Mark W. Frank.",March 2003,Sheng-Ping Yang,,,,Unknown,Unknown,Mix,,
22.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1023607223501,Incentives for Anticompetitive Behavior by Public Enterprises,May 2003,David E. M. Sappington,J. Gregory Sidak,,Male,Unknown,Unknown,Male,,37
22.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1023622407571,Foreign Ownership and Productivity in the United Kingdom Estimates for U.K. Manufacturing Using the ARD,May 2003,Richard Harris,Catherine Robinson,,Male,Female,Unknown,Mix,,
22.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1023674408480,Entry and Exit in a Transition Economy: The Case of Poland,May 2003,Barbara M. Roberts,Steve Thompson,,Female,Male,Unknown,Mix,,
22.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1023663917181,Acknowledgement,May 2003,,,,Unknown,Unknown,Unknown,Unknown,,
22.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1025517327148,Industrial Organization Society's Fifth Annual Awards: Best Paper / Younger Scholar Award,June 2003,,,,Unknown,Unknown,Unknown,Unknown,,
22.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1025534311218,Industrial Organization Society's Fifth Annual Awards: Distinguished Fellow Award,June 2003,,,,Unknown,Unknown,Unknown,Unknown,,
22.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1025540315907,Editor's Note,June 2003,,,,Unknown,Unknown,Unknown,Unknown,,
22.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1025560417239,Firm Responses to Income Inequality and the Cost of Time,June 2003,B. Peter Pashigian,Sam Peltzman,Jeanne-Mey Sun,Unknown,,Unknown,Mix,,
22.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1025565122721,Competition and Service Quality in the U.S. Airline Industry,June 2003,Michael J. Mazzeo,,,Male,Unknown,Unknown,Male,,206
22.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1025513105882,"Changes in the Effects of Mandatory Rate Regulation On Growth in Hospital Operating Costs, 1980–1996",June 2003,John E. Schneider,,,Male,Unknown,Unknown,Male,,7
22.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1025591800401,An Empirical Analysis of Electricity Regulation on Technical Change in Texas,June 2003,Mark W. Frank,,,Male,Unknown,Unknown,Male,,3
22.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1025582821812,"Alternating Currents: Electricity Markets and Public Policy, Timothy J. Brennan, Karen L. Palmer, and Martinez A. Salvador, editors.",June 2003,David W. Savitski,,,Male,Unknown,Unknown,Male,,
22.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1025513722315,"Buyer Power and Competition in European Food Retailing, Roger Clarke, Stephen Davies, Paul Dobson and Michael Waterson.",June 2003,Bruce W. Marion,,,Male,Unknown,Unknown,Male,,1
22.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/A:1025500831837,Table of Contents Volume 22 2003,June 2003,,,,Unknown,Unknown,Unknown,Unknown,,
23.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/B:REIO.0000005561.07176.30,Foreign Expansion by Italian Manufacturing Firms in the Nineties: an Ordered Probit Analysis,August 2003,Roberto Basile,Anna Giunta,Jeffrey B. Nugent,Male,Female,Male,Mix,,
23.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/B:REIO.0000005560.15486.9d,Diversification Strategies and Corporate Coherence Evidence from Italian Leading Firms,August 2003,Stefano Valvano,Davide Vannoni,,Male,Male,Unknown,Male,,20
23.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/B:REIO.0000005595.35570.1a,Can Quality Certification Lead to Stable Cartels?,August 2003,Stéphan Marette,John M. Crespi,,Male,Male,Unknown,Male,,37
23.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/B:REIO.0000005630.49071.4a,Moral Hazard and the Market for Used Automobiles,August 2003,Wayne R. Dunham,,,Male,Unknown,Unknown,Male,,7
23.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/B:REIO.0000005664.46465.f2,Review of Industrial Organization,August 2003,,,,Unknown,Unknown,Unknown,Unknown,,
23.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/B:REIO.0000006912.49052.cc,Introduction: Antitrust and Regulatory Update,September 2003,Lawrence J. White,,,Male,Unknown,Unknown,Male,,1
23.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/B:REIO.0000006911.97128.d7,Selected Economic Analysis at the Antitrust Division: The Year in Review,September 2003,David S. Sibley,Ken Heyer,,Male,Male,Unknown,Male,,9
23.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/B:REIO.0000006910.18832.0e,Economic Analyses of Mergers at the FTC: The Cruise Ships Mergers Investigation,September 2003,Mary T. Coleman,David W. Meyer,David T. Scheffman,,Male,Male,Mix,,
23.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/B:REIO.0000006909.86620.69,Economic Analysis at the Federal Communications Commission,September 2003,Mark Bykowsky,Jonathan Levy,Simon Wilkie,Male,Male,Male,Male,,1
23.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/B:REIO.0000031364.73476.9d,Introduction to the 2003 International Industrial Organization Conference Special Issue,December 2003,Christopher M. Snyder,,,Male,Unknown,Unknown,Male,,
23.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/B:REIO.0000031370.88761.7d,How Do Capital Markets Influence Product Market Competition?,December 2003,Michael H. Riordan,,,Male,Unknown,Unknown,Male,,7
23.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/B:REIO.0000031365.05276.c1,Common Sense and Simplicity in Empirical Industrial Organization,December 2003,Ariel Pakes,,,Male,Unknown,Unknown,Male,,4
23.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/B:REIO.0000031366.28559.c1,Common Properties and Sectoral Specificities in the Dynamics of U.S. Manufacturing Companies,December 2003,Giulio Bottazzi,Angelo Secchi,,Male,Male,Unknown,Male,,118
23.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/B:REIO.0000031367.79009.9b,Experimental Evidence on Product Adoption in the Presence of Network Externalities,December 2003,Sujoy Chakravarty,,,Unknown,Unknown,Unknown,Unknown,,
23.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/B:REIO.0000031368.93775.0a,An Economic Analysis of Regulated Taxicab Markets,December 2003,Daniel Flores-Guri,,,Male,Unknown,Unknown,Male,,43
23.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/B:REIO.0000031371.03322.9e,Contracts and Quality in the California Winegrape Industry,December 2003,Rachael E. Goodhue,Dale M. Heien,Daniel A. Sumner,Female,,Male,Mix,,
23.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/B:REIO.0000031369.95080.9f,Firm Size and Market Power in Carbonated Soft Drinks,December 2003,Franco Mariuzzo,Patrick Paul Walsh,Ciara Whelan,Male,Male,Female,Mix,,
23.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/B:REIO.0000031372.79077.fc,Adoption of Product and Process Innovations in Differentiated Markets: The Impact of Competition,December 2003,Pia Weiss,,,Female,Unknown,Unknown,Female,,40
23.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/B:REIO.0000031517.79297.30,Table of Contents Volume 23 2003,December 2003,,,,Unknown,Unknown,Unknown,Unknown,,
23.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/B:REIO.0000031518.24559.98,Review of Industrial Organization,December 2003,,,,Unknown,Unknown,Unknown,Unknown,,
24.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/B:REIO.0000031361.27597.7c,Management Control and Innovative Activity,February 2004,Dirk Czarnitzki,Kornelius Kraft,,Male,Male,Unknown,Male,,45
24.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/B:REIO.0000031362.43257.92,Vertical Integration and Efficiency: Ownership in the Swedish Sawmill Industry,February 2004,Jonas Månsson,,,Male,Unknown,Unknown,Male,,9
24.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/B:REIO.0000031373.16715.fd,Prices and Departures in European Domestic Aviation Markets,February 2004,Fredrik Carlsson,,,Male,Unknown,Unknown,Male,,13
24.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/B:REIO.0000031351.80206.cf,Wherein Lies the Benefit of the Second Referee in the NHL?,February 2004,Craig A. Depken II,Dennis P. Wilson,,Male,Male,Unknown,Male,,12
24.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/B:REIO.0000031347.79588.f3,Efficiency and Productivity of China's Thermal Power Generation,February 2004,Pun-Lee Lam,Alice Shiu,,Unknown,Female,Unknown,Female,,53
24.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/B:REIO.0000031464.27439.cf,Acknowledgement,February 2004,,,,Unknown,Unknown,Unknown,Unknown,,
24.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/B:REIO.0000031504.90963.18,Review of Industrial Organization,February 2004,,,,Unknown,Unknown,Unknown,Unknown,,
24.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/B:REIO.0000033488.06102.85,Introduction to RIO Symposium Issue on Store Brands,March 2004,Fiona Scott Morton,,,Female,Unknown,Unknown,Female,,
24.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/B:REIO.0000033351.66025.05,The Nature and Benefits of National Brand/Private Label Competition,March 2004,Robert L. Steiner,,,Male,Unknown,Unknown,Male,,143
24.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/B:REIO.0000033349.67467.b7,Investigating the Cross-Category Effects of Store Brands,March 2004,Serdar Sayman,Jagmohan S. Raju,,Male,Male,Unknown,Male,,36
24.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/B:REIO.0000033353.52208.ba,Does Store Brand Patronage Improve Store Patronage?,March 2004,K. Sudhir,Debabrata Talukdar,,Unknown,Unknown,Unknown,Unknown,,
24.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/B:REIO.0000033350.25229.d6,The Strategic Positioning of Store Brands in Retailer–Manufacturer Negotiations,March 2004,Fiona Scott Morton,Florian Zettelmeyer,,Female,Male,Unknown,Mix,,
24.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/B:REIO.0000033352.19694.4a,Store Brands: Who Buys Them and What Happens to Retail Prices When They Are Introduced?,March 2004,André Bonfrer,Pradeep K. Chintagunta,,Male,,Unknown,Mix,,
24.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/B:REIO.0000038239.87377.d4,Geroski's Stylized Facts and Mobility of Large German Manufacturing Firms,May 2004,Uwe Cantner,Jens J. Krüger,,Male,Male,Unknown,Male,,13
24.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/B:REIO.0000038240.63133.44,Licensing Requirements as a Coordination Mechanism for Entry,May 2004,Sherrill Shaffer,,,,Unknown,Unknown,Mix,,
24.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/B:REIO.0000038247.28065.33,Entry Effects on Cartel Stability and the Joint Executive Committee,May 2004,Helder Vasconcelos,,,Male,Unknown,Unknown,Male,,5
24.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/B:REIO.0000038273.50622.ec,Gibrat's Law: Are the Services Different?,May 2004,D.B. Audretsch,L. Klomp,A.R. Thurik,Unknown,Unknown,Unknown,Unknown,,
24.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/B:REIO.0000038274.05704.99,"Broadcasting, Attendance and the Inefficiency of Cartels",May 2004,David Forrest,Rob Simmons,Stefan Szymanski,Male,Male,Male,Male,,80
24.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/B:REIO.0000037590.02055.de,Table of Contents Volume 24 2004,June 2004,,,,Unknown,Unknown,Unknown,Unknown,,
24.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/B:REIO.0000037535.11644.2c,The Sensitivity of Capital Use to Price in Higher Education,June 2004,Malcolm Getz,John J. Siegfried,,Male,Male,Unknown,Male,,1
24.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/B:REIO.0000037536.04021.b7,"Dynamic Adjustment in the U.S. Higher Education Industry, 1955–1997",June 2004,John E. Kwoka Jr.,Christopher M. Snyder,,Male,Male,Unknown,Male,,3
24.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/B:REIO.0000037537.32935.cd,Symposium on the Industrial Organization of Higher Education,June 2004,John J. Siegfried,,,Male,Unknown,Unknown,Male,,1
24.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/B:REIO.0000037538.48594.2c,Performance Differences in German Higher Education: Empirical Analysis of Strategic Groups,June 2004,Susanne Warning,,,Female,Unknown,Unknown,Female,,90
24.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/B:REIO.0000037539.78539.02,Differentiation Among US Colleges and Universities,June 2004,Gordon C. Winston,,,Male,Unknown,Unknown,Male,,39
25.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/B:REIO.0000040474.83556.54,Regulation and Measuring Cost-Efficiency with Panel Data Models: Application to Electricity Distribution Utilities,August 2004,Mehdi Farsi,Massimo Filippini,,Male,Male,Unknown,Male,,78
25.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/B:REIO.0000040514.22968.e1,The Attributes of a Costly Recall: Evidence from the Automotive Industry,August 2004,Nicholas G. Rupp,,,Male,Unknown,Unknown,Male,,46
25.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/B:REIO.0000040475.20301.e5,On the Relationship between International Outsourcing and Price–Cost Margins in European Industries,August 2004,Hartmut Egger,Peter Egger,,Male,Male,Unknown,Male,,10
25.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/B:REIO.0000040524.32034.04,Pseudo-Generic Products and Barriers to Entry in Pharmaceutical Markets,August 2004,Ying Kong,James R. Seldon,,,Male,Unknown,Mix,,
25.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/B:REIO.0000040627.22633.f1,Editor's Note,August 2004,,,,Unknown,Unknown,Unknown,Unknown,,
25.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1023/B:REIO.0000040548.70602.b5,The Revival of Economics at the FTC in the 1960s,August 2004,Willard F. Mueller,,,Male,Unknown,Unknown,Male,,9
25.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-004-1054-6,Entry in Local Telecommunication Markets,September 2004,Donald L. Alexander,Robert M. Feinberg,,Male,Male,Unknown,Male,,18
25.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-004-1094-y,Pricing with Endogenous Direct Advertising in a Monopoly,September 2004,Lola Esteban,Agustín Gil,José M. Hernández,Female,Male,Male,Mix,,
25.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-004-1928-7,"Knowledge Spillovers, Mergers and Public Policy in Economic Clusters",September 2004,George Norman,Lynne Pepall,,Male,Female,Unknown,Mix,,
25.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-004-3536-y,Learning by Doing and Spillovers: Evidence from Firm-Level Panel Data,September 2004,Salvador Barrios,Eric Strobl,,Male,Male,Unknown,Male,,15
25.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-004-3537-x,"Foreign Direct Investment, Imports and Innovations in the Service Industry",September 2004,Knut Blind,Andre Jungmittag,,Male,Male,Unknown,Male,,56
25.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-004-5397-9,Erratum,September 2004,,,,Unknown,Unknown,Unknown,Unknown,,
25.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-004-3535-z,Vertical Structure and Patent Pools,November 2004,Sung-Hwan Kim,,,Male,Unknown,Unknown,Male,,30
25.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-004-1972-3,The Determinants of Survival of Spanish Manufacturing Firms,November 2004,Silviano Esteve Pérez,Amparo Sanchis Llopis,Juan Alberto Sanchis Llopis,Unknown,Female,Male,Mix,,
25.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-004-3172-6,Estimation of the Effects of New Brands on Incumbents’ Profits and Consumer Welfare: The U.S. Processed Cheese Market Case,November 2004,Donghun Kim,,,Unknown,Unknown,Unknown,Unknown,,
25.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-004-1971-4,Are Interactive TV-Pioneers and Surfers Different Breeds? Broadband Demand and Asymmetric Cross-Price Effects,November 2004,Kjetil Andersson,Kenneth Fjell,Øystein Foros,Male,Male,Male,Male,,1
25.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-004-1970-5,Entry Patterns in the Southwest Airlines Route System,November 2004,Charles Boguslaski,Harumi Ito,Darin Lee,Male,,Female,Mix,,
25.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-004-4852-y,Introduction: Antitrust and Regulatory Update,December 2004,Lawrence J. White,,,Male,Unknown,Unknown,Male,,
25.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-004-4853-x,"Economics Research at the FTC: Information, Retrospectives, and Retailing",December 2004,Luke Froeb,Daniel Hosken,Janis Pappalardo,Male,Male,Female,Mix,,
25.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-004-4854-9,The Year in Review: Economics at the Antitrust Division 2003–2004,December 2004,David S. Sibley,Ken Heyer,,Male,Male,Unknown,Male,,3
25.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-004-4856-7,Economic Analysis at the Federal Communications Commission,December 2004,Evan Kwerel,Jonathan Levy,John Williams,Male,Male,Male,Male,,1
26.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-004-4083-2,Rationalization of Retail Gasoline Station Networks in Canada,February 2005,Andrew Eckert,Douglas S. West,,Male,Male,Unknown,Male,,20
26.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-004-6576-4,Model Exit in a Vertically Differentiated Market: Interfirm Competition versus Intrafirm Cannibalization in the Computer Hard Disk Drive Industry,February 2005,Christopher S. Ruebeck,,,Male,Unknown,Unknown,Male,,
26.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-004-6067-7,Do Different Measures of Hospital Competition Matter in Empirical Investigations of Hospital Behavior,February 2005,Herbert S. Wong,Chunliu Zhan,Ryan Mutter,Male,Unknown,,Mix,,
26.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-004-4085-0,"Entry, Standards and Competition: Firm Strategies and the Diffusion of Mobile Telephony",February 2005,Heli Koski,Tobias Kretschmer,,Female,Male,Unknown,Mix,,
26.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-004-6614-2,Pro-competitive Price Beating Guarantees: Experimental Evidence,February 2005,Enrique Fatás,Nikolaos Georgantzís,Gerardo Sabater-Grande,Male,Male,Male,Male,,13
26.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-005-0900-5,Review of Industrial Organization,February 2005,Lawerence J. White,,,Male,Unknown,Unknown,Male,,
26.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-004-7293-8,Introduction to the 2004 International Industrial Organization Conference Special Issue,March 2005,Christopher M. Snyder,,,Male,Unknown,Unknown,Male,,
26.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-004-7294-7,Detecting Collusion,March 2005,Robert H. Porter,,,Male,Unknown,Unknown,Male,,85
26.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-004-7295-6,Regulation and Deregulation after 25 Years: Lessons Learned for Research in Industrial Organization,March 2005,Paul L. Joskow,,,Male,Unknown,Unknown,Male,,30
26.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-004-7296-5,Growth and Diversification Patterns of the Worldwide Pharmaceutical Industry,March 2005,Giulio Bottazzi,Angelo Secchi,,Male,Male,Unknown,Male,,29
26.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-004-7297-4,Government Policies Supporting Open Source Software for the Mass Market,March 2005,Stefano Comino,Fabio M. Manenti,,Male,Male,Unknown,Male,,39
26.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-005-2444-0,Acknowledgement,March 2005,,,,Unknown,Unknown,Unknown,Unknown,,
26.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-004-8110-0,Introduction to Series on U.S. Brewing Industry,January 2005,Victor J. Tremblay,,,Male,Unknown,Unknown,Male,,
26.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-004-8111-z,The Supreme Court and Beer Mergers: From Pabst/Blatz to the DOJ–FTC Merger Guidelines,January 2005,Kenneth G. Elzinga,Anthony W. Swisher,,Male,Male,Unknown,Male,,8
26.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-004-8113-x,"Beer Advertising and Marketing Update: Structure, Conduct, and Social Costs",January 2005,Jon P. Nelson,,,Male,Unknown,Unknown,Male,,22
26.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-004-8114-9,The Dynamics of Industry Concentration for U.S. Micro and Macro Brewers,January 2005,Victor J. Tremblay,Natsuko Iwasaki,Carol Horton Tremblay,Male,Female,,Mix,,
26.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-004-6617-z,Australian Residential Telecommunications Consumption and Substitution Patterns,January 2005,Gary Madden,Grant Coble-Neal,,Male,Male,Unknown,Male,,4
26.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-004-8115-8,Industry Dynamics in the Swedish Textile and Wearing Apparel Sector,January 2005,Joakim Gullstrand,,,Male,Unknown,Unknown,Male,,6
26.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-005-4206-4,Does Increasing the Market Share of Smaller Firms Result in Lower Prices? Empirical Evidence from the Canadian Retail Gasoline Industry,June 2005,Anindya Sen,,,Unknown,Unknown,Unknown,Unknown,,
26.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-005-0182-y,Sales Promotion and Cooperative Retail Pricing Strategies,June 2005,Timothy J. Richards,Paul M. Patterson,,Male,Male,Unknown,Male,,8
26.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-005-0224-5,"Flexibility, Firm-Specific Turbulence and the Performance of the Long-lived Small Firm",June 2005,Bernadette Power,Gavin C. Reid,,Female,Male,Unknown,Mix,,
26.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-005-0983-z,Up-front Franchise Fees and Ongoing Variable Payments as Substitutes: An Agency Perspective,June 2005,Luis Vázquez,,,Male,Unknown,Unknown,Male,,34
26.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-005-0223-6,Airline Code-share Alliances and Costs: Imposing Concavity on Translog Cost Function Estimation,June 2005,Chew Lian Chua,Hsein Kew,Jongsay Yong,Unknown,Unknown,Unknown,Unknown,,
26.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-005-5330-x,Table of Contents Volume 26 2005,June 2005,,,,Unknown,Unknown,Unknown,Unknown,,
27.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-005-4401-3,Industries Behind Bars: An Economic Perspective on the Production of Goods and Services by U.S. Prison Industries,August 2005,Frederic L. Pryor,,,Male,Unknown,Unknown,Male,,5
27.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-005-4836-6,Why is This Show so Dumb? Advertising Revenue and Program Content of Network Television,August 2005,Keith Brown,Roberto Cavazos,,Male,Male,Unknown,Male,,8
27.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-005-5711-1,Pricing Network Interconnection: Advantages Held by Integrated Telecom Carriers,August 2005,Clement G. Krouse,Elke Krouse,,Male,Female,Unknown,Mix,,
27.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-005-4400-4,Production Efficiency and Discriminatory Hiring Practices in the National Hockey League: A Stochastic Frontier Approach,August 2005,Leo H. Kahane,,,Male,Unknown,Unknown,Male,,58
27.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-005-4920-y,Corporate Performance: Does Ownership Matter? A Comparison of Foreign- and Domestic-Owned Firms in Greece and Portugal,August 2005,Natália Barbosa,Helen Louri,,Female,Female,Unknown,Female,,67
27.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-005-8054-z,Industrial Organization Society ’s 7th Distinguished Fellow Award,August 2005,,,,Unknown,Unknown,Unknown,Unknown,,
27.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-005-8055-y,Industrial Organization Society’s Best Paper/Younger Scholar Award,August 2005,,,,Unknown,Unknown,Unknown,Unknown,,
27.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-005-1754-6,The Collusive Equilibrium in a Quantity-Setting Supergame: An Application to Taiwan’s Flour Industry,September 2005,Tay-Cheng Ma,,,Unknown,Unknown,Unknown,Unknown,,
27.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-005-8322-y,Are EU Leading Firms Returning to Core Business? Evidence on Refocusing and Relatedness in a Period of Market Integration,September 2005,Laura Rondi,Davide Vannoni,,Female,Male,Unknown,Mix,,
27.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-005-8321-z,The Determinants of Entry are not Independent of Start-up Size: Some Evidence from Spanish Manufacturing,September 2005,Josep-Maria Arauzo-Carod,Agustí Segarra-Blasco,,Unknown,Unknown,Unknown,Unknown,,
27.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-005-1752-8,The Demand for International Message Telephone Services: A Two-Stage Budgeting Model,September 2005,Jingsong Cui,,,Unknown,Unknown,Unknown,Unknown,,
27.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-005-1753-7,On Welfare under Cournot and Bertrand Competition in Differentiated Oligopolies,September 2005,Judy Hsu,X. Henry Wang,,Female,Unknown,Unknown,Female,,49
27.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-005-3044-8,Erratum,September 2005,,,,Unknown,Unknown,Unknown,Unknown,,
27.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-005-4357-3,Introduction: Antitrust and Regulatory Update,November 2005,Lawrence J. White,,,Male,Unknown,Unknown,Male,,
27.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-005-3624-7,"The Year in Review: Economics at the Antitrust Division, 2004–2005",November 2005,Eric Emch,Ken Heyer,Robert Majure,Male,Male,Male,Male,,
27.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-005-3493-0,"Economics at the FTC: Cases and Research, with a Focus on Petroleum",November 2005,Luke M. Froeb,James C. Cooper,Louis Silvia,Male,Male,Male,Male,,5
27.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-005-1755-5,A Multinomial Logit Framework to Estimate Bid Shading in Procurement Auctions: Application to Cattle Sales in the Texas Panhandle,November 2005,John M. Crespi,Richard J. Sexton,,Male,Male,Unknown,Male,,19
27.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-005-5712-0,Empirical Analysis of Merger Enforcement Under the 1992 Merger Guidelines,December 2005,Malcolm B. Coate,,,Male,Unknown,Unknown,Male,,30
27.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-005-5053-z,Technology and the Size Distribution of Firms: Evidence from Dutch Manufacturing,December 2005,Orietta Marsili,,,Female,Unknown,Unknown,Female,,26
27.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-005-5469-5,How do Brands’ “Own Generics” Affect Pharmaceutical Prices?,December 2005,Aidan Hollis,,,Male,Unknown,Unknown,Male,,18
27.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-005-3494-z,The Effect of Format Changes and Ownership Consolidation on Radio Station Outcomes,December 2005,Charles J. Romeo,Andrew R. Dick,,Male,Male,Unknown,Male,,3
27.0,4.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-005-6175-z,Table of Contents Volume 27 2005,December 2005,,,,Unknown,Unknown,Unknown,Unknown,,
28.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-006-0004-x,Introduction to the 2005 International Industrial Organization Conference Special Issue,February 2006,Christopher M. Snyder,,,Male,Unknown,Unknown,Male,,1
28.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-006-0005-9,"Regulation in Vertically-Related Industries: Myths, Facts, and Policy",February 2006,David E. M. Sappington,,,Male,Unknown,Unknown,Male,,10
28.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-006-0006-8,Estimating Market Power in the US Copper Industry,February 2006,Claudio A. Agostini,,,Male,Unknown,Unknown,Male,,17
28.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-006-0001-0,Patent Renewals as Options: Improving the Mechanism for Weeding Out Lousy Patents,February 2006,Marc Baudry,Béatrice Dumont,,Male,Female,Unknown,Mix,,
28.0,1.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-006-0008-6,Multilateral Vertical Contracting with an Alternative Supply: The Welfare Effects of a Ban on Price Discrimination,February 2006,Stéphane Caprice,,,,Unknown,Unknown,Mix,,
28.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-006-0013-9,In Memoriam: Paul A. Geroski,March 2006,John T. Scott,,,Male,Unknown,Unknown,Male,,
28.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-006-6642-1,"Monoline Restrictions, with Applications to Mortgage Insurance and Title Insurance",March 2006,Dwight Jaffee,,,Male,Unknown,Unknown,Male,,21
28.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-006-0012-x,Auction Reforms for Effective Official Development Assistance,March 2006,Atsushi Iimi,,,Male,Unknown,Unknown,Male,,42
28.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-006-0009-5,Market Power and Incentives to Form Research Consortia,March 2006,Eliane P. Catilina,Robert M. Feinberg,,Female,Male,Unknown,Mix,,
28.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-006-0010-z,The Determinants of Pharmaceutical R&D Expenditures: Evidence from Japan,March 2006,Jörg C. Mahlich,Thomas Roediger-Schluga,,Male,Male,Unknown,Male,,27
28.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-006-0011-y,Market Share Instability and the Dynamics of Competition: a Panel Data Analysis of Japanese Manufacturing Industries,March 2006,Masatoshi Kato,Yuji Honjo,,Male,Male,Unknown,Male,,13
28.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-006-0002-z,Pseudo-Generic Products and Barriers to Entry in Pharmaceutical Markets: Comment,March 2006,Vasco Rodrigues,,,Male,Unknown,Unknown,Male,,5
28.0,2.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-006-0003-y,Pseudo-Generic Products and Barriers to Entry in Pharmaceutical Markets: Reply,March 2006,Ying Kong,James R. Seldon,,,Male,Unknown,Mix,,
28.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-006-0020-x,Introduction to the Series on the U.S. Cigarette Industry,May 2006,Victor J. Tremblay,,,Male,Unknown,Unknown,Male,,
28.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-006-0019-3,The Effect of Government Advertising Policies on the Market Power of Cigarette Firms,May 2006,Shilpi Bihari,Barry J. Seldon,,Unknown,Male,Unknown,Male,,8
28.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-006-0015-7,The Effects of Taxes and Advertising Restrictions on the Market Structure of the U.S. Cigarette Market,May 2006,Wei Tan,,,,Unknown,Unknown,Mix,,
28.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-006-0016-6,The Role of Retail Prices and Promotions in Determining Cigarette Brand Market Shares,May 2006,John A. Tauras,Richard M. Peck,Frank J. Chaloupka,Male,Male,Male,Male,,28
28.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-006-0018-4,"The Effect of Industry, Region, and Time on New Business Survival – A Multi-Dimensional Analysis",May 2006,Michael Fritsch,Udo Brixy,Oliver Falck,Male,Male,Male,Male,,148
28.0,3.0,Review of Industrial Organization,,https://link.springer.com/article/10.1007/s11151-006-0017-5,Access Pricing in the Postal Sector: Theory and Simulations,May 2006,Philippe de Donder,,,Male,Unknown,Unknown,Male,,18
28.0,4.0,Review of Industrial Organization,28 July 2006,https://link.springer.com/article/10.1007/s11151-006-9105-9,A New Retrospective on Mergers,June 2006,F. M. Scherer,,,Unknown,Unknown,Unknown,Unknown,,
28.0,4.0,Review of Industrial Organization,28 July 2006,https://link.springer.com/article/10.1007/s11151-006-9101-0,Innovation in the Retail Banking Industry: The Diffusion of Credit Scoring,June 2006,Marcello Bofondi,Francesca Lotti,,Male,Female,Unknown,Mix,,
28.0,4.0,Review of Industrial Organization,28 July 2006,https://link.springer.com/article/10.1007/s11151-006-9103-y,"Hassle Costs, Price-Matching Guarantees and Price Competition: An Experiment",June 2006,Subhasish Dugar,Todd Sorensen,,Unknown,Male,Unknown,Male,,21
28.0,4.0,Review of Industrial Organization,28 July 2006,https://link.springer.com/article/10.1007/s11151-006-9104-x,Measuring Conduct and Cost Parameters in the Spanish Airline Market,June 2006,Xavier Fageda,,,Male,Unknown,Unknown,Male,,32
28.0,4.0,Review of Industrial Organization,28 July 2006,https://link.springer.com/article/10.1007/s11151-006-9102-z,Complementarity in R&D Cooperation Strategies,June 2006,René Belderbos,Martin Carree,Boris Lokshin,Male,Male,Male,Male,,184
29.0,1.0,Review of Industrial Organization,12 September 2006,https://link.springer.com/article/10.1007/s11151-006-9113-9,Introduction,September 2006,Jean-Michel Glachant,Stéphane Saussier,,Unknown,,Unknown,Mix,,
29.0,1.0,Review of Industrial Organization,05 October 2006,https://link.springer.com/article/10.1007/s11151-006-9107-7,PPI Partnerships vs. PPI Divorces in LDCs,September 2006,Antonio Estache,,,Male,Unknown,Unknown,Male,,62
29.0,1.0,Review of Industrial Organization,12 September 2006,https://link.springer.com/article/10.1007/s11151-006-9108-6,Privatizing Highways in the United States,September 2006,Eduardo Engel,Ronald Fischer,Alexander Galetovic,Male,Male,Male,Male,,28
29.0,1.0,Review of Industrial Organization,12 September 2006,https://link.springer.com/article/10.1007/s11151-006-9109-5,Renegotiation of Concession Contracts: A Theoretical Approach,September 2006,J. Luis Guasch,Jean-Jacques Laffont,Stéphane Straub,Unknown,Unknown,,Mix,,
29.0,1.0,Review of Industrial Organization,17 October 2006,https://link.springer.com/article/10.1007/s11151-006-9110-z,Delegation of Contracting in the Private Provision of Public Services,September 2006,John Bennett,Elisabetta Iossa,,Male,Female,Unknown,Mix,,
29.0,1.0,Review of Industrial Organization,17 October 2006,https://link.springer.com/article/10.1007/s11151-006-9111-y,Simple money-based tests for choosing between private and public delivery: a discussion of the issues,September 2006,Paul A. Grout,Silvia Sonderegger,,Male,Female,Unknown,Mix,,
29.0,1.0,Review of Industrial Organization,12 September 2006,https://link.springer.com/article/10.1007/s11151-006-9112-x,"The Role of Competition in Natural Monopoly: Costs, Public Ownership, and Regulation",September 2006,John E. Kwoka,,,Male,Unknown,Unknown,Male,,17
29.0,1.0,Review of Industrial Organization,20 October 2006,https://link.springer.com/article/10.1007/s11151-006-9106-8,Public-Private Partnerships and Prices: Evidence from Water Distribution in France,September 2006,Eshien Chong,Freddy Huet,Faye Steiner,Unknown,Male,Female,Mix,,
30.0,1.0,Review of Industrial Organization,12 October 2006,https://link.springer.com/article/10.1007/s11151-006-9118-4,Measuring the Extent of Structural Remedy in Section 7 Settlements: Was the US DOJ Successful in the 1990s?,February 2007,Mikhail S. Kouliavtsev,,,Male,Unknown,Unknown,Male,,4
30.0,1.0,Review of Industrial Organization,28 February 2007,https://link.springer.com/article/10.1007/s11151-007-9127-y,On Stability in Competition: Tying and Horizontal Product Differentiation,February 2007,Alain Egli,,,Male,Unknown,Unknown,Male,,2
30.0,1.0,Review of Industrial Organization,15 February 2007,https://link.springer.com/article/10.1007/s11151-007-9125-0,"A panel data analysis of code-sharing, antitrust immunity, and open skies treaties in international aviation markets",February 2007,W. Tom Whalen,,,Unknown,Unknown,Unknown,Unknown,,
30.0,1.0,Review of Industrial Organization,28 February 2007,https://link.springer.com/article/10.1007/s11151-007-9126-z,When cost improvements harm consumers,February 2007,Philippe Bontems,Nicolas Gruyer,,Male,Male,Unknown,Male,,
30.0,2.0,Review of Industrial Organization,17 May 2007,https://link.springer.com/article/10.1007/s11151-007-9128-x,Industry costs and consolidation: efficiency gains and mergers in the U.S. railroad industry,March 2007,John D. Bitzan,Wesley W. Wilson,,Male,Male,Unknown,Male,,18
30.0,2.0,Review of Industrial Organization,17 April 2007,https://link.springer.com/article/10.1007/s11151-007-9129-9,Price-Matching Guarantees and Equilibrium Selection in a Homogenous Product Market: An Experimental Study,March 2007,Subhasish Dugar,,,Unknown,Unknown,Unknown,Unknown,,
30.0,2.0,Review of Industrial Organization,17 April 2007,https://link.springer.com/article/10.1007/s11151-007-9130-3,Was Chadwick right?,March 2007,Michel Mougeot,Florence Naegelen,,Male,Female,Unknown,Mix,,
30.0,2.0,Review of Industrial Organization,22 May 2007,https://link.springer.com/article/10.1007/s11151-007-9131-2,"Risk Sharing, the Cost of Equity and the Optimal Capital Structure of the Regulated Firm",March 2007,Clive J Stones,,,Male,Unknown,Unknown,Male,,9
30.0,3.0,Review of Industrial Organization,18 August 2007,https://link.springer.com/article/10.1007/s11151-007-9140-1,Airline Schedule Competition,May 2007,Jan K. Brueckner,Ricardo Flores-Fillol,,Male,Male,Unknown,Male,,84
30.0,3.0,Review of Industrial Organization,19 June 2007,https://link.springer.com/article/10.1007/s11151-007-9132-1,Evolution on the Shoulders of Giants: Entrepreneurship and Firm Survival in the German Laser Industry,May 2007,Guido Buenstorf,,,Male,Unknown,Unknown,Male,,90
30.0,3.0,Review of Industrial Organization,29 June 2007,https://link.springer.com/article/10.1007/s11151-007-9133-0,Sorry Winners,May 2007,Marco Pagnozzi,,,Male,Unknown,Unknown,Male,,5
30.0,3.0,Review of Industrial Organization,17 July 2007,https://link.springer.com/article/10.1007/s11151-007-9134-z,"Vertical Ownership, Program Network Carriage, and Tier Positioning in Cable Television: An Empirical Study",May 2007,Dong Chen,David Waterman,,,Male,Unknown,Mix,,
30.0,4.0,Review of Industrial Organization,16 August 2007,https://link.springer.com/article/10.1007/s11151-007-9137-9,Introduction to the Series on the Motion Picture Industry,June 2007,Victor J. Tremblay,,,Male,Unknown,Unknown,Male,,
30.0,4.0,Review of Industrial Organization,09 October 2007,https://link.springer.com/article/10.1007/s11151-007-9136-x,"Enforcement and Control of Piracy, Copying, and Sharing in the Movie Industry",June 2007,David Waterman,Sung Wook Ji,Laura R. Rochet,Male,,Female,Mix,,
30.0,4.0,Review of Industrial Organization,24 August 2007,https://link.springer.com/article/10.1007/s11151-007-9141-0,Estimating the Effects of Movie Piracy on Box-office Revenue,June 2007,Arthur S. De Vany,W. David Walls,,Male,Unknown,Unknown,Male,,72
30.0,4.0,Review of Industrial Organization,14 August 2007,https://link.springer.com/article/10.1007/s11151-007-9138-8,An Analysis of the Out-of-Market Gap for DVDs in the U.S.,June 2007,Randy A. Nelson,Clifford E. Reid,Owen Gilmore,,Male,Male,Mix,,
30.0,4.0,Review of Industrial Organization,15 August 2007,https://link.springer.com/article/10.1007/s11151-007-9139-7,The Role and Determinants of Concession Sales in Movie Theaters: Evidence from the Spanish Exhibition Industry,June 2007,Ricard Gil,Wesley R. Hartmann,,Male,Male,Unknown,Male,,14
31.0,1.0,Review of Industrial Organization,14 September 2007,https://link.springer.com/article/10.1007/s11151-007-9143-y,"Markets Linked by Rising Marginal Costs: Implications for Multimarket Contact, Recoupment, and Retaliatory Entry",August 2007,Zhiqi Chen,Thomas W. Ross,,Unknown,Male,Unknown,Male,,8
31.0,1.0,Review of Industrial Organization,14 September 2007,https://link.springer.com/article/10.1007/s11151-007-9144-x,"Foreign Ownership, Competition, and Survival Dynamics",August 2007,Erol Taymaz,Şule Özler,,Male,Female,Unknown,Mix,,
31.0,1.0,Review of Industrial Organization,24 August 2007,https://link.springer.com/article/10.1007/s11151-007-9142-z,Flawed Competition Policies: Designing ‘Markets’ with Biased Costs and Efficiency Benchmarks,August 2007,Francis J. Cronin,Stephen A. Motluk,,Male,Male,Unknown,Male,,10
31.0,1.0,Review of Industrial Organization,07 August 2007,https://link.springer.com/article/10.1007/s11151-007-9135-y,A Closer Look at Serial Growth Rate Correlation,August 2007,Alex Coad,,,Male,Unknown,Unknown,Male,,98
31.0,2.0,Review of Industrial Organization,06 November 2007,https://link.springer.com/article/10.1007/s11151-007-9150-z,Introduction: Antitrust and Regulatory Update,September 2007,Lawrence J. White,,,Male,Unknown,Unknown,Male,,
31.0,2.0,Review of Industrial Organization,06 November 2007,https://link.springer.com/article/10.1007/s11151-007-9151-y,Economics at the FTC: Pharmaceutical Patent Dispute Settlements and Behavioral Economics,September 2007,Michael A. Salinger,Pauline M. Ippolito,Joel L. Schrag,Male,Female,Male,Mix,,
31.0,2.0,Review of Industrial Organization,16 November 2007,https://link.springer.com/article/10.1007/s11151-007-9149-5,Economics at the Federal Communications Commission: 2006–2007,September 2007,Michelle Connolly,Evan Kwerel,,Female,Male,Unknown,Mix,,
31.0,2.0,Review of Industrial Organization,12 October 2007,https://link.springer.com/article/10.1007/s11151-007-9147-7,"The Year in Review: Economics at the Antitrust Division, 2006–2007",September 2007,Dennis W. Carlton,Ken Heyer,,Male,Male,Unknown,Male,,3
31.0,2.0,Review of Industrial Organization,11 October 2007,https://link.springer.com/article/10.1007/s11151-007-9148-6,Economics at DG Competition 2006–2007,September 2007,Damien Neven,Svend Albæk,,Male,Male,Unknown,Male,,4
31.0,3.0,Review of Industrial Organization,11 October 2007,https://link.springer.com/article/10.1007/s11151-007-9145-9,Quasi-Partnerships in Distribution,November 2007,David E. Mills,,,Male,Unknown,Unknown,Male,,4
31.0,3.0,Review of Industrial Organization,04 January 2008,https://link.springer.com/article/10.1007/s11151-007-9152-x,Business R&D and the Interplay of R&D Subsidies and Product Market Uncertainty,November 2007,Dirk Czarnitzki,Andrew A. Toole,,Male,Male,Unknown,Male,,64
31.0,3.0,Review of Industrial Organization,09 December 2007,https://link.springer.com/article/10.1007/s11151-007-9153-9,Restructuring Public Transit Systems: Evidence on Cost Properties from Medium and Large-Sized Companies,November 2007,Carlo Cambini,Massimiliano Piacenza,Davide Vannoni,Male,Male,Male,Male,,25
31.0,3.0,Review of Industrial Organization,22 February 2008,https://link.springer.com/article/10.1007/s11151-008-9155-2,Merger Simulation in Mobile Telephony in Portugal,November 2007,Lukasz Grzybowski,Pedro Pereira,,Unknown,Male,Unknown,Male,,13
31.0,3.0,Review of Industrial Organization,11 October 2007,https://link.springer.com/article/10.1007/s11151-007-9146-8,The Effect of Advertising on Pharmaceutical Innovation,November 2007,Winghan Jacqueline Kwong,Edward C. Norton,,Unknown,Male,Unknown,Male,,14
31.0,4.0,Review of Industrial Organization,22 February 2008,https://link.springer.com/article/10.1007/s11151-008-9156-1,Entry and Prices: Evidence from the Supermarket Sector,December 2007,Loreto Lira,Rosario Rivero,Rodrigo Vergara,Male,Male,Male,Male,,8
31.0,4.0,Review of Industrial Organization,04 March 2008,https://link.springer.com/article/10.1007/s11151-008-9158-z,Licensing Innovations with Exclusive Contracts,December 2007,C. Erutku,A. Priegue Freire,Y. Richelle,Unknown,Unknown,Unknown,Unknown,,
31.0,4.0,Review of Industrial Organization,12 February 2008,https://link.springer.com/article/10.1007/s11151-007-9154-8,Knowledge Disclosure and Transmission in Buyer–Supplier Relationships,December 2007,Werner Bönte,Lars Wiethaus,,Male,Male,Unknown,Male,,15
31.0,4.0,Review of Industrial Organization,22 February 2008,https://link.springer.com/article/10.1007/s11151-008-9157-0,Measuring Competitive Balance in Professional Team Sports Using the Herfindahl-Hirschman Index,December 2007,P. Dorian Owen,Michael Ryan,Clayton R. Weatherston,Unknown,Male,Male,Male,,74
31.0,4.0,Review of Industrial Organization,18 April 2008,https://link.springer.com/article/10.1007/s11151-008-9159-y,Firm Growth Under Sample Selection: Conditional σ-Convergence in Firm Size?,December 2007,Michael Pfaffermayr,,,Male,Unknown,Unknown,Male,,11
32.0,1.0,Review of Industrial Organization,17 April 2008,https://link.springer.com/article/10.1007/s11151-008-9161-4,Firm Survival and Chain Growth in a Privatized Retail Liquor Store Industry,February 2008,Andrew Eckert,Douglas S. West,,Male,Male,Unknown,Male,,9
32.0,1.0,Review of Industrial Organization,17 April 2008,https://link.springer.com/article/10.1007/s11151-008-9162-3,Lower Bounds of Concentration in a Small Open Economy,February 2008,Pekka Ilmakunnas,,,Male,Unknown,Unknown,Male,,2
32.0,1.0,Review of Industrial Organization,17 May 2008,https://link.springer.com/article/10.1007/s11151-008-9163-2,Collusive Communication and Pricing Coordination in a Retail Gasoline Market,February 2008,Zhongmin Wang,,,Unknown,Unknown,Unknown,Unknown,,
32.0,1.0,Review of Industrial Organization,18 April 2008,https://link.springer.com/article/10.1007/s11151-008-9160-5,Incorporating Service Quality into Yardstick Regulation: An Application to the Peru Water Sector,February 2008,Chen Lin,Sanford V. Berg,,,Male,Unknown,Mix,,
32.0,2.0,Review of Industrial Organization,05 June 2008,https://link.springer.com/article/10.1007/s11151-008-9164-1,Is there any Impact of University–Industry Knowledge Transfer on Innovation and Productivity? An Empirical Analysis Based on Swiss Firm Data,March 2008,Spyros Arvanitis,Nora Sydow,Martin Woerter,Male,Female,Male,Mix,,
32.0,2.0,Review of Industrial Organization,05 June 2008,https://link.springer.com/article/10.1007/s11151-008-9167-y,Innovation in the Shadow of Patent Litigation,March 2008,Yann Ménière,Sarah Parlane,,Male,Female,Unknown,Mix,,
32.0,2.0,Review of Industrial Organization,22 June 2008,https://link.springer.com/article/10.1007/s11151-008-9168-x,An Empirical Analysis of Mexican Merger Policy,March 2008,Marcos Avalos,Rafael E. De Hoyos,,Male,Male,Unknown,Male,,7
32.0,2.0,Review of Industrial Organization,05 June 2008,https://link.springer.com/article/10.1007/s11151-008-9165-0,Long-Term Contracts and Asset Specificity Revisited: An Empirical Analysis of Producer–Importer Relations in the Natural Gas Industry,March 2008,Christian von Hirschhausen,Anne Neumann,,Male,Female,Unknown,Mix,,
32.0,2.0,Review of Industrial Organization,05 June 2008,https://link.springer.com/article/10.1007/s11151-008-9166-z,Competition in Local Markets: Some Evidence from the Spanish Retail Banking Market,March 2008,Rebeca de Juan,,,Female,Unknown,Unknown,Female,,8
32.0,3.0,Review of Industrial Organization,19 July 2008,https://link.springer.com/article/10.1007/s11151-008-9169-9,Introduction to the Symposium on Restructuring in the U.S. Electricity Industry,May 2008,Diana L. Moss,,,Female,Unknown,Unknown,Female,,
32.0,3.0,Review of Industrial Organization,25 July 2008,https://link.springer.com/article/10.1007/s11151-008-9171-2,Restructuring the U.S. Electric Power Sector: A Review of Recent Studies,May 2008,John Kwoka,,,Male,Unknown,Unknown,Male,,53
32.0,3.0,Review of Industrial Organization,20 July 2008,https://link.springer.com/article/10.1007/s11151-008-9172-1,Electricity Market Monitoring and the Economics of Regulation,May 2008,Robert J. Michaels,,,Male,Unknown,Unknown,Male,,7
32.0,3.0,Review of Industrial Organization,20 July 2008,https://link.springer.com/article/10.1007/s11151-008-9173-0,Analytical Screens for Electricity Mergers,May 2008,Richard Gilbert,David Newbery,,Male,Male,Unknown,Male,,8
32.0,3.0,Review of Industrial Organization,20 July 2008,https://link.springer.com/article/10.1007/s11151-008-9174-z,Antitrust Versus Regulatory Merger Review: The Case of Electricity,May 2008,Diana L. Moss,,,Female,Unknown,Unknown,Female,,7
32.0,3.0,Review of Industrial Organization,06 August 2008,https://link.springer.com/article/10.1007/s11151-008-9170-3,"Electricity Merger Analysis: Market Screens, Market Definition, and Other Lemmings",May 2008,Darren Bush,,,Male,Unknown,Unknown,Male,,2
32.0,3.0,Review of Industrial Organization,07 August 2008,https://link.springer.com/article/10.1007/s11151-008-9175-y,"Economics, Competition, and Costs in the Resructuring of U.S. Electricity Markets",May 2008,John C. Hilke,,,Male,Unknown,Unknown,Male,,3
33.0,1.0,Review of Industrial Organization,03 August 2008,https://link.springer.com/article/10.1007/s11151-008-9176-x,"Private Labels, National Brands and Food Prices",August 2008,Christophe Bontemps,Valérie Orozco,Vincent Réquillart,Male,Female,Male,Mix,,
33.0,1.0,Review of Industrial Organization,29 August 2008,https://link.springer.com/article/10.1007/s11151-008-9180-1,"Sorting, Selection, and Industry Shakeouts",August 2008,Peter Thompson,Mihaela Pintea,,Male,Female,Unknown,Mix,,
33.0,1.0,Review of Industrial Organization,24 August 2008,https://link.springer.com/article/10.1007/s11151-008-9179-7,Empirical Evidence on the Success of R&D Cooperation—Happy Together?,August 2008,Birgit Aschhoff,Tobias Schmidt,,Female,Male,Unknown,Mix,,
33.0,1.0,Review of Industrial Organization,02 September 2008,https://link.springer.com/article/10.1007/s11151-008-9178-8,Incentive Complementarity in China’s Rural Enterprises,August 2008,Sandeep Mohapatra,Rachael E. Goodhue,Scott Rozelle,,Female,Male,Mix,,
33.0,1.0,Review of Industrial Organization,31 July 2008,https://link.springer.com/article/10.1007/s11151-008-9177-9,"Explaining the Credit Union Entry Decision, and Implications for Performance",August 2008,Robert M. Feinberg,,,Male,Unknown,Unknown,Male,,14
33.0,2.0,Review of Industrial Organization,17 September 2008,https://link.springer.com/article/10.1007/s11151-008-9181-0,Determinants of UK Box Office Success: The Impact of Quality Signals,September 2008,Caroline Elliott,Rob Simmons,,Female,Male,Unknown,Mix,,
33.0,2.0,Review of Industrial Organization,30 August 2008,https://link.springer.com/article/10.1007/s11151-008-9182-z,Auctioning Horizontally Differentiated Items,September 2008,Sarah Parlane,,,Female,Unknown,Unknown,Female,,4
33.0,2.0,Review of Industrial Organization,05 October 2008,https://link.springer.com/article/10.1007/s11151-008-9185-9,Does a Hospital’s Profit Status Affect its Operational Scope?,September 2008,Marco A. Castaneda,Dino Falaschetti,,Male,Male,Unknown,Male,,4
33.0,2.0,Review of Industrial Organization,12 October 2008,https://link.springer.com/article/10.1007/s11151-008-9187-7,On Retail Gasoline Pricing Websites: Potential Sample Selection Biases and Their Implications for Empirical Research,September 2008,Benjamin Atkinson,,,Male,Unknown,Unknown,Male,,17
33.0,2.0,Review of Industrial Organization,25 September 2008,https://link.springer.com/article/10.1007/s11151-008-9184-x,A Further Note on Endogenous Spillovers in a Non-tournament R&D Duopoly,September 2008,Antonio Tesoriere,,,Male,Unknown,Unknown,Male,,17
33.0,3.0,Review of Industrial Organization,18 November 2008,https://link.springer.com/article/10.1007/s11151-008-9197-5,Introduction: Antitrust and Regulatory Update,November 2008,Lawrence J. White,,,Male,Unknown,Unknown,Male,,
33.0,3.0,Review of Industrial Organization,18 November 2008,https://link.springer.com/article/10.1007/s11151-008-9196-6,Economics at the FCC: 2007–2008,November 2008,Gregory S. Crawford,Evan Kwerel,Jonathan Levy,Male,Male,Male,Male,,6
33.0,3.0,Review of Industrial Organization,26 September 2008,https://link.springer.com/article/10.1007/s11151-008-9183-y,"Economics at the FTC: The Google-DoubleClick Merger, Resale Price Maintenance, Mortgage Disclosures, and Credit Scoring in Auto Insurance",November 2008,Michael R. Baye,Matias Barenstein,Michael G. Vita,Male,Male,Male,Male,,7
33.0,3.0,Review of Industrial Organization,07 October 2008,https://link.springer.com/article/10.1007/s11151-008-9186-8,Antitrust Update: DG Competition 2007–2008,November 2008,Damien Neven,Svend Albæk,,Male,Male,Unknown,Male,,2
33.0,3.0,Review of Industrial Organization,31 October 2008,https://link.springer.com/article/10.1007/s11151-008-9191-y,"The Year in Review: Economics at the Antitrust Division, 2007–2008",November 2008,Ken Heyer,Nicholas Hill,,Male,Male,Unknown,Male,,1
33.0,4.0,Review of Industrial Organization,19 October 2008,https://link.springer.com/article/10.1007/s11151-008-9189-5,Brewing Wars of Attrition for Profit (and Concentration),December 2008,Natsuko Iwasaki,Barry J. Seldon,Victor J. Tremblay,Female,Male,Male,Mix,,
33.0,4.0,Review of Industrial Organization,01 November 2008,https://link.springer.com/article/10.1007/s11151-008-9193-9,Attendance and the Uncertainty-of-Outcome Hypothesis in Baseball,December 2008,Young Hoon Lee,Rodney Fort,,,Male,Unknown,Mix,,
33.0,4.0,Review of Industrial Organization,23 November 2008,https://link.springer.com/article/10.1007/s11151-008-9192-x,Search Cost and Price Dispersion in Vertically Related Markets: The Case of Bank Loans and Deposits,December 2008,Alfredo Martin-Oliver,Vicente Salas-Fumas,Jesús Saurina,Male,Male,,Mix,,
33.0,4.0,Review of Industrial Organization,24 October 2008,https://link.springer.com/article/10.1007/s11151-008-9190-z,"On Storage Behavior Under Imperfect Competition, with Application to the American Cheese Market",December 2008,Jean-Paul Chavas,,,Male,Unknown,Unknown,Male,,4
33.0,4.0,Review of Industrial Organization,19 October 2008,https://link.springer.com/article/10.1007/s11151-008-9188-6,Host Country’s Intellectual Property Rights and Firm’s Equity Participation,December 2008,Bong Geul Chun,,,,Unknown,Unknown,Mix,,
34.0,1.0,Review of Industrial Organization,14 February 2009,https://link.springer.com/article/10.1007/s11151-009-9204-5,Introduction: Economic Issues in Sports,February 2009,Victor J. Tremblay,,,Male,Unknown,Unknown,Male,,2
34.0,1.0,Review of Industrial Organization,18 February 2009,https://link.springer.com/article/10.1007/s11151-009-9202-7,Theory of the Perfect Game: Competitive Balance in Monopoly Sports Leagues,February 2009,John Vrooman,,,Male,Unknown,Unknown,Male,,47
34.0,1.0,Review of Industrial Organization,17 February 2009,https://link.springer.com/article/10.1007/s11151-009-9203-6,Goal! Profit Maximization Versus Win Maximization in Soccer,February 2009,Pedro Garcia-del-Barrio,Stefan Szymanski,,Male,Male,Unknown,Male,,114
34.0,1.0,Review of Industrial Organization,07 February 2009,https://link.springer.com/article/10.1007/s11151-009-9201-8,Sports Really are Different: The Contest Success Function and the Supply of Talent,February 2009,Rodney Fort,Jason Winfree,,Male,Male,Unknown,Male,,29
34.0,1.0,Review of Industrial Organization,07 February 2009,https://link.springer.com/article/10.1007/s11151-009-9200-9,Gains from Specialization and Free Agency: The Story from the Gridiron,February 2009,Rob Simmons,David J. Berri,,Male,Male,Unknown,Male,,22
34.0,2.0,Review of Industrial Organization,12 November 2008,https://link.springer.com/article/10.1007/s11151-008-9195-7,Do Court Decisions Drive the Federal Trade Commission’s Enforcement Policy on Merger Settlements?,March 2009,Malcolm B. Coate,Shawn W. Ulrick,,Male,,Unknown,Mix,,
34.0,2.0,Review of Industrial Organization,11 January 2009,https://link.springer.com/article/10.1007/s11151-008-9198-4,An Anticompetitive Effect of Eliminating Transport Barriers in Network Markets,March 2009,Federico Boffa,Carlo Scarpa,,Male,Male,Unknown,Male,,8
34.0,2.0,Review of Industrial Organization,28 February 2009,https://link.springer.com/article/10.1007/s11151-009-9205-4,A Consideration of Telecommunications Market Structure in the Presence of Municipal Provision: The Case of US Cities,March 2009,Janice A. Hauge,Mark A. Jamison,R. Todd Jewell,Female,Male,Unknown,Mix,,
34.0,2.0,Review of Industrial Organization,03 February 2009,https://link.springer.com/article/10.1007/s11151-009-9199-y,Competition in Research and Development: A Theory for Contradictory Predictions,March 2009,John T. Scott,,,Male,Unknown,Unknown,Male,,19
34.0,2.0,Review of Industrial Organization,06 November 2008,https://link.springer.com/article/10.1007/s11151-008-9194-8,Why Do Payday Lenders Enter Local Markets? Evidence from Oregon,March 2009,H. Evren Damar,,,Unknown,Unknown,Unknown,Unknown,,
34.0,3.0,Review of Industrial Organization,20 June 2009,https://link.springer.com/article/10.1007/s11151-009-9207-2,Modelling Professional Sports Leagues: An Industrial Organization Approach,May 2009,Philippe Cyrenne,,,Male,Unknown,Unknown,Male,,7
34.0,3.0,Review of Industrial Organization,09 June 2009,https://link.springer.com/article/10.1007/s11151-009-9206-3,Determinants of Contract Duration: Further Evidence from Coal-Fired Power Plants,May 2009,Maria Kozhevnikova,Ian Lange,,Female,Male,Unknown,Mix,,
34.0,3.0,Review of Industrial Organization,12 July 2009,https://link.springer.com/article/10.1007/s11151-009-9209-0,Measuring Market Conduct in the Brazilian Cement Industry: A Dynamic Econometric Investigation,May 2009,Rodrigo M. Zeidan,Marcelo Resende,,Male,Male,Unknown,Male,,9
34.0,3.0,Review of Industrial Organization,05 July 2009,https://link.springer.com/article/10.1007/s11151-009-9211-6,Merger Simulation in the Presence of Large Choice Sets and Consumer Stockpiling: The Case of the Bottled Juice Industry,May 2009,Geoffrey M. Pofahl,,,Male,Unknown,Unknown,Male,,2
34.0,3.0,Review of Industrial Organization,17 June 2009,https://link.springer.com/article/10.1007/s11151-009-9208-1,Effects of Transparency in Procurement Practices on Government Expenditure: A Case Study of Municipal Public Works,May 2009,Hiroshi Ohashi,,,Male,Unknown,Unknown,Male,,77
34.0,4.0,Review of Industrial Organization,07 July 2009,https://link.springer.com/article/10.1007/s11151-009-9210-7,Product Innovation and Survival in a High-Tech Industry,June 2009,Roberto Fontana,Lionel Nesta,,Male,Male,Unknown,Male,,75
34.0,4.0,Review of Industrial Organization,11 August 2009,https://link.springer.com/article/10.1007/s11151-009-9215-2,Policy Implications of the Effects of Concentration and Multimarket Contact in China’s Airline Market,June 2009,Yahua Zhang,David K. Round,,Unknown,Male,Unknown,Male,,28
34.0,4.0,Review of Industrial Organization,18 July 2009,https://link.springer.com/article/10.1007/s11151-009-9212-5,Uncertainty and Auction Outcomes: Evidence from Used Car Actions,June 2009,Yaron Raviv,,,Male,Unknown,Unknown,Male,,
34.0,4.0,Review of Industrial Organization,24 July 2009,https://link.springer.com/article/10.1007/s11151-009-9213-4,Small Firms and Formality: The Influence of Judicial Efficiency and Regulation Costs,June 2009,Jeffrey B. Nugent,Grigor Sukiassyan,,Male,Male,Unknown,Male,,1
34.0,4.0,Review of Industrial Organization,25 July 2009,https://link.springer.com/article/10.1007/s11151-009-9214-3,Generic Entry into the Regulated Spanish Pharmaceutical Market,June 2009,Iván Moreno-Torres,Jaume Puig-Junoy,Joan-Ramon Borrell,Male,Male,Unknown,Male,,28
35.0,1.0,Review of Industrial Organization,17 October 2009,https://link.springer.com/article/10.1007/s11151-009-9226-z,"Public–Private Agreements, Institutions, and Competition: When Economic Theory Meets Facts",September 2009,Stéphane Saussier,Carine Staropoli,Anne Yvrande-Billon,,Female,Female,Mix,,
35.0,1.0,Review of Industrial Organization,14 October 2009,https://link.springer.com/article/10.1007/s11151-009-9224-1,A Comparison of Construction Contract Prices for Traditionally Procured Roads and Public–Private Partnerships,September 2009,Frédéric Blanc-Brude,Hugh Goldsmith,Timo Välilä,Male,Male,Male,Male,,49
35.0,1.0,Review of Industrial Organization,14 October 2009,https://link.springer.com/article/10.1007/s11151-009-9225-0,Multidimensionality and Renegotiation: Evidence from Transport-Sector Public-Private-Partnership Transactions in Latin America,September 2009,Antonio Estache,Jose-Luis Guasch,Lourdes Trujillo,Male,Unknown,Female,Mix,,
35.0,1.0,Review of Industrial Organization,13 October 2009,https://link.springer.com/article/10.1007/s11151-009-9223-2,Entry and Bidding in Common and Private Value Auctions with an Unknown Number of Rivals,September 2009,Dakshina G. De Silva,Thomas D. Jeitschko,Georgia Kosmopoulou,Unknown,Male,Female,Mix,,
35.0,1.0,Review of Industrial Organization,14 October 2009,https://link.springer.com/article/10.1007/s11151-009-9220-5,Fine-Tailored for the Cartel-Favoritism in Procurement,September 2009,Ariane Lambert-Mogiliansky,Grigory Kosenok,,Female,Male,Unknown,Mix,,
35.0,1.0,Review of Industrial Organization,01 October 2009,https://link.springer.com/article/10.1007/s11151-009-9218-z,"Regulatory Intervention, Corruption and Competition",September 2009,Stéphane Straub,,,,Unknown,Unknown,Mix,,
35.0,1.0,Review of Industrial Organization,13 October 2009,https://link.springer.com/article/10.1007/s11151-009-9222-3,"Yardstick Competition, Franchise Bidding and Firms’ Incentives to Collude",September 2009,Eshien Chong,Freddy Huet,,Unknown,Male,Unknown,Male,,7
35.0,1.0,Review of Industrial Organization,14 October 2009,https://link.springer.com/article/10.1007/s11151-009-9221-4,Infrastructure Contracts: Trust and Institutional Updating,September 2009,Xeni Dassiou,Jon Stern,,Female,Male,Unknown,Mix,,
36.0,1.0,Review of Industrial Organization,04 February 2010,https://link.springer.com/article/10.1007/s11151-010-9240-1,"More Information, More Ripoffs: Experiments with Public and Private Information in Markets with Asymmetric Information",February 2010,Bart J. Wilson,Arthur Zillante,,Male,Male,Unknown,Male,,6
36.0,1.0,Review of Industrial Organization,22 January 2010,https://link.springer.com/article/10.1007/s11151-009-9236-x,Revenue Sharing and Competitive Balance in a Dynamic Contest Model,February 2010,Martin Grossmann,Helmut Dietl,Markus Lang,Male,Male,Male,Male,,24
36.0,1.0,Review of Industrial Organization,05 December 2009,https://link.springer.com/article/10.1007/s11151-009-9235-y,Market Diversion and Market Power: California Eggs,February 2010,William J. Allender,Timothy J. Richards,,Male,Male,Unknown,Male,,9
36.0,1.0,Review of Industrial Organization,04 February 2010,https://link.springer.com/article/10.1007/s11151-010-9241-0,"Intra-Industry Growth Dynamics in the Greek Services Sector: Firm-Level Estimates for ICT-Producing, ICT-Using, and Non-ICT Industries",February 2010,Ioannis Giotopoulos,Georgios Fotopoulos,,Male,Male,Unknown,Male,,17
36.0,1.0,Review of Industrial Organization,10 October 2009,https://link.springer.com/article/10.1007/s11151-009-9219-y,An Asymmetric Oligopolist can Improve Welfare by Raising Price,February 2010,Ming Chung Chang,,,,Unknown,Unknown,Mix,,
36.0,2.0,Review of Industrial Organization,06 February 2010,https://link.springer.com/article/10.1007/s11151-010-9237-9,European Antitrust Policy 1957–2004: An Analysis of Commission Decisions,March 2010,Martin Carree,Andrea Günster,Maarten Pieter Schinkel,Male,Female,Male,Mix,,
36.0,2.0,Review of Industrial Organization,04 February 2010,https://link.springer.com/article/10.1007/s11151-010-9239-7,The Consequences of “Consideration Payments”: Lessons from Radio Payola,March 2010,Adam D. Rennhoff,,,Male,Unknown,Unknown,Male,,3
36.0,2.0,Review of Industrial Organization,12 February 2010,https://link.springer.com/article/10.1007/s11151-010-9238-8,Endogenous Average Cost Based Access Pricing,March 2010,Kenneth Fjell,Øystein Foros,Debashis Pal,Male,Male,Male,Male,,6
36.0,2.0,Review of Industrial Organization,21 February 2010,https://link.springer.com/article/10.1007/s11151-010-9242-z,Bidder Asymmetry in Infrastructure Procurement: Are There any Fringe Bidders?,March 2010,Antonio Estache,Atsushi Iimi,,Male,Male,Unknown,Male,,19
36.0,2.0,Review of Industrial Organization,18 March 2010,https://link.springer.com/article/10.1007/s11151-010-9243-y,Marketing and Organisational Innovations in Entrepreneurial Innovation Processes and their Relation to Market Structure and Firm Characteristics,March 2010,Torben Schubert,,,Male,Unknown,Unknown,Male,,56
36.0,3.0,Review of Industrial Organization,19 March 2010,https://link.springer.com/article/10.1007/s11151-010-9244-x,Buyer Power and Industry Structure,May 2010,David E. Mills,,,Male,Unknown,Unknown,Male,,9
36.0,3.0,Review of Industrial Organization,09 May 2010,https://link.springer.com/article/10.1007/s11151-010-9247-7,Innovation and the Survival of New Firms in the UK,May 2010,Christian Helmers,Mark Rogers,,Male,Male,Unknown,Male,,109
36.0,3.0,Review of Industrial Organization,05 May 2010,https://link.springer.com/article/10.1007/s11151-010-9246-8,The Effects of Average Norm Model Regulation: The Case of Electricity Distribution in Sweden,May 2010,Tooraj Jamasb,Magnus Söderberg,,Unknown,Male,Unknown,Male,,18
36.0,3.0,Review of Industrial Organization,31 March 2010,https://link.springer.com/article/10.1007/s11151-010-9245-9,Market Consolidation and Productivity Growth in U.S. Wireline Telecommunications: Stochastic Frontier Analysis vs. Malmquist Index,May 2010,Daigyo Seo,Allen M. Featherstone,Yuan Gao,Unknown,Male,,Mix,,
36.0,3.0,Review of Industrial Organization,11 May 2010,https://link.springer.com/article/10.1007/s11151-010-9248-6,Internet Auctions and Frictionless Commerce: Evidence from the Retail Gift Card Market,May 2010,Lesley Chiou,Jennifer Pate,,,Female,Unknown,Mix,,
36.0,4.0,Review of Industrial Organization,23 July 2010,https://link.springer.com/article/10.1007/s11151-010-9254-8,Comparing Merger Policies in the European Union and the United States,June 2010,Mats A. Bergman,Malcolm B. Coate,Shawn W. Ulrick,Male,Male,,Mix,,
36.0,4.0,Review of Industrial Organization,14 May 2010,https://link.springer.com/article/10.1007/s11151-010-9249-5,Brand or Variety Choices and Periodic Sales as Substitute Instruments for Monopoly Price Discrimination,June 2010,Tian Xia,Richard J. Sexton,,,Male,Unknown,Mix,,
36.0,4.0,Review of Industrial Organization,12 June 2010,https://link.springer.com/article/10.1007/s11151-010-9250-z,Chart Turnover and Sales in the Recorded Music Industry: 1990–2005,June 2010,Christopher C. Klein,Shea W. Slonaker,,Male,,Unknown,Mix,,
36.0,4.0,Review of Industrial Organization,11 June 2010,https://link.springer.com/article/10.1007/s11151-010-9251-y,Geographical Agglomeration as an Alternative to Vertical Integration,June 2010,Isabel Diez-Vial,Emilio Alvarez-Suescun,,Female,Male,Unknown,Mix,,
36.0,4.0,Review of Industrial Organization,18 July 2010,https://link.springer.com/article/10.1007/s11151-010-9253-9,Quality-Adjusted Prices of Japanese Mobile Phone Handsets and Carriers’ Strategies,June 2010,Naoki Watanabe,Ryo Nakajima,Takanori Ida,Male,,Male,Mix,,
37.0,1.0,Review of Industrial Organization,18 June 2010,https://link.springer.com/article/10.1007/s11151-010-9252-x,Introduction: Economic Issues in Auctions,August 2010,Victor J. Tremblay,,,Male,Unknown,Unknown,Male,,
37.0,1.0,Review of Industrial Organization,25 August 2010,https://link.springer.com/article/10.1007/s11151-010-9257-5,eBay in the Economic Literature: Analysis of an Auction Marketplace,August 2010,Kevin Hasker,Robin Sickles,,Male,,Unknown,Mix,,
37.0,1.0,Review of Industrial Organization,15 July 2010,https://link.springer.com/article/10.1007/s11151-010-9255-7,Efficiency in Second-Price Auctions: A New Look at Old Data,August 2010,Rodney J. Garratt,John Wooders,,Male,Male,Unknown,Male,,6
37.0,1.0,Review of Industrial Organization,13 July 2010,https://link.springer.com/article/10.1007/s11151-010-9256-6,"Measuring the Economic Effect of Global Warming on Viticulture Using Auction, Retail, and Wholesale Prices",August 2010,Orley Ashenfelter,Karl Storchmann,,Unknown,Male,Unknown,Male,,26
37.0,2.0,Review of Industrial Organization,08 October 2010,https://link.springer.com/article/10.1007/s11151-010-9260-x,The Firm Size Distribution and Inter-Industry Diversification,September 2010,John Hutchinson,Jozef Konings,Patrick Paul Walsh,Male,Male,Male,Male,,10
37.0,2.0,Review of Industrial Organization,24 July 2010,https://link.springer.com/article/10.1007/s11151-010-9259-3,Assessing the Efficacy of Structural Merger Remedies: Choosing Between Theories of Harm?,September 2010,Stephen Davies,Matthew Olczak,,Male,Male,Unknown,Male,,3
37.0,2.0,Review of Industrial Organization,24 July 2010,https://link.springer.com/article/10.1007/s11151-010-9258-4,An Empirical Analysis of UK Credit Card Pricing,September 2010,Kevin Amess,Leigh Drake,Helen J. Knight,Male,,Female,Mix,,
37.0,2.0,Review of Industrial Organization,22 September 2010,https://link.springer.com/article/10.1007/s11151-010-9262-8,The Stock Market’s Valuation of R&D and Market Concentration in Horizontal Mergers,September 2010,Ralph M. Sonenshine,,,Male,Unknown,Unknown,Male,,5
37.0,2.0,Review of Industrial Organization,22 September 2010,https://link.springer.com/article/10.1007/s11151-010-9261-9,Common Knowledge Reference Price and Asymmetric Price Adjustments,September 2010,Marc Hofstetter,Jorge Tovar,,Male,Male,Unknown,Male,,8
37.0,3.0,Review of Industrial Organization,20 October 2010,https://link.springer.com/article/10.1007/s11151-010-9266-4,All-Unit Discounts and the Problem of Surplus Division,November 2010,Eberhard Feess,Ansgar Wohlschlegel,,Male,Male,Unknown,Male,,17
37.0,3.0,Review of Industrial Organization,20 October 2010,https://link.springer.com/article/10.1007/s11151-010-9264-6,The Determinants of State-Level Antitrust Activity,November 2010,Robert M. Feinberg,Kara M. Reynolds,,Male,Female,Unknown,Mix,,
37.0,3.0,Review of Industrial Organization,23 October 2010,https://link.springer.com/article/10.1007/s11151-010-9267-3,Short-Run Demand and Uncertainty of Outcome in Major League Baseball,November 2010,Scott Tainsky,Jason A. Winfree,,Male,Male,Unknown,Male,,35
37.0,3.0,Review of Industrial Organization,22 October 2010,https://link.springer.com/article/10.1007/s11151-010-9265-5,"Sunk Costs, Market Contestability, and the Size Distribution of Firms",November 2010,Ioannis N. Kessides,Li Tang,,Male,,Unknown,Mix,,
37.0,3.0,Review of Industrial Organization,30 October 2010,https://link.springer.com/article/10.1007/s11151-010-9263-7,The Application for and the Awarding of Low-Interest Credits to Finance R&D Projects,November 2010,Elena Huergo,Mayte Trenado,,Female,Female,Unknown,Female,,33
37.0,4.0,Review of Industrial Organization,04 November 2010,https://link.springer.com/article/10.1007/s11151-010-9272-6,Introduction: Antitrust and Regulatory Review,December 2010,Lawrence J. White,,,Male,Unknown,Unknown,Male,,
37.0,4.0,Review of Industrial Organization,30 October 2010,https://link.springer.com/article/10.1007/s11151-010-9268-2,"Economics at the FTC: Mergers, Dominant-Firm Conduct, and Consumer Behavior",December 2010,Joseph Farrell,Janis K. Pappalardo,Howard Shelanski,Male,Female,Male,Mix,,
37.0,4.0,Review of Industrial Organization,11 November 2010,https://link.springer.com/article/10.1007/s11151-010-9269-1,The Year in Economics at the FCC: A National Plan for Broadband,December 2010,Jonathan B. Baker,Paul de Sa,,Male,Male,Unknown,Male,,
37.0,4.0,Review of Industrial Organization,07 December 2010,https://link.springer.com/article/10.1007/s11151-010-9271-7,"The Year in Review: Economics at the Antitrust Division, 2009–2010",December 2010,Ken Heyer,Carl Shapiro,,Male,Male,Unknown,Male,,4
37.0,4.0,Review of Industrial Organization,16 November 2010,https://link.springer.com/article/10.1007/s11151-010-9270-8,"Economics at DG Competition, 2009–2010",December 2010,Damien Neven,Miguel de la Mano,,Male,Male,Unknown,Male,,4
38.0,1.0,Review of Industrial Organization,05 February 2011,https://link.springer.com/article/10.1007/s11151-011-9278-8,Does Big Drive Out Small?,January 2011,Mitsuru Igami,,,Male,Unknown,Unknown,Male,,31
38.0,1.0,Review of Industrial Organization,01 February 2011,https://link.springer.com/article/10.1007/s11151-011-9275-y,Subscription Choices and Switching Costs in Mobile Telephony,January 2011,Lukasz Grzybowski,Pedro Pereira,,Unknown,Male,Unknown,Male,,16
38.0,1.0,Review of Industrial Organization,29 January 2011,https://link.springer.com/article/10.1007/s11151-011-9276-x,The Determinants of Pricing in the Mexican Domestic Airline Sector: The Impact of Competition and Airport Congestion,January 2011,Agustin J. Ros,,,Male,Unknown,Unknown,Male,,3
38.0,1.0,Review of Industrial Organization,27 November 2010,https://link.springer.com/article/10.1007/s11151-010-9273-5,Ownership Unbundling in Electricity Distribution: Empirical Evidence from New Zealand,January 2011,Paul H. L. Nillesen,Michael G. Pollitt,,Male,Male,Unknown,Male,,38
38.0,1.0,Review of Industrial Organization,01 December 2010,https://link.springer.com/article/10.1007/s11151-010-9274-4,Multimarket Contact and Intensity of Competition: Evidence from an Airline Merger,January 2011,Volodymyr Bilotkach,,,Male,Unknown,Unknown,Male,,54
38.0,2.0,Review of Industrial Organization,08 March 2011,https://link.springer.com/article/10.1007/s11151-011-9287-7,Introduction: Issues in Network Economics,March 2011,Victor J. Tremblay,,,Male,Unknown,Unknown,Male,,
38.0,2.0,Review of Industrial Organization,09 March 2011,https://link.springer.com/article/10.1007/s11151-011-9288-6,A Short Survey of Network Economics,March 2011,Oz Shy,,,Male,Unknown,Unknown,Male,,83
38.0,2.0,Review of Industrial Organization,20 March 2011,https://link.springer.com/article/10.1007/s11151-011-9289-5,Market Power in US Broadband Services,March 2011,Thomas W. Hazlett,Dennis L. Weisman,,Male,Male,Unknown,Male,,4
38.0,2.0,Review of Industrial Organization,13 March 2011,https://link.springer.com/article/10.1007/s11151-011-9286-8,From Network Externalities to Broadband Growth Externalities: a Bridge not yet Built,March 2011,John W. Mayo,Scott Wallsten,,Male,Male,Unknown,Male,,14
38.0,2.0,Review of Industrial Organization,11 February 2011,https://link.springer.com/article/10.1007/s11151-011-9277-9,The Small Firm in a Quantity Choosing Game: Some Experimental Evidence,March 2011,Owen R. Phillips,Dale J. Menkhaus,John N. Thurow,Male,,Male,Mix,,
38.0,2.0,Review of Industrial Organization,19 February 2011,https://link.springer.com/article/10.1007/s11151-011-9282-z,The Price Effects of Using Firewalls as an Antitrust Remedy,March 2011,Charles J. Thomas,,,Male,Unknown,Unknown,Male,,
38.0,3.0,Review of Industrial Organization,22 February 2011,https://link.springer.com/article/10.1007/s11151-011-9284-x,Introduction: The Centennial of the Standard Oil of New Jersey Decision,May 2011,John Howard Brown,,,Male,Unknown,Unknown,Male,,
38.0,3.0,Review of Industrial Organization,27 February 2011,https://link.springer.com/article/10.1007/s11151-011-9283-y,Standard Oil as a Technological Innovator,May 2011,F. M. Scherer,,,Unknown,Unknown,Unknown,Unknown,,
38.0,3.0,Review of Industrial Organization,01 March 2011,https://link.springer.com/article/10.1007/s11151-011-9285-9,Contracts Versus Price Discrimination: Evidence From the SONJ Case,May 2011,John Howard Brown,,,Male,Unknown,Unknown,Male,,1
38.0,3.0,Review of Industrial Organization,24 February 2011,https://link.springer.com/article/10.1007/s11151-011-9280-1,Standard Oil and Predatory Pricing: Myth Paralleling Fact,May 2011,James A. Dalton,Louis Esposito,,Male,Male,Unknown,Male,,8
38.0,3.0,Review of Industrial Organization,15 February 2011,https://link.springer.com/article/10.1007/s11151-011-9279-7,Of Rebates and Drawbacks: The Standard Oil (N.J.) Company and the Railroads,May 2011,Michael Reksulak,William F. Shughart II,,Male,Male,Unknown,Male,,8
38.0,3.0,Review of Industrial Organization,07 May 2011,https://link.springer.com/article/10.1007/s11151-011-9294-8,Price Spikes in Energy Markets: “Business by Usual Methods” or Strategic Withholding?,May 2011,John Kwoka,Vladlena Sabodash,,Male,Female,Unknown,Mix,,
38.0,4.0,Review of Industrial Organization,12 May 2011,https://link.springer.com/article/10.1007/s11151-011-9293-9,Introduction: Antitrust and the Dynamics of Competition in High-Tech Industries,June 2011,Thomas M. Lenard,,,Male,Unknown,Unknown,Male,,3
38.0,4.0,Review of Industrial Organization,19 June 2011,https://link.springer.com/article/10.1007/s11151-011-9298-4,Antitrust in High-Tech Industries,June 2011,Robert W. Crandall,Charles L. Jackson,,Male,Male,Unknown,Male,,7
38.0,4.0,Review of Industrial Organization,03 May 2011,https://link.springer.com/article/10.1007/s11151-011-9291-y,Antitrust and Vertical Integration in “New Economy” Industries with Application to Broadband Access,June 2011,Bruce M. Owen,,,Male,Unknown,Unknown,Male,,8
38.0,4.0,Review of Industrial Organization,04 June 2011,https://link.springer.com/article/10.1007/s11151-011-9297-5,Does Antitrust Enforcement in High Tech Markets Benefit Consumers? Stock Price Evidence from FTC v. Intel,June 2011,Joshua D. Wright,,,Male,Unknown,Unknown,Male,,6
38.0,4.0,Review of Industrial Organization,31 May 2011,https://link.springer.com/article/10.1007/s11151-011-9295-7,Cloud Computing: Architectural and Policy Implications,June 2011,Christopher S. Yoo,,,Male,Unknown,Unknown,Male,,34
38.0,4.0,Review of Industrial Organization,12 May 2011,https://link.springer.com/article/10.1007/s11151-011-9296-6,"“High-Tech” Antitrust: Incoherent, Misguided, Obsolete, or None of the Above? Comments on Crandall-Jackson and Wright",June 2011,Timothy J. Brennan,,,Male,Unknown,Unknown,Male,,2
38.0,4.0,Review of Industrial Organization,07 May 2011,https://link.springer.com/article/10.1007/s11151-011-9292-x,Discussion of Papers by Bruce Owen and Christopher Yoo,June 2011,Michael Salinger,,,Male,Unknown,Unknown,Male,,1
39.0,1.0,Review of Industrial Organization,22 July 2011,https://link.springer.com/article/10.1007/s11151-011-9312-x,Symposium: The 2010 Horizontal Merger Guidelines: Editor’s Introduction,August 2011,Roger D. Blair,,,Male,Unknown,Unknown,Male,,2
39.0,1.0,Review of Industrial Organization,18 June 2011,https://link.springer.com/article/10.1007/s11151-011-9301-0,Harm to Competition Under the 2010 Horizontal Merger Guidelines,August 2011,Herbert Hovenkamp,,,Male,Unknown,Unknown,Male,,5
39.0,1.0,Review of Industrial Organization,13 July 2011,https://link.springer.com/article/10.1007/s11151-011-9307-7,"Unilateral Competitive Effects of Mergers: Upward Pricing Pressure, Product Quality, and Other Extensions",August 2011,Robert Willig,,,Male,Unknown,Unknown,Male,,37
39.0,1.0,Review of Industrial Organization,01 July 2011,https://link.springer.com/article/10.1007/s11151-011-9303-y,Coordinated Effects in the 2010 Horizontal Merger Guidelines,August 2011,Wayne-Roy Gayle,Robert C. Marshall,Jean-François Richard,Unknown,Male,Unknown,Male,,2
39.0,1.0,Review of Industrial Organization,05 July 2011,https://link.springer.com/article/10.1007/s11151-011-9306-8,The Efficiencies Defense in the 2010 Horizontal Merger Guidelines,August 2011,Roger D. Blair,Jessica S. Haynes,,Male,Female,Unknown,Mix,,
39.0,1.0,Review of Industrial Organization,22 June 2011,https://link.springer.com/article/10.1007/s11151-011-9302-z,Market Definition?,August 2011,John E. Lopatka,,,Male,Unknown,Unknown,Male,,6
39.0,1.0,Review of Industrial Organization,06 July 2011,https://link.springer.com/article/10.1007/s11151-011-9311-y,Brown Shoe Versus the Horizontal Merger Guidelines,August 2011,Keith N. Hylton,,,Male,Unknown,Unknown,Male,,3
39.0,1.0,Review of Industrial Organization,14 July 2011,https://link.springer.com/article/10.1007/s11151-011-9305-9,Market Definition and the Merger Guidelines,August 2011,Louis Kaplow,,,Male,Unknown,Unknown,Male,,16
39.0,1.0,Review of Industrial Organization,22 July 2011,https://link.springer.com/article/10.1007/s11151-011-9313-9,Proper Treatment of Buyer Power in Merger Review,August 2011,Dennis W. Carlton,Mark Israel,,Male,Male,Unknown,Male,,17
39.0,1.0,Review of Industrial Organization,17 July 2011,https://link.springer.com/article/10.1007/s11151-011-9314-8,Considerations of Countervailing Power,August 2011,Roger D. Blair,Christina DePasquale,,Male,Female,Unknown,Mix,,
39.0,1.0,Review of Industrial Organization,08 July 2011,https://link.springer.com/article/10.1007/s11151-011-9309-5,The Sound of One Hand Clapping: The 2010 Merger Guidelines and the Challenge of Judicial Adoption,August 2011,Judd E. Stone,Joshua D. Wright,,Male,Male,Unknown,Male,,2
39.0,1.0,Review of Industrial Organization,06 July 2011,https://link.springer.com/article/10.1007/s11151-011-9310-z,The 2010 Revised Merger Guidelines and Modern Industrial Economics,August 2011,Michael A. Salinger,,,Male,Unknown,Unknown,Male,,5
40.0,1.0,Review of Industrial Organization,28 December 2011,https://link.springer.com/article/10.1007/s11151-011-9328-2,"Last-Minute Bidding in Sequential Auctions with Unobserved, Stochastic Entry",February 2012,Kenneth Hendricks,Ilke Onur,Thomas Wiseman,Male,,Male,Mix,,
40.0,1.0,Review of Industrial Organization,12 August 2011,https://link.springer.com/article/10.1007/s11151-011-9316-6,Does Distance Matter Less Now? The Changing Role of Geography in Biotechnology Innovation,February 2012,Daniel K. N. Johnson,Kristina M. Lybecker,,Male,Female,Unknown,Mix,,
40.0,1.0,Review of Industrial Organization,04 January 2012,https://link.springer.com/article/10.1007/s11151-011-9330-8,Risk Aversion and Tacit Collusion in a Bertrand Duopoly Experiment,February 2012,Lisa R. Anderson,Beth A. Freeborn,Jason P. Hulbert,Female,Female,Male,Mix,,
40.0,1.0,Review of Industrial Organization,03 August 2011,https://link.springer.com/article/10.1007/s11151-011-9317-5,"Competition in the Korean Internet Portal Market: Network Effects, Profit, and Market Efficiency",February 2012,Dong Ook Choi,Jongeun Oh,Junseok Hwang,,Unknown,Unknown,Mix,,
40.0,1.0,Review of Industrial Organization,04 August 2011,https://link.springer.com/article/10.1007/s11151-011-9315-7,A Note on the Consequences of Monopsony When Goods are Jointly Produced in Fixed Proportions,February 2012,Roger D. Blair,Jessica S. Haynes,,Male,Female,Unknown,Mix,,
40.0,2.0,Review of Industrial Organization,25 January 2012,https://link.springer.com/article/10.1007/s11151-012-9335-y,Introduction: Market Structure and Efficiency,March 2012,Victor J. Tremblay,,,Male,Unknown,Unknown,Male,,
40.0,2.0,Review of Industrial Organization,03 February 2012,https://link.springer.com/article/10.1007/s11151-012-9338-8,Market Structure and Market Performance,March 2012,Stephen Martin,,,Male,Unknown,Unknown,Male,,13
40.0,2.0,Review of Industrial Organization,03 February 2012,https://link.springer.com/article/10.1007/s11151-012-9339-7,A New Method for Estimating Market Power with an Application to Norwegian Sawmilling,March 2012,Subal C. Kumbhakar,Sjur Baardsen,Gudbrand Lien,Unknown,Male,Male,Male,,54
40.0,2.0,Review of Industrial Organization,03 February 2012,https://link.springer.com/article/10.1007/s11151-012-9336-x,Collinearity in Linear Structural Models of Market Power,March 2012,Jeffrey M. Perloff,Edward Z. Shen,,Male,Male,Unknown,Male,,19
40.0,2.0,Review of Industrial Organization,25 January 2012,https://link.springer.com/article/10.1007/s11151-012-9334-z,Market Power and Technology,March 2012,Rolf Färe,Shawna Grosskopf,Victor J. Tremblay,Male,Female,Male,Mix,,
40.0,2.0,Review of Industrial Organization,17 February 2012,https://link.springer.com/article/10.1007/s11151-012-9341-0,Acknowledgement,March 2012,,,,Unknown,Unknown,Unknown,Unknown,,
40.0,3.0,Review of Industrial Organization,30 October 2011,https://link.springer.com/article/10.1007/s11151-011-9322-8,Peak-Load Versus Discriminatory Pricing: Evidence from the Golf Industry,May 2012,Frank F. Limehouse,Michael T. Maloney,Kurt W. Rotthoff,Male,Male,Male,Male,,5
40.0,3.0,Review of Industrial Organization,01 November 2011,https://link.springer.com/article/10.1007/s11151-011-9323-7,Franchise Fees and Royalties: Theory and Empirical Results,May 2012,Masayoshi Maruyama,Yu Yamashita,,Male,,Unknown,Mix,,
40.0,3.0,Review of Industrial Organization,04 August 2011,https://link.springer.com/article/10.1007/s11151-011-9318-4,Construction Procurement Auctions: Do Entrant Bidders Employ More Aggressive Strategies than Incumbent Bidders?,May 2012,Sheng Li,Peter Philips,,,Male,Unknown,Mix,,
40.0,3.0,Review of Industrial Organization,08 June 2011,https://link.springer.com/article/10.1007/s11151-011-9299-3,Public Procurement Auctions and Competition in Turkey,May 2012,İlke Onur,Rasim Özcan,Bedri Kamil Onur Taş,Female,Male,Male,Mix,,
40.0,3.0,Review of Industrial Organization,12 October 2011,https://link.springer.com/article/10.1007/s11151-011-9321-9,Reserve Prices in Repeated Auctions,May 2012,Octavian Carare,,,Male,Unknown,Unknown,Male,,5
40.0,4.0,Review of Industrial Organization,16 February 2012,https://link.springer.com/article/10.1007/s11151-012-9340-1,Vertical Integration and Costly Demand Information in Regulated Network Industries,June 2012,Elisabetta Iossa,Francesca Stroffolini,,Female,Female,Unknown,Female,,3
40.0,4.0,Review of Industrial Organization,22 December 2011,https://link.springer.com/article/10.1007/s11151-011-9329-1,An Empirical Analysis of the Average Plant Start-Up Size in Turkish Manufacturing Industries,June 2012,Seyit Mümin Cilasun,Burak Günalp,,Male,Male,Unknown,Male,,1
40.0,4.0,Review of Industrial Organization,03 January 2012,https://link.springer.com/article/10.1007/s11151-011-9331-7,Discounts and Public Service Obligations in the Airline Market: Lessons from Spain,June 2012,Joan Calzada,Xavier Fageda,,Female,Male,Unknown,Mix,,
40.0,4.0,Review of Industrial Organization,04 January 2012,https://link.springer.com/article/10.1007/s11151-011-9332-6,Yardstick Competition to Elicit Private Information: An Empirical Analysis,June 2012,Ayako Suzuki,,,Female,Unknown,Unknown,Female,,2
40.0,4.0,Review of Industrial Organization,17 January 2012,https://link.springer.com/article/10.1007/s11151-012-9333-0,Estimating Market Power with Weak A Priori Information: An Exploratory Approach to the Model-Specification Problem,June 2012,Carlo Russo,,,Male,Unknown,Unknown,Male,,1
41.0,1.0,Review of Industrial Organization,17 February 2012,https://link.springer.com/article/10.1007/s11151-012-9342-z,Introduction: Embracing Competition in the World’s Second Giant Economy: China’s 2008 Anti-Monopoly Law,August 2012,David K. Round,Ping Lin,,Male,,Unknown,Mix,,
41.0,1.0,Review of Industrial Organization,02 March 2012,https://link.springer.com/article/10.1007/s11151-012-9343-y,China’s Antimonopoly Law 2008: An Overview,August 2012,Allan Fels,,,Male,Unknown,Unknown,Male,,3
41.0,1.0,Review of Industrial Organization,24 March 2012,https://link.springer.com/article/10.1007/s11151-012-9349-5,China’s Anti-Monopoly Law: What is the Welfare Standard?,August 2012,Pingping Shan,Guofu Tan,Michael A. Williams,Unknown,Unknown,Male,Male,,10
41.0,1.0,Review of Industrial Organization,25 February 2012,https://link.springer.com/article/10.1007/s11151-012-9344-x,New Wine into Old Wineskins: Recent Developments in China’s Competition Policy Against Monopolistic/Collusive Agreements,August 2012,Xinzhu Zhang,Vanessa Yanhua Zhang,,Unknown,Female,Unknown,Female,,4
41.0,1.0,Review of Industrial Organization,01 March 2012,https://link.springer.com/article/10.1007/s11151-012-9346-8,Abuse of Market Dominance Under China’s 2007 Anti-monopoly Law: A Preliminary Assessment,August 2012,Zhiyong Liu,Yue Qiao,,Unknown,,Unknown,Mix,,
41.0,1.0,Review of Industrial Organization,04 April 2012,https://link.springer.com/article/10.1007/s11151-012-9345-9,Merger Control Policy Under China’s Anti-Monopoly Law,August 2012,Ping Lin,Jingjing Zhao,,,Unknown,Unknown,Mix,,
41.0,1.0,Review of Industrial Organization,28 March 2012,https://link.springer.com/article/10.1007/s11151-012-9351-y,A Tiger Without Teeth? Regulation of Administrative Monopoly Under China’s Anti-Monopoly Law,August 2012,Changqi Wu,Zhicheng Liu,,Unknown,Unknown,Unknown,Unknown,,
42.0,1.0,Review of Industrial Organization,10 August 2012,https://link.springer.com/article/10.1007/s11151-012-9358-4,Entry and Exit Behavior in the Absence of Sunk Costs: Evidence from a Price Comparison Site,February 2013,Michelle Haynes,Steve Thompson,,Female,Male,Unknown,Mix,,
42.0,1.0,Review of Industrial Organization,09 October 2012,https://link.springer.com/article/10.1007/s11151-012-9361-9,The Strategic Effect of Bundling: A New Perspective,February 2013,Andrea Mantovani,,,Female,Unknown,Unknown,Female,,9
42.0,1.0,Review of Industrial Organization,15 April 2012,https://link.springer.com/article/10.1007/s11151-012-9352-x,Promotional Competition Between Supermarket Chains,February 2013,Richard J. Volpe,,,Male,Unknown,Unknown,Male,,11
42.0,1.0,Review of Industrial Organization,09 August 2012,https://link.springer.com/article/10.1007/s11151-012-9357-5,Proliferation of Brewers’ Brands and Price Uniformity in Canadian Beer Markets,February 2013,Andrew Eckert,Douglas S. West,,Male,Male,Unknown,Male,,5
42.0,1.0,Review of Industrial Organization,02 October 2012,https://link.springer.com/article/10.1007/s11151-012-9359-3,The Stability of Market Shares in Liner Shipping,February 2013,Mike Fusillo,,,Male,Unknown,Unknown,Male,,8
42.0,2.0,Review of Industrial Organization,14 December 2012,https://link.springer.com/article/10.1007/s11151-012-9370-8,"Alfred E. Kahn, 1917–2010",March 2013,Paul L. Joskow,Roger G. Noll,,Male,Male,Unknown,Male,"This special compendium is fondly dedicated to the life of Alfred E. Kahn. The essays were written by Fred’s friends and collaborators over several decades, and cover only some of the disparate topics in which Fred made significant contributions as a scholar and policy maker. Fred Kahn had an extraordinary career as an academic, regulator, advisor to governments and industry, and public intellectual. His academic research demonstrated a strong commitment to the value of applying sound microeconomics principles to public policy issues—primarily to issues that are associated with the field of industrial organization. Although Fred belonged to the last generation of economists who could attain high status in the profession without making extensive use of formal mathematical and econometric models, the reasoning of microeconomic theory always provided the intellectual framework for his approach to public policy analysis as a scholar, regulator, consultant, and advisor. Most of Fred’s academic work focused on public policy responses to market imperfections in an “imperfect world” in which perfect competition was not feasible due to the attributes of the products and production processes that characterize most interesting industries. At the same time, his experiences as a regulator and business consultant affected his views on the extent to which strict application of microeconomics principles could solve policy problems in a world that is characterized by irresolvable market imperfections as well as regulatory imperfections, political constraints, and other non-economic considerations. Fred’s analysis went beyond simply identifying the (second) best economic policies for markets that are inherently imperfectly competitive. Fred’s main focus was on how to use economic analysis to solve public policy problems in ways that recognize a broad array of economic and institutional imperfections (Kahn 1966). His interest in answering the question “what is the best that we can do in an imperfect world?” never changed. But the scope of the imperfections that he found incorporated into his analysis expanded significantly as he gained more practical experience. And, not surprisingly, his policy prescriptions changed as he expanded the range of imperfections that, he believed, ought to be taken into account. Fred is best known for his two-volume book, The Economics of Regulation (Kahn 1970a, 1971), and his service as Chair of the New York Public Services Commission (the state’s regulator of gas, electric and telephone utilities) during 1974–1977, the Civil Aeronautics Board (then the federal regulator of the airline industry) during 1977–1978, and the Council on Wage and Price Stability (the “inflation Czar” for President Carter) during 1978–1980. But Fred also made numerous contributions on other policy issues as well. While Fred is best known as a scholar for his publications on antitrust and regulation, his early work included articles on the structure and behavior of large firms, patent policy, international trade, and development economics. Here we review many, but not all, of his scholarly contributions and relate them to the policy milieu in which they were written—and that Fred hoped to influence.",3
42.0,2.0,Review of Industrial Organization,29 November 2012,https://link.springer.com/article/10.1007/s11151-012-9367-3,Effective and Equitable Adoption of Opt-In Residential Dynamic Electricity Pricing,March 2013,S. Borenstein,,,Unknown,Unknown,Unknown,Unknown,,
42.0,2.0,Review of Industrial Organization,01 February 2013,https://link.springer.com/article/10.1007/s11151-013-9376-x,Spectrum Auction Design,March 2013,Peter Cramton,,,Male,Unknown,Unknown,Male,"Fred Kahn recognized the important role of market design in improving how markets work. He believed that prices should be set in an open competitive process, rather than administratively. I had the pleasure of working with Fred on a project to evaluate the pricing rule in California’s electricity market. We examined whether the electricity market should use uniform pricing or pay-as-bid pricing (Kahn et al. 2001). In this tribute to Fred Kahn, I also focus on auction design, but in the communications industry. Spectrum auctions have been used by governments to assign and price spectrum for about 20 years. Over those years, the simultaneous ascending auction, first introduced in the US in 1994, has been the predominant method of auctioning spectrum. The auctions have proved far superior to the prior methods of beauty contests and lotteries (Cramton 1997; Milgrom 2004). Despite the generally positive experience with the simultaneous ascending auction, several design issues have surfaced. Some were addressed with minor rule changes. For example, bidders’ use of trailing digits to signal other bidders and support tacit collusion was eliminated by limiting bids to integer multiples of the minimum increment (Cramton and Schwartz 2002). However, many other design problems remain. In this paper, I identify these problems, and describe a new approach—the combinatorial clock auction—which is based primarily on the clock-proxy auction (Ausubel et al. 2006), which addresses the main limitations of the simultaneous ascending auction. My focus here is on spectrum auction design, rather than spectrum policy more generally. Certainly, communications regulators face many other critical challenges, such as how best to free up new spectrum for auction (Cramton et al. 1998), or whether an auction is needed at all (Federal Communications Commission 2002). For some allocations, it is better to set aside the spectrum for common property use, as is done with unlicensed spectrum. In particular, for applications that do not create additional scarcity, the commons model is better than the auction model. There are many examples of this: garage door openers, car locks, and other device controllers, but the most important is Wi-Fi. These application require little bandwidth or power, and thus, do not make the spectrum scarce. Scarcity problems are mitigated by operator separation. In contrast, mobile phones require much greater power and bandwidth, creating spectrum scarcity, and hence an auction is needed to assign the scarce resource among the competing carriers. Spectrum auctions to date have been long-term auctions in which the winner is granted a license for 10–25 years, with a strong expectation of renewal following expiration. One might think instead that a spot market for spectrum, much like a spot market for electricity, would be a more flexible and efficient instrument. Someday that will be true. But today’s hardware, especially the handset, is not sufficiently flexible to accommodate a real-time spot market. Moreover, carriers must make large specific investments in their networks. These long-term investments are better supported with a long-term license for spectrum, which is a critical input. Over the next 20 years increasingly flexible hardware will be introduced. Eventually it will make sense to organize the spectrum market much like the electricity market. The basic element will be a real-time spot market that establishes the price of bandwidth at a particular time and location. But for now, long-term spectrum auctions are both necessary and desirable. One of the greatest challenges for the regulator is keeping up with the rapid technological development of wireless communications. Indeed, one of the main reasons for switching from beauty contests, to lotteries, to auctions was that beauty contests and lotteries were too slow. Wireless communications plays an essential role in modern economies, both in developed and developing countries. Slowing the pace of wireless innovation and development has large costs to economic growth. For this reason, regulators must do whatever they can to promote a competitive wireless industry. Allocating sufficient spectrum in a timely manner is paramount. The combinatorial clock auction described here helps facilitate the spectrum allocation process by enabling the auction to determine how the spectrum is organized, which is called the band plan. Prior methods required that the regulator determine a fixed band plan before the auction began. As a result, before each auction there is a long regulatory process, much like the beauty contests of before, but with the companies’ lobbying for particular band plans, rather than for direct spectrum awards. This is the most time-consuming and error-prone element of the spectrum management process. Thus, the new approach promises not only to improve spectrum assignments, but also to improve the band plans within which the assignments fit, and to do so with less delay. From an auction theory viewpoint, spectrum auctions are both challenging and interesting. The government is auctioning many items that are heterogeneous but similar. Often there are competing technologies as well as companies to provide a wide range of communication services. As a result, the setting has a complex structure of substitutes and complements. This is among the most difficult auction settings that are seen in practice. The goal for the government should be efficiency, not revenue maximization. The government should focus on ensuring that those who can put the spectrum to its highest use get it. Focusing simply on revenue maximization is short-sighted. Many steps such as technical and service flexibility, and license aggregation and disaggregation, improve efficiency and thereby improve revenues. But short-run revenue maximization by creating monopolies, which would create the highest profits before spectrum fees, and therefore would sustain the largest fees, should be resisted. Indeed, competition, which ultimately will lead to greater innovation and better and cheaper services, will likely generate greater government revenues from a long-run perspective. The government can best accomplish this objective with an efficient auction that puts the spectrum to its best use. The regulator may find it necessary to introduce spectrum caps or other preferences that favor new entrants so as to level the playing field between incumbents and new entrants (Cramton et al. 2011). Incumbents include in their private value the benefit of foreclosing competition, thus driving a wedge between social value and private value. In theory the regulator can correct this externality by favoring the new entrant, but in practice this has proven to be difficult. The FCC’s experience with preferences for certain bidders-set-asides, bidding credits, and installment payments-has been disappointing, at least with respect to mobile broadband communication, which is where most of the value lies. In contrast, a good example of successful intervention was Canada’s use of set asides in its 2008 Advanced Wireless Services or AWS auction. As a result, multiple deep-pocketed new entrants came to the auction and bid up the price of not only the set-aside blocks, but also the non-set-aside blocks. The result was a much more competitive auction (with much higher revenues) and the introduction prospectively of some potentially strong new service providers. The approach effectively broke up regional market-splitting by the dominant incumbents. Another successful intervention was the FCC’s use of a spectrum cap in early broadband PCS auctions. The cap limited the quantity of spectrum that any one carrier could hold in a geographic area, which addressed the potential market failure of limited competition in the market for wireless services. Despite these successes in Canada and the US, the FCC’s long and sometimes troubled history with bidder preferences is an important case study for other countries that are considering preferences for various parties. Installment payments proved especially problematic, as it led to speculative bidding, bankruptcy, and lengthy delay in the use of the spectrum. In addition, the regulator must resist the temptation to force more “winners” than the market can efficiently support. Sometimes regulators fragment the spectrum and prohibit aggregation in the auction in an effort to create as many winners as possible. The India 3G spectrum auction may be one example. Aggregation up to a suitable competitive constraint is preferred. There are three main points that I wish to emphasize: First, in terms of the auction design, it is important to enhance the substitution across the items that are being sold. Enhanced substitution is accomplished through both the product design—what is auctioned—and the auction format. Often in the spectrum setting, the product design can be just as important as the auction design. Second, encouraging price discovery is extremely important. We need a dynamic process, because unlike some situations, in the case of spectrum auctions, there is much uncertainty about what things are worth. The bidders need to do a considerable amount of homework to develop a crude valuation model, and they need the benefit of some collective market insights, which can be revealed in a dynamic auction process, in order to improve their decision-making. The nice thing about a dynamic auction is that through this price process the bidders gradually have their sights focused on the most relevant part of the price space. Focusing bidder decisions on what is relevant is in my mind the biggest source of benefit from the dynamic process. This benefit is generally ignored by economists, because economists assume that the bidders fully understand their valuation models, when in practice bidders almost never have a completely specified valuation model. Yes, they do a lot of homework, but there is still much uncertainty about what spectrum lots are worth, and how they should be valuing the spectrum. The experience of the 3G spectrum auctions in Europe is a good example. The bids were based more on stock prices in a bubble situation, rather than on solid analysis about values. The third feature that I wish to emphasize is the importance of inducing truthful bidding. This is accomplished in the auction design through an effective pricing rule and an activity rule. The two rules work together to encourage bidders truthfully to express preferences throughout the entire auction. This truthful expression of preferences is what leads to excellent price discovery and ultimately an efficient auction outcome. A variety of different pricing rules are used in practice. The two most common are pay-as-bid pricing, where the bidder pays what it bid if it is a winner, and for a homogenous product, uniform pricing, where the bidder pays the market-clearing price. In the particular applications I am discussing here, there generally are not clearing prices, because of strong complementarities and heterogeneous items. As a result, a new kind of pricing rule is needed. The pricing rule that I will describe in detail later is a generalization of Vickrey’s second-price rule. I now give a brief overview of the combinatorial clock auction. The approach may appear complex. Some amount of complexity is required given the complex economic problem. Simpler versions, such as a simultaneous clock auction are possible in settings where all bidders intend to use the same technology. This may well be the case in developing countries that are conducting spectrum auctions for a particular use after the technology battles have been resolved from the experience in developed countries. The combinatorial clock auction is especially useful in situations where the regulator does not know which technology will make the best use of the spectrum. In such cases, the auction itself can determine the ultimate band plan that specifies how the spectrum is organized. Such an auction is said to be technology neutral, since it allows the competing technologies to determine the winning technologies, as well as carriers. A good example is an auction that accommodates both paired and unpaired technologies, such as LTE and WiMAX, respectively. A combinatorial auction is essential in this case, since the two uses require that the spectrum be organized in fundamentally different ways. The combinatorial clock auction is an especially simple, yet powerful, auction that lets competitive bids determine the ultimate band plan. The combinatorial clock auction has features to address each of my three main points. First, the product design simplifies the products whenever possible. For example, if bidders primarily care about the quantity of spectrum that they win in a geographic area, the auction should involve generic spectrum (if possible), and the bidders bid for a quantity of spectrum in each area. This simplifies the auction, enhances substitution, and improves competition. The specific assignment of spectrum lots is determined in the last stage of the auction, once the critical decisions have been made (who won how much in each area). This approach also allows a technology neutral auction, which lets the spectrum be organized in different ways for the different technologies. Each bidder indicates the quantity of spectrum and the type of use in its bids. In this case, the first stage of the auction determines not only who won how much in each area, but also the overall quantity of spectrum that is allocated for a particular use in the area. Second, to encourage price discovery, the auction begins with a “clock” stage (i.e., each auction in the simultaneous auction process has a “clock” that shows the most recent bid price). Prices ascend for each product with excess demand until there is no excess demand for any product. This simple and familiar price discovery process works extremely well when bidders have incentives for truthful bidding. In the important case of substitutes, the clock stage determines an efficient assignment together with supporting competitive equilibrium prices. Moreover, complements are handled with no increase in the complexity of the clock process. Each bid in the clock stage is a package bid, so bidders can bid without fear of winning only some of what they need. Bidders may find that they are unable to express preferences for all of the desirable packages in the clock stage, so following the clock stage is a supplementary round. Bidders can increase their bids on packages on which they bid in the clock stage and submit new bids on other packages. All of the clock stage bids and the supplementary round bids then are run through an optimizer to determine the value-maximizing assignment of the spectrum. This is the generic assignment. Third, to induce truthful bidding, the auction uses Vickrey-nearest-core pricing. The efficient assignment is priced to minimize the bidders’ total payments subject to competitive constraints (no group of bidders has offered the seller more). In practice, this often implies Vickrey pricing, ensuring truthful bidding. However, because of complements, there may be one or more competitive constraints that cause the payments to be greater than Vickrey payments for some bidders. In this event, the smallest deviations from Vickrey prices are used. To induce truthful bidding throughout the clock stage, an activity rule based on revealed preference is used. This rule encourages bidders to bid in the straightforward manner of selecting the most profitable package in each round. Deviations from bidding on the most profitable package throughout the clock stage may impose a constraint on subsequent bids, either later in the clock stage or in the supplementary round. Once the generic assignments are determined and priced, the specific assignment stage is run. Each winner submits top-up bids for each specific assignment that is better than the winner’s worst specific assignment. The bids indicate the incremental value for each feasible alternative. Then an optimization program is run to determine the efficient specific assignment. Again the prices for the specific assignments are Vickrey-nearest-core prices. This concludes the auction. This paper builds on well-developed literatures in auction theory and practice–especially combinatorial auctions and spectrum auctions. Much of the literature on combinatorial auctions is summarized in Cramton et al. (2006). The work of Ausubel et al. (2006), Ausubel and Milgrom (2006a, b), Day and Raghavan (2007), Day and Milgrom (2008), Day and Cramton (2012), Milgrom (2007, 2010), Parkes (2006) and Porter et al. (2003) is especially relevant. On spectrum auctions see Coase (1959) for the original proposal, Ausubel et al. (1997) on synergies, McMillan (1994), Cramton (1995, 1997, 2006), Klemperer (2004) and Milgrom (2004) on the performance of the simultaneous ascending auctions, and Brusco and Lopomo (2002) and Cramton and Schwartz (2002) on collusion. Kagel et al. (2010) experimentally compare the simultaneous ascending auction with a particular ascending combinatorial auction, which differs significantly from the one presented here. I begin by describing some of the problems of the simultaneous ascending auction. Then I present the combinatorial clock auction, which retains the benefits, while addressing the weaknesses, of the simultaneous ascending auction. I emphasize two essential elements of the combinatorial clock auction: the pricing rule and the activity rule. Along the way, I summarize both experimental and field results with the combinatorial clock auction. The combinatorial clock auction is of great practical interest. The design has been adopted for major spectrum auctions in many countries over three continents.",104
42.0,2.0,Review of Industrial Organization,03 January 2013,https://link.springer.com/article/10.1007/s11151-012-9373-5,Alfred E. Kahn: Regulator and Language Maven,March 2013,Robert H. Frank,,,Male,Unknown,Unknown,Male,"Kahn’s reputation made him a natural choice to head New York State’s Public Service Commission, a post to which he was appointed in 1974 by then New York Governor Hugh Carey. Kahn understood that only a few simple principles do most of the heavy lifting in economics. The most important among these is the basic cost-benefit principle, which says, “Take an action if and only if its benefit is greater than its cost.” Kahn’s strategy as a regulator was to make sure that consumers had an incentive to apply that principle (expressed in terms of social benefit and social cost) when using the services of public utilities. His main focus at the PSC, therefore, was to require the state’s utilities to confront customers with prices that were based on the relevant marginal costs. Because almost every proposed change in policy creates both losers and winners, this effort was inevitably controversial. A case in point was his proposal to discontinue the telephone companies’ wasteful practice of providing free directory assistance for customers. Directory assistance operators and the equipment that they used were costing the companies—and hence ratepayers—a lot of money, even though in most cases they were merely providing numbers that consumers could have easily looked up themselves. Even so, Mr. Kahn’s proposal to institute a 10-cent charge for each directory-assistance call generated a firestorm of protest. Social scientists solemnly testified that the change would disrupt vital communication networks in communities. Ever the pragmatist, Mr. Kahn amended his proposal by adding a 30-cent credit on every subscriber’s monthly bill, paid for out of the savings made possible by the reduced volume of directory assistance calls. Opposition to the measure evaporated immediately. Today, a return to providing that service without charge would seem unthinkable. Anyone who fails to appreciate the decisive role that distributional concerns can play in public policy debates would do well to study this episode carefully. Kahn also met stiff resistance in his efforts to confront electric utility customers with the prices based on marginal cost. When he began his tenure at the PSC, the rate per kilowatt-hour for electricity in New York State was the same, no matter what time of day, or in what season, it was used. That rate structure encourages waste, he explained, because electricity is much more expensive to produce and distribute at some times than at others. Charging the same rate at all times results in utilities serving more of their peak loads with expensive auxiliary generators. If rates during peak demand periods reflected those higher costs, he argued, consumers would face powerful incentives to shift their demands to off-peak periods, thereby saving everyone a lot of money. But here, too, any change in rate structures would inevitably produce both winners and losers, and it’s an iron law of politics that prospective losers from any change are much more vocal than potential winners. Because those whose rates would increase under the new proposals did indeed resist vigorously, time-of-day and seasonal rate differentials were not widely adopted during Kahn’s tenure at the PSC. But he launched that important conversation, with the result that customers in most of the state’s service areas today have at least the option of consuming their electricity under pricing schedules that explicitly recognize hourly and seasonal variations in the cost of providing service.",1
42.0,2.0,Review of Industrial Organization,25 November 2012,https://link.springer.com/article/10.1007/s11151-012-9366-4,Telecommunication in the US: From Regulation to Competition (Almost),March 2013,Jerry A. Hausman,William E. Taylor,,Male,Male,Unknown,Male,,10
42.0,2.0,Review of Industrial Organization,09 February 2013,https://link.springer.com/article/10.1007/s11151-013-9377-9,Acknowledgement,March 2013,,,,Unknown,Unknown,Unknown,Unknown,,
42.0,3.0,Review of Industrial Organization,15 February 2013,https://link.springer.com/article/10.1007/s11151-012-9365-5,Consumers’ Reactions to Negative Information on Product Quality: Evidence from Scanner Data,May 2013,Maria De Paola,Vincenzo Scoppa,,Female,Male,Unknown,Mix,,
42.0,3.0,Review of Industrial Organization,08 February 2013,https://link.springer.com/article/10.1007/s11151-012-9364-6,Countervailing Power and Chain Stores,May 2013,David E. Mills,,,Male,Unknown,Unknown,Male,,3
42.0,3.0,Review of Industrial Organization,27 December 2012,https://link.springer.com/article/10.1007/s11151-012-9372-6,Edgeworth Price Cycles in Gasoline: Evidence from the United States,May 2013,Paul R. Zimmerman,John M. Yun,Christopher T. Taylor,Male,Male,Male,Male,"A number of recent studies have found a repeating, asymmetric, and cyclical pattern in retail gasoline prices, with a sharp and large price increase followed by smaller gradual price decreases. This type of pricing pattern corresponds with that predicted by Maskin and Tirole (1988) in their theoretical Edgeworth price cycle model. In that model, a large price increase by one firm is followed by the other firms’ undercutting that price. The subsequent price cuts continue until the price nears marginal cost, which triggers another restoration. This model implicitly suggests some form of price leadership. We examine how widespread and persistent price cycling is in the United States over a 15-year period (1996–2010) for 350 Metropolitan Statistical Areas (MSAs). While other studies such as Doyle et al. (2010) and Lewis (2009) examine data on gasoline pricing in the United States and find price cycling is a Midwestern phenomenon, a finding we confirm, our data set is long enough that the earlier observations predate cycling. Specifically, our results show that the ongoing price cycles began in 2000 and generally occur in seven states that are located in the Midwest: Illinois, Indiana, Kentucky, Michigan, Minnesota, Missouri, and Ohio. Prior to 2000, we find no MSA with cycling behavior. This is the first paper that has been able to identify when cycling in the Midwest began and which MSAs began to cycle first. Other researchers have examined whether cycling is ultimately harmful or beneficial to consumers on the basis of a cross sectional analysis; see, e.g., Doyle et al. (2010). We are able to analyze this question using panel data and a difference-in-differences framework. We find that prices in cycling MSAs are lower after they began cycling by between 0.75 and 1 cent per gallon. While this is a small effect relative to the average price of gasoline, it is a sizeable effect relative to the retail margin.Footnote 1 Since we are using a reduced form difference-in-differences model, we are not able to make conclusive findings with regard to causality. However, the lower prices are consistent with the hypothesis that price cycling is a form of retail price war, as was the case with prior episodes of price cycling in the US during the 1970s.Footnote 2
 The next section of the paper reviews the literature on price cycles. The third section details the data and the methodology that are used to identify price cycles and discusses which MSAs cycle and when. The fourth section examines the price effects of cycling using a difference-in-differences estimator. The fifth section examines possible causes of cycling. The sixth section of the paper presents conclusions.",20
42.0,3.0,Review of Industrial Organization,09 June 2012,https://link.springer.com/article/10.1007/s11151-012-9354-8,The Impact of Timing on Bidding Behavior in Procurement Auctions of Contracts with Private Costs,May 2013,Dakshina G. De Silva,Georgia Kosmopoulou,Ronald Peeters,Unknown,Female,Male,Mix,,
42.0,3.0,Review of Industrial Organization,09 June 2012,https://link.springer.com/article/10.1007/s11151-012-9353-9,Employment Effects of Acquisitions: Evidence from Acquired European Firms,May 2013,Harald Oberhofer,,,Male,Unknown,Unknown,Male,,14
42.0,4.0,Review of Industrial Organization,30 April 2013,https://link.springer.com/article/10.1007/s11151-013-9384-x,Antidumping and Industrial Organization,June 2013,Robert M. Feinberg,,,Male,Unknown,Unknown,Male,,2
42.0,4.0,Review of Industrial Organization,14 April 2013,https://link.springer.com/article/10.1007/s11151-013-9383-y,The Heterogeneous Effects of Trade Protection: A Study of US Antidumping Duties on Portland Cement,June 2013,Maya Cohen-Meidan,,,Female,Unknown,Unknown,Female,"Antidumping duties are a discriminatory trade-policy, which is aimed at protecting domestic industry against low-priced imports from a specific country. Such duties are becoming increasingly prevalent in the United States and worldwide: The number of countries with antidumping laws has increased from less than 40 in 1980 to about 90 in 2000.Footnote 1 Global antidumping usage peaked in the early 2000s, and current cases are mostly initiated by developing countries. Nonetheless, it is among the forms of import protection most sought by domestic US industries. The importance of antidumping duties is reflected by the numerous studies that examine the impact of (US) antidumping duties on prices, exchange rate pass-through, production, and imports.Footnote 2
 Past studies, however, analyze the impact of the duties on prices, market shares, and imports only at a national level; by treating countries as points in space, the existing literature on antidumping duties effectively ignores within-country transportation and trade costs, which create regional markets.Footnote 3 But there is ample evidence that regionally segmented markets exist for many industries. For example, Hillberry and Hummels (2008) found that shipments by US mining, manufacturing, and wholesale establishments were three times more likely to occur within a given 5-digit zip code than outside that zip code. This paper focuses on a highly segmented industry— the US Portland cement industry— to examine how regional segmentation of markets may affect the outcomes of antidumping duties. The empirical analysis reveals considerable variation in the response of cement markets in various regions of the United States to the same duties; these are differences that can be significantly obscured by an aggregate-level analysis. Regional variation in the policy’s outcomes implies that in some regions, the impact from antidumping duties on consumer surplus, local employment, and other import competing factors is much larger than the impact in other regions. The analysis focuses on Portland cement since the highly localized nature of the cement industry makes it an excellent candidate for studying regional variations in the impact of trade policy. Portland cement, which is the major component of concrete, is a generic type of cement that is named after the district of Portland in Southern England. Because it has a high weight-to-volume ratio, Portland cement is very expensive to transport on land, but relatively cheap to ship by sea.Footnote 4 It is also very susceptible to humidity and cannot be stored for long. Consequently, imports play a critical role in local cement markets along coastal or border regions, but not inland. The existing variation in cement import penetration across the United States lends itself to an analysis of the regional impacts of antidumping duties on the US Portland cement industry. In particular, the industry’s highly localized nature suggests the appropriateness of a differences-in-differences (henceforth diffs-in-diffs) methodology for analyzing the impact of the duties across different regions. Traditionally, diffs-in-diffs are used to examine the effect of some treatment by comparing the treatment group after treatment with both the same group before treatment, and with a control group that did not receive the treatment. In the present context, the treatment is defined as the imposition of antidumping duties on imports of Mexican and Japanese Portland cement in 1990 and 1991, respectively. Because of the high land transportation costs of cement, I assume that the US cement markets that are geographically closest to Mexico and Japan, respectively, were those likely to be most affected by antidumping duties on imports. The treatment group for antidumping duties on Portland cement is thus defined as the group of all coastal (or border) cement markets that are closest to Mexico or Japan, and the diffs-in-diffs methodology here compares the response of this group with the response of inland markets (the control group). For the duties to have a different impact across regions, it is crucial that no arbitrage opportunities exist between the control and the treatment group. Indeed, I find that cement’s high transportation costs generally prohibit any price arbitrage across US markets, supporting the use of diffs-in-diffs for empirical analysis. The first step of the analysis is to determine whether the designated control and treatment groups differed in their actual responses to the duties, which were no lower than \(30\,\%\) of imported value and averaged around \(60\,\%\) for Mexico and \(68\,\%\) for Japan. After controlling for demand and cost shifters across markets, I find that domestic cement price rose by \(5\,\%\) more in the treatment group than in the control group, and domestic production rose by \(14\,\%\) more in the treatment group than in the control group. We can thus reject the hypothesis that all of the United States was affected by the duties in the same manner. The next step is to look for variation in the response to the duties within the treatment group. To that end, I break it into four subgroups, based on location: the Pacific region (excluding California) for Japanese imports; the Mexican border region (excluding Texas) for Mexican imports by land; the Gulf of Mexico region (including Texas) for Mexican imports by sea; and California, for both Mexican imports (by land and sea) and Japanese imports.Footnote 5
 The empirical analysis reveals striking variation in responses to the duties across the treatment group regions. In the Gulf of Mexico, the imposition of antidumping duties on Mexican cement was followed by a \(9\,\%\) increase in domestic cement prices, relative to the control group. The data indicate that imports from Mexico into the Gulf of Mexico region were replaced in the wake of antidumping duties by higher priced domestic production and alternative import sources. In the Pacific region, the duties on Japanese imports had even more of an impact, with an increase of \(13\,\%\) in domestic prices and \(26\,\%\) in domestic production that resulted from (imperfect) substitution of Japanese cement imports with East Asian imports. By contrast, the Mexican border and California regions did not experience an increase in domestic cement prices after the duties were imposed, relative to the control group. Furthermore, no substitution of Mexican imports occurred in the Mexican border region: the same Mexican producers that were subject to antidumping duties continued shipping their cement to the United States, fully absorbing the duties. In California, the largest Mexican producer gradually shifted from selling its own Mexican cement to selling foreign cement imports. The substitute imports were sold at a similar price (despite higher transportation costs) so as to maintain the producer’s market share. Clearly, the impact of the duties on welfare was very different across regions, and only in the Gulf of Mexico and Pacific regions did the duties have the expected impact of increasing domestic cement prices and domestic sales. The absorption of the cost shock (i.e., the new duties) by Mexican producers in the Mexican border and California regions contrasts with the complete cessation of imports from Japan and Mexico to the Pacific and Gulf of Mexico regions, respectively. Importantly, antidumping policy is designed so that foreign producers can absorb the duties only if they are integrated with their US importers. Importantly, the affected Mexican producers in both California and the Mexican border regions became integrated (with distribution facilities in Los Angeles and New Mexico, respectively) after the duties were imposed. But vertical integration cannot, in itself, explain a foreign producer’s decision to absorb the duties. In particular, one of the integrated Mexican producers who continued to export to California and Arizona, ceased exporting its cement to the Gulf of Mexico region rather than absorbing the duties there. The difference in the responses to antidumping duties across regional markets can be attributed to differences in foreign producer’s fixed exit costs from the US market. In California and the Mexican border region, Mexican cement was shipped by land from across-the-border plants. The landlocked location of these Mexican plants meant that no alternative export markets existed, implying high exit costs from US exporting. This was not the case for the Gulf of Mexico and Pacific regions, where Japanese and Mexican producers shipping their imports by sea could easily divert them to other coastal export markets. The absorption of an unfavorable cost shock when exit costs are high is known as hysteresis, a phenomenon well documented in the international trade literature.Footnote 6
 Apart from contributing to our understanding of antidumping duties and their impact, the current paper also contributes to the extensive literature that examines the role of geography in trade. The important role of within-country transportation costs for the creation of regional markets and trade patterns is the focus of Krugman (1991), Krugman and Elizondo (1996), Rauch (1993) and Courant and Deardorff (1992), to name a few. Melvin (1985) develops a theoretical model in order to consider the combined impact of high interregional transportation costs and different factor endowments across regions of the same country on international trade and tariffs. Still, there exists little empirical work that investigates the impact of within-country regional markets on the outcomes of international trade policy. The present paper is the first to examine the role of within-country market segregation in determining markets’ responses to antidumping duties, and its findings have implications for the analysis of other types of discriminatory trade policies, such as countervailing duties or Free Trade Agreements, and their effects on prices, employment and welfare, particularly for goods with segmented local markets and high transportation costs. The rest of the paper is organized as follows: Sect. 2 briefly describes the policy and the process of antidumping investigations; Sect. 3 provides an introduction to the Portland cement industry and data; Sect. 4 establishes the existence of regional markets for cement imports within the United States and discusses the definition of the treatment group and its validity; Sect. 5 displays the regional variations in the industry’s response to antidumping duties; Sect. 6 investigates the causes for the different outcomes in each of the four treatment group regions and links the findings to hysteresis in export market exit; Sect. 7 concludes.",8
42.0,4.0,Review of Industrial Organization,22 May 2013,https://link.springer.com/article/10.1007/s11151-013-9387-7,Antidumping and Production-Line Exit: The Case of the US Steel Industry,June 2013,Bruce A. Blonigen,Benjamin Liebman,Wesley W. Wilson,Male,Male,Male,Male,"The steel industry has been the largest recipient of US antidumping (AD) and countervailing duty (CVD) protection for decades, typically accounting for at least one-third of all orders.Footnote 1 The industry has argued that trade relief is necessary for its continued viability, and has received multiple forms of trade relief over the last 40 years.Footnote 2 A primary justification for this ongoing protection is that foreign companies receive subsidies from their governments, causing them to overcapitalize and dump their excess production on the US market, thus placing US firms at a competitive disadvantage in their own domestic market.Footnote 3
 In this paper, we present a novel data set on steel plants and use it to examine the role of AD and CVD protection, as well as a variety of industry and plant characteristics, in the shutdown of production lines inside US steel factories during the period 1978–2007. We also examine the role of foreign ownership in the widespread shutting down of steel lines since the late 1970s. Despite the intermittent problems of the industry over the last several decades, the consumption of steel in the US primarily increased from the mid-1980s until the 2008 recession (albeit more slowly than the overall economy). In general, cyclical fluctuations in both domestic production and imports have been regular features of the US industry (see Fig. 1), although production has never returned to its 1973–1974 peak.
 US steel consumption and production (1967–2010). Data source: International Iron and Steel Institute During this time, there have been literally hundreds of AD and CVD investigations on various steel products as well. The industry has had mixed success proving that unfair trade has been the source of its woes, including a drastic decline in employment, despite the clear upward trend in import penetration (see Fig. 2).
 Steel employment and import penetration (1974–2005). Source: NBER-CES Manufacturing Industry Database, Becker and Gray (2009). Iron and Steel Mills (sic 3312) Alongside the laying off of hundreds of thousands of workers, the industry also closed scores of production lines within numerous steel plants over this period. In this paper, we investigate the determinants of these shutdowns, but do so at a level of disaggregation that has not been examined before in this context—production lines within a plant. Many steel plants have multiple production lines, which allow plants the flexibility to shut down (and start) production lines without any change in the overall operating status of the plant. Thus, studies of plant exit may mask the within-plant reorganizations that may occur from changes in policy and economic conditions. This may be particularly true with respect to AD and CVD actions, which often involve quite specific products. This allows us to examine whether AD/CVD protection alters the relative probability of product-line exits and, thus, affects resource allocations within plants. Given these rich data, we are able to control for plant and firm heterogeneity in capacities, products, and type of firm (integrated versus minimill producers). We also observe the startup year of the individual production line within each plant, as well as major modernization efforts and the role of foreign and domestic investment in the form of joint ventures. Finally, we observe all of the plants that are operated by all of the firms that operated in the US for the set of steel products in our study, which provide a particularly useful opportunity to examine how AD policy affects the exit of steel production lines. Consistent with Lieberman (1990) and Deily (1991), our results provide strong evidence that smaller production lines (measured in terms of tons per year) are more likely to exit. However, we also find that lines that are owned by larger firms are more likely to shut down. Moreover, our results reveal significant differences across product lines (e.g., gaivanized steel versus wire rods) and types of plants (e.g., integrated versus minimills), as well as vintage of plants. However, unlike previous findings in the literature, we fail to find any significant link between foreign ownership and exit.Footnote 4 Finally, we find no evidence that the steel industry’s aggressive pursuit of AD protection has decreased the likelihood of production-line exit.",4
42.0,4.0,Review of Industrial Organization,07 May 2013,https://link.springer.com/article/10.1007/s11151-013-9385-9,Under the Cover of Antidumping: Does Administered Protection Facilitate Domestic Collusion?,June 2013,Kara M. Reynolds,,,Female,Unknown,Unknown,Female,"In 1989, three US producers began devising a way to create a price-fixing cartel in the ferrosilicon industry (Pierce 1999). They decided to refuse to sell at prices below their domestic cartel price; when relatively inexpensive imports from Asia and South America began to flood the market, they filed antidumping petitions in both the United States and European Union. Under US antidumping law, firms may request that antidumping tariffs be imposed on products that are imported from specific countries at less than “normal” or “fair” value and that are causing (or threatening to cause) material injury to the domestic industry. Broadly, “normal” value is defined as the price set by the foreign exporter in its domestic market, although all prices set below the firm’s average cost of production are excluded from the calculation. Thus antidumping is designed to combat both price discrimination and predatory pricing on the part of foreign exporters. In this case, the ferrosilicon producers were awarded antidumping protection in 1993. Shortly thereafter, US producers offered Brazilian producers a chance to join the cartel; when the Brazilian producers refused, the US producers filed another successful antidumping complaint against Brazil. Luckily, this story has a happy ending: Antitrust authorities detected and prosecuted the cartel behavior.Footnote 1
 Although this is certainly an extreme example, it does beg the question as to what extent firms use US trade laws to engage in uncompetitive behavior in the domestic market. The ferrosilicon case is an example of an overt attempt to engage in illegal, monopolizing activities. In a similar example, a number of US firms in the polyester staple fiber industry were charged with illegal price fixing shortly after the industry filed for, and was awarded, antidumping protection against imports from Korea and Taiwan in April 1999.Footnote 2
 The cases described above suggest that the antidumping petition and investigation process reveals a significant amount of firm-specific price and cost information, which could encourage firms to engage in anticompetitive pricing activities. Note that under the Noerr-Pennington doctrine, firms are immune from prosecution under the federal antitrust laws if the firms are engaged in efforts to influence the enforcement of laws, including antidumping laws.Footnote 3 In other words, firms are allowed to collaborate on antidumping petitions without fear of being charged under antitrust statutes. The antidumping petitions must have merit, however, in order to qualify for the Noerr-Pennington exception, and several suits have been filed by foreign producers against US firms claiming that their antidumping petitions were baseless and essentially “sham” litigation.Footnote 4
 A number of authors have studied the degree to which antidumping law may lead to increased collusion among firms, although most of these authors have focused on the use of antidumping law to facilitate collusion between domestic and foreign firms. For example, Prusa (1992) first noted that nearly 40 % of US antidumping cases filed between 1980 and 1985 were withdrawn prior to the government reaching a final determination; moreover, the data suggested that these withdrawn cases restricted trade by at least as much as cases that resulted in the imposition of antidumping duties. To explain these data, Prusa (1992) developed a model in which both domestic and foreign firms benefitted from reaching an out-of-court settlement to raise prices in the wake of an antidumping filing. Zanardi (2004) finds empirical support for a similar bargaining model in which the ability of the domestic and foreign firms to reach an out-of-court settlement is hampered by coordination costs and the degree of bargaining power of the two sides. While neither Staiger and Wolak (1994) nor Taylor (2004) found empirical evidence that withdrawn petitions decreased the quantity or increased the price of imports in the United States, Rutkowski (2007) estimates suggested that there are collusive aspects that are associated with withdrawn cases in the European Union.Footnote 5
 Two theoretical models suggest that the existence of antidumping laws itself, including the associated revelation of information during the investigation process, could lead to increased collusion among both domestic and foreign firms. Although Hartigan (1995) develops a model in which one domestic and one foreign Bertrand competitor are unsure as to whether their rival is a high- or a low-cost producer, this model could easily be extended to one with multiple domestic firms. In this model, firms use the antidumping investigation to discover information about their rivals; while the domestic firm’s costs are revealed through the injury investigation, the foreign firm’s costs are revealed through the dumping investigation. In this model, high-cost firms will benefit from the revelation of information as prices increase, while low-cost firms will experience a loss of profits. 
Veugelers and Vandenbussche (1999) develop a theoretical model to explore how antidumping law might change the incentives and profitability of domestic and/or international cartels, focusing specifically on European antidumping law.Footnote 6 The authors find that antidumping legislation can be either pro-competitive or anti-competitive, depending on how the government makes its antidumping determination and the level of competition in the industry. For example, if the European Union chooses to impose antidumping duties, the model predicts that the market will always become less competitive, with the tariffs encouraging the formation of cartels. Surprisingly, there are very few empirical studies that have focused on the degree to which antidumping laws change the level of competition in the domestic industry. Hartigan et al. (1989) conduct an event study methodology to evaluate to what degree the financial markets believe that antidumping protection will improve the competitive positions of firms. The authors find that the market only values antidumping protection when the ITC determines that protection is warranted due to the threat of injury from foreign imports, not when the ITC finds that protection is warranted because of actual injury from foreign imports. 
Nieberding (1999) calculates firm-level market power statistics (based on the Lerner Index of market power) for four US industries that filed antidumping petitions in the 1980s: semiconductors, hydraulic cement, tapered roller bearings, and the steel industry. The author finds that firms have significantly more market power following successful antidumping petitions which result in duties (semiconductors and ball bearings), but less market power following unsuccessful petitions (hydraulic cement). 
Konings and Vandenbussche (2005) use a panel of 4,000 European producers who were involved in antidumping petitions in 1996 to estimate whether these investigations increased firm mark-ups. They find that successful antidumping petitions result in an average increase in mark-ups of domestic firms of approximately 8 percentage points. They found no impact of terminated, or unsuccessful, antidumping petitions on average firm mark-ups, which suggests that it is the protection itself that increases a firm’s market power rather than simply filing a petition. The results from Nieberding (1999) and Konings and Vandenbussche (2005) suggest that it is only successful antidumping petitions that result in increased market power in the domestic industry; in other words, the increased market power must be due to the fact that the antidumping duties restrict imports. In this paper, I instead explore the possibility that the petition and investigation process itself can reduce competition in the domestic market by making it easier for firms to exchange information. To do this, I first propose a method to identify whether domestic firms in the industry experience a structural break in their level of market power at the time that they file their antidumping petition. I then use this methodology to analyze the impact of antidumping petitions on competition levels in two industries: semiconductors and ball bearings. I find little evidence that the domestic firms in these industries experienced a significant increase in market power from either the antidumping petition process or from the protection itself.",4
42.0,4.0,Review of Industrial Organization,17 May 2013,https://link.springer.com/article/10.1007/s11151-013-9386-8,Antidumping Duties and Plant-Level Restructuring,June 2013,Justin R. Pierce,,,Male,Unknown,Unknown,Male,"While a large theoretical literature has considered the effect of temporary trade protection policies on restructuring activities, such as the adoption of new technology, there is little empirical evidence on the subject. This paper examines whether the temporary reduction in competition associated with antidumping duties allows plants to restructure their production processes. Using a plant-level dataset containing the universe of U.S. manufacturers, I examine how plants adjust their capital and skill intensities in response to the imposition of antidumping duties. I find that protected plants increase their capital intensities relative to unprotected plants, but only when antidumping duties have been in place for a sufficient duration. I do not find a robust effect of antidumping protection on a measure of skill intensity. The results suggest that the effect of antidumping duties on restructuring activities is not immediate, either because plants take time to assess the effects of the policy on their market, or because they are financially constrained and must generate the cash flow needed for investments. Studying the effect of temporary tariffs on plant-level restructuring activities offers several important types of insights. First, given the prominent role that antidumping duties have come to play in international trade policy, understanding the reactions of plants to this temporary trade protection is a matter of interest for researchers and policy-makers. For example, it is helpful to understand whether antidumping duties induce firms to purchase new equipment or simply allow them temporarily to increase prices. Second, antidumping duties provide a useful setting for examining the more general question of how government policies that temporarily restrict competition affect firms’ timing of irreversible investments. This paper also provides new empirical evidence that is related to a theoretical literature that examines the effect of temporary trade protection on restructuring activities—particularly the adoption of new technologies. Matsuyama (1990) shows in an infinite-horizon perfect information setting that the government can induce firms to make investments by threatening to liberalize trade in a future period, but that the threat is not renegotiation-proof, and hence may not be credible. Miyagiwa and Ohno (1995) find that under certain conditions—with either permanent tariffs or temporary tariffs with an exogenous end date—trade protection can actually speed the timing of technology adoption. Crowley (2006) examines the effect of variation in the breadth of coverage of temporary tariffs on technology adoption and finds that antidumping duties can speed the timing of adoption while preserving the order of technology adoption across countries. In this paper, I find that antidumping protection is associated with plants increasing their capital intensities, but that the effects are only present as the duration of protection increases. I measure plant-level restructuring activities in two ways. The first measure is the change in the capital-labor ratio that is observed at protected plants, relative to unprotected plants. This variable measures the extent to which plants reallocate their input usage between capital and labor—potentially as a way to respond to changes in the level of foreign competition. The second measure is the change in the share of non-production employees in total employment. To the extent that non-production workers are higher-skilled employees, an increase in the share of non-production workers represents an increase in the skill intensity of the production process. As has been noted in the literature that examines the effect of antidumping duties at the micro-level, plants and industries that receive antidumping duties may differ systematically from those that do not receive protection.Footnote 1 I construct a control group that is designed to eliminate two potential sources of bias, following the procedure described in Pierce (2011). The first source of bias is a self-selection bias that arises if industries that apply for protection differ from those that do not. I control for this self-selection bias by restricting the control group to industries that applied for protection but were turned down by the government. The second source of bias is a government selection bias that occurs if the industries that the government approves for protection differ from those that do not. I control for the government selection bias by further limiting the control group to industries that are similar to those receiving protection in terms of variables considered by the government. I compare the restructuring activities of plants in a treatment group that received protection to those in the control group described above. I use a difference-in-difference framework, which controls for time-invariant differences between the treatment and control groups, as well as macro-level shocks that affect the treatment and control groups identically at a particular time. I find that protected plants increase their capital intensities relative to unprotected plants, but that the effect is only found as the duration of protection increases. More specifically, I estimate that the effect of antidumping protection on capital intensity only turns positive after the duties have been in place for 3–4 years. This relationship holds with either product or plant fixed effects, and also when controlling for the effective rate of the antidumping duty. I do not find a robust effect of antidumping duties on my proxy for the skill intensity of the production process. While the results indicate that antidumping protection of sufficient duration is associated with capital-deepening, they should not be interpreted as an indication that antidumping duties are welfare-augmenting, or even productivity-augmenting. As discussed in Pierce (2011), antidumping duties are not generally associated with increases in productivity—for the subset of plants that report output data in physical units of quantity in that paper, productivity actually falls. Moreover, because measures of capital are based on deflated nominal values, the capital-labor ratio may spuriously change if industry-level price deflators do not accurately capture changes in the price of capital. The remainder of the paper is organized as follows: Sect. 2 describes the data. Section 3 presents my empirical strategy and provides detailed definitions of my measures of restructuring activities. In Sect. 4 I report the results of my analysis. Section 5 provides a discussion of the results, and Sect. 6 concludes.",1
42.0,4.0,Review of Industrial Organization,23 March 2013,https://link.springer.com/article/10.1007/s11151-013-9382-z,How Different Are Safeguards from Antidumping? Evidence from US Trade Policies Toward Steel,June 2013,Chad P. Bown,,,Male,Unknown,Unknown,Male,"Temporary trade barriers—such as safeguards,Footnote 1 antidumping, and countervailing duties—are increasingly relevant commercial policy instruments for a diverse set of countries and industries in the rules-based trading system. As more countries liberalized by cutting applied border tariffs since the 1980s, their governments have established national regimes and adopted GATT/WTO procedures to administer temporary trade barrier (TTB) policies. While governments have been able to maintain applied border tariffs at relatively low levels, they have subsequently processed hundreds of industry and worker requests for “new” TTB protection; this has resulted in newly applied import restrictions that have affected thousands of products and covered tens of billions of dollars in annual trade. This paper contributes to the economic literature on trade policy formation in the presence of international agreements; this is a literature that seeks to address the increasing empirical relevance of TTBs. We examine the important issue of the substitutability of two statutorily distinct TTB policies in antidumping and safeguards. In particular, we identify similarities in the realized trade effects that were associated with the United States’ application of its safeguard policy to steel imports in March 2002 when benchmarked against the historical application of the US antidumping policy on steel over 1989–2003. The 2002 application of the US safeguard policy came at the request of the domestic steel industry, which alleged injury that stemmed from foreign-produced steel. Conservative estimates put the aggregate trade impact of the resulting import-restricting tariff increases and new quotas as a 13.5 percent reduction in the value of US steel imports. In the 12 months that followed the safeguard imposition in the product categories that were targeted by the policy, this eliminated nearly $700 million worth of trade relative to the previous year. However, while the aggregate trade impact of the 2002 steel safeguard is impressive in its own right, the actual impact on imports within the affected product categories may be masked by the perception that a safeguard (SG) policy is automatically applied so as to follow the GATT/WTO’s most-favored-nation (MFN) principle: One important way through which the SG policy is statutorily distinct from other TTBs such as antidumping (AD) or countervailing duties (CVDs) is that these latter “unfair” trade laws apply new protection to imports from only one country per petition, thus allowing for differential and potentially discriminatory treatment across trading partners. The application of a safeguard policy is generally thought to result in MFN protection through nondiscriminatory treatment of imports, irrespective of the source country.Footnote 2
 The purpose of this paper is to investigate empirically one element concerning the relative substitutability of the antidumping and safeguards TTB policy instruments. We provide an econometric examination of the differential trade effects that were associated with the discriminatory treatment across export sources for the steel product categories that were affected by the 2002 US safeguard and compare them to trade effects that were associated with steel imports that were affected by US antidumping policy. We construct a panel of bilateral, product-level US steel import data that include products that were affected and unaffected by these policies, covering the period 1989–2003. Footnote 3
 Our specific empirical approach is to match the disaggregated import data to detailed information on TTB policies that is now available in the World Bank’s Temporary Trade Barriers Database (Bown 2012). For the 2002 steel safeguard, however, we also need to match import data to a number of different forms of policy exclusions that arose both at the trading partner level and at the level of specific products that were tied to particular foreign firms. The information on this last set of policy exclusions has been compiled subsequently into a unique data set that derives directly from firm-specific petitions that were filed with the US Department of Commerce. Our econometric results confirm that application of the 2002 steel safeguard policy is associated with differential trade impacts across the sources of US imports. Furthermore, we show how this impact on trade is similar to the differential trade effects of the more explicitly discriminatory protection that the US steel industry received under antidumping in earlier data that date to the late 1980s. Our evidence on antidumping is consistent with results from Prusa (1997, 2001), who uses a related approach to document the differential trade effects and potential trade diversion that resulted from an earlier period of US antidumping.Footnote 4 With respect to the 2002 US steel safeguard in particular, a comparison of different forms of discriminatory treatment across exporters suggests that while developed country exporters responded more quickly when granted an exclusion from the US safeguard, the developing-country exporters’ response was longer-lived and larger over the full period that the safeguard was in effect. Finally, we also use our approach to examine how distinct outcomes to AD/CVD investigations differentially impact trade flows. In particular, we find additional empirical support for the Staiger and Wolak (1994) result of a negative “investigation effect” of AD/CVD on exports; i.e., foreign countries that are investigated but that do not face new antidumping or countervailing duty import restrictions also experience an adverse effect on their exports. Our results that statutorily distinct TTB instruments such as antidumping and safeguards can be interpreted as substitutable policies contributes to a broader literature on the role of TTBs under the WTO.Footnote 5 Bagwell and Staiger (1990) provide one particularly important theoretical lens through which to reconcile a role for TTBs in the design of trade agreements that have otherwise resulted in countries that apply low import tariffs. Their approach borrows insights from the industrial organization literature on firm collusion and repeated games by modeling two countries as playing a dynamic, tariff-setting game in which their governments “collude” by setting low tariffs in a cooperative equilibrium. The Bagwell and Staiger model has rich theoretical predictions for TTB use; in particular, positive trade volume shocks in sectors with low import demand and export supply elasticities generate a terms-of-trade incentive to defect. This triggers an increase in cooperative tariffs so as to avoid a reversion to noncooperative (Nash) tariffs and hence a trade war. The current paper’s specific evidence on the substitutability of safeguard and antidumping policies, in that their application can result in similar effects on trade flows, complements other recent empirical research that also implicitly examines the relative substitutability of these TTB policies. First, Bown and Crowley (2013) interpret US TTB use as increases to the “cooperative” trade policy as in Bagwell and Staiger (1990), and they present evidence that both antidumping and safeguards can be viewed as cooperative tariff increases in response to trade volume shocks. Their estimation of the determinants of US industry-level use of antidumping and safeguards covers 1997–2006 and therefore also includes substantial TTB application of both policies on the US steel sector. Second, at the aggregate level, there is evidence that safeguards can be an important contributor to modern commercial policy adjustments in the face of macroeconomic fluctuations. Bown and Crowley (2011, in press) examine United States TTB policies in higher frequency data over 1988–2010 and find that, relative to models estimated on antidumping alone, the combination of antidumping and safeguards have both a stronger countercyclical response to macroeconomic shocks and a stronger reaction to exchange rate fluctuations.Footnote 6
 Our results also contribute to the body of research that examines different implications of US use of its safeguards policy. With respect to the 2002 US steel safeguard, Liebman and Tomlin (2007, 2008) provide evidence that government announcements that are associated with the policy affected share prices for at least three different types of firms: steel producers; downstream, steel-consuming industries; and firms that are otherwise unrelated to steel but are connected to the safeguard through the channel of “retaliation” against their exported products that is made possible by European Union tariff threats under a WTO trade dispute. Durling and Prusa (2003) describe the distributional impacts that resulted from the new 2002 safeguard import tariffs on steel slab, which were expected to raise the costs of not only foreign firms, but also of domestic rivals, thereby benefiting US mini-mills at the expense of a number of US vertically-integrated firms. This paper also relates to other studies of more general questions regarding import protection and the US steel industry. Blonigen et al. (2013), for example, use plant-level data from the US Census Bureau that covered 1967–2002 and provide evidence that quota-based protection has market power effects, with respect to integrated and mini-mill steel plants, whereas tariff-based import protection does not. Furthermore, Blonigen and Wilson (2010) use product- and foreign country-level data to document evidence of the impact of both cyclical and structural excess capacity (which is associated with foreign subsidies) on steel exports to the US that covered 1979–2002. Finally, research that improves the understanding of the role and implications of safeguards use is increasingly important given that application of this particular TTB has spread to so many countries. Miranda et al. (1998) and Prusa (2001) were amongst the first to document the proliferation in the adoption and use of antidumping across high-income and emerging economies worldwide. More recently, Bown (2011) extends the antidumping analysis and provides additional evidence regarding the economic significance of safeguards use for a number of countries over 1990–2009. Among the major Group of 20 (G20) economies in the WTO system, Argentina, Brazil, China, the European Union, India, and Turkey are like the United States in that they have also gone through episodes during which the application of safeguard policies affected a sizeable share of their imports. Even limiting ourselves to the 2001–2003 period that coincides with the US steel safeguard investigation and applied import restrictions, at least eight other WTO members initiated steel safeguard investigations of their own, and many resulted in the application of substantial import restrictions over a number of the same steel products as was true of the US safeguard.Footnote 7
 The rest of this paper proceeds as follows: Section 2 discusses the basic institutional background for the different TTB policies and provides a simple framework that allows for the examination of the questions of interest with regard to the differential trade effects that result from the application of such policies on imports. Section 3 presents the econometric model and a discussion of the data. Section 4 describes our estimation results, and Sect. 5 concludes.",13
43.0,1.0,Review of Industrial Organization,20 July 2013,https://link.springer.com/article/10.1007/s11151-013-9396-6,A Note from the General Editor About This Special Issue,August 2013,Lawrence J. White,,,Male,Unknown,Unknown,Male,,2
43.0,1.0,Review of Industrial Organization,17 July 2013,https://link.springer.com/article/10.1007/s11151-013-9395-7,Introduction: The Interstate Commerce Act of 1887,August 2013,Wesley W. Wilson,,,Male,Unknown,Unknown,Male,,3
43.0,1.0,Review of Industrial Organization,21 June 2013,https://link.springer.com/article/10.1007/s11151-013-9389-5,The ‘Railroad Problem’ and the Interstate Commerce Act,August 2013,John Howard Brown,,,Male,Unknown,Unknown,Male,"Railroads dramatically changed the economics of transportation over the course of the 19th Century. This unprecedented transformation challenged many of the existing norms of society. This was even true in the discipline of political economy. Economists rightly view Adam Smith as the founding father of the discipline. Smith’s opus, The Wealth of Nations, arguing as it does for a system of “natural liberty,” served as the foundation of laissez-faire policies followed throughout both the Ante-bellum and Gilded Ages of the 19th Century in the United States.Footnote 1
Laissez-faire doctrines held that monopoly as an economic problem originated with explicit grants by governments to firms or individuals. Thus early Nineteenth Century economists emphasized avoiding creating such favored enterprises. Railroads presented a challenge to these views. As enterprises, railroads were a long distance from Adam Smith’s famous pin factory. The railroad replaced a factory, where working and human capital dominated and physical capital was simple and easily transferred to other employments—with a firm where capital was mostly physical and largely sunk. This paper examines how prominent economic thinkers of the 19th Century dealt with this new type of enterprise. In the next section, a brief overview of the development of railroads in the United States during the middle half of the 19th Century is presented. This section is followed by a comparative discussion of the views of the economics of railroading by some important figures. The succeeding section discusses the role of economics in formulation of the Interstate Commerce Act.",2
43.0,1.0,Review of Industrial Organization,09 August 2013,https://link.springer.com/article/10.1007/s11151-013-9402-z,"Voting, Regulation, and the Railroad Industry: An Analysis of Private and Public Interest Voting Patterns",August 2013,Kevin E. Henrickson,Wesley W. Wilson,,Male,Male,Unknown,Male,"The Interstate Commerce Act of 1887 (the Act) marks the first attempt at federal regulation of a mode of transportation used for commerce. This Act has led to a long and rich literature that examines the impetus for regulation.Footnote 1 Within this body of work, there are two primary schools of thought, which hold that regulation is present for either the public interest or the private interest. In this paper, we examine the voting patterns of the U.S. House of Representatives and Senate in the context of these two schools of thought for both the Act and the voting patterns exhibited nearly 100 years later in the voting for three major legislative bills passed in 1973, 1976, and 1980. Before the Act was passed, railroads were (and, still are, for many shippers) the only viable shipping option. This allowed them to price at monopoly levels without any form of regulatory impediment (e.g., Aitchison 1937; Hilton 1966; MacAvoy 1965; Pegrum 1968; Gilligan et al. 1990). In contrast, other markets were, and are, characterized by intense competition between railroads (MacAvoy 1965; Hilton 1966; Ulen 1980a, b; Poole and Rosenthal 1993). In these more competitive markets, railroads priced similar shipments at much lower prices. To avoid such competitive forces, these railroads would also sometimes form associations to price collectively. However, these agreements tended to be unstable, leading to considerable rate instability e.g., MacAvoy (1965), Porter (1983), and Ulen (1980a, b). This structure led to cases in which rates for the same movement fluctuated between extremely low (destructive) and extremely high (collusive), depending on the competitive environment at the origin/destination. In addition, these differences in rates were often dramatic and unconnected to the costs of the movement. A common example of this behavior that is cited throughout the literature is the case in which shippers in short-haul monopoly markets paid more for transportation than shippers in long-haul markets where prices were tempered by competition. This competitive environment has since led to a number of historical texts on the development of the railroad industry, the factors that led to federal regulation, and the evolution of the Act.Footnote 2
 By most accounts, much of the public impetus for regulation came from the Granger movement. Farmers in the “west”, often being held captive to a single railroad to move their crops, were charged extraordinarily high prices. These shippers, through the Granger organization, successfully passed laws at the state level in the 1870s, the Granger Laws, in an attempt mitigate these high prices. Given both public and private interests for regulation as well as the ability to gauge the effects of regulation afforded by the passage, the Act has been of considerable interest to the economics literature. Hadley (1889) provides one of the first examinations of the effects of the Act. He found that, while prices on short-haul traffic fell, there were differences across railroads wherein there were few changes for “stronger” railroads but larger changes for “weaker” railroads. There are a number of other studies that discuss the effect of the Act on enforcing cartel agreements: e.g., MacAvoy (1965), Kolko (1965), Spann and Erickson (1970), and Zerbe (1980). Spann and Erickson (1970) found negative welfare effects from the Act because it improved the ability of railroads to collude, while Zerbe (1980) found the Act has positive welfare effects.Footnote 3 The difference between the two studies is explained by measurements used by each study. Regulatory effects were also examined through stock market returns. Binder (1985; 1988) may be the first to use stock market returns to examine the effects of regulation. In his studies, he found that the Act had no influence over stock market returns. But Prager (1989), using a more comprehensive dataset and different event dates, found that the Act had positive effects with the implication that “...the railroads welcomed regulation as a means of facilitating the enforcement of cartel-like agreements” (p. 280). Of most relevance to this paper is the seminal work of Gilligan et al. (1989) and Poole and Rosenthal (1993). Each of these studies examines congressional voting and the motivations for passage of the Act. Gillian et al. frame voting in terms of variables that represent preferences of railroads and shippers, and find that the Act was a political compromise that represented both public and private interests. Poole and Rosenthal (1993) introduce a variable that is intended to capture long-run preferences of voters, which substantially reduces, but does not remove, the effects reported by Gilligan et al. (1989) As in Gilligan et al. (1989) and Poole and Rosenthal (1993), we examine the voting patterns of the U.S. House of Representatives and Senate in terms of characteristics that capture both public- and private-interest theories in voting for railroad regulation. However, we collect and introduce different measures that allow a more direct relationship of the models to public and private interests. In addition, we also apply the model to examine the effects of the 3R Act of 1973, the 4R Act of 1976, and the Staggers Rail Act of 1980, passed nearly 100 years later. To this end, we introduce a measure of railroad concentration, the density of rail infrastructure, and a measure of waterway competition, while retaining many of the other variables that were used by the previous studies. As with the previous studies, we find that some (voting) legislator characteristics—e.g., Republican, Senate—have strong negative effects for most specifications and for most legislative bills. For the original Act, we find that rail concentration, the presence of water competition, and the level of grain production each have strong positive effects. For the later legislation, neither grain nor rail concentration has a major influence, while water competition remains an important factor. In the next section we review the regulatory atmosphere prior to the vote for the Interstate Commerce Act and the vote itself. Section 3 presents the application, including the model and the data, while Sect. 4 presents the empirical results. Section 5 presents concluding remarks.",2
43.0,1.0,Review of Industrial Organization,16 July 2013,https://link.springer.com/article/10.1007/s11151-013-9394-8,The Effects of the Interstate Commerce Act on Transport Costs: Evidence from Wheat Prices,August 2013,Bruce A. Blonigen,Anca Cristea,,Male,Female,Unknown,Mix,,
43.0,1.0,Review of Industrial Organization,13 July 2013,https://link.springer.com/article/10.1007/s11151-013-9391-y,"The Legacy of the Interstate Commerce Act and Labor: Legislation, Unionization, and Labor Earnings in Surface Transportation Services",August 2013,James Peoples,,,Male,Unknown,Unknown,Male,"Inarguably the most important provision of the 1887 Interstate Commerce Act (ICA) was the establishment of the Interstate Commerce Commission (ICC). The ICC’s role as a regulator of interstate commerce has included oversight of freight and passenger transport service by rail, truck, bus, pipeline, and inland water barge carriers (Moore 2012). Compared to pipeline and inland water transport, the business development of the group of carriers providing land transportation was most heavily influenced by ICC regulatory oversight. The ICC’s overarching objective to set a reasonable return on services rather than allow the market to set rates was intended to provide shippers access to a relatively low-cost and expansive transportation system. Promoting business and consumer accessibility to this transportation network contributed to a growing demand for workers to provide these services as well as to maintain the network system used by transportation carriers. While the ICA did not give the ICC authority to regulate the labor market of surface transportation industries, the setting of non-competitive rates and restricted entry created a business environment that supported relatively high-paying jobs with relatively secure employment. This study examines the ICA and its aftermath as it applies to labor in surface transportation industries. A survey of past research examining employment and wage trends in ICC-regulated industries is presented to provide an understanding of the changing labor markets in surface transportation during a period of weakening ICC regulatory authority. New information on wage and employment trends in formerly ICC-regulated industries is also presented. This investigation is significant in part because there is a dearth of research that analyses the labor market for surface transportation following the abolishment of the ICC. In addition, examining post-ICC termination wage and employment trends contributes to the analysis of industries that play a vital role in the economic growth of the US and their ability to continue providing relatively high-paying jobs in a business environment that is less protected from competition.",2
43.0,1.0,Review of Industrial Organization,17 July 2013,https://link.springer.com/article/10.1007/s11151-013-9390-z,"Railroads and Price Discrimination: The Roles of Competition, Information, and Regulation",August 2013,James M. MacDonald,,,Male,Unknown,Unknown,Male,"The following equation, derived from the standard profit maximizing condition, provides a useful framework for evaluating rail pricing (Porter 1983; Wilson 1994): For firm i operating in market j at time t, P is the profit maximizing price, MC is marginal cost at the profit-maximizing output, \({\upeta }\) is the market price elasticity of demand for rail transportation, and \({\upvarphi }\) is a conduct parameter with values ranging from 0 to 1.Footnote 2 For \({\upvarphi }\) of zero, the term in brackets goes to one, and the profit maximizing price equals MC, the competitive outcome. For \({\upvarphi }\) equal to one, the equation reduces to the monopoly result; given MC, P varies inversely with the absolute value of \({\upeta }_{\mathrm{jt}}\). In turn, \({\upvarphi }\) should vary with the number of competing railroads in a market and with the degree to which they cooperate with one another. Price discrimination can be said to occur when a firm sells different units of the same product at different prices: for given MC, P varies across units. In some cases, buyers may impose varying costs on the seller, and in that case price discrimination reflects different prices charged by a firm for units of a product, that are not accounted for by differences in marginal cost (Anderson and Renault 2011). In this broader case, price discrimination reflects differences in the markup of P over MC across units. In turn, railroad price discrimination is ubiquitous because most railroads sell services to many customers in many markets, because \({\upeta }_{\mathrm{jt}}\) varies across markets and time, and because railroads possess some market power (\({\upvarphi }\) isn’t always zero). The information requirements necessary to precisely apply even this simple model are staggering: not only does \({\upeta }_{\mathrm{jt}}\) vary across markets and time, but marginal costs can be almost shipment-specific. In turn, the range and effectiveness of actual pricing practices will be affected by technologies for gathering and using information on buyer attributes and carrier costs.",7
43.0,1.0,Review of Industrial Organization,17 July 2013,https://link.springer.com/article/10.1007/s11151-013-9392-x,Mitigating Monopoly or Preventing Discrimination: Comparing Antitrust to Regulatory Goals in the Interstate Commerce Act,August 2013,Timothy J. Brennan,,,Male,Unknown,Unknown,Male,"The conventional view of regulation and antitrust is that they are two policy tools directed toward the same end: reducing price below the monopoly level and close to what one would see under competition. However, a prominent concern in regulation, at least along with price levels, has been non-discrimination: assuring each buyer of a regulated service that it is not paying a higher price than other buyers. In the Interstate Commerce Act of 1887 (ICA), arguably the founding document of US federal economic regulation,Footnote 1 competition or monopoly receives no mention beyond an initial clause that says that charges “shall be reasonable and just”, while the substantive sections of the ICA are devoted entirely to ensuring non-discrimination. As non-discriminatory pricing is consistent with monopoly pricing, this prominence requires explanation. It hinges critically on an underappreciated distinction between markets where the buyers themselves compete with each other, and thus have demands that depend on prices that are charged to others, and markets where the buyers do not compete: e.g., final consumers. The likely explanation is that when the buyers of regulated services themselves compete, as with freight rail, they are concerned with relative prices that create strategic advantages, while uniform absolute increases in price can largely be passed on to consumers. Antitrust, on the other hand, may be viewed as focusing more on final product prices, starting with the Sherman Act’s focus on restraint of trade and monopolization.Footnote 2 As regulation reached out to end user services—electricity, telephones—the textbook focus on price levels became more relevant. The first part of the article examines the ICA to demonstrate that preventing price discrimination to shippers was its dominant and quite possibly sole focus. Examining three leading analyses of the Sherman Act’s legislative history provides three different views regarding the purpose of the antitrust laws when they were first enacted, but none of those views includes the prevention of price discrimination that is so compelling in the ICA. Having separate regulatory and antitrust statutes reinforces this difference in policy goals, although from a contemporary standpoint, one would expect the policy goals to be similar. As discussed in Sect. 4, they may even be complements, in the specific sense that regulation can increase the merit of antitrust sanctions against vertical practices, although recent Supreme Court decisions have rejected that potential complementarity. I conclude by looking at why price discrimination has different effects when the buyers are competitors—e.g., shippers of the same products over rail—than it has when the buyers are final consumers. These distinctions lead to a political economy explanation for the emphasis on the prevention of price discrimination over the mitigation of monopoly power—which is exemplified by the ICA, our founding regulatory statute. Before getting to the descriptions of the Interstate Commerce Act, it is important to make an introductory methodological note: The analysis of the ICA here is based on the text of the statute as passed in 1887. The text of the ICA may not accurately reflect the concerns and, more important here, the priorities of those from outside Congress who sought its passage or of those in Congress who drafted and voted for it. They may well have been just as or more distressed about market power and overall rate levels that were charged by then-monopoly railroads—or concerned about the prevention of monopolization of erstwhile competitive rail markets—than they were about price discrimination by railroads; but as discussed in detail below, the ICA as written states quite the opposite. The conclusion that the ICA does not reflect a priority with keeping rate levels competitive, as in the Sherman Act, so much as preventing discrimination, is a clear inference from the phrasing and the structure in the statute itself. It is the text, rather than contemporaneous arguments, that I find inconsistent with the terse Sherman Act, regardless of which of many leading interpretations of that statute one might want to adopt.Footnote 3
",3
43.0,1.0,Review of Industrial Organization,16 July 2013,https://link.springer.com/article/10.1007/s11151-013-9393-9,Understanding ICC Rate Structure Regulation: A Spatial Analysis,August 2013,Kenneth D. Boyer,,,Male,Unknown,Unknown,Male,"Modern American railroads operate in an environment that was largely shaped by the Interstate Commerce Act of 1887. In order to better understand today’s freight industry, it is useful to review the history of railroad regulation—what problems regulation was intended to fix and how the Interstate Commerce Commission tried to correct those problems. This paper uses a simple stylized spatial model of a railroad network to show that monopoly pricing requires close attention to rate relationships. It is not generally understood that the focus of railroad regulation in the late 1800s was not on the level but rather on the structure of railroad rates. To a modern economist, schooled in the idea that the problem of monopoly is that prices are set too high and that, as a result, quantities offered on the market by a monopoly are inefficiently low, the preoccupation shown by the Interstate Commerce Act with the structure of railroad rates rather than their level seems incomprehensible. In this paper, this focus on the structure of rates is traced to the fact that American railroads are organized as monopoly service providers over tracks that are owned by the railroad company. This vertical integration of infrastructure and operations gave nineteenth century railroads power that varied by commodity and location. The combination of ownership of the infrastructure and monopoly operations on it that gave the power to charge each origin–destination–commodity triad the profit maximizing rate—something that would have been impossible had the infrastructure owner not also been the monopoly operator. This paper demonstrates that profit maximization called for setting some rates at relatively high levels and others low (relative to marginal costs) rather than maintaining high prices to all customers, and more importantly, refusing to serve some origin–destination–commodity combinations. It was logical, then, that the control of market power was focused on the structure of rates rather than their level. This focus on the structure of rates is found whenever railroad track ownership and operations are within the same company. Had the nineteenth century technology permitted the practice of separating track ownership from carriage, with free entry of operators—as is the case in waterways and highways—railroad economics in North America would have developed quite differently from the way it did and it is unlikely that the 1887 Interstate Commerce Act would have put the type of limits on railroad behavior that it did. When railroads first appeared in the 1830s, public policy toward the new technology was shaped by the common law on roads in which the fixed facilities were provided by a different party than the transporter. The first charters for railroads had assumed that the same common law would be applied to railroads as were applied to other modes of transportation. For example, the Boston and Providence railroad charter authorized the line “to erect toll houses, establish gates, appoint toll gatherers and demand toll upon the road” (Cleveland and Powell 1909, p. 160). But this organization of the railroad industry was soon seen as impractical—a disappointment since it was generally recognized that granting the monopoly right to operate over a track between two locations introduced market power issues that were not seen in other modes of transportation. Canal promoters in the first half of the nineteenth century pointed to the ability of having multiple operators on a canal as an advantage for public investment in that mode rather than railroads. But the technical advantage of railroads over road and canal transport was so large that public policy favored investment in railroads over other types of transportation as soon as the technology became economically viable.Footnote 1
 All railroads built in the 80-year era of railroad building between the appearance of the Baltimore and Ohio railroad in 1830 and the beginning of World War I were constructed through the use of eminent domain. The benefit to the public welfare provided by railroads was thought to justify not only the taking of private property, but also the construction subsidies that were granted to the monopoly operators. The nineteenth century technical impracticality of allowing more than one carrier to use the tracks that were built in the public interest then gave enormous power to that operator. With the current perspective of open access to highways, it is hard to appreciate that the new companies’ ability to set rates to individual communities and vary them for particular shippers within those communities gave the operating companies market power that is rarely seen today. According to a contemporary source, “The power to make freight rates is the power to turn a wilderness into a city or a city into a wilderness” (Beale and Wyman 1915, p. 657). This power passed to the Interstate Commerce Commission under the Interstate Commerce Act. According to an observer in the early 20th century, “It is a common saying that it (the Interstate Commerce Commission) is the most powerful body in the world, administrative or otherwise, and when its authority is closely examined, there will probably be few dissenters from this view” (Fletcher 1923, p. 43). Modern railroads have about $60 billion of revenue in an economy with a GDP of $15 Trillion (AAR 2012) and carry only one tenth as many tons as are moved on the highways (USDOT 2012). How could the regulators of such a small industry have such enormous power? A part of the answer, of course, is that the railroad industry, before the widespread use of trucking, constituted a much larger share of GDP. Combined passenger and freight revenues in 1914 were $3 billion for US railroads against an estimated US GNP of $38.6 Billion. But much more importantly, the economic power of railroads was exercised at a very local rather than national level—which was made possible by the monopoly that operators had over their own tracks. A spatial model of transportation aids in comprehending how the public could have felt economically threatened by an industry that, even at the height of its influence, was a relatively small part of the economy. This paper uses an extremely simple stylized model of a freight network to illustrate how the control of the structure of freight rates to individual shippers and communities can be used to transfer social surplus to a monopoly operator. Section 2 of this paper shows that the control is exercised not simply by maintaining prices at a monopoly level, but by setting the structure of rates charged in the network to insure the profit-maximizing pairing of buyers and sellers. A spatial model also helps to understand the destructive effect of excess railroad building in the nineteenth and early twentieth century as real resources were expended to respond to the manipulation in the cost of distance that was part of the monopoly rate structure. Section 3 shows that monopoly rate structures gave individual communities an incentive to build socially wasteful lines, which created excess capacity and exacerbated the need to find railroad revenues to pay for the uneconomically dense network that had far too little traffic to support profitable operations. Sections 4 and 5 of this paper briefly describe the legal charge within the Interstate Commerce Act and how the Interstate Commerce Commission chose to interpret its mandate. Section 6 then shows the spatial equilibrium that results from implementing the regulated rate structure in the way that the ICC interpreted as its mandate—one that ignores the costs of particular traffic flows, but seeks to encourage market access for all sellers that can reach a buyer at a cost greater than or equal to average variable cost on a link, while covering all movement and track costs in the over-extended system through revenues from all links in the network. It is not surprising that, without efficiency as a criterion for setting freight rates, the resulting equilibrium contains considerable inefficiencies. But at least in the stylized example used in this paper, all shippers and receivers are better off than in the monopoly equilibrium despite the substantially higher social costs of transportation. And in the regulated equilibrium, the railroad benefits from rates that are set at a level to allow it to cover its cost, despite excess capacity—a situation that would not have been possible in a competitive market for rail services.",4
44.0,1.0,Review of Industrial Organization,01 January 2013,https://link.springer.com/article/10.1007/s11151-012-9371-7,City-Pairs Versus Airport-Pairs: A Market-Definition Methodology for the Airline Industry,February 2014,Jan K. Brueckner,Darin Lee,Ethan Singer,Male,Female,Male,Mix,,
44.0,1.0,Review of Industrial Organization,28 February 2013,https://link.springer.com/article/10.1007/s11151-013-9380-1,The Price Effects of the Delta/Northwest Airline Merger,February 2014,Dan Luo,,,Male,Unknown,Unknown,Male,"How does a merger affect the product price? The answer to this question is critical to antitrust decision-making. The price effects of a merger are the result of changes in market power and efficiency. On the one hand, the decrease in competition and increase in market power through a merger lead to an increase in price; on the other hand, any possible efficiency gains lead to a decrease in price. A retrospective study of a consummated merger can provide empirical evidence on the price effects of a merger, showing the net effect of these two forces and offering guidance for future merger analysis. One of the most studied industries in analyzing merger issues is the airline industry. Detailed and publicly available data have made such analysis possible. To our knowledge, this paper is the first one to examine the price effects of the merger between Delta Airlines and Northwest Airlines. That this merger is a relatively recent case and that Delta and Northwest were codeshare partners make it interesting to study. Following Brueckner et al. (2013a), the paper estimates the DL/NW merger’s fare impacts while controlling for other changes in legacy carrier and LCC competition.Footnote 1 Also, it combines the airport-pair and adjacent-competition approaches, incorporates potential LCC competition, and considers both nonstop and connecting markets. The reason to distinguish between these two market types is that different pricing patterns might appear. Several conclusions emerge from the empirical analysis. First, other things equal, the fares for airport-pairs where Delta and Northwest competed with each other prior to the merger do not increase by much. In nonstop markets, such price effects are statistically insignificant, whereas in connecting markets, the fare increases by 2.3 %. Second, the impact of changes in LCC competition is large while the effect of changes in competition from other legacy carriers is slight. The remainder of the paper is organized as follows. Section 2 provides a literature review. Section 3 provides background on the Delta/Northwest merger and discusses the data and the construction of the variables. Section 4 presents the detailed regression results for the base model for nonstop and connecting markets and for a disaggregated model, where the merged firm’s own price and the price of other competing firms are separately identified. Section 5 calculates the forecast for the fare change on DL and NW overlap routes, compares it with the actual fare change and decomposes the change into the DL/NW merger effect and a separate effect from changes in competition from other carriers. Section 6 incorporates the effect of DL/NW codesharing. Section 7 concludes.",43
44.0,1.0,Review of Industrial Organization,02 August 2013,https://link.springer.com/article/10.1007/s11151-013-9397-5,WIC Contract Spillover Effects,February 2014,Rui Huang,Jeffrey M. Perloff,,Male,Male,Unknown,Male,"The U.S. Special Nutrition Program for Women, Infants, and Children (WIC) provides free infant formula to many poor families. To limit their costs, WIC state agencies hold periodic auctions where the three major manufacturers of infant formula bid to become the sole provider within a state. A vigorous academic and public policy debate has centered on why the manufacturers are willing to sell formula to WIC agencies for a small fraction of the usual retail price. Our explanation is that the winning firm benefits from spillover effects, which greatly increases its share of the non-WIC market.Footnote 1
 We illustrate the spillover using a natural experiment: When a state’s WIC contract changes hands, retailers provide additional shelf space to the new WIC brand and post a logo that indicates that it is the WIC brand, while removing the logo and a comparable amount of shelf space from the previous WIC contract brand. Using store-level scanner data on infant formula sales, we show that WIC consumers respond immediately and non-WIC consumers respond with a lag to these changes. We find that spillover effects are very large: The contract winner’s brand gains almost a third of the entire market 1 year after a contract change. The next section describes the WIC program. The following one discusses the spillover effect. The subsequent section examines a variety of ways of measuring spillover effects using scanner data. The final section summarizes the paper and draws conclusions.",7
44.0,1.0,Review of Industrial Organization,27 February 2013,https://link.springer.com/article/10.1007/s11151-013-9379-7,Supermarket Entry and the Survival of Small Stores,February 2014,Fernando Borraz,Juan Dubra,Leandro Zipitría,Male,Male,Male,Male,"In the last 30 years large supermarkets have changed the retail business landscape in many countries through larger store formats, more shelf space, an increased variety of goods and services and extensive marketing strategies. In developing countries, small retailers and producers have increased political pressure in order to mitigate the negative effects of large supermarkets on profits and the probability of survival (see Reardon and Hopkins 2006).Footnote 1 Accordingly, there is a growing literature on the effects of supermarket entry on industry concentration, and on the probability of exit of small stores. We contribute to this literature by analyzing the impact of large stores’ entry on the probability of exit of small stores in the entrant’s neighborhood in Montevideo (Uruguay). We regress the probability of exit of a small store on the total area occupied by supermarkets in that store’s neighborhood and show that the entry of a supermarket in a small store’s neighborhood results in a slight but significant increase in its chances of going out of business in that year. In order to control for the endogeneity of the entry decision of supermarkets, we use two complementary techniques that we describe below. Our results are robust to alternative definitions of what constitutes a supermarket and to different model specifications. Our contribution is threefold: First, ours is the first study to focus on a developing country, so it is an indication that the effects that had been documented previously are robust. Whatever the differences between the developed and developing country markets in terms of shopping habits and entry decisions, the net effect of entry is similar. Second, relative to the prior literature, our use of neighborhood level data allows us to identify better the geographical link between entrants and the effect on nearby small stores (see Jia 2008 and the references therein). Finally, our third contribution is to shed light on the competitive effects of entrants’ responses to existing regulation about an establishment’s size. In Montevideo, existing regulation has made it difficult for very large stores to enter the market. Since the local authority has been reluctant to approve the entry of large supermarkets, but not of smaller establishments, supermarket chains have responded by launching smaller-scale outlets, which are located in various neighborhoods.Footnote 2 We analyze the resulting competitive outcome, where smaller-scale chain establishments compete with small-single store retailers and examine whether the regulation, which is aimed at protecting small stores, has in fact been effective.Footnote 3
",18
44.0,1.0,Review of Industrial Organization,19 October 2013,https://link.springer.com/article/10.1007/s11151-013-9407-7,The Impact of Upfront Payments on Assortment Decisions in Retailing,February 2014,Pio Baake,Vanessa von Schlippenbach,,Male,Female,Unknown,Mix,,
44.0,2.0,Review of Industrial Organization,13 August 2013,https://link.springer.com/article/10.1007/s11151-013-9400-1,Introduction: The Economics of Internet Advertising,March 2014,Avi Goldfarb,Victor J. Tremblay,,Male,Male,Unknown,Male,,2
44.0,2.0,Review of Industrial Organization,02 August 2013,https://link.springer.com/article/10.1007/s11151-013-9399-3,What is Different About Online Advertising?,March 2014,Avi Goldfarb,,,Male,Unknown,Unknown,Male,"Bagwell (2007, p. 1705) noted that advertising is of interest to economists because it is a “prominent feature of economic life.” As people spend more time consuming media through the Internet, online advertising is becoming an increasing large fraction of the total advertising market. Some of the most prominent technology companies, including Google and Facebook, rely primarily on advertising through the Internet to generate revenue. Thus online advertising is also a “prominent feature of economic life.” This article discusses how the growing literature on online advertising differs from the broader literature on advertising that preceded it. While the rapid growth of online advertising initially led to calls for understanding a new paradigm (Hoffman and Novak 1997; Pavlou and Stewart 2000), companies use online advertising for the same reasons they deploy other kinds of advertising: As Bagwell (2007) notes, advertising can be persuasive, altering consumer tastes. It can be informative, reducing the cost of information acquisition by consumers. Or it can be complementary to the advertised product, increasing the consumption value of a product without altering underlying preferences. To my knowledge, nothing in the literature on online advertising alters this view to suggest a new purpose for advertising. Drawing on the literature on online advertising, I argue that the fundamental economic difference between online and offline advertising is a substantial reduction in the cost of targeting. While targeting has been mentioned in the prior advertising literature, it has not been focal to understanding the economics of advertising. For example, in Bagwell’s 144-page chapter in the Handbook of Industrial Organization, the word targeting appears just 15 times. Of these, five are in the references, and five are in the section that is titled “New directions and other topics”. In contrast, targeting is a recurring theme in the literature on online advertising. Just as reduced search and transportation costs have dominated the economic literature on electronic commerce (e.g. Bakos 1997; Balasubramanian 1998; Brynjolfsson and Smith 2000; Ellison and Ellison 2009; Forman et al. 2009), reduced costs of targeting have dominated the literature on online advertising. In particular, a reduction in the cost of targeting informs many of the recurring themes in the online advertising literature, including understanding advertising effectiveness, auctions, privacy, and antitrust. Therefore, in this article, I review the economics literature on online advertising through the lens of targeting. I argue that much of the literature on online advertising, even research that does not explicitly emphasize targeting, is driven by models in which the cost of targeting plays a key role. This review proceeds as follows: In the next section, I provide a brief primer on the online advertising industry. Next, I review the literature on online advertising that explicitly emphasizes targeting. Then I discuss how reduced costs of targeting inform the discussions in the literature on understanding advertising effectiveness, on auctions, on privacy, and on antitrust. I conclude with a general discussion and some caveats to the general theme discussed.",92
44.0,2.0,Review of Industrial Organization,30 November 2013,https://link.springer.com/article/10.1007/s11151-013-9406-8,Inducing Customers to Try New Goods,March 2014,Alessandro Acquisti,,,Male,Unknown,Unknown,Male,"Since many consumer transactions nowadays are computer mediated, merchants have become quite adept at leveraging knowledge of consumers’ traits and behavior to predict their preferences, reservation prices, and future choices. The scenario where a seller is able to predict a consumer’s future satisfaction with a product better than the consumer can herself may have sounded preposterous a few years ago; but it has become quite reasonable now, due to progress in data mining and business analytics which have fostered the advent of recommender systems, behavioral advertising, and other ways of using consumers’ data to target and personalize offers and products. In the case of so-called “recommender systems” (Resnick and Varian 1997), sellers employ data mining or collaborative filtering to combine information coming from the transaction histories (and degrees of satisfaction with said transactions) of previous customers. With this information, sellers then decide what good or service to offer or recommend to her next.Footnote 1 Examples of such systems abound both offline and online (Kohavi and Provost 2001). In the offline world, information from supermarket scanners is used to develop customized coupons based on past and contemporaneous purchases. In the online world, Amazon.com has been a pioneer in developing sophisticated recommender systems to promote books, CDs, and other products based on the contemporaneous purchases of many consumers (Schafer et al. 1999). Netflix has continued to invest to improve algorithms to predict a user’s degree of appreciation of a movie, based on movie ratings by the universe of its customers (Bennett and Lanning 2007). In the case of behavioral advertising (and affine concepts such as behavioral targeting, targeted advertising, or tailored ads), a marketer can combine information from a consumer’s online browsing behavior with knowledge or inferences about her traits to predict which ad will likely match her interests. This strategy is more likely to generate a sale or at least a clickthrough. Then, the marketer will show that ad to the consumer. The number of commercial systems that track online consumers’ online behavior (often across multiple sites) to offer such targeted ads has been steadily increasing in recent years: from Yahoo! Smart Ads to DoubleClick, from TACODA to NebuAd (Yan et al. 2009). The academic literature on behavioral targeting has only recently developed (Yan et al. 2009; Goldfarb and Tucker 2011; Beales 2010), and there is little research about situations in which the recommender is, actually, the seller. This paper is concerned with the incentives for a seller to report accurately its beliefs about whether or not potential buyers will like untried products, based on the analysis of the consumer’s (and her peers’) previous behavior. The scenario we consider shares some characteristics with recommender systems, in that the merchant’s predictions are based on feedback from multiple consumers. It also shares characteristics with targeted or behavioral advertising, where the merchant must decide whether to use its own predictions truthfully when contacting the consumer with personalized offers. We investigate a simple scenario for both one-shot and repeated customer-merchant interactions, involving repeated purchase and multiple goods. In the one-shot interaction, we find that there are two types of equilibria, depending on various parameter values: For some values, sellers will target all potential buyers, so such targeted ads and purchase recommendations provide no benefit to the consumer. But for other values, ads and recommendations will be accurate. In particular, the incentive for the seller to provide accurate offers will be inversely related to the difference between the cost of producing the good and its average market evaluation. With repeated interaction, the merchant is more likely to make “truthful” offers: those that the merchant expects to match the consumers actual preferences. This may be particularly the case when consumers can communicate among themselves easily, as is the case in an on-line environment, since the cost of a bad reputation may be much higher than without communication.",1
44.0,2.0,Review of Industrial Organization,20 December 2013,https://link.springer.com/article/10.1007/s11151-013-9403-y,Advertising Effectively Influences Older Users: How Field Experiments Can Improve Measurement and Targeting,March 2014,Randall A. Lewis,David H. Reiley,,Male,Male,Unknown,Male,"Retailing pioneer John Wanamaker (1838–1922) famously remarked, “Half the money I spend on advertising is wasted; the trouble is I don’t know which half”. Measuring the impact of advertising on sales has remained a difficult problem for more than a century (Bagwell 2008). The econometric problems of endogeneity and omitted-variable bias make it very difficult to establish causality, rather than mere correlation, from observational data. In the present paper, we overcome this problem with a large-scale controlled experiment for an online advertising campaign and decompose the estimated effects of the advertising by age and gender. We find the surprising result that this advertising has its largest impact on older people. As an example of the opportunity to draw mistaken conclusions from non-experimental data, we consider a recent state-of-the-art study by marketing practitioners (Abraham 2008). We quote this study, which estimates large positive effects of advertising on sales, to describe its methodology, “Measuring the online sales impact of an online ad or a paid-search campaign—in which a company pays to have its link appear at the top of a page of search results—is straightforward: We determine who has viewed the ad, then compare online purchases made by those who have and those who have not seen it”. With observational data, this straightforward technique can give spurious results. The population who sees a particular ad may be very different from the population who does not see it. For example, people who see an eTrade ad when searching for “online brokerage” are very different from those who do not see that ad, even in the absence of advertising. Almost certainly, those who search for “online brokerage” are much more likely to sign up for an eTrade account than those who do not search for “online brokerage”. So the observed difference in sales may not represent a causal effect of ads at all (Lewis and Reiley 2013). Many studies of advertising, both in industry and in academia, suffer from similar problems of establishing correlation rather than causality. In general, advertisers do not systematically vary their levels of advertising to measure the effects on sales. Advertisers often change their levels of advertising over time, running discrete “campaigns” during different calendar periods, but this variation does not identify causal effects because other relevant variables also change. For example, if a retailer both advertises more and sells more during December than in other months, we do not know how much of the increased sales to attribute to the advertising and how much to increased holiday demand. Similarly, observational academic studies that provide regressions of sales data on advertising data often produce positive relationships, but they might be due to reverse causality, when advertisers set advertising budgets as a fraction of sales (Berndt 1991; Dorfman and Steiner 1954; Richard 1972). A time-honored scientific method for establishing causal effects is to run a controlled experiment, with treatment and control groups. In the eTrade search-advertising example, we would ideally like to experiment on the population who searches for “online brokerage”, showing the eTrade ad only to a treatment group, but not to a control group. The idea of replacing observational studies with field experiments has recently gained importance in economics and the social sciences (Levitt and List 2008). Measuring the effects of brand advertising presents particular challenges, because the effects are likely to be quite diffuse. A given advertising campaign may be a very small factor in a given customer’s purchase decision, and the results may not be as immediate as in direct-response advertising. A large sample size should enable detection of an advertising signal from the sales noise, but historically it has been nearly impossible to measure both sales and advertising for each individual. Past attempts to use experiments to measure the effects of brand advertising on sales have found mixed results because of the low signal-to-noise ratio. In the 1960s, Ackoff and Emshoff (1975a); Ackoff and Emshoff (1975b) designed controlled experiments for Anheuser–Busch to evaluate the effects of increased or decreased quantities of advertising on beer purchases, with six geographical areas per treatment. In the 1970s, a series of 19 advertising experiments for Campbell’s Soup measured aggregate sales separately for up to 31 different geographical areas (Eastlack and Rao 1989). In the 1980s and 1990s, IRI’s BehaviorScan technology enabled advertisers to deliver differing quantities of television ads and measure the effect on sales for 3,000 households at a time (Abraham and Lodish 1990; Lodish et al. 1995a, b; Hu et al. 2007). These early experiments generally lacked sufficiently large samples to reach statistically conclusive results.Footnote 1
 In the present study, we take advantage of recent technological developments in online advertising and customer database management in order to overcome this signal-to-noise problem. Our controlled experiment tracks the purchases of over one million individuals in order to measure the effectiveness of a retailer’s nationwide display-advertising campaign on Yahoo! In the companion paper, Lewis and Reiley (2013), we reported results from this experiment. In this paper, we pay particular attention to an examination of heterogeneous treatment effects by age and gender. We find much larger effects for older than for younger customers, demonstrating that in this campaign, the younger customers were the Wanamaker’s “wasted half”. This case study demonstrates the value of experiments for improving the targeting of online advertising.",12
44.0,2.0,Review of Industrial Organization,17 November 2013,https://link.springer.com/article/10.1007/s11151-013-9409-5,A More General Framework to Analyze Whether Voluntary Disclosure is Insufficient or Excessive,March 2014,Levent Celik,,,Male,Unknown,Unknown,Male,"When potential buyers of a product are unable to observe the product quality prior to purchase but know that the seller is informed about it, they may anticipate that this information will be communicated, especially in favorable situations that benefit the seller. In fact, if the seller has access to a verifiable and costless means of disclosing information, then quality will be fully revealed in all equilibria. This is the so-called ‘information unraveling’ result, which was first established by Grossman (1981); Grossman and Hart (1980), and Milgrom (1981).Footnote 1 In the words of Grossman and Hart (1980): The buyer must use the simple logic that the seller tries to be as optimistic as possible about his product subject to the constraint that he not lie. When disclosure involves a strictly positive cost, on the other hand, Jovanovic (1982) shows that information does not fully unravel in equilibrium. In this case, the seller would rather stay silent for qualities that are below a certain threshold. However, disclosure is socially wasteful because it is purely redistributive. In other words, the seller engages in excessive information disclosure when it is costly to disclose quality. The “classical literature” assumes that consumers have unit demands with identical reservation prices.Footnote 2 Under this assumption, the total quantity consumed in equilibrium is the same for all disclosure policies. Therefore, for any positive disclosure cost (regardless of how small it is), all policies other than non-disclosure involve socially excessive levels of information disclosure.Footnote 3 However, it is not clear if this same result carries over to situations in which the market demand is downward-sloping. In such a case, disclosure generally leads to a change in the equilibrium quantity consumed and is therefore not purely redistributive anymore. Since the seller ignores any consumer surplus effects when making his disclosure decision, disclosure will be socially inefficient. However, it is a priori unclear if this inefficiency is in the form of excessive or insufficient disclosure. As noted earlier, when the cost of disclosure is positive, there will be an interior threshold quality level that leaves the seller indifferent between disclosing and not. If full disclosure of this particular threshold quality strictly raises the underlying consumer surplus, however, a social planner can improve the ex-ante expected aggregate welfare by marginally lowering this threshold.Footnote 4 In such a situation, the level of voluntary information disclosure will be socially insufficient. To address this question, I consider a simple model with a single seller and a single consumer who has a linear downward-sloping demand. I show that the excessive disclosure result of the “classical literature” is still valid when all quality levels are socially desirable and the consumer’s prior beliefs are uniform over the possible values of quality. A social planner cannot improve expected welfare by mandating that the seller disclose a larger set of qualities. In other words, the consumer surplus effect mentioned above is not large enough to make disclosure insufficient. Next, I identify two situations under which voluntary disclosure may be socially insufficient; both of these situations arise when the demand curve is sufficiently elastic: The first one is when there are quality levels that are too low to generate any positive demand by the consumer. In this case, non-disclosure may lead the consumer to reduce her demand to zero even if the actual quality normally induces a positive demand when disclosed (or, in other words, even if the actual quality is socially desirable). The second one is when the consumer’s prior beliefs place sufficiently higher weight on lower qualities. Now, a failure to disclose quality leads to a severely bad perception of the product, thereby significantly lowering the consumer’s demand. As a result, the amount of forgone consumer surplus is sufficiently large. The remainder of the paper is organized as follows: In the next section, I briefly review the literature. Section 3 introduces the main setup. In Sect. 4, I analyze the equilibrium and the socially efficient levels of disclosure for three different scenarios. Finally, in Sect. 5, I conclude. All proofs are relegated to the “Appendix”.",1
44.0,2.0,Review of Industrial Organization,31 July 2013,https://link.springer.com/article/10.1007/s11151-013-9398-4,Dynamic Entry and Investment in New Infrastructures: Empirical Evidence from the Fixed Broadband Industry,March 2014,Maya Bacache,Marc Bourreau,Germain Gaudin,Female,Male,Male,Mix,,
44.0,3.0,Review of Industrial Organization,29 January 2014,https://link.springer.com/article/10.1007/s11151-014-9418-z,Time to Unbridle U.S. Thoroughbred Racetracks? Lessons from Australian Bookies,May 2014,Charles C. Moul,Joseph M. G. Keller,,Male,Male,Unknown,Male,"The business models of U.S. and Australian racetracks are generally similar. In both countries, racetrack revenues include the betting handle through the racetrack, as well as nomination and entry fees by racehorse owners. Racetracks in both countries offer pari-mutuel wagering (described in more detail below) in which the track effectively serves as an intermediary for bettors to gamble against each other rather than against the track. Costs are payouts to winning bettors and purses to winning horses. The only difference of note is that Australian racetrack revenues also include fees paid by bookies for the privilege of on-site operation. Well in advance of race-day, expected purses and entry fees are announced, and horse-owners choose in which races to run. Final purses are then sometimes dependent on actual race-day handle. Withdrawing horses by owners for trivial reasons (e.g., weather) is discouraged, and almost all withdrawals occur because of stated injury or illness.Footnote 3 Comprehensive data on handle are difficult to find, but casual observation indicates that purses, handle, and entry fees show high and positive correlations. This ordering will serve as our later justification of using purse as a proxy for unobserved characteristics that are set before race-day (e.g., prestige). Crowds tend to grow throughout the day, and it is common for racetracks to begin with races that draw less betting interest and to improve race-quality with later races. After gambling was prohibited in almost all American states in the early 20th century, racetrack-operated pari-mutuel wagering on horse races was re-introduced during the Depression. The revenue-starved states coupled this resurrection with new excise taxes on handle, and most states continue to employ these taxes. As we discuss in our conclusion, the negative welfare consequences of our proposal (detailed by Schmalensee 1981) can be mitigated by a shift from these revenue taxes on handle to a tax on cumulative takeout receipts (variable profits). For a sense of the magnitudes of handles and the related taxes, Churchill Downs (Kentucky) in the 2011 season had about $603M in handle on which it paid about $20M in tax.Footnote 4
 Horse racing is categorized as thoroughbred, quarter-horse, or harness, but all horse race gambling in the U.S. exclusively uses the pari-mutuel format. In this format, all payouts are dictated by final odds, which depend on how the handle is distributed across the field of horses at race time. All pre-race posted odds are therefore preliminary, and bettors essentially make wagers for an unspecified price. For straight wagers such as win bets on a particular horse, the racetrack deducts from the handle a percentage equal to the takeout rate and returns the remaining money to the bettors who placed wagers on the winning horse. Odds for any given race are thus determined entirely by how bettors decide to wager. Bettors make these wagers at the racetrack or at off-track betting facilities.Footnote 5
 Takeout rates in the U.S. tend to be set by state government or by the state’s gambling regulatory body, though some states offer limited discretion to racetracks.Footnote 6 As of 2013, takeout for win bets on thoroughbreds ranged from California’s 15.43 % to Arizona’s 20.75 %.Footnote 7
 Kentucky has a typical structure of regulation and provides the most closely related empirical results to our exercise, and so it warrants special attention: Kentucky has a relatively low takeout rate of 16 % for straight bets such as win (\(1\mathrm{st}\) place), place (\(1\mathrm{st}\) or \(2\mathrm{nd}\)) or show (\(1\mathrm{st}, 2\mathrm{nd}\) or \(3\mathrm{rd}\)). Takeouts for exotic bets on multi-horse outcomes (e.g., exacta, quinella) are also regulated and tend to be several percentage points higher (e.g., Kentucky has a takeout of 19 % for those exotic bets).Footnote 8
 Bettor sensitivity to takeout rates has been explored econometrically as well as in several recent experiments. Previous researchers have used cross-sectional variation in takeout rates and amounts wagered to estimate price-elasticities for U.S. pari-mutuel gambling (Gruen 1976; Suits 1979; Mobilia 1993; Thalheimer and Ali 1998; Gramm et al. 2007). These studies have generally found that takeout rates are higher than the revenue-maximizing level, with estimated own-takeout elasticities ranging from \(-\)1.6 to \(-\)3. If a track’s costs are entirely fixed, then a social planner would prefer that takeout rates be lowered to reach the point of unit-elastic demand. To our knowledge, no studies have considered how race characteristics themselves can affect these price-elasticities—exactly the information that the estimates of our reduced-form model provide. There have also been several recent attempts to learn the responsiveness of bettors to this takeout rate with temporary (Laurel Park, MD 2007a; b) or permanent (Hialeah, FL 2010; Tioga Downs, NY 2010a; b) takeout reductions.Footnote 9
 Many empirical studies have examined the determinants of handle, but relatively few have used race-level (rather than year-level or day-level) characteristics as we do. We therefore judge how well our Australian data may illuminate the U.S. regulatory problem by leaning heavily on Coffey and Maloney (2010). That paper uses data from Churchill Downs in 1994 to distinguish the incentive effect from selection in explaining the correlation between performance and reward. More importantly for our purposes, it also includes regression results that show the impact of race characteristics on the amount of money wagered. The authors find that handle is increasing in purse and field size (i.e., number of horses) but is decreasing in dispersion of horse-talent. Australia, like other countries that were part of the 19th-century British Empire, allows gambling within both a pari-mutuel format and a fixed-odds format. Depending on the state, the pari-mutuel system is either state-run or operated under substantial regulation by a for-profit firm. The state pari-mutuel takeout rate in New South Wales (Sydney) and Victoria (Melbourne) varies by bet type; the pari-mutuel takeout rate for straight win bets is 14.5 % in both states. Pari-mutuel takeout in Queensland (Brisbane) is regulated differently in that the blended takeout (weighted average of straight and exotic bet takeouts) cannot exceed 16 % over a twelve-month period and no takeout rate can exceed 25 %. Fixed odds gambling in horse racing differs from pari-mutuel wagering in several ways. As the format’s name implies, odds offered to a bettor are fixed, though these odds may be changed for subsequent bettors. Key to our exercise, bookies’ pricing (i.e., odds-setting) is not regulated. Another obvious contrast with pari-mutuel wagering is the existence of the bookie: an individual who is actively setting odds. Each bookmaker should be thought of as a three-person team: the bookie who sets odds, the penciler who records odds, and the ledger who records bettors’ wagers. The number of bookies depends primarily on the physical size of the racetrack, though cities differ in how the number of bookies varies across race-days (discussed below). Typically between 20 and 40 independent bookmakers at these racecourses compete for bettor business against one another, against the on-site pari-mutuel system, and against all off-site gambling options. These bookies are located either near the track or among the audience. Racetracks charge bookies for the privilege of operating on site. Daily fees for these locations depend on the quality of location and race-day. For example, Sydney’s Australian Racing Club during our sample charged bookies daily stand fees of AUD 110-550. During our sample, racetracks also charged bookies a fee equal to 1 % of handle; this fee was bookies’ only noteworthy variable cost. While bookies may represent franchises, only one representative of each franchise is present at a track on a race-day. While all racetracks nominally charge bookies daily fees for the privilege of operating, conversations with racing club figures indicate that the actual practices differ somewhat across cities. Sydney racetracks appear to be the most aggressive in matching the number of bookies with projected demand, and the number of operating bookies can vary substantially at a track from week to week. Melbourne and Brisbane racetracks, on the other hand, tend to maintain similar numbers of bookies across weeks. These differences are more qualitative than sharp, and so we will not attempt to impose them in our estimation strategies. They do, however, provide context when interpreting later estimates. In our Australian data, the horses that are slated to race are known in advance of race day. Opening odds from the bookmakers are posted approximately 30 min before race time, and changes to these odds are periodically made prior to the posting of the official starting prices. As shown in McAlvanah and Moul (2013), the takeouts that are implied by these fixed odds start out relatively high (about 30 %) and tend to fall as the race approaches. This decline occurs as the bettor’s value of fixed odds wagers relative to pari-mutuel wagers becomes smaller. Under typical circumstances in which no new information is revealed after betting has commenced, one expects fixed odds and pari-mutuel odds to converge as racetime approaches. In the data and throughout this paper, a wager’s gross odds is the amount for each dollar wagered that is returned to the bettor in the event of his horse winning. For example, a $1 wager on a winning horse with listed odds of 4 would pay back $4 (the original $1 plus $3 of winnings). Two commonly used measures of bookies’ profit potential are the margin and takeout.Footnote 10 The margin \(m\) is defined as the amount of a marginal dollar wagered that is retained by the bookie as a proportion of the amount returned to bettors. It is expressed within the industry as the sum of all wager prices less one: given a field of \(K\) horses, \(m=\left( \sum _{i=1}^{K}\frac{1}{O_{i}}\right) -1\), where \(O_{i}\) is the odds on horse \(i\). The takeout \(T\) is defined as the amount of a marginal dollar wagered that is retained by the bookie as a fraction of the total amount wagered. A 25 % margin therefore corresponds to the bookie’s retaining 20 % of the total amount wagered as takeout and paying out 80 %, and the connecting formulae between margin and takeout are \(T=\frac{m}{m+1}\) and \(m=\frac{T}{1-T }\). Both the margin and takeout should be weakly positive; otherwise there exists an arbitrage opportunity for bettors to wager on the entire field and earn a positive return without risk. The choice of which measure to use as the dependent variable is admittedly arbitrary. While bookie margin has instructive parallels with Arrow–Debreu prices that sum to more than one as bookies impose the equivalent of a tax, we prefer the implied takeout in order to facilitate comparisons with the competing and American pari-mutuel regimes. All of our empirical results are robust to employing bookie margin instead of implied takeout rates as the dependent variable. The takeout is therefore implicitly determined by the set of odds that is chosen by the bookmaker and thus can vary across time, racetracks and races. Shin (1991, 1992, 1993) spearheaded the applicable economic literature that examines bookie profit margins. Our research is somewhat similar to Shin (1993) in that we both use the bookmaker’s implied profit margin as the dependent variable and employ race characteristics such as size of field and dispersion of horse-talent as explanatory variables. Unlike our paper, Shin (1993) does not consider the impacts of race quality (as proxied by purse) on margins. An additional difference is that Shin (1993) frames his empirical exercise as identifying the prevalence of insider trading, which he posits is the cause of the recurrently observed favorite-longshot bias in which favorites are underbet and longshots are overbet.Footnote 11
 Our approach, on the other hand, begins with descriptive regressions and then turns to estimating reduced-form models that are explicitly derived from a (simple) structural model. These results serve distinct purposes: The estimates from the descriptive regression are useful for predicting the equilibrium impacts of race characteristics on takeout. The reduced-form estimates illuminate the mechanisms by which those equilibrium impacts arise. The counterfactual exercises that are necessary to address our policy issue are also only possible when empirical results have a reduced-form interpretation.",4
44.0,3.0,Review of Industrial Organization,06 November 2013,https://link.springer.com/article/10.1007/s11151-013-9408-6,Bid Roundness Under Collusion in Japanese Procurement Auctions,May 2014,Rieko Ishii,,,Female,Unknown,Unknown,Female,"Bid rigging is a pervasive problem in public procurement auctions. In many bid-rigging cases—members of the bidding ring meet before each auction to choose the winner; the winner bids very close to the reserve price, while the losers deliberately bid even higher in the auction. However, little is known about how the fake bids are chosen, because bid rigging is illegal and is done in secret. Although theory suggests that the winner bids the reserve price and the losers bid even higher, this is not always the case in actual bid-rigging cases, probably because doing so could attract significant attention from the antitrust authority. We study bid data from a series of procurement auctions where the Japan Fair Trade Commission (JFTC) filed a bid-rigging case during the data period. Specifically, we remark on the way that the digits are arrayed in actual bids nominated in Japanese yen, and we discuss how this feature can be related to collusion using Poisson regression models. The particular property of a bid that we examine is its “roundness” level: the length of the consecutive array of zeros at the end of the bid number. For example, if the bid is 12,300,000 JPY, then its roundness level is 5. We hypothesize that collusion increases the roundness level of bids through the bid coordination process. Specifically, we hypothesize that winners will choose round numbers because they have an incentive to avoid miscommunication when they announce their planned bids to other members, who then bid above the winning bid. Other members will simply prefer round numbers when they are assigned to choose as a bid an arbitrary number that is higher than the winner’s bid. We find that: (1) there is a positive relationship between the roundness of a bid and its relative value as a fraction of the reserve price; (2) roundness of bids is higher when collusion is active than when it is inactive; (3) among the ring bids, winning bids tend to be more rounded than losing bids; and (4) bids by non-ring members are also round when collusion is active. The paper is organized as follows: Section 2 shows the related literature. In Sect. 3, we describe the market, the data, the hypotheses and the empirical model that we use in the analysis. Section 4 presents the results of the empirical analyses. We conclude in Sect. 5.",23
44.0,3.0,Review of Industrial Organization,01 March 2013,https://link.springer.com/article/10.1007/s11151-013-9375-y,Cartelization Through Buyer Groups,May 2014,Chris Doyle,Martijn A. Han,,,Male,Unknown,Mix,,
44.0,3.0,Review of Industrial Organization,02 October 2013,https://link.springer.com/article/10.1007/s11151-013-9405-9,"Spectrum Licensing, Policy Instruments and Market Entry",May 2014,Gary Madden,Erik Bohlin,Aaron Morey,Male,Male,Male,Male,"In granting spectrum rights to provide wireless communication services, national regulatory authorities (NRAs) often employ policy instruments to encourage mobile network operator (MNO) entry, and in doing so attempt to influence aftermarket competition.Footnote 1 For instance, some regulators set aside licenses for potential entrant bidders,Footnote 2 or issue targeted bidding credits (by discounting winning bid prices or providing additional amounts of spectrum).Footnote 3 Other policy instruments that are intended to encourage entry include the license assignment mode (auction or ‘beauty contest’)Footnote 4 and making more licenses (spectrum blocks) available than incumbent firms (excess licenses) Footnote 5 (Jehiel and Moldovanu 2003). The apparent justification for the policies is the presence of high wireless service market entry barriers. In particular, incumbents generally value licenses more than potential entrants because winning licenses prevents entry and restricts aftermarket competition. Also, legacy infrastructure is readily leveraged to provide third-generation (3G) services.Footnote 6 Moreover, there are substantial establishment costs on entering new markets.Footnote 7
 Surprisingly, there is an absence of empirical research indicating whether NRA policy instruments influence the probability of entry into 3G national markets. The resolution of this question is fundamentally important given industry convergence, the growth in the demand for data services, and the spectrum dividend that has been made available from the ‘switch off’ of analogue networks. Moreover, Gruber (2007) and Hazlett and Muñoz (2009) argued that the benefits from entry, including lower retail prices and improved service quality, are expected to be substantial. Most likely, this paucity of empirical analysis results from data limitations: The available data sets typically do not include information on whether potential entrants decide to bid or not. Accordingly, the econometric analysis requires that potential entrant participation decisions be incorporated into the estimating equations—i.e., that sample selection issues be addressed. This study obtains consistent parameter estimates by treating the issue as an omitted variable problem. The proxy variable is sourced from a censored entrant-to-bidder ratio regression. Additionally, ancillary instrumental variable (IV) binomial probit and Poisson regressions address endogeneity bias concerns that are related to the specification of the entry probability equation. Specifically, endogeneity concerns arise when regulators design assignments to encourage entry, and these instruments are arguments in the entry probability equation. Following the two-stage residual inclusion (2SRI) method, the residuals that are calculated from those ancillary regressions are introduced as additional arguments in the second-stage binomial probit probability of entry equation.Footnote 8
 Using a unique dataset covering national 3G spectrum license awards, our study addresses the principal research question: Do regulators’ licensing policy instruments promote entry? The econometric results show that the entry probability is enhanced by using auction assignments and excess licenses. Furthermore, quantity, but not price, concessions encourage entry.",7
44.0,3.0,Review of Industrial Organization,08 October 2013,https://link.springer.com/article/10.1007/s11151-013-9404-x,The Merger Clearance Decision Process in New Zealand: Application of a New Two-Stage Probit Model,May 2014,Qing Gong Yang,Michael Pickford,,,Male,Unknown,Mix,,
44.0,4.0,Review of Industrial Organization,29 January 2014,https://link.springer.com/article/10.1007/s11151-013-9416-6,Competition in Two-Sided Markets with Common Network Externalities,June 2014,David Bardey,Helmuth Cremer,Jean-Marie Lozachmeur,Male,Male,Male,Male,"The theory of two-sided markets deals with market structures in which two groups of agents interact via platforms; see for instance Rochet and Tirole (2003a). The central theme is the presence of network externalities, which occur when the benefit from joining a platform for individuals of a given group depends on the size of membership (and/or usage) of the other group. Prominent examples range from credit cards, media, and software to dating clubs. We consider a two-sided market with an externality of a different nature, which we refer to as a “common network externality” (CNE). This type of externality occurs when both groups benefit, possibly with different intensities, from an increase in the size of one group and from a decrease in the size of the other. They are relevant in many markets. For instance, in the health-care sector, hospitals compete for patients on one side and for providers on the other side; health-care quality is frequently related to the provider/patientratio, which represents a special case for our CNE. Similar issues may arise in education. In this paper, we revisit Armstrong’s (2006) framework with a common network externality. Two platforms compete in prices on two distinct Hotelling lines. The CNE enters the preferences of both groups as a quality parameter. Each group values the common externality with (possibly) different intensities, but the functional form that specifies quality is the same for both groups. We focus on the symmetric equilibrium and show that network externalities affect prices in a “cumulative” way: The price on one side of the market depends on the sum of the externality valuations on bothsides of the market. When the externality is specified by a homogeneous function, price structure and platforms’ profits present some special features. In particular, the effect on one side’s price is, partially or entirely, shifted to the other side of the market. The extent of shifting and the effect of the CNE on profits, depends on the sign of the homogeneity degree of the CNE.",18
44.0,4.0,Review of Industrial Organization,28 March 2014,https://link.springer.com/article/10.1007/s11151-014-9420-5,Risk Aversion and Technology Portfolios,June 2014,Guy Meunier,,,Male,Unknown,Unknown,Male,"In many industries, firms face random output and input prices. The electricity industry is a particularly striking example because uncertainties surround the prices of fossil fuels and \(\hbox {CO}_2\) emissions, the subsidy schemes that support renewable energies, the time to build new nuclear and coal plants, and the costs of efficient coal plants and carbon capture and storage facilities. These uncertainties influence the overall supply and the technology mix that is chosen by firms, especially if these firms are risk averse. Investment in a technology could be deterred because of risk and risk aversion, and this impediment could be linked to industry structure. This paper analyzes the supply of an industry that is composed of risk-averse firms. In the model used here, two technologies are available, and each firm must decide how much to produce with each technology. One technology has a lower expected marginal cost than the other and would be the sole technology used absent risk aversion. However, a firm can diversify its portfolio by investing in the other more costly technology to reduce its risk. The influence of correlation is emphasized. The supply of a single firm indicates that higher prices are associated with lower shares of the low-cost technology in a firm’s technology “portfolio”. If risks are sufficiently correlated, then the firm does not invest in the low-cost technology, but instead solely invests in the high-cost one if the output price is relatively high. Thus, risk and risk aversion can explain how a low-cost technology is driven out of a firm’s portfolio. Industry equilibrium with price-taking and Cournot competitors is described. With perfect competition, all firms have the same portfolio of technologies. The total industry supply is determined by the aggregate risk aversion of the industry and the demand function. The risk aversion of a particular firm only determines its size, not the composition of its portfolio.Footnote 1 With Cournot competition, this feature does not hold because less risk-averse firms not only produce more but also have a larger share of the low-cost technology. At equilibrium, relatively large firms may specialize in the low-cost technology while smaller firms may specialize in the high-cost technology. This specialization is endogenous and not assumed. Large firms are not large because they have privileged access to the low-cost technology but because they are less risk averse. Small firms are not prevented from using the low-cost technology because of some fixed cost (e.g., patent fees) but solely because of the risks and a firm’s risk aversion. That is, risk aversion determines both a firm’s size and its expected marginal production cost. The rest of the paper is organized as follows: In the next section the relationship of this work to the literature is reviewed. Then, the model is introduced (Sect 3). The model is first used to analyze the supply of a single firm (Sect. 4) and then the market equilibrium with either perfect competition or Cournot competition (Sect. 5). The robustness of the results are discussed in Sect. 6. Section 7 concludes.",5
44.0,4.0,Review of Industrial Organization,28 February 2014,https://link.springer.com/article/10.1007/s11151-014-9419-y,Why Don’t Most Merchants Use Price Discounts to Steer Consumer Payment Choice?,June 2014,Tamás Briglevics,Oz Shy,,Male,Male,Unknown,Male,"Recent legislation and court settlements in the United States allow merchants to use price discounts to steer customers to pay with instruments that are less costly to merchants than credit cards, in addition to giving discounts for payments made with cash. Despite the new freedoms, steering has not been widely observed across most merchant types. In seeking to understand why discounting to encourage the use of less costly payment instruments is not observed more widely, this paper attempts to answer the following question: to what extent can merchants lower their cost by providing price discounts to buyers who pay with debit cards and cash? More precisely, using transaction data from 2012, this paper calibrates and computes merchants’ net cost saving by providing price discounts to buyers who pay with debit cards; the minimum fraction of credit card users that is needed to switch from paying with credit cards to paying with debit cards in order make a 1-percent debit card price discount worthwhile for a merchant; merchants’ net cost saving from providing price discounts to buyers who pay with cash; the minimum fraction of credit and debit card users that is needed to switch to paying with cash in order make a 1-percent cash price discount worthwhile for a merchant; and how the calibration results vary by merchant type and transaction value. The key observation that triggers our analysis is that merchants pay different fees for receiving payments via different payment instruments (credit cards, debit cards, and cash, for our purposes). Although the reader may be familiar with some of the fees associated with payment card transactions, we now provide a brief discussion that clarifies some of the terminology used to characterize some of these fees, as displayed in Fig. 1. Note, however, that for the purpose of this paper the only relevant fee is the one that merchants have to pay for processing a card transaction. Understanding the precise way in which the proceeds of this fee are allocated among card processors, acquiring and issuing banks, and card networks is not essential for the analysis of merchants’ incentives to steer consumer payment choice. Fee structure of payment card transactions Each merchant has a bank account with an “acquiring” bank. However, the acquiring bank need not be the same bank that issues the card presented by the buyer. In this case, the acquiring bank must pay an “interchange fee” to the issuing bank for each transaction submitted by the merchant. Next, the acquiring bank passes on the interchange fee to the merchant. In addition, the merchant pays a fee to the card processor that provides the swipe machine and the connection between the merchant’s point of sale and the acquiring bank. Figure 1 does not distinguish between card processors and acquiring banks because the of nature the relationship between the two entities and the fee structure vary significantly among merchants. In some instances, they could be viewed as the same entity, at least from merchant perspective, and in this case the acquiring bank provides the merchant with the necessary equipment and connections. Whereas the card-issuing bank gains revenue from the interchange fee, the acquiring bank gains net revenue from the difference between the merchant fee and the interchange fee. In terms of magnitude, the interchange fee represents the major portion of the merchant fee. Figure 1 also shows that card networks gain revenue by charging both the issuing bank and the acquiring bank a per transaction fee. Card networks may be the major credit card networks (Visa, MasterCard, Discover, and American Express) that process credit as well as signature debit transactions, or they may be PIN debit card processors (Interlink, Star, and Pulse are examples). In the past, contracts between merchants and the credit card networks prohibited merchants in the United States from using discounts and surcharges to steer customers to pay for their purchases using payment instruments such as debit cards or checks that were less costly to merchants. However, merchants were allowed to give discounts to customers who pay cash.Footnote 1
 On July 20, 2011, the Eastern District Court of New York approved the settlement of an antitrust lawsuit that had been brought by the Department of Justice (DOJ) against Visa and MasterCard.Footnote 2 In the settlement, the two card networks agreed to allow merchants to use more flexible discounting and price differentiation by (a) offering customers a discount or rebate if the customer uses a particular brand or type of general purpose card or any other form of payment; (b) offering a free or discounted product, enhanced service, or any other incentive for the above; (c) expressing a preference for the use of a particular brand or type of general purpose card or other particular form of payment; and (d) promoting a particular brand, card type, or any other form of payment. The settlement contains language and issues that are related to some, but not all, aspects of the Durbin Amendment to the Dodd-Frank Wall Street Reform and Consumer Protection Act of 2010. The second part of the Durbin Amendment concerns “Limitation on Payment Card Network Restrictions.” The Amendment, which took effect on October 1, 2011, says, “A payment card network shall not\(\ldots \)inhibit the ability of any person to provide a discount or in-kind incentive for payment by the use of cash, checks, debit cards, or credit cards.” Thus, the language and discounting freedoms in this portion of the Durbin Amendment bear some similarity to those of the settlement. In the academic literature, it is hard to find papers that investigate whether and to what degree merchants can enhance their profit by providing price discounts on payment instruments that are less costly to them. Ingene and Levy (1982) examine marketing and financial implications of offering a discount to encourage payment with cash rather than with a credit card. They use a telephone survey sample of 248 respondents to offer hypothetical cash-price discount rates in the range of 0–6.5 percent. Grant (1985) extends Ingene and Levy (1982) by analyzing how the composition of payment instrument choice affects profits if merchants offer a discount. Borzekowski et al. (2008) investigate the sensitivity of debit card use to changes in bank-imposed transaction fees.Footnote 3
 Credit card surcharges are rarely observed in the United States, partly because several states still prohibit merchants from this practice. Hayashi (2012) provides an overview of the differences between debit and cash discounts and a credit card surcharge. Bolt et al. (2010) analyze the effects of a debit card surcharge in the Netherlands. Based on consumer and retailer survey data, they show that surcharging steers consumers away from using debit cards towards cash. Koboldt et al. (2011) show that consumers are more likely to switch payment instruments when faced with card surcharges than to leave the store and buy from a competing merchant. Finally, several papers have empirically investigated buyers’ characteristics associated with their choices of payment instruments; see, for example, White (1975), Bounie and François (2006), Klee (2008), Foster et al. (2011), Schuh and Stavins (2010), Ching and Hayashi (2010), Simon et al. (2010), and Arango et al. (2011). Shy (2012) uses the 2010 and 2011 pilot Diaries of Consumer Payment Choice to identify the types of merchants that were likely to pay higher and lower interchange fees after October 2011, when debit card interchange fees were capped. This paper proceeds as follows: Sect. 2 describes the data used in our calculations. Section 3 analyzes the relationship between profit and price discounts on debit card transactions by merchant type. Section 4 analyzes price discounts that are designed to steer customers to paying with cash. Section 5 discusses obstacles that may deter merchants from using discounts to influence customers’ payment choices and Sect. 6 concludes.",10
44.0,4.0,Review of Industrial Organization,08 August 2013,https://link.springer.com/article/10.1007/s11151-013-9401-0,Corporatization and the Behavior of Public Firms: How Shifting Control Rights Affects Political Interference in Water Prices,June 2014,Michael Klien,,,Male,Unknown,Unknown,Male,"Corporatized public enterprises, where the government retains ownership but control rights over business decisions are handed over from politicians to managers, have been suggested as viable alternative to privatization. As a matter of fact, organizations with these features are not uncommon in public service and infrastructure provision—especially in Europe. This observation holds true for the Austrian water sector and the dataset used in this paper but also for the European Union as a whole, where Dexia (2004) estimates a total number of 16,000 corporatized local public enterprises to be present in public service provision. Moreover, although the concept of corporatization is not new, the increased use of separate, legally autonomous agencies represents one of the major trends in public service provision (see CEEP 2010). Hence, the question arises as to what extent corporatization matters for firm behavior. Theoretically, as argued by Shleifer and Vishny (1994), corporatization changes firm behavior because independent managers derive no direct benefit from political objects like excess employment or political price setting. Thus, the associated hypotheses would be that corporatization curbs the effect of politics on public firms. Unfortunately, the existing empirical evidence on the consequences of corporatization (e.g. Shirley 1999; Bozec and Breton 2003; Bilodeau et al. 2007 or Cambini et al. 2011) has largely ignored the issue of political interference by focusing on potentially stronger economic incentives and interpreting corporatization as a weak form of privatization. The present paper tries to fill this gap by testing whether corporatization effectively restrains political interference. Using a dataset of Austrian water providers, a series of panel data estimations assess the effect of politics on water prices and whether corporatization affects this link. This paper therefore compares the price setting of corporatized and non-corporatized firms and tests whether their price setting is equally affected by political phenomena such as electoral cycles or partisan politics. The particular empirical application of the Austrian water sector is of interest because the absence of real privatizations should allow the isolation of the ‘pure’ corporatization effect. As argued by Villalonga (2000), separating institutional effects from the various other possible determinants of economic outcomes is detrimental for the empirical analysis of governance structures. This should be easier in the case of corporatizations, where ownership remains public and only control rights are transferred. In addition, the available dataset of Austrian municipalities is not only rich in terms of the wide variety of municipal characteristics of both the local water sector and the political situation but also with respect to the panel structure. The relatively long time dimension allows for the control of unobserved heterogeneity and represents an integral part of the empirical strategy. This paper contributes to the empirical literature that analyzes the consequences of different institutional arrangements such as Kwoka (2002), Chong et al. (2006), Bel and Warner (2008) or Cambini et al. (2011). However, unlike previous papers on the topic it puts greater emphasis on political interference and corporatization as mirrored both in the theoretical section and the empirical application. Moreover, instead of the prevalent and dichotomous comparison of public and private organizations, the paper analyzes an alternative type of public sector reform: corporatization. The consequences thereof have rarely been examined empirically. The paper is organized as follows. Section 2 discusses corporatization as a means of public sector reform along with the politics of water prices. In Sect. 3 the institutional background of the Austrian water sector is outlined. The empirical analysis of a panel of Austrian water providers is presented in Sect. 4. The final section discusses the results and concludes.",15
44.0,4.0,Review of Industrial Organization,01 January 2014,https://link.springer.com/article/10.1007/s11151-013-9415-7,The Impacts of an Antitrust Investigation: A Case Study in Agriculture,June 2014,Kalyn T. Coatney,Jesse B. Tack,,Female,Male,Unknown,Mix,,
45.0,1.0,Review of Industrial Organization,22 May 2014,https://link.springer.com/article/10.1007/s11151-014-9423-2,"Revenue Sharing with Heterogeneous Investments in Sports Leagues: Share Media, Not Stadiums",August 2014,Steven Salaga,Alan Ostfield,Jason A. Winfree,Male,Male,Male,Male,"Like many industries, firms or teams in professional sport have a variety of revenue sources and investment options. Some investments are clearly designed to increase specific revenue streams and do not directly affect other firms. Investments in labor, however, can directly and negatively affect other firms in the league since winning is zero-sum and teams sometimes hire from a common pool of playing talent. Many sports leagues have designed revenue sharing policies to limit investments in labor, but these policies are highly varied and filled with exemptions. This paper argues that the policies are quite sophisticated in curbing investments in labor, while also mitigating the disincentive to invest in other resources—namely, stadiums. Professional sport is unique from other industries in that league franchises are both on-field competitors and business partners (Neale 1964). The latter is clearly visible through the various revenue-sharing arrangements that are a hallmark of sports league structure. Leagues claim the reason for revenue-sharing policies is to increase competitive balance or create an environment of economic fairness. However, many of these policies are filled with loopholes and exemptions, which raise questions regarding the economic intent of such policies. This paper analyzes these various revenue-sharing strategies by developing a theoretical model with supporting examples that explain the incentives of these policies. Specifically, this paper distinguishes between investment types and revenue sources within the revenue sharing structure of leagues; this distinction has been mentioned in previous literature but not modeled (Késenne 2001). The two largest revenue sources for franchises are media and stadium revenues, and the decision on whether to share and to what degree to share these revenues has important economic implications for leagues. This paper argues that it is often more efficient to share media revenues, as opposed to stadium revenues. This is because sharing stadium revenues reduces stadium investments, which reduces profits for the league. The paper proceeds with a brief literature review and explanation of the model. Lastly, we provide three examples from sports leagues where this model is directly applicable. The first deals with the National Football League (NFL) and the sale of Personal Seat Licenses (PSLs); the second highlights the distribution of games via the Internet in Major League Baseball (MLB); and the last deals with revenue sharing policies in European football leagues.",8
45.0,1.0,Review of Industrial Organization,11 April 2014,https://link.springer.com/article/10.1007/s11151-014-9421-4,Determinants of the Locations of Alternative Financial Service Providers,August 2014,Robin A. Prager,,,,Unknown,Unknown,Mix,,
45.0,1.0,Review of Industrial Organization,20 January 2014,https://link.springer.com/article/10.1007/s11151-014-9417-0,Effects of FTA Provisions on the Market Structure of the Korean Automobile Industry,August 2014,Minsoo Park,Hongjai Rhee,,Unknown,Unknown,Unknown,Unknown,,
45.0,1.0,Review of Industrial Organization,22 May 2014,https://link.springer.com/article/10.1007/s11151-014-9422-3,Ocean Carriers’ Collusion Under Antitrust Immunity: Evidence of Asymmetric Pass-Through,August 2014,Michael K. Fung,,,Male,Unknown,Unknown,Male,"Economists have long been interested in whether prices respond asymmetrically to cost changes—a phenomenon known as “asymmetric pass-through”. Imperfect competition is among a few possible explanations for asymmetric pass-through. The traditional structure–performance hypothesis suggests that price setting should be more favorable to consumers in more competitive markets. In an oligopolistic market, colluding firms can make additional profits by increasing prices in response to rising costs more quickly than they decrease prices when costs fall. This study attempts to find evidence for asymmetric pass-through in the international shipping market. An array of past empirical studies has been conducted on asymmetric pass-through in areas such as banking and retail gasoline markets (see, for example, Berger and Hannan 1989; Borenstein et al. 1997). Compared with markets where price fixing is illegal, the international shipping market is arguably a more ideal avenue for investigating the presence of asymmetric pass-through under imperfect competition because ocean carriers’ collusion has antitrust immunity. Over 90 % of world trade by volume is transported by ocean shipping. Despite the importance of ocean shipping to world trade, the ocean liner shipping industry that provides scheduled services has been characterized by a remarkable degree of collusion for more than a century.Footnote 1 Since imperfect competition is one possible cause of asymmetric pass-through, this study sheds light on the competitiveness of the international shipping market by examining whether ocean carriers pass fuel cost increases through to freight rates more quickly than they pass through fuel cost decreases. The sample runs from 1991 to 2007, which is a period before the European Union repealed the exemption for ocean carriers’ collusion from the European Commission competition rules. The remainder of this paper proceeds as follows: Sect. 2 briefly reviews the past literature on asymmetric pass-through. Section 3 explains the background and motivation of the study. Sections 4 and 5 respectively construct the econometric framework and describe the data. Section 6 presents the main findings with respect to asymmetric freight rate adjustments. Section 7 explores an alternative explanation for such asymmetry, and Sect. 8 concludes the paper.",4
45.0,1.0,Review of Industrial Organization,12 July 2014,https://link.springer.com/article/10.1007/s11151-014-9426-z,Foreign Entry and Firm Advertising Intensity: Evidence from China,August 2014,Sizhong Sun,,,Unknown,Unknown,Unknown,Unknown,,
45.0,2.0,Review of Industrial Organization,20 August 2014,https://link.springer.com/article/10.1007/s11151-014-9435-y,How Does Ranking Affect User Choice in Online Search?,September 2014,Mark Glick,Greg Richards,Paul Seabright,Male,Male,Male,Male,"Recent anti-trust investigations of the internet search market in the US and Europe have considered to what extent search engines have the ability to influence traffic to websites. It is well known that the ranking (i.e. the hierarchical physical location on a search-results page) of websitesFootnote 1 is positively correlated with click-through rates (CTRs).Footnote 2 If this correlation reflected a causal impact of ranking on CTRs, then search engines with a large share of total search activity would influence a large amount of traffic to websites. How could a correlation between rank and CTRs arise if there were no causal impact of the former on the latter? This might occur through reverse causation: The search engine might accurately predict the relevance of websites to users (and therefore their likely future CTRs) and then place websites on the page as a function of this prediction. Using a unique dataset of individual search behavior we show that there is indeed a strong positive correlation between the rank of a website on a given search engine results page (SERP) and the probability that an individual will click on that website. Although part of this correlation can be explained by the predicted relevance of the website, there is a substantial direct causal impact even when this is taken into account. We find that being at the top of the ranking in the algorithmic search results has a large and statistically significant causal impact on the odds of receiving a user click, and that moving the website from rank 1 to rank 2 on the same page decreases the odds of a click by between one third and two thirds depending on the specific search that is undertaken. We concede that no single statistical method completely eliminates endogeneity concerns; however, our results are robust and all evidence points to very high economic significance of the algorithmic rank. There are no studies to our knowledge in the economic literature that estimate systematically the effect of rank in the algorithmic search results using individual user data. Athey and Meidan (2011) and Athey and Nekipelov (2011) are important papers on the analysis of user behavior in the paid results. Previous research has indicated that CTRs can increase markedly for results placed at the top of a results page compared to other ranks and pages (Smith and Brynjolfsson 2001; Xu and Kim 2008; Ghose and Yang 2009. Of these studies, Xu and Kim (2008) is based on a small-sample laboratory experiment, and Xu and Kim (2008) uses data on paid search from an advertiser. The closest study in spirit to ours is Smith and Brynjolfsson (2001), which uses individual data from an Internet book-purchase site, but this relates to purchases of homogeneous books rather than searches for heterogeneous websites. 
Armstrong et al. (2009) and Armstrong and Zhou (2011) study the welfare implications of “prominence” in search markets. Among studies investigating the impact of placement on sponsored search results, Jerath et al. (2011) demonstrate the existence of a “position paradox” where advertisements at higher positions obtain more clicks, but this effect can be offset by a superior firm reputation. The paradox is that the superior firm may make higher profits from bidding for lower ranked positions. In a similar vein, Baye et al. (2012), using search data that were aggregated by retailer, consider the impact of product position and product reputation on the organic search results page on CTRs and find that both are important factors. We proceed as follows. In Sect. 2 we describe the data selection process and provide summary statistics for our dataset. We also describe the nature of the search engine algorithm and provide descriptive evidence about the determinants of ranking. In Sect. 3 we demonstrate econometrically the effect of ranking on the probability of clicking on a website. Section 4 investigates the contribution of reputation and conspicuousness to enabling page rank to influence click probabilities. Section 5 concludes.",12
45.0,2.0,Review of Industrial Organization,15 August 2014,https://link.springer.com/article/10.1007/s11151-014-9433-0,Buyer Alliances as Countervailing Power in WIC Infant-Formula Auctions,September 2014,David E. Davis,,,Male,Unknown,Unknown,Male,"State agencies in the Special Supplemental Nutrition Program for Women, Infants, and Children (WIC) infant-formula procurement auctions receive lower net-prices when they are in buyer alliances than when they are unallied. State WIC agencies provide exclusive selling rights to a single infant-formula manufacturer in exchange for a rebate on each can of the firm’s brand that is sold to WIC participants. Firms bid for the right to be an agency’s exclusive supplier by offering a net price—wholesale price minus rebate—in an auction format. Some agencies have banded together to form buyer alliances. This paper investigates the effect of those alliances on net prices received by agencies. I estimate a reduced-form equation for WIC net-price bids. I find that agencies that are in alliances receive lower net prices and that net price decreases with the size of an alliance. In contrast, agencies that are outside alliances do not benefit from size increases. Some unallied agencies are as large as alliances; consequently, it is not clear why size has benefits for agencies that are in alliances, and not for equally-sized unallied agencies. The countervailing-power literature investigates how buyer size can affect the bargaining relationship between buyers and sellers. A paper by Dana (2012) suggests that the heterogeneous makeup of buyer alliances is what provides buyers with a bargaining advantage, and that it is not necessarily buyer size. I test whether agency heterogeneity within an alliance affects net-price bids by including a heterogeneity index in estimated equations. Results indicate that more inequality in the distribution within an alliance decreases net prices. Agency size and heterogeneity are linked, and a limitation on size also limits the ability of agencies to construct heterogeneous alliances. In 2004, Congress limited the size of new alliances to 100,000 participating infants and limited the ability of alliances with over 100,000 participating infants to expand.Footnote 1 I find a cost-reducing effect of alliance size that extends beyond 100,000 participating infants. The estimates in this paper suggest that costs decline until an agency serves nearly 200,000 infants.",2
45.0,2.0,Review of Industrial Organization,03 August 2014,https://link.springer.com/article/10.1007/s11151-014-9432-1,Spatial Price Discrimination in Input Markets with an Endogenous Market Boundary,September 2014,Chin-Sheng Chen,Hong Hwang,,Unknown,,Unknown,Mix,,
45.0,2.0,Review of Industrial Organization,24 July 2014,https://link.springer.com/article/10.1007/s11151-014-9428-x,Exclusive Dealing and Its Effects: The Impact of Large Music Festivals on Local Music Venues,September 2014,R. Scott Hiller,,,Unknown,Unknown,Unknown,Unknown,,
45.0,2.0,Review of Industrial Organization,17 August 2014,https://link.springer.com/article/10.1007/s11151-014-9436-x,The Relationship Between Outcome Uncertainties and Match Attendance: New Evidence in the National Basketball Association,September 2014,Wen-Jhan Jane,,,Unknown,Unknown,Unknown,Unknown,,
45.0,3.0,Review of Industrial Organization,03 September 2014,https://link.springer.com/article/10.1007/s11151-014-9440-1,The 80th Anniversary of the 1934 Communications Act and the Inception of the Federal Communications Commission,November 2014,Michelle Connolly,,,Female,Unknown,Unknown,Female,,
45.0,3.0,Review of Industrial Organization,27 August 2014,https://link.springer.com/article/10.1007/s11151-014-9429-9,The Rationality of U.S. Regulation of the Broadcast Spectrum in the 1934 Communications Act,November 2014,Thomas W. Hazlett,,,Male,Unknown,Unknown,Male,"The 1927 Radio Act continues to define the regime under which U.S. regulators allocate radio spectrum. The statute, already law, was included virtually verbatim in the Communications Act of 1934. This new law involved a structural change. Regulation of wireline telephony, which had been the purview of the Interstate Commerce Commission (ICC) since the Mann–Elkins Act of 1910, was excised from the ICC and placed in a newly crafted Federal Communications Commission (FCC). The Federal Radio Commission (FRC) was then folded into the FCC. This agency continues to regulate wired and wireless communications in the United States today. The traditional view with regard to the origins of spectrum allocation in the United States is that there existed an existential crisis in the 1920s radio broadcasting market: what has since come to be known as a “tragedy of the commons.” But, continues that view, radio spectrum possessed peculiar technical properties requiring special measures. On the one hand, transmissions in the atmosphere would tend to spillover from one frequency space to another, creating endemic conflicts between users. On the other hand, when limits were applied to remedy this destructive activity, the number of available opportunities to broadcast would be small in number, far fewer than the demand. Both views were expressed in an important 1943 Supreme Court case in which it was determined that radio’s ostensibly unique factors permitted licensing of the electronic press—broadcasting stations (including radio and then television)—despite the Constitution’s strict language forbidding such regulation of traditional media: “Congress shall make no law abridging freedom of speech... or of the press.” The “etheric bedlam”Footnote 1 view was stated thusly by the Court: Owing to its physical characteristics radio, unlike the other methods of conveying information, must be regulated and rationed by the government. Otherwise there would be chaos, and radio’s usefulness would be largely destroyed.Footnote 2
 And the “physical scarcity”Footnote 3 argument: Suppose, for example, that a community can, because of physical limitations, be assigned only two stations... One man, financially and technically qualified, might apply for and obtain the licenses of both stations and present a single service over the two stations, thus wasting a frequency otherwise available to the area.Footnote 4
 History has not been kind to this opinion, or its successor, Red Lion.Footnote 5 Ronald Coase (1959) skewered the logic of NBC, persuasively correcting both assertions of uniqueness. First, conflicts between radio users reflected a common social coordination problem. Were there no limits to how land or newsprint could be deployed, then these economic goods would themselves be squandered in costly disputes between rival users. While administrative allocations may supply such limits, they are not necessary. The typical solution, in fact, is to attach ownership rights to the resource. Market incentives then help discover the most valuable deployments; conflicts are resolved in favor of the best options. This insight, of course, went much further than questions regarding radio spectrum allocation.Footnote 6
 Second, the excess demand exhibited for TV licenses was normally remedied by the “the price system.” Policy makers might prefer to issue licenses by fiat, without competing (money) bids, to adjudicate the excess demand. But that was an outcome of policy choice, not physics. In subsequent research, it was further shown that the stylized history used to support the traditional logic was also unfounded (Hazlett 1990). Characterizing the early radio broadcasting market as one of “chaos” misinterpreted radio law and economics.Footnote 7 In fact, priority-in-use rules were deployed, allowing “five years of orderly development [1921–1926]” (FRC 1927, 10–11). Enforced by the U.S. Department of Commerce, acting under the 1912 Radio Act and adopting common law rights of first appropriation (Lueck 1995), exclusive frequency rights governed airwaves. Stations did not broadcast under conditions of anarchy. It was in July 1926, when the Commerce Department withdrew its enforcement pursuant to conflicting federal court opinions, that airwave conflicts threatened industry development. Over the next several months many stations jumped wavelengths and about 200 new stations (of an existing 550) broke into the market. This was explicitly referenced as “the period of the breakdown of the law” (Caldwell 1929, p. 34). The emergent confusion helped policy makers finally to pass legislation, after years of fruitless effort, imposing a “public interest” licensing statute, signed into law in February 1927. The new regulatory structure protected the broadcasting rights of large, commercial stations, while sweeping away smaller stations and non-profit broadcasters, including many of those latecomers who had entered the market during the “breakdown period.” It would soon begin restricting emerging technological rivals, such as FM radio. The explanation of the 1927 Radio Act was thus described as a standard instance of shared regulatory capture. Incumbent industry interests aligned with political leaders, who wished to gain influence over a powerful medium of expression, in supporting government control over licenses. The coalition was joined, if ironically, by activist citizens groups such as the American Civil Liberties Union that saw government regulation as a useful buffer against the domination of broadcasting by private corporations. This explanation of the origins of regulation differed from Coase’s. While accepting the normative argument that markets would likely exhibit superior performance to central planning, Hazlett (1990) criticized Coase’s “error theory.” In moving to government allocations, Coase saw policy makers as simply failing to consider market mechanisms. The “public interest” system adopted was due to a “misunderstanding of the nature of the problem” (Coase 1959, p. 14). Yet, this explanation was at odds with the reliance on property rights, the views of key contemporaneous players, and the strategic nature of the regulatory solution crafted. Against the “error theory” of Coase and the “public interest” theory that Coase had effectively critiqued was added a “franchise rents” thesis, which described regulation as the result of a successful political coalition that strove to create and distribute valuable license rights. This “revisionist” (Spitzer 1989, pp. 1044–1045) view of spectrum allocation was fairly well received by scholars (Krattenmaker and Powe , 1994); Moss and Fein (2003, p. 393) refer to it as “devastating”. But, more widely and deeply, Coase’s critique of the legal argument for special treatment, based on the unique technical characteristics of radio, swept aside all serious opposition. Respected jurists from Bazelon (1975) to Robert Bork (in TRAC 1986) noted that the physical scarcity justification for trimming First Amendment protections was simply wrong. Constitutional law scholars, such as Tribe (2007, 14:45–18:04), have accused Red Lion of “perpetrat[ing] a profound fallacy about spectrum scarcity... [I]t seems to me that were the Court to revisit the Red Lion issue... the odds are overwhelming that the current court would recognize the illogic of Red Lion...”. Yet, all has not been settled. Moss and Fein (2003) re-asserted the traditional, public interest view explaining the formation of the spectrum allocation regime. Stressing that policy makers found radio broadcasting of crucial importance to democratic society, and on those grounds worth regulating, the authors fault Coase for arguing that radio spectrum was an economic resource like any other. Then, turning to the public choice (franchise rents) view of regulation, they assert that the arguments given in the Congressional Record by advocates of “public interest” regulation reveal that those advocates’ primary concern was to counter monopoly control. This, Moss and Fein argue, required different tools than were used elsewhere—specifically, antitrust law—because the scarcity issues were distinct. “Like Hazlett and others,” they write, “we find considerable evidence that [Coase] mischaracterized the historical record.” But they carve out—or seek to reclaim—a Third Way. “[W]e do not believe the available evidence proves that lawmakers were guided mainly by self-interest, as opposed to their own sense of the public interest... American lawmakers presented a perfectly reasonable and logically consistent case for federal regulation of broadcasting.” They then position their line of attack. Policy makers were less concerned with providing for an “economically efficient allocation of scarce bandwidth than with their determination to prevent a potentially dangerous concentration of political power” (Moss and Fein 2003, p. 390; emphasis in original). This critique of Coase’s “error theory,” which bleeds over to the “franchise rents” theory, allows us to—as Moss and Fein suggest—“revisit” our theory of the origins of radio regulation. The transition from the 1927 Radio Act to the 1934 Communications Act offers a perfect analytical opportunity for just this exercise. Public interest licensing was legislated in February 1927; the FRC then allocated spectrum, and regulated licensees, for 7 years. The Communications Act was then adopted, Congress electing to insert—essentially, re-enacting—the 1927 Radio Act. This process, wherein the actions of the regulatory solution were evaluated and then endorsed, allows for a larger assessment of what policy makers intended to achieve. In charting the basic structure and performance of radio broadcasting markets, from the pre-Radio Act period to passage of the Communications Act of 1934, we can observe both regime change and the resulting political equilibrium.",
45.0,3.0,Review of Industrial Organization,08 August 2014,https://link.springer.com/article/10.1007/s11151-014-9431-2,Increasing the Efficiency of Spectrum Allocation,November 2014,Gregory L. Rosston,,,Male,Unknown,Unknown,Male,"Spectrum is used for a wide variety of wireless services: broadcast radio, television, point-to-point microwave, satellite, radar, and many others. Allocating spectrum among competing non-Federal uses is one of the fundamental duties that the 1934 Communications Act assigned to the Federal Communications Commission (FCC or Commission).Footnote 1 The FCC historically has determined what services and technologies can make use of specific frequencies of the electromagnetic spectrum through an administrative rulemaking process.Footnote 2 Typically, the FCC puts different services in different parts of the spectrum (bands), although there are many exceptions where two or more uses share bands. This entire planning process, from the earliest stage through rulemaking and licensing, can take many years. Despite whatever success the Commission had at determining an optimal combination of service and technology at any point in time, continuing changes in consumer preferences and technology eventually cause that combination to become suboptimal. As the divergence between the value in the current service and in potential new uses increases, so do the gains from reallocation. In other words, the overall allocation process should strive to be both statically and dynamically efficient. Technology has changed the nature and economics of both wireless and wireline communication services, and these technological advances have interacted with communications policy and have led to a much greater variety of services available to consumers (Rosston 2014). Wireless technology has advanced, most importantly with the advent of cellular architecture, digital technology, satellite systems, and Wi-Fi. At the same time, the introduction of cable television systems, fiber optic backhaul, and the Internet have changed the nature of substitutes and complements for spectrum-based services. As new mobile wireless devices have become available, consumer demand for mobile wireless services has increased dramatically. In just the past 10 years, more than one-third of households have given up wired home phone service entirely, and apparently are relying instead on phone service from their wireless provider.Footnote 3 Consumers are also increasingly accessing the Internet over mobile devices for a variety of applications, including streaming video. Starting with Coase (1959), economists have argued for market allocation of spectrum.Footnote 4 Subsequently, there have been a large number of authors who have advocated that spectrum allocations should permit greater flexibility of use.Footnote 5 With the introduction of cellular service, which was first commercially licensed in 1984, the FCC not only repurposed a large amount of spectrum (115 MHz) but provided greater flexibility with the introduction of more flexible licenses that covered large spectrum blocks and geographic areas within which cellular licensees could deploy multiple, low-power base stations and reuse assigned frequencies as needed to meet demand. Prior to this increased flexibility, the FCC licensed each base station to operate on a particular frequency at a specific location to cover an area with a single high-power transmitter. In its initial cellular decisions the FCC continued its practice of requiring licensees to use a specific technical standard and to provide a specific service: mobile voice. In contrast, the 1994 Personal Communication Service (“PCS”) allocation (which also repurposed spectrum) had very few restrictions on either service or technology beyond those that were meant to control interference. The combination of technological advances and changes in demand and supply provided motivation for the movement of spectrum from initial allocations to more valuable uses over time. The FCC’s increasing reliance on market-based spectrum policies has facilitated the movement. Of course, reallocations would not have occurred without pressure from interest groups: service providers, consumers, and politicians who were interested in potential auction revenue. At the same time, some constituencies have opposed these moves: e.g., institutional advocates of services that stand to lose spectrum, incumbents who face potential interference or relocations, and companies that were concerned about potential competition from those that were granted greater flexibility. This paper examines several important examples of changes in spectrum use and highlights some of the complex issues that have been encountered as well as the roles of the FCC and private market actors in facilitating those transitions. There have been three main regimes for the transition of spectrum from one use to another: mandates by the FCC; initiatives by incumbent licensees to acquire additional rights with the approval and facilitation of the FCC; and most recently, the introduction of a two-sided auction to reallocate spectrum from broadcast to mobile broadband use voluntarily while simultaneously repacking incumbents in a reduced amount of spectrum and re-structuring cleared spectrum to maximize its value for mobile wireless. The case studies in Sects. 3 and 4 illustrate technical, regulatory, and business obstacles that have hampered the move toward more efficient spectrum use. The lessons from these case studies shed light on some of the decisions the FCC has made and will have to make in implementing its upcoming two-sided auction.",9
45.0,3.0,Review of Industrial Organization,19 July 2014,https://link.springer.com/article/10.1007/s11151-014-9427-y,An Oligopoly Model for Analyzing and Evaluating (Re)-Assignments of Spectrum Licenses,November 2014,Simon Loertscher,Leslie M. Marx,,Male,,Unknown,Mix,,
45.0,3.0,Review of Industrial Organization,25 June 2014,https://link.springer.com/article/10.1007/s11151-014-9424-1,Trying to Promote Network Entry: From the Chain Broadcasting Rules to the Channel Occupancy Rule and Beyond,November 2014,Stanley M. Besen,,,Male,Unknown,Unknown,Male,"Starting in the early 1940s, the U.S. Federal Communications Commission (FCC) expressed concern about the lack of competition among networks, first in radio and then in television. However, many of the policies that the Commission adopted that were intended to promote competition were either ineffectual or were undercut by others of its policies, primarily its efforts to promote “localism” in the origination of programming. Only the FCC’s eventual removal of barriers to new network entry was successful in achieving the Commission’s goal. This article recounts that history.",
45.0,3.0,Review of Industrial Organization,29 August 2014,https://link.springer.com/article/10.1007/s11151-014-9437-9,Merger Review by the Federal Communications Commission: Comcast–NBC Universal,November 2014,Christopher S. Yoo,,,Male,Unknown,Unknown,Male,"Among the many innovations created by the Communications Act of 1934 was a unique regime for reviewing mergers between communications companies. As a general matter, mergers are subject to the general review process created by the Sherman Act of 1894 and the Clayton Act of 1914, which give the antitrust authorities (specifically the Federal Trade Commission (FTC) and the Antitrust Division of the Justice Department) the right to try to convince a court to block any merger that they believe would substantially lessen competition. The Clayton Act also gave the Interstate Commerce Commission (ICC) concurrent jurisdiction over mergers involving common carriers. The Communications Act of 1934 transferred the ICC’s authority to review telecommunications mergers to the newly created Federal Communications Commission (FCC). More importantly, the 1934 Act added two new provisions that the FCC has invoked as an alternative statutory basis for reviewing communications mergers. Specifically, these new provisions prohibit companies from acquiring or transferring any telecommunications lines or broadcast stations without the FCC’s approval. The result is a system of dual merger review that requires that all communications mergers be cleared by two agencies instead of just one.Footnote 1
 Over the past two decades, the FCC’s merger review authority has become increasingly controversial and has attracted substantial criticism from both commentators and FCC Commissioners.Footnote 2 These criticisms largely focus on: (1) the substantive standards that are applied by the FCC in reviewing mergers; and (2) the adequacy of the procedures that govern merger review by the FCC. The key complaint is that the FCC implements its merger review authority in ways that both harm consumers and are subject to potential abuse. Comcast’s January 2011 acquisition of NBC Universal (NBCU) provides a useful lens through which to evaluate both of these complaints. It shows how ambiguities in the substantive standards that are applied by the FCC as well as key differences in the procedural rules allow the FCC to evade restrictions that are imposed on the antitrust authorities to help ensure that merger review promotes consumer welfare. A brief review of the aftermath of the decision raises questions as to whether this merger review benefited consumers.",3
45.0,4.0,Review of Industrial Organization,04 November 2014,https://link.springer.com/article/10.1007/s11151-014-9447-7,Introduction: Antitrust and Regulatory Update,December 2014,Lawrence J. White,,,Male,Unknown,Unknown,Male,,2
45.0,4.0,Review of Industrial Organization,22 October 2014,https://link.springer.com/article/10.1007/s11151-014-9444-x,"Economics at the FTC: Office Supply Retailers Redux, Healthcare Quality Efficiencies Analysis, and Litigation of an Alleged Get-Rich-Quick Scheme",December 2014,Keith Brand,Martin Gaynor,Elizabeth Schneirov,Male,Male,Female,Mix,,
45.0,4.0,Review of Industrial Organization,24 October 2014,https://link.springer.com/article/10.1007/s11151-014-9445-9,"Economics at the FCC, 2013–2014",December 2014,Allison Baker,Timothy Brennan,Aleksandr Yankelevich,Female,Male,Male,Mix,,
45.0,4.0,Review of Industrial Organization,01 October 2014,https://link.springer.com/article/10.1007/s11151-014-9442-z,The Year in Review: Economics at the Antitrust Division 2013–2014,December 2014,Aditi Mehta,Aviv Nevo,Jeffery Wilder,Female,Male,Male,Mix,,
45.0,4.0,Review of Industrial Organization,08 November 2014,https://link.springer.com/article/10.1007/s11151-014-9446-8,Recent Developments at DG Competition: 2013–2014,December 2014,Benno Buehler,Gábor Koltay,Massimo Motta,Male,Male,Male,Male,"The Directorate General for Competition (henceforth “DG COMP”) at the European Commission enforces competition law in the areas of antitrust (anti-competitive agreements—including cartels—and abuses of dominant position), merger control, and state aids. The workload of DG COMP can be characterized as follows: Over the past few years the European Commission has issued on average 10–12 antitrust decisions per year (the average duration of such cases between registration and decision is 4–5 years);Footnote 1 270–300 merger decisions per year, with an intervention rate (that is, the number of prohibitions, approvals subject to remedy, and withdrawal in the second phaseFootnote 2) of about 5 %;Footnote 3 and around 400 state aid decisions per year.Footnote 4
 The Chief Economist Team (which counts about 30 members) is involved in a subset of these cases. Typically it participates in antitrust cases that lead to intervention (although with a minor involvement in cartels, where cases largely hinge upon documentary evidence) and the most important merger cases (including all second phase cases), as well as the economic aspects of state aid cases. The following three sections report on important and interesting work that was done last year at DG COMP: Section 2 deals with two recent antitrust decisions (Samsung and Motorola) in the area of Standard Essential Patents (SEPs), which have recently attracted a lot of attention both in academic environments and in the media (for example the frequent news of litigation among holders of SEPs—involving, for instance, Apple, Google, Samsung—and associated court judgments around the world). Section 3 deals with INEOS/Solvay:Footnote 5 a merger case that involved the two top sellers in a chemical product market, in which DG COMP took advantage of the existence of previous recent mergers involving INEOS to carry out an ex-post evaluation of those past mergers in order to obtain valuable insights for the merger under review. Section 4 also deals with ex-post assessments, but with a different perspective and application. As a part of the State Aid Modernisation programme, EU Member States (MSs) should evaluate their aid schemes themselves. DG COMP has prepared guidelines in order to help MSs to design and carry out ex post assessments of their schemes, and we shall briefly report on the main points touched upon in the guidelines.",4
46.0,1.0,Review of Industrial Organization,10 January 2015,https://link.springer.com/article/10.1007/s11151-014-9443-y,The U.S. Federal Trade Commission at 100: A Symposium on FTC Economics,February 2015,Joseph Farrell,,,Male,Unknown,Unknown,Male,,
46.0,1.0,Review of Industrial Organization,08 July 2014,https://link.springer.com/article/10.1007/s11151-014-9425-0,"The Federal Trade Commission, Oligopoly, and Shared Monopoly",February 2015,F. M. Scherer,,,Unknown,Unknown,Unknown,Unknown,,
46.0,1.0,Review of Industrial Organization,08 August 2014,https://link.springer.com/article/10.1007/s11151-014-9434-z,Economics and the FTC’s Google Investigation,February 2015,Michael A. Salinger,Robert J. Levinson,,Male,Male,Unknown,Male,"In January 2013, the Federal Trade Commission (FTC) closed its 19-month investigation that focused on whether alleged “search bias” by Google violated US antitrust law.Footnote 1 According to the FTC’s brief closing statement, the bias allegations were that “Google unfairly preferences its own content on the Google search results page and selectively demotes its competitors’ content from those results.” The closing statement went on to explain that the key finding that convinced the FTC to close its investigation was that Google did not change “its search results primarily to exclude actual or potential competitors.” Instead, it concluded, “The totality of the evidence indicates that, in the main, Google adopted the design changes that the Commission investigated to improve the quality of its search results” (Federal Trade Commission 2013a). The Bureau of Economics is a distinctive feature of the organizational structure of the Federal Trade Commission. The internal organization of the FTC is designed to preserve an independent voice for economists. One widely accepted role for economists at the FTC is to perform the statistical analyses that are needed for both the Commission’s antitrust and consumer protection enforcement missions. But, as important as econometrics has become in some cases, the Commission’s need for statistical expertise is not sufficient to explain the number of economists employed by the FTC or the prominence of economics in the FTC’s organizational structure.Footnote 2
 The FTC’s Google investigation is an important case for evaluating the role of economists and economics at the FTC because the stakes were high and because, while econometric analysis was not central to the investigation, economics principles were. Assessing the unique role of the Bureau of Economics in such cases is harder than in cases where econometrics plays prominently. In antitrust investigations, the Commission receives separate memos from the Bureau of Economics and the Bureau of Competition (which houses the attorneys who work on antitrust enforcement) as well as separate recommendations from the two Bureau Directors.Footnote 3 When the Bureaus disagree and the Commission heeds the advice of the Bureau of Economics, the effect of the Bureau of Economics is clear. But such cases are rare. As we were not employed by the FTC during the investigation, we cannot know what positions the Bureau of Economics took or what direct influence it had on the final outcome. But focusing on the positions taken by the two Bureaus and, in particular, the differences between them in a particular case can miss the broader impact of the Bureau of Economics. The value of economics at the FTC often manifests itself in concurrence between the Bureaus on an economically sound decision that results from their history of collaboration in antitrust enforcement. We believe that the FTC’s decision to close its investigation into Google’s search practices was economically sound. We identify, on the basis of information that was revealed in the Commission’s closing statement in this matter, two ways in which economic reasoning appears to have helped the FTC arrive at its decision and a third way in which it might have helped. One possible role for economics was to provide a broad policy perspective on the appropriateness of government intervention in the design of Internet search sites. The FTC’s investigation concerned Google’s product design, which is the most important dimension of competition in Internet search. As a broad policy matter, we would expect most economists to argue that the government should exercise extreme caution about intervening in product design. A second possible role for economic reasoning was to help distinguish competitive from anticompetitive behavior. The Commission’s clear articulation of the point that Google’s competitive efforts to improve its search results for Google users would naturally harm some competitors reflects a key economic insight. However obvious the point might seem, antitrust enforcers in the past have often failed to understand it when economic analysis played less of a role in antitrust enforcement than it currently does. A third possible role for economics was in applying legal standards with economic content. Market definition arises in all antitrust cases (except possibly for price fixing cases). We argue that product definition would also have been an issue if the FTC had brought a case. We argue further that the practice of addressing legal standards with economic content is not merely a requirement of the modern legal system (as some economists both inside and outside the FTC sometimes argue) but is in fact an important mechanism for ensuring that antitrust enforcement is economically sound. The remainder of this article is organized as follows: A fundamental issue in the investigation was whether Google’s search results were biased toward its “Universals.” One cannot analyze that issue without understanding exactly what Google’s Universals are. Section 2 explains them. Section 3 discusses the nature and history of Internet search. This material provides the essential context for understanding Google’s development of Universals. Section 4 then turns to our analysis of the role of economics in the case. It is divided into three sections, each of which is devoted to one of the three possible roles for the Bureau of Economics. Section 5 contains a brief set of conclusions.",11
46.0,1.0,Review of Industrial Organization,02 August 2014,https://link.springer.com/article/10.1007/s11151-014-9430-3,"A Brief History of the FTC’s Bureau of Economics: Reports, Mergers, and Information Regulation",February 2015,Paul A. Pautler,,,Male,Unknown,Unknown,Male,"This paper provides some of the history of the Economic Division (now called the Bureau of Economics or BE) at the Federal Trade Commission (FTC). I describe the early period of the Economic Division, focusing mainly on the industry investigation and report writing activities. The early roles of economists in antitrust and consumer protection activities also get some mention. I then skip forward to the post-1980 period to discuss a few research and policy issues in which economists played leading roles: the formation of horizontal merger guidelines, the advent of merger retrospectives, and the effects of information in food health claims and mortgage loan disclosures. This history provides some insight into the life of the organization and its evolution.",5
46.0,2.0,Review of Industrial Organization,27 August 2014,https://link.springer.com/article/10.1007/s11151-014-9438-8,Competitive Effects of Exchanges or Sales of Airport Landing Slots,March 2015,James D. Reitzes,Brendan McVeigh,Samuel Moy,Male,Male,Male,Male,"Congested airports in the United States (including John F. Kennedy, LaGuardia, Newark Liberty, and Reagan National), Europe (including London Heathrow, Frankfurt, Madrid Barajas, and over 80 other airports), and elsewhere (e.g., Brazil, Australia, Japan) explicitly restrict the number of flights that may depart from or land at those airports by requiring that airlines have specified times—“slots”—for departures and landings. These “landing slot”Footnote 1 restrictions effectively place a cap on the total number of flights that may be offered to and from these airports, as well as the number of flights that may be offered by individual airlines that operate at these airports. In that sense, slot constraints constitute an explicit output restriction on airlines that use these airports. Airlines that possess landing slots have the freedom to choose the routes where they will use their landing slots. For example, while slot restrictions at John F. Kennedy (“JFK”) airport restrict the total number of flights from the airport, airlines that hold slots choose the destinations that they fly to (and from). In that sense, an airline’s slot holdings impose a constraint similar to that facing a multi-product firm that must determine how to allocate its output across different products, subject to a pre-determined capacity constraint. In this case, the products are different destinations that the airline could serve from the slot-constrained airport. An airline’s slot allocation decision is affected by how many other airlines possess slots, the quantity of slots that each possesses, and the routes that each competitor chooses for its slots. The impact of changes in the distribution of landing slots poses an important policy question, given recent transactions that involve consolidations of slots, such as airline mergers, airline alliance expansion, and outright sales and exchanges of slots. The issue is also an interesting economic question, given that total output (i.e., the total number of flights that are offered from a specified airport) may not be affected by such a transaction but output levels for individual markets (i.e., individual city-pair routes) are likely to be altered. While mergers and other forms of horizontal consolidation in many industries can frequently result in reduced output and losses in both consumer surplus and social welfare, do the effects of consolidation differ in a multi-product industry when total industry output is fixed?Footnote 2
 To the best of our knowledge, there is little prior work on how consolidations or divestitures of slot holdings affect airlines’ route choices and the number of slots that are used on a particular route, along with the associated welfare impacts. In this paper, we construct a game-theoretic model to investigate these questions. We find that when route-level fixed costs are low, decreased concentration of slot ownership leads to overall increases in social welfare and consumer surplus, though fewer routes are served. For example, in a symmetric slot-constrained Cournot–Nash equilibrium, we find that an increase in the number of slot-holding airlines may reduce the number of routes served, but it raises both social welfare and consumer surplus. A similar effect arises when slots are transferred from a larger slot holder to a smaller slot holder (holding the number of slot-holding airlines constant). Such transfers tend to reduce the number of served routes, but increase both social welfare and consumer surplus. Although these findings arise when airlines face zero or modest levels of route-level fixed costs, we show that they may be reversed if airlines face significant fixed costs in entering individual routes. In that case, more concentrated allocations of slots may actually be associated with fewer routes served and higher social welfare and consumer surplus. This paper is organized as follows: Sect. 2 presents some useful institutional background and a brief literature review. Section 3 presents our model, and Sect. 4 provides our results. Section 5 considers how our results may be affected by heterogeneous costs across airlines, network-related demand effects, connecting passengers, and other factors. Section 6 offers some potentially useful anecdotal evidence with regard to slot allocations (based on the recent slot exchange by US Airways and Delta), and Sect. 7 has concluding remarks.",4
46.0,2.0,Review of Industrial Organization,29 August 2014,https://link.springer.com/article/10.1007/s11151-014-9439-7,Competition Between Sports Leagues: Theory and Evidence on Rival League Formation in North America,March 2015,XiaoGang Che,Brad R. Humphreys,,,Male,Unknown,Mix,,
46.0,2.0,Review of Industrial Organization,20 September 2014,https://link.springer.com/article/10.1007/s11151-014-9441-0,Explaining Variation in Title Charges: A Study of Five Metropolitan Residential Real Estate Markets,March 2015,Robert M. Feinberg,Daniel Kuehn,Sisi Zhang,Male,Male,Unknown,Male,"Title charges are costs that are related to establishing and insuring title in a real estate transaction. Title charges include the costs of performing a title search, preparing a title insurance binder, attorney or other settlement agent fees, the cost of the insurance that covers the lender and (often) the buyer against title defects, and other fees related to processing the title insurance policy. Establishing that a seller has legitimate ownership of his or her property is essential to the smooth operation of residential real estate transactions, given the large share of household wealth tied up in property (GAO 2007). Title insurance also merits attention because it represents a substantial proportion of residential real estate closing costs that are paid by consumers and adds significantly to the cost of purchasing a home. Title charges vary considerably across the U.S.Footnote 1: Woodward (2008) finds that nationally, title charges averaged $1,200 per loan for FHA-insured loans in 2001. The GAO’s (2007) study of the industry identifies a wide range of premiums—the amount that is paid for the insurance policy and the major component of title charges—from an average of $700 in Des Moines, Iowa, to an average of $2,190 in New York City. Title charges are also an important component of the wider array of closing costs. A widely cited, regularly conducted survey of closing costs by bankrate.com consistently concludes that the substantial variation in title insurance charges across real estate markets accounts for much of the observed variation in closing costs (Lewis 2014). Title charges not only vary widely across markets, but also vary considerably within a metropolitan area. This study uses data from almost 3,000 FHA-insured, 30-year fixed-rate home purchase loans from May and June, 2001, in counties covering five major metropolitan real estate markets to examine the determinants of variation in title charges faced by consumers within each area.Footnote 2 To our knowledge this is the first paper that examines variation in title charges within metropolitan areas, controlling for characteristics of homebuyers, houses, neighborhoods, and settlement agencies. The model is reduced-form and does not attempt to estimate structural parameters. The five metropolitan areas studied (Cook County, Illinois; Philadelphia County, Pennsylvania; Broward County, Florida; Maricopa County, Arizona; and Sacramento County, California) were selected due to variation in the regulatory regimes in each market and especially the perception of Cook County and Philadelphia as being on opposite ends of the regulatory spectrum. Qualitative interviews with market participants (settlement agents, underwriters, and academic and legal experts) inform the empirical model and interpretation of the regression analyses. Multivariate regression analysis provides insights into the role of market-specific institutions in shaping the title charges. Our analysis of title charges across the five metropolitan areas suggests that the amounts paid by consumers vary substantially, both between and within areas. The price of a housing unit, amounts paid to real estate agents, and settlement agent fixed effects are found to be associated with title charges, though the association differs by market and component of title charges. In most of the markets studied, title charges for comparable properties vary substantially across settlement agents. Minority homebuyers pay higher total title charges than do white homebuyers in Broward and Cook counties. After controlling for various characteristics of homebuyers, housing units, neighborhoods, and the identities of the top settlement agents, between 84 % (Cook County) and 46 % (Philadelphia) of the variation in total title charges remains unexplained. Section 2 provides a brief description of the existing research on title charges. Section 3 describes market characteristics in each of the five metropolitan real estate markets. Section 4 discusses data and methods. Section 5 presents regression results, and Sect. 6 concludes.",
46.0,2.0,Review of Industrial Organization,18 December 2014,https://link.springer.com/article/10.1007/s11151-014-9448-6,Public Enterprise Efficiency: The Case of the New York Canals,March 2015,Donald F. Vitaliano,,,Male,Unknown,Unknown,Male,"Few undertakings of the 19th century are more iconic than the Erie Canal in New York State. The Canal began operations in 1825 and an enlarged version of the Canal and a system of branch canals operated into the 20th century; it triggered a national frenzy of canal building that lasted for several decades, until railroads rose to dominate transportation. It is arguably the most important government enterprise in the economic history of the United States. Even today, the Erie’s luster is largely untarnished. Bernstein (2005, p. 443), for example, writes that “This narrow ribbon of ditch, less than 375 miles long, provided the spark, the flashpoint, and the inspiration for a burst of progress inAmerica...” Bernstein’s notion of an on-time and on-budget canal is echoed by Engerman and Sokoloff (2004). Canal founder DeWitt Clinton opposed private ownership, writing in 1817 that “The cardinal interests of the state may be subordinated to the cupidity of a private association.” (Cranmer 1961, p. 131). As a natural monopoly, the Canal’s proponents feared abuse of market power under private ownership; and later it was claimed that as a public enterprise the canals served as a check against predatory pricing by railroads. The downside of public enterprise is limited incentives to minimize costs, which stem from attenuated property rights and limited competition. The present paper employs the econometric technique of stochastic frontier regression to assess the cost efficiency in operating and maintaining this key piece of 19th century public infrastructure. Short-run costs are estimated to have exceeded minimum costs by 42 % for the 10 canal system, but the dominant Erie Canal’s costs were 50 % above least cost. The paper is organized as follows: The frontier model is explained in the next section, followed by data description and model estimation. The inefficiency estimates are then presented; the management structure of the canals is outlined and followed by a regression analysis of the inefficiency residuals. An 1817 proposal for a privatized canal is discussed, followed by a summary and conclusion.",
46.0,2.0,Review of Industrial Organization,21 January 2015,https://link.springer.com/article/10.1007/s11151-015-9449-0,R&D Collaboration with Uncertain Intellectual Property Rights,March 2015,Dirk Czarnitzki,Katrin Hussinger,Cédric Schneider,Male,Female,Male,Mix,,
46.0,3.0,Review of Industrial Organization,31 March 2015,https://link.springer.com/article/10.1007/s11151-015-9459-y,Introduction: 40 Years of Areeda–Turner,May 2015,Jeroen Hinloopen,Stephen Martin,,Male,Male,Unknown,Male,"
Phillip Areeda was the leading antitrust scholar of his day. His works and his students continue to illuminate the field (Breyer et al. 1996; Clark 1996). Donald F. Turner, who held degrees in economics and in law and served as Assistant Attorney General for the Antitrust Division of the U.S. Department of Justice, co-authored Antitrust Policy: An Economic and Legal Analysis with Carl Kaysen and Antitrust Law with Phillip Areeda (Breyer 1996; Hovenkamp 1996).Footnote 1
 Their 1975 Harvard Law Review paper, “Predatory Pricing and Related Practices under Section 2 of the Sherman Act”, aimed to (1975, pp. 699–700) “formulate meaningful and workable tests for distinguishing between predatory and competitive pricing by examining the relationship between a firm’s costs and its prices”. It advocated substituting such objective tests for (1975, p. 699, footnotes omitted) “empty formulae [such] as ‘below cost’ pricing, ruinous competition, or predatory intent”. It has transformed the treatment of exclusionary pricing under U.S. antitrust law, and this special issue of the  Review of Industrial Organization commemorates the 40th anniversary of its publication.
 In the lead essay, Herbert Hovenkamp discusses the law, economics, and application of the Areeda–Turner “price below an appropriate measure of unit cost, along with a reasonable expectation of recoupment” test for finding that pricing constitutes monopolization in violation of antitrust law. “The most fundamental critique”, he writes, is that the test “carved out large areas of strategic ... behavior and made them immune from antitrust challenge”. But the straightforward way it can be applied—although Hovenkamp offers cautionary remarks on this point—has ensconced it firmly in the antitrust rulebook. Stephen Martin first offers a “readers’ guide” to the 1975 paper. He then explains the differing receptions of the price-unit cost approach to the evaluation of predatory pricing in U.S. antitrust policy and EU competition policy, with emphasis on the differing views as to the likelihood that predation will occur and differing weights that are given to the probability of incorrectly condemning competition on the merits as predatory and incorrectly exonerating predatory behavior as competition on the merits. For William S. Comanor and H. E. Frech, the research question is “whether predatory pricing ... is common and detectable”. From their review of the economic analysis of predatory pricing, they conclude that theory rules out equilibrium predatory pricing in static games with complete and perfect information, but not otherwise. They note that whether or not a firm sets price above or below some measure of unit cost is not, in and of itself, central to the modern analysis of exclusionary pricing; what is central is the way that dominant incumbent pricing affects the expectations of potential entrants and fringe incumbents. They find experimental evidence to be consistent with the possibility of equilibrium predatory pricing. After reviewing recent claims of predatory pricing in passenger airline markets (among others), they urge that rather than being a threshold that must be satisfied before an antitrust challenge can proceed, the Areeda–Turner test should be regarded as “a potentially useful form of inquiry ..., but one that is neither necessary nor dispositive”. Deirdre L. Hay and George A. Hay discuss the impact of Areeda and Turner (1975) on Australian competition policy, in the context of the Boral decision.Footnote 2 They explain differences between Section 46 of the Competition and Consumer Act, as it was at the time of the decision, and Section 2 of the Sherman Act. In particular, Section 46 has as a threshold requirement for application that a firm that is alleged to have engaged in exclusionary conduct have a “substantial degree of power in a market”. 
Boral itself involved the Melbourne-area market for concrete masonry products. In the mid-1990s, construction of a new plant, the resulting excess capacity, and a slump in demand engendered a price war in this market. One consequence was the exit of two smaller firms. Another was that the Australian Competition and Consumer Commission brought a complaint against Boral under Section 46, although Boral’s market share never exceeded 30 %, and at the end of the day, its market share was less than the market share of the firm that built the new plant. Although the application of the Areeda–Turner price-cost comparison was clearly an issue, at least as important was the role of a requirement to show a reasonable prospect of recoupment of profit lost during a predatory campaign.Footnote 3 On this matter, the Australian High Court gave with one hand and took away with the other. It held that if the recoupment requirement were satisfied, this would contribute to satisfying the Section 46 threshold requirement that an offending firm have a substantial degree of market power. It also held that Boral did not have a reasonable likelihood of recoupment. Finally, Stefan Behringer and Lapo Filistrucchi point out that the premise of the Areeda–Turner rule, that a profit-maximizing firm will not set a price below marginal cost except for exclusionary purposes, can fail to function properly in platform (i.e., two-sided) markets. They develop an extension of the rule for such markets. Applying this extension to two cases studies, they show that application of the one-sided Areeda–Turner test to two-sided markets can lead to mistaken assessments. Hovenkamp (1996, p. 835) observes that much of the controversy that swirls around the Areeda–Turner rule focuses on its implication that exclusionary prices that are above unit cost are not to be treated as illegal under the antitrust laws. The contributions to this special issue suggest that there is no danger that this controversy will subside.",
46.0,3.0,Review of Industrial Organization,17 March 2015,https://link.springer.com/article/10.1007/s11151-015-9456-1,The Areeda–Turner Test for Exclusionary Pricing: A Critical Journal,May 2015,Herbert Hovenkamp,,,Male,Unknown,Unknown,Male,"Few works of legal scholarship have had the impact enjoyed by Areeda and Turner’s (1975) article on predatory and strategic pricing (Areeda and Turner 1975). Every federal circuit court except the Eleventh has embraced some variation of the test that Areeda and Turner proposed.Footnote 1 The Supreme Court has come very close to adopting it as well. Proof of predatory pricing under the Areeda–Turner Test requires two things; the sequence is not important, and most decisions focus on whichever element is disputed or easier to resolve: First, the plaintiff must show a market structure and arrangement of firms such that the predator could rationally have predicted that the predatory pricing strategy would be profitable. This requirement, typically called “recoupment,” requires the plaintiff to show that, looking from the beginning of the predation campaign, the predator can reasonably anticipate that the present costs of predation will be more than offset by the present value of a future period of monopoly profits, thus making the strategy a sound investment. Second, the plaintiff must show that the defendant’s prices over a significant number of sales were below a relevant measure of cost, presumptively average variable cost (AVC) or, in some cases, marginal costs over a relatively short run. While Areeda’s and Turner’s original 1975 article is generally associated with the second point, on price/cost relationships, it stated the recoupment requirement as well. Writing in response to the excessively subjective, intent-based tests that courts had been applying, they (1975, p. 698) concluded that: These vague formulations of the offense overlook the fact that predation in any meaningful sense cannot exist unless there is a temporary sacrifice of net revenues in the expectation of greater future gains. Indeed, the classically-feared case of predation has been the deliberate sacrifice of present revenues for the purpose of driving rivals out of the market and then recouping the losses through higher profits earned in the absence of competition. Thus, predatory pricing would make little economic sense to a potential predator unless he had (1) greater financial staying power than his rivals, and (2) a very substantial prospect that the losses he incurs in the predatory campaign will be exceeded by the profits to be earned after his rivals have been destroyed. Later, in developing this recoupment requirement, (Areeda and Turner 1975, pp. 698–699) wrote: attention must also be given to the second prerequisite, which is less likely to occur. Although a predator may drive competitors into bankruptcy, their durable assets may remain in the market in the hands of others. Moreover, a firm can anticipate monopoly profits for only so long as its monopoly prices do not attract new entry. Losses incurred through predation could be regained in markets with very high barriers to entry. In many markets, however, and especially in those having a number of small rivals, entry barriers may be nonexistent or at least too low to preclude entry. Admittedly, a demonstrated willingness to indulge in predatory pricing might itself deter some smaller potential entrants, but it is unlikely to inhibit firms with resources comparable to those of the predator. Repeated predation in the same market, moreover, is not only costly but is likely to be easily detectable and thus the occasion for severe antitrust sanctions. The prospects of an adequate future payoff, therefore, will seldom be sufficient to motivate predation. Indeed, proven cases of predatory pricing have been extremely rare. Nearly the entire balance of Areeda and Turner’s article was devoted to the proper price–cost test. For that reason the recoupment requirement is often not considered to be a part of the Areeda–Turner Test, although it was clearly there. This view was exacerbated by the fact that nearly all of the early controversy surrounding Areeda’s and Turner’s article swirled around the AVC test, not the structural recoupment requirement. Further, although the courts almost immediately began citing Areeda and Turner in predatory pricing cases, nearly all of the early citations were to issues that involved price–cost relationships, not to structure and recoupment.Footnote 2 Indeed, one characteristic of many of these early decisions was that they addressed predatory pricing claims in markets where monopolization of any kind, let alone by predatory pricing, would have been impossible to achieve. The first serious judicial discussion of the recoupment requirement appeared in the Supreme Court’s 1986 Matsushita decision, where the Supreme Court observed that predatory pricing’s success, and thus its rationality, was unlikely in the market at hand because there was no reasonable prospect of profitable recoupment. The Court cited the Areeda–Turner article for that proposition.Footnote 3 Judge Easterbrook’s 1989 decision in the A.A. Poultry case then elaborated the requirement more fully, citing both the Areeda–Turner article and the Antitrust
Law treatise (Areeda and Hovenkamp 2015).Footnote 4 Judge Easterbrook noted the difficulties inherent in measuring price/cost relationship and took the easier route of considering recoupment in a market (egg production) that was competitively structured and where entry was easy. The Supreme Court then fully embraced this view in its 1993 Brooke
Group decision, which focused almost entirely on the recoupment requirement and again cited both the Areeda–Turner article and the Antitrust Law treatise.Footnote 5 Subsequently, in its 2007 Weyerhaeuser decision involving claims of predatory purchasing, the Court held that under the Sherman Act a plaintiff must show both recoupment and prices below a relevant measure of cost,Footnote 6 implicitly adopting an argument that predatory pricing claims should be dismissed in situations where doing so made no economic sense (e.g., Werden 2006; Melamed 2006).",13
46.0,3.0,Review of Industrial Organization,31 March 2015,https://link.springer.com/article/10.1007/s11151-015-9458-z,Areeda–Turner and the Treatment of Exclusionary Pricing under U.S. Antitrust and EU Competition Policy,May 2015,Stephen Martin,,,Male,Unknown,Unknown,Male,"Areeda and Turner (1975, p. 699) motivate their work with a critique of the received antitrust treatment of predation: “Courts in predatory pricing cases have generally turned to such empty formulae as ‘below cost’ pricing, ruinous competition, or predatory intent in adjudicating liability. These standards provide little, if any, basis for analyzing the predatory pricing offense.” Their purpose, then, is not to analyze predatory pricing as such. They aim to provide a logical structure for enforcement of the predatory pricing offense and to categorize types of exclusionary pricing that should be considered to violate antitrust law and the types of exclusionary pricing that should not be considered to violate antitrust law. The Areeda–Turner rule has had great but differing impact on U.S. antitrust and EU competition policy. In this paper, I compare the way Areeda and Turner (1975) has fared in the two systems. This paper is organized as follows: Sect. 2 contains a brief review of U.S. antitrust and EU competition policy toward dominant firm conduct. In Sect. 3.1 I offer a “readers’ guide” to Areeda and Turner (1975), limiting myself for the most part to comments that might have been made at the time the paper appeared. Section 3.2 takes note of two developments in economics over the last 40 years that relate to the paper’s contribution. In Sect. 4, I turn to the reception of the Areeda–Turner rule on alternate sides of the Atlantic. Section 5 concludes.",2
46.0,3.0,Review of Industrial Organization,27 March 2015,https://link.springer.com/article/10.1007/s11151-015-9457-0,Economic Rationality and the Areeda–Turner Rule,May 2015,William S. Comanor,H. E. Frech III,,Male,Unknown,Unknown,Male,"The Areeda–Turner (1975) (AT) rule in U.S. antitrust jurisprudence limits predatory pricing liability to circumstances where prices are set below marginal costs (which, in turn, are proxied by average variable costs). While not cast as such, the rule reflects the view that predatory pricing is rarely attempted; and even where attempted is rarely successful; and even where attempted and successful, is difficult to identify. The AT rule has gained such prominence that it is now embodied in two U.S. Supreme Court decisions. In the first one brought against a group of Japanese television manufacturers and decided in 1986, the Court dismissed a charge that low predatory prices in the U.S. were recouped by high, collusively set prices in Japan.Footnote 1 While the decision did not directly address price-cost concerns, it did state that “there is a consensus among commentators that predatory pricing schemes are rarely tried, and even more rarely successful.”Footnote 2
 Then just 7 years later, in 1993, the Supreme Court addressed the price-cost issue directly. The plaintiff alleged a predatory pricing scheme with which the jury verdict agreed and assessed damages. However, the trial judge reversed the verdict as a matter of law. Eventually, the Supreme Court took the case. In its decision, the Court rejected “the notion that above-cost prices that are below general market levels or the cost of a firm’s competitors inflict injury to competition cognizable under the antitrust laws,” and ruled explicitly that “plaintiff seeking to establish competitive injury resulting from a rival’s low prices must prove that the prices complained of are below an appropriate measure of its rival’s costs.”Footnote 3 In effect, the Areeda–Turner rule became law through this decision. As Herbert Hovenkamp observed, “The effect of Areeda and Turner’s predation test has been devastating for predatory pricing plaintiffs” (Hovenkamp 2014, p. 3). Courts are reluctant to take action against purported predators even under highly suggestive circumstances.Footnote 4 In this paper, we examine the theoretical and empirical foundations of the rule, and also whether the current judicial antipathy towards predatory pricing actions should be reconsidered.Footnote 5
 As a legal matter, the Areeda–Turner rule limits predatory pricing to circumstances where firms set prices below marginal costs.Footnote 6 At higher prices, firms receive safe harbor protection, which effectively immunizes them from antitrust liability.Footnote 7 The rule’s premise is that a rational profit-maximizing firm never sets prices below marginal costs in the absence of predatory purposes. For this reason, when such prices are actually observed, there is a strong suggestion of a predatory motive. This premise, of course, is correct only under simple static circumstances. On the face of it, the Areeda–Turner rule does not imply that prices exceeding marginal costs can never be predatory; but merely that they are ambiguous. From this ambiguity, Areeda and Turner conclude that there should be no liability in such circumstances. This recognition follows because most prices exceed marginal costs and are not predatory. But some prices above marginal costs are predatory, both in effect and intent.Footnote 8
 The AT rule rests on a judgment that instances of predatory pricing are so rare that courts should tread lightly in dealing with above-cost pricing allegations. Furthermore, and not obvious on its face, applying the marginal-cost test in practice is usually quite difficult. Requiring this analysis creates a further barrier to the successful prosecution of cases against predatory pricing, even when the Areeda–Turner criterion for predatory pricing is met.Footnote 9
 The Areeda–Turner rule, like most policy rules, rests on the distinction between Type I and Type II errors. By enforcing this rule, the decision-maker seeks to minimize the presence of Type I errors: finding predation when in fact it is not present (a “false positive”). The rule necessarily permits increased Type II errors: finding no predation when in fact it is present (a “false negative”). Since both types of error are relevant for antitrust and other policy decisions, enforcing this rule makes sense only if: (a) There are few instances of predatory pricing; or (b) If it is very difficult to determine when they are present; or (c) The social costs of a Type I error are much higher than those of a Type II error; or (d) Some combination of these possibilities. If, on the other hand, there are many and varied circumstances where prices are set for predatory purposes, then the premise underlying the rule is questionable, and there may be good reasons to reject or modify it. What then becomes critical is whether predatory pricing behavior is common and detectable. Shedding light on that question is the purpose of this paper.",3
46.0,3.0,Review of Industrial Organization,05 April 2015,https://link.springer.com/article/10.1007/s11151-015-9461-4,Areeda–Turner “Down Under”: Predatory Pricing in Australia Before and After Boral,May 2015,Deirdre L. Hay,George A. Hay,,Female,Male,Unknown,Mix,,
46.0,3.0,Review of Industrial Organization,18 April 2015,https://link.springer.com/article/10.1007/s11151-015-9460-5,Areeda–Turner in Two-Sided Markets,May 2015,Stefan Behringer,Lapo Filistrucchi,,Male,Male,Unknown,Male,"In this paper, we extend the Areeda–Turner rule to two-sided markets. We do so by following the original logic of Areeda and Turner (1975). In their seminal article, the authors set out to identify a rational dividing line between legitimately competitive prices and prices that should be regarded as predatory. Adopting the classical definition of predation as the deliberate sacrifice of present revenues for the purpose of driving rivals out of the market and then recouping the losses, they proposed that “[u]nless at or above average cost, a price below reasonably anticipated (1) shortrun marginal costs or (2) average variable costs should be deemed predatory, and the monopolist may not defend on the grounds that his price was ‘promotional’ or merely met an equally low price of a competitor”. In addition “[r]ecognizing that marginal cost data are typically unavailable” they concluded that “[a] price below reasonably anticipated average variable cost should be conclusively presumed unlawful”.Footnote 1
 Following the original logic of Areeda and Turner (1975), we seek a threshold for the price, such that a price below this threshold should be deemed predatory. We argue that such a threshold needs to take into account the specificity of two-sided markets. In these markets firms act as platforms and sell two different products or services to two distinct groups of customers.Footnote 2 An example is the newspaper market, in which publishers sell content to readers and advertising slots to advertisers. A two-sided market is further characterised by indirect network externalities between the two groups of users. These arise when the utility (or the profits) obtained by a customer (whether a final consumer or a firm) of one group depends on the number of customers of the other group and the two groups of customers do not internalise these externalities.Footnote 3
 In the case of newspapers, advertisers place a greater value on advertising in a given newspaper the more readers the newspaper has. Readers may or may not be affected by the amount of advertising in the newspaper,Footnote 4 but for the market to be two-sided already the presence of one indirect network effect is sufficient.Footnote 5
 Whereas customers do not internalize the externality (or externalities) above, two-sided platforms do internalize it (them) when deciding their optimal pricing strategies. As a result, the profit-maximizing prices by two-sided platforms may be very different from those charged by firms in one-sided markets. As pointed out by Rochet and Tirole (2006), in a two-sided market, where two products or services are sold to two groups of customers, one can distinguish the price level from the price structure. The price level is the sum of the two prices, while the price structure is the ratio of the two prices. When the unit of measurement of the goods or services sold on the two-sides are different and the matching of customers on the two sides is not one to one, the price level is not simply the sum of the two prices, but rather the sum of the two prices expressed in the same unit of measurement.
 In the case of newspapers the price level is the sum of the cover price and the per-copy advertising revenues.Footnote 6 Similarly, the price structure is the ratio of the two.Footnote 7 In two-sided markets not only the price level but also the price structure determines firms’ profits. For instance, the profits of a publisher not only depend on how much revenues per copy of the newspaper it can raise but also on what percentage of revenues comes from readers versus advertisers: For a given revenue per copy, a business strategy that charges only readers may not be as profitable as one that charges only advertisers. Indeed, we observe free newspapers more often than we observe no-advertising newspapers. The difference in pricing strategies that characterizes two-sided markets warrants in many instances a different antitrust treatment. A recent review discussing these issues is Evans and Schmalensee (2015). Parker and Alstyne (2005) were among the first to present an economic model that highlights that in two-sided markets pricing below marginal cost on one side may be a (nonstrategic) profit-maximising strategy. Indeed, by pricing below marginal cost on one side of the market a firm increases sales on that side, thus boosting demand and profits on the other side. Wright (2004) included the claim that “price below marginal cost on one side of the market is a sign of predation” among the eight fallacies that derive from applying a one-sided logic to two-sided markets.Footnote 8
 Despite the warnings of the economics literature, competition authorities and courts tend to analyse predatory claims with a one-sided logic. In the recent case Bottin Cartographes versus Google,Footnote 9 for instance, the Commercial Court of Paris found Google guilty of the abuse of a dominant position in the market for online maps that allow stores’ geolocation.Footnote 10 The Court reached its decision by simply considering that the price of Google Maps API, being equal to 0 €, was necessarily lower than the production costs of the service. Interestingly, the Court stopped just short of recognizing the implications for competition policy of the two-sided business strategy of Google, as it recognized that Google, according to the contracts, would be able to insert advertising in its Google Maps API service and therefore sell targeted advertising. Judgements such as the one above may partly be due to the fact that most policy contributions so far, such as Wright (2004), have criticized the application of the one-sided Areeda–Turner rule to two-sided markets without suggesting an alternative. Even those policy contributions, such as Fletcher (2007) or Evans and Noel (2008), that recognized the necessity to provide guidance to practitioners fall short of providing new applicable methods. In fact, when Google appealed the decision of the Commercial Court of Paris, the Court of Appeal of ParisFootnote 11 decided to suspend the proceeding and ask the French Competition Authority to deliver an opinion on whether Google’s conduct had to be considered anticompetitive.Footnote 12 The request of the Court of Appeal highlights the uncertainty among practitioners with regard to criteria to establish predatory pricing in two-sided markets. We contribute to filling this gap by explaining how one should modify the Areeda–Turner rule to account for the two-sidedness of a market. Testing for predatory pricing in a two-sided market must take into account the presence of the indirect network effects between the two sides. Hence, it has to recognize that price-cost margins on the two sides of the market are interrelated. We thus show that one needs to compare the overall price level with the joint marginal cost of the two-sides of the market. Since, as already noted by Areeda and Turner (1975), marginal cost data are difficult to obtain, one should compare the overall price level with the overall average variable cost. Filistrucchi et al. (2013) point out that there exist two-types of two-sided markets. Two-sided non-transaction markets are characterized by the absence of a transaction between the two sides of the market and, even though an interaction is present, it is usually not observable, so that a per-transaction (or per-interaction) fee or a two-part tariff is not possible. Typical examples are media markets. Two-sided transaction markets are instead characterized by the presence and observability of a transaction between the two groups of platform users. As a result, the platform is able to charge not only a price for joining the platform, but also one for using it, i.e. it can ask a two-part tariff. Examples in this category include payment cards schemes, virtual marketplaces, auction houses and operating systems. The extension of the Areeda–Turner rule that we develop is in line with the suggestion by Evans (2003) for transaction markets.Footnote 13 This suggestion was however not derived from a formal model. In addition, Evans (2003) recognized the difficulty in providing guidance as to how to implement the test in two-sided non-transaction markets. Our formulas, which are derived from the application of the same logic as Areeda and Turner (1975), are applicable instead to two-sided non-transaction markets, such as the market for newspapers that we consider in Sect. 3. However, following the same approach also for two-sided transaction markets, one would indeed obtain similar formulas to those proposed by Evans (2003). Discussing predatory pricing in two-sided transaction markets, Fletcher (2007) suggested that a predatory pricing rule should be drawn from the finding in Rochet and Tirole (2006) that the markup on each side of a two-sided market can be calculated as in a one-sided market, with the caveat that from the marginal cost one needs to subtract any extra revenue that the extra sales on that side of the market generate on the other side of the market. It turns out that the latter intuition is, to some extent, true also for two-sided non-transaction markets. By deriving our conditions from a formal model, we explain what this extra term is in a two-sided non-transaction market and highlight that one also needs to take into account the extra cost incurred on the other side of the market. We then apply our two-sided Areeda–Turner rule to two cases in the newspaper industry. We first look at the price war in the UK quality daily newspapers in the ’90s and test whether the pricing strategy of The Times from September 1993 to December 1995 was an example of predatory pricing, as claimed by its competitors, particularly by the Independent. The case was investigated by the Office of Fair Trading (OFT) which concluded against the existence of predatory behaviour. The case enjoyed considerable publicity at the time for its political implications and has not ceased to be debated, not only because the OFT decision, whether right or wrong, did not include much empirical investigation but also because, looking at it today in light of the theory of two-sided markets, it is striking that the OFT did not carry out any analysis of the advertising market. We show that, had it done so, it would have found that the pricing strategy of the Times was probably not predatory, even taking for granted the cost estimates of The Independent, according to which the Times was sold to readers at a price below average variable cost. We then discuss the case of Aberdeen Journals, whose pricing strategies between 1996 and 2000 were also investigated by the OFT. It was a case of alleged predation that involved free newspapers in Scotland. The OFT and the Competition Appeal Tribunal (CAT) calculated price-cost margins and concluded that the advertising prices that were set by Aberdeen Journals in response to the entry of Aberdeen & District Independent were below average variable costs and, therefore, predatory. We argue that, although readers did not pay for the newspapers, the OFT took the right approach in taking into account also the costs incurred on the readers side. The paper is organised as follows: Sect. 2 compares monopoly pricing in two-sided markets to monopoly pricing in one-sided markets and extends the one-sided Areeda–Turner rule to two-sided markets. In Sect. 3 we analyse the two cases of alleged predatory behaviour in the market for daily newspapers, namely the Times versus Independent war and the Aberdeen Journals case. Section 4 concludes.",23
46.0,4.0,Review of Industrial Organization,24 February 2015,https://link.springer.com/article/10.1007/s11151-015-9453-4,Rethinking Antitrust in the Presence of Transaction Costs: Coasian Implications,June 2015,Dennis W. Carlton,Bryan Keating,,Male,Male,Unknown,Male,"Coase (1960) altered fundamentally how most economists think about externalities and government intervention. Coase made the point that in a world with well-defined property rights and no transaction costs, parties would always wind up at an efficient point, thereby eliminating externalities and the need for government intervention. But Coase’s main point was that we do not live in such a world and that by the assignment of property rights, a government can influence transaction costs and thereby the ability of the economy to reach an efficient point. Therefore, a government should assign property rights in order to enable the economy to reach an efficient solution.Footnote 1
 We explore in this article the implications of Coase’s insights for antitrust and show how Coase’s insights mean that we should refocus much or at least some of our economic analysis of the antitrust issues that are related to mergers and market power. This article together with a companion paper (Carlton and Keating forthcoming) makes several points that are related to transaction costs and antitrust. In the absence of transaction costs, output would be at the efficient level, and there would be no deadweight loss, and hence no need for antitrust if one uses a total surplus criterion (Demsetz 1968). Since there are transaction costs, it is important for an antitrust analysis to examine whether they are sufficiently low to enable nonlinear pricing; and, if not, whether the conduct that is under scrutiny lowers transaction costs so as to allow the use of nonlinear pricing. Failure to account for the use of nonlinear pricing can lead to a mistaken antitrust analysis—especially when efficiencies are involved. Finally, the cost of creating a coalition of economic agents is related to transaction costs. Cooperative game theory tells us that one can view all of antitrust in a unified way as the creation of one coalition that exploits the non-coalition members. By studying when coalition formation is low and high, one can identify situations where the creation of market power is possible. This paper is organized as follows. Section 2 examines the foundational model of antitrust in which a firm (or group of firms) maintains a uniform price that is above marginal cost, restricts output (below the level that would be dictated by the criterion of price equals marginal cost), and harms consumer and total welfare. For example, the famous Williamson diagram (Williamson 1968) is still the way mergers are often thought of—with the deadweight loss from the merger’s consequence of raising the price offset in part or in total by the efficiency gain from the lowered costs that are also the consequence of the merger. But Coase’s insight forces us to focus on transaction costs in our analysis. What prevents any firm with market power from eliminating the deadweight loss that is typically associated with that market power? How does competition affect that transaction cost, and how will that transaction cost be altered by a change in market structure or by certain conduct such as the imposition of vertical restrictions? Section 2 explores these questions and shows that only by answering them can we hope to understand the antitrust implications of a merger or of specific conduct that comes under antitrust scrutiny. To illustrate the importance of transaction costs in an antitrust analysis, Sect. 3 summarizes some merger simulations from Carlton and Keating (forthcoming), where a merger simulation with nonlinear pricing is developed and where the results show that the usual merger simulation with uniform pricing can yield misleading results. Finally, Sect. 4 describes how all of antitrust, including both horizontal and vertical behavior, can be thought of as the creation of one coalition that exploits the non-members of the coalition. By focusing on the transaction costs of creating various coalitions, one can identify when antitrust violations are most likely to occur. We illustrate these ideas by applying them to exclusive dealing, credit card firms, and the setting of royalties in standard-setting associations.",6
46.0,4.0,Review of Industrial Organization,09 April 2015,https://link.springer.com/article/10.1007/s11151-015-9462-3,Specialization and Competition in the Venture Capital Industry,June 2015,Yael V. Hochberg,Michael J. Mazzeo,Ryan C. McDevitt,Female,Male,,Mix,,
46.0,4.0,Review of Industrial Organization,08 February 2015,https://link.springer.com/article/10.1007/s11151-015-9452-5,Limited Memory Consumers and Price Dispersion,June 2015,Levent Kutlu,,,Male,Unknown,Unknown,Male,"A traditional assumption in the literature on imperfect competition is that consumers have perfect information about available prices. Hence, the consumers are able to recall the prices that they encountered during the search process. In a variety of interesting cases this assumption can be strong.Footnote 1 Previous research suggests that many consumers do not remember the price of a product that they just bought and often claim that the price was not an important input in their purchase decision (Wakefield and Inman 1993). However, they can tell whether the price of a product is expensive or not. This suggests that, faced with memory constraints, consumers make their decisions using heuristics that help them to process the information on prices. A potential heuristic to process the information is categorization based on perceived similarities (Rosch and Mervis 1975). In this scheme, which we follow in this study, the consumers do not necessarily remember the prices of products but rather remember the price group in which the product is assigned by the consumer. We consider a duopoly market in which firms compete for limited-memory consumers with uniformly distributed valuations. Hence, the valuations of consumers are heterogeneous. The consumer with limited memory of the offered prices is able accurately to compare the offers to her valuation; and she can only remember whether the price of the product at a firm is above her valuation or not. One potential explanation is that the consumer faces a budget constraint and knows whether she can buy the product or not at check-out. It is as if the consumers are indifferent among any prices that are offered, given that the price is below their valuations. It turns out that the only pure strategy Nash equilibria are the ones where firms charge different prices. In a similar framework where the valuations of the consumers are homogeneous, Chen et al. (2010) provide some evidence for price dispersion. However, in their framework only a mixed-strategy equilibrium exists. Hence, the price dispersion is a product of the randomized behavior of firms. Our paper shows that even when the firms play pure strategies, price dispersion may happen if the valuations of the consumers are heterogeneous. A prominent example where price dispersion is present is that of search models. Generally, in these models price dispersion is constructed as a way to justify consumer search. In contrast to these models, our model does not involve much search and price dispersion occurs as a result of memory limitations of the consumers. The rest of this paper is organized as follows. In the next section, we provide a brief literature review. Section 3 presents our model and result. Section 4 concludes and provides a summary. The appendix provides the technical details.",7
46.0,4.0,Review of Industrial Organization,01 February 2015,https://link.springer.com/article/10.1007/s11151-015-9450-7,Impact of External Knowledge Acquisition Strategies on Innovation: A Comparative Study Based on Dutch and Swiss Panel Data,June 2015,Spyros Arvanitis,Boris Lokshin,Martin Woerter,Male,Male,Male,Male,"This is a paper on the impact of external knowledge acquisition strategies on innovation performance and is mainly motivated by the observation of the necessity of the acquisition of new knowledge as a precondition for successful innovative activities of enterprises. In addition to their own research and development (internal R&D) enterprises typically are engaged in the trading of knowledge on the technology market (contract or external R&D) and/or cooperate actively—formally or informally—with other firms and research institutions. For applied industrial economics an important task is an understanding of how firms integrate internal knowledge and various types of externally acquired knowledge and if such activities increase firms’ performance. An important motive for this research interest is the improvement of our understanding of the role of such strategies with respect to the innovation performance of enterprises that engage in such strategies (see Cassiman and Veugelers 2006; Belderbos et al. 2006). Better insights into knowledge acquisition strategies and their impact on innovation would allow the formulation of a knowledge-based technology policy. We focus in the paper at hand on two knowledge acquisition strategies: external or contract R&D and R&D (innovation) cooperation. Further, we use data for more than one cross-section and try to tackle the problem of potential endogeneity of the knowledge strategies, which is an issue that has been scarcely addressed until now in the literature (see, e.g., Cassiman and Veugelers 2006). Why a comparative study of the Netherlands and Switzerland? It is interesting to investigate the impact of knowledge acquisition strategies on innovation performance for two countries that show several similarities (small open economies, technologically advanced—near the “technological frontier”), with Switzerland as an “innovation leader” and the Netherlands as an “innovation follower” according to an EIS (European Innovation Scoreboard) 2008 assessment. At the same time, there are differences that might be relevant for the outcomes of knowledge acquisition strategies: EU membership and a more active innovation policy in the Netherlands: e.g., more public support of corporate R&D (which is almost non-existent in Switzerland) and of R&D (innovation) cooperation. Our study is original in two respects: First, we investigate the impact of external R&D and R&D (innovation) cooperation as well as the combined effect of these two strategies, based both on qualitative and quantitative variables that measure the two strategies and separately for manufacturing and services using three cross-sections of firm data for both countries. With one exception (Cassiman and Veugelers 2006), all other reviewed studies (see Sect. 2) investigated primarily complementarities between in-house R&D and external (contract) R&D but not between the external knowledge acquisition strategies (cooperation; external R&D), which is the main subject of this study. Second, we compare two technologically advanced European countries with different innovation policies that might influence corporate strategies of knowledge acquisition. Informed by the growing literature on open innovation (Chesbrough 2003; Dahlander and Gann 2010; Drechsler and Natter 2012; Fey and Birkinshaw 2005), we expected that the more that firms rely on different external knowledge sourcing modes, the better they would perform in terms of innovation. While we find some evidence that both external technology sourcing and R&D cooperation positively impact innovation in isolation, we hardly find evidence of an additional gain in performance when both are used simultaneously. The structure of the paper is as follows: In Sect. 2 we briefly discuss related empirical literature. Section 3 presents the model specification. Section 4 deals with the data. In Sect. 5 we discuss the method and present the results. Finally, Sect. 6 concludes.",31
46.0,4.0,Review of Industrial Organization,25 February 2015,https://link.springer.com/article/10.1007/s11151-015-9454-3,International Trade and Domestic Competition: Evidence from Belgium,June 2015,Maria Caterina Bramati,Alberto A. Gaggero,Edna Maeyen Solomon,Female,Male,Female,Mix,,
47.0,1.0,Review of Industrial Organization,31 May 2015,https://link.springer.com/article/10.1007/s11151-015-9465-0,A Holy Alliance: Collusion in the Renaissance Europe Alum Market,August 2015,Andrea Günster,Stephen Martin,,Female,Male,Unknown,Mix,,
47.0,1.0,Review of Industrial Organization,13 February 2015,https://link.springer.com/article/10.1007/s11151-015-9451-6,The Competitive Effect of Exclusive Dealing in the Presence of Renegotiation Breakdown,August 2015,Dongyeol Lee,,,Unknown,Unknown,Unknown,Unknown,,
47.0,1.0,Review of Industrial Organization,04 March 2015,https://link.springer.com/article/10.1007/s11151-015-9455-2,Ethical Differentiation and Consumption in an Incentivized Market Experiment,August 2015,Marieta Valente,,,Female,Unknown,Unknown,Female,"Ethical concerns are regularly revealed in consumer surveys. Studies on ethical consumption that rely on survey answers are however limited by the absence of incentive compatibility and attitudes may not necessarily translate into actions. Some authors have even called into question the existence of the “ethical consumer” as a result of an attitude–behavior gap (Devinney et al. 2010; Boulstridge and Carrigan 2000). While it is a fact that sellers ethically differentiate some goods and that these ethical goodsFootnote 1 are purchased and sold, ethical consumption and differentiation has been scarcely researched under controlled conditions. Carefully designed economic experiments can provide an informative research option by giving monetary incentives to participants so as to observe incentivized behavior. There are however few such examples in the literature. In this paper I report on a conventional lab (economic) experiment (as defined by Harrison and List 2004) of a market that allows ethical goods to be endogenously supplied by firms as a response to buyers’ choices. In this incentivized economic experiment, a preference by buyers or sellers towards more ethical goods comes at the expense of own earnings, so actual ethical consumption and differentiation behavior in a controlled setting is observed. The design involves an experimental posted-offer market with one buyer and two sellers who compete in price and introduce the possibility for sellers to endogenously decide to supply ethically differentiated goods. Sellers can propose a price and a contribution to an ethical cause per unit sold—that is, linked to the sale of the good—and buyers choose from whom to make their purchases (or whether to purchase at all). With this design, market outcomes and behaviors concerning the supply and demand of ethically differentiated goods can be studied. In fact, despite the stringent competition setting, ethical purchases are actually observed in all but one market; and, although contributions to the ethical cause decline with repetition, they remain positive throughout the market interactions. Finally, at the end of the market experiment, a brief questionnaire is included with an ethical attitudes question, so as to compare the replies with actual behavior in the incentivized setting and add to the discussion of the attitude–behavior gap. Section 2 discusses further the background for this experiment. Section 3 presents the details of the experimental design and implementation, as well as the issues to be explored with this design and the hypotheses to be tested. The results are explored in Sect. 4 and discussed in Sect. 5.",6
47.0,1.0,Review of Industrial Organization,13 May 2015,https://link.springer.com/article/10.1007/s11151-015-9463-2,Merger Policy at the Margin: Western Refining’s Acquisition of Giant Industries,August 2015,Nicholas Kreisle,,,Male,Unknown,Unknown,Male,"As noted by Carlton (2009), Kwoka (2013), and others, the value of retrospective merger analysis lies not only in understanding the impact of a particular merger or similar mergers but also in evaluating the accuracy of prospective merger analysis by the relevant antitrust authority. However, this evaluation can only take place when the antitrust authority has precisely stated its forecast of any post-merger competitive effect. This paper analyzes Western Refining’s acquisition of Giant Industries in May 2007 after a US District Court denied the Federal Trade Commission’s (FTC) request for a preliminary injunction to stop the transaction. During the trial, both the FTC and the merging parties employed economic experts who predicted the merger’s likely impact on the wholesale price of gasoline in Albuquerque, New Mexico. Therefore, in addition to assessing the narrow question of whether this particular merger affected prices, I can also address the broader issue of how any such impact aligned with either side’s predicted effect. The paper also compares empirical methods in retrospective merger estimation. Petroleum prices often exhibit non-stationarity, so I compare OLS and GLS versions of my difference-in-differences approach. Both methods theoretically produce consistent estimates. First, I run OLS regressions using autocorrelation-consistent standard errors (Newey–West). Second, I explicitly estimate an autoregressive term in the error using GLS (Prais–Winsten). I exploit an abundance of pre-merger data to compare these approaches both for the actual merger effect and for various placebo merger dummy variables in the pre-merger period to investigate the ability of either procedure to identify small price changes reliably. This particular merger is unusual because the FTC predicted that an ongoing output expansion project at Giant would reduce prices from 6 to 10 cents per gallon (cpg) in the absence of the merger. If that characterization is correct, then anticompetitive harm could still be inferred if prices did not fall “enough” relative to the FTC’s predicted effect from the output expansion. Indeed, the evidence generally suggests that gasoline prices declined at the wholesale level by 3–4 cpg and the retail level by 4–8 cpg, falling short of the 6–10 cpg decline the FTC predicted in the absence of the merger. While this finding leaves some room to infer an anticompetitive merger effect, it hinges on the FTC’s theory of the counterfactual. In the following section 1 summarize the FTC’s theory of competitive harm and the parties’ rebuttal, focusing on gasoline “rack” (i.e. wholesale) prices as was the focus at trial. Ensuing sections describe the research design, and analyze the robustness of the results across products, control cities, and estimation method. In an attempt to understand the mechanism by which prices may have declined, I also use firm-specific pricing in Albuquerque to look for changes in downstream behavior after the merger. The final section offers concluding thoughts as to whether the retrospective evidence conflicts with the theories put forth by both the FTC and the merging parties.",3
47.0,1.0,Review of Industrial Organization,20 May 2015,https://link.springer.com/article/10.1007/s11151-015-9464-1,"Scale, Scope and Survival: A Comparison of Cooperative and Capitalist Modes of Production",August 2015,Natália Pimenta Monteiro,Geoff Stewart,,Female,Male,Unknown,Mix,,
47.0,2.0,Review of Industrial Organization,07 August 2015,https://link.springer.com/article/10.1007/s11151-015-9472-1,How Much Do Cartel Overcharge?,September 2015,Marcel Boyer,Rachidi Kotchoni,,Male,Unknown,Unknown,Male,"Our aim in this paper is to determine the order of magnitude of the average cartel overcharge, based on an extended version of a database of cartels that was used by Connor (2010).Footnote 1 This database contains overcharge estimates (OEs) that were obtained from a survey of several studies of cartels as well as three types of variables: the first group (Y) consists of variables that describe the cartel episode (e.g., duration, scope, geography, etc.). The second group (Z) consists of factors that are posterior to the cartel episode (e.g., estimation method or publication source). The third group (W) consists of a single dummy variable that indicates whether the cartel was “found or pleaded guilty”. While Y and W are likely related to the true overcharge, Z captures potential estimation biases. The raw OE data are themselves potentially biased and the variable W is likely endogenous. Hence, a naive OLS regression of the OEs on Y, W, and Z should be avoided. To verify whether the OEs are biased or not, we perform a meta-regression analysis, in the spirit of Connor and Bolotova (2006), who show that part of the variability of the OEs is indeed due to the bias factors. We use a Kullback–Leibler divergence to compare the probability of an OE’s being larger than some value θ conditional on (Y, W) to the same probability conditional on (Y, W, Z). The two conditional probabilities are quite close for \( \uptheta \in [0,65\,\% ] \) but diverge sharply for θ > 65. This divergence is caused by the fact that the joint distribution of the variables that are involved in the probit models that are specified for the probability of (OE > θ) become degenerate as θ exceeds a certain threshold. Next, we regress the logarithm of OE on Y, W, and Z on increasing subsamples of type (0, θ]. The results allow us to identify the range \( OE \in (0,49\,\% ] \) as the most reliable for our meta-analysis. Thus, our final results are derived from a Heckit regression that infers bias-corrected OEs for the whole sample by using unbiased estimates of coefficients obtained from the subsample \( OE \in (0,49\,\% ] \). Applying the methodology described above, we find mean and median bias-corrected OE of 16.47 and 16.17 % for the subsample \( OE \in (0,49\,\% ] \) of 16.68 and 16.17 % for the subsample of effective cartels (with strictly positive OEs), and of 15.47 and 16.01 % for the whole sample. These numbers are significantly lower than the means and medians of the raw OE data. Moreover, the comparison of bias-corrected mean and median OEs reveals a fairly homogenous behavior of cartels across different types, geographical locations, and time (antitrust regime) periods. The paper is organized as follows: in Sect. 2, we describe the context and the literature that surround our research. Section 3 presents the raw OE and discusses data problems. Section 4 illustrates the danger of converting Lerner indices into OE while ignoring the competitive mark-ups. Sections 5 and 6 presents the methodology that we used to detect the presence of bias in the OE data. Section 7 presents the determinants of cartel overcharge that are unveiled by our meta-analysis. Section 8 presents the steps of our bias-correction methodology and the summary statistics for the bias-corrected OE. Section 9 presents an analysis of variance of the OE bias. Section 10 concludes. “Appendix” contains the summary statistics of the database.",
47.0,2.0,Review of Industrial Organization,30 July 2015,https://link.springer.com/article/10.1007/s11151-015-9471-2,Three-Part Tariffs with Heterogeneous Users: Monopoly and Duopoly Cases,September 2015,Ji Won Baek,Jan K. Brueckner,,,Male,Unknown,Mix,,
47.0,2.0,Review of Industrial Organization,15 July 2015,https://link.springer.com/article/10.1007/s11151-015-9467-y,"Market Power, Transactions Costs, and the Entry of Accountable Care Organizations in Health Care",September 2015,H. E. Frech III.,Christopher Whaley,Richard M. Scheffler,Unknown,Male,Male,Male,"The US health care sector has been an area of continuing public policy concern for many years, with increased emphasis on cost control, in particular, that stretches back at least to the 1960s. The most recent major federal legislation to address the sector is the Patient Protection and Affordable Care Act of 2010 (the ACA). Included in the ACA was a major provision to encourage the formation of accountable care organizations (ACOs). ACOs are a type of joint venture that typically includes both physicians and hospitals, and often health plans. ACOs partially integrate to coordinate care and share the risks and rewards of cost reduction to specific consumers in a specific geographic area. They provide an overlay of managed-care-type incentives and organization. Managed care organizations (MCOs), which are especially tightly integrated health maintenance organizations (HMOs), have arisen in the market over time. ACOs extend many of the operational structures of MCOs and HMOs (see the glossary of US health care terms in Table 1). The current ACO movement is designed to spread the general type of organization and incentives more broadly. ACOs are hybrid organizations, formed by contract.Footnote 1
 As a means to promote care coordination, which proponents argue will reduce unnecessary and duplicative care, the ACA promotes ACOs. Medicare-sponsored (hereafter “public”) ACOs meet the regulatory requirements of the federal Medicare program for consumers who are 65 or over. Public ACOs can also serve privately-insured consumers. In contrast, other ACOs are designed only for privately-insured consumers (private ACOs) and cannot participate in the Medicare ACO program. Several prototypical ACOs took part in an earlier demonstration project, with mixed results (Wilensky 2011). ACOs involve both vertical and horizontal cooperation, which could increase market power and raise antitrust concerns.Footnote 2 Higher prices or lower quality for private health plans is a possible outcome (Scheffler et al. 2012; Federal Trade Commission/Department of Justice 2011; Berenson et al. 2010; Greaney 2011; Cuellar and Gertler 2006). Medicare sets prices, so the use of market power against Medicare primarily affects non-price dimensions such as amenity, quality, and access (Kessler and McClellan 2000; Gaynor et al. 2013). In this paper, we analyze ACO patterns of entry (or formation) with the use of a unique, proprietary database of ACOs that has been created by the Optum Institute. The database includes public and private ACOs that were in full operation or in development. The proprietary data were created by searches in May 2011, October 2011, and May 2012 (ACO Market Activity 2012).Footnote 3 The data on the private ACOs are especially interesting, since there is no formal registry for them. We find that market structure, demographics, and other economic variables affect local market entry.Footnote 4
",13
47.0,2.0,Review of Industrial Organization,18 July 2015,https://link.springer.com/article/10.1007/s11151-015-9468-x,Patent Portfolio Management of Sequential Inventions: Evidence from US Patent Renewal Data,September 2015,Jinyoung Kim,,,Unknown,Unknown,Unknown,Unknown,,
47.0,2.0,Review of Industrial Organization,07 July 2015,https://link.springer.com/article/10.1007/s11151-015-9466-z,"Rivalry, Market Structure and Innovation: The Case of Mobile Banking",September 2015,Zhaozhao He,,,Unknown,Unknown,Unknown,Unknown,,
47.0,3.0,Review of Industrial Organization,09 September 2015,https://link.springer.com/article/10.1007/s11151-015-9475-y,Introduction: Behavioral Industrial Organization,November 2015,Michael D. Grubb,Victor J. Tremblay,,Male,Male,Unknown,Male,,5
47.0,3.0,Review of Industrial Organization,27 August 2015,https://link.springer.com/article/10.1007/s11151-015-9477-9,Behavioral Consumers in Industrial Organization: An Overview,November 2015,Michael D. Grubb,,,Male,Unknown,Unknown,Male,"A fast growing literature on behavioral industrial organization (IO) revisits classic IO questions while relaxing assumptions of the standard model. The majority of the work maintains the assumption that firms maximize profits but enriches the model of consumer behavior to be more realistic by allowing for self-control problems, loss aversion, inattention, overconfidence, confusion, and other deviations from homoeconomicus. A smaller fraction of the work considers firms that are run by managers who, like their customers, are also human and sometimes make mistakes. The fascinating branch of work on behavioral managers and firms is largely beyond the scope of this special issue, apart from its appearance in Bailey’s (2015)’s discussion of U.S. antitrust policy, but readers may refer to other surveys (Ellison 2006; Ho et al. 2006; Armstrong and Huck 2010; Goldfarb et al. 2012). Thus far, explicitly behavioral consumers appear most often in theoretical IO models, but they are appearing more often in empirical IO models as well.Footnote 1
 The IO literature with behavioral consumers is diverse, but a large fraction of it may be grouped into three primary branches: First, firms will cater to consumers’ non-standard preferences, such as loss aversion or a preference for commitment. Second, overconfidence and other biases lead consumers to systematically misforecast future choices. As a result, they systematically misweight different dimensions of product price or other product attributes, and firms offer complicated contracts to exploit the mistake. Third, artificial product differentiation and market power often arise because consumers fail to choose the best price due to suboptimal search, confusion when comparing prices, and excessive inertia. Beyond these three main branches, research examines a variety of other issues such as inattention and strategic naivety, and researchers continue to expand the field in new directions.Footnote 2
 Below I give a brief overview of the three primary branches of the literature with references to more comprehensive surveys. Next, I draw attention to two recurring themes: (1) that consumer heterogeneity, such as the presence of both savvy and non-savvy consumers, has important consequences for market outcomes and policy; and (2) that equilibrium effects often offset consumer benefits of policies that are aimed at improving individual decision making. I finish by highlighting some recent empirical work.",42
47.0,3.0,Review of Industrial Organization,28 July 2015,https://link.springer.com/article/10.1007/s11151-015-9470-3,Beyond “Ellison’s Matrix”: New Directions in Behavioral Industrial Organization,November 2015,Kfir Eliaz,Ran Spiegler,,Male,,Unknown,Mix,,
47.0,3.0,Review of Industrial Organization,21 August 2015,https://link.springer.com/article/10.1007/s11151-015-9480-1,Search and Ripoff Externalities,November 2015,Mark Armstrong,,,Male,Unknown,Unknown,Male,"This paper examines situations in which “savvy” and “non-savvy” consumers interact in the marketplace. An old intuition in economics suggests that savvy consumers help to protect other consumers, and intervention to protect vulnerable consumers is needed only when there are insufficient numbers of savvy types present in the market. In broad terms, a “search externality” operates so that consumers who are informed about the deals available in the market increase the likelihood that less informed consumers also obtain reasonable outcomes. More recent work, however, has examined situations where consumers benefit from the presence of non-savvy types. In such markets, a “ripoff externality” is present—some consumers end up buying services they do not value, say, which help fund generous deals elsewhere—and vulnerable consumers may need protection even when they are relatively few in number. This paper discusses two principal issues. First, what determines the direction of inter-consumer externalities in a market? That is, when do savvy consumers protect other consumers, when do non-savvy consumers improve the deals offered to the savvy, or when is there no interaction between the two groups at all? Second, which kinds of market interventions—such as policies to increase the number of sellers, to constrain high prices or ripoffs, or to increase the proportion of savvy types in the market—benefit both types of consumers and which benefit one type at the expense of the other? For current purposes, there are two broad notions of consumer savviness (or expertise) that might be relevant. First, a consumer might be well informed about prices, product qualities or her idiosyncratic values for the various products. For instance, a savvy consumer knows whether a given wine will likely be to her taste just by looking at the label, or a savvy consumer looking for a new television may know the range of available prices (e.g., because she has access to online resources). Alternatively, a consumer might be strategically savvy, in that she has a good understanding of the game being played in the market. For instance, consumers might be unable to discern product quality (so they are not savvy in the first sense) but they understand how quality depends on price in equilibrium and buy accordingly. Likewise, they foresee a firm’s incentive to set its future, or otherwise hard to discover, prices. A consumer who is savvy in this sense is aware of her future behaviour, while a strategically naive consumer might not predict accurately what she will want or need in the future. A consumer might be non-savvy in both senses. Indeed, strategic naivety might be the cause of information problems. In a market where in fact there is price dispersion but naive consumers think that all sellers offer the same price, for example, a naive consumer might choose not to incur the search cost required to become informed about the range of available prices. A framework for discussing these issues is the following.Footnote 1 Suppose there are two kinds of consumers—“savvy” and “non-savvy”—and the proportion of savvy consumers in the population is \(\sigma \). To focus on the impact of savviness on outcomes, I suppose that there are no systematic differences in tastes for the product in question across the two groups of consumers. For the most part, I take the extent of savviness, \(\sigma \), to be exogenous and out of the control of consumers and sellers. Let \(V_{S}(\sigma )\) and \(V_{N}(\sigma )\) denote the expected net surplus enjoyed in equilibrium by an individual savvy and non-savvy consumer respectively, while \(V(\sigma )\equiv \sigma V_{S}(\sigma )+(1-\sigma )V_{N}(\sigma )\) measures aggregate consumer surplus. As long as sellers cannot somehow target savviness directly, we expect that \(V_{S}(\sigma )\ge V_{N}(\sigma )\) so that savvy consumers obtain weakly better deals than their non-savvy counterparts. This is because tastes do not differ across the two groups of consumer, and a savvy type could mimic a non-savvy buying strategy and so obtain surplus \(V_{N}\).Footnote 2 In situations where this makes sense, the difference \( V_{S}(\sigma )-V_{N}(\sigma )\) represents a consumer’s incentive to “become savvy” when \(\sigma \) other consumers are already savvy. A rational, but uninformed, buyer must obtain non-negative surplus \(V_{N}\ge 0\), for otherwise she would choose to stay out of the market. However, a strategically naive consumer might experience negative surplus. In many cases \(V_{S}\) and \(V_{N}\) move the same way with \( \sigma \)—either both increase with \(\sigma \), both decrease with \(\sigma \) , or neither depends on \(\sigma \)—although it is not inevitable that this be so.Footnote 3
 Likewise, let \(\Pi _{S}(\sigma )\) and \(\Pi _{N}(\sigma )\) denote the profit for sellers that is generated in equilibrium by an individual savvy and non-savvy consumer respectively, while \(\Pi (\sigma )\equiv \sigma \Pi _{S}(\sigma )+(1-\sigma )\Pi _{N}(\sigma )\) measures industry profit. Here, it is less clear how \(\Pi _{S}\) and \(\Pi _{N}\) compare, although in most of the situations discussed in this paper non-savvy consumers generate at least as much profit as do the savvy and \(\Pi _{S}(\sigma )\le \Pi _{N}(\sigma )\). In perfectly competitive situations we expect average profit to be zero, although profit extracted from one group might be used to subsidize the offer made to the other. Finally, let \(W(\sigma )=V(\sigma )+\Pi (\sigma )\) denote total welfare when \(\sigma \) consumers are savvy. In this paper I focus on three kinds of externalities: 
Search externalities: When consumers are better off when the proportion of savvy types is larger—that is, when \(V_{N}(\sigma )\) and \(V_{S}(\sigma )\) increase with \(\sigma \)—I say that “search externalities” are present. This is because the leading example where savvy consumers protect non-savvy consumers is when the former are better informed about prices or qualities available in the market. When more consumers are aware of all the available deals this forces sellers to offer good deals, which in turn are available to non-savvy buyers (as well as to other savvy buyers).Footnote 4
 
Ripoff externalities: When individual consumers are better off when the proportion of savvy types is smaller—that is, when \( V_{N}(\sigma )\) and \(V_{S}(\sigma )\) decrease with \(\sigma \)—I say “ripoff externalities” are present. A leading example of this situation is when non-savvy consumers can be “ripped off” with extra charges, and the resulting revenue is passed back to all consumers in the form of subsidized headline price. It is possible that aggregate consumer surplus V rises with \(\sigma \), even though both \(V_{S}\) and \(V_{N}\) fall with \(\sigma \), if the gap \((V_{S}-V_{N})\) is large (as is the case in Sect. 3.3). 
No interactions between consumers: On the boundary between these cases are situations in which there is no interaction between the two groups of consumers, and \(V_{S}\) and \(V_{N}\) do not depend on \(\sigma \). These cases often involve biased beliefs on the part of non-savvy consumers. Here, competition delivers what each type of consumer thinks they want, and neither wishes to choose the deal offered to the other type. Ex post, though, biased consumers might regret the deal they chose. (A lucky charm to help predict winning lottery numbers, say, has no impact on the savvy consumers who do not buy it, but may be attractive ex ante to gullible gamblers.) The plan for the rest of this paper is as follows. Models which generate price dispersion are examined in Sect. 2, and I present three models to exemplify the three patterns of externalities listed above. Models with add-on pricing are presented in Sect. 3, and again variants are chosen to illustrate the three patterns of externality.Footnote 5 One lesson from the analysis is that small changes in model assumptions can swing the market from one kind of externality to the other, and the “small print” in the model specification matters. I conclude the paper with some suggestions for markets outside these two families where search or ripoff externalities are likely to be present.",47
47.0,3.0,Review of Industrial Organization,05 September 2015,https://link.springer.com/article/10.1007/s11151-015-9476-x,"Failing to Choose the Best Price: Theory, Evidence, and Policy",November 2015,Michael D. Grubb,,,Male,Unknown,Unknown,Male,"Both the “law of one price” and Bertrand’s (1883) prediction of marginal cost pricing for homogeneous goods rest on the assumption that consumers will choose the best price. In practice, consumers often fail to choose the best price. As a result, homogeneous goods sellers charge positive markups, and “the ‘law of one price’ is no law at all” (Varian 1980, p. 651). To choose the best price, a consumer must first search for prices, then select the lowest price among those found, and finally switch when prices change. The traditional explanation for consumers’ failure to choose the best price is that searching and switching are costly (Baye et al. 2006; Farrell and Klemperer 2007). Conditional on these costs, it is traditionally assumed that consumers’ searching and switching decisions are optimal, and that consumers will initially choose the lowest price discovered. Evidence suggests, however, that all three assumptions are overly optimistic: Consumers sometimes appear to search too little, exhibit confusion in their choices, and/or show excessive inertia through too little switching away from past choices or default options. All three mistakes may contribute to positive markups that fail to diminish as the number of competing sellers increases.Footnote 1 Firms may have an incentive to exacerbate the problem by obfuscating prices, thereby using complexity to make price comparisons difficult and soften competition. I discuss each barrier to choosing the best price—limited search, confusion, and inertia—in Sects. 2–4. For each, I discuss selected evidence for the problem as well as related theory and evidence on the resulting equilibrium outcomes. Together, the work surveyed constitutes an important branch of the behavioral industrial organization (IO) literature. A distinct branch of the behavioral IO literature, which I survey separately in Grubb (2015c), studies equilibrium outcomes when consumers have none of the preceding problems but rather have systematically biased expectations about their own future choices, due to overconfidence or related biases. An important difference between the two branches of work lies in whether or not the modeled consumer mistakes increase firms’ market power. In the work surveyed herein, consumer mistakes lead both to excessive inertia and to noise in active choices that is uncorrelated across consumers. In the work on overconfidence and related biases, consumers systematically mis-weight different dimensions of price (or other product attributes) in the same way: for instance, by overweighting a teaser rate relative to a reset rate on a loan. In the former case, noise in consumer choice spuriously differentiates products, creating market power and dispersion in prices but not necessarily any systematic distortion of prices in one particular direction. In the latter case, in contrast, systematic consumer mistakes lead firms to distort prices specifically to exploit consumer bias but does not necessarily increase markups or lead to price dispersion (Grubb 2015c). Section 5 discusses policies to improve market outcomes when consumers exhibit limited search, confusion, or inertia. Of particular interest is the policy of providing or facilitating expert advice to consumers to aid them in their choices. Such a policy may be implemented imperfectly, so that the resulting advice is biased, as in the case of Mexico’s privatized social security market (Duarte and Hastings 2012). If consumers follow the advice, then its introduction shifts consumers from making choices with noise, as considered in this survey, to making choices based on a systematically biased weighting of different components of price or other product attributes, as discussed by Grubb (2015c). Thus the policy provides a link between these two important branches of the behavioral IO literature. (A third branch of the literature concerns consumers with non-standard preferences. For a brief overview of all three main branches of the IO literature with behavioral consumers see Grubb (2015a) earlier in this special issue.)",67
47.0,3.0,Review of Industrial Organization,21 August 2015,https://link.springer.com/article/10.1007/s11151-015-9473-0,On the Welfare Costs of Naiveté in the US Credit-Card Market,November 2015,Paul Heidhues,Botond Kőszegi,,Male,Male,Unknown,Male,"Researchers have noted that exploitative contracting can induce a variety of total-welfare-reducing distortions (see Sect. 4 for a discussion of the literature). In this paper, we focus on one requirement for a market outcome to maximize total surplus: efficient participation requires that the marginal benefit to consumers equals the marginal cost of producing the good or service. We describe as a ""participation distortion"" the failure of this condition to be met and investigate the participation distortion that arises from the presence of naive consumers in the marketplace. In a competitive market, systematic underestimation of the total price by naive consumers as well as the transfer from more-profitable naive to less-profitable sophisticated consumers can lead to inefficient overparticipation. Based on a rough calibration for the US credit card market, we argue that the resulting welfare loss may be large when compared to conventional welfare losses such as those from market power. Our results call for more careful empirical investigation of the participation distortion and suggest that ignoring the distortions due to such contracting will lead to misguided welfare results in the credit-card industry. More generally, the results suggest that it may be fruitful to redirect some of the empirical work on the quantification of the welfare losses from market power to the quantification of the welfare losses due to firms' reactions to consumer misunderstandings. Considerable discussion has focused on the redistributive character of consumers' misunderstanding of contingent charges or other costs that are associated with product ownership. For the UK banking industry, for example, Armstrong and Vickers (2012) demonstrate that contingent charges are—presumably unexpectedly—incurred by a minority of the population, who nevertheless often incurs these charges repeatedly and end up paying large amounts of money for contingent charges such as unarranged overdrafts of their current accounts. As this part of the population is presumably poorer than average,Footnote 1 the resulting ""reverse Robin Hood"" exercise leads to a disadvantageous redistribution. While we fully agree that the redistribution issue that results from consumer misunderstandings is important, we highlight that there are also likely to be considerable total welfare costs associated with consumer misunderstandings.",14
47.0,3.0,Review of Industrial Organization,19 July 2015,https://link.springer.com/article/10.1007/s11151-015-9469-9,Behavioral Economics and U.S. Antitrust Policy,November 2015,Elizabeth M. Bailey,,,Female,Unknown,Unknown,Female,"Behavioral economics is an active and growing field in economics. While behavioral economics is a particularly robust field in finance,Footnote 1 behavioral economics is much less developed in the field of industrial organization: the field that is most closely related to antitrust. That body of research has been growing in recent years, however.Footnote 2
 In the United States, federal antitrust laws prohibit business practices that lessen competition and result in consumers’ paying higher prices for goods and services.Footnote 3 The antitrust laws also address the lessening of non-price competition, such as business practices that lessen competition by resulting in diminished quality or a slower pace of innovation. A related application of behavioral economics to U.S. public policy is through consumer protection regulations, which are enforced, in part, by the U.S. Federal Trade Commission. Camerer et al. (2003) and Tremblay and Tremblay (2012, pp. 587–646) provide overviews of the application of behavioral economics to consumer protection policy. Enforcement of the antitrust laws in the U.S. relies heavily on the use of economics.Footnote 4 By drawing on economic concepts such as competition, prices, profits, and innovation, the use of economics and economic models is central in guiding the development of antitrust policy. For example, economic models are used to predict the effect of a merger on prices post-transaction.Footnote 5 In the non-merger context, economic models are often used to assess certain single-firm conduct with the use of tests that are related to profitability, such as the ‘no economic sense’ test and the ‘profit sacrifice’ test.Footnote 6
 Antitrust analyses, by and large, rely on the traditional neoclassical models that are applied in industrial organization, which assume that consumers are fully rational. In addition, the standard model of firm decision-making used in an antitrust analysis assumes that a firm makes choices about price, quality, innovation, and output to maximize profits. Both of these assumptions are wrong, at least to some extent, in the sense that there are many apparent real-world counter-examples. Understanding how well actual individual and firm decision-making behavior conforms with that assumed in standard economic models makes good sense. If the models used to evaluate potential antitrust concerns rest on assumptions that are flawed, then the resulting analyses may not provide useful predictions. How closely models’ assumptions track actual behavior determines, in part, how useful these models are in predicting potential anti-competitive effects. For these reasons, the economic models employed must be ones that fit the facts on the ground. For example, some enterprises, by their nature as a non-profit, may not maximize profits. And even for-profit companies may depart from strict profit maximization over the short or medium term. In the short-run, firms might choose instead to increase revenues or market share. Behavioral economics focuses on how consumers and firms may deviate from the standard models of individual and firm decision making. In this article, I discuss the role for behavioral economics in antitrust policy. Section 2 describes how economics is used in modern antitrust analyses. Section III discusses how behavioral economics may augment the evaluation of potentially anticompetitive behavior. Section 4 provides a discussion of antitrust cases that have employed insights from behavioral economics. Section 5 provides a conclusion and directions for future work in this area.",9
47.0,3.0,Review of Industrial Organization,24 September 2015,https://link.springer.com/article/10.1007/s11151-015-9486-8,Call for Papers,November 2015,,,,Unknown,Unknown,Unknown,Unknown,,
47.0,4.0,Review of Industrial Organization,05 November 2015,https://link.springer.com/article/10.1007/s11151-015-9492-x,Introduction: Antitrust and Regulatory Update,December 2015,Lawrence J. White,,,Male,Unknown,Unknown,Male,,
47.0,4.0,Review of Industrial Organization,29 October 2015,https://link.springer.com/article/10.1007/s11151-015-9488-6,"Economics at the FTC: Fraud, Mergers and Exclusion",December 2015,David J. Balan,Patrick DeGraba,David Schmidt,Male,Male,Male,Male,"The Bureau of Economics (BE) supports the Federal Trade Commission’s (FTC’s) consumer protection and antitrust activities by providing economic analysis for case work. It also advises the Commission and other government entities about the impact of government regulation on competition and consumer well-being, and analyzes economic phenomena in the nation’s economy as they relate to antitrust and consumer protection (https://www.ftc.gov/about-ftc/bureaus-offices/bureau-economics/about-bureau-economics). BE’s staff consists of roughly 80 Ph.D. economists, four financial analysts, nearly 20 research analysts who typically have undergraduate or masters economics degrees, and support staff. BE plays three major roles at the FTC: The primary function of BE is to work with Commission attorneys on consumer protection and competition enforcement matters, and in particular, to provide economic analysis to better inform enforcement decisions. Second, the economists in BE are actively engaged in research that continually sheds light on agency-relevant issues.Footnote 1 Third, much of the policy and advocacy work (e.g., advising other government agencies on the competitive impact of policies under consideration) that is performed by economists at the FTC is a concerted effort with attorneys in the Office of Policy Planning, the Office of the General Counsel, the Bureau of Competition, and/or the Bureau of Consumer Protection.Footnote 2
 When working on law enforcement investigations, economists in BE typically provide their own independent economic analysis to the Commission. However, this analysis is greatly enriched by the interaction and cooperation between the economists and FTC attorneys from the Bureaus of Competition and Consumer Protection who work together to gather relevant information during the course of investigations. The economic analysis is an important input into decisions that have significant impact on consumers and businesses. For instance, FTC consumer protection actions resulted in a total of $642.4 million in ordered redress and disgorgement in calendar year 2014.Footnote 3 Furthermore, the FTC logged over 2.5 million consumer complaints that related to problems such as identity theft and imposter scams.Footnote 4 On the antitrust side, U.S. merger and acquisition activity quickened: 1663 transactions were reported to the U.S. Department of Justice (DOJ) and the FTC in fiscal year 2014—up from 1326 in fiscal year 2013.Footnote 5 Only a small percentage of these resulted in the antitrust authorities undertaking a full phase investigation in which a “Second Request” for information is sent to the merging parties: The FTC issued 30 Second Requests, and the DOJ issued 21.Footnote 6 The FTC in FY2014 brought 17 merger enforcement actions, which consisted of 13 consent orders that permitted the merger to proceed subject to certain conditions; three transactions that were abandoned or restructured during the investigations; and the Commission filed a complaint in federal court to permanently enjoin one transaction. The FTC also brought eight non-merger antitrust enforcement actions in FY2014, six of which were resolved with consent agreements.Footnote 7
 BE continues to engage with the larger economics community by publishing research articles in academic journals, presenting original research at conferences, and maintaining an active seminar series. In addition, it organizes the annual FTC Microeconomics Conference, the seventh of which was held in October of 2014 in Washington, DC.Footnote 8 Paper sessions, panel discussions, and keynote addresses covered such topics as the impact of “big data” on consumers and firms; merger remedies; peer-to-peer Internet markets; and narrow healthcare networks. The next FTC Microeconomics Conference will again be in Washington, DC, on November 13–15, 2015.Footnote 9
 The remainder of this article is divided into four sections: Each focuses on a specific matter that involved a variety of economic issues and analyses. Section 2 discusses two parallel consumer protection investigations of a practice that resulted in fraudulent, unauthorized charges being added to consumers’ mobile phone bills. A typical service was one that would send the consumer a daily horoscope or joke via text messaging, for which the consumer would be charged a monthly fee. These investigations resulted in settlements with AT&T and T-Mobile that required each carrier to pay at least $90 million in refunds to consumers as well as civil penalties to the FCC and states. We describe reduced-form and structural econometric analysis that BE staff relied upon to estimate the consumer injury in these cases. Section 3 summarizes the findings of a research project that was aimed at building upon extensive work that BE previously has done to investigate the prevalence of fraud by examining whether some of the determinants of susceptibility to fraud can be identified through the use of experimental methods. Subjects in the experiments were asked to assess a sequence of advertisements that contained claims of varying plausibility, and were asked to evaluate the ads. The study tested whether these assessments were correlated with various economic, psychological, and demographic measurements that were elicited from the subjects. In Sect. 4, we turn to our first of two antitrust matters: the Verisk/EagleView merger investigation. Verisk makes and markets software to insurance companies to help them prepare property insurance claims estimates. One of the inputs on which this software relies is an estimate of the size and shape of the roof of the insured building. EagleView developed and marketed software to estimate a roof’s size and shape using overhead photographs, which allowed these estimates to be obtained without having to send an individual to perform a physical inspection. These products were complements; but Verisk also had developed software to estimate roof sizes from photographs, in direct competition with EagleView. We describe the economic analysis of that horizontal competition between the companies, and address the vertical issues that arose due to the complementary nature of the companies’ original products. The final section discusses the FTC’s case against the North Carolina Board of Dentistry. This case made it to the Supreme Court, based on an important question regarding the legal requirements for actions of state governments to be exempt from federal antitrust enforcement. This was decided in the FTC’s favor in February of 2015. However, a determination that an action is not exempt from the antitrust laws leaves open the question of whether the action is in violation of those laws. The FTC alleged that the dental board had violated Section 5 of the Federal Trade Commission Act by issuing cease-and-desist letters to non-dentist providers of teeth-whitening services. We discuss economic analysis that is relevant to the question of whether that action constitutes anticompetitive exclusionary conduct.",1
47.0,4.0,Review of Industrial Organization,30 October 2015,https://link.springer.com/article/10.1007/s11151-015-9489-5,Recent Developments at DG Competition: 2014,December 2015,Giulio Federico,Massimo Motta,Penelope Papandropoulos,Male,Male,Female,Mix,,
47.0,4.0,Review of Industrial Organization,04 November 2015,https://link.springer.com/article/10.1007/s11151-015-9490-z,Economics at the Antitrust Division 2014–2015: Comcast/Time Warner Cable and Applied Materials/Tokyo Electron,December 2015,Nicholas Hill,Nancy L. Rose,Tor Winston,Male,Female,Male,Mix,,
47.0,4.0,Review of Industrial Organization,20 November 2015,https://link.springer.com/article/10.1007/s11151-015-9491-y,"The Year in Economics at the FCC, 2014–2015",December 2015,D. Bring,W. Leighton,D. Waterman,Unknown,Unknown,Unknown,Unknown,,
48.0,1.0,Review of Industrial Organization,08 August 2015,https://link.springer.com/article/10.1007/s11151-015-9474-z,The EU Leniency Programme and Recidivism,February 2016,Catarina Marvão,,,Female,Unknown,Unknown,Female,"Article 101Footnote 1 of the EU Treaty prohibits explicitly the existence of cartels. However, recent antitrust cases provide evidence that cartel agreements are a perennial problem in the EU: in 2012 and 2013, a total of 32 groups of firms were put under formal cartel investigation by the European Commission DG-Competition.Footnote 2
 The US Leniency Programme was put in place in 1973, but only when it was revised in 1993 did it originate a large number of cartel reports and led to the conviction of several international cartels (Hammond 2004). Following the example of the “successful” US Leniency Programme, the European Commission launched, in July 1996, the European Leniency Programme (LP) (European Commission 1996). This programme grants immunity or reduction of fines to individual firms that are members of a cartel, in exchange for the initial reporting of the cartel and/or relevant cooperation with the Commission during a cartel investigation. To be entitled to a leniency-related penalty reduction, the firm should provide “significant added value with respect to the evidence already in the Commission’s possession”. This is vague, since the applicant does not know, when applying, what information the European Commission (EC) has and/or to which extent it can meet the “added value” requirement. The present paper contributes to the existing literature by empirically examining which factors give incentives to cartel members to self-report and what firm and/or cartel characteristics influence the leniency decision by the Commission. This is also the first paper to specifically examine the case of recidivism and to use a double-sided Tobit model to analyze firm-level data, which was collected by the author. The empirical results in the paper confirm that the first reporter receives significantly larger leniency-related penalty reductions. The results also illustrate how the 10 repeat offenders and 79 multiple offending firms can apparently play the “leniency game” and receive larger leniency-related penalty reductions than do single offending firms. Although the LP creates an incentive to report the cartel, there may also exist an incentive to collude and then be the first reporter. To reinforce this finding, it is shown that the share of multiple offenders in a cartel may also have a significant, positive and large impact on the individual leniency-related penalty reduction. The organization of the rest of the paper is as follows: in the next section, a review of the literature is presented. In Sect. 3, the goals and evolution of the EU Leniency Programme are discussed. In Sect. 4, the dataset is described, and the case of multiple and repeat offenders and the financial crisis are discussed. The empirical methodology is described in Sect. 5 before the results are presented in Sect. 6. Section 7 offers concluding comments.",15
48.0,1.0,Review of Industrial Organization,19 August 2015,https://link.springer.com/article/10.1007/s11151-015-9479-7,How Success and Uncertainty Compel Interest in Related Goods: Playoff Probability and Out-of-Market Television Viewership in the National Football League,February 2016,Scott Tainsky,Jie Xu,Steven Salaga,Male,,Male,Mix,,
48.0,1.0,Review of Industrial Organization,21 August 2015,https://link.springer.com/article/10.1007/s11151-015-9478-8,"Unilateral Effects Analysis in Differentiated Product Markets: Guidelines, Policy, and Change",February 2016,Malcolm B. Coate,Shawn W. Ulrick,,Male,,Unknown,Mix,,
48.0,1.0,Review of Industrial Organization,18 August 2015,https://link.springer.com/article/10.1007/s11151-015-9481-0,Tacit Collusion in Electricity Markets with Uncertain Demand,February 2016,Richard Benjamin,,,Male,Unknown,Unknown,Male,"Daily repetition of electricity auctions gives electricity-generating firms the incentive to engage in implicit collusion. Tacitly colluding allows firms to raise prices and receive greater profits than those that are obtainable in the stage-game Nash equilibrium. A few works to date have modeled electricity auctions as infinitely repeated games,Footnote 1 but only under demand certainty (i.e. firms face known demand functions when submitting their bids). Those that do mention uncertainty assume its resolution before market participants submit their bids.Footnote 2
 In reality, though, the assumption of known demand is untenable. For example, in the PJM Interconnection L.L.C. (PJM),Footnote 3 the deadline for bids in the day-ahead energy market is noon, 1 day ahead of the operating day. While this is unsurprising, bidding in the real-time market (by those generators that are available, but not selected in the day-ahead market) also closes one-day ahead of the operating day, at 6:00 p.m.Footnote 4 Significant shocks, like errors in weather forecasts and outages of generators and transmission lines, occur between market settlement and real-time operations. Market participants therefore face significant unresolved uncertainty when they place their bids. Likewise, variable output from intermittent renewable resources introduces uncertainty in residual demand. These factors argue that understanding the role that uncertainty plays is vital in understanding electricity market bidding strategies.Footnote 5
 This paper thus contributes to the study of electricity markets by modeling them as infinitely repeated games under uncertainty. Sections 3–5 present the basic model. Our analysis demonstrates that with the addition of uncertainty, the auction’s low bid is payoff relevant. This causes a change in the optimal bidding strategy in the uniform price auction from asymmetric to symmetric bidding. Section 6 extends the basic model. Section 6.1 examines the N-firm, symmetric oligopoly model. It shows that increasing the number of firms does not affect the critical discount rate that supports symmetric bidding. It also shows, however, that the bid-rotation equilibrium becomes less stable. Section 6.2 introduces demand response programs, which add demand elasticity in the high-demand period. Demand response discourages collusion by decreasing the incentive of firms to bid at the maximum allowable price (the “price cap”). Section 6.2 explores the impact of cost-asymmetry. It shows that the presence of low- and high-cost units allows for an asymmetric equilibrium where the low-cost firm acts as a sort of Stackelberg leader. It further asserts that physical and regulatory considerations argue for this equilibrium. Section 7 concludes and provides policy implications.",11
48.0,1.0,Review of Industrial Organization,29 August 2015,https://link.springer.com/article/10.1007/s11151-015-9483-y,"The Effects of Past Entry, Market Consolidation, and Expansion by Incumbents on the Probability of Entry in Banking",February 2016,Robert M. Adams,Dean F. Amel,,Male,Male,Unknown,Male,"Entry and potential entry play a central role in the competitive interactions of firms in standard theories of industrial organization. These theories posit that greater entry or potential entry leads to more competitive market equilibria. Because theory points to greater competition with an increasing probability of entry, potential entry assumes considerable importance in government regulation in the U.S. through the implementation of the antitrust statutes. In antitrust enforcement in the U.S. banking industry, for example, the attractiveness of a market for future entry is the most prominent mitigating factor cited when potentially anticompetitive consolidations are allowed. For these reasons, research into the determinants and effects of actual entry has a long history, both in banking and in other industries. This paper extends previous empirical work on entry in the banking industry in three ways: First, it supplements the determinants of entry that have been examined in previous research to include the effects of past entry and strategic barriers to entry on the probability of current entry into banking markets. Second, it utilizes more complete data on entry than have been used previously, and it examines separately two types of entry: entry by new firms, and entry into new markets by existing firms. Third, it examines the sensitivity of the probability of entry to changes in individual determinants of entry. The third point is most important for policy considerations: As policy makers evaluate potential entry in a market using the determinants of entry from our model, they can more easily gauge how likely entry will be, given a market’s characteristics. The literature on entry in banking has focused almost exclusively on entry by new firms in urban markets. However, entry into new markets by existing firms is another relevant form of entry. In fact, it is the dominant form of entry in every year of our sample. Even in the years before the Riegle-Neal Act of 1994 effectively allowed nationwide branching, entry by branch expansion outstrips entry by new firms.Footnote 1 The substantially greater time and monetary costs of entry through the formation of a new charter compared to the costs of entry by an existing bank that establishes a branch in a new market may lead to differences in the circumstances in which the two types of entry occur. This paper also extends the literature by considering both forms of entry into rural markets; previous research has focused on entry into urban markets, primarily because most entry occurs there. Using a panel data set that covers 12 years and nearly 3000 local banking markets, this paper uses a reduced-form model to analyze the factors that previous research has found predict entry into local markets. Our data set allows us to consider all factors—such as incumbent branch expansion, horizontal mergers and acquisitions, and past entry—that have been analyzed in most previous research. We analyze urban and rural markets separately and find that the entry process is potentially different in the two market types. Our reduced-form model precludes any conclusions about causation; but the resulting predictions on the likelihood of future entry are, nonetheless, valuable to policymakers who seek to evaluate the likely competitive effects of bank mergers. The remainder of the paper is organized in the following manner: Sect. 2 discusses the extant literature on bank entry. Section 3 discusses the model, including both its theoretical underpinnings and our empirical implementation. Section 4 describes the data, and Sect. 5 discusses the basic results and a large number of robustness checks. Section 6 includes conclusions and a policy discussion.",10
48.0,2.0,Review of Industrial Organization,02 January 2016,https://link.springer.com/article/10.1007/s11151-015-9496-6,Industrial Organization Research by Federal Reserve Board Economists,March 2016,Robin A. Prager,,,,Unknown,Unknown,Mix,,
48.0,2.0,Review of Industrial Organization,02 January 2016,https://link.springer.com/article/10.1007/s11151-015-9498-4,Can Financing Constraints Explain the Evolution of the Firm Size Distribution?,March 2016,Ralf R. Meisenzahl,,,Male,Unknown,Unknown,Male,"The recent financial crisis renewed the debate about the importance of financing constraints for firm growth. If financing constraints are a crucial determinant for firm growth, then tight credit standards and lower collateral values may, at least in part, account for the sluggish recovery that followed the great recession. Consequently, several current policy initiatives such as the creation of the $30 billion small business lending fund in 2010 seek to ease firms’ access to credit. The success of these policies depends on the importance of financing constraints for firm growth. To assess this importance, this paper examines the effect of financing constraints on firm growth patterns for small businesses in the US. In the absence of frictions, firm size and growth should be independent—the so-called Gibrat’s law. However, the literature documents that firm size, firm age, and firm growth are not independent, suggesting the presence of frictions.Footnote 1 Theoretical papers introduce financial frictions in dynamic models to predict stylized facts of firm growth patterns.Footnote 2 The empirical plausibility of financing constraints as crucial frictions inhibiting firm growth has been called into question by Angelini and Generale (2008), who, using Italian credit register data, find no systematic differences between financially constrained and financially unconstrained firms. This paper provides new evidence for the importance of financing constraints for firm growth with the use of US small businesses’ credit decisions in the federal reserve’s survey of small business finances (SSBF). While small, these businesses account for almost 50 % of GDP and for most of US labor market dynamics. I examine whether financing constraints as suggested by a lack of access to credit affect firm growth patterns in the US and find that financially constrained firms are smaller as measured by employment, sales, and net worth. This result differs from the evidence that has been presented by Angelini and Generale (2008), for two reasons: The Italian credit register data exclude firms with less than 10 employees; and the data contain no information on discouraged borrowers. While the contemporaneous correlation between firm size and access to credit suggests that financing constraints may matter for firm growth, it could also reflect that smaller firms have less access to credit without inhibiting firm growth. I therefore analyze whether access to credit affects future employment growth. The regression analysis shows that having no access to credit reduces a firm’s annual employment growth rate by 1 % point in the pooled sample. For young firms, this effect increases to 1.7 % points. In the subsample of firms that report a need for (new) credit, this effect increases to 2.5 % points lower employment growth and 3.5 % points for young firms, respectively. I address to potential endogeneity of no access to credit with an instrument variable approach. Since information asymmetries between borrowers and lenders are smaller for large firms and firms that can secure credit with collateral, I use firm size and net worth as instrument for no access to credit. The results of the instrumental variable regressions suggest that having no access to credit reduces a firm’s annual employment growth rate by 15 % points. In sum, the results suggest that access to credit affects firm growth patterns. The smallest firms may be rationed out of the credit market and exhibit lower employment growth rates. Yet, the results do not imply that all firms should receive credit. For instance, banks may screen firms and withhold credit from less productive firms.Footnote 3 However, in times of tight credit conditions, credit rationing or perceived credit that rations deterring potential borrowers from applying for credit may constrain firm growth unduly. In such an environment, policies that aim to ease access to credit can be beneficial. The paper is organized as follows: Sect. 2 summarizes the data. Section 3 analyzes the effect of financing constraints on firm growth. Section 4 discusses the results. Section 5 concludes.",6
48.0,2.0,Review of Industrial Organization,14 January 2016,https://link.springer.com/article/10.1007/s11151-015-9497-5,Community Bank Performance: How Important are Managers?,March 2016,Dean F. Amel,Robin A. Prager,,Male,,Unknown,Mix,,
48.0,2.0,Review of Industrial Organization,05 February 2016,https://link.springer.com/article/10.1007/s11151-015-9499-3,Where Are All the New Banks? The Role of Regulatory Burden in New Bank Formation,March 2016,Robert M. Adams,Jacob Gramlich,,Male,Male,Unknown,Male,"The rate of new bank formation in the United States (the dashed line in Fig. 1) declined dramatically in recent years. From 1976 to 2009, the average number of new banks formed each year exceeded 130, and some years saw the formation of nearly 300 new institutions. From 2010 to 2015, however, only 4 new banks were formed.Footnote 1
 New charters and federal funds rate This dramatic reduction in new bank charters could be a concern for policymakers if, as some have suggested, the decline has been caused by the increased regulatory burden that was instituted in response to the recent financial crisis. Numerous regulations have been passed since the financial crisis: some affecting large banks; some affecting small banks; and some affecting both. These regulations include rules on capital, lending, regulatory compliance, and charter formation, among others. Collectively these regulations—as well as uncertainty around their interpretation, enforcement, and future extension—may have depressed banking profits, and thus new bank supply, to historically low levels. Other factors besides regulation, however, may have contributed to the decline in new bank charters. In particular, the macro economy has been weak since the financial crisis, which can reduce bank profits in at least two ways. First, the weak economy has introduced a low interest rate environment (the solid line in Fig. 1), which diminishes new banks’ ability to earn spread interest.Footnote 2 As seen in Fig. 1, a strong correlation exists between interest rates and new entry.Footnote 3 Second, a weak economy may diminish household and business demand for banking services such as loans and deposit-taking services. If factors such as these have depressed entry, there may be less cause for concern that regulation is driving supply to such low levels. The aim of this paper is to understand how much of the recent decline in new bank formation is attributable to non-regulatory factors. We model banks’ entry decisions using time- and geography-varying determinants of prospective profit,Footnote 4 and then use the model to predict the level of new bank formation absent any effect from post-crisis regulatory change. The results suggests that most of the current decline in new charters—approximately 75 % or more in our preferred specifications—could be explained by non-regulatory factors. Whether or not regulation has had a constraining effect is harder to determine due to its contemporaneity with other factors. The remainder of the paper proceeds as follows: Sect. 2 discusses the existing literature on bank entry and profitability. Section 3 presents information on new charter formation, as well as relevant trends in bank profitability and branch expansion. Section 4 discusses our model of new banking entry, and Sect. 5 discusses the data we use to estimate the model. Section 6 describes our results and model predictions, and Sect. 7 concludes.",9
48.0,2.0,Review of Industrial Organization,18 January 2016,https://link.springer.com/article/10.1007/s11151-016-9500-9,Crowding Out Effects of Refinancing on New Purchase Mortgages,March 2016,Steve A. Sharpe,Shane M. Sherlund,,Male,Male,Unknown,Male,"The financial crisis and collapse of the housing market, and the concomitant surge in mortgage defaults, left the housing finance industry in tatters, as many originators failed or substantially scaled back operations. In order to help revive economic activity and support recovery of the housing market in particular, the Federal Reserve embarked on a path of extraordinarily accommodative monetary policy, including a commitment to purchase Treasury securities and mortgage-backed securities. The resulting boost to the housing market was expected to help bring a halt to and then (hopefully) begin to reverse the slide in house prices, increase household wealth, and spur household consumption. A range of estimates have been offered on the extent to which Federal Reserve large-scale asset purchase programs reduced longer-term market interest rates, including those on residential mortgages and mortgage-backed securities (MBS).Footnote 1 But even if policy substantially lowered MBS yields, the ultimate effects on mortgage borrowers were more muted. For example, it has been argued that the reduction in MBS yields was not entirely passed through in the form of lower mortgage rates. Scharfstein and Sunderam (2015) cite the lack of a competitive market structure, while Fuster et al. (2013) point to higher costs as well as fatter originator profit margins that arise from temporary market power. Many industry participants cited higher guarantee fees that were charged by the housing government-sponsored enterprises (GSEs) and lender “capacity constraints”. Our study aims to gauge the effects of low interest rates and potential capacity constraints on borrowers subsequent to the financial crisis by focusing on mortgage quantities and product mix—specifically, the quantity of mortgages originated for financing home purchases—while also differentiating across customers of various credit qualities. In particular, we examine how the interplay of refinancing demand and industry processing capacity may have impinged on the ability of borrowers with modest credit-quality to obtain purchase mortgages. We begin by constructing an empirical proxy for the “capacity utilization” of underwriting labor in the mortgage industry: the monthly flow of mortgage applications divided by total mortgage industry employment. We show that industry labor capacity has demonstrated little if any propensity to expand in response to increased refinance application volumes. Rather, lenders appear to expand and contract their mortgage staffs largely in response to the demand for purchase mortgages. This pattern of behavior could be rationalized if companies face substantial fixed training costs, which would discourage hiring to service temporary surges in demand. To the extent that refinancing waves were historically large but unpredictable and relatively short-lived, it seems plausible that the reduced underwriting capacity following the crisis was again insensitive to refinancing waves that presumably turned out to be more persistent than expected. We also propose a model of mortgage lenders as multiproduct firms, which employ a single pool of labor input to produce purchase mortgages and refinance mortgages. For each of those two products, lenders serve a wide range of borrower quality; importantly, mortgages for riskier borrowers require more labor to produce. When lenders are capacity-constrained, they prioritize which mortgage applications to complete and originate: They lend first to applicants of relatively low credit risk, whose mortgages are less costly to complete. As capacity constraints ease, lenders turn to underwriting the riskier, more-difficult-to-complete mortgage applications, which potentially increases purchase originations to higher credit-risk borrowers. Empirically, we indeed find that a decrease in capacity utilization has a positive and substantial effect on the originations of borrowers with low to moderate credit scores. In particular, a decrease in capacity utilization of the magnitude that was seen in 2013 is estimated to increase purchase originations by 20–30 % among borrowers with credit scores of 620 or less, 20–25 % among borrowers with credit scores of 621–680, 8–14 % among those with credit scores of 681–710, and up to 8 % among those with credit scores of 711–740.Footnote 2
 The remainder of this paper is organized as follows: Sect. 2 provides some background and some key empirical facts that guided our thinking and estimation and summarizes the data that we use. Section 3 presents our theoretical model, and Sect. 4 discusses our empirical strategy and results. Section 5 concludes.",13
48.0,3.0,Review of Industrial Organization,07 March 2016,https://link.springer.com/article/10.1007/s11151-016-9508-1,The Power and the Limits of Industrial Organization,May 2016,Severin Borenstein,,,Male,Unknown,Unknown,Male,,3
48.0,3.0,Review of Industrial Organization,10 March 2016,https://link.springer.com/article/10.1007/s11151-016-9506-3,From the Fringe to the Forefront: Low Cost Carriers and Airline Price Determination,May 2016,John Kwoka,Kevin Hearle,Phillippe Alepin,Male,Male,Male,Male,"Although low-cost carriers (LCCs) have existed in the airline industry since deregulation, they have traditionally been at the fringes of the market: located at secondary airports, providing cheaper but lesser quality service, and representing the marginal players. Over the past 10–15 years, however, LCCs have grown enormously in size and importance. They have moved into many primary airports in direct competition with legacy carriers. Their route structures have grown from point-to-point to something that resembles hub-and-spoke systems. LCCs collectively now carry approximately 30 % of all passenger traffic in the US and account for 25 % of revenue-passenger miles. On about one-third of all nonstop routes in the country, an LCC is the largest single carrier. Many studies, of course, have documented the fact that the presence of LCCs—and Southwest in particular—affects airline pricesFootnote 1; but that observation derives from empirical results that typically view LCCs as fringe players that constrain larger legacy carriers. That approach may not fully capture the role of LCCs in a world where they have come to prominence in, and sometimes dominance of, domestic airline markets. Our study takes a new look at the impact of LCCs on fare determination on the routes that they serve, that they threaten to enter, or that are adjacent to airports where they operate; and we do so in a manner that captures how LCCs and legacy carriers compete in jointly determining overall pricing. This exercise establishes the quite different roles of legacy carriers and LCCs in market fare determination. We find, for example, that the price-reducing effect of overall LCC share on market-wide prices diminishes past some point where they dominate a route, and further, that the internal structure of the LCC segment—their number and size—matters as well. We then examine pricing at the individual carrier level and identify the determinants of legacy carrier pricing and of LCC pricing. This permits insights into price determination in markets where either legacy carriers or LCCs might dominate, as well as insights into which specific carriers influence pricing by others. We find, for example, that legacy carrier fares are determined by quite different forces than are LCC prices: The effect of an additional LCC on a route has a substantial effect on legacy carrier pricing, but a considerably smaller effect on other LCCs’ prices. We also find differences in the effects of specific LCCs—Southwest, JetBlue, AirTran—on legacy carriers’ prices and also on each other’s prices.Footnote 2 With respect to legacy carriers as well, we find muted competition with each other and little effect on LCC prices. All these differences suggest a more nuanced view of the LCC segment and legacy carriers at the present time than is common in the literature. The next section describes the most important features of the low-cost carrier segment, followed by a description of the data that are used in this study. The subsequent two sections report on the detailed analysis of market-wide prices and carrier-route prices. A final section summarizes findings and offers some implications for policy as this industry undergoes further transformation.",24
48.0,3.0,Review of Industrial Organization,11 September 2015,https://link.springer.com/article/10.1007/s11151-015-9485-9,"Exclusionary Conduct of Dominant Firms, R&D Competition, and Innovation",May 2016,Jonathan B. Baker,,,Male,Unknown,Unknown,Male,"The antitrust concern with monopolization is not limited to prices; it also includes a dominant firm’s suppression of new technologies, products, and business models. Two well-known monopolization cases provide illustrations. At the start of the twenty-first century, Microsoft, which was the monopolist of operating systems for Intel-compatible personal computers, was found to have prevented nascent operating system competition by excluding Netscape’s browser and Sun’s Java programming language. A half century before, the Lorain Journal newspaper protected its monopoly on advertising by local businesses by excluding a radio station entrant.Footnote 1
 This article evaluates the innovation consequences of antitrust enforcement against exclusionary conduct by a dominant firm through a Nash equilibrium model of research and development (R&D) competition between a dominant firm and a rival to create new products.Footnote 2 The article is concerned solely with incentives to innovate; it abstracts from the potential benefits of antitrust enforcement in lowering (quality-adjusted) prices and increasing output in static markets. In the model, R&D investment increases the prospects of innovation success but does not influence post-investment price competition in the event that both firms succeed.Footnote 3 These simplifications make transparent the role of strategic interactions that involve R&D investment. In particular, the model demonstrates that enforcement actions that challenge pre-innovation exclusion and enforcement actions that challenge post-innovation exclusion will tend to be effective in different strategic settings.Footnote 4 An antitrust prohibition on dominant firm exclusion of its rival from post-innovation (pre-innovation) product market competition will tend to increase the overall likelihood of industry innovation if the dominant firm’s best response function slopes upward (downward) and is sufficiently steep, or if its rival’s best response function slopes downward (upward) and is sufficiently steep. In addition, an antitrust prohibition on dominant firm exclusion of its rival from R&D competition increases the overall likelihood of industry innovation if the dominant firm regards its rival’s R&D investment as a strategic complement (its best response function slopes upward). The model also shows that whether one firm regards the other firm’s R&D investment as a strategic complement or strategic substitute turns on an increasing differences condition: whether the first firm’s incremental benefit of increased R&D investment is greater if its rival’s R&D effort succeeds or if its rival’s R&D effort fails.Footnote 5 Baker (2016) applies these results to identify observable factors that would suggest whether dominant firms are likely to regard rival R&D as a strategic complement or strategic substitute and to evaluate whether antitrust enforcers and courts should question a dominant firm’s claim that alleged exclusionary conduct enhances its incentive to innovate by increasing its return to R&D investment.",2
48.0,3.0,Review of Industrial Organization,15 September 2015,https://link.springer.com/article/10.1007/s11151-015-9484-x,"Sequential Product Innovation, Competition and Patent Policy",May 2016,George Norman,Lynne Pepall,Dan Richards,Male,Female,Male,Mix,,
48.0,3.0,Review of Industrial Organization,28 October 2015,https://link.springer.com/article/10.1007/s11151-015-9487-7,"Competition, Cost Innovation, and X-inefficiency in Experimental Markets",May 2016,Andrew Smyth,,,Male,Unknown,Unknown,Male,"X-inefficiency theory maintains that firms may not minimize their costs of production, especially in markets where they experience little competitive pressure.Footnote 1 To date, there have been no attempts to study x-inefficiency using experimental methods.Footnote 2 While there are always questions of external validity with experimental research, the laboratory offers an excellent test bed for x-inefficiency theory because the theory posits a behavioral response to external stimuli—an increase in productive efficiency in response to market competition. In the lab, competitive stimuli can be precisely applied, and any behavioral response that affects efficiency can be readily observed. In these experimental markets, subjects participated in a repeated, two-stage game. In the first stage, they decided how much to spend on cost innovation. Innovation was stochastic, with their probability of achieving a lower production cost increasing in their expenditure. In the second stage, they made pricing and capacity decisions given their realized production cost. This second, “market” stage was a monopoly, or a duopoly, or a quadopoly. X-inefficiency theory typically assumes that the cost frontier is achievable—if management makes necessary expenditures. In these experiments, as in actual markets, cost innovation was stochastic. Chance dictated that subjects could not always achieve the exogenous cost frontier, so x-inefficiencies are measured relative to optimal innovation paths that are calculated for each market structure. The data show that subjects in more competitive market structures attempted closer-to-optimal cost innovation. They support the hypothesis that competitive pressure reduces x-inefficiency relative to monopoly. More competitive market structures also increased total surplus and the percentage of total surplus that is consumer surplus, relative to monopoly. Finally, the experiments illustrate how x-inefficiency affects surplus dynamically. Outside the lab, competitive pressure may limit opportunities for afternoon tee times, opulent office decor, or for using obsolete production methods. In these experiments, differential pricing pressure alone created differences in cost efficiency for monopolies relative to more competitive markets. Thus, the data highlight price as a mechanism through which competitive pressure curbs x-inefficiency.",5
48.0,3.0,Review of Industrial Organization,10 September 2015,https://link.springer.com/article/10.1007/s11151-015-9482-z,The Effect of State-Private Co-partnership System on Russian Industry,May 2016,Nadia Vanteeva,Charles Hickson,,Female,Male,Unknown,Mix,,
48.0,4.0,Review of Industrial Organization,17 February 2016,https://link.springer.com/article/10.1007/s11151-016-9503-6,Cartel Stability: Determinants and International Evidence,June 2016,Robert M. Feinberg,,,Male,Unknown,Unknown,Male,,
48.0,4.0,Review of Industrial Organization,27 April 2016,https://link.springer.com/article/10.1007/s11151-016-9520-5,Price Fixing Hits Home: An Empirical Study of US Price-Fixing Conspiracies,June 2016,Margaret C. Levenstein,Valerie Y. Suslow,,Female,Female,Unknown,Female,"More than a century after the passage of the Sherman Antitrust Act and 20 years after the adoption of more aggressive enforcement by the US Department of Justice (DOJ), cartels continue to affect US markets. Fifty new criminal cases, most of which were price fixing, were filed in 2013; over a billion dollars in criminal fines were levied.Footnote 1 In this paper, we study the formation and breakup of price-fixing cartels convicted of operating in the US in the last half-century. Understanding how and why these cartels continue to form and persist (and get caught) is critical to developing better models of firm behavior and better competition policy. In this paper, we present analysis of a sample of Section 1, Sherman Act price-fixing cases between 1961 and 2013. Approximately half-way through the sample period, the DOJ strengthened its leniency policy. This policy change increased firms’ incentives to turn in cartels in which they were participating. These data allow us to examine the effectiveness of this policy at encouraging cartel breakup and deterring cartel formation. One of the few areas of consensus flowing from theoretical research on collusion is that it requires patience. In general there is a monotonic relationship between the ability of a cartel to sustain collusion and the discount rate of its members. There have been very few empirical studies of the relationship between the discount rate and collusion; there is a small experimental literature, discussed below, that has studied this question. Previously, using a sample of international cartel prosecutions by the DOJ and European Commission (EC), we found that market interest rates had little impact on cartel stability, but that firm-level financial weakness, which could raise individual discount rates, was an important determinant of cartel breakup (Levenstein and Suslow 2011). In this paper, we continue to pursue the study of the relationship between patience and cartel stability. We consider both economy-wide determinants of the discount rate and firm-level leverage and liquidity in industries with cartels. In contrast, the theoretical literature is quite conflicted about how the business cycle may affect collusion. This question has been the focus of much of the prior empirical research on cartel breakup (see Levenstein and Suslow 2006a, 2011 for discussion of this literature). We examine the impact of business cycle fluctuations on cartel breakup. Our previous research suggests that economy-wide fluctuations in demand have had little impact on cartel breakup in contemporary cartels (Levenstein and Suslow 2011). That analysis covered a period of remarkable macroeconomic stability in the United States; consequently, it may not provide a good setting for addressing this question. The data analyzed in this cover a number of business cycles and provide a better basis for analysis. We also examine the cyclicality of cartel formation. Competition observers have often claimed that cartels are more likely to form during recessions, but there has been no systematic study of this question. Admittedly, measuring cartel formation is challenging. Our examination of prior research on cartel formation with NBER business cycle dates suggests no obvious pattern (Levenstein and Suslow 2015, 446–449). Cartels were found to form during recessions, but not disproportionately so.",19
48.0,4.0,Review of Industrial Organization,18 March 2016,https://link.springer.com/article/10.1007/s11151-016-9509-0,The Rise and Fall of Cartels with Multi-market Colluders,June 2016,Jun Zhou,,,,Unknown,Unknown,Mix,,
48.0,4.0,Review of Industrial Organization,19 April 2016,https://link.springer.com/article/10.1007/s11151-016-9516-1,"Policy Innovations, Political Preferences, and Cartel Prosecutions",June 2016,Vivek Ghosal,D. Daniel Sokol,,Male,Unknown,Unknown,Male,"Cartel prosecutions has been perhaps the biggest growth area of antitrust enforcement globally. Fines for collusion have reached record levels in recent years, which has brought increased attention to antitrust. Yet, the determinants of cartel cases remains understudied. Our paper examines the policy determinants and the political preferences that may guide cartel prosecutions. We examine the long-run evolution of U.S. cartel enforcement by examining its three major attributes: number of cartel cases initiated, fines for corporations and individuals, and incarceration for individuals. The changes resulted from major policy innovations in public enforcement, particularly leniency. Higher financial penalties and greater incarceration reinforced the leniency policy mechanism. As we detail later, based on these changes, we note four distinct policy regimes: pre-1978, 1978–1992, 1993–2003, and 2004–2013. These policy initiatives were designed to minimize the incentives to form cartels, as well as to destabilize existing cartels. The transformation of cartel policy as part of optimal antitrust enforcement occurred at about the same time that much of antitrust underwent significant change doctrinally. Many of the transformations of antitrust enforcement in this period were a function of an intellectual shift, in part due to Chicago law and economics scholars.Footnote 1 These scholars advocated a fundamental change in the then existing U.S. antitrust law and policy: moving liability from per se to a rule of reason due to potential efficiencies of the behavior in question.  Cartel enforcement played a smaller role for the Chicago School overall, which focused on the reform of merger and monopolization enforcement.Footnote 2 The lack of the emphasis on cartels was due both in part to the overall confusion by the courts as to other areas of law as well as to the fact that conceptually cartel enforcement was “low hanging fruit”: the identification of harm by cartel behavior from the standpoint of consumer welfare was simple. The per se application of liability to hard core cartels made them less effective and destabilized them.Footnote 3 The present structure of cartel enforcement with high fines, significant incarceration, an emphasis on enforcement against large international cartels and the use of leniency is very different from what concerned academic writing from Chicago or other scholars until the 1990s. This article contributes to the literature in two key dimensions. First, we conduct a detailed analysis of the evolving policy regimes, and quantify their effects on the total number of cartels prosecuted, and the penalties per firm and individual. Our work sheds light on previous theoretical work that examines deterrence with regard to enforcement tools and cartel formation.Footnote 4 Further, a number of papers have modeled how leniency provides incentives to improve detection because leniency may destabilize cartels.Footnote 5 By examining alternative policy regimes, we extend the empirical work in this area. As far as we are aware, such a detailed analysis is not available using data over such a long time period. Second, we conduct an extensive analysis of political effects. In doing so, we extend prior work that examines political preferences.Footnote 6 Given our long time period, we are able to examine both inter-political party as well as intra-political party effects. The broader policy differences across various Presidential administrations have been stark. Our analysis allows us to examine whether the overall policy differences also extended to the area of cartels. In our empirical analysis we use data over a 45-year period, 1969–2013, to examine the intertemporal dynamics of cartel prosecutions. Our estimates show marked differences across the policy regimes in the number of cartels prosecuted, and the penalties imposed. Across the policy regimes, the number of cartels prosecuted have declined, while the fines levied per firm and per individual increased dramatically. We also find interesting results related to political effects; there is little evidence of inter-political party effects, but more revealing intra-political party effects.Footnote 7 In our empirical estimation we control for the prosecution variables’ own dynamics, as well as business cycles and the agency’s overall workload. The paper is organized as follows: In Sect. 2, we describe some of the key cartel enforcement and institutional changes from 1890 to the present.Footnote 8 In Sect. 3 we describe the data, and develop the empirical specification in Sect. 4. We present the empirical results in Sect. 5. In Sect. 6 we briefly note issues that are related to cross-jurisdictional cartel enforcement, by the European Commission, and scope for further research in this area. Final discussion and concluding remarks appear in Sect. 7.",8
48.0,4.0,Review of Industrial Organization,15 February 2016,https://link.springer.com/article/10.1007/s11151-016-9505-4,The Determinants of Cartel Duration in Korea,June 2016,Robert M. Feinberg,Hyunchul Kim,Minsoo Park,Male,Unknown,Unknown,Male,"There is a long empirical literature in Industrial Organization, dating at least back to the 1970s, examining determinants of cartel stability. However these studies have all been based on data derived from US and European antitrust enforcement actions. In Feinberg and Park (2015), a database of horizontal conspiracy antitrust cases in South Korea was examined to analyze the impact of these enforcement actions on prices and profit margins. In this paper, we take a different approach and explore the determinants of cartel duration as revealed in these cases. We believe this to be among the first of such studies for a newly-developed economy (or new adopter of antitrust enforcement). Previous work in this area goes back to Hay and Kelley (1974) for the US, Dick (1996) for US export cartels, Marquez (1994), Suslow (2005), Zimmerman and Connor (2005), and Levenstein and Suslow (2011) for international cartels, and De (2010) for European cartels. With the growth of antitrust enforcement agencies around the world, the ability to study cartel activity in other countries is now feasible. Recently Choi and Hahn (2014) have analyzed the role of the recent strengthening of the antitrust leniency/amnesty program in Korea on cartel stability; we utilize similar data, but our focus here is somewhat broader. It must be acknowledged in this analysis, as in previous work in this area, that we are analyzing formal cartel agreements that have been uncovered by the antitrust authority—in this case the Korean Fair Trade Commission—and rely on their estimates of when cartels were formed and ended. Excluded, therefore, are tacitly collusive agreements and formal agreements that never came to light. And, of course, the end-dates of these cartels are not necessarily the “natural” ones suggested by theory, but rather those truncated by government investigations and enforcement. Furthermore, while stability of cartel efforts can be examined, explaining the determinants of the frequency of cartel formation is beyond the scope of our analysis.",4
49.0,1.0,Review of Industrial Organization,18 January 2016,https://link.springer.com/article/10.1007/s11151-016-9501-8,Downstream Competition and the Effects of Buyer Power,August 2016,Zhiqi Chen,Hong Ding,Zhiyang Liu,Unknown,,Unknown,Mix,,
49.0,1.0,Review of Industrial Organization,08 December 2015,https://link.springer.com/article/10.1007/s11151-015-9494-8,Mitigation of Perverse Incentives in Professional Sports Leagues with Reverse-Order Drafts,August 2016,Liam J. A. Lenten,,,Male,Unknown,Unknown,Male,"Perverse incentives for pro-sports teams to underperform stem from the existence of player drafts in a handful of elite closed-end leagues, with suspicions of ‘tanking’ not uncommon. The catalyst is the reverse-order element, whereby the bottom-ranked team receives first pick in the subsequent draft; thus losing is linked to the prospect of a higher-order pick from the annual pool of available and/or emerging talent. The perverse incentives are strongest during the latter stages of the regular season for teams that already face a weakened win-incentive following expiration of playoff-qualification likelihood.Footnote 1 This is a crucial ongoing issue for relevant league administrators, as they care greatly about setting the right incentives for teams always to produce their best performance. Taylor and Trogdon (2002) demonstrate such underperformance in the National Basketball Association (NBA); this is the league in which the perverse-incentive problem is believed anecdotally to be most acute.Footnote 2 The NBA introduced a ‘lottery’ system—the top pick is drawn randomly, with probabilities weighted progressively towards lower-ranked teams—in 1984 (the National Hockey League, NHL, followed suit in 2007); this weakened the negative correlation between final rank and pick order. While the results of Price et al. (2010) indicate that this system reduces these perverse incentives, the lottery also inadvertently undermines (partially) the draft’s ability to allocate the best emerging players as intended. This study proposes a simple policy change to the draft rule that governs how the order of picks is determined: The change would be from fewest wins at end-of season (as currently) to fewest games played at the point when a team is eliminated from the playoffs. Using MLB and NBA data, we conclude that this rule change would significantly increase the conditional probability of victory of any team that currently has a perverse incentive to lose when it plays against an opponent that can still make the playoffs; thus the change would reduce the scope for perverse behavior that is consistent with tanking. This empirical result also means that the rule proposal would enhance competitive balance.Footnote 3
 A trial of the proposed rule in the four ‘major leagues’ (comprising also of the NHL and the National Football League, NFL) could well be worthwhile. Section 2 of this paper outlines the policy proposal, as well as its significance for economic policy more generally; Sect. 3 provides a summary of the data and modeling; Sect. 4 describes the results; and Sect. 5 concludes.",15
49.0,1.0,Review of Industrial Organization,10 December 2015,https://link.springer.com/article/10.1007/s11151-015-9495-7,Rivalry Effects and Unbalanced Schedule Optimisation in the Australian Football League,August 2016,Stephan Lenor,Liam J. A. Lenten,Jordi McKenzie,Male,Male,Male,Male,"Scheduling within-season sporting fixtures (i.e. games or matches) is a complex task for sports leagues administrators. In a regular ‘balanced’ (or round-robin) season—where each team meets all other teams an equal number of times—the administrator has to consider such issues as venue availability/capacity, sequencing, match times, travel equity, etc., in the objective function. However, when a season has an ‘unbalanced’ design, and teams do not meet rivals an equal number of times, the complexity of the problem is compounded as administrators also have to determine which teams will meet more often, and which will meet less often (or not at all).Footnote 1
 Historically, in the unbalanced portion of the season, the Australian Football League (AFL) have scheduled a number of key rivalries between large-market teams in the league to be repeated with the remainder of matches mostly allocated randomly. According to AFL administrators, this policy is pursued with the objective of maximising aggregated attendance.Footnote 2 To the extent that scheduling decisions have a measurable effect on match attendances, TV viewership and other revenues (e.g. advertising and merchandising), attention to the design of the unbalanced portion of sporting schedules represents an important, but potentially overlooked, aspect of sports league policy. This paper considers the current within-season scheduling policies of the AFL in relation to the claim that the status-quo arrangement maximises aggregate attendance by optimising the subset of rematches for the unbalanced portion of the season.Footnote 3 We find some support for the current policy as the top-ranked rivalries invariably include the matches repeated by policy design. However, our results suggest that the AFL could increase attendance by up to 7 % in the unbalanced part of the season by more attention to the selection of rematches. In addition to the optimisation exercise, we also analyse the temporal implications of the AFL’s maintained policy. Specifically, we consider the subset of teams that invariably meet twice per season and how these rivalries have fared over time. Finally, we show that the attendance gains that are achievable in the unbalanced part of the season under our optimised design are superior to candidate systems that are used in other sports leagues that contend similarly with unbalanced season schedules.",11
49.0,1.0,Review of Industrial Organization,20 November 2015,https://link.springer.com/article/10.1007/s11151-015-9493-9,Are Collaborative Agreements in Innovation Activities Persistent at the Firm Level? Empirical Evidence for the Spanish Case,August 2016,Erika Raquel Badillo,Rosina Moreno,,Female,Female,Unknown,Female,"Empirical contributions to the study of cooperation in innovation have expanded significantly in the last decades (Tether, 2002; Miotti and Sachwald 2003; López 2008; Abramovsky et al. 2009). However, understanding the persistence with which these agreements are carried out remains an important and under-researched topic. From a management perspective, cooperating in a persistent way allows firms to obtain know-how knowledge, which involves information about who knows what and who knows what to do, as well as the social ability to cooperate and communicate with different partners (Lundvall 2004). The main objective of this paper is to analyse if collaborative agreements in innovation are persistent at the firm level; and, in such a case, to study what are the main drivers of this phenomenon. In addition, we assess whether firms cooperate persistently on top of the widely documented persistence that is found in R&D activities (Peters 2009; Raymond et al. 2010; Triguero and Córcoles 2013; Arqué-Castells 2013; among others). We also aim at providing evidence on the extent to which having participated in technological collaborations with one type of partner in the past influences current collaborative agreements—not only with the same but also with other type of partners. Knowing which determinants of persistence are prevalent has important policy implications: If collaboration activities are state dependent, collaboration-stimulating policy measures, such as government support programmes, would be expected to have a deeper effect: They not only affect current collaboration agreements but also are likely to induce a permanent change in favour of cooperation. If, on the contrary, persistence is driven by individual characteristics, temporary shocks to technological collaboration will rapidly dissipate, and support programmes are unlikely to have long-lasting effects: In this case, policy should focus more on policies that try to improve the specific factors that drive cooperation in innovation. We follow a dynamic approach in the analysis of cooperation persistence: We take into account unobserved individual heterogeneity and address the initial conditions problem for a sample of Spanish firms in the period 2002–2010. On average, we find that a firm that cooperates in t − 1 has a probability of cooperating in t that is around 33 % points higher than that of a firm that did not cooperate in the previous period. We also show that such persistence is genuine in the sense that it is beyond the persistence that is observed in R&D. While the highest persistence is found in the case of vertical collaboration, we also observe that cooperation agreements with research-based agents increase the likelihood of cooperating in the future with a different type of partner. After this introduction, Sect. 2 proceeds with the literature review. Section 3 describes the database that is used, and Sect. 4 presents the empirical model. In Sect. 5 we present and discuss our results; and the main conclusions of the paper are presented in Sect. 6.",11
49.0,1.0,Review of Industrial Organization,01 February 2016,https://link.springer.com/article/10.1007/s11151-016-9502-7,Is Price Competition More Efficient than Quantity Competition? A Reversal with Unionized Oligopolists,August 2016,Minas Vlassis,Stefanos Mamakis,,Male,Male,Unknown,Male,"The pylons of modern oligopoly theory are the models of Cournot, where firms compete in the product market by independently adjusting their own quantities, and Bertrand, where the rival firms independently adjust their own prices.Footnote 1 These alternative hypotheses deliver valuable implications for the theory and practice of industrial economics (see Vives 2001); whilst, as argued by Tremblay and Tremblay (2011) and Tremblay et al. (2013), both quantity and price rivalry have been observed in real life.Footnote 2
 On the other hand, with regard to the labour market, the presence of trade unions and collective bargaining agreements are common in most imperfectly competitive industries, especially in Europe (see, e.g., Hartog and Theeuwes 1992). There are two ways in which unions negotiate with firms. The first involves bargaining about wages alone: “Right-to-Manage” (see, e.g., Nickell and Andrews 1983). The second, involves bargaining about both wages and employment: “Efficient Bargains” (McDonald and Solow 1981; MacCurdy and Pencavel 1986; Alogoskoufis and Manning 1991; Petrakis and Vlassis 2000). With respect to welfare considerations, the union-oligopoly literature so far seems to suggest that, compared to quantity competition and right-to-manage bargaining, price competition and efficient bargains entail higher output, employment, and consumer surplus. It has been also shown that, in contrast to the case of right-to-manage bargaining, under efficient bargains output and employment are not decreasing with union power, provided that union members are risk averse/neutral (see, e.g., Booth 1996).Footnote 3 Yet, the literature has not so far investigated whether efficient bargains and/or right-to-manage bargaining can be endogenously sustained under price competition in the product market. Therefore, an analytical conclusion with regard to the welfare properties of the alternative possible product and labour market equilibria is still needed. In the present paper we develop a unionized duopoly framework, where two independent upstream /downstream vertical chains (firm/union pairs) may alternatively compete in quantities or in prices. Like Petrakis and Vlassis (2000), we moreover argue that, prior to the realization of any downstream market strategy, and before entering into pair-wise negotiations, the firm and the union, in each firm/union pair, collectively decide about the pair-specific bargaining agenda. However, unlike the aforementioned authors, we consider that each pair’s bargaining agenda is observable by the rival pair, before pair-specific bargains are struck: In the broader context of contracting among upstream input suppliers and downstream producers the publicity of the bargaining agenda can be due to the long-term nature and the exclusivity of such vertical relationships, which may amongst other clauses provide specific input-per-output rules. Similarly, firm-union contracts may (apart from the wage) specify employment, at least implicitly: via staffing ratios, crew sizes, worker shifts, and other relevant rules that are often negotiated between the union and the firm’s management (see, e.g., McDonald and Solow 1981; Manning (1987; Rogers and Streek 1994). Our key result is that with firm-union bargaining a pair of Bertrand firms will both not be able to revert to the “Efficient Bargains” mode, and thus both firms will stay in the benchmark “Right-to-Manage” bargaining mode and will thus incur the inefficiencies of double-marginalization; whereas for a pair of Cournot firms, one of them will choose “Efficient Bargains”, and thus it is possible to improve efficiency sufficiently (compared to the Bertrand firms) that overall welfare improves. In particular, our findings show that, under price competition, the equilibrium bargaining agenda in each firm/union pair would always regard only wages (“right-to-manage”). Under quantity competition, however, and if union bargaining power is sufficiently low, the firm and the union in one firm/union pair would agree on a wage and employment bargaining agenda (“efficient bargains”) while the other pair’s agents would collectively choose right-to-manage. Quite remarkably, we further show that, if apart from union power the degree of substitutability among the firms’ products is low enough, then quantity competition may via efficient bargains prove to be more socially efficient compared to price competition. Unions may thus prove to be an efficiency-enhancing institution in oligopoly markets, in so far as they are not powerful enough to extract an excessive share of the profits differential emerging under efficient bargains. The remainder of the paper is organized as follows: Sect. 2 presents our structural model and the sequence of events arising in its context. In Sect. 3 two alternative sets of candidate product and labour market equilibria are derived; each set corresponds to an alternative hypothesis about the mode of product market rivalry, and the Nash equilibrium is found for each set. In Sect. 4 our findings are evaluated in social welfare terms, and Sect. 5 concludes the paper. 
The product market of our reference industrial sector consists of two unionized firms i (=1, 2), which produce differentiated goods. By assumption, both firms may compete by independently adjusting their own quantities or by independently adjusting their own prices. Firms exhibit symmetric C.R.S. production technologies in the labour input, given that the deployed capital input is always sufficient to produce the good. Effectively, therefore, each firm possesses a simple Leontief technology: q

i
 = N

i
 where, q

i
, N

i
, denote the firm i’s output and number of employees, respectively. For simplicity it is moreover assumed that the productivity of labour equals one. The representative consumer’s preferences for products \(q_{i} ,q_{j} ,z\) are given by a simple variant of Dixit’s (1979) quasi-linear specification, where z denotes a composite numeraire product. Therefore, each firm i ≠ j = 1, 2, faces an inverse demand function of the following form: In expression (2), \(\gamma\)
\(\in ( 0 , 1 )\) is a measure of the degree of substitutability between the firms’ products: As \(\gamma\) the degree of differentiation among the firms’ products increases, while as \(\gamma\) the firms’ products become more close substitutes. Inverting (2) we subsequently obtain product demand for each firm i, as a function of its own and its rival (j) firm’s price: Hence, alternatively if we consider (own) quantity or (own) price to be the firm i’s choice variable, the profit maximand of each firm can respectively be expressed as in (4) and (5) below: The sectoral labour market is unionized, and union structure as well as collective bargaining is decentralized to the firm level. If we assume utilitarian behavior on the part of the unions, with both of them endowed with risk-neutral members, the union i’s maxim and is given by the following variant of Oswald’s (1982) familiar rent formula: where w
0 stands for the exogenous reservation wage. The latter is typically considered to be a weighted average of the unemployment benefit and the wage (obtained by any union member) outside the reference sector. In the above context our postulated sequence of events is as follows: At stage one, firms and unions, simultaneously and independently in each firm/union pair i ≠ j = 1, 2, collectively decide about the agenda (scope) of negotiations. An agreement with respect to efficient bargains can be reached whenever both the firm and the union would raise no veto against the pair’s unilateral switch from the right-to-manage bargaining (R) agenda to the efficient bargains (E) agenda.Footnote 4
 At stage two, given that the pair i’s bargaining agenda is also observable by the rival pair j, firm-union collective negotiations about only wages (R), or about both wages and employment (E), are simultaneously and independently conducted in each firm/union pair. At stage three, and given the mode of competition in the product market, if the R agenda is everywhere sustained then the firms i ≠ j = 1, 2, simultaneously and independently adjust their own quantities, or their own prices.Footnote 5 Otherwise, if the E agenda has been chosen by one, or by both, firm/union pair(s), then: In the first instance, the firm conducting right-to-manage bargaining unilaterally adjusts its own quantity (or its own price) at stage three, whilst the rival firm/union pair, by conducting efficient bargains, has already collectively chosen the firm’s own quantity (or price) at stage two. In the second instance, wages and quantities (or prices), in any firm/union pair, are via efficient bargaining chosen at stage two. Hence, stage three is meaningless.Footnote 6
",1
49.0,2.0,Review of Industrial Organization,29 April 2016,https://link.springer.com/article/10.1007/s11151-016-9521-4,The Staggers Act at 35: Railroad Economics and Regulation,September 2016,Richard L. Schmalensee,Wesley W. Wilson,,Male,Male,Unknown,Male,,
49.0,2.0,Review of Industrial Organization,08 April 2016,https://link.springer.com/article/10.1007/s11151-016-9515-2,Modernizing U.S. Freight Rail Regulation,September 2016,Richard L. Schmalensee,Wesley W. Wilson,,Male,Male,Unknown,Male,"The U.S. railroad industry has been federally regulated since the passage of the Interstate Commerce Act of 1887 (ICA).Footnote 1 Provisions of the ICA and its amendments over the next 60 years were designed to encourage agreements among railroads to stabilize prices. Part of the policy was to limit the ability of railroads to enter or exit markets by requiring regulatory approval based on “public convenience and necessity”. With the rise of truck competition and the growing importance of products that could be moved efficiently by trucks, railroads’ traffic levels eroded, and they were left with large networks with many low density lines. The regulatory system’s pricing and routing restrictions hampered competitive responses.Footnote 2 By the mid-1970s, the industry was in financial ruin. There had been multiple bankruptcies, and the major Eastern railroads had been effectively nationalized in 1976 with the creation of CONRAIL, which required substantial federal subsidies.Footnote 3 Nationwide, railroad facilities and service had significantly deteriorated. In hopes of restoring the freight rail system to financial and operational health without nationalization and federal subsidies, Congress passed three major pieces of legislation: the Regional Rail Reorganization Act of 1973 (the 3-R Act); the Railroad Revitalization and Regulatory Reform Act of 1976 (the 4-R Act); and the Staggers Rail Act of 1980. The stated goals of the Staggers Act were to (49 USC 10101a): assist the railroads of the Nation in rehabilitating the rail system in order to meet the demands of interstate commerce and the national defense; reform Federal regulatory policy so as to preserve a safe, adequate, economical, efficient, and financially stable rail system; assist the rail system to remain viable in the private sector of the economy; provide a regulatory process that balances the needs of carriers, shippers, and the public; and assist in the rehabilitation and financing of the rail system. Staggers substantially modified railroad regulation by placing greater reliance on the market to yield reasonable rates, and accordingly reducing regulatory control of entry and exit and other decisions, while providing shippers protection against unreasonable rates when competition was not present. As is discussed in the next section, this legislation has enabled dramatic changes in the railroad industry.Footnote 4
 In 2005, Congress called on the Transportation Research Board of the National Academy of Sciences to conduct a study to examine and make recommendations onFootnote 5: The performance of the nation’s major railroads regarding service levels, service quality, and rates; The projected demand for freight transportation over the next two decades and the constraints limiting the railroads’ ability to meet that demand; The effectiveness of public policy in balancing the need for railroads to earn adequate returns with those of shippers for reasonable rates and adequate service; and The future role of the Surface Transportation Board in regulating railroad rates, service levels, and the railroads’ common carrier obligations, particularly as railroads may become revenue adequate. Funds for the study were appropriated in 2012; the study, in which the authors participated,Footnote 6 began in 2013; and the Study Committee released its report (TRB 2015) in June 2015. The Study Committee’s fundamental conclusion was that while the regulatory system developed under Staggers was a sensible response to the problems of freight rail in 1980, it is no longer a good fit for today’s very different industry. As we discuss below, the Committee offered a number of recommendations for modernizing freight rail regulation. In the next section, we provide a brief summary of the post-Staggers evolution of the freight rail industry. Section III describes the current system of rate regulation and summarizes the study’s recommendations for changing that system. Section IV deals with the modernization of policy with respect to monitoring revenue adequacy, evaluating mergers, and collecting and disseminating data, and Section V offers some conclusions.",3
49.0,2.0,Review of Industrial Organization,03 May 2016,https://link.springer.com/article/10.1007/s11151-016-9522-3,The Staggers Act and Firm Performance: Long-Run Evidence,September 2016,Lee Pinkowitz,Rohan Williamson,,,Male,Unknown,Mix,,
49.0,2.0,Review of Industrial Organization,03 June 2016,https://link.springer.com/article/10.1007/s11151-016-9524-1,Regulation in a ‘Deregulated’ Industry: Railroads in the Post-Staggers Era,September 2016,John W. Mayo,David E. M. Sappington,,Male,Male,Unknown,Male,"The rail industry was in dire economic straits prior to the passage of the Staggers Rail Act of 1980.Footnote 1 Industry output, productivity, and investment were all relatively low, and rail carriers were suffering substantial financial losses. The losses arose despite the prevalence of extensive regulatory policy that was designed in part to promote carrier solvency.Footnote 2 In light of the limited success of nearly ubiquitous regulatory oversight, the Staggers Act took a different approach to enhancing industry performance. The Act afforded rail carriers expanded freedom to introduce new services and set reasonable prices for their services. For this reason, the Act is often referred to as “The Railroad Deregulation Act.”Footnote 3
 The Staggers Act is widely regarded as a major triumph of deregulation. Numerous scholars have documented the many dimensions on which industry performance improved after the Act was enacted.Footnote 4 Industry output, productivity, investment, quality, and earnings all increased, while prices declined.Footnote 5
 Although the Staggers Act brought substantial deregulation to the rail industry, it did not eliminate regulatory oversight entirely. The legislation retained a variety of regulatory controls that were to be applied in settings where competition alone was judged incapable of imposing the requisite discipline on rates that are set by railroads. The Staggers Act also did not eliminate the mandate in the Railroad Revitalization and Regulatory Reform Act of 1976 to ensure that rail revenues are “adequate.”Footnote 6 The precise meaning of this mandate is subject to considerable debate. However, if the mandate is interpreted to preclude railroads from earning revenues in excess of the level that isrequired to attract capital to the industry (as opposed to ensuring that revenues attain at least this level),Footnote 7 then the mandate introduces the prospect of explicit earnings regulation in the rail industry as industry revenues approach and exceed “adequate” levels. The economic literature provides many useful insights with regard to the effects of earnings regulation, both when it is applied to all services supplied by a regulated firm and when it is applied to only a portion of the firm’s services. The literature also provides useful guidance with regard the use of cost allocation procedures in an attempt to measure the earnings that are derived from the provision of specific services. A primary purpose of this paper is to review the key findings in the literature and assess their implications for regulation in the rail industry. A primary conclusion that we reach is that explicit earnings regulation is likely to stifle innovation and limit economic efficiency in the rail industry. Thus, such regulation could reverse some of the well-documented successes that have arisen in the post-Staggers era freight rail industry. Section 2 describes the pricing constraints that have been imposed in the rail industry since the passage of the Staggers Act, in the absence of explicit revenue adequacy regulation.Footnote 8 The discussion in Sect. 2 emphasizes the fact that only a portion of the rates that a rail carrier sets are subject to regulatory oversight. Section 3 reviews the key conclusions that are drawn in two related strands of the literature on regulatory economics: the literature that analyzes the partial regulation of multiproduct firms, and the literature that assesses the merits and effects of earnings regulation. Section 4 develops a stylized framework for assessing the economic implications of the introduction of explicit earnings regulation. Although this simple framework does not capture all of the relevant impacts of such regulation, the framework allows us to analyze several potentially worrying manifestations of the regulation, including reduced incentive for industry innovation. Section 5 discusses the implications of our analysis and identifies important questions that remain to be addressed.",6
49.0,2.0,Review of Industrial Organization,03 May 2016,https://link.springer.com/article/10.1007/s11151-016-9523-2,Freight Rail Costing and Regulation: The Uniform Rail Costing System,September 2016,Wesley W. Wilson,Frank A. Wolak,,Male,Male,Unknown,Male,"The declining financial health of railroads in the post-World War II period and several high-profile railroad failures in the 1970s led to a series of legislative efforts that were intended to allow railroads to achieve revenue adequacy. These reforms culminated with the passage of the Staggers Rail Act of 1980.Footnote 1 The major changes implemented are: (1) greater pricing flexibility for railroads; (2) the ability to sign confidential negotiated contracts between railroads and shippers; and (3) reduced impediments to mergers and track abandonments.Footnote 2 Because of the financial condition of the industry at the time, these reforms also require an annual determination of whether each railroad is “revenue adequate”: whether it has achieved a rate of return that is sufficient to attract the capital that is necessary for its long-term financial viability. Under Staggers, a railroad can set the rate for a shipment at any level. Once issued, a rate can be challenged only if it exceeds a legislatively defined value and the railroad is found to lack effective competition in the market for this shipment, which is defined in the law as the railroad having “market dominance”. A rate that is eligible for challenge could still ultimately be judged legal, or “reasonable,” by regulators if the railroad was not found to be market dominant. Only when the legislative rate threshold is violated and the railroad is found to be market dominant is the rate subject to regulation. Staggers also provides a blanket exemption on rate regulation for shippers that negotiate private contractual terms with the railroad providing service. Because these rates are the result of a presumably voluntary negotiation, they cannot be challenged. Many commodities are exempt from rate challenges because they can be competitively moved by truck. Staggers also relaxed the standards for allowing railroad mergers and streamlined procedures for selling and abandoning rail lines. The impact of these changes on the industry has been dramatic, with significant reductions in operating costs and rail rates, the removal of uneconomic capacity, the introduction of many new services, and greater industry consolidation.Footnote 3 Overall, these changes have resulted in a substantial improvement in the financial health of the freight rail sector, which is consistent with the goals of the Staggers Act. However, the small number of rate cases (fewer than 50 through 2015) that have been filed at the Surface Transportation Board (STB) since this industry regulatory body was established in 1996 has caused some industry observers to question whether the rate relief provisions of the Staggers Act have been working in a manner that is consistent with the law’s dual goals of allowing railroads to achieve revenue adequacy and also protecting shippers from excessive rates. The rate relief process—which was put in place by the Interstate Commerce Commission (ICC) and continued by the STB—has come under regular criticism for its lack of transparency, inconsistency with economic theory, high cost of access, and inappropriateness for some shippers: particularly those with small shipment volumes and small rate-relief claims. The STB’s Uniform Rail Costing System (URCS) is a crucial input to this rate-relief process. It is used to screen rates for eligibility to be challenged. Staggers requires the rate to exceed 180 % of a shipment’s URCS “variable cost” in order to establish eligibility. URCS is also used in STB proceedings to assess the reasonableness of the challenged rate if market dominance is found, and in some cases, even to set the value of the regulated rate.Footnote 4 Because of its central role in the STB rate relief process, URCS should provide an economically meaningful measure of shipment-level costs on which a profit-maximizing railroad would base its pricing and operating decisions. Otherwise, which shipments receive rate relief and the level that is set for a reasonable rate may simply be the result of an arbitrary cost allocation process, which would imply an arbitrary process for receiving rate relief. The purpose of this paper is to provide an assessment of the validity of using URCS in the STB’s rate relief process. We first review the STB’s regulatory mandate under the Staggers Act, emphasizing the critical role played by URCS. We then describe the details of the URCS methodology in order to demonstrate that it is an administrative cost-allocation procedure that is used to assign fractions of accounting cost categories to specific shipments. Any change in these cost allocation rules that are used to compute the URCS “variable cost” of a shipment changes the value of this measure, which would affect the shipment-level revenue-to-variable-cost ratio (R/VC) and, therefore, change which rail shipments violate the STB’s initial market dominance screen. We then assess whether the URCS “variable cost” of a shipment provides an economically meaningful measure of the increase in the railroad’s costs that are caused by providing that shipment. To accomplish this, we introduce the economic theory of costing in multiproduct industries to demonstrate how cost concepts that affect the pricing and operating decisions of a profit-maximizing railroad are determined. This discussion demonstrates that the URCS “variable cost” can differ significantly and unpredictably from the incremental cost of a shipment or the marginal cost of moving one more ton of the good that is being shipped. These two cost concepts are relevant to the pricing and operating decision of a profit-maximizing railroad. We also demonstrate that even if the STB knew a railroad’s shipment-level multiproduct cost function and was able to compute an accurate measure of the incremental cost of a shipment or the marginal cost of shipping an additional ton, this information would be of limited use in determining the reasonableness of the rate that is charged for a shipment. Railroads provide many shipments using the same rail line, yards, and even the same train. This implies the existence of significant economies of scope and scale in the provision of rail services. The presence of substantial joint and common costsFootnote 5 that give rise to these economies of scope and scale requires the railroad to price some traffic above its incremental cost or marginal cost of an additional ton shipped in order to achieve sufficient firm-wide revenues to recover total production costs. Consequently, even complete knowledge of the railroad’s multiproduct cost function would still leave the regulator with the challenging task of setting the maximum allowable markup over the marginal cost of the additional ton that is shipped for each product. Accordingly, the problem of determining an excessive price for a shipment is isomorphic to the problem of determining an excessive mark-up over the marginal cost of a shipment. For all of these reasons, we argue that the URCS methodology should be abandoned and that an alternative approach to protecting captive shippers from excessive rates should be developed in the post-Staggers Act regime where a significant fraction of shipments is exempt from rate relief and many shipments move under confidential negotiated rates. We recommend an approach that builds on the price benchmark concept that was proposed in the recent National Academies of Sciences/Transportation Research Board Report (2015). The remainder of the paper proceeds as follows: The next section describes the current STB methodology for fulfilling its Staggers Act regulatory mandate. Section 3 presents our analysis of the validity of the URCS methodology for computing the “variable cost” of a shipment. Shipment cost concepts that are based on the economic theory of multiproduct production are then derived and contrasted with the URCS “variable cost” of a shipment. This section also describes how shipment-level cost concepts that are grounded in economic theory are used by profit-maximizing railroads to set shipment prices and make operating decisions. Section 4 presents empirical evidence that demonstrates that the URCS “variable cost” of a shipment fails several tests of its appropriateness for use in setting shipment prices and making rail operating decisions. Section 5 demonstrates that even the best possible economic model for how railroad costs are incurred would be of limited use in determining a reasonable regulated shipment price without detailed knowledge of the demand functions that the railroad faces for all rail services. Section 6 describes what cost information should be collected by the STB to meet its Staggers Act regulatory mandate in an industry with a significant fraction of shipments that are exempt from the rate relief process. The final section of the paper summarizes our findings that the URCS methodology does not yield an economically valid measure of the cost of a shipment and concludes that its use should be abandoned in the rate relief process.",7
49.0,2.0,Review of Industrial Organization,28 April 2016,https://link.springer.com/article/10.1007/s11151-016-9519-y,"Understanding Railroad Investment Behaviors, Regulatory Processes, and Related Implications for Efficient Industry Oversight",September 2016,Mark Burton,Charles Sims,,Male,Male,Unknown,Male,"When market conditions support traditional competition, economic policies needn’t tend to the matter of investment. However, when achieving acceptable economic outcomes requires active public sector involvement, policies must sometimes be designed to monitor and even influence the investments (or disinvestments) that underlie targeted product service delivery, prices, and quantity results. Within this context, the policy reforms that were adopted for the railroad industry 35 years ago to revitalize and oversee the nation’s freight railroads sought to assure ongoing, adequate rail industry investment in both infrastructure and equipment.Footnote 1
 In practice, current rail industry investment oversight by the Surface Transportation Board (STB) is confined to establishing the ability to invest in freight transportation capacity. The specific nature and scale of capital improvements are no longer routinely considered.Footnote 2 Investment ability is measured by what is referred to as “revenue adequacy”; and this adequacy, in turn, is judged through a comparison of railroad returns on investment to regulators’ estimate of the corresponding industry cost of capital.Footnote 3 If railroads’ returns are greater than the current industry cost of capital, the outcome is viewed as revenue adequate. This criterion is applied loosely to both individual carriers and to the railroad industry as a whole. Originally, revenue adequacy was introduced as a simple benchmark measure of rail industry well-being. However, the importance of this determination has been amplified by the steadily increasing role that it plays as a practical threshold in rail rate oversight.Footnote 4 So long as this is the case, a correct assessment of revenue adequacy and, in particular, a correct evaluation of the cost of railroad capital are critical elements in the broader regulatory process. It is this criticality and possible opportunities to improve the assessment of revenue adequacy that motivate our work. As directed by Congress, the Surface Transportation Board (STB) oversees the annual calculation of an industry-cost-of-railroad capital estimate.Footnote 5 The current STB measure blends the cost of debt financing and the cost of financing capital through equity (based on their relative use) and is, therefore, dominated by the equity cost of capital.Footnote 6 In turn, the equity cost of railroad capital is estimated as the equally weighted average of results derived through a Capital Asset Pricing Model (CAPM) application and the manipulation of a multi-stage Discounted Cash Flow (DCF) model.Footnote 7
 The STB construct is intended to account for the full range of opportunity costs that are associated with investments in railroad capital. However, the characteristics of many rail industry investments, combined with the particular ways in which the STB methods are applied, suggests that the current process may not fully meet this goal. Specifically, it appears that the STB methods do not adequately account for the influence of sunk costs, which may: (1) lead to the systematic underestimate of railroad industry cost of capital; or (2) call into question the simple comparison between the return on investment and the cost of capital. Roughly 15 years ago, within a regulatory rate proceeding, Hausman and Myers (2002) demonstrated that the uncertainty surrounding revenue forecasts, combined with the sunk nature of many railroad capital costs can create a setting where regulatory processes underestimate the cost of railroad capital. The sunk nature of these investments creates an additional opportunity cost of immediate investment. As a remedy, they suggested a real-options approach to asses cost of capital that provides a more realistic estimate of these costs than can be obtained under simpler net present value calculations. The Hausman-Myers application focused on the use of a real-options methodology to estimate the firm-level capital component of stand-alone cost (SAC) within an individual rate case.Footnote 8
 Here, we contend that the same implications of sunk cost that were noted by Hausman and Myers continue to affect railroads’ ongoing investment decisions and that, perhaps, these factors also influence revenue adequacy determinations. As Hausman and Myers (2002) note on page 293, “Indeed, economic analysis of irreversible investment under uncertainty demonstrates that a given project typically must offer expected returns well above ‘breakeven’, including the cost of capital, before the project is undertaken because of the sunk and irreversible investments.” This suggests that in order to assess revenue adequacy following current STB practice, rail industry cost of capital must account for the influence of relatively large sunk costs, and we believe they do not do so. Alternatively, STB’s revenue adequacy determinations should acknowledge that returns in excess of the cost of capital do not necessarily signal revenue that is adequate to make capital improvements. Accordingly, we conclude that there is, at least, the potential to improve ongoing revenue adequacy assessments by accounting for sunk costs in rail industry investments. The scenario we outline contains a variety of elements that must be carefully explored if our conclusions are to be judged as valid. Accordingly, we proceed as follows: Sect. 2 offers a brief sketch of rail industry capital, with particular attention to the issue of sunk costs and their implications for necessary returns on investment. In Sect. 3, we first describe and then evaluate the cost-of-capital calculations and revenue-adequacy determination under current STB practice to see if, where, and to what extent the influence of sunk costs are (or should be) reflected in these methods. Next, in Sect. 4, we provide a basic exposition of the real-options approach to investment decisions, centered on firm-level railroad examples. In doing so, we illustrate why sunk costs should (and probably do) matter to railroads’ investment decision-making and why these costs may affect the compensation that is demanded by those who fund those investments. Finally, Sect. 5 explores how the resulting real-options-based differences in revenue adequacy evaluations might influence future railroad policy.",2
49.0,2.0,Review of Industrial Organization,26 April 2016,https://link.springer.com/article/10.1007/s11151-016-9517-0,This Time is Different (?): Telecommunications Unbundling and Lessons for Railroad Regulation,September 2016,T. Randolph Beard,Jeffrey Thomas Macher,Chris Vickers,Unknown,Male,,Mix,,
49.0,2.0,Review of Industrial Organization,01 June 2016,https://link.springer.com/article/10.1007/s11151-016-9527-y,Open Access to Infrastructure Networks: The Experience of Railroads,September 2016,José A. Gómez-Ibáñez,,,Male,Unknown,Unknown,Male,"In the last three decades many countries have restructured their network industries—including railroads, telecommunications, electricity, and gas—to require that network providers give access to independent companies that seek to use their networks. The basic idea is that only some of the activities of these industries are inherent or natural monopolies, and that one can introduce more competition into those industries by opening access to the monopoly elements to newcomers. Usually the monopoly is thought to reside mainly in the infrastructure network that connects the customers but not in the services that are provided or carried over that network. In electricity, for example, the wires of the local distribution networks are often thought to be a natural monopoly, while power generation is not. Similarly in railroads the track is thought to have the characteristics of a natural monopoly, while the trains that operate over them largely do not. This paper reviews the experiences with open access in railroads in Australia, Europe, and North America to argue that the benefits in increased competition are often offset by costs in reduced coordination between the access providers and the access users. A simple analytic model suggests that it takes only a modest increase in coordination costs to offset the benefits of even fairly significant increases in competition. The published empirical estimates of coordination costs vary considerably, but the railroad case studies suggest several factors that are likely to determine them. In particular, coordination costs are likely to be high when the interface between the access provider and the access users is intimate and technically complex, the network is close to capacity or needs investment, the access users differ in the network services that they desire, there is little reciprocity between providers and users, and the access grants are broad rather than selective. Open access comes in a variety of forms, but at a minimum it requires that the incumbent network provider allow independent companies to use its network. The independent companies must pay the network provider access charges and meet various technical standards, and certain types of services or facilities may be off limits. But key parts of the network are available to provide significant services. Some advocates of open access believe that it is also important to prohibit the incumbent network provider from continuing to offer a full range of services in competition with the access seekers. In the case of railroads, the incumbent would still be responsible for providing track and perhaps stations, yards, and other hard-to-duplicate facilities but would not continue to provide train services in competition with independent train companies. Instead the incumbent would be required to divest its train operations as a separate company or reorganize them as a separate ring-fenced subsidiary. The purpose of such divestiture or ring-fencing is to make it harder and less financially rewarding for the managers of the monopoly network provider to favor their old colleagues in the newly divested or ring-fenced train company. Such divestitures or ring fencing are often referred to as “vertical separation” or “vertical unbundling.” A reform that is related to open access involves the tendering of franchises to provide specified services over a network for a period of time. The idea, developed by Demsetz (1968), is that if the presence of natural monopoly makes competition within a market impractical then one can introduce competition for the market by periodically tendering franchises of limited duration. Sometimes the franchise is vertically integrated (with the winner responsible for both the services and the associated infrastructure); but often it is vertically separated (for the services only, with the franchising authority or a separate firm responsible for the infrastructure). Access is open in the sense that any qualified firm can bid to provide the services, but greatly limited in that the scope of the services is typically set by the franchising authority and can’t be changed once the franchise is awarded. Finally another form of open access involves reciprocal exchanges between two or more infrastructure providers. The participating firms are vertically integrated in that they are both access providers and users. Usually these exchanges of access are highly selective and sometimes voluntary. In the case of railroads, for example, two firms may agree to share track in a congested urban area or corridor. Similarly in telecommunications, competing cell phone operators may agree to share towers. From a public policy perspective open access can be seen as a tradeoff between the benefits of increased competition among those seeking to use the network and the costs of reduced coordination between those access users and the access provider. Increased competition will make it harder for the access seekers to charge prices well above their costs. But quality services require the coordination of the operations and the investments of the access users and the provider, if only to make sure that their equipment is compatible and that capacity is available when and where the users need it. The fact that the access user and provider functions have traditionally been integrated in the same firm strongly suggests that coordination between these two functions is much easier when they are provided by one firm, reporting to the same CEO and stockholders, than if they are provided by two independent firms (Coase 1937; Williamson 1975). The costs of lost coordination take three principal forms: The first is the loss in economies of scale, traffic density, or distance from having multiple access users rather than one. These are presumably small because the economies of scale or density are thought to reside primarily with the network infrastructure rather than with the services that are provided over it. The second is the transaction costs of researching, drafting, negotiating, monitoring, and enforcing the system of rights and contracts that are needed to attempt to align the incentives of the now separate access-providing and using firms. These transaction costs can be especially high when durable, relationship-specific investments are required of either the access provider or users. The last, and potentially most important, is the residual inefficiencies that remain because the contracts are not completely successful. In many cases it may be simply impossible to devise and implement a set of rights and contracts that ensure that the network provider and users adopt the whole-system perspective of a single integrated firm. The benefits of added competition take two forms: The first is to reduce the ability of access seekers to charge their customers prices in excess of their costs, while the second is to encourage access seekers to reduce their costs. To examine the competition–coordination tradeoff in railroads, the remainder of this paper is divided into six parts: The first part presents a simple analytic model of the competition–coordination tradeoff and its implications. This is followed by a very brief review of the published empirical estimates of competition benefits and coordination costs. The next three parts examine the lessons about coordination costs from railroads in Australia, Europe and North America. The final part summarizes the lessons about whether coordination costs are likely to offset competition benefits. The case studies are particularly suggestive because Australia, Europe, and North America have pursued different policies. Australia and Europe have required their railroads to open access for many different types of freight and passenger train services, and have encouraged track providers to spin off train operations as separate companies or ring-fenced subsidiaries. In the United States and Canada, by contrast, the freight railroads remain largely vertically integrated in that each railroad operates most of the trains that travel over its tracks. Only roughly 20 % of the track is open to another railroad, and much of that is the result of voluntary exchanges of access between railroads rather than government compulsion (Association of American Railroads 2006, pp. 16, 60–61; Gómez-Ibáñez 2009b, p. 8).",4
49.0,2.0,Review of Industrial Organization,23 April 2016,https://link.springer.com/article/10.1007/s11151-016-9518-z,Three Principles for Optimal Pricing of Trackage Rights,September 2016,Kenneth D. Boyer,,,Male,Unknown,Unknown,Male,"In order to develop the theory of optimal track charges, it will be useful to begin with an equilibrium model of freight flows over a network (see, for example, Yang and Huang 2005). To make the problem tractable, it will be useful to assume that there is a single commodity that is produced at M locations that are indexed by m, and is moved to N locations that are indexed by n. The track network provides multiple paths between each origin and destination, with the use of sequences of track segments. Assume that there are J paths in a complete enumeration of paths from origin m to destination n. Paths may have varying numbers of track segments. Let i index the segment number within path j. Movement of the single commodity from origins to destinations is done using carriers. It is assumed that a large number of carriers exist. In order to simplify the calculation of full costs on each path, these carriers will be assumed to be “merchants” that take ownership of goods at the origin and sell them at the destination where they are unloaded. Carriers can be private: The carrier may be the same as the producer in each origin or can be the same as a receiver in the destination, acting on its own account. The simplification of carriers’ being merchants will allow user costs of transportation to be combined with carrier costs. While the term “carrier cost” is used in the exposition below, the term should be considered to include inventory carrying costs and similar items that vary with the time it takes to get from an origin to a destination. Carrier costs are the equivalent to what the road literature calls the full cost of driving in which the un-priced costs of resources that are used in driving are added to expenditures.Footnote 4
 Carriers are assumed to be profit maximizers with revenue that is derived from the margin between the purchase price at the origin where the good is picked up and the sales price at the destination where it is delivered. Carrier costs per unit of traffic are assumed to be a linear function of the time between pickup and delivery. Costs are thus computed as the rental rate on equipment (in this single commodity problem, no backhauls are assumed), plus the wage rate of operators, plus fuel costs that are also assumed to be a linear function of time. A carrier also needs to pay a fee for each track segment that is used for the path that it chooses. Thus a carrier that chooses path j would have total cost per traffic unit equal to: where p is the carrier’s cost per unit of time (including the time value of the commodity carried,) ti is the time it takes to traverse track segment i, and Ri is the charge for using track segment i. A profit-maximizing carrier will choose a route between m and n that minimizes the cost per unit of transportation. Since track charges affect route choice and different routes have different costs, track charges affect the real resources that are used in transportation. This paper is focused on finding optimal values for Ri for each of the track segments. Optimal values are those that maximize social welfare: subject to: The problem in Eqs. (2), (3), and (4) is to maximize the combined willingness to pay for the good at all destinations (the sum of p(q) functions) less the combined variable cost of production at each origin (the sum of s(q) functions) and the variable cost of transportation. The full price for any route chosen must also follow Wardrop’s law, according to which all of the paths that are actively used to connect m and n will have the same full price per unit of transportation.Footnote 5
 Let W be a measure of the capacity of a track segment. W can be thought of as the width of the railroad line, to invoke the idea that segments that have multiple tracks have diminished difficulties with congestion than single track lines.Footnote 6 Segment capacity can be varied by considerably more measures than just adding a second parallel track. Single track lines can increase their capacity by increasing the number and length of passing sidings, for example. Tracks can be banked to achieve higher speeds. Signaling and various methods of train control can also be used to increase capacity without constructing a full second track. Similarly, track capacity can be degraded by allowing tracks to become unlevel, requiring slow orders to prevent derailments. All of these affect the value of W. Following the tradition of road pricing, W is treated as a continuous variable. The time to traverse a track segment i is modeled as: where 
Q

i
 is the sum of all freight flows—regardless of origin or destination—that use track segment i. Equation (6) assumes that the speed of traffic depends on the amount of traffic in relation to the capacity of the track. I assume that travel time falls with track capacity and rises with Qi, beyond some critical Q

i
/W

i
 ratio. A profit-maximizing carrier must monitor traffic conditions on each link to ensure that the cost minimizing route is chosen and to make sure that the cost of transportation does not exceed the margin between the purchase price of the commodity and the price for which it can be sold at the destination. Track charges affect social welfare because they help to determine which routes are used and also affect the amount of freight that is carried. Track charges, while they do not enter the social welfare maximand, help to ration the traffic on each track segment. In particular, if a track charge is too high, it might cause a carrier to choose an unnecessarily circuitous route, thus increasing real expenditures within the transportation system. If track charges are too low, it may cause traffic to be uneconomically attracted to a route or cause origins to be supplied from uneconomic locations or origins shipping to uneconomic destinations, thus creating excessive congestion, and again causing more real resources to be expended than is necessary in completing flows from the origin to destination. The total time-related-costs of all of the carriers that use track segment i is given by: The marginal cost of accommodating one more unit of traffic on link i is found by differentiating Eq. (8) with respect to Qi. The traditional view of traffic flows on a link within a transportation network is shown in Fig. 1. When there is free-flowing traffic, represented by the region of flat MC and AVC lines in Fig. 1, additional traffic can be accommodated without slowing any other traffic that might be present. But beyond the critical value, the derivative \(\partial c_{i} /\partial Q_{i}\) becomes positive, as a result of the slowing of flows as traffic levels begin to approach capacity levels. This additional cost of transportation is the familiar congestion toll of road pricing and is represented as the second term of Eq. (9). A congestion toll is simply a measure of the additional cost that is due to traffic-slowing that is imposed on the totality of traffic by the decision to increase the level of traffic by one unit. Efficiency conditions under constant returns to scale at the track segment level If there is a single carrier on the track segment, it is reasonable to expect that the costs of traffic-slowing are taken into account when making dispatch decisions. But if there are multiple carriers on a track segment, this slowing is imposed on other carriers and is not taken into account by a profit-maximizing carrier in making its route choice and in deciding on levels of traffic to take from origins to destinations. Track owners have other costs that have not been taken into account by the discussion so far. One of these is maintenance costs, E

i
, that vary proportionately with the level of traffic. I assume that Maintenance costs that vary with traffic level are assumed to be directly passed through to carriers in the form of a track fee.Footnote 7 There are also annual maintenance costs that do not vary with traffic levels, called “weather” costs here and represented as Hi; there are also costs representing the opportunity cost of land, Ai, and there are amortization costs of track and structures, Si. Both Ai and Si are assumed to be proportional to track capacity and are determined by the value of land, track, and structure multiplied by the rental rate on capital. These other costs of owning tracks are not directly passed through to the carriers in the form of track fees, but instead are paid for by the proceeds of congestion tolls. It is clearly appropriate for each carrier to compensate the track owner for the increased track maintenance on a track segment that is used in delivering freight from an origin to a destination in order to internalize the costs of the routing decisions. However, it is also socially welfare maximizing for the track owner to add to directly attributable maintenance costs a charge that is equal to the optimal congestion tolls: the monetized value of slowing that is imposed on existing flows due to the arrival of one more unit of freight (see, for example, Vickrey 1969). Congestion tolls give signals to the carriers to choose alternative routes that are less crowded but perhaps more circuitous. In so doing, congestion tolls minimize the aggregate cost of transportation and increase social surplus. Congestion tolls have long been paradoxical since they are not a compensation for changes in the level of seller costs that are occasioned by the decision of the carrier to use a piece of infrastructure. They are collected by a party that is not harmed by the decision-maker whose behavior is non-optimal. It is other carriers on the track segment that are slowed by the routing decision, but it is the track owner that collects the payment. But in fact, it is the lack of capacity that causes carriers to slow one another, and the decision of how much capacity to put in place can be affected by the congestion tolls that are collected by the track owner, as outlined in the next section of this paper. Congestion tolls, like effluent taxes and all Pigovian charges, are not motivated by principles of fair compensation, but rather are justified as tools for inducing agents to make efficient decisions. Under some situations, efficiency-inducing charges can be reconciled with what appears to be fair compensation. Figure 1 shows the costs of a track segment that is optimally sized for the demand. Figure 1, like all figures in this paper, is measured in full costs, including all of the time costs of carriers. Full costs combine costs borne by the track authority and those of carriers. The short-run average variable cost curve represents the directly attributable maintenance costs that a track owner needs to undertake due to track usage, as well as the time rental cost for locomotives and equipment and the inventory carrying costs of freight that is handled by the carriers. The flat segment represents the region of free-flowing traffic, where there are so few trains relative to the capacity of the line that they do not get in each other’s way. The marginal cost and average variable cost curves diverge, however, when traffic gets to the level where the arrival of one more train slows the average time of passage of other trains. The short-run average variable cost represents the full price that is seen by the carrier (on the assumption that traffic-based maintenance costs are charged to the carrier) for its traffic, while the short run marginal cost curve also includes the classic slowing that each train imposes on others that use the track. In Fig. 1, the optimal congestion toll is P0–P1: the amount that each carrier needs to be charged to internalize the traffic-slowing that is imposed on others that use the same piece of infrastructure. Figure 1 shows a long-run equilibrium because when the toll is added to the costs that are seen by the carrier, P1, the track capacity is exactly correctly sized for the resulting demand, Q*, as shown by the fact that the short-run average total cost is at a minimum for traffic level Q*. A failure to charge the optimal congestion toll leads to over-use of the track segment—up to the point where SAVC crosses Demand—since the full marginal cost of carriage is above the full price that is paid for using the track. Over-use of highways when congestion tolls are not charged are experienced as traffic jams, and similar non-optimalities can be anticipated in track usage if optimal congestion tolls are not charged on tracks that are used by multiple carriers.",2
49.0,2.0,Review of Industrial Organization,10 May 2016,https://link.springer.com/article/10.1007/s11151-016-9525-0,The Regulatory Determinants of Railroad Safety,September 2016,Jerry Ellig,Patrick A. McLaughlin,,Male,Male,Unknown,Male,"Railroad safety in the United States has improved dramatically since the 1970s. The total number of accidents on the seven current Class I U.S. railroads and their predecessors fell from more than 11,000 in 1978 to 1867 in 2013–despite the fact that revenue ton-miles doubled. The number of injuries declined even more sharply: from 1486 in 1978 to 166 in 2013.Footnote 1 These improvements have coincided with two significant regulatory changes. First, the quantity of safety regulation imposed by the Federal Railroad Administration (FRA) quadrupled.Footnote 2 Second, the government removed most economic regulation of railroads in the Staggers Rail Act of 1980. These policy changes created a significant debate over whether the improvement in safety was caused by safety regulation, partial economic deregulation, or both. The Staggers Act deregulated most rail rates, made it easier for railroads to abandon unprofitable lines, and established time limits for regulators to decide whether to approve mergers. It also retained some rate regulation for shippers who lacked competitive alternatives to a single railroad. Railroads argue that improved financial health caused by partial deregulation allowed them to invest in maintenance, which improved safety (Hamberger 2015, p. 15). Regulators argue that railroads’ improved financial health gave them the resources to comply with regulations (Savage 1998, pp. 151–152). “Since these changes occurred at roughly the same time, it is difficult to determine whether increased safety regulation or the improved financial health of railroads was primarily responsible for the improvements in safety observed after the Staggers Act” (Bier et al. 2001). Track maintenance illustrates the conundrum of disentangling the effects of contemporaneous policy changes. Savage (1998, p. 152) contends, “Since the early 1980s, track capital expenditures and government inspections have tracked each other closely, making any econometric untangling of their relative contribution to the decline in accident rates difficult.” Perhaps responding to this challenge, Dennis (2002) estimated a production function for railroad safety that included both investment and regulatory activity. He found that the track-related accident rate is correlated with investment but not with federal inspection activity or railroad compliance with federal track standards. Safety regulation, however, could have motivated some of the track-related maintenance investment. We shed new light on the “safety regulation vs. economic deregulation” debate by utilizing a new database that measures separately the amounts of safety regulation and economic regulation that applied to railroads each year from 1975 to 2013. The database, RegData, counts the number of restrictions (words such as “must,” “shall,” etc.) in each chapter of the Code of Federal Regulations (CFR) and produces an index that measures the amount of regulation that applies to each 3-digit industry in the North American Industrial Classification System (NAICS) (Al-Ubaydli and McLaughlin 2015). Thus, RegData allows us to assess whether a discrete change in the amount of safety or economic regulation applied to railroads is correlated with the level of railroad safety. We can also determine whether the size, significance, or direction of this correlation changed following partial economic deregulation after 1980. Partial economic deregulation provides a unique opportunity to observe whether normal market incentives motivate railroads to operate safely, or if society must rely on direct regulation of safety as the primary method to ensure safety. The answer to this question should be of interest in the broader debate over the efficacy and efficiency of safety regulation in many industries—not just railroads. We find that increases in RegData’s measure of FRA regulation are associated with improved safety prior to partial economic deregulation, but not after. Increases in RegData’s measure of economic regulation, meanwhile, are associated with higher accident rates before the passage of the Staggers Act, but not after. The Staggers Act itself is associated with a large reduction in accident rates, accounting for as much as 89 % of the decline in the accident rate between 1978 and 2013. These results suggest that FRA safety regulation had its biggest effect on railroad safety during the period when economic regulation curtailed railroads’ incentives to operate safely and make investments that would improve safety. The removal of much economic regulation substantially improved safety by altering railroads’ investment and operating behavior. One consequence is that changes in safety regulation post-Staggers appear to have little marginal effect on safety.",6
49.0,3.0,Review of Industrial Organization,06 April 2016,https://link.springer.com/article/10.1007/s11151-016-9514-3,The Search of Prior Art and the Revelation of Information by Patent Applicants,November 2016,Corinne Langinier,Philippe Marcoul,,Female,Male,Unknown,Mix,,
49.0,3.0,Review of Industrial Organization,23 March 2016,https://link.springer.com/article/10.1007/s11151-016-9511-6,Empirical Evidence on Competition and Revenue in an All-Pay Contest,November 2016,Zhongmin Wang,Minbo Xu,,Unknown,Unknown,Unknown,Unknown,,
49.0,3.0,Review of Industrial Organization,01 March 2016,https://link.springer.com/article/10.1007/s11151-016-9504-5,Unilateral Effects with Endogenous Quality,November 2016,Brijesh P. Pinto,David S. Sibley,,Unknown,Male,Unknown,Male,"We examine whether a merger leads to higher or lower quality and identify the determinants of these effects. Merger analysis tends to focus only on the price effects of mergers, treating quality as exogenous. An important exception is the recent paper by Brekke et al. (2016). Their paper examines the same issues as do we and uses a more general framework, but their paper does not focus on unilateral effects—which is a main concern of ours.Footnote 1 Also, although the BSS framework is more general than ours, they only obtain unambiguous results for special cases. We examine whether a merger leads to higher or lower quality and identify the determinants of these effects. We also ask whether or not there is a first-order approach (FOA) to quality-related mergers that predicts merger-simulation results well.Footnote 2 The only analysis that compares the predictive power of the FOA to merger simulation results is that of Cheung (2012), which ignores quality.Footnote 3
 We describe an n-firm Bertrand model in which each firm chooses price and quality and find numerous cases in which the merged parties raise quality as a result of the merger. We explore which features of the model lead to the merger’s raising or lowering quality. For example, if we assume that there are no efficiencies due to the merger, then, the lower the price elasticity of demand, the more likely it is that the merger will raise quality. Finally, we derive an upward quality pressure index (UQPI) and also examine the usual upward pricing pressure index (UPPI). We find that the UPPI correctly predicts the directions of price effects while the UQPI often fails to predict the directions of quality effects. However, in the special case of quality-adjusted prices—i.e., “hedonic prices”—the standard UPPI correctly predicts merger simulation results.Footnote 4
",4
49.0,3.0,Review of Industrial Organization,03 March 2016,https://link.springer.com/article/10.1007/s11151-016-9507-2,Pricing Strategies in Advance Selling: Should a Retailer Offer a Pre-order Price Guarantee?,November 2016,Oksana Loginova,,,Female,Unknown,Unknown,Female,"In modern markets, sales of a product may precede the date when the product becomes available for consumption. Advance selling is a marketing strategy by a firm that allows consumers to submit pre-orders for a new to-be-released product. Advance selling reduces uncertainty for both the firm and consumers. It helps the firm partially to resolve uncertainty about the future demand for its product, thus allowing for better production and distribution capacity planning. By placing an advance order consumers avoid the risk of facing a stock-out.Footnote 1 At the same time, consumers may be uncertain about their valuations of the new product, which permits a greater extraction of consumer surplus by the firm in the advance selling season. A pricing phenomenon that is often observed along with advance selling is a pre-order price guarantee. Many retailers—such as Amazon.com, GameStop, or Best Buy—guarantee that the ultimate price that the customer pays is the lowest price between the pre-order price and the price on the release day. For example, the Amazon.com pre-order price guarantee policyFootnote 2 states: “Order now and if the Amazon.com price decreases between your order time and the end of the day of the release date, you’ll receive the lowest price.” This promotional offer eliminates another uncertainty that consumers face: the level of future price.Footnote 3
 I develop a theoretical framework to analyze the profit-maximizing strategy that a seller of a new product may adopt. A fraction of consumers know their valuations in advance (experienced consumers), while the rest learn their valuations only when the product becomes available in the regular selling season (inexperienced consumers). The retailer knows the number of experienced consumers, but is uncertain about the number of inexperienced consumers. Experienced consumers may be taken as those who have purchased earlier versions of the product in the past. The game starts with the retailer’s announcement of the advance selling price, which he may couple with the price guarantee policy. After observing the number of pre-orders, the retailer decides how much to produce for the regular selling season. If the price guarantee policy was announced and the regular selling price is below the advance selling price, the retailer refunds the price difference for the pre-orders. Unsold units are scrapped at a price below the retailer’s marginal cost, which makes it costly to produce and not sell. I show that when consumers are less heterogeneous in their valuations for the product, the retailer should implement advance selling and offer a pre-order price guarantee. For some parameter configurations the price guarantee policy acts as a commitment device not to decrease the price in the regular selling season. In other situations, it enables the retailer to react to the information obtained from pre-orders. If the number of pre-orders is small, the retailer sets a low price in the regular selling season, which targets the low-valuation customers who remain in the market; and he refunds the price difference for the pre-orders. He sets a high price if the number of pre-orders is large, so no consumer purchases the product in the regular selling season. When consumers are more heterogeneous in their valuations, the retailer may not want to implement advance selling. I show that if the market size uncertainty is small, or the scrap value is high, spot selling at a high price becomes the retailer’s optimal pricing strategy. In the basic model I assume that the retailer cannot credibly commit to the regular selling price in the advance selling season. The question, then, arises: If the retailer can commit to a price schedule at the beginning of the game, will he do so in equilibrium? In contrast to the Coase conjecture,Footnote 4 I find that the retailer is (weakly) better off if he offers a pre-order price guarantee than if he commits to a price schedule. The intuition behind this result is that a price commitment does not have the flexibility of a pre-order price guarantee. Because in my model learning by the retailer occurs between the advance and regular selling seasons, it becomes valuable for him to be able to react to the new information by either increasing or decreasing the price. The rest of the paper is organized as follows: A literature review appears in Sect. 2. The model is introduced in Sect. 3. I derive the retailer’s optimal pricing strategy in Sect. 4. In Sect. 5, I consider the situation in which the retailer can credibly commit to the regular selling price in advance. Concluding remarks are provided in Sect. 6.",12
49.0,3.0,Review of Industrial Organization,17 March 2016,https://link.springer.com/article/10.1007/s11151-016-9510-7,Multidimensional Auctions for Public Energy Efficiency Projects: Evidence from Japanese Esco Market,November 2016,Atsushi Iimi,,,Male,Unknown,Unknown,Male,"Competitive bidding is an important policy instrument for governments to procure goods and services at the lowest possible cost. Basic auction theory indicates that greater competition generally allows for the identification of the lowest-cost vendor or contractor in a market, because the probability of winning a public contract declines as firms face more contenders in an auction (Wilson 1977; Milgrom and Weber 1982; Wolfstetter 1996). Traditional competitive bidding systems, such as first- and second-price auctions, are particularly useful when an object to be purchased is simple and standardized, such as office supplies and computers. Procurers have to, by and large, predetermine technical standards and other specifications before calling for tenders. Then, potential vendors or contractors compete only by offering lower prices. In practice, however, many objects that are purchased by governments are complex and highly customized. For instance, in large infrastructure projects and consulting services, there are a number of technical approaches to achieve the same objective. Procurers may not know which approach is the best and instead ask potential contractors to propose their approaches. Then, not only prices but also other aspects need to be evaluated. Theory exists. Multidimensional auctions are implementable to evaluate both monetary and nonmonetary bids at once (Che 1993; Cripps and Ireland 1994; Branco 1997; Asker and Cantillon 2008). Despite the growing use of multidimensional auctions, there is little evidence that shows how they actually work. A fundamental problem of multidimensional auctions is that there is a tradeoff between price and “quality,” which is often referred to as anything that the procurer cares about other than prices. There is asymmetric information: Procurers do not ex ante know how price and quality are related to each other. Bidders know and can propose a combination. Proposed combinations are assessed under a given evaluation rule, often by using a set of criteria and weights. This paper examines the clusters of characteristics of the winning bidders of multidimensional auctions, using data from the public energy service company (ESCO) market in Japan. Public ESCO projects—in which a governmental and public agency is the procurer—are multidimensional service contracts that intend to improve the energy efficiency of buildings and facilities. Procurers—in this case, facility owners—prefer to maximize energy savings, while minimizing necessary investment costs. A variety of approaches may exist: from a high-cost and highly energy-efficient technology to a low-cost but less energy-efficient one. Other social and environmental benefits can also be taken into consideration in the bid evaluation. This paper shows empirically how the project and procurement conditions, such as intensity of market competition, affect the winning price and quality bids. Particular attention is paid to the possible effects of the information disclosure and risk-sharing schemes on procurement outcomes. The remaining paper is organized as follows: Section 2 provides an overview of procurement practices in the public ESCO market. Section 3 develops our empirical approach. Section 4 provides a summary of the data. Section 5 presents the main estimation results and policy implications, and Section 6 discusses robustness of the results and other statistical issues. Section 7 concludes.",4
49.0,3.0,Review of Industrial Organization,04 April 2016,https://link.springer.com/article/10.1007/s11151-016-9513-4,Thirteen Editions of The Structure of American Industry: An I.O. Perspective,November 2016,Kenneth G. Elzinga,F. M. Scherer,,Male,Unknown,Unknown,Male,"In 1950, as an assistant professor at Michigan State College, Walter Adams brought out the first edition of The Structure of American Industry (hereafter, Structure). In the years that followed, Adams was promoted to associate professor, professor, distinguished university professor, and even acting president of what, in 1955, became Michigan State University. Structure progressed through eight subsequent editions under Adams’ editorship until his death in 1998. In 1995, James Brock joined his former teacher as co-editor; and in 2015, Structure, now edited by Brock alone, appeared in its 13th edition. Best-selling novels go through multiple printings during their day in the sun. Very few textbooks in any field are sustained through 13 editions. Although many of its sales have been for classroom use, Structure is more than a textbook. Consistent with Adams’ original intent, the book serves as a source of information and analysis for individuals inside and outside the academy. Journalists, consultants, and even Supreme Court justices have turned to it for help in understanding specific industries. Over and beyond the data and analysis of industry case studies, Structure provides a gateway into the field of Industrial Organization. By comparing the industries included for study, one observes the changing composition of the U.S. economy. By following one industry over multiple editions, one discerns how that industry has evolved. Reviewing all the editions opens a window on how industry case studies have been executed. It also provides background on how other analytical paradigms in Industrial Organization have shifted away from the case study approach that was taken in the scholarly project that Adams began in 1950. In this article’s first section, we trace the ebb and flow of particular industries that appear over various editions of Structure and their authors. In Appendix A (http://kenelzinga.com/), we identify other books that, like Structure, consist of multiple industry case studies. Section one also explores more deeply why the choice of industries in Structure metamorphosed over time, reflecting both evolving patterns in the U.S. economy and the appearance of major independent studies, often of book length, by authors who later contributed to Structure. The second section examines in more detail the common paradigm on which the case studies were organized, evolving by the 4th edition into a Structure–Conduct–Performance-policy (SCP) framework. We trace the SCP paradigm’s roots and evaluate contemporary criticisms. The third and fourth sections focus on two topics that are found in either all or a majority of the editions. One is the steel industry, on which editor Adams had published independent analyses in the American Economic Review (1964) and Quarterly Journal of Economics (1966). The first nine editions all have steel industry chapters that were written or co-authored by Adams. Section four focuses on a chapter that appears in all 13 editions under the title, “Public Policy in a Free Enterprise Economy.” The fifth section assesses external indicators of the book’s success, aside from the market test of being published 13 times that spanned six decades. The sixth section offers our concluding retrospective on this long-lived work.",
49.0,4.0,Review of Industrial Organization,05 November 2016,https://link.springer.com/article/10.1007/s11151-016-9549-5,General Editor’s Note: Antitrust and Regulatory Update,December 2016,Lawrence J. White,,,Male,Unknown,Unknown,Male,,
49.0,4.0,Review of Industrial Organization,12 November 2016,https://link.springer.com/article/10.1007/s11151-016-9550-z,"Economics at the Antitrust Division 2015–2016: Household Appliances, Oil Field Services, and Airport Slots",December 2016,Randy C. Chugh,Nathan G. Goldstein,Nancy L. Rose,,Male,Female,Mix,,
49.0,4.0,Review of Industrial Organization,21 October 2016,https://link.springer.com/article/10.1007/s11151-016-9546-8,"Economics at the FCC, 2015–2016: Competition, Merger Review, and Spectrum Management",December 2016,O. Carare,E. Kiselev,T. Waldon,Unknown,Unknown,Unknown,Unknown,,
49.0,4.0,Review of Industrial Organization,22 October 2016,https://link.springer.com/article/10.1007/s11151-016-9547-7,Recent Developments at DG Competition: 2015/2016,December 2016,Adina Claici,Daniel Coublucq,Lluís Saurí,Female,Male,Unknown,Mix,,
49.0,4.0,Review of Industrial Organization,10 November 2016,https://link.springer.com/article/10.1007/s11151-016-9548-6,Economics at the FTC: Horizontal Mergers and Data Security,December 2016,Dan Hanner,Ginger Zhe Jin,Ted Rosenbaum,Male,Female,Male,Mix,,
50.0,1.0,Review of Industrial Organization,04 April 2016,https://link.springer.com/article/10.1007/s11151-016-9512-5,If It’s All the Same to You: Blurred Consumer Perception and Market Structure,February 2017,Edward J. D. Webb,,,Male,Unknown,Unknown,Male,"Can we always tell similar goods apart? The quality of a good is a nebulous attribute that is hard to assess at first glance; consequently, given this limitation to our perception, it is interesting to examine how it influences the selection of goods that we are presented with. This is done by looking at firms’ product design and the degree of concentration in a market in which consumers are bounded in their ability to distinguish between goods of different quality. Intuitively, it is not clear whether bounded perception should help or hinder a given firm. On the one hand, it is more difficult for a firm to distinguish its product. On the other hand, it could produce a “knock off” good and ride on the success of its rival. It is shown that both intuitions may be correct, depending on the cost structure: whether the cost of quality is fixed or marginal. A clear illustration is thus given of the importance of studying the interaction between individuals with decision-making limitations and other economic agents, as the results are non-straightforward and not necessarily robust to small changes in the surrounding arrangement. The model used is a vertically differentiated duopoly, with the results of fixed and marginal costs of quality contrasted. With fixed costs, firms must distinguish themselves or fall into the Bertrand trap, which leads to greater market concentration. With marginal costs, one firm can “imitate” the other by producing a good of the same perceived quality but with lower marginal costs. The market may then be either more or less concentrated depending on how bounded consumer perception is. Section 2 reviews some of the existing literature on perception. Section 3 formalizes bounded perception, and Sects. 4 and 5 examine its effect on a model of vertical differentiation with sequential quality choice with respectively fixed and marginal costs of quality. Section 6 presents an extension in which firms pay a cost to enter the market. Section 7 discusses the findings, Sect. 8 concludes.",1
50.0,1.0,Review of Industrial Organization,18 May 2016,https://link.springer.com/article/10.1007/s11151-016-9526-z,Structural Change in Competitive Balance in Big-Time College Football,February 2017,Steven Salaga,Rodney Fort,,Male,Male,Unknown,Male,"Competitive balance is an important characteristic of fan preferences in sports industries.Footnote 1 While there has been some attention to competitive balance relative to historic events in US college football, to our knowledge there is no formal, comprehensive time series assessment of competitive balance in Football Bowl Subdivision (FBS) conferences. In this paper we analyze the time series behavior of competitive balance measures over the histories of each of the FBS “Power 5” conferences through the 2010 conference season: the Atlantic Coast (ACC); Big 12; Big Ten; Pacific-12; and Southeastern (SEC).Footnote 2
 College sports are important to university administrators because they generate a variety of values across the rest of a university campus.Footnote 3 These values—as well as athletic department revenues that determine the portion of the university budget that will be spent on athletics—may depend on competitive balance. Thus, competitive balance becomes a management issue for university administrators through their college conferences and on up through the National Collegiate Athletic Association (NCAA). Further, competitive balance becomes a public policy issue since most athletic programs receive general university budget support, which, in turn in most cases, is partly publicly funded. It is common in time series analysis of balance to measure uncertainty about game outcomes, playoff outcomes, and outcomes over consecutive seasons. However, playoffs have only limited and recent applicability in college football (from a time series perspective). Consequently, we employ what is now referred to as the “BP Approach” (which is named for its originators: Bai and Perron, 1998, 2003) to analyze the time series behavior of uncertainty over game and consecutive season outcomes.Footnote 4
 Our most general result is that the time series of two game-uncertainty measures and one consecutive-season-uncertainty measure are quite stable for all Power 5 conferences. The series are stationary for all Power 5 conferences by unit root tests. Further, there are no structural “break points” that are detected by the BP Approach at all for the SEC (1933–2010). For the other four conferences, there are only six total break points, and there are never more than two conferences that share a proximate break point. None of the structural breaks are associated with either World War I or II, or the Great Depression, and none occur after the early 1990s. This remarkable stability occurred despite major changes in college football policy, most notably: the imposition of the original amateur requirement in 1906; the introduction of athletic grant-in-aid in 1956; and TV “deregulation” in 1984.Footnote 5 Rather than a form of negative “statistical finding”, in this case the comparison is relevant vis-a-vis Rottenberg’s (1956) invariance proposition: Is competitive balance changed (or not) by particular policy implementations? From the policy perspective, it is essential to answer this question in order to assess whether or not competitive balance is indeed influenced by any particular policy. Our paper proceeds as follows: In Sect. 2 we describe our data and the measures of competitive balance that are employed in the analysis. The results of unit root and break point tests are in Sect. 3.Footnote 6 Section 4 contains our assessment of the stability of competitive balance in college football. Conclusions and suggestions are in Sect. 5.",16
50.0,1.0,Review of Industrial Organization,07 June 2016,https://link.springer.com/article/10.1007/s11151-016-9528-x,"The Impact of Minimum Quality Standard Regulations on Nursing Home Staffing, Quality, and Exit Decisions",February 2017,John R. Bowblis,Andrew Ghattas,,Male,Male,Unknown,Male,"When quality is not easily verified, firms may have an incentive to reduce quality in order to increase profits. This is particularly true in the healthcare sector, where patients are less informed than providers and quality is difficult to measure (Chou 2002). Minimum quality standards are an important tool that regulators can use to assure a minimum level of quality. Over the last 20 years, minimum quality standards have become increasingly common in hospitals and nursing homes in the U.S., often in the form of minimum staffing regulations for nurses. Since nurses play a vital role in providing care and staffing levels are easy to measure, staffing regulations set standards for the composition and level of nurse staffing with the goal of improving patient outcomes. Advocates for minimum staffing regulations argue that low nurse staffing levels are associated with poor quality and that more stringent staffing regulations will increase staffing levels and improve quality. While it is clear that more stringent minimum staffing regulations increase staffing levels (Park and Stearns 2009), the empirical results on other quality measures are often mixed, with results that depend on the healthcare industry, type of nurse, and quality measure that is examined (Cook et al. 2012; Lin 2014). Further, more stringent staffing regulations are often not fully funded, which result in lower profitability and, in some cases, with providers losing money (Bowblis 2015). This could lead to some providers exiting the market. The theoretical literature offers some suggestions on what will occur in the face of minimum staffing regulations. There is a general consensus that providers that are below a regulatory standard will increase staffing, but there is ambiguity in other dimensions. In this paper, we empirically test how providers respond to minimum staffing regulations. Utilizing panel data over six-and-a-half years, we examine how nursing homes in New Mexico and Vermont responded to newly implemented minimum staffing regulations for nurses. These new regulations, which became effective in the early 2000s, impact nursing home staffing patterns, and as a result, may impact multiple dimensions of nursing home behavior. We examine these behaviors in terms of nurse staffing levels, nurse composition, use of contracted nurses, quality, and market exits. Although there are number of papers that have examined nursing home staffing regulations (Park and Stearns 2009; Bowblis 2011a; Matsudaira 2014a, b; Bowblis 2015; Chen and Grabowski 2015), this paper differs from existing studies in a number of ways: Prior research focuses on changes in existing regulations, whereas New Mexico and Vermont did not have minimum staffing regulations prior to the early 2000s. Because these states did not have pre-existing regulations, nursing homes in these states were free to choose staffing levels to maximize objectives without significant government restraints. We are therefore able to examine how nursing homes respond to newly implemented regulations, whereas existing studies focus on the strengthening of existing regulations. The rest of the paper begins by providing a general background on minimum quality standards and then the role of minimum nurse staffing regulations in the nursing home industry. Section 3 describes the staffing regulations in New Mexico and Vermont. Section 4 describes the data and the empirical strategies while Sect. 5 presents the main results. Section 6 concludes.",12
50.0,1.0,Review of Industrial Organization,01 July 2016,https://link.springer.com/article/10.1007/s11151-016-9529-9,"New Outsourcing, Demand Uncertainty and Labor Usage",February 2017,Sasan Bakhtiari,Robert Breunig,,Male,Male,Unknown,Male,"The motivation for this paper is to use firm-level data to examine the relationship between demand uncertainty and new outsourcing. Outsourcing provides one way for firms to cope with large unexpected changes in demand. Unique firm-level, longitudinal data allow us to study this relationship. We first address whether there is a relationship between the firm’s decision to undertake new outsourcing and its ability to predict future sales. We find that the relationship is asymmetric and depends upon firm size. For firms with 50–200 employees, firms are more likely to engage in new outsourcing in response to positive sales shocks. For smaller firms, positive sales shocks have no impact on the decision to undertake new outsourcing. For firms of all sizes, we find that firms are less likely to engage in new outsourcing in response to negative sales shocks. To learn more about firms’ motivation for new outsourcing, we examine patterns of labor utilization and their relationship to firms’ prior expectations about sales. New outsourcing does not appear to be a response to firms’ prior decisions about hiring in anticipation of growth. Those firms that engage in new outsourcing use labor more intensively, show a larger increase in work hours, and have lower net job growth. Thus, overall, new outsourcing appears to be related to firm strategy around labor utilization and to demand shocks. For small and medium-sized Australian firms, new outsourcing seems unrelated to firm cost-cutting. In what follows, we begin by discussing the background and literature around demand uncertainly and outsourcing. We devote the third section to discussion of our data. The fourth and fifth sections examine the relationship between new outsourcing, demand uncertainty, and labor utilization. We conclude in section six.",1
50.0,1.0,Review of Industrial Organization,29 June 2016,https://link.springer.com/article/10.1007/s11151-016-9530-3,Parking Discounts: Price Discrimination with Different Marginal Costs,February 2017,Daniel Flores,Vitaliy Kalashnikov,,Male,Male,Unknown,Male,"The lack of complimentary parking is easy to understand when parking costs are very high. For instance, parking in downtown New York for a few hours can cost as much as $50. A shop or restaurant cannot offer to absorb the cost of these expenditures if customers purchase on average $20 in merchandise or food, respectively. However, it is not straightforward to explain why some firms provide complimentary parking and others do not when the cost of parking is only $1 or $2 per hour in the immediate area. In this paper, we model the problem of an urban merchant that should decide whether to provide reduced price parking to its customers or not. Although the merchant is a monopolist in the market for a certain good, it is not the unique provider of parking. Indeed, the market for parking is competitive. Unlike previous work that considers the provision of parking in suburban shopping malls where most customers come by car, we assume that the firm faces two relevant groups of customers: drivers and pedestrians. Drivers require parking in order to purchase the good from the monopolist. In contrast, pedestrians do not require parking to purchase from the monopolist. Given that the merchant can’t distinguish between drivers and pedestrians until drivers ask for parking reimbursement, it charges both groups the same price for the good. However, the merchant can try to price discriminate between them through a parking discount if the merchant benefits from charging drivers a lower price than it charges to the pedestrians.Footnote 1 It is not clear whether this is generally the case. On the one hand, drivers may be willing to pay more for the good because they have high incomes. On the other hand, pedestrians may be willing to pay more because they are less mobile. The problem that we study is common in many other contexts. That is, our analysis extends to other situations in which a firm sells a main good and offers an additional service that is required only by some of the customers. For example, we can think of car repair shops that offer transportation; restaurants that provide babysitting; hotels that provide Wi-Fi signals; electrical appliance shops that offer equipment installation; or more generally shops that charge the same price to customers that pay with cards or with cash.Footnote 2
 This article contributes to the understanding of these situations in several ways: First, we believe that this is the first article that shows that price discrimination can explain free or reduced price parking in urban shopping centers. Second, this article extends the recent work of Chen and Schwartz (2015) on third-degree price discrimination with different marginal costs and applies it to the study of parking fees. Third, the article addresses a policy question: Should local governments regulate or prohibit parking charges in commercial establishments? Proposals to prohibit parking charges have been sent to congress recently in Latin American cities such as Monterrey and Panama.Footnote 3
",6
50.0,1.0,Review of Industrial Organization,19 July 2016,https://link.springer.com/article/10.1007/s11151-016-9531-2,On the Impact of Input Prices on an Entrant’s Profit Under Multi-Product Competition,February 2017,Duarte Brito,Markos Tselekounis,,Male,Male,Unknown,Male,"In many network industries, such as telecommunications, electricity and rail, the vertically integrated (“incumbent”) operators control upstream inputs that are required for the supply of the final service. Given that these critical inputs are characterized by natural monopoly cost conditions (Armstrong et al. 1996), sector-specific regulators have mandated that incumbents provide access to these inputs for alternative operators (“new entrants”). The impact of input prices on the promotion of static and dynamic efficiency has been at the core of the policy debate since the liberalization of network industries. Part of this debate has evolved around the effect of the input prices on an entrant’s profit as they affect its decision between buying the incumbent’s inputs and making its own inputs, which in turn affects the efficiency outcomes. The existing literature studies the relationship between the price of an input that is controlled by a vertically integrated incumbent and a single-product entrant’s profit. However, in some network industries it is reasonable to assume competition between multi-product firms, particularly when different production technologies coexist. In this paper, we extend the Hotelling model to accommodate multi-product competition with horizontal and vertical differentiation so as to study the impact of input prices on an entrant’s profit under this framework. We assume that the supply of the high-quality product requires an input that is controlled by a vertically integrated incumbent, whereas the corresponding low-quality input is costless, which means that the entrant only buys the high-quality input. We show that the introduction of multi-product competition results, in contrast with the single-product case, in an entrant’s profit function that may increase with the wholesale price of the critical high-quality input. The intuition for this result lies in the two opposite effects of an increase in the wholesale price of the critical input on the entrant’s equilibrium profit. The first effect corresponds to the increase in its cost that, taking output as given, results from an increase in the input price. Obviously, this “direct” effect negatively affects the entrant’s profit. The second effect corresponds to the increase in its demand that results from the rival setting a higher equilibrium retail price as a response to the input price increase.Footnote 1 This positive “strategic” effect is qualitatively similar both for single-product and multi-product firms. We argue that when the entrant is a multi-product firm, the magnitude of the negative direct effect decreases, whereas the magnitude of the positive strategic effect increases. The reason is that a multi-product firm sets higher retail prices than does a single-product firm because it internalizes the positive effect on the demand for each product that results from increasing the price of the other(s). Thus, equilibrium output will be lower and so will the direct effect. As for the strategic effect, an increase in the input price of the high-quality product leads to higher retail prices set by the rival, and hence, the demand for each of the entrant’s products will increase, making the strategic effect stronger. As a result, it is more likely for a multi-product entrant to benefit from an increase in the wholesale price of the critical input. In our specific demand model these effects result in a condition under which the entrant’s profit is positively correlated with the input price. This condition requires that the entrant’s profit margin in the low-quality product should be higher than the profit margin in the high-quality product. We also show that the assumption of full market coverage that is implied by our modeling setup just makes it more likely that the entrant becomes better off with an increase in the input price. In terms of policy relevance, this implies that a deregulatory policy may induce the entrant to buy the incumbent’s inputs at higher wholesale prices, rather than to make its own inputs. Thus, multi-product competition may distort the efficiency implications of changes in the input prices that were drawn under a single-product setting. In the next section we review the related literature and present the contribution of the article. In Sect. 3 we describe the model, whereas the equilibrium outcomes are presented in Sect. 4. The impact of the input price on the entrant’s profit is explained in Sect. 5. In Sects. 6 and 7 we discuss the robustness of the main result and, respectively, its policy implications for the fixed broadband industry. The last section concludes.",2
50.0,1.0,Review of Industrial Organization,21 January 2017,https://link.springer.com/article/10.1007/s11151-016-9561-9,Call for Papers,February 2017,,,,Unknown,Unknown,Unknown,Unknown,,
50.0,2.0,Review of Industrial Organization,07 February 2017,https://link.springer.com/article/10.1007/s11151-017-9569-9,Resale Price Maintenance and the Tenth Anniversary of Leegin,March 2017,Kenneth G. Elzinga,,,Male,Unknown,Unknown,Male,,2
50.0,2.0,Review of Industrial Organization,28 December 2016,https://link.springer.com/article/10.1007/s11151-016-9560-x,Online RPM and MFN Under Antitrust Law and Economics,March 2017,Pinar Akman,D. Daniel Sokol,,Unknown,Unknown,Unknown,Unknown,,
50.0,2.0,Review of Industrial Organization,23 December 2016,https://link.springer.com/article/10.1007/s11151-016-9559-3,Resale Price Maintenance: An Economic Analysis of its Anticompetitive Potential,March 2017,Roger D. Blair,Wenche Wang,,Male,Female,Unknown,Mix,,
50.0,2.0,Review of Industrial Organization,05 January 2017,https://link.springer.com/article/10.1007/s11151-016-9558-4,Resale Price Maintenance Post Leegin: A Model of RPM Incentives,March 2017,William S. Comanor,David Salant,,Male,Male,Unknown,Male,"The Leegin decision of 2007 changed the course of antitrust jurisprudence with respect to resale price maintenance (RPM) in an essential way. No longer would the critical issue be whether an agreement existed between supplier and distributor to set resale prices as it had been for decades. Ever since the Dr. Miles decision of 1911, these restraints have been evaluated under Sect. 1 of the Sherman Act, which required a combination or agreement among the parties for a violation to be found. In the presence of the per se rule established in the Dr. Miles decision, the only remaining issue was whether Sect. 1 could be applied, so that was where the battles were fought. All this changed post-Leegin as attention was redirected to the actual consequences of the restraint. The parties were now required to specify the gains and losses from the restraint so that economic analysis would play a more consequential role. From the start, the Court acknowledged that RPM could have different competitive effects depending on the market circumstances in which it was applied (Leegin 2007). This recognition was evident in Justice Kennedy’s majority opinion. He reserved one section for circumstances where the benefits from the restraints would exceed their costs and the following one for the reverse. In large measure, Justice Kennedy relied on various economic studies that detailed the ways in which the gains resulting from RPM exceeded their costs. Many of these studies provided economic models in which RPM could be used to create more efficient distribution systems. However, when he turned in the opposite direction, he had less to rely upon. Although there were numerous reports of RPM’s leading to higher prices and exclusionary outcomes, there were fewer formal models that specifically detailed the anti-competitive consequences of vertical price restraints. Even the leading text on antitrust economics (Blair and Kaserman, 2nd ed., 2009, p. 373) merely noted the leading defect of RPM was its use to facilitate price-fixing arrangements. (Comanor 2011) In this paper, we seek to fill this void. Our purpose is to present a formal model of supplier–distributor interactions in which both the gainers and losers from RPM are identified. This model like all others must rest on structural predicates. Rather than simply adopting a pro forma underlying structure, as is generally done, we take our predicates from those present in a prominent post-Leegin RPM decision which involved Babies R Us (BRU) (McDonough et al. v. Toys R Us, Inc. 2009). The model itself has similar implications to that developed by Asker and Bar-Isaac (2014). However, in their model, an upstream firm uses RPM to exclude rivals, while in the one developed here, a dominant distributor employs RPM to exclude downstream rivals. In that regard, we follow an earlier model put forth by Comanor and Rey (2000). That case is described in some detail in a recent paper (Comanor 2013) so there is little need to repeat that discussion. Instead it is sufficient for our purposes to describe the contours of the market structure within which RPM was practiced. Suppliers of strongly branded and highly priced baby products interacted with a dominant distributor that accounted for large proportions of their products’ sales. Although these suppliers typically faced competition from generic rivals, there were reasons to conclude, and the judge so ruled, that those products were sold in separate and distinct markets. At the same time, the dominant distributor faced competition from a group of rivals that employed a new technology, the Internet. These rivals had lower costs due to the new technology and were therefore able to charge lower prices for the same products. However, many consumers had strong preferences for using the established distributor, which offered certain services that the new rivals could not provide. There was also evidence, which was noted in Judge Brody’s decision, that the dominant distributor coerced its principal suppliers to impose RPM so that the rival distributors would not set prices below those charged by the dominant distributor. If such lower prices were set, product shipments would be discontinued, as in fact occurred. Although the suppliers may have preferred to have the alternate distributors actively selling their products, they were unwilling to jeopardize their distribution arrangements with the leading distributor. And in the end, they imposed RPM limitations on the new distributors. In her decision, the Judge referred twice to a particular passage from the Leegin decision: A dominant retailer, for example, might request resale price maintenance to forestall innovation … that decreases cost. A manufacturer might consider it has little choice but to accommodate the retailer’s demands for vertical price restraints if the manufacturer believes it needs access to the retailer’s distribution network. (Leegin, p. 893) While this passage suggests circumstances where enforcing RPM may have strong anti-competitive consequences, it hardly represents a detailed economic model. In this paper, we offer just such a model. The essential actors are a monopolistic supplier, a dominant distributor, and a fringe of rival distributors. Not only does this fringe behave as perfect competitors but to be relevant in the market, its members must also have lower costs than their more dominant alternative. However, the fringe faces a structure of demand where some consumers strongly value the services that are offered by the dominant distributor and are willing to pay a premium to obtain their product from that source rather than the fringe. Finally, we assume—again following the circumstances of the case—that arbitrage prospects make it infeasible to charge different prices to the fringe distributors than to the dominant outlet. In effect, the upstream supplier is unable to practice price discrimination. In the following section, we develop an economic model in which these sets of actors interact. Of course, much rests on the structure of consumer preferences for the services that are offered by the two sets of distributors. However, all that we assume is that consumers exhibit a wide range of preferences for the services that are offered.",
50.0,2.0,Review of Industrial Organization,19 January 2017,https://link.springer.com/article/10.1007/s11151-017-9564-1,"Flawed Economic Models Have Misled RPM Policy: Changes in Canada, Europe and the United States",March 2017,Tarcisio da Graça,Robert Masson,,Male,Male,Unknown,Male,"Minimum resale price maintenance (RPM) occurs when an upstream firm—e.g., a manufacturer with monopoly power—sets a minimum price below which downstream retailers are not permitted to make sales.Footnote 1 Some RPM practices have been criticized from a competition policy point of view when they have enabled or facilitated collusion or foreclosed competition. There is little—if any—disagreement on this point. However, many observers contend that RPM that is not associated with collusion or foreclosure enhances consumer welfare. We claim that for a certain type of goods this contention is based on a false premise, and we show, in contrast, that the introduction of RPM can reduce consumer surplus. For this type of goods, we show further that even those few authors who pointed out that RPM can reduce consumer surplus in fact underestimate the consumer welfare loss. Specifically, we conclude that RPM that induces “sterile” presale services—i.e., services that do not modify the value-in-use of a product—potentially can reduce consumer welfare by far more than has been recognized in the economic and legal literature. Importantly, although in equilibrium RPM must increase profits—or it would not be instituted—this effect may be more than offset by consumer surplus loss so that RPM may reduce total welfare as well. Many economics authors have touted the potentially beneficial consequences of RPM practices. In the legal context, since the U.S. Supreme Court ruled in Leegin
Footnote 2 in 2007 that vertical agreements to fix minimum prices are no longer a per se violation of section 1 of the Sherman Act, there has been a renewed interest in the topic. In Canada, the Competition Act was amended in 2009 so that RPM is no longer a criminal violation per se, although it may be a civil violation depending on the circumstances. Even in Europe it appears that there may be a softening of the policy towards RPM.Footnote 3 It is our concern that this move towards RPM leniency stretches too far. In light of our discussion, it is advisable that competition authorities remain vigilant against potentially harmful RPM practices. Our analysis focuses on the “services”Footnote 4 arguments that were made famous by Telser (1960). In particular, we focus on the presales services that inform consumers about the true value of a product pre-purchase.Footnote 5 We argue that this type of presales service has little social value and should not be considered to be procompetitive in the way that many economists have modeled them and that the Supreme Court interpreted them in Leegin. RPM is not profitable for all products. Its potential profitability is for those products for which, in the absence of informative pre-sale services, consumers’ initial valuations are low. In this context “low” could mean a low expected value or, given an expected value, low expected utility if variance/uncertainty is high. Consequently, we examine products for which, in the absence of informative pre-sales services, consumer valuations are low in comparison to the value that they would realize from the actual use of the product, were they to purchase it. More generally, products can be overvalued, correctly valued, slightly undervalued, or significantly undervalued. But it is only this last category—a priori significantly undervalued—for which firms would consider initiating RPM. We will only model products of this nature.Footnote 6
 To model profitable RPM, we will assume that consumer initial valuations are low but that when retailers offer pre-sale services, expected values increase while their actual values-in-use remain unaltered. We shall call this type of service “sterile” presale services. As a consequence, the RPM equilibrium price and quantity are higher while consumer surplus is reduced as the inframarginal consumers—those consumers who would buy the product even without the services—end up paying more without any gain in their actual in-use value of the product. A different rationale for RPM may explain why manufacturers of luxury, high-end, or exclusive goods institute RPM. It is possible that some consumers value such goods at higher prices as a sign of sophisticated taste. In addition to the utility of the product from its functionality, these consumers may derive great satisfaction from showing off their exclusive products, characterizing a form of snob effectFootnote 7 (one could think of jewelry as an example of this sort, or better yet “badges” such as Gucci, Cartier, Rolex). In Leegin, the manufacturer of luxury leather products sought to profit from the snob effect of its products through the institution of RPM. Our concern is that the U.S. Supreme Court’s leniency towards RPM motivated by the snob-effect rationale may be applied to justify RPM that is motivated by the sterile presale services rationale. If a manufacturer institutes RPM to induce demand-stimulating but sterile pre-sales services, one presumes it believes that profits will be higher with these services. By setting a wider marginFootnote 8 (as compared to the margin without RPM), the manufacturer prompts retailers to provide the services as the RPM price covers the services’ costs. Assuming perfect competition among retailers and constant returns to scale (in both sales and services), retailers are indifferent between offering services with RPM and not offering services without RPM. A manufacturer desires RPM because it perceives RPM as a profitable scheme where those services stimulate demand so that the RPM outcome is greater demanded quantity at a higher price. Following this rationale, we expose flaws in some economic literature that has had pivotal impact on policy and court decisions. In the U.S., for instance, the Brief for Petitioner in their appeal of Leegin from the Court of Appeals for the Fifth Circuit to the Supreme Court cited prominent authors. We challenge some of these authors’ arguments: in particular, Bork (1978) and Posner (1976). These authors have been influential outside the U.S., as well. In Europe, while the overall approach to RPM remains more restrictive than the approach that has been determined by the U.S. Supreme Court for RPM,Footnote 9 the 2010 European Guidelines on Vertical Restraints opens up a possibility of an efficiency defense that is equally flawed. In light of our findings, a self-contained, freestanding (independent of the core competitive violations: collusion, exclusion, foreclosure, or abuse of dominance) treatment of RPM in competition statutes is a sensible attitude. Furthermore, based on our results, per se illegality—or at a minimum a presumption of illegality—of RPM that solely induces sterile presale services is advised in countries where competition enforcement hinges on a consumer surplus standard. In total welfare jurisdictions competition authorities should remain skeptical about the weight of any presales services justification for RPM as a claim that it is an efficiency-improving strategy. We proceed as follows: Sect. 2 provides the reader with the historic and legal context of RPM. In Sect. 3, we briefly review some related literature. The graphical analysis of Sect. 4 is an intuitive explanation of our conceptual discussion that exposes the flaw in the influential literature in Leegin. We move towards deepening the analysis by presenting a numerical example in Sect. 5 with endogenous wholesale prices; the literature relied on in Leegin is based on an unrealistic assumption that wholesale prices are exogenous, unchanged when demand is stimulated by RPM. In Sect. 6 we discuss implications of our analysis in terms of legal treatment that depends on the welfare standard of a jurisdiction. Section 7 concludes the paper.",
50.0,2.0,Review of Industrial Organization,06 January 2017,https://link.springer.com/article/10.1007/s11151-016-9562-8,Challenges for Empirical Research on RPM,March 2017,Alexander MacKay,David A. Smith,,Male,Male,Unknown,Male,"Multiple candidate theories have been presented to explain the possible costs and benefits of minimum resale price maintenance (RPM), with little corresponding empirical research to test whether anti-competitive or pro-competitive practices have a greater influence. Moreover, since Leegin,Footnote 1 which relaxed the legal treatment of RPM at the federal level, policy makers have been debating whether to propose new legislation to address the legality of RPM. What empirical evidence is there to help guide public policy? In the words of Mathewson and Winter (1998, p. 80), “there is not a great deal of evidence.” Nearly 20 years later, this still rings true. The challenge of future empirical research is to focus the theoretical literature and provide a basis from which policy-makers can make informed choices. This paper serves as a guide to empirical researchers whose aim is to test for the existence and effects of RPM or to evaluate consumer welfare effects. As RPM has been found most often in a retail setting, most of the examples that follow are set in the context of a manufacturer-retailer relationship. However, the principles can be extended to almost any vertical relationship. Below, we discuss the methods and data that can be used to test for the existence and effects of RPM, the corresponding challenges, and the identification of welfare effects. We would like to emphasize here that an empirical analysis should consider as broad of a set of goods as possible. Many theories of RPM suggest that durable search goods, infrequently purchased goods, fashion goods, quality goods, and new entrants are natural candidates for demand-enhancing services and pro-competitive uses of RPM.Footnote 2 However, focusing on these types of goods alone would result in a biased sample, as the ability to exercise market power—which may be facilitated by RPM—could exist for almost any product. As Pitofsky (1982) asks, “think for a moment about the product areas in which resale price maintenance has appeared—boxed candy, pet foods, jeans, vitamins, hair shampoo, knit shirts, men’s underwear. What are the [demand-enhancing] services we are talking about in these cases?” While many economists would have predicted that televisions would be subject to minimum RPM agreements,Footnote 3 some likely were surprised to find out that minimum RPM agreements have also applied to non-durable goods such as dried cereal,Footnote 4 toothpaste,Footnote 5 beer,Footnote 6 herbicides,Footnote 7 milk, bread, ice cream, snack foods, paper goods, gasoline, paint, and pet supplies.Footnote 8 Although Ippolito (1991) found that 65% of private cases and 68% of public cases in her data are for products that can be classified as complex, new, or infrequently purchased-products where the special services theory for RPM is most likely to hold—she found that over 30% of cases involved products that are not natural candidates for the special services theory. To avoid selection bias, future studies should not isolate a group of products that might a priori fit certain pro- and anti-competitive theories of minimum RPM. Researchers should extend their analysis beyond examples from previous cases. In this paper, we outline three approaches for demonstrating the existence of RPM, along with the potential challenges to each approach. We then turn to the additional problems of demonstrating welfare effects, even when the existence of RPM has been determined. Finally, we present some solutions to the challenge of identifying welfare effects, and we suggest guidelines for future research.",4
50.0,2.0,Review of Industrial Organization,07 February 2017,https://link.springer.com/article/10.1007/s11151-017-9570-3,Leegin and the Economics of Resale Price Maintenance,March 2017,Howard P. Marvel,,,Male,Unknown,Unknown,Male,"A decade ago, the U.S. Supreme Court overturned a nearly century-old precedent when it issued its Leegin opinion.Footnote 1 The overturned precedent, Dr. Miles,Footnote 2 had assigned resale price maintenance (RPM) to the class of contractual restraints that are treated as per se illegal. Leegin, a producer of women’s fashion accessories marketed under the Brighton brand name, had adopted a pricing policy under which it “refused to sell to retailers that discounted Brighton goods below suggested prices” (Leegin, p. 883). PSKS was one of the retailers to which Leegin refused to sell, after Leegin discovered that PSKS was offering a 20% discount across the Brighton product line. When sued by PSKS, Leegin attempted to introduce expert testimony to show that the pricing policy allowed it to compete successfully and was therefore procompetitive, but the district court excluded the testimony as inappropriate for a per se violation of the Sherman Act. The Supreme Court was emphatic in ending the legal distinction between price (illegal per se) and non-price (rule of reason) vertical restraints: “In sum, it [the rule that it is per se illegal under §1 of the Sherman Act, 15 U. S. C. §1, for a manufacturer to agree with its distributor to set the minimum price the distributor can charge for the manufacturer’s goods] is a flawed antitrust doctrine that serves the interests of lawyers—by creating legal distinctions that operate as traps for the unwary—more than the interests of consumers—by requiring manufacturers to choose second-best options to achieve sound business objectives” (Leegin, p. 904). The Court’s finding that RPM could be a method through which producers competed with one another (interbrand competition) marked a dramatic change in attitudes toward the practice. RPM had long been legal when adopted unilaterally under the Colgate
Footnote 3 rule that permitted a producer to set its price for resale one level downstream as long as it did not contract for that minimum price with its downstream distributors.Footnote 4
 But that was a non-economic artifice to permit the use of RPM. The economic analysis upon which the Court relied in Leegin recognized that a producer would only (voluntarily)Footnote 5 set a minimum price for resale—resulting in higher margins for distributors—if doing so induced those distributors to provide demand-increasing efforts for the product whose price was controlled. With Leegin, it was no longer necessary to turn a legal blind eye toward the deal that manufacturers were making with their preferred distributors. As one legal commentator put it, with Leegin “the U.S. Supreme Court has invited businesses to reconsider their distribution agreements” (Lindsay 2007). This paper first discusses the impact of the Leegin decision. We show that price comparison websites, which had developed rapidly pre-Leegin, soon atrophied in the wake of Leegin, which suggests that discounts had become much less prevalent. But while the Court’s acceptance of RPM as a good option “to achieve sound business objectives” removed the stigma associated with price maintenance policies, the legal treatment of the practice did not change. With many well-known brands selling in nationwide markets, hostility to RPM in state antitrust laws forced firms to continue to utilize Colgate policies to control resale prices—policies that had been permitted prior to Leegin. Section 2 provides counts of the appearance of the term “resale price maintenance” in court opinions. These counts suggest that Leegin’s influence was less than that of an earlier Supreme Court opinion, Business Electronics,Footnote 6 that clarified the application of Colgate policies. The limitation of Colgate is that a firm that has adopted a unilateral policy must terminate any retailer that chooses not to adhere to the required resale price. For example, adhering to the Colgate requirement retail prices be announced unilaterally allowed Nike to control the resale price of its shoes. But failing to follow the unilateral requirement resulted in charges that Nike’s rival shoe producer, Reebok, had engaged in RPM and forced Reebok into a costly settlement (Marvel 2008) and forced Reebok to drop its RPM policy. Unilateral resale price maintenance policies can become unworkable when the manufacturer fails to resist the temptation to negotiate with a discounter, as was apparently the case for Johnson & Johnson (see Sect. 3). Prior to the Leegin opinion, characterizing vertical restraints as RPM had been an attractive option for plaintiffs, given the per se illegal status of the practice. But in the aftermath of Leegin, plaintiffs can prefer to characterize the vertical elements of a distribution practice as subservient to a claimed horizontal arrangement among distributors to control their prices and/or margins. Doing so allows the vertical restraint that was the central issue in an RPM proceeding to be reinterpreted as merely incidental to a broader conspiracy. It was necessary to avoid characterizing the relevant vertical restraint as RPM in consequence of the standards developed under the Colgate doctrine for determining whether the restraint in question was a contract, combination, or conspiracy as opposed to unilateral. Leegin had rightly described these standards as “stringent”Footnote 7 (Leegin, p. 903). In the remainder of this paper, we consider two recent attempts to attack RPM-like arrangements as elements of horizontal price-fixing conspiracies. In Sect. 4, we consider a case—MM Steel,
Footnote 8—in which distributors complained to manufacturers about a free-riding competitor, with the result that the manufacturers refused to deal with the free rider. By interpreting the vertical arrangement as deriving from a horizontal agreement among distributors, the free-riding plaintiff managed to suppress any discussion of the economics of the vertical relationship, avoid the stringent standards for evaluating whether the vertical relationship at issue constituted a contract, and avoid as well consideration of whether the behavior in question could reasonably have been supposed to yield monopolistic results in the market in question. A second case—Uber,
Footnote 9—involves a claim that the ride-sharing service, Uber, has orchestrated a horizontal price-fixing conspiracy among drivers to raise the price of its car services to riders. In its pleadings, Uber has argued that its involvement is resale price maintenance—a remarkable turnaround from RPM’s pre-Leegin pariah status. 
Leegin has thus been influential even though the retention of per se illegality by a handful of states has limited its impact on the legal status of RPM. It is reasonable to expect that claims of RPM will be avoided by antitrust plaintiffs, who will prefer indirect routes of attack on vertical price fixing. Antitrust strictures will ensnare only firms that, like Leegin, are unwary enough to contract directly with distributors to curb their discounting or, alternatively, are willing to reinstate distributors who were terminated for failure to charge the manufacturer’s preferred resale prices.",3
50.0,2.0,Review of Industrial Organization,20 January 2017,https://link.springer.com/article/10.1007/s11151-017-9563-2,Inducing Cooperation with a Carrot Instead of a Stick,March 2017,David E. Mills,,,Male,Unknown,Unknown,Male,"Much has been made of the influence of economics on antitrust policy in recent decades (Kovacic and Shapiro 2000; White 2010). There is no better example of this influence than the shift that has taken place in the antitrust treatment of minimum resale price maintenance (RPM): In Dr. Miles Medical Co. v. John D. Park & Sons. Co., 220 U.S. 373 (1911), the Supreme Court held that it is illegal per se for a manufacturer to enter into an agreement with retailers that specifies a minimum resale price. This decision reflected the antitrust hostility toward vertical restraints that prevailed for several decades before a more nuanced understanding of vertical price restraintsFootnote 1 took hold among economists and antitrust scholars. After nearly a century, the Court overruled Dr. Miles and held in Leegin Creative Leather Products, Inc. v. PSKS, Inc., 551 U.S. 877 (2007), that “vertical price restraints are to be judged by the rule of reason” (p. 1). This dramatic reversal was based squarely on economic reasoning and on a half-century’s developments in the economic theory of vertical relationships.Footnote 2 The Court observed that “[e]conomics literature is replete with procompetitive justifications for a manufacturer’s use of resale price maintenance” and specifically relied on the justification that the practice “encourages retailers to invest in services or promotional efforts that aid the manufacturer’s position as against rival manufacturers” (p. 2). By placing RPM under the rule of reason, Leegin affirms the antitrust priority of preserving interbrand competition and recognizes that certain restraints on intrabrand competition can serve this purpose. There are several and somewhat diverse economic theories that explain why a manufacturer might use RPM to build and maintain an efficient distribution system. These theories, some of which were advanced more than half a century ago, attribute procompetitive or benign effects to the practice.Footnote 3 The most influential procompetitive theories of RPM focus on manufacturers’ efforts to induce retailers to provide “retailer services” that promote the sale of their brands. This is the role that Leegin Creative Leather Products, Inc. attributed to its suggested retail price policy when that policy was challenged by the plaintiff in Leegin. The Court’s decision in Leegin legitimized this role and validated the procompetitive effects of this use of RPM. Retailer-service theories of RPM hold that retailers can perform customer services or supply brand-specific information to their customers that promote sales of particular brands. Pre-sale assistance by knowledgeable salespersons, product placement, and various shopping amenities are familiar examples of such services. Manufacturers have an interest in eliciting these services from retailers, but retailers’ financial incentives are not the same as those of the manufacturers. Eliciting services contractually is not always feasible. Incomplete information and costly monitoring may prevent manufacturers from inducing services in this way. To overcome this contracting problem and secure the services that they seek from retailers, manufacturers may use price or non-price vertical restraints to align retailers’ interests with their own. Hovenkamp (2005) explains this in terms of the agency problem that manufacturers face: Manufacturers profit when their distribution systems work as efficiently as possible. While dealers collectively profit when a manufacturer’s product is highly successful, individual dealers often profit even more when they can earn high markups by limiting competition with other dealers in the same brand. The interests of manufacturers and dealers are thus sometimes at odds, and this tension explains most vertical intrabrand restraints (p. 184). Telser (1960), whose procompetitive theory of RPM came first, observed that retailers are deterred from providing services that manufacturers seek when they cannot recover their cost because free-riding retailers that do not provide services undercut their retail prices.Footnote 4 He recognized that a manufacturer may implement RPM to eliminate the threat of free riding by establishing a minimum retail price that encourages (or at least enables) retailers to provide the services the manufacturer seeks. Other procompetitive theories of RPM that feature retailer services followed. Telser’s theory applies to retailer services that: (1) affect the demands of those consumers who encounter the retailer directly; and that (2) do not prevent consumers from purchasing the brand from a different retailer than the one that provides the services. The closely related theories of RPM put forward by Marvel and McCafferty (1984) and Klein and Murphy (1988) apply to retailer services that have one but not both of these characteristics. Marvel and McCafferty’s theory emphasizes the “quality certification” service that retailers with reputations for selling high-quality merchandise perform for manufacturers. This service has the second characteristic of Telser’s retailer services and, like Telser’s, focuses on the role that RPM plays in the prevention of free riding. But the services to which Marvel and McCafferty draw attention do not have the first characteristic of Telser’s retailer services. The reach of the reputational benefit that a discriminating retailer confers on the manufacturer is not limited to the customers of the discriminating retailer, but extends to every customer. Marvel and McCafferty’s argument “does not require that dealers provide tangible services, but rests instead on the mere willingness of dealers to stock the product in question… [because]… consumers care where a product is sold but do not care where they purchase their own supplies of the good” (p. 347). The retailer services that Klein and Murphy’s theory of RPM emphasize have the first characteristic of Telser’s retailer services, but not the second. This theory shares with Telser’s the notion that manufacturers seek to elicit tangible activities that alter the demands of those consumers one-by-one. But Klein and Murphy do not share Telser’s concern with the prevention of free riding. They hold that manufacturers’ RPM policies often have nothing to do with free riding. Instead, Klein and Murphy interpret RPM as a device for enforcing incomplete performance contracts that are aimed at stimulating and securing non-contractible retail services in support of a manufacturer’s brand. An RPM-protected profit margin is said to induce retailers to provide the services that are sought by the manufacturer in order to avoid termination and forfeiture of that margin. This mechanism is entirely different than one that removes the incentive for discounters to undercut the prices of their full-service rivals. It is clear from Telser’s theory that RPM enables retailers to provide services that support sales of a given manufacturer’s brand. But it is less clear why RPM actually compels retailers to invest the funds that are provided by an RPM-protected profit margin in supplying those services. Klein and Murphy maintain that in Telser’s theory, in which free riding must be defeated, RPM does not “create a direct incentive for retailers to supply desired services” (p. 266). They suggest that retailers may prefer using the funds that are supplied by an RPM-protected margin on one brand to promote the sale of unrelated products or “may merely take the additional money… and continue to free ride” (p. 266). This observation leads Klein and Murphy to question whether Telser’s theory of RPM actually explains why manufacturers adopt the practice. An alternative conclusion to be drawn from Klein and Murphy’s observation is that Telser’s theory requires an RPM-protected profit margin that makes it more profitable for retailers to provide services than not. Depending on the cost and effectiveness of the retailer services sought, it may be possible for a manufacturer to offer a margin that is sufficiently generous that its best use is the use that is intended by the manufacturer. Mathewson and Winter (1998, p. 67, n. 17) write that “[t]he amount of service provided increases not because each retailer has ‘more profit to spend on service’ as is often argued, but because the marginal benefit of providing service has increased.” It follows that if RPM is to be an effective mechanism for eliciting retailer services that promote the sale of a manufacturer’s product, then some of the net benefits created by those services must accrue to the retailers who provide them. Otherwise retailers would make more profit by free riding. This means that the manufacturer who implements RPM to induce downstream selling effort cannot capture all of the gains that RPM produces. This paper presents a model of manufacturer-retailer interactions that clarifies why, as a rule, retailers and manufacturers are joint beneficiaries of service-inducing RPM. The model identifies factors that determine how RPM-generated benefits are allocated between a manufacturer and its retailers. The paper then goes on to explore an alternative solution to manufacturers’ problem of inducing retailers to supply an efficient level of services, and compares this solution to RPM. In lieu of RPM or any other vertical restraint, manufacturers may use market share discounts (MSD) to create an incentive for retailers to perform services that support sales of the manufacturer’s brand. MSD policies are a form of non-linear pricing that offers retailers “loyalty discounts” or “loyalty rebates” that are conditional on the retailer’s sales of the manufacturer’s brand comprising a certain share of the retailer’s total sales of the product in question. MSD is not a substitute for RPM in every set of circumstances. The kinds of retailer services that can be elicited with MSD are those that have Telser’s first characteristic, but may or may not have the second characteristic. MSD is effective for summoning those retailer services that influence consumers individually, not collectively. For this reason, the analysis of RPM and MSD that follows is relevant to inducing services that fit Telser’s theory and Klein and Murphy’s theory. The analysis is not relevant to the quality certification services in Marvel and McCafferty’s theory.Footnote 5
 As will be seen, the outcomes and efficiency effects that Telser and Klein and Murphy attribute to RPM can be replicated and usually surpassed if manufacturers substitute MSD for RPM. To induce efficient retailer services in this framework, manufacturers’ RPM policy must concede to retailers some of the incremental profit that is created by those services. But if MSD is used in lieu of RPM or any other vertical restraint, manufacturers may induce those services and retain all of the incremental profit that they create.",
50.0,3.0,Review of Industrial Organization,12 July 2016,https://link.springer.com/article/10.1007/s11151-016-9535-y,Variety and the Cost of Search in Supermarket Retailing,May 2017,Timothy J. Richards,Stephen F. Hamilton,Koichi Yonezawa,Male,Male,Male,Male,"It is well understood that consumer search costs can allow retailers to exercise market power, even in homogenous product markets (Burdett and Judd 1983). Moreover, there is considerable evidence that search costs exist in numerous retail environments (Mehta et al. 2003), including online formats (Brynjolfsson and Smith 2000; Clay et al. 2001; Hong and Shum 2006; Moraga-González and Wildenbeest 2008; Kim et al. 2010; De los Santos et al. 2012). Yet virtually all the evidence on the relationship between consumer search and prices relies on evidence across stores for a single product, rather than from the multiproduct retail environments in which consumers routinely shop. In this paper, we consider the link between retail product variety and the cost of search in a multiproduct setting. We apply our model to a household-level data set of breakfast cereal purchases offered by two competing retailers. Consumers search among multiple brands of breakfast cereal, and retailers offer an assortment of items within the category that potentially complicates price comparison across retailers. Selecting among multiple products in a retailer’s product line complicates the process of consumer search, because consumers must search jointly for desired brands within a given store, for lower prices within a given store, and for lower prices across retail stores. We frame the relationship between consumer search and product variety as follows: If the cost of evaluating each item on the shelf is constant, then greater product variety increases the number of products that consumers must sift through, raising the total cost of search;Footnote 1 however, a wide array of brands also increases the likelihood that consumers find products that match their tastes (Oppewal and Koelemeijer 2005). Greater variety provision increases the odds that consumers find reasonable matches with tastes for a given amount of search, thereby reducing the cost of search. Existing empirical research on search costs typically considers consumer search as a single-product process, as when consumers search for a particular book title (Hong and Shum 2006; Wildenbeest 2011). Instead, we develop an empirical model of search that focuses on the effect of variety on search costs in a multi-product environment. Search is a joint process over products and prices in a nested empirical environment where consumers search over retail stores, and then over items within the selected retailer. It is essential to consider how retail prices respond to multiproduct search for at least two reasons: (1) consumers searching over brands are unlikely to know the exact price they would pay for a similar item elsewhere (Degeratu et al. 2000; Mojir et al. 2016); and (2) the set of comparable goods is likely to differ across retailers.Footnote 2
 Our analysis provides three novel contributions to the literature on consumer search. First, we decompose search costs into the cost of searching among items within a store, and the cost of searching among stores.Footnote 3 Second, we empirically examine the effect of increased product variety on search costs, and the consequent effects of “variety search” on the size of consumer consideration sets.Footnote 4 Third, we consider how multi-product search, or search among differentiated products within each store, responds to product variety. Product variety choices by retailers can also condition retailer market power by changing the cost of consumer search. We find that the cost of search among brands rises with variety at a given retailer. Thus, variety may reduce equilibrium search intensity, which provides retailers an additional source of market power (Cotterill 1986; Trindade 2015). We also distinguish between search costs among stores and search costs among brands within stores. We find greater product variety makes brand search more costly on the within-store margin, but reduces the cost of search among stores on the between-store margin. Our findings suggest that retailers may use variety as a competitive tool to reduce the cost of searching across stores, while at the same time facilitating a rise in prices on the within-store margin through increased search costs among brands. The increase in consumer search costs on the within-store margin provides retailers with incentives to raise prices on all brands in the product category, because the effect of greater sales of one brand on reduced sales of other brands is fully internalized by retailers on the within-store margin. The remainder of the paper is organized as follows: in the first section, we derive an econometric model of nested search in which consumers first choose stores, and then brands within stores, while stores compete in prices and assortments. In the second section, we describe the household-panel data used for the analysis, and explain why understanding search in consumer packaged good categories is critically important to not only the retailing function, but manufacturer conduct as well. We follow with a presentation of our estimation results, and discuss some of the primary implications of our findings, both for retailing, and for search more generally. The final section concludes, and suggests some research questions that remain.",11
50.0,3.0,Review of Industrial Organization,16 August 2016,https://link.springer.com/article/10.1007/s11151-016-9539-7,Collusion in Markets with Imperfect Price Information on Both Sides,May 2017,Christian Schultz,,,Male,Unknown,Unknown,Male,"The effect of market transparency on competition is much debated; see for instance OECD (2001). The EU Council finds that “The transparency of energy prices contributes to the creation and smooth operation of the internal energy market” and Council Directive 90/377/EEC specifies a procedure to improve the transparency of gas and electricity prices that are charged to industrial end-users; see Official Journal (1990). Similarly, it is a general perception that price comparison sites promote competition since they facilitate consumer search. On the other hand, many find that improved transparency on the producer side facilitates tacit collusion. For example, Albaek (1997) argue that the Danish Competition Authority’s decision to gather and publish firm-specific transaction prices for ready-mixed concrete made tacit collusion easier and led to increased prices. In general, competition authorities are well aware of the potential anti-competitive effects of price-disclosures; see, e.g., OECD (2012). It is an interesting and unresolved issue as to whether and when an increase in price transparency that affects both sides of the market at the same time is pro-competitive when tacit collusion is a concern. This paper investigates this issue. It assumes that only a fraction of consumers are informed about prices (as in Varian 1980) and that firms learn each other’s prices only with some probability. I find that in a homogeneous market an increase in transparency on both sides of the market is anti-competitive since here only the producer side matters. In a differentiated market, however, this is not so. In general, the result depends on how information proliferates on each side. For two standard information technologies, the result is unambiguous. In a sufficiently differentiated market, an increase in price transparency is pro-competitive, provided that firms are easier to inform than are consumers. From a competition policy perspective, the results imply that if tacit collusion is a relevant and major concern, then in homogeneous markets competition authorities and consumer agencies should not make efforts to improve price transparency as the producer-side effect dominates and it is anti-competitive. In (sufficiently) differentiated markets, however, under standard assumptions on information proliferation, the consumer side effects dominate and increased transparency on both sides is likely to be pro-competitive. The organization of the rest of the paper is the following. Section 2 reviews the related literature. Section 3 introduces the market. Section 4 characterizes the one period equilibrium. Section 5 introduces tacit collusion and the effects of transparency and discusses how sales monitoring as well as advertisement by the firms affect the results of the main model. Section 6 considers the case where transparency changes on both sides of the market simultaneously. Section 7 offers some concluding comments.",7
50.0,3.0,Review of Industrial Organization,22 July 2016,https://link.springer.com/article/10.1007/s11151-016-9532-1,Does Bundling Decrease the Probability of Switching Telecommunications Service Providers?,May 2017,Stephanie Lee,,,Female,Unknown,Unknown,Female,"The telecommunications industry has grown rapidly over the past decade, with telecommunications companies offering a wide variety of services including high-speed Internet, wireless phones, landline phones, and television services. In addition to offering each service separately, increasingly many companies bundle two or more separate services together and offer them at a discounted price.Footnote 1 Companies would want their existing subscribers to stay with the companies for as long as possible because the companies would profit from the subscribers’ repeated purchases. The bundling of services can potentially have an effect of locking-in existing subscribers and making it more difficult for them to switch their service provider.Footnote 2
 In this paper, I examine whether bundling makes individuals less likely to switch their service provider by increasing switching costs. In this context, the switching costs include the inconvenience that individuals who subscribed to bundled services would experience if they try to switch service providers (Greenstein and Prince 2014). For instance, if an individual has a wireless phone, a landline phone, and Internet all bundled together, then in order to switch to a different Internet service provider, he would not only have to change the Internet service provider, but would also have to change service plans for both the wireless phone and the landline phone. Such a process may be troublesome, so the individual may decide to stay with the current service provider. Using a South Korean survey dataset from the government agency, Korea Information Society Development Institute (KISDI), I find that Internet subscribers who previously bundled are about 17.4 percentage points less likely to switch their Internet service provider than those who did not bundle. The survey was specifically designed to understand the bundling of telecommunications services, and the dataset contains detailed information on individuals’ past and current bundle statuses. In my empirical analysis, I include a wide range of controls that includes demographic characteristics, company preferences, past service providers, and status-change years. The results are robust to additional controls and specifications. If individuals who purchased a service as a part of a bundle are systematically different from those who did not purchase it as a part of a bundle, the negative relationship between switching service providers and having bundled in the past may be driven by unobserved heterogeneity. In order further to address the potential selection problem, I use an endogenous treatment model (Heckman 1976, 1978), where whether individuals purchased services as a bundle in the past is modelled separately from whether individuals switched their service provider. The endogenous treatment model also consistently reveals that Internet subscribers who previously bundled are 25.2 percentage points less likely to switch their service provider. The finding that bundling reduces the probability of switching service providers can have important implications for market competitiveness and consumer welfare. However, when evaluating the overall welfare effects of bundling, the welfare gains from the discounts that individuals receive when purchasing a bundle should be carefully weighed against the welfare losses from increased switching costs.Footnote 3 Although estimating the overall welfare effects of bundling is beyond the scope of this paper, this paper contributes to the discussion on the implications of the bundling of telecommunications services by presenting robust empirical evidence that bundling reduces the probability of switching service providers.",10
50.0,3.0,Review of Industrial Organization,25 July 2016,https://link.springer.com/article/10.1007/s11151-016-9534-z,Firms’ Information Acquisition with Heterogeneous Consumers and Trend,May 2017,Yukiko Hirao,,,Female,Unknown,Unknown,Female,"Consumers can be capricious. They may also exhibit herd behavior. If a product is deemed fashionable, “everyone” wants to have it. Magazines and newspapers report what’s in and what’s out every season. Examples of products or shops for which fads are important include trendy restaurants, fashion and cosmetics, brand bags, pop music, movies, video games, and toys. In the presence of consumer herd behavior, sellers and producers would want to figure out what captures fickle consumers’ fancy. This paper considers firms’ product/location choices and incentives to acquire information in a market where fads and consumer herd behavior are important. (Product and location choices are used interchangeably in this paper.) I use the spatial model of horizontal product differentiation. In the standard model of horizontal product differentiation, firms try to locate where the demand is. In the absence of price competition, they choose the same location: The principle of minimal differentiation holds in the absence of price competition in a linear city model (Hotelling 1929).Footnote 1 When price competition is introduced, firms try to differentiate their products from each other in order to soften price competition; differentiation is maximal for quadratic transportation costs (d’Aspremont et al. 1979). The introduction of trend alters the spatial model of product differentiation in the following way: Consumers are heterogeneous in the sense that individual consumers are located at different points along a linear city, but are alike in their tendency to follow the trend: If a trend setter—an idol pop singer or a charismatic celebrity—claims that a certain location/product is trendy, then suddenly everyone thinks the item is hot, and the disutility of buying a product that is not “trendy” increases. Firms do not know where the exact trend spot will be when choosing their products/locations. Nor do consumers know the trend spot ex ante; the trend spot is announced randomly by the fickle trend setter. Hirao and Inoue (2004) showed that unless the trend spot is expected to be at or close to the extreme ends of a linear city, each firm chooses an interior location; the principle of maximal differentiation no longer holds in the presence of an uncertain trend spot. Second, this paper addresses the firms’ incentives to acquire information. It is shown that if given an opportunity, each firm would want to acquire information about the exact trend spot, regardless of whether or not its rival is informed: Information acquisition is a dominant strategy. Consumer surplus is also higher if both firms are informed, because the firms set lower prices on average if they are informed. Lastly, firms’ choices of product differentiation are excessive relative to the social optimum. Furthermore, the social planner would also choose to acquire information, as the exact knowledge of the trend spot lowers consumers’ average transportation costs. Many papers have been devoted to the study of the choice of quality and product diversity when consumers are imperfectly informed (see, e.g., Shapiro 1982; Wolinsky 1983), and price competition when consumers are uncertain about which firm sells which quality (e.g., Gabszewicz and Grilo 1992). This paper differs from the literature in that it is the firms rather than the consumers that are uninformed. There is also a literature on price experimentation by duopolistic firms. Gal-Or (1988) examines learning about cost. Mirman et al. (1994) study learning about market demand from observations of outputs. Aghion et al. (1993) and Harrington (1995) analyze price experimentation by duopolists to learn about the degree of product differentiation. This paper differs from these studies in that I deal with the choice of location in the presence of trend, but do not explicitly model the information acquisition process. The papers that analyze firms’ ex post incentives to reveal private information after receiving a signal include Okuno-Fujiwara, et al. (1990), Jansen (2008), Bagnoli and Watts (2015), and the accounting literature on information disclosure (e.g., Darrough (1993)). Instead of studying firms’ ex post incentives to disclose information, this paper addresses the welfare aspects of ex ante information acquisition in a horizontally differentiated model. The rest of the paper is organized as follows: Sect. 2 summarizes Hirao and Inoue’s (2004) analysis of firms’ location choices in the presence of an uncertain trend spot. Section 3 examines whether the firms would want to know the exact location of the trend spot in the first stage, as well as the effect of information acquisition on consumer surplus. The socially optimal location choice is also analyzed in Sect. 3. Section 4 briefly discusses two extensions: the differential disutility case, and corner solutions. Section 5 concludes.",
50.0,3.0,Review of Industrial Organization,14 July 2016,https://link.springer.com/article/10.1007/s11151-016-9533-0,Pricing Strategies with Costly Customer Arbitrage,May 2017,Hugh Sibly,,,Male,Unknown,Unknown,Male,"The literature has paid little attention to the consequences of unbundling. Alger (1999) also considers two customer types that can form collations (joint purchases that enable unbundling) but (unlike this paper) face zero transaction costs when making and dividing up joint purchases. Alger’s analysis focuses on a separating equilibrium. In contrast to the usual conclusions of mechanism design, Alger shows that joint purchases ensure that both consumer types receive strictly positive utility, the quantities in both types’ bundles are downwardly distorted, and the firm’s profit is lower. McManus (2001) shows that a firm that utilizes two-part tariffs may benefit from customer coalition formation, as between-customer arbitrage allows it to capture more consumer surplus as profit. Gans and King (2007) present a model in which the firm may utilize perfect price discrimination even when consumer arbitrage is possible. Their model’s assumptions differ from the present one in that: (1) each of the two customer types has only one unit of demand; and (2) the firm is uncertain as to the proportion of customers that are of a given type. Resale of a monopolist’s output has been considered in different contexts: Hammond (1987) considers a continuum economy in which goods are costlessly exchangeable. In general equilibrium goods must be sold at linear prices: the exchangeability undermines non-linear pricing. Aguirre and Espinosa (2004) consider the impact of consumer arbitrage in a linear city model with convex transportation cost. Calzolari and Pavan (2006) consider pricing mechanism for a monopolist that sells a durable good that can be resold in a secondary market. A considerable literature has developed with respect to auctions with resale (see for example Zheng 2002).",
50.0,3.0,Review of Industrial Organization,18 July 2016,https://link.springer.com/article/10.1007/s11151-016-9537-9,Price Discrimination in Input Markets and Quality Differentiation,May 2017,Chin-Sheng Chen,,,Unknown,Unknown,Unknown,Unknown,,
50.0,4.0,Review of Industrial Organization,02 May 2017,https://link.springer.com/article/10.1007/s11151-017-9577-9,Introduction to the RIO Special Issue on Net Neutrality,June 2017,Scott Wallsten,,,Male,Unknown,Unknown,Male,"The FCC and many other agencies make promoting competition a key component of their agenda. The Open Internet Order was no exception.Footnote 1 But there is no bright line between when an industry is “competitive” and when it is not. Amanda Delp and John Mayo review the history of regulatory thinking about the concept of competition. They discuss the development of the phrase “workable competition” in the mid-twentieth century and its evolution into “effective competition.” They offer a definition of effective competition that they believe would be useful for policymaking today. Unfortunately, they conclude, the FCC has thus far not consistently applied any particular definition of competition.",
50.0,4.0,Review of Industrial Organization,02 December 2016,https://link.springer.com/article/10.1007/s11151-016-9553-9,The Evolution of “Competition”: Lessons for 21st Century Telecommunications Policy,June 2017,Amanda B. Delp,John W. Mayo,,Female,Male,Unknown,Mix,,
50.0,4.0,Review of Industrial Organization,29 November 2016,https://link.springer.com/article/10.1007/s11151-016-9552-x,"Law, Social Welfare, and Net Neutrality",June 2017,Keith N. Hylton,,,Male,Unknown,Unknown,Male,"Consider a toll bridge with two types of users: ordinary cars, and heavy trucks. The difference between the two is that the heavy trucks are more costly to the bridge owner to service because they impose more congestion on bridge traffic. Congestion reduces the flow of traffic over the bridge, thereby increasing the average cost of the service. In addition, the trucks impose more depreciation (wear and tear) on the bridge. A profit-maximizing bridge owner would adopt a system of “discriminatory” Ramsey prices: the owner would charge a mark-up above user-specific marginal cost that is inversely related to the elasticity of user demand.Footnote 5 If we assume that the demand elasticity of cars is no greater than that of trucks—cars involve a larger percentage of leisure travelers who are more likely to seek cheaper though more time-consuming routes—the owner would charge higher prices to trucks than to cars. A regulatory authority that seeks to maximize welfare subject to a given level of profit that is promised to the bridge owner would also choose a system of discriminatory Ramsey prices, though not precisely the same as those chosen by the unregulated monopolist. The mark-up above user-specific marginal cost would be somewhat less, but would still vary inversely with the elasticity of user demand.Footnote 6
 Suppose, however, that the regulator requires the bridge owner to charge the same price to both cars and trucks. Under the conditions assumed, cars would, in effect, finance an internal subsidy for trucks. As a result, trucks would tend to use the bridge more than if the cross-subsidy were not present, and cars would use the bridge less than if the cross-subsidy were not present. The additional use by trucks would increase congestion costs and thereby increase the cost of the service and increase wear-and-tear costs. Charging cars and trucks different prices would permit the bridge owner to internalize to truck owners the additional costs that are imposed by the trucks. This, in turn, would discourage the trucks from excessive use—for example, from imposing a marginal cost of $1 on the bridge owner and other users when the marginal benefit to the truck owner from the particular use is only $0.50. A charge that varied with the intensity of the use would encourage truck owners to consider the congestion costs and the miles of wear and tear that are imposed in each relevant time period. The higher charge would also induce some truck owners to avoid the bridge in favor of another route. Over time, charges might encourage technological innovation toward trucks that carry the same freight while imposing lower congestion and depreciation costs. Charging separate prices allows the bridge owner to reduce congestion and depreciation costs, and pass those cost savings on to consumers in the form of lower general prices (for an equivalent unit of service) for use of the bridge, which, in turn, would increase the total consumption of the services that are offered by the bridge. Admittedly, in some cases the bridge owner might choose not to charge differential prices. Perhaps the differences in service costs are minor, and the administrative costs of differential pricing exceed the efficiency gains. Alternatively, perhaps trucks provide the greatest source of demand for new bridge capacity. Foresighted bridge owners would therefore be reluctant to tax a major source of industrial capacity growth. In these cases, the bridge owner may choose not to impose differential pricing even if completely free to do so. The bridge analogy seems to apply straightforwardly to the net neutrality problem: net neutrality is equivalent to prohibiting the bridge owner from using differential pricing, and generates similar costs. Some broadband-intensive providers of internet content, such as Netflix, would—in the absence of differential pricing—impose extraordinary congestion costs that would result in an internal subsidy from consumers of other internet services.Footnote 7 Hence, permitting the network owner to price differentially can and probably would enhance consumer welfare.Footnote 8 To the extent that heavy use of the service has a depreciation effect (electrical components suffer wear and tear from use), similar costs are imposed.Footnote 9
",2
50.0,4.0,Review of Industrial Organization,17 February 2017,https://link.springer.com/article/10.1007/s11151-017-9571-2,Some Simple Analytics of Vertically Linked Markets,June 2017,Joseph Farrell,,,Male,Unknown,Unknown,Male,"Net neutrality and a number of other economic questions share a basic vertical linkage structure that I discuss here: A firm, F, sells a product (internet access, in the case of net neutrality), but can also choose policies that affect competitive and other conditions for the use of that product, in ways that affect: (a) F’s follow-on profits; and (b) the value derived by its customers. For instance, an internet access provider might block some traffic, or charge content providers an access fee; or it might agree to cache one provider’s content but not another’s, or to exempt certain content from bandwidth limits. It might choose more—or less—protective privacy policies. In other markets, a seller of a photocopier or of a car might insist on doing certain repairs itself and charge high repair prices, or it might include repairs in a bundled warranty, or allow only authorized providers to perform repairs and enforce a variety of conditions in return for authorization. An online seller might treat shipping and handling as a profit center, or might offer free shipping. A credit card issuer might charge higher or lower late fees; an airline determines pricing and service quality for its baggage handling and in-flight meals. Such policies can differ both in pricing and in non-price ways. Some of these choices can naturally be viewed as hindering otherwise plausible competition in an “aftermarket,” but others (such as shipping policies or credit card fees) are less intuitively seen that way. If F were to choose a harmful or inefficient policy, would demand for its initial product (the photocopier, or the internet access itself) fall so much as to deter F, and would its likely price for that initial product fall so much as to compensate consumers? This article describes a highly simplified but helpful model in which to study those questions. The basic technique below is to use a change of variable to study how F’s profit-maximizing price for its access (or fore-market) product will compare, as between two policies that differ in their follow-on quasi-profits for F and in their direct impacts on the surplus that consumers will actually derive, and will expect to derive. Rather than analyze one policy at a time, I focus on the difference; indeed, it is analytically helpful below to focus on an infinitesimal change in policy that can then in principle be integrated up. For clarity, I first describe the basic idea in a particularly simple case, with no attempt even at the more-easily-achieved increases in generality.",2
50.0,4.0,Review of Industrial Organization,18 March 2017,https://link.springer.com/article/10.1007/s11151-017-9573-0,Wither U.S. Net Neutrality Regulation?,June 2017,Michael L. Katz,,,Male,Unknown,Unknown,Male,"In February 2015, the Federal Communications Commission (Commission) imposed its most recent round of regulations that govern the behavior of firms that provide broadband Internet access services (BIAS).Footnote 1 Figure 1 illustrates how the Commission conceptualizes BIAS provision. A BIAS provider is a platform that connects edge providers and end users. According to the Commission, end user “refers to any individual or entity that uses a broadband Internet access service,” and edge provider “refer[s] to content, application, service, and device providers, because they generally operate at the edge rather than the core of the network. These terms are not mutually exclusive.”Footnote 2
 A BIAS platform connects edge providers and end users A BIAS provider uses its “last mile” facilities to connect end users to its routers and, through them, to the rest of the Internet. Although not illustrated in Fig. 1, an edge provider can reach the BIAS provider’s platform either through direct connection to the BIAS provider’s network facilities or through an intermediary network. The Commission’s regulations generally constrain a BIAS provider’s treatment of edge providers. In particular, any BIAS provider must comply with the following conditionsFootnote 3: 
No Blocking: “A person engaged in the provision of broadband Internet access service, insofar as such person is so engaged, shall not block lawful content, applications, services, or non-harmful devices, subject to reasonable network management.”Footnote 4
 
No Throttling: “A person engaged in the provision of broadband Internet access service, insofar as such person is so engaged, shall not impair or degrade lawful Internet traffic on the basis of Internet content, application, or service, or use of a non-harmful device, subject to reasonable network management.”Footnote 5
 
No Access Charges Levied on Edge Providers: The “no-blocking rule prohibits broadband providers from charging edge providers a fee to avoid having the edge providers’ content, service, or application blocked from reaching the broadband provider’s end-user customer.”Footnote 6 Similar language is applied to fees to avoid throttling.Footnote 7
 
No Paid Prioritization: “A person engaged in the provision of broadband Internet access service, insofar as such person is so engaged, shall not engage in paid prioritization.”Footnote 8 Paid prioritization is defined as “the management of a broadband provider’s network to directly or indirectly favor some traffic over other traffic, including through use of techniques such as traffic shaping, prioritization, resource reservation, or other forms of preferential traffic management, either (a) in exchange for consideration (monetary or otherwise) from a third party, or (b) to benefit an affiliated entity.”Footnote 9 There is no exception to this provision for “reasonable network management.”Footnote 10
 
No-Unreasonable Interference/Disadvantage Standard: In addition to these specific rules, the order includes a catch-all ruleFootnote 11: 
Any person engaged in the provision of broadband Internet access service, insofar as such person is so engaged, shall not unreasonably interfere with or unreasonably disadvantage (i) end users’ ability to select, access, and use broadband Internet access service or the lawful Internet content, applications, services, or devices of their choice, or (ii) edge providers’ ability to make lawful content, applications, services, or devices available to end users. Reasonable network management shall not be considered a violation of this rule. These regulations are ostensibly intended protect and promote “openness” because—according to the Commission—“the Internet’s openness promotes innovation, investment, competition, free expression, and other national broadband goals.”Footnote 12 The Commission has also identified more-specific rationales, including promoting free speech and civic engagement by preventing BIAS providers from censoring edge providers,Footnote 13 and preventing exclusionary behavior whereby vertically integrated access providers “favor[] their own or affiliated content over other[,] third-party sources.”Footnote 14
 In this article, I explore some of what economics says about the relationship between the Commission’s stated objectives and the possible or likely effects of its current rules. I focus on the rationales for—and effects of—the ban on access charges that are levied on edge providers and the prohibition of paid prioritization. As will become evident, I conclude that the Commission has made several claims about the benefits of its policies that economics does not support. I also conclude that the open Internet regulations are likely to have several adverse and/or unintended consequences, including the stimulation of market trends that may undermine the regulations themselves. This article proceeds as follows: In Sect. 2, I examine several rationales that the Commission has put forth to justify its ban on BIAS providers’ charging edge providers for access to end users. I argue that the Commission’s various rationales (e.g., promoting free speech and creativity) generally lack limiting principles and do not justify the pricing ban. And I show that, although the Commission claims to be seeking to prevent exclusionary behavior, its rules may actually increase the incentive for a vertically integrated BIAS provider to engage in foreclosure against competing edge providers. In Sect. 3, I consider the Commission’s prohibition of paid prioritization, and I show that there is a substantial risk that it will be a Robinson–Patman Act for the twenty-first century (i.e., a policy that seeks to limit competition under the guise of preventing anticompetitive price discrimination).Footnote 15
 In Sect. 4, I argue that gaps in the current regulations—coupled with certain market developments (some of which will be hastened by the regulations themselves)—will render the rules increasingly ineffectual. Perhaps the most fundamental implication of this finding is that it reveals a substantial conflict between the Commission’s regulations and its stated objective of promoting consumer sovereignty and choice. In a brief concluding section, I argue that the current state of the regulations is unstable, and that proponents are likely to call for even more extensive and stringent regulations.",7
50.0,4.0,Review of Industrial Organization,16 November 2016,https://link.springer.com/article/10.1007/s11151-016-9551-y,The Post-Internet Order Broadband Sector: Lessons from the Pre-Open Internet Order Experience,June 2017,Timothy Brennan,,,Male,Unknown,Unknown,Male,"To understate the obvious, much has been written about “net neutrality” in general and the Federal Communications Commission’s (FCC’s) “Open Internet” Order issued in February of 2015 (Federal Communications Commission 2015, hereafter “OI 2015”). Some of that writing has applied industrial organization economics to potential consequences of vertical control by broadband providers in imperfectly competitive markets, including investment incentives and discrimination in prices and services, and ways to resolve network externalities (Farrell and Weiser 2003; Hermalin and Katz 2007; Choi and Kim 2010; Brennan 2011; Economides and Tåg 2012; Economides and Hermalin 2012; Litan and Singer 2014). OI 2015 paid specific attention to issues raised by price discrimination in intermediate good (input) markets (OI 2015 at ¶126, citing Katz 1987; Yoshida 2000). Many commentators have focused on the importance of fair and nondiscriminatory access to the Internet when innovation, social inclusion, and civic participation depend ever more on such access (Ganley and Allgrove 2006; Newman 2008; Lee and Wu 2009; Schewick 2012; Mehta 2015). Others have discussed whether net neutrality policies are consistent with the architecture and operation of the Internet (Yoo 2010; Claffy and Clark 2014). Most of the commentary has centered on a number of legal issues. Some of these are part of wider debates about the extent to which regulatory agencies can act without explicit Congressional direction. In this context the question is whether the FCC followed the procedural requirements of the Administrative Procedures ActFootnote 1 (raised in Pai 2015) or whether it acted within the boundaries of agency discretion established in the Chevron caseFootnote 2 and questioned recently in the Obamacare case King v. Burwell.Footnote 3 Other legal questions are narrower. Commenters have questioned whether the FCC established a record sufficient to reverse its 2005 classification of “broadband Internet access service” (BIAS) as an unregulated “information service”, or attempted to regulate the price BIAS providers charged content (“edge”) providers for delivery to end users without following appropriate regulatory processes, such as hearings to determine just and reasonable rates (Ford and Spiwak 2014a; Pai 2015). In the midst of all of this discussion, it may be useful to see what we can learn from past experience about what may happen if OI 2015 survives legal challenges. The record of alleged (rather than theoretical) conduct that the FCC cited in support of OI 2015 is meager. It cited two incidents that were challenged prior to issuing an Open Internet Order in 2010 (“2010 Order”), the reversal of which by the D.C. Circuit in 2014 precipitated OI 2015.Footnote 4 It mentioned two other incidents since then, making a total of four, which are listed below. The thinness of this record, especially since the reversed 2010 Order, is particularly noteworthy because of the contrast with the experience that followed the imposition of restrictions on the information service offerings of the regional Bell operating companies (RBOCs) after their 1982 divestiture from AT&T.Footnote 5 Between the time the divestiture went into effect in 1984 until the information service restrictions were eliminated in 1990 by the trial court on orders from the D.C. Circuit,Footnote 6 the RBOCs continually pushed against those restrictions by regularly seeking DOJ’s support for waivers to provide one information service or another.Footnote 7 The lesson from the divestiture experience is that regulated firms will push back against binding regulations to identify the true limits of the rules. The paucity of such efforts while the Open Internet Order of 2010 was binding—and when the FCC’s legal authority to “regulate the Internet” was in some doubtFootnote 8—suggests that the rule may not have been binding in the first place. This leads to the first main subject of this paper: Why might a regulation—that the FCC claimed was desperately needed—had been largely non-binding? This discussion will review why firms with market power retain incentives to provide levels of service that their customers want, and why (outside regulated contexts) discrimination in favor of affiliated service providers is likely to promote efficient price discrimination. These claims admittedly leave open the question of why Verizon challenged the FCC’s 2010 Internet Order. In general, large BIAS providers have claimed that their conduct conforms to the letter of that order (Comcast Corp. 2014). This implies that the concern could be that granting the FCC the level of authority that is implicit in the 2010 order would lead to regulations that would thwart envisioned future practices, such as direct delivery charges to content providers or “paid prioritization”: offering better delivery service such as greater speed or reduced latency for higher price. To shed light on these concerns, we can turn to specific instances when broadband providers engaged in conduct that the FCC challenged or has hinted that it might challenge under OI 2015. As noted above, the record identifies four such instances. Two were challenged before the FCC’s adoption of its 2010 Open Internet Order: Madison River telephone companies’ denial of ports to “voice over Internet protocol” (VoIP) providers, which was subject to an FCC order in 2005.Footnote 9
 Comcast’s deferral of delivery of BitTorrent traffic to off-peak delivery times, which was subject to an FCC order in 2008.Footnote 10
 OI 2015 alluded to two other incidents, although not as practices that would definitely be proscribed: AT&T’s refusal to provide FaceTime video calling via iPhones over its 3G network (OI 2015 at para. 96, n. 200, discussing conduct subject to complaint in 2012).Footnote 11
 Comcast and other major BIAS providers’ practice of charging Netflix for delivery of traffic, with service throttled until such payments were agreed upon (OI 2015, para. 196–201, esp. n. 505, referring to Netflix’s comments in 2014). Each of these examples provides cautionary lessons with regard to how OI 2015, if upheld largely in its entirety, might affect the development of the broadband sector. One interpretation of this history may be that OI 2015 stands on weak footing. This interpretation may be an artifact of the decision to frame the issue largely in terms of antitrust concepts. We therefore conclude with some rationales for the OI 2015 outside antitrust that may motivate both support for and opposition to the order. On the regulation side, perhaps BIAS providers are concerned that OI 2015 is the “camel’s nose under the tent“; a precursor to regulating retail internet rates or, similarly, requiring wholesale provision of access to broadband facilities at regulated rates to non-facilities based retailers. Another concern for both proponents and opponents of OI 2015 could be that BIAS providers are not profit maximizers and thus may not provide that quality of service that theory and evidence summarized here predict. Supporters of strong rules may also invoke non-economic social concerns that are related to the First Amendment or a sense that the Internet is primarily a global community to which everyone should have equal access without some having preferential treatment. Finally, one might speculate that the motive for Open Internet rules may involve how U.S. content providers are treated by BIAS providers in other countries.",5
50.0,4.0,Review of Industrial Organization,21 December 2016,https://link.springer.com/article/10.1007/s11151-016-9556-6,The Effect of Regulation on Broadband Markets: Evaluating the Empirical Evidence in the FCC’s 2015 “Open Internet” Order,June 2017,Thomas W. Hazlett,Joshua D. Wright,,Male,Male,Unknown,Male,"In 2015, U.S. telecoms regulators dramatically shifted a generation of public policy with respect to the Internet. Since the early 1960s, the Federal Communications Commission (FCC) promulgated rules that effectively quarantined traditional common carrier regulations to “basic” or “telecommunications” services. This approach allowed “enhanced” or “information” services to develop without the restrictions and obligations (including payments to the Universal Service Fund) that had traditionally been imposed under Title II of the 1934 Communications Act. The Commission argued this was to encourage investment and experimentation, and to bring innovative networks and applications into the marketplace. These evolving services are inherently difficult to regulate because the form, utility, and economic value of newly emerging technologies are uncertain. The policy of open markets for information services worked well, according to a 1999 FCC staff paper that reviewed the historical policy arc: The story of the Commission and its role in the development of the Internet highlight the benefits of the FCC’s early deregulatory efforts to facilitate the growth of computer applications offered over the public telecommunications network… [T]he Commission has acted in numerous ways to ensure that this incredible network of networks continued to develop unregulated… (Oxman 1999, p. 6). Specifically, the Commission excluded evolving data networks from common carriage rules that had been imposed on telephone carriers under Title II of the 1934 Communications Act. As the paper continued: When innovative new IP [Internet Protocol] communications services first entered the marketplace, the Commission had already firmly established its deregulatory approach. The FCC did not seek to apply legacy Title II regulations to the Internet as it developed and flourished – the first email programs in the 1970s, interactive newsgroups in the 1980s, and the World Wide Web in the 1990s all grew up over the nation’s telephone lines free from regulation (Oxman 1999, p. 24). The FCC veers sharply from this path in its 2015 Open Internet Order (OIO2). Instead of seeing regulatory forbearance as key to encouraging innovative activity to spur investment in networks and competition in services, the Commission now sees the emergent landscape as dotted with “gatekeepers” and “terminating monopolies” in the form of broadband Internet service providers (ISPs) (FCC 2015a, b, par. 80). The Order adopts “bright-line rules” that prohibit “paid prioritization,” where ISPs and content providers contract for quality-of-service levels that may include faster delivery to end users. It also bans “blocking” access for end users (restricting the content of certain websites) and “throttling” access for end users (partially restricting the content of certain websites). These rules apply to “both fixed and mobile broadband” ISPs (FCC 2015a, b, par. 110). The blocking and throttling bans are conditional on the content in question being “legal” and “non-harmful” (Id., par. 115), and ISPs are still permitted to engage in “reasonable network management” (Id., par. 112). This presumably allows the blocking of malware, viruses, spam, and communications traffic seen as highly deleterious to subscribers. The 2015 rules were controversial.Footnote 1 A 2016 verdict of the U.S. Court of Appeals upheld the rules on a 2–1 vote (USTA 2016). The opinion generated a vigorous dissent (USTA Dissent 2016). The new rules stem from “network neutrality” regulations that were long championed (e.g., Wu and Yoo 2007) and were twice imposed in slightly different forms by the FCC. A federal court overturned the 2007 Comcast Order in 2010 (Comcast
2010). The same court set aside the 2010 Open Internet Order (OIO1) in 2014 (Verizon
2014). The Commission’s 2015 OIO2 rulemaking put forward similar rules to those adopted in OIO1, but offered a new legal justification for re-classifying broadband networks as “telecommunications services,” therefore subjecting them to the Title II common carrier obligations. The justification offered for this reform—referenced by both commentators and FCC members as “the nuclear option” (FCC 2015a, b, p. 389)—was premised on economic theory and evidence. The Administrative Procedures Act requires that a regulatory commission “examine the relevant data and articulate a satisfactory explanation for its action including a ‘rational connection between the facts found and the choice made.’”Footnote 2
 The argument that drives network neutrality rules is that broadband ISPs enjoy endemic market power. They are “terminating access monopolies”Footnote 3 that can impose inefficient restrictions on their subscribers. In particular, ISPs can control prices or otherwise regulate the flow of services that are available from complementary producers over the ISP’s broadband network—a form of vertical integration by contract. If undertaken for anti-competitive purpose and achieving anti-competitive effect, it would be deemed vertical foreclosure in economics (or under antitrust law). Of course, vertical integration (including coordination between input suppliers and their downstream partners) is ubiquitous throughout the economy and in most cases is overwhelmingly efficient and provides net benefits to consumers (Cooper et al. 2005; Lafontaine and Slade 2007). “The concern,” writes Owen (2011, p. 381), “is with vertical integration that may give firms both the opportunity (through denial of access or price discrimination) and incentive (increased profit) to restrict competition.” To differentiate pro-competitive from anti-competitive vertical arrangements, antitrust law uses a “rule of reason” adjudication framework that weighs costs and benefits, and recognizes possible losses from enforcement errors that go in either direction (Manne and Wright 2010). In this analysis, market power is generally a necessary but not sufficient condition for vertical conduct to result in competitive harm. It is both necessary and sufficient, as a matter of antitrust economics and law, that consumer harms with regard to conduct are in evidence, and that the expected social gains from the proffered legal remedy exceeds its risks. This implies that the existence of an intermediary—also known as a “gatekeeper”—resolves the policy question. It is important to show that harms result, given market structure and firm behavior, and that policies to create alternative outcomes create consumer welfare gains. Evidence about how the practices that are targeted (blocking, throttling, paid prioritization) by the FCC’s Order impact market outcomes is essential to establishing a credible case for implementing new rules. Former FCC Chief Economist Gerald Faulhaber writes that “the economics literature does not support net neutrality (absent empirical evidence demonstrating actual bad behavior)” (Faulhaber 2015, p. 51). He specifically notes “[e]mpirical analysis is required to determine, in any particular circumstance, whether paid prioritization is helpful or harmful. No such evidence has been produced, either in the literature or in the FCC order” (Id., p. 52). A key issue on which the FCC does opine relates to the impact of common carrier (Title II) regulation on broadband investment. “Many experts have suggested that Title II regulation will dampen investment in both networks and edge providers,” notes Faulhaber. The FCC “dismisses this, claiming that investment in wireless networks has held up despite the announcement of Title II. That is just happy talk that supports similar language in the new order” (Id., p. 53). We shall examine the claim—or “happy talk”—in more detail below. We here note that the Commission’s 2015 Open Internet Order does not include references to any empirical studies that evaluate, let alone establish, the empirical propositions that the agency advances as justification for new Title II rules. Listing circumstances in which firms may possibly resort to vertical foreclosure is not the same as offering evidence that it has happened, will happen in the future, or would be successfully countered by rules designed to offset the anticipated action. The consumer harm that Title II hopes to prevent is still largely speculative, as is the efficacy of Title II regulations as a potential remedy. Commissioner Pai described the FCC’s Title II decision as “a solution that wouldn’t work to a problem that doesn’t exist” (Pai 2016, p. 1). In 2010, the FCC offered that, “we… disagree that we have acted on ‘speculative harms alone,’” (FCC 2010, par. 23, fn. 60). The Commission cited one paper to refute the disputed charge: Goolsbee (2007). “The Goolsbee Study provides empirical evidence that cable providers have acted in the past on anticompetitive incentives to foreclose rivals, supporting our concern that these and other broadband providers would act on analogous incentives in the future.” The FCC’s sole citation is rich with implication. In fact, the paper examined vertical integration in cable TV programming and distribution markets, which suggests that the Commission could not find any economic study to back up its empirical claims with respect to the broadband market. Moreover, Goolsbee explicitly warned against using its econometric results to infer that anticompetitive discrimination had occurred or advanced as the basis for formulating public policy: The statistical exercise was “obviously meant only to be suggestive” (Goolsbee 2007, p. 30). But most fundamentally, the actual evidence in the analysis does not suggest that cable TV operators engaged in vertical foreclosure. Indeed, Goolsbee’s empirical results indicate that, on average, operators have discriminated against the programming services that they owned—the opposite of vertical foreclosure (Hazlett and Wright 2012, pp. 813–834). This paradoxical outcome begs explanation, supplied in an examination of the model employed. At bottom, the FCC’s interpretation of this research is wholly inappropriate as support for the policy reforms advanced. The FCC’s 2015 Net Neutrality Order does not respond to criticism of its exclusive reliance on the Goolsbee study to establish that vertical foreclosure is a phenomenon in broadband markets worthy of regulation; nor does it establish that broadband markets exhibit any of the traditional forms of market failure that may in some circumstances require regulation (Wright 2015, pp. 5–8). Rather, the 2015 Order eliminates any reference to Goolsbee (2007) and does not cite any cost-benefit analysis of U.S. broadband markets to justify the Commission’s reforms. The Order does reference several theory articles, however, written between 1983 and 2000, for the proposition that price discrimination may be used in an anticompetitive strategy (FCC 2015a, b, par. 126).Footnote 4 The theory is misinterpreted, as one of the cited authors has explained (Katz 2016). More deeply, the theoretical possibility of such behavior is not at issue. The question is whether that theory fits the facts of the existing broadband market, and whether the effective way to counter such strategies is via ex ante rules for network neutrality via Title II regulation. The lack of systematic empirical research on vertical foreclosure, and on the effectiveness of regulation to counter it, makes the FCC’s assertions regarding the broadband marketplace all the more crucial. We evaluate four of the Commission’s claims: Capital investments made by broadband ISPs went up following the imposition of the 2010 network neutrality rules. FCC wireless auction No. 97, which registered relatively high bids for AWS-3 licenses in January 2015, demonstrated that there was no depressing effect on network investment due to FCC network neutrality rules. Since the 1980s, mobile markets have developed under “light touch common carrier” regulation that establishes the pro-efficiency basis of such rules, which are said to be analogous to the FCC’s 2015 OIO2 Title II re-classification (for fixed and wireless broadband services). The application of Title II rules to DSL and Fiber-to-the-Premises networks encouraged broadband deployment. We evaluate these four empirical assertions one at a time, and then provide a summary of arguments in the Conclusion. In short, each of the claims is dubious. In total, the facts that are cited by the Commission provide no plausible case for Title II regulation of U.S. broadband networks. Four years ago, the Commission adopted open Internet rules to protect and promote the “virtuous cycle” that drives innovation and investment on the Internet… In the years that those rules were in place, significant investment and groundbreaking innovation continued to define the broadband marketplace. For example, according to US Telecom, broadband providers invested $212 billion in the three years following adoption of the rules—from 2011 to 2013—more than in any three-year period since 2002. Likewise, innovation at the edge moves forward unabated (FCC 2015a, par. 2). 
The issue as to whether Title II classification for broadband networks produces consumer gains is intimately connected to the capital investment (capex) question. Should rules on networks entice immediate gains—expanding access for end users to more Internet content—but undercut long-run investment incentives, the purported benefits could be illusory. The capex issue has been addressed in the net neutrality policy debate by no less than the U.S. Department of Justice (DOJ) Antitrust Division. In 2010, it advised the FCC to tread lightly in applying new regulatory rules so as not to reduce incentives for new network investment: Although enacting some form of regulation to prevent certain providers from exercising monopoly power may be tempting with regard to… areas [that are served by only one or two broadband providers], care must be taken to avoid stifling the infrastructure needed to expand broadband access. In particular, price regulation would be appropriate only where necessary to protect consumers from the exercise of monopoly… (DOJ 2010, p. 28). The admonition from the DOJ is not historically surprising. The long-stated rationale for deregulating “information services” is that traditional common carriage rules suppress their emergence without providing sufficient offsetting benefits (Kellogg et al. 1999). Hence, it is important that the Commission, in advancing new rules in the 2015 Open Internet Order (OIO2), offers an empirical assessment that purports to establish the opposite causal relationship. In the passage that was quoted above, it connects the 2010 Open Internet Order (OIO1) (unveiled at the very end of the year) with a positive response in ISP capex: the highest level of investment, over 2011–2013, for any such period in a decade. The Commission connects this increase to the announced rules, which are asserted to have supported a “virtuous circle.” The FCC’s proposed test is theoretically weak. While the FCC did adopt net neutrality rules at the end of 2010, the rules were immediately challenged in federal court. Complaints under the rules were tabled until the litigation was decided. Ultimately, and not particularly surprisingly, the D.C. Circuit overturned the rules (Verizon 2014). So, the idea that the market had a strong reaction to the 2010 rules, and adjusted according to new expectations—either with respect to a “virtuous circle” or added enforcement costs—is debatable. Nonetheless, the Commission’s empirical approach is to observe, without any trend or other adjustment, capital invested by ISPs in one three-year period (2011–2013). It concludes that the level of capex in this period is historically high. However, by simply adjusting nominal outlays by the GDP Deflator, a standard measure of economy-wide inflation, the asserted result vanishes. Of sixteen data points, rolling three-year averages from 1996–1998 through 2011–2013, 12 values for capex are higher than the 2011–2013 figure, only three values lower (Fig. 1).Footnote 5
 3-Year rolling average broadband capex (2014 dollars, bil.) Two more simple adjustments further reveal how the FCC’s empirical assessment is unwarranted—calculating annual ISP capex spending as a ratio to U.S. GDP and then as a ratio to the S&P500 Index. These measures incorporate changes that account for overall economic growth, on the one hand, and for the change in capital values (throughout the economy), on the other. In Figs. 2 and 3 it appears that the 2011–2013 period was not associated with any notable uptick in trend insofar as the “virtuous circle” of Internet investment is concerned. ISP Capex/GDP Capex/S&P500 index (×100) These impressions are supported by running simple regressions to calibrate the change in capex over the 2011–2013 period (using 3-year moving averages). As shown in Table 1, there are no statistically significant changes in ISP investment post-2010. And, using the FCC’s unadjusted model, the relationship that is associated with the 2011–2013 period is—while not statistically significant—negative. The best that can be said for the FCC’s analysis is that it is uncompelling. Even the bare bones framework that is adopted by the FCC shows no positive reaction of ISP capex following the 2010 net neutrality rules.",11
50.0,4.0,Review of Industrial Organization,08 December 2016,https://link.springer.com/article/10.1007/s11151-016-9555-7,Avoiding the Pitfalls of Net Uniformity: Zero Rating and Nondiscrimination,June 2017,Christopher S. Yoo,,,Male,Unknown,Unknown,Male,"The European Union’s 2015 adoption of its Single Telecom Market regulation and the U.S. court’s 2016 decision that upheld the Federal Communications Commission’s (FCC’s) 2015 Open Internet Order [U.S. Telecom Association v. FCC, 825 F.3d 674 (D.C. Cir. 2016)] marked turning points in the decade-long controversy over network neutrality. These decisions moved the debate past whether to mandate network neutrality and instead focused it on how to enforce network neutrality. Regulators who implement network neutrality have focused a great deal of attention on a practice known as “zero rating”: Zero-rating plans permit subscribers to access certain content or applications without having that traffic count against the subscribers’ data cap. The most prominent examples in the U.S. are T-Mobile’s Music Freedom and Binge On programs, which permit qualifying subscribers to stream unlimited amounts of music and video without paying any additional charges. Other Internet service providers (ISPs) are applying zero rating to popular applications such as Facebook, WhatsApp, and Wikipedia. Zero rating represents the most prominent example of a practice known as service differentiation, in which providers offer access to only part of the full range of Internet services (such as email-only plans) or provide access to a subset of services on a preferred basis. The current debate has not fully appreciated how service differentiation can benefit consumers and encourage Internet adoption. On the demand-side, service differentiation addresses what surveys reveal is the major obstacle to adoption—that the majority of nonadopters do not see the value of an Internet connection—by providing preferential access to the content and services that particular users value the most. Service differentiation also reflects the growing heterogeneity of the demands that end users are placing on the network and can enable ISPs to create consumer value by providing offerings that are better tailored to what consumers want. As customer preferences become increasingly heterogeneous, ISPs naturally diversify their service offerings to meet that demand. On the supply-side, service differentiation promotes competition by broadening the ways that ISPs can compete. Offering service-specific plans that are targeted at key subsegments of the population can promote entry even by firms that suffer from disadvantages in cost and network size. Conversely, prohibiting service differentiation would limit the dimensions of competition to price and network size; these are considerations that tend to favor the largest players, and these considerations risk imposing a government-mandated net uniformity. Service differentiation also responds to the technical realities of mobile broadband by reflecting variations in the costs of providing different services and supporting every application over every connection. A review of the policies that different countries around the world have adopted with respect to service differentiation confirms these insights. Although press reports claim that as many as a dozen countries have banned zero rating (e.g., Guha and Aulakh 2015), a close analysis reveals that only one country—India—has actually taken that step. As described in greater detail below, six countries have pursued enforcement actions against zero rating plans. Of these, four clearly did not categorically ban the practice, and a fifth may not have either and has likely been overridden by subsequent legislation that has been enacted by the European Union. Enforcement authorities’ actions tend to apply to plans that provide easier access to proprietary services than to service differentiation plans that are based on services that are provided by third parties. They have also tended to target smaller providers that attempted to challenge well-entrenched incumbents. Generally accepted principles of competition policy suggest that ex ante prohibition of service differentiation would be inappropriate. The circumstances that are identified by the theoretical literature under which vertical integration or coordination between content/services and conduit can harm consumers are stylized and limited. Moreover, surveys of the empirical literature indicate that vertical integration is usually benign or beneficial and conclude that consumers would be better off if regulators did not bar vertical restraints. Competition policy has long recognized that ex ante prohibition is appropriate only for well-established and well-understood practices. When practices are novel and in a state of flux, as with service differentiation, consumer welfare and innovation would be better served by an ex post regime that places the burden on the party that challenges the practice to provide empirical evidence of harm. The U.S. Supreme Court’s antitrust jurisprudence also helps identify factors that militate against liability, such as lack of market power, nonexclusivity, and nonproprietary services.",10
50.0,4.0,Review of Industrial Organization,03 December 2016,https://link.springer.com/article/10.1007/s11151-016-9554-8,The Digital Divide and Other Economic Considerations for Network Neutrality,June 2017,Michelle Connolly,Clement Lee,Renhao Tan,Female,Male,Unknown,Mix,,
50.0,4.0,Review of Industrial Organization,11 February 2017,https://link.springer.com/article/10.1007/s11151-016-9557-5,The FCC’s Net Neutrality Decision and Stock Prices,June 2017,Robert W. Crandall,,,Male,Unknown,Unknown,Male,"The process of developing the new net neutrality rules was driven in large part by political considerations. For more than a decade, the FCC had pursued a policy of regulatory forbearance towards broadband Internet services; the Commission chose to rely on platform competition between (fixed) telecom carriers, cable companies, and—more recently—wireless carriers. In this largely unregulated environment, telecommunications and cable television companies invested heavily in facilities that delivered ever-faster speeds over copper wires, coaxial cable, and the spectrum (through wireless devices). But as the cable and telecom industries consolidated, a political concern arose that the large cable and telecom companies—the internet service providers (ISPs)—might begin to exercise market power by denying access or providing inferior access to content providers, particularly if the ISPs themselves owned competing content.Footnote 3 This concern was not buttressed with any empirical analyses that demonstrated such discrimination or denial of access. Until 2010, the FCC relied on a simple “Internet Policy Statement” to promote an open Internet. However, in June 2010 the Commission moved a step closer to formal regulation by issuing an “Open Internet Order” that formalized the Policy Statement’s goals of no blocking of content, no unreasonable discrimination, and full transparency for ISPs; but the Order stopped short of imposing full common carrier regulation under Title II of the Communications Act. Subsequently, Verizon challenged the Commission’s Order and won a pyrrhic victory at the U.S. Court of Appeals in 2014.Footnote 4 The Court found that the FCC could not impose anti-blocking and non-discrimination rules on ISPs because the ISPs had not been categorized as common carriers. However, the Court appeared to be sympathetic with these policy goals and even suggested how the FCC might implement them in a manner that was consistent with the requirements of the Communications Act. The FCC then issued a new Notice of Proposed Rulemaking, outlining various potential approaches to implementing a policy of net neutrality.Footnote 5
 Over the next few months, the Commission and Chairman Tom Wheeler weighed whether to move towards formal regulation under Title II of the Federal Communications Act or simply utilize the Section 706 “forbearance” process to deal with various complaints about unfair practices by ISPs. At the same time, substantial political pressures began to weigh on the Commission, as advocates launched extensive and intensive lobbying campaigns. As the Commission approached its final decision, President Obama weighed in. On November 10, 2014, the President unexpectedly intervened in this regulatory process by issuing a statement that urged Chairman Wheeler and the “independent” FCC to use Title II to regulate broadband ISPs.Footnote 6 The President’s surprising statement spawned a barrage of new comments in the FCC’s rulemaking process, which gave Chairman Wheeler sufficient support to follow the President’s recommendation three and one-half months later. It is not unusual for an independent regulatory commission to be influenced by political pressures—particularly when the stakes are large. And the stakes were very large in this case. The delivery of a variety of content over the Internet threatens to wreak havoc in the media, cable television, and telecommunications industries. As an increasing volume of video content is made available for “streaming” over high-speed broadband connections, the traditional linear model of distributing television programming over cable television, telephone-company fiber-optic networks, or high powered satellites is facing a major challenge. The companies that are involved in this process—including newcomers such as Amazon, Apple, and Google—are among the largest companies in the U.S. economy. Traditional media companies—such as Disney, Time Warner, 21st Century Fox, CBS and Viacom—had a combined enterprise value approaching $500 billion at the beginning of 2015. The ISPs—cable companies, erstwhile “telephone” companies, and satellite carriers—had combined enterprise values of at least $700 billion. And the new media companies—such as Facebook, Google, Netflix, and many others—had a combined value of at least $700 billion. Surely, one has to add Apple’s $700 billion market value to this mix, given its interest in media content, its nascent Apple TV service, and the importance of the iPhone in the wireless broadband sector. Thus, in the aggregate the companies that were affected in a major way by the FCC’s lurch back to regulation had a value that approached $2 trillion, or about one-twelfth of the value of all listed stocks in the United States. A major regulatory decision in this environment—particularly one that reverses more than a decade of regulatory forbearance—would surely attract notice and likely reverberate through the capital markets.",3
51.0,1.0,Review of Industrial Organization,10 August 2016,https://link.springer.com/article/10.1007/s11151-016-9538-8,Agency and Incentives: Vertical Integration in the Mortgage Foreclosure Industry,August 2017,Lauren Lambie-Hanson,Timothy Lambie-Hanson,,,Male,Unknown,Mix,,
51.0,1.0,Review of Industrial Organization,20 August 2016,https://link.springer.com/article/10.1007/s11151-016-9540-1,How Much Vertical Integration? Contractual Choice and Public–Private Partnerships in the United States,August 2017,Daniel Albalate,Germà Bel,R. Richard Geddes,Male,Unknown,Unknown,Male,"The term public–private partnership, or PPP, is often used to describe long-term, relational contracts between a public-sector sponsor and a private partner that are created to deliver large infrastructure projects across a range of economic sectors. PPPs have been used for decades in many countries. Popular sectors include water, transport, and energy.Footnote 1 PPP use in the United States is rising rapidly, with many U.S. states’ passing laws that facilitate such a contractual approach. We here focus on the structure of PPPs and the bundling of various aspects of project delivery. We do so because bundling, together with risk transfer, is the critical characteristic that distinguishes PPPs from traditional procurement (Albalate 2014).Footnote 2 We examine the combining (or vertical integration) of construction and operational elements of project delivery versus bundling within each element separately. Vertical integration in PPPs is important because many anticipated benefits from PPPs rely on synergies between construction and operation. Understanding why governments that engage in PPPs choose to bundle construction and operations—or to deliver them separately—is important for understanding the social benefits of PPPs more broadly. We have assembled a large data set on PPP projects with the use of the International Major Projects database that is collected by the Public Works Financing (PWF) monthly newsletter. The PWF database includes the universe of North American PPP projects. PWF requests detailed PPP project information once per year from the major PPP project developers active in the North American market.Footnote 3 These companies have strong incentives to comply with that request because the influential annual PWF ranking of the world’s top transportation infrastructure developers is based on information reported in the database.Footnote 4
PWF then cross checks that information with the Transportation Infrastructure Financing and Innovation Act (TIFIA) loan database, as well as several other sources to ensure completeness and accuracy. We use data on 553 U.S. PPP projects that were authorized between 1985 and 2013.Footnote 5 We model the determinants of vertical integration decisions in PPPs with the use of multinomial logistic regression. We include financial, economic and political variables. We find that certain financial variables are important drivers of that choice, while political variables have little influence. Economic-sector variables help predict the bundling decision and serve as proxies for transaction costs, externalities, and commercial risk.",10
51.0,1.0,Review of Industrial Organization,22 September 2016,https://link.springer.com/article/10.1007/s11151-016-9544-x,The Nonlinear Effects of Market Structure on Service Quality: Evidence from the U.S. Airline Industry,August 2017,Kang Hua Cao,Betty Krier,Jerrod Sharpe,,Female,Male,Mix,,
51.0,1.0,Review of Industrial Organization,17 September 2016,https://link.springer.com/article/10.1007/s11151-016-9542-z,IP-for-IP or Cash-for-IP? R&D Competition and the Market for Technology,August 2017,Patrick Herbst,Eric Jahn,,Male,Male,Unknown,Male,"What type of “currency” do firms use when they trade intellectual property (IP)? Looking at the empirical evidence, it is not obvious that cash is the only method of payment. Rather, it seems that firms pay with their own IP in exchange for other firms’ technology. This means of exchange is particularly evident in the discussion of so-called cross-licensing agreements. Put simply, cross-licensing implies granting reciprocal access to IP or patents by firms. Evidence suggests that cross-licensing is more than a simple, reciprocal seller-buyer-relation but is part of a common standard for technology transfer. For example, Anand and Khanna (2000) report that within the US manufacturing industry, 12.6 % of licensing agreements are cross-licensing contracts.Footnote 1 Cohen et al. (2000) observe that among the US manufacturing firms surveyed, 33.5 % use patents on product innovations in cross-licensing. Limiting trade in technology to reciprocal exchange can also be part of a long-term strategy. Intel’s formerly proclaimed “IP-for-IP” strategy is a case in point. This strategy involved that Intel granted access to its IP only to firms who gave Intel access to their own IP (Shapiro 2001, 2004). Cohen et al. (2000, p. 29) report that survey “[r]espondents noted that firms are reluctant to sell their technology, but are willing to trade it only to firms that have valuable technology (intellectual property) to use as currency”. In this paper, we suggest that the means of exchange in the market for technology affect the R&D activities of firms. We show that in an environment with trade restrictions (IP-for-IP/cross-licensing, or even no trade in technology) firm profits might increase as overinvestment in R&D is decreased. However, these trading restrictions come at the cost of forgone gains from trade when IP is distributed asymmetrically across firms. By providing a model of the trade-offs involved, our analysis shows that an IP-for-IP environment can be beneficial for firms as it balances R&D overinvestment against gains from trade in technology. The paper is organized as follows: Sect. 2 discusses the related literature. Section 3 lays out our general approach. Section 4 introduces the model. Section 5 analyzes R&D competition under free trade, IP-for-IP, and no trade, and compares the outcomes under these environments when patent complementarities are present and when they are absent. Section 6 introduces specific extensions to the model and discusses policy implications. Section 7 concludes.",
51.0,1.0,Review of Industrial Organization,26 August 2016,https://link.springer.com/article/10.1007/s11151-016-9541-0,Informative Advertising in a Mixed Oligopoly,August 2017,Shaohua Han,John S. Heywood,Guangliang Ye,Unknown,Male,Unknown,Male,"Advertising exposure has doubled in a generation, with the typical US urban dweller exposed to nearly 5000 ads per day (Story 2007). Economists study the consequences of this advertising for consumers, firms and social welfare (for an excellent review see Bagwell 2007). Yet, little research recognizes that publicly (i.e., government) owned firms actively advertise. Economists often model public firms as maximizing social welfare, which raises interesting questions about their ability to “regulate through participation” in markets with advertising (Merrill and Schneider 1966). We model a mixed duopoly in which a welfare maximizing public firm competes against a profit maximizing private firm.Footnote 1 We assume informative advertising (Stigler 1961), so that the public firm advertises in order to increase output and thus increase welfare. We show that total advertising with the public firm often, but not always, exceeds that in a private duopoly. Critically, whenever advertising does exceed that in the private duopoly, welfare is actually lower and so could be improved by privatization. This emerges because increased advertising is associated with a shift in production toward the inefficient public firm and also because advertising is inefficiently divided between the two firms. In sum, the case for a public firm appears weaker in a market with advertising than without it. The United States Postal Service spent $147 million advertising its package service in 2011 when competing with UPS and FedEx (USPS 2013). Similarly, German, Japanese, and Canadian public banks advertise when competing with private banks; and public airlines advertise extensively when competing against private airlines.Footnote 2 Yet Matsumura and Sunada (2013) present the only study of the advertising by a welfare-maximizing public firm of which we are aware. They consider a variant of the model by Glaeser and Ujhelyi (2010) in which there exist misleading (rather than informative) advertisements and also negative ads that cancel the misleading ads. They show that the welfare maximizing public firm continues to engage in misleading advertisements and that the extent of advertising varies with the number of firms. In what follows, we place a canonical informative advertising model in a mixed duopoly. We isolate when advertising exceeds that in private oligopoly and when welfare is lower. We then elaborate on the model to assume that one firm can partially free-ride on the advertising of its rival. We also consider the case with a foreign private firm; and finally we illustrate how Bertrand competition in a market of imperfect substitutes alters our results. In all cases the public firm is often associated with both greater total advertising and a reduction in social welfare.",7
51.0,1.0,Review of Industrial Organization,22 March 2017,https://link.springer.com/article/10.1007/s11151-017-9575-y,Optimal Product Placement,August 2017,Chia-Ling Hsu,Rafael Matta,Takeharu Sogo,Unknown,Male,Unknown,Male,"Many markets with intermediaries, such as online software markets, match buyers to sellers. It is often costly for buyers to locate the ones they most want, and this can affect the pricing policies of the sellers. Accordingly, intermediaries can increase sales by optimally choosing how to display their relevant products: e.g., to put one product on the front page and put another on the second page on the menu; or display one product close to the door and display another far from the door in the store. We model the interactions between two sellers, a unit continuum of buyers, and a platform intermediary, in which any extensive search for desired products is costly.Footnote 1 The sellers produce vertically differentiated products. The platform, which earns a fixed proportion of the profits from the sellers, selects which products to display on the front page; and the remaining products, if any, are displayed on the second page. We argue that the platform strategically decides to delegate products, possibly the better ones, to the second page to soften price competition, thereby extracting more buyer surplus. In our main model with heterogeneous search costs across buyers, buyers can observe both the prices and qualities of both products, but cannot buy the second-page product before visiting the second page. We find that the shape of the distribution of search costs is a key determinant for the platform’s optimal arrangement of the products. For a large class of distributions of search costs, the platform hides the better product, which goes against the common findings in the literature. We further extend our model to incorporate market segmentation: one form of horizontal differentiation. We find that the individual taste difference across products undermines the incentive to obfuscate the access to some products. Thus, when tastes are sufficiently heterogeneous, our previous prediction can be reversed: The platform shifts the focus from reducing price competition to targeting a greater audience. As an illustration to our model, consider the market for apps for smartphones. According to Gartner (2013), the market for online mobile applications reached 64 billion downloads in 2012, generating over $18 billion in revenue. Table 1 indicates that the platforms—App Store, Google Play, BlackBerry World, and Windows Phone Store—receive an approximately fixed fraction of seller revenues.Footnote 2 Thus, it would be reasonable to think that they are interested in maximizing the sum of the sellers’ revenues. In the App Store, buyers usually make their purchase decisions from the products that are available on the front page of the platform. Hafner (2010) describes a typical consumer’s behavior: “A survey of iPhones, iPod Touch and Android users... found that people discover apps most often by browsing app stores. And even though the iTunes store is bloated with offerings, people tend to gravitate to the most popular.” Platforms seem to have the technology (e.g., dynamic content loading) to display more products on the front page so that buyers can find products of interest to them without incurring additional search costs. The question is whether a platform wants to display more products on the front page and—if it chooses not to show more products on the front page—which products, of high or low quality, it wants to delegate to other pages. Broadly speaking, our study contributes to the vast literature on oligopoly theory that deals with ways to soften competition.Footnote 3 Hotelling (1929) was the first to model this issue formally. d’Aspremont et al. (1979) use quadratic transportation costs in the Hotelling model, establishing that the firms choose maximum differentiation to soften price competition. Shaked and Sutton (1982) show that firms choose to differentiate their products vertically to soften price competition. Lancaster (1966) proposes the characteristics approach, which was later developed by Anderson et al. (1989). The general lesson from these studies is that the relative importance of softening price competition and increasing market demand is the key determinant of product positioning: the degree of product differentiation (Belleflamme and Peitz 2015). Tirole (1988) identifies three forces that limit product differentiation: (i) the limited scope of price competition due to technology or regulation; (ii) the tendency to place products where the demand is; and (iii) the positive externalities between firms. Each of them increases the relative importance of increasing market demand over softening price competition. In Sect. 3.1 we show that the platform may choose to display products separately using two pages to soften price competition. However, in Sect. 3.2, where we introduce a form of individual taste differences across products, we show that the platform would choose to display products together on a single page precisely because of (ii). Important strands of the behavioral industrial organization literature study how the presence of behavioral consumers—who search too little, stick too much to past choices, and/or have biased expectations about their own future choices—can lead to positive markups even in a competitive environment (see reviews by Grubb 2015a, b). Although we too find that positive markups are offered in equilibrium with competition between sellers, we assume that all agents are homo economicus. Our study more directly contributes to the intentional obfuscation literature. Ellison and Wolitzky (2012) develop the idea of Stahl (1989) to consider a form of obfuscation: Sellers may choose to increase the search costs to deter buyers from searching, so that the sellers can charge prices that are close to monopolistic ones (see also Wilson 2010). Another interpretation of obfuscation comes from Ellison (2005): He studies an add-on price model, where sellers produce vertically-differentiated products, while advertising only low-price products to attract buyers, who will be induced to purchase the upgraded version, the high-quality product. This view is empirically supported by Ellison and Ellison (2009). 
Hagiu and Jullien (2011) suggest that the platform might strategically increase the effective search costs by intentionally reducing the efficiency of searching. However, in their model the platform intentionally mismatches consumers with their less preferred goods, whereas our platform behaves identically regardless of the type of buyer (see also White 2013). Empirical studies about search obfuscation acknowledge the significance of search costs, even when these costs involve merely moving one’s eyes one line down a list.Footnote 4 Koulayev (2014) finds empirical evidence for the dependence of price elasticity on the size of search costs in online hotel bookings. McDonald and Wren (2013) find empirical evidence that the practice by online insurance sellers of posting multiple prices under different brand names is consistent with search obfuscation. In contrast, we theoretically show that the platform, not the sellers, obfuscates a product to soften price competition. In the directed search literature, Weitzman (1979) asks how an agent would choose the order of sampling for a set of products [see also Wolinsky (1986) and Zhou (2011) for differentiated products]. Arbatskaya (2007) studies the pricing rules of homogeneous companies when a sampling sequence is given exogenously. Our paper differs in two ways: first, our products are heterogeneous; and second, the ordering is chosen by the platform, not the buyers. In a more closely related paper, Armstrong et al. (2009) analyze prominence in the sense that a prominent firm is one sampled first by consumers. They find the highest-quality firm earns the greatest profit by becoming prominent, implying that consumers sample products in order of quality. In contrast, we find that a platform may display the worse product first. Another closely related paper is by Song (2016), who considers the manipulation of product positions on different pages in a similar framework. Unlike our paper, his focuses on horizontal differentiation and shows that goods with more ambiguous characteristics—goods that provide more uncertain utility—are better kept on the front page. In Baye and Morgan (2001), advertisers pay fees to the platform to advertise their prices and consumers pay for access to these prices. The platform sets advertising fees sufficiently high to avoid excessive participation and thus excessive price competition between advertisers, which would reduce the rents that the platform can extract from advertisers. In Kamenica (2008), the platform chooses the sequence of products to show to consumers in order to affect consumers’ beliefs about the availability of products. However, we assume that consumers are knowledgeable about their available options. 
Athey and Ellison (2011) study position auctions in which advertisers bid for sponsored-link positions—with values to advertisers that are contingent on the sales to consumers—and consumers rationally infer the qualities of links from the ordering of those links. Athey and Ellison focus on equilibria in which bids are increasing in quality: Sponsored-links are ordered from highest quality to lowest. However, we show that a platform may display the worse product first. Our paper is also related to the Mussa and Rosen (1978) model of quality choice by a monopolist. Donnenfeld and White (1990) establish that increasing the quality difference by reducing the quality of the lower-quality product will increase the monopolist’s profit, since it will make it more difficult for buyers with high willingness-to-pay for quality to switch to the lower-quality product, inducing price discrimination. Similarly, the “damaged goods” literature (Deneckere and McAfee 1996) establishes that with heterogeneity in consumers’ private valuations of products, selling the low-quality version in addition to the high-quality version enables the seller better to segment consumers and induce price discrimination. In our model, by contrast, having the low-quality product present can benefit the platform when two pages are used, but this is because it reduces price competition. The rest of the paper is organized as follows: Sect. 2 presents a model of product placement with homogeneous search costs. Section 3 deals with heterogeneous search costs across buyers. Section 3.2 incorporates market segmentation. Section 4 concludes. Appendix contains proofs that are omitted from the text.",1
51.0,2.0,Review of Industrial Organization,02 August 2017,https://link.springer.com/article/10.1007/s11151-017-9585-9,Introduction to the Special Issue,September 2017,Jeroen Hinloopen,Stephen Martin,,Male,Male,Unknown,Male,"It is difficult to exaggerate the importance of the US Supreme Court’s 1977 decision in Continental T.V. v. GTE Sylvania.Footnote 1 Before GTE Sylvania, as exemplified by the 1967 Schwinn decision,Footnote 2 antitrust’s core approach in the US was to rely on competition in the sense of rivalry to deliver good market performance. Sylvania reversed Schwinn, and after Sylvania, the scope of the rule of reason expanded—for all areas of antitrust, not only vertical restraints—as courts entered into explicit evaluation of the impact of business practices on market performance. From a perspective of 40 years with respect to the decision, the papers that make up this special issue explore the economics of the intrabrand competition/interbrand competition tradeoff that is central to Sylvania, give some detail about the ways other competition policy regimes have handled the issues that were present in the decision, and challenge the economic basis for one of Sylvania’s most influential policy pronouncements, that interbrand competition is the primary concern of antitrust. In the spirit of such explicit evaluation, in the lead paper of this special issue, Liang Lu compares market performance under alternative distribution arrangements when two firms in an imperfectly competitive manufacturing segment distribute their differentiated products through differentiated retailers in an imperfectly competitive downstream market (Lu 2017). The first arrangement she examines, the wholesale model, has each manufacturer set a wholesale price for each retailer. Each retailer then sets its retail price. This contrasts with the second arrangement, the agency model, in which the manufacturer sets the retail price at a given retail outlet, after the retailer sets the proportion by which it divides revenue with the manufacturer. Under the wholesale model, there is a double-marginalization problem. Because the agency model eliminates this, consumer surplus is higher under the agency model than under the wholesale model. But manufacturer profit is less under the agency model than under the wholesale model, while retailer profits may be greater under the agency model if products are sufficiently differentiated. The analysis implies that agency distribution may be observed when retailers are powerful relative to manufacturers, and illustrates that fine points are involved in the explicit evaluation of the welfare consequences of alternative distribution arrangements. Competition policy regimes around the world face the same economic and policy issues that are present in Sylvania. The second and third contributions to the special issue explain how competition authorities in India and China, respectively, have come to grips with these issues. In the second contribution, Aditya Bhattacharjea examines a decision of the Supreme Court of India that came 5 months before Sylvania and anticipated the main lines of Sylvania’s policy orientation, before suffering legislative reversal (Bhattacharjea 2017). He then reviews some recent cases that have been decided under India’s newer competition law, which suggest that the rule of reason is once again beginning to be applied to vertical restraints. In the third contribution, John Liu and Yue Qiao, in turn, examine recent vertical restraint cases under China’s Anti-Monopoly Law. These cases too confront the same issues that arose in Sylvania, and Liu and Qiao’s (2017) analysis of these decisions sheds light on China’s rapidly-developing approach to antitrust policy. They conclude that while enforcement agencies are inclined to take a per se illegality view of vertical restraints, courts show a greater tendency to take what looks like a rule-of-reason approach. In the final paper, Stephen Martin and John T. Scott trace the impact the US Supreme Court’s remark, in footnote 19 of Sylvania, that “Interbrand competition… is the primary concern of antitrust law” (Martin and Scott 2017). In vertical restraint cases, this dictum has very nearly transformed Sylvania’s mandate to make a rule-of-reason comparison of the consequences of restrictions on intrabrand competition with the expected intensification of interbrand competition into a rule of per se legality for vertical restraints. The priority that footnote 19 gives to interbrand competition has propagated itself to all areas of US antitrust. Martin and Scott suggest that there is no economic justification for the stance of footnote 19, and that it should be withdrawn. The papers in this special issue illustrate that the analysis of the impact of vertical contractual relationships on market performance is complex, as is the application of policy informed by such analysis. They further illustrate that the issues that were present in Sylvania face antitrust and competition policy authorities around the globe.",
51.0,2.0,Review of Industrial Organization,19 July 2017,https://link.springer.com/article/10.1007/s11151-017-9583-y,A Comparison of the Wholesale Model and the Agency Model in Differentiated Markets,September 2017,Liang Lu,,,,Unknown,Unknown,Mix,,
51.0,2.0,Review of Industrial Organization,09 August 2017,https://link.springer.com/article/10.1007/s11151-017-9588-6,Sylvania’s Indian Precursor and Its Legacy,September 2017,Aditya Bhattacharjea,,,Male,Unknown,Unknown,Male,"In January 1977, 5 months before the Sylvania judgment, the Supreme Court of India delivered a remarkably similar verdict. In Telco v Registrar of Restrictive Trade Agreements
Footnote 1 (hereafter Telco), the Indian court anticipated the essential arguments of its U.S. counterpart on the possibly pro-competitive role of vertical restraints, in particular territorial restrictions on dealers. It reversed the earlier treatment of such restraints as anti-competitive per se under the then-prevailing Indian competition law, and held that they should be dealt with under the rule of reason. In Sect. 2 of this paper, I summarize the legal and factual background of the Telco case. Excerpts from the Indian Supreme Court’s judgment are presented in Sect. 3, highlighting its similarities (and a few differences) with Sylvania.
Footnote 2 I shall not attempt to summarize the background and arguments of the latter judgment, which should be familiar to readers of this Special Issue. In Sect. 4, I trace the short-lived impact of Telco on Indian competition jurisprudence under the earlier law, and the latent but growing influence of post-Telco/Sylvania approaches to vertical restraints on India’s newer law and its interpretation. I shall show that while both the old and new laws were loosely based on European models, the influence of U.S. case law seems to be more evident in their interpretation, with the addition of some specifically Indian touches. Section 5 concludes the paper.",3
51.0,2.0,Review of Industrial Organization,02 August 2017,https://link.springer.com/article/10.1007/s11151-017-9587-7,"Vertical Restraints, the Sylvania Case, and China’s Antitrust Enforcement",September 2017,Zhiyong Liu,Yue Qiao,,Unknown,,Unknown,Mix,,
51.0,2.0,Review of Industrial Organization,24 July 2017,https://link.springer.com/article/10.1007/s11151-017-9584-x,GTE Sylvania and Interbrand Competition as the Primary Concern of Antitrust Law,September 2017,Stephen Martin,John T. Scott,,Male,Male,Unknown,Male,"In its 1966 Schwinn decision,Footnote 1 the U.S. Supreme Court declared that non-price vertical restraints,Footnote 2 when associated with the distribution of products for which title had passed from manufacturer to distributor, were illegal per se under Section 1 of the Sherman Act. Barely 10 years later, with GTE Sylvania,Footnote 3 the Court reversed Schwinn and prescribed rule-of-reason treatment for such non-price vertical restraints. 
Sylvania marked a sea change in the evolution of antitrust doctrine (Fox 1981, p. 1152; footnotes omitted)Footnote 4:  In applying the antitrust laws from the 1950s to the early 1970s, the Court emphasized freedom of traders and competition among many players, not efficiency. Beginning in 1974, the first year of the Burger Court’s antitrust majority, antitrust law shifted course. In the 1977 Sylvania opinion, the Supreme Court said that market impact must control antitrust decisions. Market impact was assessed in terms of efficiency.  For the Sylvania majority, Justice Powell described the analytical problem that is posed by vertical restraints in the following way (433 U.S. 36, 51, footnote omitted):  The market impact of vertical restrictions is complex because of their potential for a simultaneous reduction of intrabrand competition and stimulation of interbrand competition. He immediately cut this Gordian knot in the accompanying footnote 19, declaring:  Interbrand competition is the competition among the manufacturers of the same generic product… and is the primary concern of antitrust law. In Grimes’ words (2002, p. 28, footnote omitted) “The Court offered no authority for this broad pronouncement, now frequently repeated as holy writ.” Nor could it have done so. No authority was to be found in antitrust precedents; received interpretation of antitrust policy declined to favor competition in one dimension over competition in another. No economic argument supportedFootnote 5 the general proposition that a reduction in intrabrand competition necessarily stimulates an increase in interbrand competition so great that the net effect is to improve market performance. Indeed, it was and is recognized that a reduction in intrabrand competition can simultaneously reduce interbrand competition. The Sylvania majority dictated the use of a (433 U.S. 36, 58–59) “rule-of-reason standard… based upon demonstrable economic effect” to decide the antitrust status of non-price vertical restraints. In practice, bolstered by footnote 19, the result has been de facto legality for non-price vertical restraints (Ginsburg 1991). After reviewing theoretical and empirical evidence, we conclude that antitrust should abandon the priority conferred on interbrand competition by footnote 19, and evaluate vertical restraints under a rule of reason that considers the overall impact of interbrand and intrabrand competition on market performance without preconceptions as to their relative importance. The paper is organized as follows: In Section 2, we concisely review Sylvania. In Section 3 we trace the expansion of footnote 19’s influence on antitrust jurisprudence. In Section 4 we contrast footnote 19 with earlier antitrust positions. In Section 5 we review economic arguments and evidence about the relative impact of interbrand competition and intrabrand competition on market performance. Section 6 concludes.",4
51.0,3.0,Review of Industrial Organization,01 February 2017,https://link.springer.com/article/10.1007/s11151-017-9567-y,Targeted Advertising and Cumulative Exposure Effects: The Impact of Banning Advertising to Children in Quebec,November 2017,Lynne Pepall,Joseph Reiff,,Female,Male,Unknown,Mix,,
51.0,3.0,Review of Industrial Organization,16 September 2016,https://link.springer.com/article/10.1007/s11151-016-9543-y,"Consumer Payment Preferences, Network Externalities, and Merchant Card Acceptance: An Empirical Investigation",November 2017,David Bounie,Abel François,Leo Van Hove,Male,Male,Male,Male,"In many developed countries, consumer penetration rates of certain types of payment cards today reach 90 % and beyond (Bagnall et al. 2016). The same cannot be said about merchant acceptance. For example, according to the survey among French retailers that we build upon in this paper, in 2008 only 68 % accepted cards.Footnote 1 Taken together, these two observations suggest that, at least in some countries, the bottleneck for increased card usage—and further cash replacement—lies primarily with merchants. Yet there is little empirical research into the reasons behind the often low merchant acceptance of cards—perhaps because such an analysis requires a specific approach that integrates both sides of the market. Indeed, payment cards are subject to network externalities, so that merchant benefits depend on consumer uptake: The higher is the number of customers who pay by card, the higher is the utility of a terminal for merchants. In addition, there may be an element of ‘must-take’ (Rochet and Tirole 2011). Merchants who refuse to accept cards stand to lose business to rival retailers. Whatever the reason, there is some evidence in the payments literature that consumer card usage effectively drives merchant card acceptance. However, this evidence is mostly of an indirect nature. The present paper provides more direct evidence, for the case of France. We mainly rely on a 2008 nation-wide survey among 4601 merchants, but in addition we also match these merchant data with consumer data from two large-scale shopping diary surveys. Specifically, in the binary logit model that we use to explain merchant acceptance of debit and credit cards we include a proxy variable for the externality and/or pressure that is exerted by card-paying consumers. This proxy is based on the diary surveys and is fine-grained: We have statistics on the card usage of French consumers for five intervals of transaction values, across nine sectors and up to 96 regions. We find that these revealed payment preferences indeed drive card acceptance. Our paper has two main contributions. In terms of methodology, we are the first to match individual merchants with consumer payment preferences in their geographic location, in their sector, and for their average transaction size. Bagnall et al. (2016, pp. 29–30) see this as a promising avenue for future research. On the empirical level, we provide evidence of the existence of network externalities on the merchant side of the payment card market. Up to now, this evidence was either indirect (Arango and Taylor 2008; Jonker 2011), biased (Loke 2007), or based on aggregated (i.e. bank-level) data (Carbó-Valverde et al. 2012). In what follows, we first review the literature and point out its limitations. Section 3 then provides an introduction to the French payment market. In Sect. 4 we describe the data that we subsequently, in Sect. 5, use to construct our variables. Section 6 presents our results, and Sect. 7 concludes.",29
51.0,3.0,Review of Industrial Organization,22 March 2017,https://link.springer.com/article/10.1007/s11151-017-9574-z,Endogenous Cartel Organization and Antitrust Fine Discrimination,November 2017,Tim Reuter,,,Male,Unknown,Unknown,Male,"The stability of a cartel depends on its ability to punish deviating members. For effective punishment, defecting behaviour must be recognized. In a world with incomplete information, defections might not be visible to other participants. For example, individual demand fluctuations can be the result either of fluctuations in aggregate demand or of defecting behaviour of the other cartel members. Cartels therefore seek to implement mechanisms that help to identify deviations. One common mechanism is to engage a third party that monitors the behaviour of cartel members and reports deviations from the cartel agreement to the other members. This allows the cartel members to distinguish deviations from aggregate demand fluctuations and makes punishment more effective. The involvement of such third parties in the organization of cartels raises some interesting research questions especially with regard to enforcement policies that have to date not been considered. We first explain how a cartel chooses its organizational form: whether it organizes with or without third-party assistance based on the level of uncertainty in the market and on the level of antitrust enforcement. Second, we derive optimal enforcement policies, taking into account that cartels can decide between different organizational forms and that such different forms lead to different probabilities of cartel breakdown. Our model proposes that the legislator can, under certain conditions, increase welfare by setting a lower fine for cartels that operate without the help of third parties relative to the fine that is applicable to cartels with third-party assistance. By offering a fine discount for cartels that operate without a third-party monitor, some cartels will be willing to collude without a third-party monitor, even though the involvement of the third-party monitor would increase cartel persistence. In order to obtain the lower fine, firms are willing to accept a lower persistence of the cartel. However, two drawbacks arise from fine differentiation. First, with a lower fine, some new cartels will form that would not be stable under a uniformly high fine. Second, cartels that organize without a third-party collusion facilitator become more persistent. As their expected fine decreases, the value of collusion increases. This allows firms to lower the level of punishment that is necessary to guarantee incentive-compatibility. As a consequence, the cartel will be better functioning and will cause greater welfare harm. The positive effect and the first drawback are known in the broader law and economics literature. The second drawback arises particularly in a cartel enforcement context, because of the repeated-game nature of collusion and has not been identified before. While the different effects go into different directions, we establish that some level of fine differentiation is optimal, whenever the antitrust authority (AA) is unlikely to convict cartels. Fine differentiation is in conclusion a second-best in situations when the level of enforcement is low (e.g., because of a small budget of the AA). The rest of the paper is structured as follows: Sect. 2 discusses the role of trade associations in cartel agreements, enforcement policy with respect to collusion facilitators, and the related literature. Section 3 introduces the repeated game and its timing, strategies and payoffs. Section 4 determines whether collusion is stable and which cartel organization firms select. Section 5 shows how fine differentiation affects incentive-compatibility and the choice of cartel organization. Conditions for the optimality of fine differentiation are determined. Section 6 discusses model extensions and policy implications.",
51.0,3.0,Review of Industrial Organization,19 October 2016,https://link.springer.com/article/10.1007/s11151-016-9545-9,The Weekend Effect in Television Viewership and Prime-Time Scheduling,November 2017,Jungwon Yeo,,,Unknown,Unknown,Unknown,Unknown,,
51.0,3.0,Review of Industrial Organization,31 January 2017,https://link.springer.com/article/10.1007/s11151-017-9565-0,Airline Deregulation and Its Impacts on Air Travel Demand and Airline Competition: Evidence from Korea,November 2017,Joo Yeon Sun,,,,Unknown,Unknown,Mix,,
51.0,3.0,Review of Industrial Organization,01 March 2017,https://link.springer.com/article/10.1007/s11151-017-9566-z,Unilateral Effects of Horizontal Mergers with Vertical Relations Between Firms and Other Structural Market Changes,November 2017,Magne K. Asphjell,Harald N. Bergh,Jostein Skaar,Male,Male,Male,Male,"The upward pricing pressure (UPP) is a measure of one-sided incentives for a firm to raise its price following a horizontal merger, developed by Farrell and Shapiro (2010) and Werden (1996). The measure is based on pre-merger observables: margins and diversion ratios. As it requires substantially less data and resources than a full merger simulation, it has quickly become an important tool for competition authorities, when assessing the effects of mergers. The European Commission has used this type of analysis in several telecom cases: e.g., Hutchinson 3G Austria/Orange (M.6497); Hutchinson 3G UK/Telefonica Ireland (M.6992); and Telefonica Deutschland/E-plus (M.7018). The framework was later extended by Hausman et al. (2011), who deduced expressions for unilateral pricing effects, with the assumption of general linear demand. Despite the restrictive assumption of linear demand, the formulas constitute a useful screening tool in order to identify potentially harmful mergers in practice, and were utilized by the European Commission in the Austrian telecom case (M. 6497) and by the Norwegian Competition Authority in the Tele 2/TeliaSonera merger case in 2015. However, the unilateral pricing effect (abbreviated to UPE) test does not recognize that competition may be partly internalized pre-merger: for instance, due to vertical relations. Nor does the test explicitly include the possibility of a change in marginal costs: for instance, due to merger-related efficiency gains. Furthermore, the formula can be used only to calculate the unilateral pricing effects that follow from a merger, but no other types of structural changes. However, mergers are not the only structural market change that can cause adverse effects. In reality, vertical relations are not uncommon between downstream competitors. Conducting a UPE-test on a merger between firms with vertical relations, based on the framework that was developed by Hausman et al. (2011), will predict unilateral pricing effects incorrectly. To see this, assume that two firms (A and B) are competing downstream, and that A buys inputs from B. Let us also assume that pre-merger competition between the firms is perfectly internalized through the input price. As prices are optimally chosen pre-merger, a further price increase would not be profitable. However, the UPE-test implicitly assumes full pre-merger competition, and consequently assesses how prices change when competition between the firms becomes fully internalized. As a consequence, the UPE-test predicts a positive price change. Hence, estimates of unilateral pricing effects that do not take vertical relations into account, will be incorrect. In this article, we show that the unilateral effects framework easily can be expanded, in order to predict correct unilateral pricing effects for several structural changes. First, we will give a short presentation of the current framework, as presented in Hausman et al. (2011). This will serve as a baseline for the vertical relations model. However, we allow marginal costs to change due to the merger, thus taking into account the possibility for efficiency gains.Footnote 1 In Sect. 3, we present the model for the unilateral pricing effects of merging competitors with pre-merger vertical relations. In Sect. 4, the unilateral pricing effects that follow an exit of the upstream production of one vertically integrated competitor will be analyzed. The vertical relationship that is described here—despite being only one of many—is present in important consumer markets: e.g., the markets for groceries and telecommunication. Furthermore, the unilateral pricing effects of such structural changes were assessed in several competition cases: for instance, in the Tele 2/Teliasonera merger case (2015) and the ICA/Norgesgruppen purchasing agreement case (2014). Finally, Sect. 5 offers some concluding remarks.",4
51.0,4.0,Review of Industrial Organization,07 November 2017,https://link.springer.com/article/10.1007/s11151-017-9601-0,General Editor’s Note: Antitrust and Regulatory Update,December 2017,Lawrence J. White,,,Male,Unknown,Unknown,Male,,
51.0,4.0,Review of Industrial Organization,09 November 2017,https://link.springer.com/article/10.1007/s11151-017-9592-x,Recent Developments at DG Competition: 2016/2017,December 2017,Benno Buehler,Daniel Coublucq,Tommaso Valletti,Male,Male,Male,Male,"The Chief Competition Economist’s team (“CET”) is a part of the Directorate General for Competition of the European Commission (“DG Comp”), which was created in 2003 to assist in evaluating the economic impact of its actions. The CET’s staff consists of 30 economists (mostly holding Ph.D.s) with a mix of permanent and temporary positions. The head of the CET—the Chief Competition Economist—is recruited outside the European Commission and has a three-year term. The CET has both a support role and a scrutiny role. As part of its support role, it provides guidance on methodological issues of economics and econometrics in the application of EU competition rules. It contributes to individual competition cases—in particular, the ones that involve complex economic issues and quantitative analysis—and to the development of general policy instruments, as well as assisting with cases that are pending before the Community Courts. Members that are seconded from the CET to case teams have a specific and independent status and report directly to the Chief Competition Economist. As part of the scrutiny role, the Chief Competition Economist can report his opinion directly to the Director-General of DG Comp as well as to the Competition Commissioner, providing her with an independent opinion on the economic aspects of a case before she proposes a final decision to the European Commission. The CET is active in DG Comp’s three main areas of policy areas: antitrust, mergers, and acquisitions, and state aid. Historically, the CET’s main domain of activity is merger investigations—typically 50–60% of CET’s time—while state aid and antitrust each takes roughly 20–25% of CET’s work allocation. Between January 2016 and July 2017, the Commission took decisions in six (non-cartel) antitrust cases: Container Shipping,Footnote 1 CDS—Information market,Footnote 2 and Cross-border access to pay-TV (Paramount),Footnote 3 all three of which were in July 2016; ARA foreclosureFootnote 4 in September 2016; E-book MFNs and related matters (Amazon)Footnote 5 in May 2017; and Google Search (Shopping)Footnote 6 in June 2017. A short description of the Google Search case is given immediately below, while Sect. 3 provides details of the CET’s work in the Amazon e-book MFN case. In the Google Search (Shopping) case, the European Commission found that Google had abused its market dominance as a search engine throughout the European Economic Area by giving an illegal advantage to another Google product: its comparison shopping service. While this case is not further developed in this article, it has attracted considerable attention. In a nutshell, according to the Commission’s findings, Google had systematically given prominent placement to its own comparison shopping service, which were placed above the results that Google’s generic search algorithms consider most relevant whenever a consumer typed a product-related query into the Google general search engine. By contrast, rival comparison shopping services were subject to Google’s generic search algorithms, including demotions (which lower a search entry’s rank in Google’s search results). The European Commission decision did not object to the design of Google’s generic search algorithms or to demotions as such, nor to the way that Google displayed or organised its search results pages; but the Commission objected to the fact that Google had leveraged its market dominance in general internet search into a separate market—comparison shopping—in order to promote its own comparison shopping service in search results, whilst demoting those of rivals. In practice, this meant that consumers very rarely saw rival comparison shopping services in Google’s search results. According to the Commission’s decision, this conduct had a significant impact on competition in comparison shopping markets, as consumers generally clicked far more on search results at or near the top of the first search-results page than on results lower down the first page, or on subsequent pages, where rival comparison shopping services were most often found after demotion. Since the start of the abuse in each country of the European Economic Area, Google’s comparison shopping service made significant gains in traffic, whilst rival comparison shopping services suffered a decrease in traffic from Google’s search results pages on a lasting basis. One aspect of the case in which the CET took an active role was the assessment of experiments that were run by Google on its search interface. Using data that were generated by changes in the display of Google’s Shopping Unit, the Commission evaluated the impact on the traffic of the competitors of Google’s shopping service. The Commission concluded that the display of the Shopping Unit that the Commission identified as favourable to Google, did indeed have significant negative consequences on traffic of the competitors. In order to comply with the decision, Google announced on 28 September 2017 that it would open the Shopping Unit to the competitors of Google’s shopping service. Competitors are allowed to participate in an auction for display slots in the Shopping Unit, similarly to Google’s own shopping service. Google’s shopping service is to be operated under separate accounts and has to be financially self-sustaining in order to assure that it does not receive privileged treatment from its parent company. The remedy is subject to the Commission’s evaluation that also involves an external expert. During the period January 2016 to July 2017, 590 merger transactions were notified to DG Comp.Footnote 7 A significant share of these cases (412, i.e. 70%) are so-called “simplified” cases that require a simple assessment in which the CET is not involved. The remainder of the cases are subject to a “first-phase” investigation of 25 working days, which typically ends in a clearance Decision without remedies (128 cases) or with remedies (33 cases). When remedies at the end of the first-phase investigation are not adequate to resolve the competitive concerns identified at that stage, or if none are submitted, the transaction is subject to a “second-phase” or “in-depth” investigation, which lasts 90 working days.Footnote 8 A major step of this phase is the issuance of a Statement of Objections, which informs the Parties to the transaction of the European Commission’s preliminary conclusions. During this period, the majority of the second-phase cases were authorized subject to remedies (eight cases), whilst three case were prohibited, and one was withdrawn after the submissions of the Statement of Objections.Footnote 9
 The CET is typically involved in all second-phase investigations and very often involved in complex first-phase investigations. Most assessments of merger transactions are related to unilateral effects on price. Nevertheless, competition authorities have long been concerned with the potential effects of mergers on innovation. The European Commission Horizontal Merger Guidelines mention that effective competition benefits consumers by promoting innovation and that mergers may deprive consumers of the benefit of improved and new products.Footnote 10,Footnote 11 Since 2014, theories of harm that are based on innovation concerns have been pursued by DG CompFootnote 12 in at least seven merger cases and upheld by the Court of Justice of the European Union in another case.Footnote 13
 Innovation concerns normally emerge in markets or industries in which the merging parties have strong innovation capabilities and/or track records, are facing few rivals with such capabilities and where barriers to entry in research and development (“R&D”) are significant. The innovation concerns are related to the possibility that, following the transaction: (1) the merging parties will limit future price competition between their forthcoming and their existing products, or between their forthcoming products; and (2) the merged entity will discontinue, delay, or redirect its efforts in each of the merging parties’ pre-merger lines of research. The innovation concerns are also related to the possibility that: (3) the transaction will remove one of the few competitors with innovation capabilities in these markets. In the pharmaceutical and agrochemical industries, the Commission typically assessed overlaps between the merging firms’ pipelines (at various stages of their development) as well as with their current products, and the overlap between their lines of research.Footnote 14 In engineering sectors—in particular in industrial gas turbines and in oil-field products—the Commission reviewed the R&D capabilities of the merging parties and their main competitors, usually in terms of R&D strength and track record, in particular with a view of ensuring that remedies replicate the competitive constraints that would be lost as a result of the merger.Footnote 15 In services areas, such as financial exchanges, the Commission analysed innovations related to products, technology, process, and market design. Section 2 below provides details of the CET’s work in the Dow/DuPont case, which hinge upon, in particular, concerns that are related to innovation. During the period 2016–2017, state aid control has been characterized by enforcement under the new state aid architecture following the State Aid Modernization initiative (SAM). The SAM has led to a significant decrease in the number of notifications, as more state aid is covered by the General Block Exemption Regulation (GBER), which enables Member States to grant subsidies that satisfy a number of conditions without prior approval from the Commission. This enables the Commission to focus more resources on assessing state measures that are a priori potentially more distortionary. In 2016, the Commission took 535 decisions in the area of state aid, most of which were compatible or no aid decisions.Footnote 16 An important area of activity concerned tax rulings, with the adoption of the Apple recovery decisionFootnote 17 and the opening of a new investigation of possible aid to GDF Suez (Engie) in Luxembourg.Footnote 18 The Commission has continued to approve a number of ex-post evaluation plans that cover many areas of government spending, such as R&D tax credits, regional aid, subsidies for renewable energy, subsidies for broadband investment, etc. In a large number of these plans, Member States have committed to implement evaluation techniques (such as regression discontinuity design) in line with the Staff Working Document that was published by the Commission in 2013.Footnote 19 As a follow-up to the capacity mechanisms sector enquiry,Footnote 20 the Commission is also assessing the designs of a large number of individual capacity mechanisms across Member States.",8
51.0,4.0,Review of Industrial Organization,30 October 2017,https://link.springer.com/article/10.1007/s11151-017-9594-8,Recent Developments at the CMA: 2016–2017,December 2017,Chris Doyle,Alex Moore,Mike Walker,,Male,Male,Mix,,
51.0,4.0,Review of Industrial Organization,03 November 2017,https://link.springer.com/article/10.1007/s11151-017-9597-5,"Economics at the FCC, 2016–2017: Auction Designs for Spectrum Repurposing and Universal Service Subsidies",December 2017,Evan Kwerel,Paroma Sanyal,Patrick Sun,Male,Unknown,Male,Male,"The Federal Communications Commission (FCC) is an independent regulatory agency with responsibility for the telecommunications and electronic media sectors, including the allocation and management of all U.S. radio frequency spectrum except for that utilized by the federal government. The agency’s goals include the promotion of competition in telecommunications and media services, the mitigation of market power with targeted regulatory intervention where necessary, and the management of the radio frequency spectrum efficiently to advance these goals and others, such as universal service. Economists at the FCC contribute to the realization of each of these goals, through analyses of market power, assessments of the potential harms of major mergers by FCC license holders, and the design of appropriate spectrum management tools and auction mechanisms. The goal of this article is to describe the economic analysis that forms the core of several auctions that the FCC designed and/or conducted over the course of the past year to aid in the realization of its core goals of spectrum management and the promotion of broadband internet access by all Americans. In March of 2017, the Broadcast Incentive Auction concluded as the first two-sided auction mechanism that repurposed spectrum from broadcast television to wireless service. It freed up a total of 70 MHz of licensed spectrum for wireless service use and 14 MHz of spectrum for unlicensed use. It also generated $19.8 billion in gross revenue, of which $10.1 billion will go to television broadcast stations that agreed voluntarily to relinquish their spectrum, leaving $7.3 billion for the Federal Treasury after covering other costs that were associated with the auction. In Sect. 2, we summarize the auction and key design features that were responsible for its success and discuss the benefits and costs of using a two-sided incentive auction mechanism for broadcast to wireless service spectrum repurposing, as opposed to alternative means of repurposing spectrum. Section 3 describes ongoing Commission efforts at using auction mechanisms to target subsidies for broadband internet service expansion to currently unserved or underserved areas, as part of the FCC’s universal service policies. We begin by describing the programs that the FCC implemented to allocate such subsidy support in the past and contrast them with the current efforts at using more efficient auction mechanisms to induce service providers to bid to serve areas where it would be profitable for them to build out with subsidies but unprofitable absent subsidies. We describe the practical challenges that such an auction design has to overcome in the context of the ongoing Mobility Fund II auction, which will provide up to $4.53 billion over 10 years for expanding mobile wireless broadband (4G LTE) in unserved and underserved rural areas, and the Connect America Fund II auction, which will provide nearly $2 billion over 10 years to expand high-speed Internet access to rural areas that are currently unserved by fixed broadband.",3
51.0,4.0,Review of Industrial Organization,03 November 2017,https://link.springer.com/article/10.1007/s11151-017-9596-6,"Economics at the FTC: Deceptive Claims, Market Definition, and Patent Assertion Entities",December 2017,Julie Carlson,Ginger Zhe Jin,Nathan Wilson,Female,Female,Male,Mix,,
51.0,4.0,Review of Industrial Organization,04 November 2017,https://link.springer.com/article/10.1007/s11151-017-9599-3,"Economics at the Antitrust Division 2016–2017: Healthcare, Nuclear Waste, and Agriculture",December 2017,Ari D. Gerstle,Helen C. Knudsen,Dean V. Williamson,Male,Female,Male,Mix,,
52.0,1.0,Review of Industrial Organization,14 June 2017,https://link.springer.com/article/10.1007/s11151-017-9579-7,Is “Delitigation” Associated with a Change in Product Safety? The Case of Vaccines,February 2018,Gayle DeLong,,,,Unknown,Unknown,Mix,,
52.0,1.0,Review of Industrial Organization,24 February 2017,https://link.springer.com/article/10.1007/s11151-017-9572-1,Settlements and Appeals in the European Commission’s Cartel Cases: An Empirical Assessment,February 2018,Michael Hellwig,Kai Hüschelrath,Ulrich Laitenberger,Male,Male,Male,Male,"
In the United States, the interplay between settlements and appeals has long been of interest for both lawyers and economists. Guided by the seminal contribution of Priest and Klein (1984), both theoretical and empirical economic research centered around the question when legal cases go to trial and when they settle—with a particular focus on private law enforcement. In such an environment, the relationship between settlements and appeals is straightforward: either a case is settled—thus leaving no basis for an appeal—or the case goes to trial, which offers the possibility to bring an appeal subsequent to an unfavorable court decision. Thus, ceteris paribus, an increase in the relative importance of settlements is expected to translate into a decreasing relevance of the appeals process. In the European Union, the settlement procedure in cartel cases was introduced in June 2008 as part of public cartel enforcement: it enables the EC to close investigations faster by eliminating or reducing several procedural steps that are required under the standard procedure such as (for example): granting full access to file (requiring prior redacting and translation efforts); conducting oral hearings; as well as drafting detailed decisions. Parties that admit liability and waive these procedural rights receive a discount of 10% on the final fine that is imposed; however, they keep the right subsequently to appeal the Commission’s fining decision. Although the key aim of the introduction of the settlement procedure was the faster and more efficient handling of cartel investigations by the EC, one potential knock-on effect is of particular interest for both academics and practitioners: the impact of the introduction of the settlement procedure on the number of appeals against Commission’s decisions in cartel cases. Although a clearly negative relationship between the number of settled cases and the number of appeals is still expected, the question of the extent of this reduction is interesting from at least three different perspectives. First, in contrast to the United States, appeals against settled EC decisions are still possible, and an impact assessment therefore allows conclusions about the workability of the settlement procedure. Second, the degree of savings that are reached by avoiding lengthy appeals processes allows insights as to the amount of freed enforcement resources and the related increase in the deterrence effect of competition law. Third, from a practical perspective, insights as to the size of the reduction in the number of appeals cases is important for legal and economic consulting practices as they imply a need for resource reallocations. In this context, we use a data set that consists of 575 firm groupsFootnote 1 that were convicted by the EC for cartelization from 2000 to 2015 to investigate the impact of the settlement procedure on the probability to file an appeal. Based on the estimation of a model of a firm’s decision to appeal in the pre-settlement era, we subsequently run out-of-sample predictions to estimate the number of hypothetical appeals cases that would have otherwise occurred in the settlement era in the absence of the settlement procedure. Comparing these estimates with the actual number of appeals, we find a settlement-induced reduction in the number of appeals of about 53%. The remainder of the article is structured as follows: the subsequent Sect. 2 provides a review of theoretical and empirical research with direct links to our research question, followed by a detailed description of the implementation of settlements and appeals in the EU cartel enforcement process in Sect. 3. Section 4 presents our empirical analysis and results, before Sect. 5 concludes the article with a summary of its major insights and a discussion of the main welfare implications.",5
52.0,1.0,Review of Industrial Organization,08 June 2017,https://link.springer.com/article/10.1007/s11151-017-9578-8,Product Similarity and Cross-Price Elasticity,February 2018,Sreya Kolay,Rajeev K. Tyagi,,Unknown,Male,Unknown,Male,"Cross-price elasticity is one of the most commonly used constructs in theoretical and empirical work in the areas of pricing and market structure. A higher cross-price elasticity between two products means that they are more substitutable, and is often suggested as an indication of products that are more similar to each other in characteristics space. For example, Hausman et al. (1991, p. 893) state that cross-price elasticity gives a “natural measure” of similarity among products, and that products that are similar to each other in some characteristics will have a higher cross-price elasticity. Besanko et al. (2000, pp. 228–229) state how cross-price elasticity increases in substitutability, which, in turn, increases as products are more similar on performance characteristics and use occasions. Church and Ware (2000, p. 344) also equate higher cross-price elasticity to more similar products. This implied positive relationship between cross-price elasticity and similarity between products is also mentioned in many empirical studies. For example, Irvine (1983) hypothesizes and finds that cross-price elasticities are higher between cars that are more similar in size and make. Davis (2006) finds intuitive his results that cross-price elasticities are higher between movie theaters that show more movies of the same type. Pinske and Slade (2004) expect and find that cross-price elasticities between beer brands are greater when brands are of the same type and have similar alcohol levels. The purpose of this paper is to investigate theoretically the relationship between the similarity between two products and the cross-price elasticities between them. We consider two products that differ on two dimensions. All consumers agree on which product is superior on the first dimension, for example, its quality. We term this a product’s base strength, and call the product with a higher base strength the “stronger” product and that with the lower base strength the “weaker” product. The second dimension is a horizontal product attribute for which consumers differ in their preferences (e.g., color, style). We then examine how the cross-price elasticities of the two products change as they become more similar to each other on the horizontal product attribute. We show that making these products more similar on the horizontal product attribute increases the weaker product’s cross-price elasticity, but could increase, decrease, or have an inverted-U shaped effect on the stronger product’s cross-price elasticity. We also show how these results are affected by the difference in the products’ base strengths, the nature of the increase in the firms’ marginal costs if costs vary with base strength, and the nature of the disutility that consumers incur by buying a product that is away from their ideal points. The driving force for our results is the differential effect that bringing two products with different base strengths closer on a horizontal attribute has on their relative attractiveness for consumers, and hence in the price competition between them. If the two products had the same location on the horizontal attribute, then all consumers would prefer the stronger product to a weaker product at the same price. However, since the products have different locations on the horizontal attribute and the consumers differ in their ideal points for this horizontal attribute, many consumers choose the weaker product because the stronger product is far from them on the horizontal attribute. When these products become closer on the horizontal attribute, then: (i) each product becomes a better substitute for the other on the horizontal attribute; and (ii) the relative standing of the stronger product with respect to the weaker product improves—consumers have to now incur a smaller disutility in switching from the weaker product to the now horizontally-closer stronger product. These two effects work in the same direction for the weaker product but in opposite directions for the stronger product in their price competition. We show how this causes an increase in product similarity to (i) always increase the percentage change in the weaker firm’s sales caused by a percentage change in the stronger firm’s price (the weaker firm’s cross-price elasticity); but (ii) increase or decrease the percentage change in the stronger firm’s sales caused by a percentage change in the weaker firm’s price (the stronger firm’s cross-price elasticity). We also show how whether the stronger firm’s cross-price elasticity increases or decreases in product similarity depends on the difference in products’ base strengths, the nature of the increase in the firms’ marginal cost when costs vary with base strength, and the nature of the disutility that consumers incur by buying a product that is away from their ideal points. Our results add to the earlier referenced papers that discuss the relationship between product similarity and cross-price elasticities. Specifically, we show that one cannot unequivocally equate increased product similarity to increased cross-price elasticity. Our results also have an implication for the use of cross-price elasticity as a criterion to help define market boundaries in antitrust cases (e.g., Bain 1951; Rubinfeld 2000; de Juan 2003; Nevo-Ilan 2007). We show that a product that is considered to be in the same market with another product based on its high cross-price elasticity could be quite dissimilar in product features. Our paper is also related to the literature on merger analysis: The Department of Justice-Federal Trade Commission horizontal merger guidelines (2010) make it clear that there is no single methodology that is recommended across all situations to answer the question of whether a merger is likely to lead to a substantial price increase. However, Werden (1992, 1997) provides a number of examples where courts and firms have relied on cross-price elasticity measures to help define close competitors to study the question of a potential price increase as a result of mergers.Footnote 1 The literature on merger simulations also uses cross-price elasticity, and aims to estimate cross-price elasticities that are more realistic in the sense that they are increasing in the substitutability between the products (Werden and Froeb 1994; Hausman and Leonard 2005). Our insight is that greater or lesser similarity between two products need not be a good indicator of their cross-elasticities. Our paper can also be seen as related to some work on information sharing and price discrimination. For example, Holmes (1989), Stole (2007), and Liu and Serfes (2010) show that if two firms compete in two markets where the same market is stronger for both firms, then the cross-price elasticity between the firms’ products helps predict which of the two markets will have a lower price. Since the results in our paper show that increasing product similarity can increase or decrease cross-price elasticities, we can infer that the direction of price discrimination between markets can be ambiguous when products become more similar.",2
52.0,1.0,Review of Industrial Organization,20 June 2017,https://link.springer.com/article/10.1007/s11151-017-9580-1,Analyzing the Impact of Electricity Market Structure Changes and Mergers: The Importance of Forward Commitments,February 2018,David P. Brown,Andrew Eckert,,Male,Male,Unknown,Male,"Conventional market structure analyses that are frequently used to assess the impacts of mergers do not perform well in electricity markets (e.g., see Borenstein et al. 1999). As a result, simulations are used to assess the effects of a merger or other market structure changes. A complication in electricity markets is the presence of forward markets, in which firms trade in advance of the spot market at prices that are then fixed. Prior research has demonstrated that a firm that has committed to greater supply in forward markets has less incentive to exercise market power in the spot market (Wolak 2000, 2007), which makes it important to account for forward positions when analyzing the effects of a proposed merger.Footnote 1
 Two difficulties arise in incorporating forward positions into merger analysis. First, while spot market data are abundant, information on firms’ forward contracting is difficult to obtain. A second difficulty is the potential for firms to adjust their forward positions after a merger. If forward contracts are endogenously chosen, then ignoring the changes to incentives for forward contracting that result from the merger can lead to incorrect conclusions in merger analysis. Therefore, the purpose of this paper is examine empirically the role of assumptions with regard to forward contracts in the simulation of merger effects and market structure changes. Following Bushnell et al. (2008), we develop a Cournot model of the Alberta wholesale electricity market that incorporates firms’ forward positions. Using data for the 2013–2014 period, we choose the monthly forward positions of the five largest firms in the market to calibrate the baseline model. We use our model to simulate the effects of different market structure changes that involve two firms (ATCO and ENMAX) that exhibit different forward positions and degrees of market power execution, in order to highlight the importance of forward commitments. First, we consider a hypothetical merger of the two firms under different asset divestiture scenarios.Footnote 2 Second, we consider the expiration of a virtual divestiture (in Alberta known as a Power Purchase Agreement), which was used during restructuring to mitigate market power concerns.Footnote 3 While virtual divestitures have been popular means of addressing market power in multiple jurisdictions, to our knowledge ours is the first paper to simulate the effects of their expiration.Footnote 4 Finally, we examine the sensitivity of the effects of market structure changes to assumptions with regard to how firms’ forward positions are chosen. We illustrate that the effect of market structure changes depends critically on the level of firms’ forward contracts. We demonstrate that a transaction that results in a limited change in concentration can result in large market price effects due to the nature of firms’ forward commitments. In addition, we demonstrate that the implications of asset divestitures depend on the firms that acquire the divested assets, and how firms adjust their forward contracts. These results emphasize that ignoring the adjustment of firms’ forward contracts following a transaction can lead to biased conclusions regarding the competitive effects of proposed mergers. Recent changes to the U.S. Federal Energy Regulatory Commission’s horizontal market power screens have been viewed as improvements in the use of concentration measures because they account for firms’ existing forward commitments (Bushnell 2005; FERC 2012). However, the use of pre-existing forward contracts abstracts from changes in firms’ incentives to sign new forward contracts. The remainder of the paper will proceed as follows: Sect. 2 reviews the relevant literature. Section 3 describes the Alberta market. The model is developed in Sect. 4. Data and estimation are described in Sect. 5. Section 6 presents the results of our empirical model for the current market structure. Section 7 presents the counterfactual simulations, under the assumption that forward contracts are unchanged. Section 8 examines the sensitivity of these results to changes in firms’ forward positions. Section 9 concludes.",6
52.0,1.0,Review of Industrial Organization,01 July 2017,https://link.springer.com/article/10.1007/s11151-017-9581-0,Strategic Choice of Network Externality and Its Impact on Digital Piracy,February 2018,Yuanzhu Lu,Sougata Poddar,,Unknown,Unknown,Unknown,Unknown,,
52.0,1.0,Review of Industrial Organization,03 February 2017,https://link.springer.com/article/10.1007/s11151-017-9568-x,A Welfare Analysis of Location Space Constraints with Vertically Separated Sellers,February 2018,Youping Li,Jie Shuai,,Unknown,,Unknown,Mix,,
52.0,2.0,Review of Industrial Organization,18 January 2018,https://link.springer.com/article/10.1007/s11151-018-9614-3,Symposium: The NCAA Cartel—Introduction,March 2018,Roger D. Blair,,,Male,Unknown,Unknown,Male,,2
52.0,2.0,Review of Industrial Organization,13 October 2017,https://link.springer.com/article/10.1007/s11151-017-9590-z,"The National Collegiate Athletic Association Cartel: Why it Exists, How it Works, and What it Does",March 2018,Allen R. Sanderson,John J. Siegfried,,Male,Male,Unknown,Male,"This essay describes the National Collegiate Athletic Association’s (NCAA) economic cartel: why it exists; how it works; what it does; the effects that it has on its member institutions; and its likely future. But first, we ask why it is worthwhile to rehash yet again the cartel activities of the NCAA (Koch 1973; Fleisher et al. 1992).
 The answer is simple: power and money. The revenues are large,Footnote 1 and arise principally from television broadcast rights that have soared since the 1984 landmark US Supreme Court decision (Board of Regents of the University of Oklahoma v. NCAA, 468 US 85) that stipulated that big-time commercialized intercollegiate athletic competition is subject to the 1890 Sherman Antitrust Act.Footnote 2
 The irony of this explosion of broadcast riches that poured mostly into about 100 university athletic departments and NCAA headquarters is that the 1984 Court decision ended an agreement among America’s colleges that had restricted the supply of college football games that would be available for broadcast; the restricted supply pushed the price of broadcast rights to a level above the competitive price. One would have expected the end of that arrangement to reduce prices and revenues, which did occur immediately after the decision (Siegfried and Burba 2004). But revenues quickly reversed. The short-lived decline in broadcast revenues to about one-third the 1983 level was followed by three decades during which broadcast revenues left the initial post-1984 dip in their dust (Carroll and Humphreys 2016; Zimbalist 1999, p. 101). Several things caused this explosion in revenue: Some were orchestrated by the NCAA and its member institutions; some were a result of evolving demographics; and others emanated from rapidly changing broadcast technology.Footnote 3
 Although many people predicted that after 1984 broadcast rights would decline sharply toward the marginal costs of airing college football games, about a quarter million dollars at the time (Siegfried and Burba 2004), they failed to appreciate the rapid growth of television networks that demanded football game content, and the degree to which college football demand is regional, which preserved market power for regional conferences. Prior to 1984, ABC and CBS—which held the rights to televise Saturday intercollegiate football—had been airing simultaneous regional contests rather than a single game broadcast nationally. The greater appeal of Southeastern Conference (SEC) games in the American South and of Big Ten matchups in the “rust belt” must have been enough to boost advertising receipts by more than the extra cost of airing multiple games. Interest in college sports, especially football, is regional in part because many alumni of colleges and universities reside relatively close to their alma maters,Footnote 4 and they and the current students constitute a substantial base demand for television broadcasts, as well as for live attendance. After 1984, the largest conferences (called “power conferences”)Footnote 5 began to expand in order to solidify their regional dominance. Starting with the Big Ten’s addition of the Pennsylvania State University (Penn State) in 1990, all five dominant conferences added teams during the 1990s and 2000s. The 1984 Court decision dissolved the NCAA’s single football television contract. After a brief period of confusion during which home and visiting teams for some games each sold “exclusive” rights to the same game to different broadcasters, a duopoly emerged. The College Football Association (CFA), formerly an internal NCAA lobbying group, negotiated television rights for teams in the SEC, the ACC, and the Big Eight (which has since evolved into the Big-12), plus Notre Dame and Penn State, which were two successful independents at the time. The Big Ten and Pac-10 joined to offer networks an alternative television package. This duopoly was not challenged by antitrust authorities, but eventually proved to be unstable. The CFA dissolved in 1995 amidst internal wrangling over increasingly lucrative revenue shares (Siegfried and Burba 2004). The Big Ten and Pac-10 had separated in 1990, for similar reasons. Since 1995 each of the five power conferences has negotiated television broadcast rights on behalf of its members. They have been able to parlay the regionally parochial sports interests of their fans and the growing number of broadcast networks that seek game content (e.g., Fox and ESPN) relative to the number of conferences that offer games into an ever growing financial bonanza. As a result, by 2015 the 65 teams in the power conferences were each earning $20 to $35 million annually from television broadcast rights (Alsher 2017). The powerful intercollegiate athletics programs have taken other steps to diminish any semblance of economic competition that may have existed a few decades ago. In 2007, as the outcome of a settlement that ended an antitrust suit between the National Invitation Tournament (NIT) and NCAA, the NCAA purchased the NIT, thereby ending its modest competitive threat to the NCAA’s lucrative “March Madness” basketball tournament. The NAIA (National Association of Intercollegiate Athletics, which governs about 250 very small athletics programs) has been marginalized, and women’s basketball has been brought under control of the NCAA.Footnote 6 Because many big-time university sports teams play in locations where there is limited competition for live gate attendance and their devoted fans exhibit relatively inelastic demands, the teams can exploit their market power in pricing and implement price discrimination to maximize gate receipts as well. While the power conferences solidified their market power, technological developments have increased the relative value of televising events that viewers prefer to watch live: “breaking news,” and live sporting events. Many fans prefer to watch a sporting event in real-time rather than recording it to view later and skipping over the commercials; and viewers cannot easily avoid the commercials in live sports broadcasts. This increases the relative value of advertising on live events, and thereby allows price increases that further bolster broadcast revenues. The consequence of these changes has been to create a college commercial sports enterprise that now measures aggregate revenues in the billions and compensates head coaches and some athletic directors in the millions.Footnote 7 Gross revenues of intercollegiate athletics programs have grown to such large proportions that an enterprise that was once largely a peripheral activity on college campuses no longer goes unnoticed. Media reporters, columnists, faculty, and the student-athletes themselves have begun to question the distribution of the largesse. Protests have been lodged about the unfairness of coaches and athletic administrators receiving salaries that are far in excess of what they could earn in their next-best employment opportunities and that are at least partially earned on the backs of players, many of whose families are economically challenged. Players have attempted to unionize in order to bargain for more compensation and better health insurance coverage. Others have questioned the absence of challenges to the cartel agreement that limits player compensation (Sanderson and Siegfried 2015a, b) and allows conferences to sell broadcast rights collectively. And recently, a series of privately initiated antitrust actions have been lodged against the NCAA’s continued operation as if it believed that it were exempt from the nation’s antitrust laws. The next sections briefly review the history and evolution of the NCAA, and describe the theoretical and empirical underpinnings of the NCAA’s economic cartel.",14
52.0,2.0,Review of Industrial Organization,01 December 2017,https://link.springer.com/article/10.1007/s11151-017-9606-8,Athlete Pay and Competitive Balance in College Athletics,March 2018,Brian Mills,Jason Winfree,,Male,Male,Unknown,Male,"
The issue of player pay has been a controversial topic in college athletics. One argument that is often made with respect to player pay is that increasing pay will decrease competitive balance. For example, in a recent court case, the NLRB cited competitive balance as a reason for not allowing unionization, which would have increased direct payments to players.Footnote 1 Similarly, the National Collegiate Athletic Association (NCAA) has argued that player pay would hurt balance.Footnote 2 NCAA president Mark Emmert has also cited balance as an argument against player pay. However, missing in these discussions is the counterfactual: What is competitive balance in the absence of player pay? This study theoretically analyzes and empirically explores the impacts of direct player compensation on competitive balance in college sports. We argue that players are already compensated, albeit indirectly, through various types of amenities and this creates a certain level of imbalance. It is not obvious that direct cash payments to players will increase competitive balance when compared with the current state of indirect payments. While it is certainly true that player pay would allow larger universities to pay for more talented teams than smaller schools, what seems to be missing is a discussion of the current recruiting process and balance levels that result. As the casual college sports observer knows, the current recruiting process is not random. So, even though direct player compensation is similar for all teams,Footnote 3 many universities are able to recruit better athletes. As previous research has shown, the marginal benefit of some of the athletes to their university is far greater than their compensation; see Brown (1993, 1994, 2011), Brown and Jewell (2006), Lane et al. (2014) and Hunsberger and Gitter (2015). So if a university can get better players by paying them more, they would do so. In the current scenario, because direct payments to the athletes are limited, indirect payments to athletes are increased. In other words, in the presence of a pay restriction, athlete payrolls are a smaller percentage of expenses as compared to professional leagues. Alternatively, player payroll constitutes 70.4% of National Basketball Association expenses and 48% of National Football League expenses (www.spotrac.com). Instead of providing this direct wage compensation, college teams try to recruit players indirectly by having better coaches and facilities or other amenities that recruits might want. One piece of evidence of this is that college coaches receive a higher percentage of team revenue than do professional coaches. In 2015, the National Football League’s highest paid coach was Sean Payton at $8 million, which represented an estimated 2.22% of the New Orleans Saints revenues. In the same year, the highest paid college football coach was Nick Saban at $7.087 million, which is an estimated 7.45% of the revenue that was generated by the football team at the University of Alabama. Certainly there are other factors that could influence these percentages, but many college coaches are paid for their recruiting skills. Therefore, much of the rents that were received by the university because of player pay restrictions are transferred to coaches and facilities. Presumably some policies, such as unionization, would increase direct payments to players. If all NCAA athletes, or all NCAA football players, joined a union, this would create a bilateral monopoly. And in cases where players are not unionized, universities would be left with a choice, as they are now, to pay players and compete in the direct compensation market. While this would increase benefits for the players, it would also presumably decrease indirect payments to players in the form of coaches and facilities, and the impact on competitive balance is not obvious. In other words, increasing the limits of direct compensation will likely crowd out indirect compensation, and the impact of this crowding-out on competitive balance is not clear.",5
52.0,2.0,Review of Industrial Organization,14 October 2017,https://link.springer.com/article/10.1007/s11151-017-9591-y,Modeling Competitive Imbalance and Self-Regulation in College Sports,March 2018,Rodney Fort,,,Male,Unknown,Unknown,Male,"Competitive imbalance matters for college sports conference management. For example, college football is of paramount importance because of its ability to generate revenue for the athletic department at some schools and other values across the rest of campus at all schools.Footnote 1 If Rottenberg’s (1956) “uncertainty of outcome hypothesis” holds for college football, then imbalance matters in the generation of both revenues and these other values.Footnote 2
 Competitive imbalance in college sports also is of interest as a public policy issue. First, most athletic programs receive general university budget support, which is typically publicly derived. In this area, there is little theoretical work, and the focus of the empirical work is at the NCAA level (Eckard 1998; Depken and Wilson 2004a, b, 2006). Second, the courts have relied on competitive imbalance beliefs in their findings on college athlete compensation (Fort 2017). Drawing from the observable principal-agent relationship between university administrators (UAs) and their athletic departments, athletic directors (ADs) can be viewed as inheriting a revenue-maximization objective that is subject to a spending constraint. In this paper, a conference of revenue-maximizing athletic directors is modeled. Nash equilibrium in talent investment predicts competitive imbalance. Higher-revenue departments will have higher talent levels; and the greater is the revenue disparity, the greater will be the imbalance. With respect to self-regulation: If the conference adopts pooled revenue sharing, the model predicts an increase in the absolute level of talent in the conference. Since college national championships are determined across conferences, this may be why nearly all conferences have nearly complete revenue sharing. In addition, pooled revenue sharing reduces competitive imbalance in the conference. The model also helps explain the form of the NCAA amateur requirement (strictly limited to grants-in-aid).Footnote 3 Further, the model predicts that the current form of the NCAA amateur requirement will have no impact on competitive imbalance. The amateur requirement simply transfers money from athletes to athletic departments.Footnote 4
 The amateur requirement prediction also means that reversing the transfer, by moving toward play-for-pay, will not change competitive imbalance as long as ADs still pursue revenue maximization. The NCAA has claimed and tried to show in legal proceedings that the amateur requirement reduces competitive imbalance. The result here is that the NCAA has no theoretical justification in the case of revenue maximizing ADs.Footnote 5
 The paper proceeds as follows: In Sect. 2, the principal-agent relationship between UAs and ADs is summarized. Section 3 presents a Nash equilibrium model for a conference of revenue maximizing athletic directors. In Sect. 4, the model is used to investigate the impacts of pooled revenue sharing on competitive imbalance, and the same is done in Sect. 5 for the NCAA amateur requirement. Conclusions, limitations, and suggestions for further research are in Sect. 6.",3
52.0,2.0,Review of Industrial Organization,27 November 2017,https://link.springer.com/article/10.1007/s11151-017-9604-x,Rent Sharing and the Compensation of Head Coaches in Power Five College Football,March 2018,Michael A. Leeds,Eva Marikova Leeds,Aaron Harris,Male,Female,Male,Mix,,
52.0,2.0,Review of Industrial Organization,21 November 2017,https://link.springer.com/article/10.1007/s11151-017-9602-z,State of Play: How Do College Football Programs Compete for Student Athletes?,March 2018,Jill S. Harris,,,Female,Unknown,Unknown,Female,"Two-sided matching models help us understand how economic agents find each other. Whether it is medical schools and medical students in a scramble for residency programs or top rated high school football players and college football programs that sign letters of intent, both parties are searching for optimal matches. In the National Collegiate Athletic Association (NCAA), these matching outcomes can have far-reaching effects on regular season wins, championships, and revenues. Several sports studies examine the matching process from the athlete’s perspective. This study focuses on the football programs’ choices. Using panel data, it introduces a negative binomial count model of the top 100 football players in Division I (DI) and the factors that may contribute to programs’ signing a larger (or smaller) share of these top-quality high school athletes. The college football recruiting process is examined from the athlete’s perspective by DuMond et al. (2008). They review the broader literature that addresses college choices by non-athletes. However, there is a noticeable gap in the literature as to the process from the college football program’s perspective.Footnote 1 An interesting study on the market for football coaches by Brown et al. (2007) reveals that good matches improve winning percentages. Berri et al. (2011) consider factors that influence the NBA amateur draft where teams select players. Similarly, Harris and Berri (2015) examine factors that influence the WNBA draft. While the NBA recruits players directly from high school, the WNBA rarely does so. Two-sided matching models of medical interns and hospitals and college students and schools have been considered by Roth (1984) and Roth and Sotomayor (1992). Still, no paper that I have found investigates the college-athlete matching process from the college’s perspective. The theoretical framework is straightforward: Football programs are organizations that produce wins.Footnote 2 Student-athlete labor is an input in the wins production technology. Because the number of scholarships is fixed by the NCAA and programs are not allowed to bid for athletes using wages, schools compete for the best-quality athletes through the use of non-price competition. The empirical approach is similar to DuMond et al. (2008) and Harris and Berri (2015). Findings from the count model align with some of the results from the DuMond et al. (2008) study but also contrast in intriguing ways. For example, DuMond et al. report that athletes are more likely to sign with championship programs that consistently win their conference titles, have not been involved in NCAA enforcement actions, and are located close to the athlete’s home state. I find that DI football programs successfully recruit a larger portion of the “Rivals Top 100” high school players when the programs have a higher number of conference championships, have earned a bowl championship, and belong to the SEC. However, in stark contrast to DuMond et al., I also find that NCAA infractions during the sample period are associated with a larger share of top-quality recruits. This result makes economic sense in light of the extended literature on cheating in the NCAA. Before I summarize the data, empirical approach, and the results, I present a brief review of the related literatures.",2
52.0,2.0,Review of Industrial Organization,22 November 2017,https://link.springer.com/article/10.1007/s11151-017-9600-1,Strategic Interaction in a Repeated Game: Evidence from NCAA Football Recruiting,March 2018,Brad R. Humphreys,Jane E. Ruseski,,Male,Female,Unknown,Mix,,
52.0,2.0,Review of Industrial Organization,24 October 2017,https://link.springer.com/article/10.1007/s11151-017-9593-9,The Role of Broadcasting in National Collegiate Athletic Association Sports,March 2018,Allen R. Sanderson,John J. Siegfried,,Male,Male,Unknown,Male,"When the 1984 Supreme Court decidedFootnote 1 NCAA v. Board of Regents of the University of Oklahoma, 468 US 85, which specified that the National Collegiate Athletic Association’s (NCAA) restrictive television plan violated Section 2 of the Sherman Act, Apple had just introduced the first mass-market personal computer, the Macintosh, and the ubiquitous ‘mouse.’ Though prototypes had existed for a few decades, in 1984 the Internet had not yet surfaced. Electronic Arts (EA), a company that would figure prominently in the Ed O’Bannon court case,Footnote 2 began producing video games in 1990.Footnote 3 And now-familiar social media sites, links and streaming services—Pandora (2000), Facebook (2004), Flickr (2004), YouTube (2005), Reddit (2005), Twitter (2006), Tumblir (2007), Spotify (2008), Hashtag (2009), Instagram (2010), Snapchat (2011), Vine (2012), and Yik Yak (2012)—were only dream material in Harvard dorms and Silicon Valley cafeterias in the late twentieth century.Footnote 4
 In 1984 the Big Ten conference actually had 10 members. With the addition of the Pennsylvania State University (Penn State) in 1990 and subsequently Nebraska, Maryland, and Rutgers, it grew to 14. For now. Its competitive peer conferences have expanded as well, and split into divisions to create faux conference-championship games that allow for expanded schedules, and greater ticket and broadcast rights revenue. Concomitantly, broadcasting’s share of big-time college sports revenues has mushroomed over this 30-year period, and individual athletic conferences and institutions have created or contracted separate television packages with various broadcast networks, where most of the football broadcast rights revenues appear.Footnote 5 With the advent of widescreen displays and high-definition television,Footnote 6 cable and satellite TV, the Internet, smartphones, social media sites, and streaming capabilities, technological advances that were unforeseen on June 27, 1984, have changed broadcast and home-entertainment viewing choices forever, and arguably have upset the balance of in-venue versus at-home options and preferences for fans and families.Footnote 7
 In this essay we describe and discuss these important technological changes with regard to broadcasting and the growth of new revenue streams they have created over the last 30 years that have influenced how, when, where and even for whom college sports are played. We review broadcast history, including the introduction of cable television and new media technologies, complementary industries such as sponsorships and apparel, and public goods and winner-take-all market considerations as they relate to broadcasting. We examine the growth and importance of broadcasting revenues in college sports and the impact on the NCAA and its members. Finally, in the context of twentieth century changes after 1984 and twenty-first century innovations to date—which are roughly two 16-year intervals—we consider how all of this may play out by 2030. In college athletics, some things are more or less certain: one way or another, the athletes eventually will have a greater voice in decision-making and will receive a larger share of the economic pie, though the precise paths and conflict resolutions in a rapidly changing environment are difficult to know.Footnote 8 The long-standing equilibrium in major professional sports leagues was disrupted by unionization and player free-agency in the 1970s and 1980s; then came the tremendous growth in revenues: from television and the money that could be extracted from a team’s playing facility (usually a publicly-financed venue) in the form of advertising, premium seating, and public construction subsidies. The equilibrium in college athletics was jolted by the conjunction of the 1984 Board of Regents decision and the explosion in potential television revenue streams that has made much more money available and disrupted existing NCAA arrangements. The NCAA can to a large extent control how many football games are played, but not when they are played nor the broadcast arrangements, and with the advent of streaming and portable devices it may not be able to dictate even for whom they are played.Footnote 9
",3
52.0,2.0,Review of Industrial Organization,14 October 2017,https://link.springer.com/article/10.1007/s11151-017-9589-5,The NCAA and the Rule of Reason,March 2018,Herbert Hovenkamp,,,Male,Unknown,Unknown,Male,"Today antitrust law assesses most collaborative practices under the rule of reason (Hovenkamp 2017). The few exceptions that are still subject to “per se” treatment include naked price fixing, naked market division, a few boycotts, and an increasingly narrow, idiosyncratic, and widely criticized rule for some tying arrangements (Areeda and Hovenkamp 2011, ¶1720). The per se rule continues to have significant policy value, however, even though its domain is smaller than it once was. Per se analysis can produce large resource savings, provided that the rule is kept within proper bounds. For example, once a practice such as a price fix is properly characterized as “naked,” which means that it is not accompanied by any form of integration in development, production, or distribution, then the practice can be condemned simply on proof that it has occurred—without elaborate, costly, and sometimes inconclusive inquiries into market power or anticompetitive effects (Areeda and Hovenkamp 2011, vol. 7, ¶¶1509–1510; White 2008). A significant limitation is that in private damages actions a plaintiff may still have to prove these things in any event, because damages are typically based on an overcharge, which may require proof of market power. So the per se rule has its biggest bite in government criminal or civil cases or in private cases that seek only an injunction. In the latter, some “threatened loss or damage” must still be proven, but it need not be quantified.Footnote 1
 In sharp contrast to the per se rule, antitrust’s rule of reason requires an assessment of anticompetitive effects. Typically, this requires, first, a showing that the defendants have market power, which means that they have the power to profit by holding output below the competitive level and concomitantly maintaining the price above the competitive level. Market power is traditionally estimated by defining a “relevant market,” or grouping of sales such that cross elasticities between those things inside and those things outside the group is sufficiently low. Then one computes the defendants’ aggregate market share. More direct, econometric measures are undoubtedly superior in many circumstances where the data are available, but these methodologies are still used in only a minority of antitrust cases (Areeda and Hovenkamp 2011, vol. 2B, ¶¶512, 521). Once sufficient power is shown the tribunal must assess the challenged practice’s impact on competition. The plaintiff generally makes out a prima facie case by finding an anticompetitive effect, which means either a restraint that tends to reduce output or that excludes a significant firm or firms. At that point the burden of proof shifts to the defendant to offer a justification. If the defendant succeeds, then the burden shifts yet again back to the plaintiff to show that similar effects could have been achieved by a “less restrictive alternative”: an alternative that is effective for the purpose at hand but that does not impose the same threats to competition (Areeda and Hovenkamp 2011, vol. 7, ¶¶1504–1507; Hemphill 2016). This elaborate process of initial assignment and subsequent shifting of the burden of proof is sometimes referred to as “balancing.” In fact, however, the nature of issues typically make “balancing” little more than a metaphor (Hovenkamp 2016). Frequently the things to be measured are incommensurate or do not come in convertible units of measurement. Most often the courts state the requirement as balancing, but then never really balance anything (Hovenkamp 2016, 371).Footnote 2 Fortunately, only a very small portion of litigated antitrust cases ever get to the point that serious balancing becomes necessary. The per se rule does not require balancing because its relies on what we presume to be a collective judicial judgment that, once a particular practice falls within a particular class, its social value is almost certainly nil or very small, so any amount of harm counts in favor of condemnation. Many of the cases that have developed the contours of antitrust’s rule of reason have been challenges to rule-making by the members of the NCAA. The NCAA is an elaborate joint venture of roughly 1200 members that govern collegiate sports. Most of its important decisions are made collaboratively. Through such rule-making the NCAA regulates such things as player eligibility standards; disciplinary standardsFootnote 3; player compensation, including compensation from third parties for such things as licensing of names and likenessesFootnote 4; the number of games to be played and the ability of member schools to play unscheduled games; TV advertising contractsFootnote 5; and other things.",3
52.0,2.0,Review of Industrial Organization,01 November 2017,https://link.springer.com/article/10.1007/s11151-017-9598-4,Whither the NCAA: Reforming the System,March 2018,Andrew Zimbalist,,,Male,Unknown,Unknown,Male,"Intercollegiate athletics has long been caught in the ambiguous space between professional and amateur sport. As a hybrid and immensely popular system run by the NCAA, intercollegiate athletics has been critiqued as ethically hypocritical, educationally corrosive, materially exploitative, and economically unsustainable. Economic, political and legal pressureFootnote 1 has been building over the last 10 years to reform the system. Such reform will ultimately require a choice between the professional and the amateur models, or a bifurcation whereby a select group of a few dozen schools chooses a professional paradigm while a thousand-plus schools opt for the official NCAA vision of academically centered amateur athletics. After considering the arguments for a market-oriented reform in the direction of professionalism, I argue for an educationally-based reform that is accompanied by a constrained and conditional antitrust exemption for the NCAA or an alternative governing body.",3
52.0,2.0,Review of Industrial Organization,20 November 2017,https://link.springer.com/article/10.1007/s11151-017-9603-y,The NCAA Cartel and Antitrust Policy,March 2018,Roger D. Blair,Wenche Wang,,Male,Female,Unknown,Mix,,
52.0,3.0,Review of Industrial Organization,11 December 2017,https://link.springer.com/article/10.1007/s11151-017-9607-7,An Empirical Analysis of Countervailing Power in Business-to-Business Bargaining,May 2018,Walter Beckert,,,Male,Unknown,Unknown,Male,"Since the early work of Galbraith (1952, 1954), countervailing power—or buyer power—has been an element of competition analysis. Competition authorities that investigate business-to-business (B2B) dealings treat it as a factor that can mitigate upstream market power. Prices in B2B relationships are complex. They may reflect countervailing power if the contracting counterparties bargain over rents, and they may also reflect nonlinearities, which possibly are due to some degree of price discrimination. This paper exploits a panel data set of the UK brick industry that comprises all transactions over the period 2001–2006 between the four main UK brick manufacturers and their customers. It studies the effects of countervailing power and price discrimination on “ex-works” brick prices at the transaction level. Customers in the brick market are heterogeneous, in terms of their size, geographic spread and position in the construction industry supply chain. While related structural work (Beckert et al. 2016) focusses on one specific customer segment, this study uses the entire data set of transactions with all customers and embeds the heterogeneity of buyer-seller relationships in a reduced-form empirical model of prices. The empirical approach to model transaction prices that is advocated in this paper exploits the full richness of the data. It is neither limited to a market segment that is defined by a subset of buyers, nor by the restrictions that are imposed by a structural model. It can serve practitioners as an initial screen: to test an antitrust market definition and to provide an indicative competitive assessment for an entire market. The empirical model builds on existing theoretical results from the bilateral bargaining (Horn and Wolinsky 1988; Inderst and Wey 2003; Stole and Zwiebel 1996) and nonlinear pricing and price discrimination literatures (Katz 1987; Stigler 1949; Thisse and Vives 1988). Because transportation costs are significant in this high weight-to-value industry, features of local demand and supply play an important role. The model distinguishes the effect of countervailing power—which results from the buyer’s local bargaining weight vis-à-vis the selected manufacturer—from that of the buyer’s local outside options. The latter depend on the set of manufacturers with whom a buyer has established transactional relationships and from which the buyer selects the local supplier for a transaction. The empirical analysis shows, first, that prices exhibit nonlinear volume discounts and ’freight absorption’ effects. Second, it also shows that buyers with larger local commercial significance—in terms of the volume of bricks that they buy locally—have countervailing power, at least locally: Through their local commercial significance they enjoy higher bargaining weights and receive lower ex-works prices, relative to locally smaller buyers. And third, it shows that buyers that have established supply relations with more manufacturers that are local to the delivery site benefit from the ensuing competition and pay lower prices. Surprisingly, it reveals that small buyers benefit more from competition because, unlike large buyers, they are not constrained by the capacity of the supplier so that they have more supplier options. Finally, it shows that the effect from competition among established manufacturers dominates the local commercial significance effect. This is important for competition assessment because the former is under the buyer’s control, while the latter is not. The paper proceeds as follows: Sect. 2 reviews the literatures on countervailing power and bargaining, price discrimination, and competition analysis practice on which this study draws. Section 3 describes the industry background and the data that are used. Section 4 lays out the empirical approach for the data analysis, and Sect. 5 reports estimation results. Section 6 concludes.",1
52.0,3.0,Review of Industrial Organization,29 July 2017,https://link.springer.com/article/10.1007/s11151-017-9586-8,Optimal Leniency Programs When Firms Have Cumulative and Asymmetric Evidence,May 2018,Marc Blatter,Winand Emons,Silvio Sticher,Male,Male,Male,Male,"A corporate leniency program reduces the sanctions for self-reporting cartel members. In 1993 the US Department of Justice significantly clarified its first-informant rule that guarantees amnesty for the first reporting firm even when an investigation has already started. This program has been so effective that many other countries followed suit. The theoretical literature on leniency typically makes the following two assumptions: first, if one firm reports the illegal behavior, the cartel is convicted for sure; each firm thus possesses perfect evidence. Inducing one firm to report, no matter which one, is sufficient for the antitrust authority (AA) to convict the cartel. Second, if each firm has perfect evidence, the distribution of the evidence is automatically symmetric. We relax both assumptions: our firms have imperfect and cumulative evidence. The evidence of one firm increases the probability of conviction, but not necessarily to one; the evidence of two firms leads to a higher probability of conviction than the evidence of one firm alone. With imperfect evidence we can allow for asymmetric evidence: one firm may have more evidence than does another firm. This framework allows us meaningfully to analyze minimum-evidence standards, a marker system, and ringleader discrimination—three typical features of leniency programs. We first show that without these features the asymmetry of the evidence may indeed make it more difficult to deter collusion as compared to symmetric evidence. The high-evidence firm may prefer to remain silent while the low-evidence firm reports. We then look at a minimum standard of evidence which a firm has to meet to get leniency. A standard such that the high-evidence firm qualifies while the low-evidence firm does not lowers the AA’s enforcement cost. It provides the high-evidence firm with strong incentives to report. Next we analyze a marker system. After a firm applies for the marker, the AA informs the firm about its position in line. If the firm is first in line, it gets the marker and thus receives leniency if it chooses to report. The marker system allows firms to report conditionally: they reveal their information if the marker is available and they do not reveal if the marker is no longer available. When both firms conditionally report, the AA gets only one report: it gets less evidence than in the no-marker case where both firms report. If firms are sufficiently asymmetric, the marker can, however, be useful. Yet, with appropriate minimum-evidence standards the marker system is ineffective. If only the high-evidence firm qualifies for leniency, it can be sure to avoid the fine, and a marker is not necessary for that privilege. Finally, we assume that the high-evidence firm is the ringleader of the cartel and analyze the effects of denying leniency to the ringleader. If the ringleader’s evidence is similar to the evidence of the other cartel members, ringleader discrimination lowers deterrence costs: without leniency it is less attractive for the ringleader to collude in the first place. Yet, if the ringleader has sufficiently more evidence than the other firms, ringleader discrimination is ineffective: the ringleader plans not to report anyway. Ringleader discrimination is less effective than minimum-evidence standards: shutting out the high evidence firm from leniency generates less deterrence than barring the low evidence firms. Our paper builds on the analysis of leniency programs by Motta and Polo (2003), Spagnolo (2003), Aubert et al. (2006), and Harrington (2008).Footnote 1 This literature analyzes the effects of leniency on the frequency of collusion and derives optimal fine structures. Our basic set-up is closest to Motta and Polo (2003). Besides in the nature of evidence, our framework differs from theirs in two other respects: first, we focus mainly on cartel deterrence. By contrast, they also consider the possibility that a leniency program may temporarily interrupt collusion which we deal with briefly in the Appendix. Second, in our setting the AA fully deters at minimum cost whereas in Motta and Polo (2003) the AA faces a budget constraint so that it may not be able to achieve complete deterrence. The novel feature of our set-up is the cumulative and asymmetric nature of the evidence. Imperfect evidence has already been addressed, yet from a different angle. In Aubert et al. (2006) firms can destroy their evidence, thereby reducing the cartel’s risk of being convicted. In our setting, the firms’ evidence is exogenously given and if a firm blows the whistle it has to reveal everything. Yet, our firms may not possess all the evidence necessary that is to convict the cartel. In Harrington (2008) the AA’s stand-alone evidence varies over time, which affects the value of additional evidence that is provided by the firms. However, as in all of the above-mentioned papers, a cartel is convicted for sure as soon as one member turns in. By contrast, in our setting a firm that submits evidence increases the probability of conviction, but not necessarily to one. 
Feess and Walzl (2010), Silbye (2010), Herre et al. (2012), and Charistos and Constantatos (2016) address asymmetric evidence. As in our framework, Feess and Walzl (2010) and Silbye (2010) consider two firms that possess different amounts of evidence. The AA chooses a fine structure that decreases with the amount of provided evidence. We touch on the issue of the optimal fine structure by considering minimum standards of evidence and ringleader discrimination. Nevertheless, following the winner-takes-all characteristics of the US leniency program, in our setting firms either get full or no leniency at all. We do not consider leniency as depending in a more subtle way on the amount of evidence to be of further interest due to the difficulties to implement such rules in practice. 
Charistos and Constantatos (2016) study the effects of a marker system. In their set-up the AA does worse with a marker system than without because with a marker it does not get the entire available evidence. As to ringleader discrimination, in Herre et al. (2012) the ringleader possesses perfect information, while the other cartel members possess incomplete (and identical across firms) evidence. They analyze whether or not the ringleader should be granted leniency. Similar to our results they find that excluding the ringleader from leniency has a deterring effect when firms are sufficiently symmetric. A further comparison of their results with ours is difficult because they allow for side payments between members to stabilize the cartel, which we do not. In Chen et al. (2015) the ringleader and his follower both posses perfect evidence. Ringleader discrimination can lead to increased or decreased levels of cartel conduct. On the one hand, ringleader discrimination undoes some of the destabilizing benefit of the leniency program. On the other hand, under discrimination the ringleader faces a more severe punishment which can reduce the incentive to instigate in the first place.Footnote 2
 To the best of our knowledge, we are the first to analyze minimum standards of evidence formally. In both the US and the EU, the institutional details of a leniency program are not determined by competition law, but instead by the internal policies of the AAs.Footnote 3 This implies that the AA can revise its leniency program as to what it sees fit. Typically, leniency programs include the following features: (1) the assignment of leniency to the first applicant who reports participation in a cartel;Footnote 4 (2) a marker system that allows an applicant to secure its position in line; (3) the requirement of full disclosure of evidence; (4) an ongoing requirement to cooperate fully with the AA; (5) a requirement to cease collusive behavior; and (6) ringleader discrimination. We take all of these features into account. In line with the US leniency program, in our model only the first evidence-providing firm receives leniency. We require the firms to reveal all evidence in their possession. Furthermore, a reporting firm has to cease its collusive conduct. Both the US and the EU leniency programs specify requirements with respect to the evidence that an applicant has to provide. The Antitrust Division of the US Department of Justice requires the applicant to report “the wrongdoing with candor and completeness” and to provide “cooperation that advances the Division in its investigation.”Footnote 5 In Sect. 4, we deal with these requirements by introducing minimum standards of evidence. We also analyze the effects of a marker system: a standard element of most leniency programs, under which the AA informs the firm whether it is the first to seek leniency.Footnote 6 Common arguments for its use are legal certainty and transparency, and that it encourages a “race to the courthouse.” In possession of the marker, a firm has, e.g., 30 days to collect the evidence necessary to “perfect the marker.” For reasons of tractability, we ignore the time dimension of the marker system. In our model, the AA immediately informs a firm whether leniency is available. In the US it is not possible for ringleaders to obtain a fine reduction. By contrast, in the EU ringleaders benefit from leniency as long as the undertaking did not take “steps to coerce other undertakings to join the cartel or to remain in it” (European Commission 2006, p. 13). We deal with the effects of ringleader discrimination in Sect. 6. The rest of this paper is organized as follows: the next section describes the model. In Sect. 3 we derive the equilibria for the reference scenario. In Sect. 4 we extend the model to minimum standards of evidence, in Sect. 5 to the marker system, and in Sect. 6 to ringleader discrimination. Section 7 concludes.",7
52.0,3.0,Review of Industrial Organization,24 November 2017,https://link.springer.com/article/10.1007/s11151-017-9605-9,Sharing Audience Data: Strategic Participation in Behavioral Advertising Networks,May 2018,Steven Schmeiser,,,Male,Unknown,Unknown,Male,"Internet advertising is a large and growing market, with 2014 revenues of nearly $50 billion in the United States.Footnote 1 Fine grained audience data and the ability to target consumers precisely sets online advertising apart from traditional offline advertising. This paper examines the incentives of websites to share audience data with behavioral advertising intermediaries—a primary source of data that are used for precise targeting. Several studies (reviewed below) have examined the consequences of increased targeting ability for the advertising market, but have taken the general availability of targeting data as an exogenous technological progression. Here, I consider special interest websites that possess the audience data that are required for targeting and examine their choice of whether or not to make their data available for targeting on other websites. In my model, multi-homing consumers visit special interest websites and general audience websites. A special interest site caters to a single advertising market (e.g., rock climbing, stock trading, cooking) and a visit to a special interest website identifies a consumer as a “match” that the advertiser would like to reach. A visit to a general audience site (e.g., The New York Times, CNN, Yahoo!) does not reveal any information that is useful for targeting ads—for a general audience site to target ads it needs an external source of data. Websites choose between two types of advertising intermediaries: a contextual intermediary and a behavioral intermediary.Footnote 2 The contextual intermediary uses the site’s own content to target ads to the audience, while the behavioral intermediary uses a consumer’s browsing history to build a profile of a consumer’s interests and uses that profile to target ads. If all special interest websites in an advertising market use the contextual intermediary, then the general audience sites are unable to identify consumers in this market, as no audience data leave the special interest sites. If the special interest sites use the behavioral intermediary, targeted ads may be shown on both the special interest sites and the general audience site. I first consider a monopoly special interest site. The site faces a trade-off in choosing intermediaries. By choosing the contextual intermediary, the site prevents its audience data from being used to target its consumers on general interest sites and this keeps all impressions (ad views) on the special interest site. If the special interest site chooses the behavioral intermediary, it may be able to show higher value ads, but its audience data are used to target consumers on general audience sites. This increases the supply of impressions per user, which decreases the average value of an impression. The price decrease that is due to increased supply depends crucially on the value of repeated impressions. In the duopoly setting, special interest sites have an additional strategic concern that is driven by consumers that visit both sites. If one special interest site uses the contextual intermediary, the other special interest site may leak its audience data to the behavioral intermediary, creating a negative externality. In equilibrium, identical special interest sites always choose the same intermediary. When sites are not identical, there are equilibria in which the sites choose different intermediaries. I find that sites are more likely to choose the behavioral intermediary when the value of repeated impressions is high, when the amount of multi-homing between special interest sites is high, and when traffic (per consumer) on the special interest site is high relative to the general audience site. In addition, a monopoly special interest site is less likely to share consumer data with a behavioral intermediary than a duopolist. This suggests that concentration among special interest sites is beneficial to consumer privacy.",1
52.0,3.0,Review of Industrial Organization,17 July 2017,https://link.springer.com/article/10.1007/s11151-017-9582-z,Sectoral Regulators and the Competition Authority: Which Relationship is Best?,May 2018,Pedro P. Barros,Steffen H. Hoernig,,Male,Male,Unknown,Male,"Over the last three decades a series of heavily regulated markets were at least partially liberalized: e.g., telecommunications, energy, transport, and others. After deregulation these markets often continued to be subject to both sector-specific regulation and general competition law. This created an overlap of jurisdictions in several countries, such as Denmark, France, Germany, Italy, Netherlands, Spain, the UK and the US,Footnote 1 where competition policy and sectoral regulation intersect. The relationship between sectoral regulators and competition authorities has been laid out in quite distinct ways. The sectoral regulator may have to obtain a binding opinion from the competition authority (Denmark). In France and Germany authorities must inform each other, though in practice in Germany the sectoral regulator has the option to intervene first. Italy and Sweden give priority to the competition authority, which may have to receive an opinion from the sectoral regulator. The Netherlands and the UK require concurrency: explicit coordination of decisions between authorities.Footnote 2 In the US, the Department of Justice shares jurisdiction with the FCC (Federal Communications Commission) in the telecommunications and media sectors and the FERC (Federal Energy Regulatory Commission) in the energy sector. In this paper we mostly take the existence of two authorities as given. Our focus is on investigating the determination of incentives for each authority to intervene and on the informational advantages of two independent views over the same case.Footnote 3
\(^{,}\)
Footnote 4 The explicit acknowledgment of the incentives that face the relevant economic authorities is, of course, crucial to institutional design. Under “cooperation”, or joint decision making, both economic authorities must have successfully concluded an investigation into the same matter and agree on having a case of anti-competitive behavior. It takes to the extreme the duty of consulting the other economic authority. Under “competition”, or independent decision making, a case is closed as soon as one of the authorities successfully concludes the investigation, irrespective of whether the other authority has come to a conclusion or even opened a case.Footnote 5
 The overlap of jurisdictions leads to lower effort in both cases. If each authority’s equilibrium probability of finding anti-competitive behavior is high, then competition induces lower efforts than does cooperation (and vice-versa if this probability is low). More important, under competition both the probability that anti-competitive behavior is challenged and total welfare are higher: institutional design should allow for “competition” between economic authorities rather than forcing joint decision making. These results rely on the common “social welfare standard” of valuing consumer surplus and firms’ profits equally. Often, though, authorities are biased, either because their mission is to concentrate on protecting consumers, or because they are captured by firms. We find that the optimum allocation of efforts cannot be achieved under bias, not even if the other authority could be given a “corrective bias”. Interestingly, this optimal corrective bias may go in the same direction as the bias that is to be corrected. Still, having two economic authorities with overlapping jurisdictions tends to be welfare-improving when lobbying and biases play an important role. Section 2 sets out our model, and Sect. 3 discusses the relation between the authorities. In Sect. 4 we consider biases in the objective functions of authorities. Section 5 presents some extensions of the basic model, while Sect. 6 concludes.",2
52.0,3.0,Review of Industrial Organization,14 December 2017,https://link.springer.com/article/10.1007/s11151-017-9608-6,Ex-post Evaluation of Mergers in the Supermarket Industry,May 2018,Tiago Pires,André Trindade,,Male,Male,Unknown,Male,"The focus of antitrust enforcement agencies throughout the world is, most frequently, to perform counterfactual experiments for future scenarios. Less often is the goal to evaluate what did in fact occur. Retrospective merger reviews can nevertheless be an important instrument for antitrust authorities. Not only can they be used to reverse policy recommendations but also to help in forecasting the future. By quantifying the impact of mergers ex-post, we can evaluate the effectiveness of the current merger guidelines and whether rules are too aggressive or too soft (Hosken 2011; Kwoka 2013). This paper evaluates the effects of horizontal mergers in the supermarket industry that took place in the US over the period 2003–2005. We restrict our attention to mergers that create changes in market concentration.Footnote 1 We perform the analysis by matching a list of supermarket merger events over this period with store-level data from Nielsen Scantrack. The supermarket industry is particularly interesting to study because consumers care not only about prices, but also about the variety of products offered (Bureau of Labor Statistics 2010). Our paper relates to the broad literature on merger evaluation, but is more closely related to a subset of the literature that uses information from past events to recover the impact of horizontal mergers.Footnote 2 The string of papers in this branch of the merger literature can be divided into two groups: those that use other products in the same industry (but produced by firms not directly taking part in the event) as controls; and those that use outside markets as the counterfactual scenario.Footnote 3 We employ the second approach.Footnote 4
 We use a difference-in-differences type estimator to separate time patterns and time-invariant unobserved heterogeneity from the effects of the merger. The analysis is therefore based on comparisons between stores in cities with mergers and stores in cities without mergers. Due to the richness of our data, which includes mergers at different moments in time, we are able to disentangle the causal effects from confounding unobserved time effects.Footnote 5 We further contribute to the literature by estimating the effects of mergers on product variety, and assessing the existence of any differential effect between the short term and the long term.Footnote 6
 Our baseline results reveal a 3% increase in variety post-merger for supermarkets that are located in event cities, but no effect of mergers on average prices.Footnote 7 Our results therefore indicate that mergers may have stronger effects on variety than on prices, which is the main focus of most of the existing literature.Footnote 8 The rise in variety for supermarkets that are located in event cities is explained by Other stores–supermarkets from chains not taking part directly in the merger—for whom variety increases more than 4% after a merger. Our estimates suggest that the mergers’ effects depend on observed characteristics of the cities where the merger occurs - particularly on market concentration. In the next section we discuss the potential effects of mergers on the outcomes that we analyze. Section  3 describes the data and the construction of the list of events; then, in Sect.  4, we present our estimation and identification strategy. Finally, Sect.  5 reports and discusses the results.",3
52.0,3.0,Review of Industrial Organization,05 March 2018,https://link.springer.com/article/10.1007/s11151-018-9622-3,A Brief History of the Review of Industrial Organization (RIO) and the Industrial Organization Society (IOS),May 2018,William G. Shepherd,,,Male,Unknown,Unknown,Male,,3
52.0,4.0,Review of Industrial Organization,17 January 2018,https://link.springer.com/article/10.1007/s11151-017-9611-y,Frederic M. Scherer: Over a Half Century—and Counting—of Seminal Scholarly Contributions,June 2018,David B. Audretsch,Albert N. Link,John T. Scott,Male,Male,Male,Male,,3
52.0,4.0,Review of Industrial Organization,02 April 2018,https://link.springer.com/article/10.1007/s11151-018-9629-9,Intangible Investment and Firm Performance,June 2018,Nathan Chappell,Adam Jaffe,,Male,Male,Unknown,Male,"Throughout his career, F. M. Scherer was interested in the determinants of firm performance, including how strategy and investment decisions—particularly related to technology and innovation—contributed to performance. The possible importance of management and R&D in productivity is an aspect of a broader developing realization of the importance of intangible investment in firm performance (Corrado et al. 2009, 2012; Bontempi and Mairesse 2015). We can think of firms as having stocks of intangible capital of various kinds, in the form of: knowledge about production possibilities; practices and procedures; strategies; organizational structures; etc. Intangible investment increases these stocks, just as traditional investment increases traditional capital such as machines and structures. And an increase in intangible capital should increase firm output and the productivity of labour, in a manner that is analogous to that resulting from increases in tangible capital. If we could measure the stocks of intangible capital, we could include them in estimating production functions for firms, and estimate their effect on output and their rates of return. But if we don’t include them in the production function, then their impact on output flows through to the “residual” or the productivity of the firm. This means that, in principle, observed differences in productivity could be due to underlying differences in the extent of intangible investment. Similarly, since we would expect firms to earn a return on their intangible investment, the profitability of the firm—measured in the traditional manner as profits relative to the value of traditional capital—should be increased by intangible investment. An alternative view could be that firms engage in intangible investment (e.g. employee training, organizational restructuring, new product designs) in response to perceived weakness or threats to the business. While this possibility is not inconsistent with such investment’s having a productivity and profitability payoff, it suggests that observed investment might be concentrated in poorly performing firms and perhaps is thereby obscuring an underlying positive causal effect of intangible investment on productivity.Footnote 1
 In this paper, we try to untangle the relationships among intangible investment, firm characteristics and environment, and firm performance, with the use of New Zealand firm-level survey data on intangible investment that is linked to administrative and tax records of firm performance and characteristics. We examine both the characteristics of firms that are associated with intangible investment, and what firm performance looks like subsequent to such investment. To preview our findings: The results suggest that—when we compare firms within a narrowly defined industry—intangible investment is highest in larger firms, younger firms, and firms that face moderate competition in the marketplace. Contrary to the prediction from the simple version of the investment story, we find no evidence that higher intangible investment is associated with higher productivity or higher profitability. Subsequent to reporting intangible investment, firms appear to increase spending on both capital and labour, and they report an increase in deflated revenue; but the rates of increase of inputs and outputs are such that measured productivity and profitability do not increase. Consistent with this “growth without profit” picture, we find some evidence that intangible investment is associated with subsequent improvement in ‘soft’ aspects of firm performance such as firm-reported customer and employee satisfaction. Because all of our variables are determined jointly by the decisions of the firm, it is very difficult to draw causal inferences with regard to the empirical associations we have found. Nonetheless, we have sliced the data many different ways and found little evidence of intangible investment’s contributing positively to productivity in New Zealand. Further, we find no evidence that firms that invest in intangibles are underperformers before undertaking the investment, so it appears unlikely that a positive investment effect is being concealed by a negative selection effect. Thus it appears that low intangible investment is a not a likely candidate for a large contribution to New Zealand’s relatively poor productivity performance. Instead, such investment appears to be associated with firm growth, and possibly improvement in firm performance along dimensions that are not captured by productivity statistics. The results do not allow us to say whether intangible investment causes firm growth, in the sense of being a choice available to any firm that wants to grow faster. But it is clearly associated with growth, which suggests that in at least some situations it is a necessary factor for growth.",20
52.0,4.0,Review of Industrial Organization,07 February 2018,https://link.springer.com/article/10.1007/s11151-018-9617-0,Propensity to Patent and Firm Size for Small R&D-Intensive Firms,June 2018,Albert N. Link,John T. Scott,,Male,Male,Unknown,Male,"Scherer (1965, 1967a, b, 1970, pp. 346–399) provided the foundational papers that set the research agenda for scholarly investigations of the Schumpeterian hypotheses about seller concentration and rivalry in research and development (R&D) investments and about the advantages of firm size for R&D investments. His subsequent research and reviews of the literature about the Schumpeterian hypotheses (Scherer 1980, pp. 407–458, 1983a, b, 1984a, b; Ravenscraft and Scherer 1987; Scherer and Ross 1990, pp. 613–660) have furthered our understanding of these issues and extended the breadth and scope of related research agendas. In the context of Scherer’s foundational work, this paper not only complements the existing literature but also provides a new perspective on the Schumpeterian hypothesis about firm size.Footnote 1
 The remainder of the paper is outlined as follows: In Sect. 2, we discuss the Schumpeterian firm-size hypothesis with regard to the advantages of firm size for the performance of R&D investments, and we explain the theory that underlies our new test of that hypothesis. Section 3 describes the sample of research projects in small R&D-intensive firms that we use to test our hypothesis. Section 4 presents the associated econometric model; also in Sect. 4 are definitions of the variables in our estimation, relevant descriptive statistics, and a discussion of the estimates. Section 5 compares our findings to the findings in the literature about the Schumpeterian firm-size hypothesis. Finally, Sect. 6 concludes the paper and emphasizes the ways in which our analysis both complements the extant literature about the Schumpeterian firm-size hypothesis as well as extends it.",17
52.0,4.0,Review of Industrial Organization,09 February 2018,https://link.springer.com/article/10.1007/s11151-018-9616-1,Value Based Pricing of Pharmaceuticals in the US and UK: Does Centralized Cost Effectiveness Analysis Matter?,June 2018,William S. Comanor,Stuart O. Schweitzer,Frederic Schoenberg,Male,Male,Male,Male,"Among Scherer’s major research areas is the economics of the pharmaceutical industry. He returned frequently to the particular issues found in that industry. In addition to his many specific research findings, he produced two lengthy and detailed handbook chapters: “The pharmaceutical industry” (2000); “Pharmaceutical innovation” (2010). Both chapters combine insightful commentary on existing literature along with presentations of the author’s new findings. Among the issues that were emphasized in his first Handbook chapter is a review of the various means that have been used to regulate drug pricing outside the United States. These include the following alternatives: International price comparisons so that a country’s drug prices are set according to those in other “reference” countries. Administrative price setting that employs product criteria such as a product’s novelty and perhaps also the manufacture’s nationality. Administrative price that is based on argument and persuasion—especially for highly profitable products. Administrative price setting with prices linked to overall firm profitability rather than to individual products. Following his review, Scherer (2000, p. 1331) summarized his conclusions in the following statement: Efforts by national authorities to curb pharmaceutical costs and offset the demand-increasing effects of generous health care insurance by imposing drug price controls are found throughout the industrialized and less-developed world. These sometime succeed in their proximate goal, but cause bulges in other parts of their health care balloon, bias new research and development incentives, and distort international trade and investment patterns. Scherer’s point is that—despite their laudatory goals—regulatory actions may create economic distortions even when successful in achieving their primary objective. Increasingly, government policies that are directed towards limiting pharmaceutical prices have emphasized value-based criteria. Price levels should be supported, many argue, only when justified by therapeutic improvements but not otherwise. Particularly since pharmaceuticals are increasingly paid from public funds, national health authorities should make certain that value is received for the outlays involved. While this judgment directly applies to the developed countries of Europe and Asia, it is increasingly relevant for the United States where nearly 40% of all prescriptions filled currently are paid through the Medicare and Medicaid programs (IMS 2015, p. 45). This regulatory approach is most clearly formalized in the United Kingdom where the National Institute for Health and Clinical Excellence (NICE) was created within the British National Health Service (NHS). Its assigned function was specifically to apply cost-effectiveness analysis to new drugs along with other medical interventions. New drugs specifically would be judged as cost effective or not, and then the NHS would provide reimbursement support only for pharmaceuticals which had passed this test. Through this mechanism, the therapeutic value of new drugs would be assured. Critically, when making its determinations of whether new drugs are cost effective, NICE considers the drug company’s prices as fixed. Indeed its officials assert they have no effect on prices (George 2010). In contrast to Britain, there is no formal regulatory mechanism that assures cost-effectiveness in the United States. While the primary regulatory authority that deals with pharmaceuticals—the US Food and Drug Administration (FDA)—is required to certify the safety and efficacy of all new pharmaceuticals, its mandate does not apply to prices. Furthermore, the Medicare authority is not authorized to negotiate prices centrally with drug manufacturers (Schweitzer 2007, pp. 218, 219). In this manner, questions of cost effectiveness are specifically left to market processes. In this paper, we examine the pricing implications of these alternate regimes. We ask whether the explicit attention that is paid in the UK to questions of cost-effectiveness matter. Our essential hypothesis is that value-based pricing is enforced by both regulatory and market processes, and with similar outcomes.",8
52.0,4.0,Review of Industrial Organization,16 January 2018,https://link.springer.com/article/10.1007/s11151-018-9615-2,Industrial Organization and the Organization of Industries: Linking Industry Structure to Economic Performance,June 2018,David B. Audretsch,,,Male,Unknown,Unknown,Male,"The thesis of this paper is that the scholarly field of industrial organization is shaped and directed by the debate concerning some of the most pressing policy issues at any historical time period about the link between the organization of industries and economic performance. By industrial organization, we mean the scholarly field of research as defined by Scherer (1970, 1980) and Scherer and Ross (1990). By the organization of industries, we mean the actual way in which economic activity is organized within the unit of observation of an industry. As Scherer (1970) explained in his path-breaking book, Industrial Market Structure and Economic Performance, the first stirrings of industrial organization as a field came as a response to the emergence of the trusts of the late 1800s and their perceived adverse impact on performance criteria such as prices and profits. Not only were the trusts alleged to have demolished family businesses, farms in the Midwest and entire communities, but also the public policy debate at the time accused them of threatening the underpinnings of democracy in the United States. In arguing for the passage of the 1890 Act, Senator Sherman argued, “If we will not endure a King as a political power we should not endure a King over the production, transportation, and sale of the necessaries of life. If we would not submit to an emperor we should not submit to an autocrat of trade with power to prevent competition and to fix the price of any commodity”.Footnote 1
 As Scherer (1970) also made abundantly clear, the field of industrial organization solidified in the 1930s when there was concern that prices were not downwardly flexible. Scholars in the field (Scherer 1970, chapter 12, pp. 284–303) developed theories of administered pricing to explain the power of large corporations to maintain price levels even in a regime of falling demand. As Scherer also explained, a series of studies in the field of industrial organization were undertaken attempting to link price flexibility to the degree of concentration, which suggested that the Great Depression may have been prolonged by large corporations exerting market power to main price levels. A central focus of Industrial Structure and Economic Performance (Scherer 1970) was on the relationship between firm size and productive efficiency. One of the central policy concerns throughout the post-World War II era was the perceived military and economic competition with the Soviet Union. Nikita Khrushchev had squarely provoked the United States with the provocative challenge that the “growth of industrial and agricultural production is the battering ram with which we shall smash the capitalist system.”Footnote 2 The Soviet Union, thanks to its system of centralized planning and production, could enjoy the efficiency gains accruing from large-scale production without worrying about any deleterious effects due to the shortcomings of market competition. This left public policy in the United States as throughout the west with a dilemma. The commitment to market competition might place limits on permissible firm size and market concentration, which could compromise technological efficiency and productivity in this perceived national competition versus the Soviet Union. At the same time, maximizing efficiency and productivity to ward off this “red scare” might result in levels of market concentration not commensurate with competition, low prices and allocative efficiency. Perhaps it was the ability and relevance in addressing one of the most pressing public policy issues of that era that led to the ascendance of industrial organization as one of the most important and recognized fields of economics during the Zeitalter in which Scherer published the three editions of his book. In organizing and assessing a massive literature examining those very issues, Industrial Market Structure and Economic Performance provided a framework for identifying and analyzing this tradeoff and for framing the public policy response in terms of antirust or competition policy, regulation, and public ownership to deal with this tradeoff (Williamson 1968). In particular, Industrial Market Structure and Economic Performance spans and synthesized a broad spectrum of painstaking and meticulous empirical studies to identify how much market concentration existed and how it was evolving, along with its impact on economic performance. Long before the cold war was resolved, a different policy challenge emerged. The OPEC price shock for crude oil in October 1973 triggered unprecedented waves of simultaneous increases in unemployment and inflation, or what become known as “stagflation” throughout the remainder of the decade. The field of industrial organization was where thought leaders in business and policy again turned for solutions. In rising to the call, scholars in industrial organization responded by resurrecting the Administered Pricing thesis and undertook a wave of studies to determine the impact of market power on price increases. The stagflation of the 1970s gave way to a new pressing policy issue in the 1980s: the loss of competitiveness in the traditional manufacturing industries to countries such as Germany and Japan (Derouzos et al. 1989). As American corporations responded with massive waves of downsizing, and employment levels fell in the traditionally strong industries such as autos and steel and tires, the public policy debate shifted from constraining large corporations towards enabling more success in terms of creating sustainable, high-paying jobs (Thurow 2002). In this paper we examine how and why the field of industrial organization generated so much interest and excitement during the era corresponding to publication of the three editions of Scherer’s seminal work, Industrial Structure and Economic Performance. The paper concludes that it was the ability to address the compelling issues of its era that confronted public policy that made the academic field of industrial organization not just interesting but also highly relevant and timely. In particular, by analyzing how and why the organization of industries matters for economic performance, along with the various policy approaches available to public policy, under the stewardship of F.M. Scherer the scholarly field of industrial organization prospered and flourished.",10
53.0,1.0,Review of Industrial Organization,28 March 2018,https://link.springer.com/article/10.1007/s11151-018-9628-x,Introduction to the Special Issue on “The Intersection Between Industrial Organization and Healthcare Economics”,August 2018,Christopher M. Snyder,Victor J. Tremblay,,Male,Male,Unknown,Male,"This special issue is located at the intersection between the subfields of industrial organization (IO) and healthcare economics. As Fig. 1 documents, this intersection is a “hot” research area.
 The black curve plots the percentage of the IO literature (as proxied by articles indexed by EconLit having an L, the code for IO, in one of their subject descriptors) on a healthcare topic (as proxied by the mentioning “health” somewhere in the paper). Fewer than 2% of the IO articles that were published in 1991—only 23 of them—were on healthcare. By 2016, the IO literature itself had grown almost 10 fold to over 10,000 articles. The healthcare segment constituted a growing share—6%—of this growing literature, with over 600 articles in the intersection published that year. Notice the particularly rapid growth in the relative attention paid by IO to healthcare over the last five years.Footnote 1
 Various explanations for this explosion in interest in the IO/healthcare intersection come readily to mind: one is that a steadily growing fraction of the economy is devoted to healthcare. This is documented by the grey curve in Fig. 1, which shows that between 1991 and 2015 the percentage of U.S. GDP that was devoted to healthcare expenditures grew by five percentage points: from nearly 13% to nearly 18%. It is natural that IO economists’ interest should grow in proportion to the size of the industry in question. A second explanation is that a growing share of research and development (R&D) expenditure is being poured into the healthcare sector: From 1991 to 2015, the share of U.S. R&D in the healthcare sector grew from 16 to 32%.Footnote 2 It is natural for IO economists—especially those specialists in innovation and technological change—to train their lens on the dynamic healthcare sector. A third explanation is that important healthcare reforms—such as the U.S. Affordable Care Act of 2010 (popularly known as “Obamacare”)—were contemplated or enacted during the period; these reforms had interesting IO implications in addition to sweeping ramifications for the overall economy. It is natural for IO economists to want to contribute to the analysis of these policies. Sources: The grey curve is based on the Excel table NHE15_Summary.xls, retrieved on September 27, 2017 from https://www.cms.gov/Research-Statistics-Data-and-Systems/Statistics-Trends-and-Reports/NationalHealthExpendData/NationalHealthAccountsHistorical.html. The black curve is based on authors’ count of articles returned by EconLit searches over all Journal of Economic Literature subject descriptors in the L (industrial organization) category each year, calculating the percentage of those articles mentioning “health.” The authors conducted the counts on September 27, 2017, using the version of EconLit for American Economic Association Members available at https://www.aeaweb.org/econlit/econlit-for-members Growth in relevance of healthcare as an IO topic We suggest another reason for the explosion in the IO/health intersection: the dawning realization that healthcare markets—unique as they are—are not necessarily more distinctive than airlines, electricity, or hundreds of other markets that IO economists have studied for decades; see Chandra et al. (2016) for an argument along these lines. The tools that have been honed by IO economists in their analysis of these other markets—with all due care to understand the relevant institutional details in each new setting—can be fruitfully applied to health markets.",1
53.0,1.0,Review of Industrial Organization,14 December 2017,https://link.springer.com/article/10.1007/s11151-017-9609-5,Vertical Alignment Between Hospitals and Physicians as a Bargaining Response to Commercial Insurance Markets,August 2018,Ian McCarthy,Sean Shenghsiu Huang,,Male,Male,Unknown,Male,"Hospital employment of physicians increased by 55% from 2003 to 2011, and over 50% of physicians now identify themselves as employees rather than in private practice (MedPAC 2013; The Physician’s Foundation 2012). These numbers reflect the quickly changing relationship between physicians and hospitals over the last decade, with the employer–employee model supplanting the traditional medical staff model of private physicians with hospital admitting privileges. With healthcare accounting for nearly 20% of U.S. GDP and $3 trillion in total spending (Gaynor et al. 2015), these dramatic changes in healthcare market structure may significantly affect future spending, broader economic growth, patient health, and labor market outcomes for physicians, nurses, and other healthcare professionals. The goal of the current paper is to examine the potential motivating factors for this increase in physician–hospital alignment. We focus in particular on alignment as a tool to increase bargaining power with private insurers. Examining vertical integration as a bargaining response is important for several reasons: For example, there is increasing concern among policy makers surrounding this form of vertical integration in healthcare—particularly in relation to the formation of Accountable Care Organizations (ACOs). Such integration can improve coordination of care and thus (it is argued) offer more efficient care delivery; however, these effects likely depend in part on the underlying motivation for alignment. In addition, a variety of recent federal healthcare policies may influence competition in the private health insurance market (e.g., minimum benefits and restrictions on plan pricing), and evaluating the full effects of such policies should include any subsequent responses from other entities. To date, much of the current literature with respect to competitiveness in the health care provider market has focused on the effects of hospital mergers or system-joiners (i.e., horizontal integration) rather than the effects of physician–hospital alignment (i.e., vertical integration).Footnote 1 The literature generally finds an increase in hospital prices following mergers and system-joiners, with ambiguous effects on quality (Alexander et al. 1996; Kessler and McClellan 2000; Dranove and Lindrooth 2003; Dafny 2009; Spang et al. 2009; Harrison 2011).Footnote 2 In studies that focus specifically on physician–hospital alignment, Cuellar and Gertler (2006) found that alignment led to higher prices and no efficiency gains, while Ciliberto and Dranove (2006) found no effect of vertical integration on hospital prices. In related studies, Afendulis and Kessler (2007) found that overall Medicare expenditures increased when patients with coronary artery disease were treated with a physician as part of an integrated network relative to a nonintegrated physician. Baker et al. (2014b) similarly found that an increase in market share for more vertically integrated systems was associated with higher prices and increased spending. Existing studies therefore indicate that physician–hospital alignment increases spending, with potential increases in prices as well.Footnote 3
 Gone largely unexamined thus far is the underlying motivation for increased physician–hospital alignment. Some exceptions include Burns et al. (2000), Cuellar and Gertler (2006), and Brunt and Bowblis (2014). Burns et al. (2000) examined the relationship between the managed care market and the number of hospitals with some form of physician alliance; they find that hospital alliances with physicians were significantly more common in areas with more managed care payers. Cuellar and Gertler (2006) study this relationship by looking at hospital transitions from one form of alignment to another. Based on data for Arizona, Florida, and Wisconsin from 1994 through 1998, they find a statistically significant relationship between physician–hospital alignment and managed care penetration. Citing survey evidence from health care providers, Gaynor and Town (2012b) further discuss how physician–hospital alignment appears to be driven in part by incentives to increase bargaining power with insurers and perhaps less driven by efficiency gains or cost savings. And more recently, Brunt and Bowblis (2014) examined the relationship between concentration in the insurance market and consolidation among primary care physicians; they find that physicians were more likely to work in larger practices or be owned by a hospital when insurance markets were more concentrated. Extending this literature, we examine the motivation for physician–hospital alignment by investigating the relationship between concentration in private insurance markets and the degree of alignment between hospitals and physicians. Our analysis makes three primary contributions relative to the existing literature: First and most important, we consider vertical integration as a potential bargaining mechanism with private insurance. This differs from Brunt and Bowblis (2014), who included horizontal integration across physicians and physician groups in their measure of alignment. This also differs from Burns et al. (2000), Cuellar and Gertler (2006), and Ciliberto and Dranove (2006), who study the relationship between vertical integration and managed care penetration. In a bargaining context, it is the market power of private insurers that is arguably most relevant, as opposed to the overall presence of managed care. For example, a large managed care presence that is concentrated on one insurer offers a very different bargaining setup relative to a market with a similarly large managed care presence but spread across several small insurers. Second, our methodology allows for a broader assessment of physician–hospital alignment by considering different levels of integration, as opposed to the binary treatment of integration in Burns et al. (2000). Specifically, we consider the following “levels” of integration: (1) the typical medical staff model (least aligned); (2) hospital administrative support with relatively few restrictions of physician practice patterns; (3) hospital support along with influence on physician practice patterns; (4) hospital employment of physicians; and (5) an equity model in which physicians share in the financial outcomes of the hospital (most aligned).Footnote 4 Related to this second contribution, our analysis is broader in scope relative to existing studies, and we examine all hospitals across the U.S. rather than a specific geographic subset of hospitals (Cuellar and Gertler 2006; Ciliberto and Dranove 2006). We also pursue a range of sensitivity analyses, including allowing for misreported physician–hospital alignment using the monotone rank estimator (Cavanagh and Sherman 1998; Abrevaya and Hausman 1999; Hausman 2001), as well as allowing for endogenous insurance market concentration. Third, we consider the differential response to commercial insurance markets across observable hospital characteristics. These differential responses are important not only for understanding the underlying motivation for physician–hospital alignment, but also for appropriate policy evaluation. For example, the Affordable Care Act fundamentally changed the structure of the commercial insurance market, as well as directly influencing healthcare delivery and hospital behaviors. Hospital and physician responses to these changes in health insurance markets are not well understood but are critical to an appropriate evaluation of these policies. In addition, several states attempt to regulate alignment between physicians and hospitals, often with different restrictions across hospital types (Lammers 2013). If physician–hospital alignment derives in part from commercial insurance market pressures, then these regulations may differentially prohibit the natural bargaining response. The subsequent welfare consequences, although beyond the scope of this paper, will depend in-part on which types of hospitals or markets are able to respond more quickly to commercial insurance pressures. Our analysis is based on data from the 2009–2011 American Hospital Association (AHA) Annual Surveys and commercial insurance data from the American Medical Association (AMA) annual reports on competition in the private health insurance market. Our overall results suggest that increased concentration in the private insurance market significantly affects vertical integration between hospitals and physicians, with a 1% increase in private health insurance concentration associated with a 0.16% increase in hospital employment of physicians and a 0.36% increase in the number of equity relationships. We also find a differential response to private insurance pressures across ownership type, with larger effects among for-profit hospitals but no significant effects among not-for-profit hospitals. The remainder of the paper is organized as follows: in Sect. 2, we discuss the theoretical support for a relationship between private insurance markets and hospital bargaining effort. Section 3 describes our data in more detail and presents summary statistics. Sections 4 and 5 present our analysis of the relationship between commercial insurance markets and physician–hospital alignment, and Sect. 6 concludes.",9
53.0,1.0,Review of Industrial Organization,27 October 2017,https://link.springer.com/article/10.1007/s11151-017-9595-7,Governance Structure and Exit: Evidence from California Hospitals,August 2018,Keaton S. Miller,Wesley W. Wilson,,Male,Male,Unknown,Male,"Roughly 60% of the hospitals in the United States are organized as non-profit organizations (Sloan 2000). These hospitals comprise the second largest sector of spending and employment by non-profit organizations, second only to education (Friesenhahn 2016). Indeed, according to National Health Expenditure Account data, total hospital spending across all organizational structures accounted for roughly 5.7% of US GDP in 2015(Centers for Medicare and Medicaid Services 2016). The industry consists of three different types of firms: Hospitals that are for-profit, non-profit, and owned by the government and churches. In this paper, we examine differences across these three groups with respect to size, utilization (as measured by turnover rate), and entry and exit behavior. We specifically focus on the degree to which the “non-profit” organizational status changes the behavior and competitive conduct of firms. In other industries, firm behavior has been studied primarily through the lens of prices and quantities of goods with different product characteristics. In general, econometricians with detailed data on prices and quantities may recover policy functions and primitives of firm profit functions by making assumptions with respect to competitive conduct. However, given the wide range of services that are offered by hospitals (Gaynor et al. 2013), the prevalence of multi-plant firms—i.e., hospital systems—the negotiations that are involved on the demand side (Gowrisankaran et al. 2015), and the difficulties in data procurement, this approach has had only limited success in the hospital industry. In the face of these difficulties, we turn to an alternative set of decisions: exit. To the extent that for-profit and non-profit firms differ in their cost structure and objective functions, those differences must flow through to their exit policy functions just as they would to any other firm decision. Using administrative data on the universe of California hospitals from 1980–2013, we estimate flexible exit policy functions with a variety of geographic controls and hospital state variables, and we test the null hypothesis that for-profit and non-profit firms pursue identical strategies. To isolate the effects of governance structure on these decisions, we control for several other factors: First, services that are offered by different hospitals may be offered at different quality levels, with differential effects on both costs and demand that may flow through to the relevant policy functions. Indeed, models of non-profit firms often include a measure of quality or social welfare in the firm’s objective function (Chang and Jacobson 2012). Theoretical and Monte Carlo results from models of competition with a quality dimension find that lower-quality firms are more likely to exit, ceteris paribus (Ericson and Pakes 1995). Unfortunately, our data do not include any direct measures of quality. The literature on hospital quality (see Gaynor and Town 2011, for a review) has largely found a positive relationship between the local level of competition and the quality of hospital services (as measured by patient mortality). Additionally, to the extent that information on hospital quality is available to the demand side, firms with higher levels of quality (or to be precise, a superior price/quality ratio) may enjoy higher utilization rates. Therefore, our specifications include measures of local competition and average turnover rates. We also include measures of the breadth of services provided, as firms with a more diverse set of product offerings may be able to self-insure if demand or cost shocks in one specialty would otherwise lead to exit. In general, many changes in health products have stemmed from changes in medical technology. Consequently, firms with different vintages of capital may face alternative cost structures—e.g., the cost of rewiring a 1950s-era hospital building to support a modern computer network infrastructure may be much higher than the cost of incorporating that infrastructure in a new building—which affect their policy functions. As a robustness check, we estimate exit functions both for the set of firms that were present in 1980 and the set of firms that entered between 1981 and 1990. Finally, multi-plant firms have significantly increased in prevalence throughout the last 25 years. Nearly half of the hospitals that were present in California in 2013 are members of a multi-hospital network. Hospitals within these networks may behave according to alternative policy functions for a variety of reasons, including both the opportunities for financial risk-sharing that is afforded by the network and effective increases in market power when negotiating with insurers. We address these possible effects by incorporating an indicator variable that represents membership in one of these networks. Across specifications, we find significant differences in behavior between firms with different governance structures. These differences are largely driven by the differential impact of membership in a multi-hospital firm between for-profit and non-profit establishments; but they also stem from a difference in the baseline probability of exit after controlling for firm-, competitor-, and market-level characteristics. To complete our analysis of these decisions, we additionally characterize the entrants during the period relative to both the remaining incumbents and the simultaneous exiters. We find that new firms are likely to locate in relatively less competitive areas (as measured by the number of competitors within a given radius of the new firm) and in wealthier and less dense areas. While entrants are larger than are contemporaneous exiters, they are on average smaller than firms that were active through the entire period. Our focus on California is driven by the wealth of administrative data that were collected by the state’s Office of Statewide Health Planning and Development (OSHPD) from 1980 to 2013. Each year, each licensed hospital is required to report detailed information on its finances and operations. The data cover a period of significant turnover in the hospital market. Overall, we find yearly entry and exit rates that average 9.5 and 10% respectively. In 1980, California had 488 short-term-care general hospitals. By 2013, there were only 328 hospitals, of which 273 were incumbents that survived through the entire study period. Despite these changes, the total number of licensed beds decreased only 7%, from 85,043 to 78,425, even though the population of California increased over 50% during the period. This paper builds on several related literatures: First, we build on an extensive literature that examines the differences between for-profit and non-profit hospitals, reviewed by Sloan (2000) and more recently by Gaynor and Town (2011). In general, many of these studies have focused on behaviors with respect to particular outputs or in response to individual policy changes and seek to identify whether non-profits are simply “for-profits in disguise” in the sense that both types of organizations pursue the same objectives or purposes (Weisbrod 1988). For instance, Duggan (2002) examined the response to a change in California’s Medicaid reimbursement system and concluded that non-profit hospitals mimic the behavior of for-profit hospitals, if the for-profit firms are nearby. In contrast, Bayindir (2012) investigated the treatment choices of hospitals across governance structures and found that non-profits differ substantially from for-profits when treating less profitable patients. Our results are consistent with a rejection of the “for-profits in disguise” hypothesis. Other approaches have yielded similar results, such as Gowrisankaran and Town’s (1997) dynamic model of oligopoly in the hospital sector based on the quality ladder model of Ericson and Pakes (1995). Using aggregate data from 1991, they estimate several parameters that characterize the differences between for-profit and non-profit hospitals and find that non-profit hospitals are longer lived and have higher quality. Our approach, driven by micro-level panel data, allows us to control for a broader range of hospital-specific characteristics. Within this literature, our work is perhaps closest to the Hansmann et al. (2003) analysis of capacity reduction in the hospital industry. They viewed changes in hospital capacity as stemming from reductions in demand as measured by changes in local population, and employed national survey data that were collected by the American Hospital Association to estimate varying rates of capacity reduction across organization structures. They find, in general, that non-profit hospital bed capacity at the zip-code level changes more slowly relative to for-profit bed capacity in response to changes in local population. In contrast, we examine entry and exit at the hospital level and control for the competitive environment and conditions that are faced by each hospital. Similarly, Ciliberto and Lindrooth (2007) studied hospital exit during the 1990s as a function of hospital reimbursement rates and efficiency. They find that changes in overall market conditions led to differential effects during their study period and conclude that hospital efficiency was much more relevant to exit decisions in the late 1990s than earlier in the decade, while the role of Medicare decreased throughout the period. In addition to the hospital studies, there is a long history of both theoretical and empirical research on industry evolution and exit. Much of the empirical work builds off the work of Jovanovic (1982) and Ghemaway and Nalebuff (1985). Jovanovic (1982) provides a model of noisy industry selection, wherein firms enter an industry knowing the distribution of costs, but not their own position in the distribution. They learn over time, with some firms surviving and others exiting as they discover their “type.” Ghemaway and Nalebuff (1985) examine the order of exit by firms in a declining market. In a model with fixed capacities, Ghemaway and Nalebuff (1985) found that there was strategic liability of firm size, and predicted theoretically that large firms exit first. Ghemawat and Nalebuff (1990) allow for partial adjustments in firm capacities, and find that the largest firm is the first to adjust and continues until it is the same size as the smaller firm and thereafter firms reduce capacity at the same rate. Whinston (1988) extends the model to firms with multiple plants. He finds that size does not explain exit order and that multi-plant firms may have larger firms’ shutting down a plant first. Fudenberg and Tirole (1986) examine conditions of entry wherein a firm enters knowing its own costs, but not that of its rival. Over time, firms grow pessimistic about their rival’s costs, with the result that the longer that rivals survive, the sooner the firm will exit. Empirically, studies have attempted to delineate the role of inefficiency and cost with strategic reasons for exit (Lieberman 1990; Klepper and Simons 2005), competition and market imperfections (Deily 1991), evolution (Audretsch and Mahmood 1994), innovation (Audretsch and Mahmood 1995), and firm characteristics at the time of entry and exit decisions (Dunne et al. 2005). These studies identify a wealth of variables in specifying exit models. These variables include growth in the market, firm scale and size, whether the firm is a multi-plant firm, product diversity, measures of information, experience, etc., which we use to help guide our specification of hospital exit. Our examination of the characteristics of entrants and exiters is similar in style to the analyses that were popularized by Dunne et al. (1988). Like Audretsch and Mahood (1993), we find that firms tend to enter small and survival is driven by growth. Our approach can be related to the recent advances in two-step methods that are used to estimate the structural parameters of dynamic games. To take one prominent example: Bajari et al. (2007) show that reduced-form techniques can be used to estimate policy functions consistently. Due to the complexities that were mentioned above (in particular, the dimension of the product space), we do not try to recover estimates of the underlying cost and revenue structures that are faced by firms with different governance structures.Footnote 1 Instead, we focus on these functions themselves as containing important information about the differences in behavior between firms of different types. We proceed as follows: Sect. 2 describes our data on California hospitals and supplementary data on California geographies, and provides details about the entrants and exiters during the study period. Section 3 presents our econometric approach. Our results are discussed in Sect. 4, and Sect. 5 concludes.",3
53.0,1.0,Review of Industrial Organization,27 March 2018,https://link.springer.com/article/10.1007/s11151-018-9624-1,Does Competition Lead to Agglomeration or Dispersion in EMR Vendor Decisions?,August 2018,Seth Freedman,Haizhen Lin,Jeffrey Prince,Male,Unknown,Male,Male,"Over the past decade the fraction of hospitals that have adopted and used Electronic Medical Records (EMRs) has increased drastically. The U.S. federal government began incentivizing EMR adoption in 2011; and as of 2015, 96% of hospitals have implemented a system that meets government certification standards.Footnote 1 Correspondingly, EMR software has become a major industry, with $27 billion in revenues as of 2015.Footnote 2
 EMRs from different vendors typically are not interoperable, despite much of the perceived productivity and health-related benefits of EMR adoption hinging on hospitals being able to share patient information electronically. Since there are many EMR vendors to choose from, hospitals face a classic challenge in networked industries when making their EMR vendor choice: Is it better to differentiate from or coordinate with competing hospitals? As in many network technology adoption decisions, hospitals face countervailing incentives in their EMR vendor choice: Choosing the same vendor as local competitors would allow hospitals to exploit network effects by making it easier to exchange patient information with other local providers. This could lead to a number of benefits: First, information exchange can potentially improve patient care and lead to cost efficiency by allowing immediate access to patient medical records, saving physician time, reducing redundant tests, etc. As an additional incentive for hospitals to coordinate, information exchange and interoperability is a requirement to justify “meaningful use” and qualify for incentive payments under the 2009 Health Information Technology for Economic and Clinical Health (HITECH) Act. Coordination in vendor choice could also make adoption less costly. For example, there could be knowledge spillovers from nearby hospitals facilitating the adoption and use of an EMR from the same vendor. Last, there could be better technical support if vendors tend to invest more resources in markets where they have greater penetration. We categorize those potential benefits as network effects, which could lead to coordination in vendor choice.Footnote 3
 However, there are also costs associated with choosing the same vendor as local competitors. If hospitals can easily exchange patient information, patients may be more likely to switch providers. Baker et al. (2015) find that medical records impose a switching cost for patients. Miller and Tucker (2014) find evidence that large system hospitals strategically prevent outflow of patient data to maintain their competitive advantage. There is also anecdotal evidence that hospitals view clinical data as a key strategic asset, which tie physicians and patients to their organization (Grossman et al. 2008). Therefore, hospitals may have incentives to differentiate in order to lock-in their patients and physicians. We categorize these potential costs as business-stealing effects, which could lead to differentiation. Given the countervailing incentives of network and business stealing effects, it is an empirical question of what factors determine the incentives’ relative strengths and which effect is likely to dominate. In this paper, we quantify the extent to which markets exhibit adoption patterns that are characterized by agglomeration or by dispersion and thereby provide suggestive evidence as to the overall net effect of these two forces in EMR adoption. We then examine the role that hospital market concentration plays in determining whether adoption is more agglomerated or dispersed. On the one hand, greater market concentration could dampen network benefits, since each hospital is less reliant on coordination with other hospitals. On the other hand, greater market concentration could dampen business-stealing effects, since hospitals face less competitive pressure.Footnote 4
 We specifically examine EMR vendor choice by U.S. hospitals for their Clinical Data Repository (CDR) system: a hospital’s database of patient information. We use the multinomial test for agglomeration and dispersion (MTAD) (Augereau et al. 2006) to characterize market equilibrium CDR vendor choices. We find that hospitals tend toward agglomeration and that the level of agglomeration increases with hospital market competition. This relationship holds true among early adopters who had adopted CDR as of 2005, and becomes even more exaggerated as the technology diffused between 2005 and 2012. While our main analysis treats hospitals as individual firms, these results are also robust to treating hospitals within a market that are members of the same system as a single firm. Our findings have important implications both for public interest in interoperability (as shown through the HITECH Act) and for antitrust policy, especially at a time when hospital consolidation has been accelerating. They show that, as hoped, hospitals do tend toward agglomeration, likely leading to greater interoperability. However, the role of the HITECH Act in driving this tendency toward agglomeration is left to future research. With regard to antitrust policy, our results indicate that increased consolidation would lead to more dispersion of EMR vendor choices. Hence, a potential downside of hospital consolidation—increased obstacles in information sharing due to stronger incentives to differentiate—does seem relevant in this market and should be considered in the evaluation of hospital mergers. Our findings contribute to the existing literature in a number of ways. First, while other papers have explored the extent to which firms differentiate or coordinate when adopting network technologies (e.g., Augereau et al. 2006; Gowrisankaran and Stavins 2004; Desai 2014; Lin 2015), our paper is the first to our knowledge to examine explicitly the role of market structure in shaping the market equilibrium adoption outcomes. Our data allow us to measure market competition in the hospital setting using information on patient admission and to examine how the extent of agglomeration changes as the competitive landscape changes. Our paper is also different from most of the previous work on standards wars, because the EMR software industry exhibits much greater variety than other previously studied industries such as internet service providers and electronic payment in banking. In our context, no single EMR vendor has a market share that is greater than 30%, and only six vendors have a market share that exceeds 5%. Therefore, we are able to explore agglomeration and dispersion in a context where the adopting firms’ choice set is relatively large. Our paper also makes important contributions to the literature on health information technology. A growing literature explores the determinants of EMR adoption (Doolan and Bates 2002; Poon et al. 2004; Dranove et al. 2015b) and the effects of EMR adoption on outcomes such as cost and quality (e.g. Agha 2014; McCullough et al. 2013; Miller and Tucker 2011; Freedman et al. 2018; Dranove et al. 2015a). Our paper advances the literature on adoption decisions by specifically studying the role of market competition in shaping hospitals’ decisions of which vendor to adopt rather than just the extensive margin of whether to adopt EMR technology or not.",5
53.0,1.0,Review of Industrial Organization,23 March 2018,https://link.springer.com/article/10.1007/s11151-018-9625-0,The Role of Hospital and Market Characteristics in Invasive Cardiac Service Diffusion,August 2018,Jill R. Horwitz,Charleen Hsuan,Austin Nichols,Female,Female,Male,Mix,,
53.0,1.0,Review of Industrial Organization,15 March 2018,https://link.springer.com/article/10.1007/s11151-018-9623-2,"The Evolution of Health Insurer Costs in Massachusetts, 2010–2012",August 2018,Kate Ho,Ariel Pakes,Mark Shepard,Female,Male,Male,Mix,,
53.0,1.0,Review of Industrial Organization,09 April 2018,https://link.springer.com/article/10.1007/s11151-018-9627-y,Estimating the Causal Effect of Entry on Generic Drug Prices Using Hatch–Waxman Exclusivity,August 2018,Luke M. Olson,Brett W. Wendling,,Male,Male,Unknown,Male,"The relationship between generic drug prices and competition is receiving increased attention from policy makers who are concerned about rapidly growing medical care costs.Footnote 1 The National Health Expenditure Accounts estimate that 2015 expenditures on prescription drugs represented 10% of the $3.2 trillion that was spent on healthcare in the United States and that prescription drug expenditures rose 9% relative to 2014: a growth rate that exceeded any other category.Footnote 2
 Many policy makers view generic drug competition as the principal method to contain the growth in prescription drug costs. For example, an industry study suggests that generic drugs accounted for 3.8 billion of the 4.3 billion prescriptions (88%) in 2014, but only 28% of the respective drug expenditures.Footnote 3
 In addition, numerous laws, regulations, and legal precedents play an important role in directly affecting drug competition by altering the structure and competitive environment of these markets. For example, the Hatch–Waxman Act has been instrumental in shaping the competitive environment for both generic and branded drugs; the Supreme Court recently decided that some patent litigation settlements between branded and generic competitors may violate antitrust laws; and, Medicare Part D has led to significant changes in the provision of prescription drugs for the elderly.Footnote 4 These policies and precedents, alongside antitrust competition policy, underscore the importance of drug competition in U.S. healthcare policy. Policy makers’ reliance on generics to “rescue” the pharmaceutical market has not been fully supported by the empirical literature, which to date has found mixed effects of generic drug competition on prices. For example, Regan (2008) finds evidence of nearly perfect competition with a single generic competitor. In contrast, Reiffen and Ward (2005) find evidence that competition from competitors beyond the sixth and seventh entrants may continue to reduce prices. Neither result is consistent with leading theoretical models of oligopolistic competition among homogeneous goods that often predict that the first few entrants have larger effects on prices than later entrants. The inconsistencies in these patterns suggest that additional research is necessary to understand competition in generic drug markets better.Footnote 5
 In this paper, we revisit the empirical relationship between generic drug prices and the number of generic competitors. We set aside branded drugs and focus solely on generic competitors, and treat competitors in the market for the same generic drug as homogeneous. We devote special attention to whether endogenous selection is responsible for some of the discrepancies that are found in the empirical literature. In particular, we consider whether the relationship between price and competition is steeper for drugs that eventually attract numerous competitors. If endogenous selection biases the estimates of generic competition, then we would expect to see a relatively shallow relationship between price and competition in naïve correlations between the two. In particular, we expect that endogenous selection would result in relatively small effects for one, two, and three competitors but large price effects by later competitors. However, if we control for selection, we expect to see a relatively steep relationship between price and competition, since we expect that most of the price effect in these markets is due to these early entrants. Our analyses exploit a 180-day marketing exclusivity period that is awarded to successful patent litigants under the provisions of the Hatch–Waxman Act. We assume that the FDA’s marketing restrictions during the 180-day exclusivity period remove selection effects. We compare our estimates of generic competition inside to those outside the exclusivity period, and we attribute any differences in the estimates to endogenous selection since selection cannot occur during the generic exclusivity period due to regulatory restrictions on entry. We also divide samples into large- and small-market drugs. Since large-market drugs generally attract more entrants outside of the exclusivity period than small-market drugs, we expect the selection effects to be more pronounced in the sample of large-market drugs. We find that an additional generic competitor reduces generic drug prices by a statistically significantly greater extent during the 180-day exclusivity period than outside of the exclusivity period in the sample of large-market drugs. If we limit the analysis to the sample of drugs where there were patent-validity challenges to the incumbent’s patent, which may have more similar entry conditions to drugs that face a generic exclusivity period, the differences in the estimates of the effect of a third competitor are not statistically significant in the sample of small-market drugs either during or outside of the generic exclusivity period. We continue to find large and statistically significant differences among large-market drugs. However, the sample of drugs where there were patent-validity challenges includes some patent challengers that failed to win in court and thus did not have an exclusivity period. If we further limit the sample to only successful patent challenges—such that all of the drugs in the sample have a Hatch–Waxman 180-day exclusivity period—we find that our estimates exhibit similar patterns. However, limiting the sample to generic drugs with successful patent-validity challenges results in imprecisely estimated differences that are statistically insignificant. We also consider a different approach to estimating the influence of selection that does not rely on the Hatch–Waxman exclusivity period: we consider whether the “eventual” number of competitors—which is a crude measure of the “entry attractiveness”—is important in explaining price. We find that “eventual competition” is important in explaining price, especially for large-market drugs. This finding is also consistent with selection effects and corroborates our results from the Hatch–Waxman exclusivity period. We conclude that endogenous selection into generic drug markets has important implications for price and may affect inferences with regard to the effects of generic competition. Drug markets that are attractive to enter—perhaps because of low entry costs or favorable demand conditions—also appear to command lower generic prices (i.e., the relationship between price and competition is steeper for drugs that attract numerous competitors). Since significant entry into attractive markets occurs quickly, econometric estimates that fail to account for selection may underestimate the effects of early competitors (i.e., first through third) and overestimate the effects of later competitors (i.e., fourth and beyond). The next sections provide a background of the theory and the literature (Sect. 2), our identification strategy (Sect. 3), a description of the data (Sect. 4), and our results (Sect. 5). We conclude in Sect. 6.",7
53.0,1.0,Review of Industrial Organization,25 April 2018,https://link.springer.com/article/10.1007/s11151-018-9630-3,The Impact of the Entry of Biosimilars: Evidence from Europe,August 2018,Fiona M. Scott Morton,Ariel Dora Stern,Scott Stern,Female,Male,Male,Mix,,
53.0,1.0,Review of Industrial Organization,07 June 2018,https://link.springer.com/article/10.1007/s11151-018-9639-7,Are Important Innovations Rewarded? Evidence from Pharmaceutical Markets,August 2018,Margaret K. Kyle,,,Female,Unknown,Unknown,Female,"Drug prices are among the most controversial issues in health policy. Despite accounting for only 12.3% of total spending on health in the US and a median of 15% in the OECDFootnote 1, pharmaceutical prices have risen faster than inflation. High profile cases in recent years, including SovaldiTM and EpiPenTM, have also brought increased scrutiny. Critics note that pharmaceutical firms are among the most profitable, enjoying margins in excess of 25% in 2015 (Forbes 2015). At the same time, pharmaceutical treatments are credited with significant reductions in the burden of cardiovascular diseases, HIV/AIDS, multiple sclerosis, and many others. Innovation policy must balance the incentives for developing such treatments with the ability of patients or payers to pay for them. A critical question, therefore, is the extent to which drug prices and the policies that underpin them, such as patent protection, have provided the correct incentives for innovation. Specifically, if more important innovations provide higher returns to society, then innovation policy should provide them with higher rewards. In most markets, economists measure the value of an innovation with estimates of demand. Markets aggregate information about a product’s quality, and we expect the its price and market share to reflect this. In practice, this approach is difficult to apply in pharmaceutical markets, for reasons that will be outlined in the following section. As a result, the link between price (or profits) and social value—essential for innovation incentives—may be weak. Many economic studies rely instead on patent-based measures of innovation. During the lengthy process of drug development, patent applications are often filed well before much information on therapeutic value exists; and (as in other sectors) most patents that are filed ultimately have little commercial value as the products with which they are associated fail in development. Since patent length does not vary with therapeutic value, there is little reason to expect that patent terms favor investment in the most therapeutically important drugs. Prior work has established that overall, pharmaceutical R&D investment responds to market size—particularly patent-protected market size (Acemoglu and Linn 2004; Kyle and McGahan 2012; de Mouzon et al. 2015). There are a number of prominent examples where innovation incentives that are provided by price and/or patents may be insufficient. The so-called neglected diseases attract little R&D investment despite a heavy burden, mainly because the ability to pay in the countries that are most affected is low. More recently, antimicrobial resistance has increased the need for novel antibiotics, but expected profits under current pricing policies have stimulated little interest from pharmaceutical firms. New antibiotics should be used sparingly in order to preserve their efficacy, but low volumes reduce profits. In response to cases such as these, some have proposed “delinkage” of price and quantity from pharmaceutical profits in order to change the direction of R&D (Kremer and Glennerster 2004). This paper focuses not on the overall level of drug prices, but rather on the relationship between therapeutic value and different measures of market rewards—the number of patents, price, market share, and total revenues—of a new treatment. I use an assessment of therapeutic value provided by the French Haute Authorité de la Santé (HAS), which is independent of price. I find a weak relationship between most measures of rewards and this assessment of therapeutic value, which suggests that the returns to developing a “me-too” product are not very different from developing a breakthrough. Of course, incremental innovation may yield considerable benefits as well (Arcidiacono et al. 2013; Bokhari and Fournier 2013; Hult 2016; Yin 2013), but the results presented here suggest that a re-balancing of innovation incentives may be worth considering.",8
53.0,1.0,Review of Industrial Organization,06 March 2018,https://link.springer.com/article/10.1007/s11151-018-9621-4,Preventives Versus Treatments Redux: Tighter Bounds on Distortions in Innovation Incentives with an Application to the Global Demand for HIV Pharmaceuticals,August 2018,Michael Kremer,Christopher M. Snyder,,Male,Male,Unknown,Male,"In previous work (Kremer and Snyder 2015), we argued that a drug may be more lucrative than a vaccine, even when both products target the same disease and thus have the same health benefit—even in the absence of epidemiological externalities. The argument is that a vaccine is sold before consumers contract the disease, when consumers differ considerably in disease risk, which prevents the firm from easily extracting much of their surplus with a uniform price. On the other hand, a drug is sold after consumers have contracted the disease, when they no longer differ in disease risk, which allows the manufacturer to extract more surplus from these relatively homogeneous consumers. The drug may thus end up being more lucrative—and the manufacturer biased toward developing it over the vaccine—even if the vaccine is substantially more effective or lower cost.Footnote 1
 In that paper we calibrated the distribution of infection risk in the U.S. population for human immunodeficiency virus (HIV) and found it to be close to Zipf: a power-law distribution with exponent equal to 1. A Zipf distribution of disease risk intuitively means that each doubling of risk cuts the number of consumers with at least that risk in half, which leads to an iso-revenue property. In view of our theoretical result that (owing to this iso-revenue property) the Zipf risk distribution generates the worst bias against preventives, our previous work provided one explanation for why a variety of HIV drugs have been developed but as yet no vaccine has appeared. The present paper contributes along both empirical and theoretical dimensions. The main contribution is empirical. We expand the calibrations of demand for HIV pharmaceuticals beyond the U.S. market, calibrating a global demand curve using country-level data on disease prevalence, factoring in the joint distribution of income using data on per capita gross domestic product (GDP) and considering a range of values of the income elasticity of healthcare expenditures for robustness. For consistency, throughout most of the analysis we interpret calibrated world demand in a similar way as Kremer and Snyder (2015) did U.S. demand: we take demand to represent individual purchase decisions in a (perhaps counterfactual) private market in the absence of intervention by governments or insurance companies and in the absence of epidemiological externalities.Footnote 2 However, the calibrations can be interpreted more broadly. We offer an alternative interpretation of world demand as reflecting purchases by national agencies on behalf of citizens in their health systems. This interpretation allows for consumer heterogeneity and epidemiological externalities within countries. The resulting calibrated demands are employed to examine a range of policy issues: one exercise leverages Kremer and Snyder’s (2015) formulas for worst-case bounds on deadweight loss from pharmaceutical sales in the private market. Since the greatest conceivable distortions occur at the extensive margin (whether a product is developed at all) rather than the intensive margin (how high the mark up is for an existing product, which generates a Harberger (1954) deadweight-loss triangle), the formulas hinge on the percentage of the surplus generated by completely relieving the disease burden that the producer can extract for itself; we refer to this as the producer-surplus ratio, denoted \(\rho \). The producer-surplus ratio in turn depends on how the demand curve is shaped. Using the calibrated demands, we can compute \(\rho \) for a monopoly producer of either a vaccine (v) or a drug (d). In our baseline calibration (indicated by superscript 0), we obtain a producer-surplus ratio of \(\rho _v^0 = 44\%\) for an HIV vaccine. Considering the market for an HIV vaccine in isolation, we compute a worst-case bound on deadweight loss of \(100 - 44 = 56\%\). In other words, the distorted incentives provided by the private market to the firm with regard to the vaccine’s development and price could dissipate as much as 56% of the global benefit from curing HIV. Considering the market for an HIV drug in isolation, we compute a baseline estimate of the drug-producer-surplus ratio of \(\rho ^0_d = 38\%\), which leads to a worst-case bound on deadweight loss of \(100 - 38 = 62\)%. Rather than consider the vaccine and drug markets in isolation, it is natural to wonder what the worst-case deadweight loss is in the comprehensive case in which either or both products can be produced. The previous theoretical result relevant to this comprehensive case is Proposition 15 of Kremer and Snyder (2015). We have been able to tighten the bounds, as reported in Proposition 3 of this paper. For canonical values of model parameters, these tighter bounds lead to an exact expression for worst-case deadweight loss as reported in Proposition 2 of this paper. The exact expression simply equals the larger of the two worst-case bounds for the isolated products; using the numbers from the calibration, \(\max (56, 62) = 62\)%. The previous result merely told us that worst-case deadweight loss in the comprehensive case is no less than the difference between the worst cases for the individual products: no less than \(62 - 56 = 6\)%. The new bound thus represents a dramatic sharpening of the analysis in this application: instead of saying that worst-case deadweight loss lies somewhere in the interval [6, 100%], we can now pinpoint it at 62%. The fit of our demand calibration appears to be good. Based on the calibrated global demand for an HIV drug, we calculate that—in the absence of international price discrimination, subsidies in low-income countries, or regulatory threats to intellectual property—a profit-maximizing monopolist would charge such a high drug price that only about 4% of infected individuals worldwide would buy the treatment. These price and quantity estimates are remarkably close to the actual prices and quantities of antiretroviral therapies (ARTs) in 2003—the baseline year for our analysis—which arguably approximates the “state of nature” before subsidies or other policy interventions became widespread. Since the calibrations require assumptions about particular parameter values, we gauge the robustness of the results by providing calibrations for a range of values of these parameters. The key parameter is the income elasticity of healthcare expenditure: \(\varepsilon \). We first consider the baseline case of unit income elasticity, which is close to leading estimates that use international data: e.g., Newhouse (1977) estimates \(\varepsilon = 1.3\). We provide calibrations for a wide range of \(\varepsilon \) that span these values as well as \(\varepsilon = 0\), which is equivalent to a model in which consumers vary only in disease risk. Because the disease-risk distribution is even more Zipf-similar than the distribution of the product of risk and income, the potential for deadweight loss is enormous in the model with only disease risk: for example, deadweight loss reaches 70% of the overall disease burden in the vaccine market. We also use the calibration to assess the welfare effects of counterfactual policies such as subsidies, reference pricing, and a price-discrimination ban. With regard to subsidies, owing to the Zipf-similar shape of demand in the baseline vaccine calibration, a small subsidy is enough to swing the equilibrium from a high price at which few consumers are served to universal vaccination. Thus universal vaccination may be a more robust public policy than previously thought, possible to rationalize even in the absence of epidemiological externalities, and possible to effectuate without a mandate. With regard to reference pricing, if all other countries peg their prices to some proportion, u, of the U.S. price, a monopoly manufacturer of either a vaccine or a drug would prefer to serve the U.S. even if the ceiling were as low as \(u = 0.2\). This result highlights the pivotal U.S. role in the pharmaceutical market and explains why other countries may be emboldened to free ride. With regard to price discrimination, cross-country price discrimination can be quite lucrative in our model because each country’s consumers are homogeneous, so one different price per country is all that is needed to accomplish perfect price discrimination and attain the social optimum. Hence, banning price discrimination can be quite distortionary: it could lead to as much as a 56% decline in vaccine producer surplus and a 62% decline in drug producer surplus; these declines equal the potential increase in deadweight loss in these markets. As discussed, the most closely related paper in the past literature is Kremer and Snyder (2015).Footnote 3 Other of our past related work includes Kremer et al. (2012), which focuses on epidemiological externalities, and Kremer and Snyder (2016), which generalizes the bounds on deadweight loss to product markets beyond pharmaceuticals.Footnote 4
 A detailed discussion of the connection between this line of our research and other authors’ work is provided in Kremer and Snyder (2015). Here we highlight just two key connections. The present paper contributes to the literature on incentives for innovation in R&D-intensive industries (see, e.g., Newell et al. 1999; Acemoglu and Linn 2004; Finkelstein 2004;  Budish et al. 2015). Most closely related are studies of innovation in healthcare markets by Lakdawalla and Sood (2013) and especially Garber et al. (2006). The latter paper relates static and dynamic deadweight loss to the shape of the demand curve as we do. They focus on a different distortion—that coinsurance can induce overconsumption and excess entry by defraying a fraction of the pharmaceutical price—whereas the distortion in our model is due to under-consumption and too little entry. The present paper also contributes to the literature on the revenue and welfare consequences of government interventions in the international pharmaceutical market. See, e.g., Kyle (2007), Sood et al. (2008), and a series of papers by Patricia Danzon and coauthors, including Danzon and Ketcham (2004) and Danzon et al. (2005). The paper is organized as follows: the next section presents the model. Section 3 provides propositions that tighten the bound on deadweight loss from our previous work. The rest of the paper focuses on the calibrations. Section 4 describes the methods and Sect. 5 the data that are used in the calibrations. Section 6 presents the results from calibrations for the baseline scenario and Sect. 7 results for scenarios that involve price discrimination. Section 8 presents calibrations for alternative parameterizations to explore robustness. Section 9 concludes. Proofs of propositions are provided in the “Appendix”.",7
53.0,2.0,Review of Industrial Organization,23 December 2017,https://link.springer.com/article/10.1007/s11151-017-9610-z,Outsourcing and Price Competition: An Empirical Analysis of the Partnerships Between Legacy Carriers and Regional Airlines,September 2018,Kerry M. Tan,,,,Unknown,Unknown,Mix,,
53.0,2.0,Review of Industrial Organization,25 January 2018,https://link.springer.com/article/10.1007/s11151-018-9612-5,A Tale of Two Cities: An Examination of Medallion Prices in New York and Chicago,September 2018,Sutirtha Bagchi,,,Unknown,Unknown,Unknown,Unknown,,
53.0,2.0,Review of Industrial Organization,24 February 2018,https://link.springer.com/article/10.1007/s11151-018-9619-y,Evaluating Partial Divestitures When Vertical Relations are Important,September 2018,Pedro Pereira,Tiago Ribeiro,,Male,Male,Unknown,Male,"The merger simulation literature—e.g., Nevo (2000)—typically assumes that the underlying transactions involve discrete objects, such as product lines, brands, or firms. However, in industries such as outdoor advertising, retail banking, or gasoline stations, acquisitions—and particularly divestitures—may involve, instead, part of a firm’s productive capacity. Consider a merger in retail banking. Suppose that there is a concern that the transaction will lessen competition, and there is considerable overlap in the locations of some of the merging firms’ branches. A usual remedy is for the merged entity to divest some of the overlapping branches: to divest productive capacity. If there is available demand data at the level of the units that constitute the firms’ productive capacity—at the branch level—one can, with an adequate product redefinition, use the traditional merger simulation approach. However, usually the data is available at the product or brand level. Hence, the traditional approach has to be adjusted. In this article, we use the approach of the partial-ownership literature—O’Brien and Salop (2000)—to model the partial sale of a firm’s productive capacity to several buyers in the Portuguese outdoor advertising industry. We develop a differentiated products equilibrium model with two important characteristics that reflect this industry. First, the model includes two levels of activity that are related vertically: the wholesale and the retail levels. Second, the model allows firms to have several shareholders. The estimated equilibrium model is used to perform several counterfactual exercises that involve the sale to various buyers of parts of a firm’s productive capacity: with and without synergies. The framework is shown to be useful, permitting a flexible analysis of the impact of capacity divestitures. The results show that, as expected, the competitive impact of a divestiture depends on the identity of the buyers and the amount of capacity sold. But more interestingly, the results also show that a divestiture may have a net anti-competitive impact. The latter case, while a theoretical possibility, is usually ignored. A divestiture has two opposing effects. On the one hand, it reduces the asset seller’s ability to internalize the diversion of sales, thereby putting downward pressure on prices. On the other hand, it increases the asset buyer’s ability to internalize the diversion of sales, thereby putting upward pressure on prices. In some circumstances, the latter effect dominates. Hence, in the context of a merger review, divestitures should not always be assumed to be pro-competitive. The rest of the article is organized as follows. Section 2 inserts our article in the literature. Section 3 gives an overview of the Portuguese outdoor advertising industry. Section 4 presents the theoretical framework. Section 5 describes demand estimation, and presents the demand estimates. Section 6 conducts the counterfactual exercises. Section 7 concludes.",2
53.0,2.0,Review of Industrial Organization,12 January 2018,https://link.springer.com/article/10.1007/s11151-018-9613-4,"Establishment Survivorship in U.S. Manufacturing, 1987–1992",September 2018,John Howard Brown,,,Male,Unknown,Unknown,Male,"The period from the 1970s through the early 1990s saw the United States economy buffeted by the forces of increased foreign competition and technological revolution. During this period, manufacturing’s role in the American economy continued its secular decline from 32.8 per cent of GDP in 1982 to 25.9% in 1992, while service activities of various descriptions continued their growth to 72.2% of GDP in 1992. At the same time, U.S. manufacturing was confronted with a huge increase in import competition, with imported manufactures rising 187% between 1982 and 1992. Comparatively speaking, United States manufacturing exports lagged, rising by only 146% (World Bank 2004). Pressured by lower wage competition and a strong American dollar throughout the 1980s, American firms scrambled to restructure and relocate their manufacturing capabilities. This raises an interesting question: Did the scale of output in American manufacturing change during this period? In this paper the survivor method for determination of the efficient scale of output for industry is applied to data from the 1987 and 1992 Censuses of Manufactures to resolve this question. The method, first proposed in its modern form by Stigler (1958), is conceptually quite simple. In a competitive environment, firms face a selective pressure to adopt a scale of output that is economically efficient. Establishments whose scale of production activities falls outside of the most efficient range are more likely to be unprofitable.Footnote 1 Thus inefficiently sized establishments will either exit the industry or adapt to efficiently sized operations. In either case, efficiently sized establishments will constitute an increasing share of the industry. The technique was implemented for large segments of the United States economy during the 1960s by Sands (1961), Saving (1961), Weiss (1964) and Shepherd (1967), using data from the 1940s and 1950s. More recent applications of the technique have been limited to analysing specific industries, such as trucking (Giordano 1997), or other countries’ manufacturing: Germany (Hofmann 1986), Italy (Cardani 1979), and South Africa (Reekie 1984). Giordano (2003) provides a summary of both the strengths and the criticisms of the technique and further results. This paper considers survivorship trends in the U.S. economy between 1987 and 1992. It extends the classic literature of the 1960s by: (1) examining a much larger segment of manufacturing; (2) employing statistical tests of changes in establishment distributions of manufacturing output, rather than the impressionistic evaluation of the prior literature; and (3) offering some statistical tests to determine which features of the changing environment of business are most responsible for the observed changes in the establishment distribution of economic activity among different sized manufacturing facilities. The balance of the paper consists of four sections: In the next section, the methodology of survivorship, the nature of the data, and the techniques employed are explained. The succeeding section derives and reports the survivor estimates of optimal scale of establishments for the industries that are covered. The survivorship experience of some of specific industries is discussed. The following section applies statistical techniques to explain the trends in the optimal scale of industries that are estimated in this study. A brief conclusion rounds out the paper.",
53.0,2.0,Review of Industrial Organization,22 February 2018,https://link.springer.com/article/10.1007/s11151-018-9618-z,Is There Complementarity Between Certified Labels and Brands? Evidence from Small French Cooperatives,September 2018,M’hand Fares,Saqlain Raza,Alban Thomas,Unknown,Unknown,Male,Male,"Consumers’ demand for high-quality food has been increasingly drawing attention throughout the world, particularly in industrialized countries (Braham 2003; Vanhonacker et al. 2010; Hu et al. 2011). Many quality signals can be used—both private (brand) and common (certified label)—to foster the development of high-quality food in the market (Crespi and Marette 2003; Lence et al. 2007). Previous research has typically focused on either brand or common certified label efficiency, while in many instances both signals coexist. Agricultural products that pair brand names and certified labels— such as indications of origin—are becoming common (Yue et al. 2006; Boizot-Szantai et al. 2005). Our paper offers the first attempt to test empirically for this coexistence by estimating the complementary effect that may exist between certified labels and brands. First, we develop empirical models to test for complementarity between both signals. Since Arora (1996), it is considered that complementary between different practices can be estimated using a reduced-form approach (bivariate probit). However, unobserved heterogeneity may first bias the estimates. To overcome this problem, we use exclusion restriction and indirect testing of complementarity by implementing a multinomial logit model. Unobserved heterogeneity may also make the discrete response model of the reduced-form approach incoherent (Miravete and Pernias 2010). To avoid this incoherence problem, we estimate a multinomial probit model to recover the structural parameters by separating complementarity from unobserved heterogeneity. To estimate the reduced and structural form models of complementarity between quality signals we use a sample of 993 small French cooperatives. The cooperativesFootnote 1 may choose between four strategies of quality signaling: no signal; certified label only; brand only, or a combined-signal (certified label and brand) strategy. The question we address is then whether the combined-signal is due to complementarity—i.e. the joint adoption of two signals (certified label and brand) is because of the net gain that is generated by the combination of signals—or to unobserved heterogeneity between cooperatives. Our estimations show two main results: First, using a reduced-form approach (bivariate probit) generates at least biased estimates because of unobserved heterogeneity. Indeed, we get a result of complementarity (the correlation parameter between errors is positive) while the indirect test of complementarity that emerges from the multinomial logit estimation provides no clear evidence of complementarity. In contrast, estimating the structural model using a multinomial probit approach exhibits a clear effect: There is a robust interaction between label and brand variables, but the interaction is negative. This implies that both signals are more substitutable than complementary. The remaining sections are organized as follows: In Sect. 2, we provide background information on small French cooperatives and their quality signaling strategies. In Sect. 3, we present and discuss the complementarity and empirical models. Section 4 presents the database and the different variables that are used in the econometric estimations. Section 5 discusses the results of the empirical models on complementarity or substitutability between labels and brands. Section 6 provides some concluding remarks.",7
53.0,2.0,Review of Industrial Organization,28 February 2018,https://link.springer.com/article/10.1007/s11151-018-9620-5,Product Design Competition Under Different Degrees of Demand Ambiguity,September 2018,T. Florian Kauffeldt,Boris R. Wiesenfarth,,Unknown,Male,Unknown,Male,"Firms compete by creating products with new or different designs for instance, to enter new markets, to retain current customers or to attract new customers. Product differentiation decisions are often decisive for the success or failure of an enterprise. The case of Nokia shows the importance of product differentiation. In the late 1990s and early 2000s, Nokia was one of the world’s largest mobile phone makers. Subsequently, Nokia sales fell and Nokia sold its phone unit to Microsoft in 2014. Newspaper articles suggest that one of the main reasons is Nokia’s failure in product differentiation: “Nokia, the world’s largest mobile phone maker, paid a heavy price on Friday for missing the trend toward stylish clamshell phone handsets, denting its vaunted reputation as the arbiter of cellphone chic” (Cowell 2004, New York Times), and, “Nokia once ruled the global handset business but failed to compete in the smartphone era [...]” (Reuters 2016, Fortune). Product design decisions are predominantly made under uncertainty about demand since the markets for consumer products are continually changing. Ellsberg (1961) shows that it is important to distinguish between two types of uncertainty:Footnote 1 Risk, which refers to situations where probabilities are known and ambiguity, where probabilities are imperfectly known.Footnote 2
 Location-then-price duopoly models based on the model of Hotelling (1929) are a standard way of analyzing how product design choices are made by firms.Footnote 3 There are extensions of Hotelling’s model that incorporate demand uncertainty; but, so far, there is no model that analyzes the impact of the degree of ambiguity on product differentiation. This paper offers a model that fills this gap: Our main result is that the effect of ambiguity on product differentiation depends on a firm’s ambiguity attitude. More precisely, an increase in ambiguity leads to expanded product differentiation whenever firms are sufficiently optimistic. Otherwise, increasing ambiguity leads to reduced product differentiation. Furthermore, our model provides a unifying framework for the models of Meagher and Zauner (2004) and of Krol (2012).",1
53.0,3.0,Review of Industrial Organization,22 August 2018,https://link.springer.com/article/10.1007/s11151-018-9654-8,The 1968 Merger Guidelines: Editor’s Introduction,November 2018,George A. Hay,,,Male,Unknown,Unknown,Male,"1. Purpose The purpose of these guidelines is to acquaint the business community, the legal profession, and other interested groups and individuals with the standards currently being applied by the Department of Justice in determining whether to challenge corporate acquisitions and mergers under Section 7 of the Clayton Act. (Although mergers or acquisitions may also be challenged under the Sherman Act, commonly the challenge will be made under Section 7 of the Clayton Act and, accordingly, it is to this provision of law that the guidelines are directed.) The responsibilities of the Department of Justice under Section 7 are those of an enforcement agency, and these guidelines are announced solely as a statement of current Department policy, subject to change at any time without prior notice, for whatever assistance such statement may be in enabling interested persons to anticipate in a general way Department enforcement action under Section 7. Because the statements of enforcement policy contained in these guidelines must necessarily be framed in rather general terms, and because the critical factors in any particular guideline formulation may be evaluated differently by the Department than by the parties, the guidelines should not be treated as a substitute for the Department’s business review procedures, which make available statements of the Department’s present enforcement intentions with regard to particular proposed mergers or acquisitions. 2. General Enforcement Policy Within the over-all scheme of the Department’s antitrust enforcement activity, the primary role of Section 7 enforcement is to preserve and promote market structures conducive to competition. Market structure is the focus of the Department’s merger policy chiefly because the conduct of the individual firms in a market tends to be controlled by the structure of that market, i.e., by those market conditions which are fairly permanent or subject only to slow change (such as, principally, the number of substantial firms selling in the market, the relative sizes of their respective market shares, and the substantiality of barriers to the entry of new firms into the market). Thus, for example, a concentrated market structure, where a few firms account for a large share of the sales, tends to discourage vigorous price competition by the firms in the market and to encourage other kinds of conduct, such as use of inefficient methods of production or excessive promotional expenditures, of an economically undesirable nature. Moreover, not only does emphasis on market structure generally produce economic predictions that are fully adequate for the purposes of a statute that requires only a showing that the effect of a merger “may be substantially to lessen competition, or to tend to create a monopoly,” but an enforcement policy emphasizing a limited number of structural factors also facilitates both enforcement decision-making and business planning which involves anticipation of the Department’s enforcement intent. Accordingly, the Department’s enforcement activity under Section 7 is directed primarily toward the identification and prevention of those mergers which alter market structure in ways likely now or eventually to encourage or permit non-competitive conduct. In certain exceptional circumstances, however, the structural factors used in these guidelines will not alone be conclusive, and the Department’s enforcement activity will necessarily be based on a more complex and inclusive evaluation. This is sometimes the case, for example, where basic technological changes are creating new industries, or are significantly transforming older industries, in such fashion as to make current market boundaries and market structure of uncertain significance. In such unusual transitional situations application of the normal guideline standards may be inappropriate; and on assessing probable future developments, the Department may not sue despite nominal application of a particular guideline, or it may sue even though the guidelines, as normally applied, do not require the Department to challenge the merger. Similarly, in the area of conglomerate merger activity, the present incomplete state of knowledge concerning structure-conduct relationships may preclude sole reliance on the structural criteria used in these guidelines, as explained in paragraphs 17 and 20 below. 3. Market Definition A rational appraisal of the probable competitive effects of a merger normally requires definition of one or more relevant markets. A market is any grouping of sales (or other commercial transactions) in which each of the firms whose sales are included enjoys some advantage in competing with those firms whose sales are not included. The advantage need not be great, for so long as it is significant it defines an area of effective competition among the included sellers in which the competition of the excluded sellers is, ex hypothesi, less effective. The process of market definition may result in identification of several appropriate markets in which to test the probable competitive effects of a particular merger. A market is defined both in terms of its product dimension (“line of commerce”) and its geographic dimension (“section of the country”). (i) Line of commerce The sales of any product or service which is distinguishable as a matter of commercial practice from other products or services will ordinarily constitute a relevant product market, even though, from the standpoint of most purchasers, other products may be reasonably, but not perfectly, interchangeable with it in terms of price, quality, and use. On the other hand, the sales of two distinct products to a particular group of purchasers can also appropriately be grouped into a single market where the two products are reasonably interchangeable for that group in terms of price, quality, and use. In this latter case, however, it may be necessary also to include in that market the sales of one or more other products which are equally interchangeable with the two products in terms of price, quality, and use from the standpoint of that group of purchasers for whom the two products are interchangeable. The reasons for employing the foregoing definitions may be stated as follows. In enforcing Section 7 the Department seeks primarily to prevent mergers which change market structure in a direction likely to create a power to behave non-competitively in the production and sale of any particular product, even though that power will ultimately be limited, though not nullified, by the presence of other similar products that, while reasonably interchangeable, are less than perfect substitutes. It is in no way inconsistent with this effort also to pursue a policy designed to prohibit mergers between firms selling distinct products where the result of the merger may be to create or enhance the companies’ market power due to the fact that the products, though not perfectly substitutable by purchasers, are significant enough alternatives to constitute substantial competitive influences on the production, development or sale of each. (ii) Section of the Country The total sales of a product or service in any commercially significant section of the country (even as small as a single community), or aggregate of such sections, will ordinarily constitute a geographic market if firms engaged in selling the product make significant sales of the product to purchasers in the section or sections. The market need not be enlarged beyond any section meeting the foregoing test unless it clearly appears that there is no economic barrier (e.g., significant transportation costs, lack of distribution facilities, customer inconvenience, or established consumer preference for existing products) that hinders the sale from outside the section to purchasers within the section; nor need the market be contracted to exclude some portion of the product sales made inside any section meeting the foregoing test unless it clearly appears that the portion of sales in question is made to a group of purchasers separated by a substantial economic barrier from the purchasers to whom the rest of the sales are made. Because data limitations or other intrinsic difficulties will often make precise delineation of geographic markets impossible, there may often be two or more groupings of sales which may reasonably be treated as constituting a relevant geographic market. In such circumstances, the Department believes it to be ordinarily most consistent with the purposes of Section 7 to challenge any merger which appears to be illegal in any reasonable geographic market, even though in another reasonable market it would not appear to be illegal. The market is ordinarily measured primarily by the dollar value of the sales or other transactions (e.g., shipments, leases) for the most recent 12 months period for which the necessary figures for the merging firms and their competitors are generally available. Where such figures are clearly unrepresentative, a different period will be used. In some markets, such as commercial banking, it is more appropriate to measure the market by other indicia, such as total deposits.",
53.0,3.0,Review of Industrial Organization,10 October 2018,https://link.springer.com/article/10.1007/s11151-018-9662-8,Donald Turner’s Merger Guidelines as an Antitrust Watershed,November 2018,Donald I. Baker,,,Male,Unknown,Unknown,Male,We have now been just over half a century since Professor Donald F. Turner arrived in Washington in 1965 as the new Assistant Attorney General in Charge of the Antitrust Division (“AAG”) at the U.S. Department of Justice in 1965. His appointment was a game changer in both how the Antitrust Division defined its mission internally and how it explained what it was doing to the public. The 1968 Merger Guidelines were a novel effort at institutional transparency which implemented both the internal and external dimensions of what Professor Turner was trying to achieve.,
53.0,3.0,Review of Industrial Organization,09 August 2018,https://link.springer.com/article/10.1007/s11151-018-9652-x,The 1968 Merger Guidelines: In Praise of Committing to Restraint,November 2018,Gregory J. Werden,,,Male,Unknown,Unknown,Male,"By promulgating guidelines, an enforcement agency can conserve resources. Stating the intention to challenge particular (easily detectable) conduct can deter that conduct—provided that a challenge has significant adverse consequences. In the 1960s, a merger challenge under Section 7 of the Clayton Act had significant adverse consequences: Contested litigation took more than 5 years to resolve and often ended with a divestiture order. The Department of Justice therefore resolved to deter anticompetitive mergers by announcing the intention to challenge mergers in well-specified classes. By promulgating guidelines, an enforcement agency also can mitigate the law’s chilling effect on beneficial conduct. If an enforcement action has significant adverse consequences, uncertainty about enforcement can deter conduct that is both lawful and efficient. In the 1960s, Supreme Court’s Section 7 decisions had placed the legality of all horizontal mergers in doubt. The Department of Justice therefore resolved to avoid deterring procompetitive and competitively neutral horizontal mergers by specifying when it would not challenge a horizontal merger. Although the 1968 Merger Guidelines have a stone-age quality when viewed through 21st century eyes, they remain a paragon of good government and still can serve as a model for competition agencies around the world. The 1968 Guidelines courageously articulated when the Department would exercise its prosecutorial discretion under Section 7 by not acting. With respect to horizontal mergers, this essay explains how the 1968 Merger Guidelines were a praiseworthy commitment to restraint.",1
53.0,3.0,Review of Industrial Organization,15 September 2018,https://link.springer.com/article/10.1007/s11151-018-9658-4,Geographic Market Definition in the Merger Guidelines: A Retrospective Analysis,November 2018,Kenneth G. Elzinga,Vandy M. Howell,,Male,Unknown,Unknown,Male,"The enforcement trajectory of the six Horizontal Merger Guidelines—1968, 1982, 1984, 1992, 1997, and 2010—serves as a chronicle of how merger enforcement has changed over the last 50 years. To simplify the evolution somewhat: In the 1968 Guidelines, mergers were prohibited if they increased concentration (even a little), and the taproot concern was that increased concentration would lead to joint action between firms that would harm consumers: collusion, whether tacit or direct, between the merging firm and other sellers in the relevant market. By the time of the 2010 Guidelines, it was well understood that mergers can benefit consumers; and while increases in concentration remained a concern, more attention was paid to unilateral conduct: whether a merger would enable the exercise of market power by the merged firm’s acting unilaterally. As the Guidelines evolved, they introduced the hypothetical monopolist test; afforded more consideration to the cost-savings that a merger might generate; and clarified how entry conditions matter when evaluating a merger. While the Guidelines today have greater specificity than when they were first issued, their framework still enables the enforcement agencies to exercise discretion in their exegesis. A remarkable feature of the Guidelines is the fact that they have changed so substantively over time, while the text of Sect. 7 of the Clayton Act has remained the same. Though they are not law de jure, the Guidelines have come to be law de facto. The Guidelines receive attention and use outside of agency merger approval and litigation. The language of the Guidelines is of consequence beyond its adoption and use by antitrust authorities and is regularly cited and used to shape analyses in contexts that are unrelated to the scrutiny of mergers and acquisitions. The Guidelines’ paradigm influences how a variety of practitioners and decision makers address questions of competition and monopoly. To make sense of contemporary horizontal merger enforcement—and other topics in antitrust enforcement as well—it is fruitful to look back and see how we arrived where we are. In particular, in this paper we review the six editions of the Guidelines and describe the evolution over time of how relevant geographic markets have been defined—as well as the role of geographic market definition in assessing the prospect of merging firms exercising market power.Footnote 1 To illustrate the changes we also offer an example that explains some ways in which the various versions of the Guidelines have differed in their stated approach to geographic markets. Using the Pabst Brewing Company and Blatz Brewing Company merger that was challenged by the Department of Justice (DOJ) in 1959, we show what facts might have been expected to be emphasized differently over time were one to follow the changes in the language of the Guidelines. Conceptually, the definition of the relevant geographic market is as important as the definition of the relevant product market. To assess whether a merger is likely to cause harm or bring benefits to consumers, or to consider whether a firm or group of firms has geographic market power in general, one must know what market forces currently, or in the future, would thwart any attempt to increase prices (either unilateral or collusive). The answer to this question depends, among other things, on identifying the set of existing and potentially entering firms that would compete with the merging firms (or firms in question). Geographic market definition is the use of economic analysis to identify that set of firms. Which of the competitors that can or do sell the relevant products at issue could or will constrain pricing? Only the one down the street? All firms in the county, or the state, or the country? Getting the answer to these questions right is just as important as getting product market definition right. Over the history of the Guidelines, questions about geographic market definition have been secondary to questions about product market definition. This is reflected in the various versions of the Guidelines, where the methods for identifying the geographic scope of competition are always discussed second, and have sometimes been described in the Guidelines as an exercise that requires using identical methodologies to those used in identifying product markets—without emphasis on the specific details that may require attention when defining geographic markets. In particular, the analysis of geographic markets can be especially important in markets for in-person services, where demand or supply may not as easily shift across geographic space in response to price changes.Footnote 2 Many products can be readily moved about in geographic space. People sometimes cannot. In service markets such as healthcare, the analysis of the relevant geographic market may be more important than the relevant product market. In describing the evolution of geographic market definition over the history of the Guidelines, one cannot totally set aside how the Guidelines define the delineation of relevant product markets and their participants. There are two reasons for this: (1) Product markets and geographic markets are, as a matter of theory, defined conjointly; and (2) Identifying the set of market participants is critical for defining the relevant geographic markets (and vice versa).Footnote 3 Nevertheless, this paper’s focus is that of how geographic market definition is spelled out in the Guidelines over time.",4
53.0,3.0,Review of Industrial Organization,17 September 2018,https://link.springer.com/article/10.1007/s11151-018-9661-9,Merger Guidelines and the Limits of Our Understanding,November 2018,Peter C. Carstensen,,,Male,Unknown,Unknown,Male,"The contrast between the original 1968 Merger Guidelines and the most recent guidelines is striking (DOJ 1968, DOJ and FTC 2010). The 1968 version presented a focused but comprehensive statement of enforcement policy that was based on the change in market structure that a merger would produce. The application was straightforward, so that lawyers, business executives, and their advisors could readily identify whether and how serious the risks of an enforcement challenge might be. Moreover, there was a clear objective: Reject any merger that was likely to result in undue concentration or produce a market structure that was likely to have adverse effects on competition. In the intervening years the Guidelines were revised several times. The most recent version only addresses horizontal combinations, dramatically increases the thresholds at which any presumption of anticompetitive effect will arise, and requires an inquiry into the likelihood of some relatively specific anticompetitive effect as well as soliciting claims that despite any likely harm to competition the merger might in some way enhance consumer welfare (DOJ and FTC 2010, pp. 29–31). Only if a sufficient likelihood of an anticompetitive effect exists and no justification is deemed sufficient is the transaction objectionable. Moreover, the primary focus is on the narrowest market in which such an effect might occur (Id. at 7). This results in settlements in which the merger is allowed subject only to divestiture of some specific elements or even a limited term injunction that regulates the conduct of the merged enterprise. The shifting nature of the guidelines reflects a profound shift in public policy toward mergers. Whereas mergers among major competitors were once viewed with concern, implicit in the current version of the Guidelines is a belief that mergers among major competitors will generally have desirable economic effects. Hence, any enforcement action must proceed cautiously and only after a large investment of resources to determine if some specific type of adverse effect is likely to occur. Risks of over-enforcement (blocking mergers that would ultimately have no negative competitive effects) are a great concern, while those of under-enforcement (failing to block mergers that in fact have anticompetitive consequences) are apparently less pressing. Perhaps this relative emphasis is because of a deep faith in the accuracy of the assessment of competitive risk. Indeed, analysis of the likely effects—positive and negative—of proposed mergers has required a substantial investment of resources both on the part of the parties and of the public enforcers. The current belief in the overall desirability of mergers even among substantial competitors justifies greatly enhanced investments of resources in assessing the merits of each specific merger based on the expectation that these investments will identify only those mergers that are likely to harm competition and thereby serve the public interest in a vibrant economy. The thesis of this article is that this effort to refine the analysis of the potential competitive effects of mergers reflected in the changing guidelines has not in fact improved the accuracy of the resulting enforcement decisions. Instead, it has contributed to allowing an increasing number of combinations that have had or are likely to have demonstrable adverse effects on the competitive process. This outcome is a result of the substantively erroneous belief that mergers among substantial market competitors are likely to produce significant positive economic results. Empirical evidence shows that over-enforcement errors are not and will not be costly, but under-enforcement error has been and will have substantial competitive costs. In addition, the contemporary merger review process creates substantial costs—especially for the enforcers—even though the results of these investments in assessing the potential for specific competitive effects have proven unreliable. It is important to distinguish between the changed methodology of the Guidelines and the specific thresholds and standards that may be employed. Generally, open-ended review is more likely to result in a decision either not to challenge a merger at all or to focus narrowly on specific components, while a system that is based on a few market-specific characteristics is likely to result in a stricter standard for judging the merits of mergers that have these characteristics.Footnote 1 In the case of the Guidelines, both the basic structural criteria and the open-ended analysis of competitive effects have contributed to the present anemic merger policy. A return to a focused standard based on market structure and changes in that structure is the better policy option in a dynamic world with an overall higher degree of accuracy with respect to avoiding risks of competitive harm. But it should be acknowledged that such a policy with its presumptive “safe harbor” for mergers below the established structural threshold creates a risk of under-enforcement with respect to any of those mergers that might be likely to result in competitive harms. However, such cases should be relatively rare and would be equally unlikely to be challenged under the current open-ended review process. Insofar as possible, the following analysis will try to differentiate between the method of analysis and the policy question of whether merger standards should be stricter or looser than is the current situation. As will be evident, this author believes that return to the focused structural criteria of the 1968 Guidelines is preferable regardless of the levels of concentration that are used to determine whether to challenge a merger. However, the author is also a long-time advocate for stricter structural standards in horizontal merger policy–a position that appears to be gaining more support from both the academic and enforcement communities; see Simons (2018) (nominee to be head of the FTC); Hovenkamp and Shapiro (2018). Part 2 describes the evolution of the Guidelines from their 1968 origin to the most recent 2010 version. It also provides a brief account of the development of merger doctrine in the formative era to show how the 2010 guidelines represent a reversion to the pre-Brown Shoe model of open-ended merger analysis. Part 3 argues that over-enforcement is unlikely to cause significant long-term economic harm, while under-enforcement is quite likely to result and has resulted in significant competitive harms. Finally, open-ended competitive effects analysis creates significant costs and ambiguities, and has proven of limited effectiveness in improving the quality of merger analysis. This leads to the conclusion that simpler structural standards are the better policy choice. Part 4 advances the argument for stricter structural standards based on the sliding scale framework that was used in the 1968 Guidelines. Part 5 discusses briefly several additional important issues in restoring an effective, comprehensive merger policy.",
53.0,3.0,Review of Industrial Organization,17 March 2018,https://link.springer.com/article/10.1007/s11151-018-9626-z,Price Competition and Market Segmentation in Retail Gasoline: New Evidence from South Korea,November 2018,Taehwan Kim,,,Unknown,Unknown,Unknown,Unknown,,
53.0,3.0,Review of Industrial Organization,26 June 2018,https://link.springer.com/article/10.1007/s11151-018-9645-9,Fifty is the New Forty: EU Merger Policy Permits Higher Market Shares After the 2004 Reform,November 2018,Federico Mini,,,Male,Unknown,Unknown,Male,"In 2004 the European Commission (EC) adopted Council Regulation 139/2004 (‘EC 139/2004’), which substantially amended the merger regulation that had been introduced 15 years earlier with Council Regulation 4064/89 (‘EC 4064/1989’).Footnote 1
 Among other changes, the EC adopted horizontal merger guidelines (‘2004 HMG’);Footnote 2 established the Chief Economist position with a staff of economists “to strengthen further the economic underpinnings of our competition analysis”;Footnote 3 introduced an efficiency defense;Footnote 4 and replaced the “creation/strengthening of a dominant position” test in EC 4064/1989 with the “significant impediment to effective competition” test (‘SIEC test’) as the basis to determine whether to block a merger. It is widely held that the SIEC test closed a legal gap that had made it harder for the EC to challenge mergers when the newly-formed firm was not the market leader.Footnote 5 Monti (2004), then Commissioner for Competition Policy, commended these changes as aimed at “ensuring that competition enforcement in Europe is grounded in sound economics” and converging toward antitrust policy in the US (based on the “substantial lessening of competition” test) and other jurisdictions (e.g., the UK) whose tests revolve around the merger’s effect on competition. The EC publishes all decisions on proposed mergers under its jurisdiction. I use them to investigate if and how EC’s post-reform decisions about horizontal mergers’ anticompetitive effects due to the elimination competition between the merging parties (‘unilateral effects’) differ from the pre-reform regime.Footnote 6
 Both pre- and post-reform, the EC has relied on market concentration levels—the merging firms’ shares or the Herfindahl–Hirschman Index (HHI)—as critical evidence to evaluate horizontal mergers. My study shows that, post-reform, the EC challenge rate fell significantly for markets with intermediate concentration levels. I estimate an econometric model of the policy regime pre- and post-reform to explain this decrease. The model links decisions under each regime to concentration levels and other market features: e.g., the market’s geographic scope; the merging parties’ nationalities; or whether the merger led to vertical overlaps too. I then use the model to predict how the estimated pre-reform policy regime would have handled the post-reform cases, with a view to decomposing the differences between observed challenge rates into policy effects and case-mix effects. The paper is organized as follows: Sect. 2 summarizes the EC merger appraisal process and reviews the existing literature on this topic. Section 3 describes the dataset and reports summary statistics. Section 4 previews the observed reduction in challenge rates. Section 5 discusses the methodology used to decompose this reduction in policy and case-mix effects. Section 6 reports the results of the analyses. Section 7 concludes.",4
53.0,3.0,Review of Industrial Organization,23 July 2018,https://link.springer.com/article/10.1007/s11151-018-9646-8,Relative Performance Prizes and Dynamic Incentives in Best-of-N Contests,November 2018,Xiandeng Jiang,,,Unknown,Unknown,Unknown,Unknown,,
53.0,4.0,Review of Industrial Organization,16 November 2018,https://link.springer.com/article/10.1007/s11151-018-9674-4,General Editor’s Note: Antitrust and Regulatory Update,December 2018,Lawrence J. White,,,Male,Unknown,Unknown,Male,,
53.0,4.0,Review of Industrial Organization,19 October 2018,https://link.springer.com/article/10.1007/s11151-018-9669-1,Economics at the FTC: Non-price Merger Effects and Deceptive Automobile Ads,December 2018,Matthew Jones,Bruce Kobayashi,Jason O’Connor,Male,Male,Male,Male,"The staff of the Federal Trade Commission’s Bureau of Economics (BE) is composed of about 75 Ph.D. economists, a few financial analysts, and about 20 other staff: primarily research analysts. BE supports the FTC’s two primary missions: competition (antitrust), and consumer protection. Providing economic analysis that relates to the Commission’s law enforcement activities (i.e., investigations and litigation) is BE’s primary role; but FTC economists also engage in “competition advocacy” before other government agencies on state and federal laws and regulations that relate to the FTC’s primary missions and interact with counterparts at foreign agencies. Finally, BE’s staff are actively engaged in policy-oriented economic research. Review of the competitive effects of proposed mergers is the most common means by which economists contribute to the FTC’s competition mission. The FTC brought enforcement actions against 23 mergers in FY2017. Fifteen of those were resolved with consent orders under which the merger could proceed subject to certain conditions; six mergers were abandoned or restructured during the investigation, requiring no additional conditions; and the Commission filed a complaint in federal court to enjoin two of the transactions. The FTC brought actions in nine non-merger antitrust matters in FY2017, three of which were resolved with consent agreements while the Commission filed challenges either in federal court or under its own administrative adjudication process in the remaining six.Footnote 1 The Commission also took actions in over 70 consumer protection actions in 2017 that covered a wide assortment of activities, including deceptive advertising and wire fraud (Federal Trade Commission 2018). The economic impact of FTC decisions can be substantial. For example, FTC consumer protection and competition enforcement actions combined resulted in over $5 billion in redress and disgorgement in 2017 (Federal Trade Commission 2018). BE economists are also active participants in the larger economics community. Our economists regularly publish original research articles in academic journals, participate in conferences, and maintain an active seminar series. BE continues to organize an annual FTC Microeconomics Conference, which marked its tenth year in November of 2017.Footnote 2 Some of the topics considered in the paper sessions, panel discussions, or keynote addresses included new behavioral models, cross-market mergers, privacy and data security, and empirical evidence on market structure and competition. The next FTC Microeconomics Conference will take place on November 1–2, 2018 in Washington, DC.Footnote 3
 This article discusses two economic analyses performed by BE economists to support our competition and consumer protection missions. Section 2 of this article discusses the evaluation of the potential non-price effects of a merger of websites that run paid daily fantasy sports (“DFS”) contests. On November 17, 2016, DraftKings and FanDuel entered into an agreement to undertake a “merger of equals” (Federal Trade Commission 2017). The FTC alleged that these two firms competed aggressively against each other on price and non-price factors to win and retain users. While evaluation of the effect a merger can have on prices is often fertile ground for economic analysis in merger review, non-price effects are not as commonly addressed. So, while the FTC did allege that this merger would result in higher prices that would harm consumers, this article will focus on the analysis of how the merger would affect the non-price dimensions of competition in the DFS market. Section 3 of this article describes a conceptual approach to quantifying in dollars the harm to consumers that is caused by deceptive advertising by automobile dealers. Even when the available case-specific data is very limited, the model can be used to obtain a reasonable estimate of harm with the use of information from auto industry surveys. The model can also be used to estimate unjust gains, and it can be applied in other contexts where deceptive claims cause consumers to spend time and effort in the pursuit of a deal before learning that the advertised deal is not actually available.",4
53.0,4.0,Review of Industrial Organization,10 October 2018,https://link.springer.com/article/10.1007/s11151-018-9668-2,Recent Developments at the CMA: 2017–2018,December 2018,Adriano Basso,Julie Bon,Chris Whitcombe,Male,Female,,Mix,,
53.0,4.0,Review of Industrial Organization,20 September 2018,https://link.springer.com/article/10.1007/s11151-018-9663-7,Economics at the Antitrust Division: 2017–2018,December 2018,Luke M. Froeb,Russell W. Pittman,Gregory J. Werden,Male,Male,Male,Male,"Antitrust enforcement poses counter-factual questions, such as “what was the effect of that conspiracy?” These questions are difficult to answer because they compare two states of the world, but only one of the states is observed. Antitrust economists use models to draw inference about the unobservable counter-factual or “but for” world. To illustrate, Fig. 1 plots winning bids for frozen perch that were supplied to a Defense Department procurement depot before and after the collapse of a bid-rigging conspiracy. When the conspiracy collapsed in September 1989, the winning bids (solid line) fell and began to track the price of fresh perch, which was the biggest cost driver. An Antitrust Division statistician, working with Division economists, regressed winning bids on current and lagged fresh perch prices during the post-conspiracy period, then “backcast” non-collusive winning bids during the conspiracy period (dashed line). They estimated that the conspiracy raised prices by 23% (Froeb et al. 1993). Actual and predicted winning bids for frozen perch filets The estimate’s credibility derives from the transparency of the modeling. The analysis was made replicable—and thus also subject to challenge—by providing a clear mapping from the data to the prediction of the but-for world. An opposing party could challenge the mapping or the data. That sort of scrutiny—and potential falsification—gives credibility to economic analysis and has elevated the role of economists and their models in antitrust. Economics has not always played such a prominent role. Forty years ago, when the most senior of the authors began his career at the Antitrust Division, inference was primitive, drawn mainly from the Structure-Conduct-Performance paradigm, and supported mainly by cross-industry regressions of price or profit on industry concentration. In antitrust trials, it was not uncommon for opposing experts to opine about the effects of a merger based on little in the way of economic theory or empirical evidence, and without offering any mapping from either to their opinions. Economic analysis now occupies a central role in antitrust enforcement and credible expert opinions are derived from theoretical and empirical models. This article describes some of the work of Antitrust Division economists over the past year, with a focus on modeling. It begins by illustrating the mapping from evidence to prediction for proposed mergers through the use of tools that were developed by Antitrust Division economists for predicting merger effects using Bertrand, Cournot, and auction models. It then turns to two hot topics in competition policy: the implications of claims of increasing margins for merger enforcement and the validity of claims of increasing concentration. Finally, it considers how mergers affect prices in bargaining models.",1
53.0,4.0,Review of Industrial Organization,01 November 2018,https://link.springer.com/article/10.1007/s11151-018-9671-7,Recent Developments at DG Competition: 2017/2018,December 2018,Andrea Amelio,Thomas Buettner,Hans Zenger,Female,Male,Male,Mix,,
53.0,4.0,Review of Industrial Organization,11 November 2018,https://link.springer.com/article/10.1007/s11151-018-9672-6,"Economics at the FCC, 2017–2018: Internet Freedom, International Broadband Pricing Comparisons, and a New Office of Economics and Analytics",December 2018,Jerry Ellig,Paul LaFontaine,Sean Sullivan,Male,Male,Male,Male,"The Federal Communications Commission (FCC) is an independent regulatory agency with responsibility for the telecommunications and electronic media sectors, including the allocation and management of all U.S. radio frequency spectrum except for that used by the federal government. For fiscal years 2018–2022, the FCC revised its strategic goals to articulate four priorities: closing the digital divide; promoting innovation; protecting consumers and public safety; and reforming the FCC’s processes (FCC 2017a, p. 4). Economists at the FCC contribute toward the realization of each of these goals, through analysis of the nature and significance of the underlying problems that regulations are intended to solve, as well as assessments of alternative solutions. Three major FCC initiatives demonstrate the role that economic analysis played in Commission decisions in 2017–2018: the Restoring Internet Freedom Order; the new hedonic pricing model that was used in the International Broadband Data Report; and the January 2018 Order that reorganized Commission economists into the Office of Economics and Analytics. Section 2 describes the economic analysis in the Restoring Internet Freedom Order, which restored the pre-2015 classification of broadband as a lightly-regulated service under Title I of the Communications Act instead of as a common carrier that is regulated under Title II. The Order relies on disclosure, competition, antitrust, and consumer protection laws to prevent Internet Service Provider (ISP) behavior that harms consumers. The Order carefully considered relevant economic research on: two-sided markets; competition analysis of broadband markets; the effects of non-neutral ISP business practices on economic efficiency; and the effects of common carrier regulation on the incentives of regulated firms to make sunk investments. Section 3 highlights innovations in economic analysis that was incorporated into the Commission’s annual International Broadband Data Report (IBDR). In the past, this report compared broadband prices for similar services across countries, and made no adjustment for supply or demand factors that could significantly influence prices—such as income, education, population density, or availability of relevant content. The U.S. often fared poorly in these unadjusted international price comparisons, and commentators have used these ranking as justification for heavier regulation or government provision of broadband networks. The 2018 report uses a hedonic pricing model to estimate what a U.S. consumer could expect to pay for broadband in each country if each country had demographic, cost, and quality profiles that are similar to the U.S. By this measure, the U.S. ranks 7th out of 29 countries in fixed broadband pricing and 10th in mobile broadband pricing. Section 4 outlines a fundamental change in organizational structure that is intended to improve the quality and use of economic analysis in Commission decisions. In January 2018, the Commission voted to move most of its economists out of the separate operating bureaus and place them in a new Office of Economics and Analytics, which is patterned after the Bureau of Economics at the FTC and the Economic Analysis Group in the Antitrust Division. This initiative followed the recommendation of an internal working group of career civil servants, who surveyed the organizational economics literature that outlines the pros and cons of different organizational forms and conducted extensive interviews with: FCC managers and staff; former FCC officials; current and former managers from other federal agencies; and representatives from consumer groups, think tanks, and industry associations. The Commission also tasked the new office with reviewing the economic content of all matters that come before the Commission, and the FCC committed to conducting a full benefit–cost analysis for all regulations with annual economic impacts of $100 million or more.",
54.0,1.0,Review of Industrial Organization,05 October 2018,https://link.springer.com/article/10.1007/s11151-018-9666-4,Airlines Symposium Introduction,February 2019,John Kwoka,,,Male,Unknown,Unknown,Male,,
54.0,1.0,Review of Industrial Organization,31 May 2018,https://link.springer.com/article/10.1007/s11151-018-9635-y,"Network Structure and Consolidation in the U.S. Airline Industry, 1990–2015",February 2019,Federico Ciliberto,Emily E. Cook,Jonathan W. Williams,Male,Female,Male,Mix,,
54.0,1.0,Review of Industrial Organization,05 June 2018,https://link.springer.com/article/10.1007/s11151-018-9636-x,"Airline Partnerships, Antitrust Immunity, and Joint Ventures: What We Know and What I Think We Would Like to Know",February 2019,Volodymyr Bilotkach,,,Male,Unknown,Unknown,Male,"The aim of this paper is to take stock of what we know about airline partnerships and their effects on prices and other product characteristics; identify the gaps in our knowledge; and suggest a research agenda for the near future. My key message after reviewing the growing body of work on this subject is: while we have learned a lot, there is a lot of work that remains to be done if we want to be a source of sound policy advice on airline partnerships. Furthermore, the issue of airline cooperation will remain policy-relevant for the foreseeable future. Alliances between competitors were not invented in the airline industry. Joint ventures, marketing, technology/product licensing, and research and development partnerships can be found in many markets. However, it would not be easy to point to a market where partnerships have become as important as in the airline industry over the last 25 years. Member airlines that belong to the three global alliances carry over half of all passenger traffic worldwide. While only a fraction of these passengers travel on interline itineraries—change operating airline en route—airlines and their passengers also benefit from these partnerships in other ways. The airlines benefit from cost savings due to the joint use of airport facilities and coordinated marketing, while their passengers have the ability to use airlines’ loyalty programs on flights and in airport lounges that are operated by partner carriers. The extent and importance of airline partnerships differ across the markets. In the currently largest segment of global airline industry—the US domestic market—the use of interlining and other forms of partnerships is minimal. Major network carriers—American, United, and Delta—are capable of channelling almost all domestic passenger traffic within their networks—including flights that are operated by both mainline and regional airlines. US domestic partnerships played a somewhat more important role before the merger wave of the last decade; since then, however, interline itineraries in the US market have been a niche product that is used by a small share of passengers. On the other hand, members of the four joint ventures on the trans-Atlantic market—narrowly defined as the market for travel between the US and the European Economic AreaFootnote 1—control a majority of the seats on non-stop trans-Atlantic flights. While exact extent of interlining within the joint venture networks cannot be ascertained from the publicly available data, we can say that interline itineraries are very common in this market, and many trans-Atlantic links carry predominantly connecting rather than origin-and-destinationFootnote 2 passengers. Perhaps more interestingly, the trans-Atlantic market is currently home to various types of airline partnerships: from ad hoc arms’ length agreements to cost- and revenue-sharing joint ventures. The latter essentially represents the closest thing to a merger in the current regulatory environment. Interestingly, there are indeed important gaps in our knowledge on the matter. On the surface, there are no difficult issues: parallel partnerships—those involving overlapping parts of the partners’ networks—are anticompetitive, while complementary ones are pro-competitive, as they lead to the removal of double marginalization—a classical result. If we add economies of traffic density to the picture, however, partnerships can yield benefits to consumers even on the overlapping parts of the joint network through lower average cost with higher traffic volumes: this is known in Transportation Economics as economies of traffic density. However, current theoretical research does not fully differentiate between different forms of codesharing; between partnerships with and without antitrust immunity; and between partnerships with antitrust immunity and joint ventures. The issue of incremental benefits of deeper levels of cooperation between the airlines is only partly addressed by the empirical body of work. The effects of partnerships on efficiency—much promoted by the partner airlines in their applications for antitrust immunity and joint ventures—have received only cursory attention in the academic literature (due in part to limited data availability on the issue). As our understanding of the incremental benefits of closer forms of cooperation is limited, we are somewhat in the dark with regard to the effects of the relevant policy options. While earlier studies demonstrated substantial price decreases due to antitrust immunity, more recent work shows only modest gains in this area. Effects of joint ventures are as of yet not studied. It is not clear whether antitrust immunity should be granted in an open-ended fashion as is the case now; or be subject to periodic reviews as some in policy circles have suggested. We also are agnostic as to the implications of repeated interaction and multimarket contact on international routes; there is, however, clear evidence that multimarket contact affects airlines’ competitive conduct in the US domestic market. As full-fledged cross-border mergers in the airline industry are unlikely for the foreseeable future, there will be demand for further work on airline partnerships. I suggest the following lines of inquiry as the most promising here: first, we should gain a better understanding of the implications of different forms of codesharing, and more generally learn to distinguish between different forms of partnerships in our modelling exercises. An evaluation of the incremental benefits of joint ventures appears to be the most fruitful and useful line of inquiry here. Second, as joint ventures currently only include some of the alliance members; they have a potential to disrupt the current equilibrium. Alliance members that are left out of the joint ventures may seek to form different partnerships and joint ventures. Understanding the airlines’ incentives in this respect appears to be a promising avenue for future research: both theoretical and empirical. Third, we need to gain a better understanding of the effects of repeated interaction and multimarket contact: we need to understand whether airline partnerships contribute to a tacitly collusive environment in the industry. Last (but not least), I believe that it makes sense to evaluate the effects of partnerships on non-price product characteristics and efficiency—if suitable data become available. The rest of the paper is organised as follows: in the next section, I introduce the readers to various forms of airline partnerships. This is followed by a review of the relevant literature. Extensive discussion of both pro- and anti-competitive effects of these partnerships is offered next. Afterwards, I discuss the current gaps in research: both theoretical and empirical. Then, I propose a research agenda for the future, and conclude.",20
54.0,1.0,Review of Industrial Organization,15 May 2018,https://link.springer.com/article/10.1007/s11151-018-9632-1,Do Airlines Pad Their Schedules?,February 2019,Silke J. Forbes,Mara Lederman,Zhe Yuan,Female,Female,,Mix,,
54.0,1.0,Review of Industrial Organization,27 September 2018,https://link.springer.com/article/10.1007/s11151-018-9664-6,Strategic Responses to Competitive Threats: Airlines in Action,February 2019,John Kwoka,Birzhan Batkeyev,,Male,Unknown,Unknown,Male,"Incumbent firms that face threatened or actual entry can respond in a wide variety of ways. These range from accommodation at one extreme, to pre-entry efforts to deter and post-entry battles for market dominance at the other. Modern theoretical work that investigates an incumbent firm’s possible actions has cautioned that we should expect to observe only rational strategies: those that would remain profit-maximizing if entry were actually to occur. That insight has focused attention on entry-deterring strategies by the incumbent firm that involve prior capacity expansion and similar strategies whose irreversibility makes them credible entry deterrents, unlike price with its easy reversibility. There is now considerable theoretical work that demonstrates, for example, how sunk costs and first mover advantages can alter market equilibrium in an incumbent’s favor. Reality, however, does not always seem to comply. Observed strategies by incumbents in the face of threatened entry often varies more widely than theory considers to be rational. Airlines, for example, are routinely observed to use price to challenge an actual or potential entrant, despite theory’s insistence that price is a weak and ineffective strategic weapon. In other cases, an incumbent’s action persists well after deterrence has failed and the entrant is firmly established, again contrary to standard theory. In even less expected scenarios, an incumbent may initiate action after entry occurs. In addition, the choice of strategy is seen to differ depending on the identity and characteristic of the incumbents and the entrants, suggesting deeper differences among firms and their perception of self-interest. These scenarios pose challenges to received theory and understanding. A full understanding of these anomalies—or of entry and deterrence more generally—is beyond the scope of this paper. Our more modest objective is to cast some light on the nature of firms’ responses to entry through a detailed examination of a series of episodes that illustrate different strategic choices by incumbent firms. These episodes reveal both predicted and some unexpected scenarios along the lines just suggested. The latter indicate the need for more refined hypotheses in order to explain some behavior that received theory would find puzzling about the strategies used by firms facing entry. Our examples are intended to illuminate some particularly interesting scenarios, but our choice of examples serves another important purpose. We do not have a large panel data set of entry and response events that would allow for statistical controls for firm, market, and myriad other factors that influence these strategies. Instead, we select examples that by design hold such factors constant. For example, we examine strategies utilized by the same firm in the same market but against different entrants. In other cases with the same incumbent, we examine responses to entry on different routes with known characteristics. While short of a framework for holding all factors constant simultaneously, this method offers much greater insights than idiosyncratic examples where nothing is held constant. We examine the U.S. airline industry where entry and entry responses are frequent and well documented. As noted, we examine experiences selected and designed to illuminate particular actions and responses. Furthermore, since we wish to avoid instances where the incumbent is engaged in capacity or price changes due to ordinary internal growth, we primarily develop instances where entry is arguably exogenously determined. We capture this, at least initially, by focusing on routes where entry arises from mandated slot or gate divestitures, rather than due to organic growth. Throughout, we examine two strategic response variables—price and capacity on a route—and two different time dimensions: prior to entry, and after entry. We compare an incumbent’s actions on the route in question to its actions on a sample of control routes by the same carrier. This difference-in-difference approach permits statistical testing to determine whether and to what degree an incumbent’s behavior was in fact a response to entry as opposed to the carrier’s routine response to changing market conditions. As noted at the outset, we find a range of both predicted and unexpected scenarios. The former serve to confirm standard hypotheses about responses to entry, while the latter suggest the need for more refined hypotheses about firm strategies in the face of threatened entry. The paper proceeds as follows: The next section provides background into the theoretical and empirical literature on entry deterrence and pre-emption, together with its implications for airlines. This is followed by a description of several relevant experiences and an effort to “map” these onto the theory just described. Section 2 offers background information on theory and evidence; Sect. 3 describes the data and methodology; Sects. 4 and 5 present the analysis and findings; and Sect. 6 concludes with commentary on the cumulated evidence that sometimes corroborates theory and other times seems to run counter to it. We view these observations as encouragement for new theory and additional empirical work.",7
54.0,1.0,Review of Industrial Organization,27 April 2018,https://link.springer.com/article/10.1007/s11151-018-9631-2,The Impact of Passenger Mix on Load Factors in the Airline Industry,February 2019,James D. Dana Jr.,Daniel J. Greenfield,,Male,Male,Unknown,Male,"Load factors—the percentage of available seats that are occupied by paying customers—in the U.S. airline industry vary with the share of business travelers. While both business and leisure travel have grown significantly in the U.S., leisure travel has grown significantly faster. We present evidence of a strong correlation between load factors and the share of leisure travelers across routes, and we view this as support for the argument that the increase in the share of leisure travelers over time is partly responsible for increases in airline load factors. Specifically, we find that the elasticity of load factor with respect to the share of business travelers is − 0.1. Thus, the decrease in the share of business travelers between 1997 and 2016, which was from 47 to 31%, is associated with a 3.4% increase in load factors, which suggests about 18% of the increase in load factors between 1997 and 2016 (load factors increased from 70 to 83%) is attributable to the change in passenger mix.Footnote 1 We think business travelers are different from leisure travelers in several respects. First, business travelers are typically less price-sensitive and have a higher willingness to pay. Second, and more importantly for our analysis, business travelers are typically less willing to travel at alternative departure times to obtain a lower price. That is, leisure travelers are more willing to consider less convenient flights. Leisure travelers are also more willing to accept smaller seats, longer travel times, more connections, and other reductions in product quality. We argue that differences in the preferences of leisure and business travelers imply that the increase in the share of leisure travel is partly responsible for the significant growth in airline load factors, as well as other important changes in the airline industry. Increased load factors benefit firms through lower average costs, and they benefit consumers if some of that cost savings is passed on to air travelers.Footnote 2 Theoretically, an increase in the share of leisure travelers implies that capacity utilization should increase because more passengers will be willing to adjust their travel plans to help airlines fill their aircraft. Because airline schedules are set in advance and demand is uncertain, airlines with more leisure travelers find it easier to fill their planes using small price changes that shift demand. Or put even more succinctly, business travelers are willing to pay for empty seats to preserve flexibility, while leisure travelers are not. We present two simple theoretical models—one with price rigidities and one with market-clearing prices—which establish that this relationship between passenger mix and aircraft utilization arises in equilibrium. We then test this prediction using cross-sectional variation in the share of business travel and in airline load factors. Though consumer preferences are largely exogenous, we control for other market characteristics—including market structure—that might affect load factors because we think that these could also be correlated with the share of business travelers and could introduce omitted variable bias. We find strong negative correlation between the share of business travelers and load factors across a variety of empirical specifications. The next section of the paper discusses the overall trends in leisure and business travel. Section 3 examines our theoretical model and describes how increases in the share of leisure travelers lead to higher load factors. Section 4 describes our empirical model. Section 5 describes our data. Section 6 describes the estimation results, and Sect. 7 concludes.",2
54.0,1.0,Review of Industrial Organization,17 July 2018,https://link.springer.com/article/10.1007/s11151-018-9648-6,Interchange Fees and Innovation in Payment Systems,February 2019,Marc Bourreau,Marianne Verdier,,Male,Female,Unknown,Mix,,
54.0,1.0,Review of Industrial Organization,19 July 2018,https://link.springer.com/article/10.1007/s11151-018-9647-7,Ex-ante Agreements and FRAND Commitments in a Repeated Game of Standard-Setting Organizations,February 2019,Gastón Llanes,,,Unknown,Unknown,Unknown,Unknown,,
54.0,1.0,Review of Industrial Organization,09 October 2018,https://link.springer.com/article/10.1007/s11151-018-9667-3,A Prospective Analysis of Competitive Balance Levels in Major League Soccer,February 2019,Carlos Gomez-Gonzalez,Julio del Corral,Cornel Nesseler,Male,Male,Male,Male,"Since the studies of Rottenberg (1956) and Neale (1964), the issue of competitive balance has been a focus of research interest in sports economics. The term “competitive balance” refers to the degree of parity among teams in sports leagues. From an economic perspective, competitive balance is an important factor since sports fans are often highly invested in the performance of their favorite teams (Zimbalist 2006). The majority of empirical studies employ retrospective (ex-post) measures to test competitive balance. These papers normally use actual game outcomes such as victories or points as the basis of analysis. In contrast, recent studies argue for the use of prospective measures (ex-ante)—based on expected rather than actual outcomes—in analyzing competitive balance (Bowman et al. 2013a, b; McEwen and Metz 2016; Paul et al. 2009). Kringstad and Gerrard (2007) explain that professional sports leagues have complex payoff structures that offer multiple prizes and mini-competitions, such as winning the league, qualifying for play-offs, or not being relegated. In the context of competitive balance, traditional measures that simply compare the accumulation of victories or points do not fully capture this complexity of payoffs and resulting outcomes. As a simple example, consider a four-team league in which teams play each other twice. Each season, there are 12 games; in a sport with no ties, teams will share 12 wins. Assume that at the end of season 1, the four teams have 6, 2, 2, and 2 wins respectively, and at the end of season 2, the teams have 4, 4, 4, and 0 wins. One could argue that season 2 was more “competitive” since three teams tied for the top spot. However, the standard deviation of wins—a commonly-use measure of competitive balance (Fort 2006)—is equal to 2.0 in both seasons. Thus, analysis using the standard deviation of wins in this case leads one to conclude that there is no change in competitive balance from seasons 1 to 2.Footnote 1 The complex nature of sporting contests and leagues suggests the need for competitive balance analysis that captures the range of potential outcomes. In the present paper, we introduce a methodology for using ex-ante information from betting markets to consider the entire distribution of expected performance. The graphical results allow for a more complete picture of competitive balance across all teams in a given league and how this balance changes over time. We also add to the literature by analyzing a relatively young, North American professional league: Major League Soccer (MLS). MLS provides an excellent case due to its distinctive league structure and policies. For our analysis, the probabilities of winning are calculated from MLS betting odds during the period 2004 through 2015. The aim of this study is to examine the characteristics of competitive balance in MLS by using sports betting data in conjunction with graphical analysis. The main contribution of the study is, then, a graphical interpretation of competitive balance, which identifies the subtleties of competitive balance and incorporates expected team performance. Overall, the graphical interpretation of ex-ante information provides meaningful information for league managers while expanding on previous analyses solely based on numerical outcomes in soccer leagues.",6
54.0,2.0,Review of Industrial Organization,18 June 2018,https://link.springer.com/article/10.1007/s11151-018-9643-y,Introduction (to CRESSE Special Issue of RIO),March 2019,Yannis Katsoulacos,Bill Kovacic,Thomas Ross,Male,Male,Male,Male,"
This Special Issue of the Review of Industrial Organization is devoted to an examination of competition policy and its enforcement, with a focus on the policy aspects that are of particular interest to younger jurisdictions in developing countries. Some of the articles are based on presentations that were made in sessions that were related to competition policy developments in developing countries at the 12th CRESSE Conference on Competition and Regulation that took place in July 2017.Footnote 1 Additionally, some articles are based on presentations that were made during the special session on competition policy that was co-organized by CRESSE and the 2nd World Congress on Comparative Economics that took place in St. Petersburg in June 2017. With the unprecedented global growth of competition policy enforcement in the last 15 years—with over 130 Competition Agencies operating at present worldwide—the issues that relate to the appropriate design of competition law, enforcement procedures, and institutional regimes have gained added significance. Much of this recent expansion has involved the introduction of new laws and agencies in developing countries within very different national contexts than those in the experienced developed world. As a result, it has become very important to take stock of how competition policy and law have been implemented in developing countries, recognizing the progress and gains that have been achieved as well as the challenges and persistent problems that remain. This Special Issue brings together well known academics and practicing economists and lawyers who provide a comprehensive coverage of experience with enforcement in a number of important developing countries in which competition law has developed over the last 10–15 years; specifically, Chile, China, India, Russia, Pakistan, Bangladesh, and South Africa. There is an interesting and wide range of topics covered: The links to and developments of Competition Policy, widely defined to include all of the policies that aim to enhance competition in an economy, and Competition Law enforcement, narrowly defined as antitrust and merger policy, in China (by Yongzheng Liu and Guangliang Ye) and in India (by Aditya Bhattacharya, Geeta Gouri and Oindrila De); The optimal institutional structure of competition authorities, with empirical evidence from the case of Russia (by Svetlana Avdasheva, Svetlana Golovaneva and Yannis Katsoulacos) and institutional design in South Asia countries (by Udai Mehta and Parveer Singh Ghuman); Cartel prosecution in Chile (by Umut Aydin and Nicolas Figueroa) and South Africa (by Willem Boschoff and Rossouw van Jaarsveld); Reforming merger policy in developing countries (by Boris Begovic and Dusan Popovic); and Enforcement in the area of abuse of dominance in China (by Xiao Fu and Guofu Tan) and in India (by Payal Malik, Naha Singh, Ram Tamara and Nisha Kaur Uberoi). We hope that this issue will advance discussions and stimulate more research on the effective design of competition policy law, policy, and institutions in developing countries. The guest-editors would also like to thank the General Editor, Lawrence J. White, for his support for this special issue. Yannis Katsoulacos, Bill Kovacic, and Thomas Ross March 2018.",
54.0,2.0,Review of Industrial Organization,22 May 2018,https://link.springer.com/article/10.1007/s11151-018-9634-z,Competition Policy and Trade Barriers: Empirical Evidence from China,March 2019,Yongzheng Liu,Guangliang Ye,,Unknown,Unknown,Unknown,Unknown,,
54.0,2.0,Review of Industrial Organization,20 June 2018,https://link.springer.com/article/10.1007/s11151-018-9641-0,Competition Law and Competition Policy in India: How the Competition Commission has Dealt with Anticompetitive Restraints by Government Entities,March 2019,Aditya Bhattacharjea,Oindrila De,Geeta Gouri,Male,Unknown,Female,Mix,,
54.0,2.0,Review of Industrial Organization,15 June 2018,https://link.springer.com/article/10.1007/s11151-018-9640-1,Optimal Institutional Structure of Competition Authorities Under Reputation Maximization: A Model and Empirical Evidence from the Case of Russia,March 2019,S. Avdasheva,S. Golovanova,Y. Katsoulacos,Unknown,Unknown,Unknown,Unknown,,
54.0,2.0,Review of Industrial Organization,22 June 2018,https://link.springer.com/article/10.1007/s11151-018-9644-x,Institutional Design of Select Competition Authorities in South Asia: Identifying Challenges and Opportunities,March 2019,Ghuman Parveer Singh,Mehta Udai S.,,Unknown,Unknown,Unknown,Unknown,,
54.0,2.0,Review of Industrial Organization,19 May 2018,https://link.springer.com/article/10.1007/s11151-018-9633-0,The Chilean Anti-cartel Experience: Accomplishments and Challenges,March 2019,Umut Aydin,Nicolás Figueroa,,Male,Male,Unknown,Male,"Chile’s competition regime is among the pioneers in Latin America. The first Chilean competition law was adopted in 1959. This law was replaced by a new one in 1973, which in turn was reformed in 2003, 2009, and 2016. The current institutional structure dates from 2003, when the Tribunal for the Defense of Free Competition (Tribunal de Defensa de la Libre Competencia, TDLC hereafter) was established as a specialized competition court to function alongside the National Economic Prosecutor’s Office (Fiscalia Nacional Económica, FNE hereafter). Under this system, the FNE investigates infringements and brings cases to the TDLC, which adjudicates these and other cases brought by private parties. The 2003 reform modernized and professionalized the Chilean competition regime, and ensured that the institutions have adequate resources for effective enforcement. Further reforms in 2009 and 2016 have focused on improving enforcement and increasing fines with respect to cartels, and the 2016 reform introduced the possibility of criminal prosecution of cartel participants. These recent reforms have ensured that the Chilean competition law is in line with recommendations of international organizations such as the Organization for Economic Cooperation and Development (OECD) and the International Competition Network, as well as international best practices. An area that has gradually received more attention in the Chilean competition regime is enforcement against cartels. The Law for the Defense of Free Competition (Decree Law 211, 1973) prohibits cartels; nonetheless enforcement in this area had traditionally lagged behind other areas, such as abuse of dominance. This began to change in the late 2000s. The discovery of collusion among pharmacies (2008), poultry producers (2011), and tissue paper producers (2015) has caused public outrage, and motivated lawmakers to initiate reforms that strengthen Chilean anti-cartel legislation and policy, including the introduction of a leniency program, higher fines, and criminal sanctions against cartel participants. This paper aims to analyze critically the Chilean anti-cartel law and policy. Our review of the literature in economics and law indicates that successful anti-cartel law and enforcement practices seek to maximize deterrence by maintaining a high cartel detection rate, severe sanctions against cartel participants, and predictable and consistent application of the rules (Baker 2011; Harrington and Chang 2015). We evaluate the law, the design of enforcement institutions, and the actual enforcement record in Chile in light of the debates in these literatures. We argue that various reforms to the Chilean competition law have increased the deterrent effect of the anti-cartel regime. The 2003 and 2009 reforms increased the monetary fines that could be imposed on companies, strengthened the enforcement institutions, granted them extensive powers of investigation, and introduced a leniency program, thereby increasing the potential for cartel detection and the possibility of successful prosecution of detected cartels by allowing the FNE to collect more direct evidence. Nonetheless, until the 2016 reform, monetary fines remained too low to deter cartelization. Simply put, collusion made sense from a business perspective (see for example Deloitte 2014, p. 17). With the introduction of sanctions on individuals, such as prison sentences and disqualification from holding directorship roles in companies, and allowing for fines up to 30% of the sales of the company or double the economic benefit obtained from collusion, the 2016 reform has raised the severity of sanctions significantly, and thus increased the deterrent effect of the system. We argue nonetheless that various challenges remain in the implementation of the anti-cartel regime. This paper focuses on anti-cartel policies in a single jurisdiction that has a rather unique institutional design (an investigative agency and a specialized competition tribunal), which limits the generalizability of our results and the lessons that we can draw from the Chilean case. Nonetheless, we argue that many of the challenges faced by the Chilean enforcement authorities in detecting and sanctioning cartels are similar to challenges that are faced by newer competition regimes—such as the maximum level of fines set in law being an insufficient deterrent against collusion (Aydin 2016). Thus, we argue that analysis of the Chilean case is useful in identifying such challenges and exploring how they might be resolved, and we expect our findings to be illuminating for other countries in Latin America, emerging economies, as well as other small and concentrated economies. In the rest of the paper we first present a review of the literature in the fields of economics and law to identify the components of a successful anti-cartel law and policy. We then move on to our case study, describing how the Chilean competition legislation and enforcement institutions have evolved over time. The third section focuses on the enforcement record in the area of cartels in the period 2003–2016. We present some data on enforcement, and discuss a number of key cartel cases that came before the FNE and the TDLC. The fourth section discusses the key changes introduced by the 2016 reforms in the area of cartels, evaluating how they strengthen the combat against cartels in Chile, and identifying the aspects that may present challenges in enforcement. The fifth section concludes by highlighting the key findings of the paper and making some policy recommendations.",2
54.0,2.0,Review of Industrial Organization,06 June 2018,https://link.springer.com/article/10.1007/s11151-018-9637-9,Recurrent Collusion: Cartel Episodes and Overcharges in the South African Cement Market,March 2019,Willem H. Boshoff,Rossouw van Jaarsveld,,Male,Unknown,Unknown,Male,"Collusion is often a recurrent phenomenon. In markets characterized by a history of legal collusion, illegal cartel conduct often reappears. In other markets subject to large demand shocks, successive periods of collusion are interspersed with price wars. Understanding and modelling recurrent collusion is therefore of importance to antitrust agencies, as it may have a significant impact on the size of price overcharge estimates. In private litigation cases, in particular, courts must often determine the exact period of harm and knowledge of interruptions in collusive effects is therefore important. While canonical models of collusion implicitly treat cartel conduct as recurrent, there have been only limited attempts to model such behaviour empirically. This paper suggests a model that both identifies periods of harm—i.e., dates collusive periods—and estimates the size of the harm, by modelling the transition between collusive and non-collusive periods. In particular, the paper employs a Markov regime-switching (RS) methodology to model recurrent collusion in the South African cementFootnote 1 market. As shown, the application holds insights for competition policy in both developed and developing countries, given the prevalence of collusion in the cement industry internationally. The RS methodology explicitly allows for distinct data-generating processes during collusion and competition. This, in turn, allows for the detection of structural changes and, hence, the delineation of periods of collusive and non-collusive behaviour. By construction, the RS methodology allows for an estimation of an average price overcharge over a sample period that may include a number of collusive episodes. Furthermore, by using the information from the RS model the overcharge estimate can account for situations where transition took place over a period of time or the industry was in some intermediate state. In general, the Markov RS model is ideally designed to accommodate structural changes and transition between collusive and non-collusive periods. Section 2 provides an overview of the literature on recurrent collusion, highlighting key requirements for an empirical model of recurrent collusion. Section 3 discusses the RS methodology, relating the method to recent work on structural breaks in collusion detection. Section 4 outlines the cement market case study and describes the data; Sect. 5 presents the results on recurrent collusion in this market. Section 6 concludes.",4
54.0,2.0,Review of Industrial Organization,15 June 2018,https://link.springer.com/article/10.1007/s11151-018-9642-z,Merger Control and Economic Growth of LDCs: Some Observations and Recommendations,March 2019,Boris Begović,Dušan Popović,,Male,Male,Unknown,Male,"The aim of this paper is to evaluate merger control as a segment of competition policy in less developed countries (LDCs). The only standard for its evaluation in this paper is economic growth. This approach assumes that economic growth is the priority of LDCs, and that the only aim of the competition policy of LDCs should be speeding-up economic growth. Accordingly, competition policy is evaluated by considering the main engines of economic growth: production factors accumulation, and the improvement of efficiency of their utilisation. This deviates from the standard Chicago School consideration of efficiency as the only aim of competition policy. Nonetheless, no other standards for evaluation but economic growth are considered, although it has been suggested (Bakhoum 2011; Gal and Fox 2015) that competition policy in LDCs should be a multiple-aim policy. Since economic growth is the priority of LDCs, competition policy is, in principle, well equipped to deal with it, especially the growth of total factor productivity (TFP), as a component of economic growth (Voigt 2009). Although accumulation of production factors is an indispensable engine of growth for LDCs, the appropriate competition policy in these countries should encourage the restructuring of ongoing business operations and the reallocation of resources from low to high productivity activities, and should enable both local innovation and imitation, considering that LDCs are far from the technological frontier. Those are operational targets that are within the realm of competition policy. Nonetheless, competition policy is not well equipped to deal with non-economic aims such as: supporting the public interest (whatever its specification may be); reducing inequality; safeguarding democracy;Footnote 1 promoting fairness and social inclusion; or development of small and medium-size enterprises (SMEs). If these aims are considered the aims of “economic development” (Bakhoum 2011), then this paper deals only with economic growth, not with economic development. At the end of the day, there could be economic growth without development, but there could be no economic development without growth. For this paper, competition policy is considered as a combination of competition law (with three main areas of enforcement: restrictive agreements, abuse of dominant position, and merger control) and advocacy, which is aimed at increasing competition apart from the competition law enforcement. It is assumed that the same resources can be reallocated among competition law enforcement and advocacy, as well as among the three pillars of competition law enforcement. Elasticity of substitution of the resources among these activities within a national competition authority (NCA) is assumed to be unitary. Although in this paper it is accepted that the competition policy of the LDCs should converge towards the competition policy of developed nations—in the sense that an “economics-based model” (Greber 2013) is accepted—the “absolutist view” (Priest 2013) that competition policy in every jurisdiction should be identical is not accepted. This enables a specific competition policy model for LDCs to be formulated, within the “economics-based model”, deviating from the conventional wisdom that competition policy in LDCs should inevitably have all three pillars, including merger control (UNCTAD 2017). The structure of the paper is consistent with its specified aim and described framework of assumptions. The heterogeneity of the LDCs will first be explored, with the implications for the economic growth of the specific groups of LDCs and pro-growth competition policy in them. Then specific economic features of LDCs that are relevant for the pro-growth competition policy in them will be analysed, focusing on mergers, their impact on economic growth, and the consequences of their control. The competition policy institutional environment of LDCs will then be analysed, identifying constraints for efficient implementation of competition policy, focusing on the institutional demands of merger control. Merger control in LDCs will be evaluated next: both its pros and cons. Based on that, desirable options for merger control in the LDCs will be specified and their implications will be analysed; the conclusion and recommendations follow. The recommendations are not general: Three regimes of merger control are recommended, depending on the level of institutional and economic development. For the LDCs with low levels of both, no merger control at all is suitable. For the LDCs with intermediate levels of both, very restricted merger control is recommended, evolving into somewhat restricted merger control for the remaining LDCs. The restrictions are: high notification thresholds (only pre-merger compulsory notification is considered); the exemption of cross-border and vertical mergers; and formal rules in the merger control process. Advocacy is recommended as the main substitute activity of the NCAs.",1
54.0,2.0,Review of Industrial Organization,07 June 2018,https://link.springer.com/article/10.1007/s11151-018-9638-8,Abuse of Market Dominance Under China’s Anti-Monopoly Law: The Case of Tetra Pak,March 2019,Xiao Fu,Guofu Tan,,,Unknown,Unknown,Mix,,
54.0,2.0,Review of Industrial Organization,18 August 2018,https://link.springer.com/article/10.1007/s11151-018-9651-y,Legal Treatment of Abuse of Dominance in Indian Competition Law: Adopting an Effects-Based Approach,March 2019,Payal Malik,Neha Malhotra,Nisha Kaur Uberoi,Unknown,Female,Female,Female,"Competition law regulates the very manner in which enterprises conduct their business: what they produce, how they produce, how much they produce, at what price do they sell their products, how they distribute their products, how they interact with peers, how they enter into business collaborations, how they draft contracts, how they invest in other businesses, and so on. Almost every process of the normal functioning of a business is within the domain of competition law. Therefore, competition law has a behavioural dimension to it. Nevertheless, like any other law, competition law attempts to codify—in this case conduct that is anticompetitive or procompetitive. Despite the codification, competition law enforcement is primarily driven by the way in which a competition authority reads and interprets the law and the liability standard that it adopts for establishing anticompetitive conduct. Some authorities might strictly follow the letter of the law and thus adopt a form-based approach, without actually extrapolating the effects of the transaction or conduct on competition and consumer welfare. However, other authorities might consider the spirit of the law and adopt an effects-based approach by balancing the procompetitive effects against the anticompetitive effects of the conduct or transaction on a case by case basis. It is important to note here that structuralist legal methods, which are essentially static in nature, are inadequate for analysing intrinsically dynamic competition phenomena. Competition authorities adopt different legal standards for different types of transactions and conduct, depending upon their perception of its potential anticompetitive or procompetitive effects. For instance, mergers and acquisitions and certain horizontal agreements—such as those that are related to research and development collaborations and technology sharing—are assessed using an effects-based approach in most jurisdictions. This is primarily in recognition of their potential to create efficiencies and enhance innovation and consumer welfare. However, the abuse of dominance has yet to achieve firm ground in being placed within an effects-based approach across several jurisdictions, even though the net effect of an action that is undertaken by a dominant firm is not necessarily anticompetitive, and cannot be presumed. In India, abuse of dominance is prohibited under Section 4 of the Competition Act 2002Footnote 1 and is predominantly enforced using a form-based approach. Section 4 of the Act defines ‘dominance’ and lists actions that are to be considered abusive, if undertaken by a dominant firm. Currently, the Competition Commission of India (CCI) mostly enforces this provision of the Act based on three key steps: (1) identifying the relevant product and geographic markets; (2) assessing the dominance of the concerned enterpriseFootnote 2; and (3) determining whether the dominant firm pursued an activity that can be constituted as an abuse of dominance under the Act. Under this form-based approach, the action of a dominant enterprise that falls in the categories that are defined in the provision of the Act is established as an abuse. This in itself is considered to be a violation of the law, with limited or no attempt to identify any other possible objective justification for the action of the dominant firm. Enforcement of competition law using a form-based approach often results in false positives: punishing actions that are procompetitive. For instance, while rebates that are offered by a dominant firm may lead to exclusion of present or potential competitors, it may also have procompetitive effects when lower costs and greater incentives to innovate due to economies of scale are passed on to consumers. Therefore, a form-based competition law enforcement may actually end up limiting consumer welfare. Further, a form-based approach is likely to create inconsistencies in outcomes of competition assessment, which results in the evolution of a muddled jurisprudence. Moreover, it may also become a hindrance to growth in today’s fast moving, technologically evolving, and extremely complex and inter-linked markets, by unnecessarily restricting the freedom of firms to pursue strategies in their best business interest. The current trajectory of India’s economic development requires a competition law that focuses on promoting efficiencies and allowing firms freely to innovate, strategize, and reap profits. This will eventually enable them to create value and benefits for their customers and the entire Indian economy. At the same time, it is also important to check continuously for any kind of exploitation as the economy grows and new market structures emerge. Therefore, there is an increasing need for adopting an effects-based approach (over a form-based approach) to bring about a more effective balance in competition law enforcement in India. Adoption of an effects-based approach requires a radical change in thinking and approach towards antitrust law on abuse of dominance in India. In order to meet the needs of the modern Indian economy, competition law in India underwent a significant shift in 2009, with the repealing of the Monopolies and Restrictive Trade Practices (MRTP) Act of 1969. This was because the focus of the MRTP Act was limited to restricting monopolies, and it was inadequate for a rapidly liberalising, privatising, and globalising India. The MRTP Act was replaced by the Competition Act (2002) (notified in 2009), which was much more specific in its formulation (including the abuse of dominance) and introduced a new focus of promoting competition in the Indian markets.Footnote 3 Given the changing economic scenario and market dynamics today, there is once again a need to revolutionize India’s antitrust enforcement on abuse of dominance into an effects-based approach. In fact, this approach has already been emphasised in the Raghavan Committee Report (2000), which formed the basis of India’s Competition Act 2002. Specifically, the committee recommended in its report that while assessing an abuse of dominance case, key questions that must be evaluated include: How will the practice harm competition? Will it deter or prevent entry? Will it reduce incentives of the firm and its rivals to compete aggressively? Will it provide the dominant firm with an additional capacity to raise prices? Will it prevent investments in research and innovation? Do consumers benefit from lower prices and/or greater product and service availability? While the Raghavan Committee Report did mention these aspects of competition assessment, there was no certainty as to whether the actual interpretation and implementation of the law would really adopt an effects-based approach. Such concern was shared by Rakesh Mohan and Sudhir Mujli,Footnote 4 who cautioned that if the Act was not adjudicated in an effects-based framework, its impact would be restrictive for India’s economic growth and entrepreneurship.Footnote 5 Section 2 of our paper highlights the benefits of adopting an effects-based approach in assessing abuse of dominance cases, along with providing an economic framework for implementing the same. We also briefly discuss the special case of platform markets to show the need for adopting an effects-based approach in undertaking competition assessment in non-traditional markets. Further, in this section we analyse case law from the European Union (EU) to show the difficult but nevertheless positive transition of the EU towards adopting an effects-based analysis in assessing abuse of dominance cases, for at least certain types of practices.Footnote 6 In Section 3, we provide an account of how the jurisprudence has developed for abuse of dominance cases in an emerging jurisdiction such as India. In Section 4 we conclude our paper.",2
54.0,3.0,Review of Industrial Organization,31 January 2019,https://link.springer.com/article/10.1007/s11151-019-09679-5,"Competition, Mergers, and R&D Diversity",May 2019,Richard J. Gilbert,,,Male,Unknown,Unknown,Male,"Almost all merger challenges in research-intensive industries by U.S. antitrust agencies include allegations of harm to innovation (Gilbert and Greene 2015). However, economic research that relates mergers to innovation incentives has been limited until recently. Letina (2016), Salinger (2016), Federico et al. (2017, 2018), Motta and Tarantino (2017), and López and Vives (2018) show that mergers can have unilateral effects for investment in research and development (R&D) that are conceptually similar to the unilateral effects from mergers for price competition.Footnote 1 This paper extends the analysis in Federico et al. (2017, 2018) in several respects: The model employed in this paper does not impose diseconomies of scale at the firm level in R&D. A firm can choose any number of R&D projects at a constant incremental cost. The model shows that mergers can increase the probability of discovery in some circumstances. The model allows for “replacement effects” described by Arrow (1962) that can reduce firms’ incentives to invest to develop new products or reduce costs. The model also allows for information spillovers that can reduce industry R&D incentives. Absent spillovers, the model shows that mergers often—but not always—reduce industry R&D effort and the probability of discovery. In addition, adverse price effects from mergers can harm consumers even if mergers increase innovation incentives. Mergers can promote innovation and expected consumer surplus if technological spillovers benefit imitators or enable follow-on innovations.",14
54.0,3.0,Review of Industrial Organization,30 August 2018,https://link.springer.com/article/10.1007/s11151-018-9657-5,Search Fatigue,May 2019,Bruce I. Carlin,Florian Ederer,,Male,Male,Unknown,Male,"It is well-accepted in economics that search is costly unless you are a “shopper” with zero search costs.Footnote 1 But consumers may find it difficult to become a shopper if firms engage in obfuscation (Spiegler 2006), shroud attributes (Gabaix and Laibson 2006), create price complexity (Carlin 2009), strategically release information and restrict advertising (Campbell et al. 2017), manipulate the layout of product offerings (Gu and Liu 2013), or excessively proliferate products (Hämäläinen 2017).Footnote 2 The fact that search is also tiring (e.g., Spears 2011) adds an intertemporal consideration to a consumer’s ability to become a shopper.Footnote 3 Search in one period may induce fatigue and inertia in subsequent periods—especially when the task of identifying the optimal choice is challenging. When firms intentionally make search more difficult, this not only affects a consumer’s current purchase decision, but also her willingness to participate in active search later on. As a result, a consumer may choose to become a shopper in some periods, but not in others. In this paper, we study oligopoly behavior when fatigue from searching in one period may affect consumers’ costs and incentives to become informed in future periods. Thus, we allow consumers to endogenously and dynamically choose to become “shoppers”, in contrast to previous contributions.Footnote 4 Search may occur between stores and within them–as in Hämäläinen (2017). We endow firms with the ability to engage in wasteful artificial product differentiation, whereby they may produce superfluous goods to make a consumer’s search more arduous and influence her dynamic decision to search or rest.Footnote 5 Indeed, large product lines and multiple offers appear to be effective in tiring consumers during search and causing inertia and suboptimal choices (Fasolo et al. 2009). We show that, whereas a monopolist would always choose to produce only one valuable product, firms that compete in an oligopoly engage in socially wasteful product proliferation. Moreover, the amount of product proliferation that occurs depends on the search technology. The more discriminating a consumer is in her search, the more artificial differentiation is necessary to tire her out during her search process. Sequential search leads to more product proliferation than does all-or-nothing search. In fact, when the consumer sorts products one-by-one (i.e., sequential search across and within stores), the firms respond by engaging in a “finding the needle in a haystack” game in which product proliferation is the most severe. In response to the added effort that is required during search, it might seem intuitive that a consumer would pace herself and smooth her search over time when facing a stream of lifetime choices. However, this does not arise in equilibrium in our model. Instead, it is optimal for the consumer to engage in time-varying search, whereby she exerts effort intermittently and rests following the periods of active search. When the consumer is not fatigued, she searches in the usual sense, prices are competitive, and no consumer assistance is offered. During these periods, the consumer earns all of the surplus. However, while she recovers, she chooses products randomly, prices are at monopoly levels, and the firms assist the consumer if she visits their store. Therefore, due to the firms’ product proliferation, cycles arise with time-varying prices (or time-varying price dispersion) and rent extraction, which are not only robust to the type of search technology, but also to the specific form of how fatigue affects future costs. Our results are consistent with empirical findings by Ericson (2014), who provides evidence for product proliferation, time-varying prices, and cycles of consumer inertia in the Medicare Part D insurance market, and by Hortaçsu et al. (2017), who document significant time-varying search costs and intermittent inertia due to product proliferation in the Texas retail electricity market.Footnote 6",10
54.0,3.0,Review of Industrial Organization,31 July 2018,https://link.springer.com/article/10.1007/s11151-018-9650-z,Merger Analysis in Two-Sided Markets: The Belgian Newspaper Industry,May 2019,Patrick Van Cayseele,Stijn Vanormelingen,,Male,Male,Unknown,Male,"Over the last decades, there has been a major consolidation wave in media industries worldwide, which has led to the emergence of large cross-media companies. This trend towards media ownership concentrations has raised concerns about potential harmful effects on the dissemination of accurate information. There are two possible detrimental effects of concentration in media markets: a reduction in opinion diversity/content quality, and an increase in market power by media companies (Chandra and Collard-Wexler 2009). Concerning the first effect, we refer interested readers to George (2007) and Fan (2013). We focus on the second effect, as we evaluate the impact of a merger in the Belgian newspaper industry on prices and welfare. Media markets are typical examples of two-sided markets due to the existence of network effects between advertisers and readers. We take into account the two-sided nature of the newspaper industry and estimate both advertisers’ and readers’ demands, which are interrelated. While advertising demand clearly depends on the readership of a newspaper, we take the assumption that readers are indifferent to advertising.Footnote 1 This way we focus on the one-way network effects from readers to advertisers. Subsequently, we build a structural model of oligopolistic competition between newspaper publishers to predict the merger effect on prices and welfare. Using a panel dataset of newspaper level prices and quantities of both advertising and readers’ side for the period 1994–2005 for the readers’ side and 2001–2005 for the advertising side, we find that the cover price of newspapers is below marginal cost. Moreover, this is more pronounced for readers of elite newspapers. The merger that we evaluate has little impact on prices and welfare. The small welfare losses that arise from the merger are easily offset by possible efficiency gains. Although merger simulations are now often applied when a competition authority has to decide whether to approve a merger, less is known about the accuracy of merger simulation predictions and more retrospective merger analysis is needed (Bjornerstedt and Verboven 2016). This paper performs such an ex-post evaluation and finds no impact of the merger on cover prices. The responses of the individual publishers to the ownership change are however not in line with the predictions. To the best of our knowledge, this paper provides the only ex-post evaluation of a merger simulation in a two-sided market. The rest of the paper is structured as follows: A brief overview of the Belgian newspaper industry and a literature review is provided in Sect. 2, and Sect. 3 shows the empirical model for both the demand for advertising space and readers’ demand for newspapers. The data used for the analysis are described in Sect. 4 and Sect. 5 presents the results of estimating the demand equations. Section 6 introduces a model for profit maximizing newspaper publishers that we use to infer the markups that were charged before and after the merger. Section 7 concludes.",9
54.0,3.0,Review of Industrial Organization,26 July 2018,https://link.springer.com/article/10.1007/s11151-018-9649-5,A Structural Break Cartel Screen for Dating and Detecting Collusion,May 2019,Carsten J. Crede,,,Male,Unknown,Unknown,Male,"The recent success of empirical methods that have been used by competition authorities in the Netherlands, Brazil, and Mexico and that have led to the detection of several cartels—as well as the spectacular case of the LIBOR market manipulation—have increased the interest in cartel screens (Abrantes-Metz 2014). The purpose of these empirical methods is to detect a cartel by identifying patterns in market outcomes that suggest collusion. They are meant “not to deliver the final evidence based on which colluders will be convicted, but instead to identify markets where empirical red flags are raised and which are worth further investigations.” (Abrantes-Metz 2014, p. 7). Increasing the detection probability might be necessary to prevent cartel recidivism and to increase deterrence with respect to potentially more successful and stable cartels (Harrington 2007). There are two categories of cartel screens: Structural screens identify markets that are likely to be subject to cartelisation due to industry characteristics. Behavioural screens detect cartels by detecting patterns in market outcomes that are treated as signs of collusion (Abrantes-Metz 2014; Harrington 2007). The literature on behavioural cartel screens has grown significantly in the last decade. Most notable are the contributions of Abrantes-Metz et al. (2006) and Bolotova et al. (2008), who propose cartel screens that are based on the analysis of price variance in an industry. In this article, a novel behavioural cartel screen is proposed that is based on identifying structural breaks in the data-generating process (DGP) of industry prices that are induced by cartel activity. The idea to trace structural breaks that originate from changes in pricing dynamics to detect cartels was first suggested by Harrington (2008). A DGP that characterises competition is established with a reduced-form price equation that is based on periods that are characterised by competition; the DGP is used to test suspicious periods for collusion. Absent other explanations for the structural breaks, their existence raises an empirical red flag that suggests that there might be a cartel and that the market requires further investigation. In addition to screening, the structural break cartel screen is suitable to date the start of a conspiracy that has already been detected. This is often an issue in antitrust litigation, when it is uncertain whether the earliest written evidence that has been found of a cartel represents the start of the conspiracy. Application of the new screen is discussed based on three European pasta markets—two of which were cartelised. Each market has different features, which allows a test of the screen under varying circumstances: The market in Italy featured a cartel and altered industry pricing dynamics that are consistent with tacit collusion after cartel breakdown. The cartel in the Spanish market lasted only 3 months, which renders it difficult to detect its impact on market prices. The French market did not feature a cartel, but saw prices rise significantly during 2007 due to a strong input cost shock. Unlike variance-based cartel screens, the proposed structural breaks screen successfully detects the cartels in Italy and Spain, but does not report a false positive of a cartel in France. Robustness checks show that the power of the test increases with the precision, with which the DGP of competition in an industry can be modelled.",9
54.0,3.0,Review of Industrial Organization,20 August 2018,https://link.springer.com/article/10.1007/s11151-018-9653-9,Is There a Loyalty-Enhancing Effect of Retroactive Price-Reduction Schemes?,May 2019,Lisa Bruttel,,,Female,Unknown,Unknown,Female,"This paper studies price-reduction schemes that condition on quantity. More specifically, it considers retroactive price-reduction schemes, where the price reduction is granted only after a certain absolute or relative quantity threshold has been reached but then the reduced price is also applied to all units below the threshold.Footnote 1 Such retroactive price reductions are frequently used in business-to-business relationships, which implies that the buyer often is a retailer.Footnote 2 Retroactive price reductions are often said to induce buyer loyalty. The economic reason is a so-called “suction effect:” Once a buyer starts ordering some units, he will not buy from alternative sellers anymore because close to the quantity threshold the marginal price for the remaining units up to the threshold is very low in comparison to the alternative offers. On top of such rational drawing power, everyday life provides us with a considerable evidence that price-reduction schemes also behaviorally influence buyers: As an example, think of the members of frequent flier programsFootnote 3 or the use of point cards that are stamped when purchasing a cup of coffee. Professional retailers may tend to such judgmental biasesFootnote 4 too—in particular, if they own a relatively small business unit such as, for example, a travel agency.Footnote 5 This paper presents results from an experiment that is designed to address the research question of whether buyers have a behavioral tendency towards participating in retroactive price-reduction schemes, even if these schemes do not maximize their expected profit. This question has implications for market entry or exclusion models in economic theory, because buyers form the “other side” of the market, which is often neglected in formal models that represent their decisions in some standard demand function. A loyalty-enhancing effect of retroactive price-reduction schemes may serve the incumbent firm as an additional instrument to exclude (potential) rivals from competition. The experiment in this paper studies three repetitions of a decision problem with 20 rounds in which participants in the role of buyers decide whether to buy a fictitious product either from a large incumbent firm (“seller 1”) or from competing firms in the market (which are represented by “seller 2”). Seller 1 offers a retroactive price-reduction scheme. Seller 2 represents the spot market, where the product is offered randomly at a high or at a very low price. Treatments vary the framing of the price-reduction scheme as an immediate discount or a final refund. Another treatment variation determines whether the pricing scheme of seller 1 or the price offers of seller 2 maximize the expected profits of the buyer. The experiment reveals two main findings: First, retroactive price-reduction schemes bias behavior toward the incumbent (seller 1) only when the buyer initially believes that buying from seller 1 is optimal but subsequent events cause buying from seller 2 to become optimal. Second, this effect is stronger if seller 1’s price-reduction scheme is framed as a discount. Loss aversion can explain this result.",
54.0,3.0,Review of Industrial Organization,23 August 2018,https://link.springer.com/article/10.1007/s11151-018-9655-7,The Effect of ID Verification in Online Markets: Evidence from a Field Experiment,May 2019,Jeffrey A. Livingston,Patrick A. Scholten,,Male,Male,Unknown,Male,"Buyers and sellers in online market transactions are often completely unknown to each other. This gives fraudulent sellers the opportunity to fake their online identity, or steal another reputable seller’s identity. As a result, it is far less likely that the seller will be tracked down and held accountable should a problem arise. This can exacerbate problems that arise from asymmetric information. Buyers who are aware that such sellers have little incentive to act honestly may avoid participating in potentially welfare-enhancing transactions entirely. This is the standard market unraveling problem that can accompany adverse selection and/or moral hazard. Because these problems are so potentially damaging, both governments and private market institutions have developed ways for market participants to verify their identity.Footnote 1 The goal of this study is to estimate whether such programs effectively influence buyer behavior. We study a service formerly offered by eBay.com called ID Verify, which allowed sellers to have their identity confirmed by Equifax: one of the three major credit information companies that issues credit reports. Once ID verified, a graphical icon is then displayed next to the seller’s name and feedback rating on their auction pages.Footnote 2 Since the decision to become ID verified is endogenous, it is difficult to identify the effect of ID Verify using naturally-occurring data. The program likely tended to be employed only by sellers who had already established a good reputation. Accordingly, one cannot tell whether the better outcomes that are experienced by sellers who have purchased ID verification are due to the sellers’ ID verification or due to their superior reputations.Footnote 3,Footnote 4 To overcome this problem, we conduct a field experiment on eBay where both ID verification and the strength of the seller’s reputation are randomly determined. Sets of four matched auctions of iPod shuffles, which have a retail price of $49.99, are conducted. The control group consists of auctions by a seller identity that is not ID verified and also has no reputation (a feedback rating of zero). The treated groups include auctions by a seller identity that is ID verified but has no reputation, auctions by a seller identity that is not ID verified but has a solidly positive feedback rating, and auctions by a seller identity that is ID verified and also has a solidly positive feedback rating. The results provide only meager evidence that consumers in this marketplace react positively to ID verification. Both ID verification and a good reputation attract more bidders relative to the control identity, but only a good reputation has an effect on the winning bid. ID verification alone results in winning bids that are no different than the control identity, but the identity that has only a good reputation receives winning bids that are substantially above those earned by the control identity. Further, the good reputation-ID verified identity may receive a lower winning bid than the good reputation identity that is not ID verified. The remainder of the paper proceeds as follows. Section 2 provides some background on the ID Verify program. Section 3 describes the experimental design. Section 4 presents the data. Section 5 presents and discusses the results of the analysis. Section 6 concludes.",1
54.0,4.0,Review of Industrial Organization,20 February 2019,https://link.springer.com/article/10.1007/s11151-019-09684-8,Introduction to the RIO Special Issue on Antitrust and the Platform Economy,June 2019,Thomas M. Lenard,,,Male,Unknown,Unknown,Male,"The last few years have seen increasingly intense debates about antitrust policy; these debates are motivated in large part by the emergence of large tech platforms. The concern is that “[t]he United States has a market power problem,” and that “economic forces [today] mirror the industrial concentration and economic inequality of the turn of the twentieth century.”Footnote 1 Some view today’s tech giants as “just as dominant” as Standard Oil and AT&T were in their day.Footnote 2 And, indeed, the world’s five largest companies by market capitalization are Apple, Amazon, Alphabet, Microsoft and Facebook.Footnote 3 There is no question that these companies are the source of transformational new products and services. Whether they also have gotten too big and powerful is now the subject of heated debate, with critics offering remedies that range from common carrier-style regulation to more aggressive antitrust enforcement (including a fundamental reevaluation of our approach to antitrust), possibly leading to the break-up of one or more of these companies.Footnote 4 Any discussion of the role of antitrust in the platform economy should probably start with Microsoft: the seminal digital economy antitrust case. The Microsoft case raised a number of fundamental questions that involve industrial organization and antitrust enforcementFootnote 5: Does the existence of network effects imply that technology markets are different from more traditional markets? Are these markets prone to concentration and conditions that make entry difficult? Does this require a different antitrust approach? Does rapid technological innovation necessarily make these markets vulnerable to new entrants and therefore diminish the need for vigorous antitrust enforcement? Alternatively does constant change make antitrust enforcement more difficult? Do dominant firms pose a threat to innovation due to their ability to extend their position into new markets and deter entry by potential competitors? These questions are still relevant today. In addition, the emergence of large multi-sided platforms that are dependent on large amounts of user data raises additional questions: Is data a source of market power and a barrier to entry? How should markets be defined in this space? How should antitrust deal with products that are provided at no financial cost to consumers? How do we define harm in these markets? If an antitrust problem is found, can appropriate remedies—that yield benefits that are greater than the remedies’ costs—be fashioned? The question of appropriate remedies was a major issue in the Microsoft case. Finally, do the criteria for antitrust more broadly need to change? In particular, should the consumer welfare standard be abandoned in favor of a different, perhaps broader, set of objectives? The authors of the papers in this special issue address many of these questions, starting with an examination of lessons learned from some of the most important antitrust cases of the past century.",4
54.0,4.0,Review of Industrial Organization,29 January 2019,https://link.springer.com/article/10.1007/s11151-019-09680-y,The Dubious Antitrust Argument for Breaking Up the Internet Giants,June 2019,Robert W. Crandall,,,Male,Unknown,Unknown,Male,"In recent months, a variety of revelations with respect to alleged violations of consumer privacy and other consequences of their enormous size have ramped up interest in pursuing some sort of government “regulation” of the large Internet firms: Facebook, Amazon, Apple, and Google (and even Netflix). These firms have grown extremely rapidly and now account for nearly 10% of the market value of all listed U.S. stocks. They dominate the digital advertising market and may well achieve a similar position in major media, displacing or weakening the traditional media companies, such as Walt Disney, CBS, NBC-Universal, Viacom, and 21st Century Fox. Amazon has entered the retail grocery market and may soon begin to provide its own transportation for goods that are purchased on its website. Google is pursuing new technologies for driverless vehicles, sending warning signals to traditional vehicle manufacturers. Facebook continues to displace traditional newspapers and video outlets as the source of daily news and opinion (and the platform for their advertisers). Given the size of the new digital giants and their major positions in individual market segments—social media, Internet search, online shopping, etc.—it was inevitable that critics would begin to suggest the use of antitrust enforcement to rein them in and perhaps create more competition in their respective market spaces. As early as 2010, academics began to explore the possibility of using Section 2 of the Sherman Act to devise remedies that would facilitate greater entry into digital markets (Butts 2010). Most of the proponents of a vigorous antitrust policy in this space rely in one way or another on the results of the Microsoft antitrust case that was ended by a decree that imposed various restrictions on Microsoft’s future behavior. This decree was entered after the U.S. Court of Appeals reversed a lower court order that would have broken up Microsoft.Footnote 1 To many critics, the Microsoft case decree was a failure because it did not separate Microsoft’s operating systems division from its applications software operations, or at least provide stronger incentives for entry into these two markets.Footnote 2 Any discussion of the possibilities of using antitrust to constrain the ever-expanding digital-media giants inevitably begins with the invocation of Microsoft. In this paper, I look at developments in the two major markets that were involved in Microsoft and show that competition has developed with a vengeance despite the perceived failings of the Microsoft decree. But just as important is the general misperception of the effectiveness of major (Section 2, Sherman Act) monopolization cases in the past. A careful review of these cases suggests that government intervention of this nature has not been as successful as casual observers of antitrust claim and should therefore be approached with extreme caution. This paper begins with a review of the “landmark” cases that pundits often cite as examples of the success of antitrust. A careful review of these cases suggests a different perspective.",9
54.0,4.0,Review of Industrial Organization,20 March 2019,https://link.springer.com/article/10.1007/s11151-019-09685-7,Antitrust in the Internet Era: The Legacy of United States v. A&P,June 2019,Timothy J. Muris,Jonathan E. Nuechterlein,,Male,Male,Unknown,Male,"Think of a company—past or present—that uses scale, vertical integration, and innovation to transform retailing; that becomes America’s largest retailer by giving consumers a wider range of products than the competition and at lower prices; and whose very success prompts calls for radical changes to the nation’s antitrust laws. Who is this behemoth? Amazon fits this description except in one respect: It is not close to being the leading U.S. retailer.Footnote 10 Instead, the company that we describe is the now-defunct Great Atlantic and Pacific Tea Company: A&P, where one of us bagged groceries as a teenager.Footnote 11 A&P was the largest American retailer for more than 40 years; it pioneered the large retail chain and later the supermarket. A&P brought enormous benefits to consumers—especially the less affluent—through lower prices, greater variety, and opportunities for improved nutrition. But those consumer benefits did not go unpunished. Although A&P is no longer a going concern and is rapidly passing from public memory, it was once a disruptive juggernaut of American retailing. From humble beginnings in the mid-nineteenth century, it emerged by the 1920s as the largest American retail chain by far, vertically integrating into multiple stages of food production, distribution, and retail sales. As recounted by Marc Levinson, A&P’s leading biographer: By 1929, when it became the first retailer ever to sell $1 billion of merchandise in a single year, A&P owned nearly 16,000 grocery stores, 70 factories, and more than 100 warehouses. It was the country’s largest coffee importer, the largest butter buyer, and the second-largest baker. Its sales were more than twice those of any other retailer.Footnote 12 Levinson attributes A&P’s success to the far-sightedness of its long-time owners, the brothers George and John Hartford: “At a time when most retailers worried about the profit margin on each item they sold, the Hartfords focused on their long-term return on investment. They understood that if their company kept its costs down and its prices low, more shoppers would come through its doors, producing more profit than if it kept prices high.”Footnote 13 Low costs were the linchpin of this strategy: First, A&P built its own distribution network to bypass “jobbers” and other profit-taking middlemen that mom-and-pop grocers relied upon for delivery. Eliminating these middlemen was highly efficient because, as the FTC observed in 1919, “[t]he cost of these individual delivery systems … [wa]s a large item to be figured into the wholesale prices.”Footnote 14 For example, “[m]ost produce … was sold by individual farmers to small-town dealers who in turn sold to bigger dealers in nearby cities, creating a lengthy and circuitous route before perishable merchandise finally reached the retail store.”Footnote 15 Instead, A&P or its affiliates bought directly from food producers and passed the wholesale savings to consumers through lower retail prices. The main “victims” of this practice were the bypassed middlemen and the smaller grocers who continued to rely on the middlemen’s expensive services and thus found themselves undersold at retail. As discussed below, both groups would play a central role in goading the government into waging war against A&P. Second, once it had eliminated the middlemen, A&P persuaded food producers to sell to it on highly advantageous terms. A&P won deeper discounts than other purchasers in part because, given its scale, it bought in such large and predictable volumes that it offered the producers major cost savings. No doubt some of those discounts were also attributable to A&P’s bargaining strength. Any contractual transaction produces a “surplus”: value that the two sides agree to divide. The greater one side’s leverage is, the greater is its portion of the surplus from the deal; but so long as a bargain is struck, both sides remain better off than in the absence of any deal.Footnote 16 In this case, A&P’s purchasing clout enabled it to win a larger share of the surplus in the form of unusually deep discounts, of which consumers received the lion’s share. Here, too, consumers were the winners; the main victims were the smaller grocers who lacked the bargaining clout to win similar discounts, and who thus could not meet A&P’s low retail prices.Footnote 17 Third, A&P kept costs low by vertically integrating—not only into distribution, but into food production as well. Like many forms of vertical integration today, A&P’s produced major efficiencies, which again benefited consumers. For example, its baked goods were “delivered to stores in the same trucks that delivered other foods rather than by commissioned salesmen, a system that saved a penny per one-pound loaf at a time when the average loaf sold for a nickel.”Footnote 18 More broadly, “A&P’s manufacturing plants earned money because the company learned to use the flow of orders from its [retail] stores to run the plants steadily at full capacity, reducing the waste that comes from expensive factory equipment that is not fully utilized.”Footnote 19 A&P also succeeded because it did what many tech companies do today, albeit amid much controversy: use data to create greater consumer value. For example, A&P used such data to meet previously unrecognized regional preferences: “Philadelphians, it found, liked their butter lightly salted, with a light straw color, whereas New Englanders preferred more salt and a deeper yellow coloration.”Footnote 20 And the company’s “mass of sales data allowed A&P’s bakeries to forecast demand with a high degree of accuracy, minimizing returns of stale bread and doughnuts” and thus reducing costs and ultimately retail prices.Footnote 21 These innovations enabled A&P to sell top-quality groceries at unusually low prices, which won the loyalty of consumers but also the enmity of undersold competitors and displaced wholesalers. Ultimately these disgruntled rivals prevailed on the government to give them what they could not win in the market: a way to blunt A&P’s popularity with consumers. The first wave of government intervention came via state and federal taxes that were imposed only on chain stores like A&P; this was a transparent effort to prop up the profit margins of smaller and less efficient stores. “By the mid-1930s, 29 of the 48 states had taxes on chain stores, some of them so high as to capture half of the profits of an average chain grocery store.”Footnote 22 A second and longer-lasting attack on chain stores was the Robinson–Patman Act of 1936, originally—and more descriptively—entitled “the Wholesale Grocer’s Protection Act.”Footnote 23 The Act imposes a general prohibition on selling “commodities of like grade and quality” at different prices to different buyers, but is subject to various exceptions; for example, a seller may defend such differential pricing to buyers on the ground that it makes “due allowance for differences in the cost of manufacture, sale, or delivery” or is needed to “meet” competition.Footnote 24 The main effect of the Act on A&P and other chain stores was to keep them from obtaining goods at lower wholesale prices than their smaller competitors and thus from passing along the savings to consumers. As the Seventh Circuit recently remarked with notable understatement, the Act’s “fit with [contemporary] antitrust policy is awkward, as it was principally designed to protect small businesses” at the expense of consumers.Footnote 25 The Robinson–Patman Act had its intended effect, at least in the first decades after its enactment. As Levinson recounts, “[t]he average publicly traded grocery company lost 58 percent of its stock market value” over a two-and-a-half year period after the legislation was introduced, even while the broader stock market was gaining value, “suggest[ing] that investors expected the law to have a severe impact on profitability. That expectation proved correct.”Footnote 26 A&P and other supermarket chains lost profits even as they raised retail prices to cover the higher cost of wholesale goods.Footnote 27 Again, the ultimate victims of the Act were the millions of ordinary consumers who were forced to pay higher prices for food and other necessities. The Robinson–Patman Act remains on the books, and it has spawned eight decades of case law so arcane in its distinctions and so baroque in its complexity that it would have driven even the medieval scholastics to distraction. In the words of Robert Bork, the Act and its subsequent application are “the misshapen progeny of intolerable draftsmanship coupled to wholly mistaken economic theory.”Footnote 28 To take one such example, what does it mean for a seller to make “due allowance for differences in … cost” when charging different amounts to different buyers?Footnote 29 That question has embroiled courts in intractable disputes about how to allocate savings in joint-and-common costs across product lines—a conceptual problem without an economically meaningful solution.Footnote 30 In the words of a Yale Law professor writing in 1937, the year after Robinson–Patman was enacted, “[n]o accountant has been able to devise a method yielding by-product or joint-cost figures which does not embody a dominance of arbitrariness and guesswork,” and “[t]rial is to proceed by the ordeal of cost accountancy.”Footnote 31 The author concluded, presciently, that the Act “seems destined to raise more questions than it settles” and “presently will reveal its own defects and invite abandonment or amendment.”Footnote 32 Ultimately, the Act was indeed refined and partially abandoned, though by non-enforcement and creative judicial interpretation rather than legislative action. By the 1960s, the Act had come under increasing fire from practitioners, economists, legal scholars, and enforcement officials for both its indeterminacy and its anti-consumer orientation. The critics included a practitioner, Frederick Rowe, the author of a two-volume treatise on the Act’s complexities and an influential 1957 article criticizing the ActFootnote 33; Philip Elman, an FTC Commissioner who wrote key dissents in the 1960s from findings of liability under the ActFootnote 34; Morris Adelman, an MIT economist who critiqued the objectives of the Robinson–Patman Act in his 1959 book that condemned the government’s Sherman Act case against A&PFootnote 35; Robert Pitofsky, who condemned the FTC’s Robinson–Patman case law as a key contributor to an American Bar Association Report in 1969, a quarter century before he became FTC ChairmanFootnote 36; and then-law-professor Richard Posner, who wrote a critical analysis of the Act in 1976.Footnote 37 Significantly, of these five, only Posner could be labeled as part of the “Chicago School” of antitrust, an epithet that populists today use to describe anyone who believes that antitrust doctrine should rest on economic analysis.Footnote 38 Each of the other Robinson–Patman critics either was clearly unconnected to the Chicago School or, in Pitofsky’s case, was an outspoken opponent of it.Footnote 39 What these five shared was a basic commitment to economic rigor and consumer welfare—a commitment that transcends any particular “School.” In 1977, this growing criticism led the Department of Justice to publish a major attack on Robinson–Patman enforcement: It called the Act “protectionist” with a “deleterious impact on competition” and ultimately consumers.Footnote 40 The FTC, which had issued nearly 1400 Robinson–Patman complaints over the preceding four decades, was reaching the same conclusion: The agency dramatically slowed enforcement efforts in the 1970s and all but ended them thereafter.Footnote 41 Private actions have continued, but here, too, the courts have heeded the intellectual consensus against the Act by creatively reinterpreting it, where possible, to align with the general consumer orientation of contemporary antitrust. A&P itself played a role in those judicial developments by persuading the Supreme Court in 1979 to reject “interpretations of the Robinson–Patman Act which … help give rise to a price uniformity and rigidity in open conflict with the purposes of other antitrust legislation.”Footnote 42 The Supreme Court carried creative reinterpretation of the Act to new heights when, in 2006, it found that “[t]he Robinson–Patman Act signals no large departure from th[e] main concern of antitrust”—promoting consumer welfare—and lower courts should thus avoid applying the Act in ways “geared more to the protection of existing competitors than to the stimulation of competition.”Footnote 43 Of course, these developments were small comfort to A&P and other chain stores in mid-twentieth century America—and smaller comfort still to the millions of American consumers who were forced to pay the equivalent of a federal tax on groceries and other necessities to support inefficient retailers and middlemen. And for A&P in particular, the worst was yet to come. A&P was already burdened by the Robinson–Patman Act and anti-chain taxation laws when, in 1944, the federal government indicted the company and its key executives, including the Hartford brothers, for criminal violations of the Sherman Act.Footnote 44 After a lengthy bench trial, a federal district court convicted all defendants, and the court of appeals affirmed.Footnote 45 Viewed from the perspective of contemporary antitrust theory, the courts’ opinions are a bracing comedy of economic errors, and they illustrate just how unpredictable and arbitrary antitrust can become when unmoored from its current foundations in consumer welfare analysis. The district court’s opinion occupies some 54 double-columned pages in the Federal Supplement; but one studies it in vain to uncover any business practice that could plausibly harm consumers. There are vague assertions that A&P had priced below cost in various product lines and places and thereby committed a form of predatory pricing: a plan to drive competitors from the market and thereafter raise retail prices to monopoly levels.Footnote 46 On inspection, however, the government’s claims of below-cost pricing rested on accounting tricks rather than economic realities.Footnote 47 More fundamentally, as Morris Adelman subsequently explained, the government had identified no scenario in which A&P could ever hope to recover its short-term losses through long-term monopoly prices. Anticipating the Brooke Group recoupment test by more than a quarter century, Adelman explained that “[n]o reasonable and prudent A&P management would have incurred losses to drive out competition because it would have been impossible to claim the pay-off,” given that “[e]ntry into the food trade was so cheap and easy that any attempt to raise prices would immediately have resurrected competition.”Footnote 48 The government fared no better when it tried to tie A&P’s supposed buying power to consumer harm. It argued that, because A&P forced suppliers to give it such deep discounts, those suppliers responded by raising prices to other grocery stores, such that—in the words of the prosecution—“[t]he consumers who buy food in stores competing with A&P pay part of the low cost of A&P’s operations.”Footnote 49 As Levinson points out, though, this theory of consumer harm nonsensically “implies that manufacturers met their profit targets by raising prices to other stores to compensate for their price breaks to A&P. But why would manufacturers have charged other retailers less if only A&P had paid more?”Footnote 50 In this and other respects, Adelman suggests, “the government lawyers, although competent in their profession, were so sadly illiterate in economic facts and economic analysis that they simply did not realize what they were saying.”Footnote 51 The prosecution and district court also impugned A&P for vertically integrating into food production and distribution, but here, too, one struggles to find any connection between the practices described and any harm to consumers. The district court was particularly perturbed that one A&P affiliate—the Atlantic Commission Company (“Acco”)—operated as A&P’s purchasing agent for fresh produce and sold to third-party grocery stores whatever A&P’s retail stores did not need—typically at higher (i.e., market) prices. The court condemned this practice because “Acco’s policy of charging A&P one price and its other customers another, all worked to create restrictions upon competition and to handicap the competitors of A&P in view of the fact that competitors paid Acco earnings which went to A&P who did the competitive retailing.”Footnote 52 It characterized as “unearned tribute” the payments that third-party retailers made to Acco for its leftover produce; noted that such payments found their way into “the treasury of A&P” and “could be used as defendants wished in competing with others”; and concluded that these “odorous unjustified transactions” and “[t]he multiple roles of Acco taint[ed] the whole fabric of defendants’ operations.”Footnote 53 The court repeated variations on this rhetorical theme for several pages, but at no point did it explain why Acco’s “multiple roles” posed any genuine problem. No one forced third-party grocery stores to pay “unearned tribute” to Acco. Instead, they presumably bought from Acco because its prices were competitive with those of other suppliers, and there were in fact many supplier alternatives. Indeed, Levinson observes, Acco’s “sales to buyers other than A&P came to a mere 3 percent of U.S. grower’s total produce sales.”Footnote 54 In other words, these third-party grocery stores would have been no better off, and perhaps worse off, had Acco thrown out the produce that A&P did not need rather than offering it to them. At bottom, the complaint here was not that Acco charged third-party grocers too much, but that vertical integration with Acco enabled A&P to obtain produce too cheaply (including through the elimination of double-marginalization) and pass the savings to consumers. Ultimately, the government’s case had nothing to do with any genuine theory of consumer harm and everything to do with protecting companies at all levels of the grocery business from A&P’s disruptive efficiency—no matter what the ensuing cost to consumers.Footnote 55 One prosecutor claimed that “A&P sells food cheaply [to consumers] in its own stores because it is a gigantic blood sucker, taking its toll from all levels of the food industry.”Footnote 56 That logic bears a striking resemblance to a wholesaler association’s argument in favor of the Robinson–Patman Act the previous decade: that rapid expansion of efficient chain stores was taking money “right out of [the] pocket” of “the producer and shipper[]” and “giving it to the consumer,” who presumably had no right to it.Footnote 57 The similarity between these arguments was no coincidence. Adelman explains: the A & P case is best understood as an attempt … to infuse the Robinson–Patman Act into the Sherman Act.… The hostility to price competition, the yearning for secure entrepreneurial status, the envy and hate of the small businessman for big business were long ago embodied in a set of standard myths. Great gobs of misunderstood evidence were forced into these molds to produce the case for the prosecution.Footnote 58 Nevertheless, the district court carefully recited that neither bigness nor vertical integration was per se unlawfulFootnote 59 and that businesses “have the right to set prices at such figures as to meet competition.”Footnote 60 How, then, are executives at large companies to know when they have crossed the line? What limiting principle keeps the Sherman Act from condemning any aggressive, price-reducing competition? Instead of analysis, the court offered standardless rhetoric. Vertical integration, it held, is permissible—unless it confers “unreasonable advantages over competitors not similarly integrated.”Footnote 61 Retail price cutting is permissible—unless it amounts to an “unreasonable restraint of competition.”Footnote 62 A large buyer, the court continued, may drive a hard bargain with suppliers—unless it “manipulate[s] its power in order to realize an unwarranted discrimination or preference.”Footnote 63 In each of these contexts, the court identified no criteria that would distinguish “reasonable” (or “warranted”) from “unreasonable” (or “unwarranted”) conduct. The court’s opinion was shot through with such “I know it when I see it” value judgments, often expressed with some type of olfactory or visual metaphor. For example, the court found that various A&P “practices over the years leave a bad odor”Footnote 64 and that Acco’s sales to unaffiliated grocers at market rates were not only “unjustified,” but “odorous.”Footnote 65 And various actions may, “standing alone, [have been] devoid of wrongful character, but when the fabric woven from them is considered as a whole,” it “t[ook] on a polluted colored light.”Footnote 66 These and similar passages revealed only that the prosecution moved the district court to a visceral dislike of these defendants. They identified no coherent rule of decision for future cases, let alone one that served the intended beneficiaries of the Sherman Act: consumers. In 1949, the Seventh Circuit upheld the A&P convictions in a shorter opinion that contained just as little analysis.Footnote 67 The government promptly returned to court, and this time sought the economic death penalty: the breakup of A&P. The company responded with an aggressive legal and public relations defense. It ran one advertisement with a photograph of the Empire State Building and the caption: “It’s Far Too Big. It Ought to be Seven Buildings.”Footnote 68 A&P also orchestrated a write-in campaign from ordinary consumers: the beneficiaries of A&P’s supposed multi-decade predation. One representative letter to the Attorney General read: “I am dropping you a line to see if you will try and help us housewives save our A.&P. stores. We surely could not make our money go so far in small stores.”Footnote 69 The government’s civil case stalled amid personnel changes in DOJ’s leadership at the end of the Truman administration. It then settled soon after President Eisenhower took office: In exchange for the government’s agreement to drop the suit, A&P agreed to close Acco.Footnote 70 A&P began its long decline almost immediately thereafter. The decline began with the sudden death of chief executive John Hartford in 1951, accelerated with a series of managerial missteps over the ensuing decades, and finally culminated in 2016 with the closure of the company’s few remaining stores. There are usually multiple reasons for a great company’s demise, and A&P was no exception. The Hartford brothers’ plans for a new generation of management proved faulty, and the company was less nimble than its rivals in adjusting to America’s post-war economy. But A&P faced an enormous distraction that its rivals did not: a long struggle with the federal government, including criminal cases against senior executives and an attempt to dismantle the company. Those constant legal threats occupied a considerable amount of one of the most precious resources any company has—the time and energy of its senior management. In 1949—the same year that the Seventh Circuit upheld the A&P convictions—two seminal articles appeared from economists sharply critical of the government’s case against A&P: The first was Morris Adelman’s initial analysis of the case,Footnote 71 which he later expanded into a full-length book.Footnote 72 The second was a student note published in the Yale Law Journal. Although student notes then appeared without bylines, the author was Donald F. Turner, who had earned an economics doctorate from Harvard and was teaching economics at Yale while earning his law degree there.Footnote 73 In 1954, Turner joined the Harvard Law faculty, where he coauthored a definitive antitrust treatise with his colleague Phil Areeda after leading the Antitrust Division from 1965 to 1968. Turner’s student note made short work of the government’s case against A&P. He explained that neither the government nor the courts had made any serious effort to “draw the line between ‘predatory’ and ‘competitive’ price cutting,” and thus their “general broadside against A&P’s reduction of gross profit rates is a direct attack on the competitive process. … Does the Government or the court feel that business should never risk a loss for the sake of ultimate gain? If so, a good share of competition must be consigned to limbo.”Footnote 74 Likewise, Turner explained, the court’s attacks on Acco’s role within the A&P corporate family “approach saying that vertical integration is illegal per se,” even though the court professed to reject that position.Footnote 75 More broadly, Turner took aim at a “serious contradiction” in what he called the “[n]ew” Sherman Act: a misguided effort to apply the Act to attack the very competitive forces it was meant to promote.Footnote 76 For example, in the name of protecting “competition,” the government prosecuted A&P for competing too hard with smaller and less efficient grocers. Yet “vigorous competition is not a friendly pastime. New methods of production and distribution not only disturb existing firms; they frequently demolish them. It then becomes much too easy to identify the demise of these beleaguered competitors with a decline in competition itself.”Footnote 77 That conceptual error not only leads to unjust prosecutions, but subverts the very point of the antitrust laws: The lure of temporary monopoly profits is an important impetus to the introduction of new products and new techniques, which rudely upset the peaceful, profitable existence of long-entrenched business firms. This constant change to the new, the more efficient, is the very heart of the process of effective competition.… But in [the A&P case] the defendant corporation represented the forces of competition, efficiency and change. The potential contradiction in the New Sherman Act is sharply exposed.Footnote 78 
In short, Turner argued, the antitrust philosophy on display in the A&P case was a paradox: a policy at war with itself. If that thesis sounds familiar, it should: It is the title of Robert Bork’s book-length critique of antitrust policy three decades later.Footnote 79 Although Bork’s book is often cited as a foundational text of antitrust’s “Chicago School,” Turner was no Bork, nor would anyone call him an antecedent of the Chicago School. To the contrary, Turner helped found the “Harvard School,” which is often cited as a counterweight to the Chicago School in American antitrust theory.Footnote 80 And Turner went on to lead antitrust enforcement in the Johnson Administration, which was not known for its conservatism on economic policy. This illustrates an important point, to which we return below: One need not be a Chicago School adherent to reject the type of analytical sloppiness that motivated the prosecution of A&P. Nor need one be a Chicago School adherent to agree with Turner that courts and enforcement agencies can promote the competitive goals of the antitrust laws only if they allow disruptive companies to reach efficient scale, achieve the efficiencies of vertical integration, and undersell smaller and less efficient competitors through relentless price-cutting. To take those positions, one need only know some economics and view the welfare of consumers as the central objective of sound antitrust policy.",3
54.0,4.0,Review of Industrial Organization,13 February 2019,https://link.springer.com/article/10.1007/s11151-019-09693-7,"Digital Data, Platforms and the Usual [Antitrust] Suspects: Network Effects, Switching Costs, Essential Facility",June 2019,Catherine Tucker,,,Female,Unknown,Unknown,Female,,23
54.0,4.0,Review of Industrial Organization,19 February 2019,https://link.springer.com/article/10.1007/s11151-019-09683-9,"Multisided Platforms, Big Data, and a Little Antitrust Policy",June 2019,Michael L. Katz,,,Male,Unknown,Unknown,Male,"Commentators on both the right and the left ends of the political spectrum have called for new and more forceful approaches to antitrust enforcement with respect to large multisided platforms—especially Amazon, Facebook, and Google.Footnote 1 In part, these calls have been driven by the sheer scale and prominence of these companies.Footnote 2 These calls have also been driven by the fact that these platforms make extensive use of data collected about their users.Footnote 3 Some commentators argue that the control of extensive user data allows these platforms to amass substantial market power in their existing markets and extend it to others,Footnote 4 while other commentators argue that substantial market power allows these companies to abuse consumer privacy.Footnote 5 In this article, I examine the application of antitrust policy to multisided platforms for which big data—data sets that are large due to a combination of breadth, depth, and frequency of collection—about their users are central to their business models.Footnote 6 I am particularly interested in the situation in which a multisided platform analyzes big data regarding users on one side of the platform to estimate their preferences and predict their behavior in ways that are valuable to users on another side of the platform. Such data analyses can assist the users on the second side of the platform in better targeting: product designs (e.g., the use of viewership data to guide video programming development); pricing strategies (e.g., various forms of price discrimination); and promotional strategies (e.g., the use of search histories and other data to facilitate the sale of highly targeted advertising).Footnote 7 There are several possible features of platforms’ utilization of user big data that have raised concerns among academics, antitrust authorities, and others:Footnote 8 User data can be an important asset. User data clearly can be very valuable for some multisided platforms, such as those selling targeted digital advertising; and firms that lack access to such data may be unable to compete successfully. The collection and analysis of user data may be subject to strong increasing returns due to experience effects and economies of scale and scope. Both the collection and utilization of user data may yield strong benefits to experience and scale because the additional data that are generated by having more customers and transactions may allow a platform to train better the algorithms that underlie its services. There can also be economies of scope in both the collection of data (e.g., a firm active in several markets may be able to collect diverse data that can be aggregated to build a richer model of consumer behavior) and its use (e.g., the same model of consumer behavior might be applied to sell a wide range of products). User data can facilitate sophisticated pricing strategies. As noted above, user data can facilitate various forms of price discrimination. A multisided platform for which users on one side extend credit or insurance to users on the other side might also collect data that allow users on the first side to assess the party-specific risks or costs of transacting with a given user on the other side. To the extent that a given user’s data are used to improve the products or services tailored to him or her, the collection of data that are not portable across platforms can create switching costs and give rise to consumer lock-in. Such effects could arise with respect to recommendation engines, for example, or with a multisided platform that connects patients and healthcare providers while maintaining patient healthcare records. Users may have strong preferences regarding how their data are used. Platforms often collect data that can affect the terms on which other agents are willing to trade with a given user. For example, employers might be less willing to consider a job applicant whose internet search history reveals an interest in treatments for behavioral health disorders. Or a consumer’s online purchase history might be used by an e-retailer to offer that consumer personalized prices. Both because of the direct economic effects, and because at least some people have an intrinsic (as opposed to instrumental) preference not to have certain information known by others, users can thus have strong preferences regarding the collection, dissemination, and use of their data. Users are unlikely to have similarly strong preferences about a multisided platform’s use of other inputs. The nature of user data has several broad implications. First, if user data are commercially valuable, lack substitutes, and are not shared across platforms, then the existence of significant increasing returns in collecting and utilizing user data can limit the number of viable competitors and create a “data barrier to entry,” especially when the accumulation of the necessary data takes considerable time.Footnote 9 The resulting levels of industry concentration raise the possibility that platforms will have substantial market power and that their conduct can raise antitrust concerns.Footnote 10 Indeed, some people are concerned that big data will create unlimited advantages of scale and scope that will lead to the domination of a wide swath of the economy by a handful of firms.Footnote 11 Second, to the extent that user data lack substitutes and are important to a platform’s success, the possibility arises that a platform may engage in exclusionary conduct that is intended to weaken rivals’ ability to compete by limiting their access to user data or making that access more costly.Footnote 12 The desire to raise rivals’ costs could motivate a wide range of conduct, including: refusing to sell data to rivals (or doing so only at elevated prices intended to raise rivals’ costs); entering into exclusive contracts with third-party data providers; or creating obstacles to user data portability (e.g., by storing data in proprietary formats or denying users control of data about them). The desire to weaken rivals could also motivate predatory behavior, whereby a platform seeks to prevent rival platforms from attracting users and sales that would otherwise generate data and strengthen the rivals’ abilities to compete. Third, when user data are an important asset, they can be a central part of analyzing the competitive effects and/or efficiencies of a merger. In many respects, the issues that are posed are standard ones for merger policy. However, user data raise at least three issues that are somewhat novel or may arise with particular force. First, to the extent that particular datasets lack substitutes, a platform might use a merger to obtain data in order either: (a) to use those data to compete more effectively; or (b) to preempt rivals from obtaining data that would allow them to compete more effectively. Second, the role of user data may suggest reasons to consider potential entry arguments more seriously and broadly than is typical. Third, because it may be possible to share user data and because the value of a given dataset could decay rapidly, there are issues in designing remedies that are specific to user data. Last, some of the possible uses of user data raise issues regarding price discrimination and user privacy. The latter set of issues is of particular interest. There are important questions regarding both: (a) the role of antitrust enforcement in promoting the use of efficient privacy protections; and (b) the effects that public policies that are intended to promote privacy have on platform competition and the realization of the goals of antitrust enforcement. In what follows, I address these implications for the antitrust treatment of specific conduct.Footnote 13 I begin by examining exclusionary behavior: conduct that raises rivals’ costs in Sect. 2, and predatory conduct in Sect. 3. I consider the implications of big data for merger analysis in Sect. 4. I then discuss price discrimination briefly in Sect. 5 before examining privacy issues in Sect. 6. Many people consider the use of antitrust enforcement to promote privacy to constitute an expansion of the goals of antitrust. In Sect. 7, I discuss a call to expand the objectives of antitrust even further to combat “fake news.” In a short final section, I address the question of whether antitrust is up to the task of protecting competition in markets that are populated by multisided platforms that make extensive use of big data about their users. I conclude that it is, but that there are areas where additional thinking would be particularly valuable.",15
54.0,4.0,Review of Industrial Organization,10 January 2019,https://link.springer.com/article/10.1007/s11151-019-09677-7,Burdens and Balancing in Multisided Markets: The First Principles Approach of Ohio v. American Express,June 2019,Joshua D. Wright,John M. Yun,,Male,Male,Unknown,Male,"Multisided platforms such as payment cards, ride-sharing apps, and online search engines are increasingly becoming an important part of antitrust analyses. Since the seminal work of Rochet and Tirole (2003, 2006) and Evans (2003), there is broad recognition that multisided platforms have features, such as cross-group effects, that set them apart from single-sided markets.Footnote 1 This realization has led to a split among courts, antitrust practitioners, and economists as to the best method to assess whether mergers or conduct that involve platforms result in the creation or maintenance of monopoly power and violate the antitrust laws. Monopoly power is necessarily evidenced by a reduction in market output and a corresponding increase in the market price. To that end, market definition and competitive effects analyses are antitrust’s analytical tools for identifying unlawful acquisitions or maintenance of monopoly power.Footnote 2 For platforms, however, there is a lack of consensus among scholars and practitioners on how to: (1) define relevant product markets; and (2) evaluate competitive harm.Footnote 3 In turn, this lack of consensus has created a lack of clarity for courts and competition authorities that seek guidance in this critical area of antitrust. That void set the table for the Supreme Court’s recent decision in Ohio v. American Express.Footnote 4 The Supreme Court was asked to decide, in broad terms, between two competing schools of thought on the appropriate antitrust analytical framework to apply to markets involving platforms. The first school of thought argues that platforms should be assessed in a manner similar to single-sided markets in that each side should, ultimately, be considered separately.Footnote 5 We label this the “separate markets” approach to market definition. Those adopting the separate markets approach would argue that payment card platforms, such as American Express, participate in two distinct product markets: (1) a market to cardholders; and (2) a market to merchants.Footnote 6 This first school typically extends the separation approach to competitive effects. We label this the “separate effects” approach, as it concludes that any effect that makes consumers worse off in any one of these markets—for example, an increase in price on either side of a platform—is generally sufficient to show antitrust harm regardless of effects in other markets.Footnote 7 The platform separatists typically assume that evidence of any such effect is a cognizable antitrust harm sufficient to dispel a plaintiff’s prima facie burden under the antitrust laws. The second school of thought argues that platforms are inherently defined by the interrelationships between their various sides and thus product market definitions should generally include all sides of a platform. At the very least, commentators advocating the “integration” approach would require courts and agencies explicitly to consider cross-group effects when defining markets.Footnote 8 Assuming cross-group effects are strong, we can label this as the “integrated market” approach. For instance, American Express would be considered a platform that operates in a single product market.Footnote 9 Given this integrated market definition, it follows naturally that a proper competitive effects analysis must include all sides of the platform, which we label as “integrated effects”. The separate and integrated approaches interact with antitrust law in important ways that shape analysis and dictate outcomes. It is critical for our purposes to distinguish harm to one group in a multisided market from “harm to competition” of the sort that the antitrust laws condemn. It is well understood that harm to a specific group of consumers does not necessarily constitute cognizable antitrust harm. Consumers might be harmed by conduct that does not create or maintain monopoly power. Price discrimination generally harms some groups of consumers but benefits others; yet, it is generally not the type of conduct that results in a restriction of market output and increase in market price.Footnote 10 Many decisions in competitive markets harm some group of consumers but benefit others.Footnote 11 The antitrust laws focus exclusively upon harm that arises from conduct that creates or maintains monopoly power—and it imposes the burden of proof on the plaintiff to demonstrate that the conduct at issue creates an “anticompetitive effect”.Footnote 12 The distinction between harm to a group of consumers and “competitive harm” or “anticompetitive effects” cognizable by the antitrust laws—that is, those caused by the creation or maintenance of monopoly power—is an important one for understanding the optimality of antitrust rules for governing the conduct of platforms. For example, the separate effects approach assigns to the plaintiff the burden of proof to show harm to competition in one market and assigns the defendant the burden of proof to demonstrate competitive effects in the other market. The latter effects are considered “efficiencies”—which are capable of rebutting anticompetitive effects in the first market—but sometimes are deemed non-cognizable “out-of-market” efficiencies. The implicit assumption is that any effect in any market in the platform context is fundamentally antitrust-relevant. In other words, the separate effects approach assumes evidence of harm to any group on any side of the platform is, by definition, the sort of “harm to competition” that is proscribed by the antitrust laws.Footnote 13 We believe this assumption is both incorrect as a matter of economics and leads to problematic antitrust analysis. By contrast, the integrated effects approach does not treat the other side of a platform as simply a potential consideration for an “efficiencies defense” that is capable of rebutting a showing of harm. The integrated effects approach rejects the “separate effects” assumption that harm to one group of consumers in the platform context equates to “harm to competition,” in the antitrust sense. Antitrust does not proscribe all conduct that harms consumers. The antitrust laws prohibit conduct that harms consumers because it harms competition. When a firm acquires monopoly power and is able to reduce market output and raise market prices, we see evidence of harm to competition. But what is the equivalent of this concept in the platform context? The integrated effects approach views effects on all sides of the platform as an essential component to understanding whether there is harm to competition in the first place.Footnote 14 The contrast between the separation and integration schools is clearly illustrated by the contrasting approaches taken by the district court and the Second Circuit in American Express, as well as the dueling amicus briefs from attorneys and economists on each side. The district court found that American Express operates in two separate product markets; consequently, it requires two separate competitive effects analyses. The Second Circuit reversed and found that American Express operates in one integrated product market and, consequently, there must be a single, integrated competitive effects analysis.Footnote 15 In fully affirming the Second Circuit, the Supreme Court endorsed the integrated effects approach. Specifically, the Supreme Court held that, generally, a single competitive effects analysis should be applied to the transaction platform as a whole rather than applying separate analyses to separate sides of the platform. The Supreme Court majority observes, “[C]redit-card networks are best understood as supplying only one product—the transaction—that is jointly consumed by a cardholder and a merchant. Accordingly, the two-sided market for credit-card transactions should be analyzed as a whole”.Footnote 16 Thus, “[i]n two-sided transaction markets, only one market should be defined”.Footnote 17 Moreover, “[e]vidence of a price increase on one side of a two-sided transaction platform cannot by itself demonstrate an anticompetitive exercise of market power”.Footnote 18 The last sentence clearly rejects the separate effects approach that equates any effect on any side of a platform as synonymous with the “competitive effects” with which the antitrust laws are concerned. In this paper, we argue that the Court in American Express got the analysis right and fundamental antitrust principles demand that competitive effects for platforms must always incorporate both sides given that cross-group effects inextricably bind one side to the other. Beyond the mere recognition of cross-group effects, the integrated-effects approach recognizes a simple, yet critical economic insight: the very definition of the exercise of monopoly power—the reduction of market-wide output and increase in the market priceFootnote 19—cannot be satisfied by evidence of a price effect on only one side of a given platform. Antitrust law requires that the plaintiff show conduct likely to harm competition—the acquisition or maintenance of monopoly power—in order to dispel its burden. To that end, evidence of an increase in price or other effects that makes one group worse off cannot meet that burden. The problem with such evidence is not that it is merely incomplete or only partially shows antitrust-relevant harm to competition. The flaw is that, without more, evidence of such an effect on one side of a platform is equally consistent with neutral or procompetitive conduct in the platform setting.Footnote 20 Adopting the integrated-effects approach to competitive effects renders the decision on product market less critical. To that end, we argue that both the separate-product markets and integrated-product market approaches are consistent with an integrated-effects approach.Footnote 21 Thus, however a court ultimately determines the relevant product market or markets, we find that there is no inconsistency as a matter of economics or the law in assessing the competitive effects on the platform as a whole. In Sect. 2, we further detail the two broad schools of thought on market definition and competitive effects for multisided platforms. In Sect. 3, we illustrate the superiority of the integrated effects approach and explain why that approach is more consistent with fundamental principles of antitrust law and economics. Section 4 demonstrates why, even if courts define separate product markets—such as for certain types of platforms that do not involve a direct transaction between the two sides, e.g., newspapers, they should adopt an integrated-effects approach. Section 5 concludes.",8
54.0,4.0,Review of Industrial Organization,11 February 2019,https://link.springer.com/article/10.1007/s11151-019-09688-4,The Misguided Assault on the Consumer Welfare Standard in the Age of Platform Markets,June 2019,A. Douglas Melamed,Nicolas Petit,,Unknown,Male,Unknown,Male,"We live an age of populism (Goldberg 2018). Though public opinion polls suggest moderate concern about corporate power and big business (Gallup 2018),Footnote 1 established political figures from the left and right are trying to revive an anti-monopoly agenda. They often appeal to the “romantic” tradition of the US antimonopoly movement in the gilded age (Langlois 2018). In this new conversation, “big is bad” rhetoric is no longer used to implicate big oil, big steel, or big finance. Oligopoly firms from all sectors are criticized for their contribution to high prices, low wages, income inequality, and slow productivity growth. And in information industries, consumer-facing platform-based firms—such as Facebook, Amazon, Netflix, and Google—are attacked for the additional reason that they are said to undermine the political process. Recently, respected news outlets—such as The Economist and the Financial Times—have called for government action to disperse platform-based firms’ economic and political power. The concern about corporate concentration is not just a byproduct of political alienation or scapegoating in a context of technological change. Studies by economists report a secular and broad-based increase in industry concentration and wealth inequality, though their magnitudes and interpretation are disputed (Shapiro 2017; White and Yang 2017).Footnote 2 Recent empirical works attribute observed increases in firms’ markups to a rise in market power and a decline in competition (Barkai 2016; De Loecker and Eeckhout 2017; Diez et al. 2018). Though the causes of alleged market power growth are diverse, rapid technological change is said to be a common factor that enables firms to create and preserve market power (De Loecker and Eeckhout 2017). In the political economy literature, some warn that the interaction of increased industry concentration and corporate power with politics is both a threat “to the functioning of the free market economy and to the economic prosperity it can generate, and a threat to democracy as well” (Zingales 2017). In information industries, a common perception is that “new business models developed by corporate social media redefine power relations”, including in labor markets or in the political system (Langlois and Elmer 2013). Concerns about industry concentration and corporate power in the twenty-first century naturally lead to discussions of antitrust policy. A recent study suggests that weak antitrust institutions and lax product market regulation explain the relatively higher degree of industry concentration and profits observed in the US compared to the EU (Guttiérez and Philippon 2018). Many scholars have been discussing ideas to make antitrust enforcement more aggressive (Baker et al. 2018). Some critics go further and argue that antitrust law is fundamentally flawed and that the “consumer welfare” (“CW”) standard on which contemporary antitrust is based prevents antitrust law from effectively addressing the new problems of industry concentration and corporate power (Steinbaum and Stucke 2018). Broadly speaking, the CW standard embodies the idea that antitrust laws promote economic welfare and are intended to protect economic agents from the predictable harms that are caused by improperly obtained market power.Footnote 3 But according to some critics, under CW-driven antitrust, the courts “rewrite doctrine not to protect consumers, but to preserve the freedom of dominant and other powerful corporations” (Vaheesan 2018). Antitrust law thus needs to be fundamentally reformed, these critics argue, perhaps by legislation, to replace the crabbed CW paradigm. Wu (2018) offers an alternative test: antitrust laws should ask whether conduct is “competition on the merits” or “rather, an effort to disable or subvert the competitive process”. According to the critics, the flaws of the CW standard are nowhere better seen than in digital markets in which matchmakers—such as Google, Amazon, Facebook, Uber, or Netflix—exploit large troves of personal data and gigantic computing power to convince distinct groups of users to interact through their platform by reducing friction (Evans and Schmalensee 2017) and improving convenience (Wu 2018). The economics of multi-sided platform markets in general—and of “cross-platform network externalities”, “winner takes all” effects, and “information goods” in particular—increase the returns to long-term growth and scale strategies, rather than short term revenue and profit maximization. Firms that operate in platform markets have incentives to support aggressive low-price strategies, leveraging across multiple lines of businesses, discrimination against digital complements, and defensive growth through predatory startup acquisitions and M&A (Khan 2017). In addition, as platform-based firms grow and tip towards monopoly, they become “massive employers” (Naidu et al. 2018) that obtain the ability and incentive to act as monopsonists in labor markets: reducing wages, increasing automation, and eventually hurting employees (Sunstein 2018). Nothing of this, it is said by some, can be remedied in a CW-driven antitrust system in which the liability standard prohibits only conduct that leads to output reduction and price increases. Moreover, the economic language of CW is blind to the political harms that are created by the accumulation of personal data by digital platforms, including its adverse effects on free speech and privacy, opportunistic data grabs by non-State actors, and distortions of the democratic process (Pasquale 2013). In this paper, we discuss whether the CW standard needs to be replaced or revised in order for antitrust law to deal effectively with the economic challenges of the platform economy. By platforms, we mean firms “whose core mission is to enable and to generate value from interactions between users” (Belleflamme and Peitz 2018). We argue that both the general and platform-specific assaults on the CW standard are misguided, that the CW standard is capable of addressing the economic concerns critics have raised, and that the proposed alternatives would make things worse—not better. Populist criticisms of antitrust policy are as wrong in today’s digital economy as they were in the past, when scholars criticized the dominant “efficiency” paradigm and contrasted it with the “competitive process”, “market access”, or “consumer choice” (Fox 2007). We do not discuss here calls for a broadened antitrust law to address current political and other non-economic problems because we believe non-economic problems should be dealt with by other laws that are designed for those specific purposes. As Turner (1987) explained 30 years ago, incorporating non-economic goals into antitrust law “would broaden antitrust’s proscriptions to cover business conduct that has no significant anticompetitive effects, would increase vagueness in the law, and would discourage conduct that promotes efficiencies not easily recognized or proved”. Nor do we address calls for multifaceted regulatory intervention beyond antitrust law to address perceived problems of concentrations of wealth or economic capture that are not manifest in market power: the ability to extract supra-competitive terms of trade from trading partners (Khan 2018a, b, c). We also leave aside the purely legal, and originalist, argument that CW takes antitrust away from Congress’ intent in 1890. Antitrust has long been understood to evolve over time through a common law-like process, enriched by the jurisprudence of courts under the impetus of private plaintiffs and the Federal Trade Commission (FTC) and Justice Department. As the Supreme Court explained in State Oil v Khan, “the general presumption that legislative changes should be left to Congress has less force with respect to the Sherman Act”.Footnote 4 This article is organized as follows: In part 2, we identify and describe the scholarly discussion on the CW standard in the age of platform markets. In part 3, we explain what we believe to be the fundamental flaw in the assault on CW: It is based on a misunderstanding of the CW standard. In part 4, we assess the main operational criticisms that are levelled at CW and explain why we think they are misplaced in general and with respect to modern platform businesses in the digital economy. In part 5 , we explain why the alternatives to CW that have been suggested by its critics would not be an improvement.",21
54.0,4.0,Review of Industrial Organization,24 February 2019,https://link.springer.com/article/10.1007/s11151-019-09681-x,"Attention Platforms, the Value of Content, and Public Policy",June 2019,David S. Evans,,,Male,Unknown,Unknown,Male,"Attention platforms supply content to consumers who spend time on their properties.Footnote 1 During that time, the platforms present ads on behalf of marketers.Footnote 2 Many online attention platforms also collect consumer data, which they use to target ads for marketers. Attention platforms include traditional ad-supported media businesses, such as a radio, television, and print—as well as online businesses, such as search and social. A variety of public policy issues that involve attention platforms—particularly online platforms—have emerged in recent years. These issues include privacy, hate speech, fake news, mergers, and monopolization.Footnote 3 This paper shows that two related aspects of attention platforms are important for the sound economic analysis of these issues: First, attention platforms generate valuable content. Even though people often do not pay for that content, we know from revealed preference that the content is valuable because people spend a considerable amount of their time—which has an opportunity cost—consuming it. Second, the demand for advertising and the supply of content are interdependent. A decrease in the demand for advertising reduces the returns to supplying content. While people may not like ads, they do like content. Accounting for the value of content and these positive feedbacks cannot determine optimal interventions by themselves. However, failure to account for these features of attention platforms can result in poorly designed or unnecessary interventions—as well as not making warranted interventions. This paper has seven sections including this introduction: Sect. 2 describes the basic economics of attention platforms. It shows that content helps solve a transaction-cost problem and facilitates efficient matching between advertisers and consumers. Section 3 documents the value of content that is supplied by platforms using the time-value approach. It shows that the value of ad-supported content in the U.S. is immense; the use of any plausible measure of the opportunity cost of time reaches that result. Section 4 shows that there are positive feedback effects between the advertiser and user sides of attention platforms, just as there are between the sides of other platforms. In the case of attention platforms, the positive-feedback effect is the result of the interdependence between advertising demand and content supply rather than positive indirect network effects. Section 5 illustrates the importance of these features in conducting cost-benefit calculations of policy interventions that involve privacy. Section 6 then considers the implications of these features for the antitrust analysis of attention platforms. Section 7 offers some concluding remarks.",13
55.0,1.0,Review of Industrial Organization,14 February 2019,https://link.springer.com/article/10.1007/s11151-019-09690-w,Introduction to the Special Issue in “Celebrating 25 Years of the EU Single Market”,August 2019,Christos Genakos,Michael Pollitt,,Male,Male,Unknown,Male,,
55.0,1.0,Review of Industrial Organization,01 March 2019,https://link.springer.com/article/10.1007/s11151-019-09698-2,Antitrust Enforcement in Europe in the Last 25 Years: Developments and Challenges,August 2019,Yannis Katsoulacos,Galateia Makri,Eleni Metsiou,Male,Unknown,Female,Mix,,
55.0,1.0,Review of Industrial Organization,19 February 2019,https://link.springer.com/article/10.1007/s11151-019-09687-5,Competition Policy in Banking in the European Union,August 2019,Joaquín Maudos,Xavier Vives,,Male,Male,Unknown,Male,"Competition in the European banking sector has evolved over the past 25 years with deregulation, technological change, and market integration as key drivers—starting with the single market initiative of 1992. The banking directives, the introduction of the euro in 1999, and the financial and debt crisis from 2007 until 2012 with its regulatory reform changes have punctuated this evolution. Changes in regulation have been present throughout the period, highlighting the importance of the Second Banking Directive (single banking license, home country control, mutual recognition, and freedom of cross-border services), the successive Basel agreements, and the Financial Services Action Plan (1999–2005). More recently, the pillars of the banking union—the Single Supervisory Mechanism and the Single Resolution Mechanism in 2014 and 2015, respectively—have been added. Competition was suppressed in banking after the Great Depression in the 1930s and up to 1970s, and competition policy was not enforced despite the inefficiencies that were induced by financial repression. In this period, central banks and regulators in a range of countries tolerated collusive agreements among banks and preferred to deal with a concentrated sector that was characterized by soft rivalry. This started to change when the idea that competition enhances efficiency took hold in the sector, and liberalization and deregulation ensued. Pushed by changes in information technology and competition, banking has been transformed from the traditional loan, deposit, and intermediation operations for maturity transformation to a more services-oriented industry with a higher market-based component. In the European Union (EU), the European Commission (EC) did not apply the two main competition articles of the Rome Treaty (85 and 86) to banking until the early 1980s (Züchner case). This was followed by a process of removal of banking exceptions to competition policy at the national level. The “1992” single market program did not transform banking into a competitive industryFootnote 1 because of the many frictions and market failures in the sector. Competition authorities were increasingly active; and up to the 2007–2009 crisis, market integration efforts were underway, and competition policy in banking was getting closer to being implemented as in any other sector of economic activity—but still with some special provisions. This “normalization” of competition policy in banking was truncated by the crisis. State aid distorted competition, and mergers were allowed without concern for market power. The aftermath of the crisis has posed a host of new questions on the relationship between competition and financial stability, as well as between competition policy and regulation in banking. In general, as in other jurisdictions, regulation has lagged behind the process of liberalization of the financial sector. Competition issues have been intertwined with market integration. The authorities had expressed concern about competition problems in the banking sector well before the 2007–2009 crisis and in connection with the banking liberalization process.Footnote 2 As we will show, financial integration has progressed slowly and unevenly across different activities and segments. The financial crisis has produced a negative effect on financial integration—particularly in the euro area, which has suffered more deeply from the effects of the sovereign debt crisis that started in 2010. The relevance of the analysis of competition policy in banking derives from the crucial importance of the sector in any modern economy, as we have witnessed from the consequences of the recent crisis. Competition is widely perceived as a source of efficiency; but in banking a trade-off with stability may appear. The aim of this paper is to assess the development of competition policy in banking in the European Union in the last 25 years. We focus on five aspects: M&A; cartels; state aid; “too big to fail” policies; and the regulatory architecture where the competition authority operates. We describe first the key trends in three areas, which are key when assessing competition policy: market concentration, financial integration, and market power. The introduction of the single market and of the euro allowed an advance of integration, which created conditions for more competition. However, the crisis and regulatory failures reversed previous advances—to the detriment of competition. The plan of this paper is as follows: Sect. 2 reviews the trends in concentration, market integration, and competition in the EU banking sector. Section 3 surveys the evolution of competition policy in banking as explained; and Sect. 4 concludes.",17
55.0,1.0,Review of Industrial Organization,26 February 2019,https://link.springer.com/article/10.1007/s11151-019-09686-6,The European Framework for Regulating Telecommunications: A 25-year Appraisal,August 2019,Martin Cave,Christos Genakos,Tommaso Valletti,Male,Male,Male,Male,"Few sectors have undergone so rapid a transformation in the past 25 years as telecommunications. In 1993, the sector provided national and international voice services, leased lines, and little else. Mobile communications was still in its infancy, with penetration rates that could be counted on the fingers of one hand. Data traffic transmitted via the internet was emerging at that time from the rarefied US environments of the Defence Advanced Research Projects Agency (DARPA) and the National Science Foundation Network (NSFNET) and becoming both public and commercial—aided by the development of the World Wide Web. Social media were not to follow for nearly another decade. In those 25 years, analogue transmission in the telecommunications sector has long given way to digital; but the sector’s role as an enabler of the digital transformation of the economy and society is just beginning, with numerous predictions that almost every act of consumption and production—in both the private and the public sector, as well as of social intercourse—will be transformed by the new cluster of information and communication general purpose technologies. Hence, there is no doubt that telecommunications is a sector of major strategic importance. By the second half of the twentieth century, in most of the world including Europe, telecommunications were characterized by both monopoly and public ownership: two characteristics that are often associated with certain benefits but also with a substantial dose of inertia and inefficiency. Thus, unlike information technology, telecommunications had to liberate itself from these latter tendencies through re-invention, while remaining under a form of indirect public control via regulation. In this paper we summarize how this process has unfolded in Europe over the last 25 years and discuss how the regulatory regime has adapted, and, in particular, how it has in recent years shepherded the sector towards significant changes in market structure. Because terrestrial local access telecommunication networks are locationally specific, the opportunities for international trade and rivalry in telecommunications are limited: A network in Paris is no substitute for one in London; by contrast, electricity generated in France can be sold in the UK. At the same time, an operator that owns core or long-distance networks in adjacent countries can reduce costs by reconfiguring them in a less costly fashion that ignores national boundaries. The impact of the European single market has thus been felt chiefly through the free movement of capital and in the form of a uniform regulatory regime that applies in all Member States. It is the latter aspect which is considered here. In Sect. 2 we note some regulatory landmarks in the process and mention some outcome changes. Section 3 describes how fixed telecommunications networks in Europe are emerging from a starting point of monopoly to a state that more closely approximates oligopoly. Section 4 evaluates Europe’s success in achieving and maintaining effective competition in the mobile sector. Section 5 concludes.",20
55.0,1.0,Review of Industrial Organization,10 February 2019,https://link.springer.com/article/10.1007/s11151-019-09682-w,The European Single Market in Electricity: An Economic Assessment,August 2019,Michael G. Pollitt,,,Male,Unknown,Unknown,Male,"As early as 1988 the European CommissionFootnote 1 began considering how the Single European Act of 1986—which paved the way for the European Single Market—might be applied in the energy sector, specifically to electricity and gas supply. This began a long process of opening national wholesale and retail electricity and gas markets to trade and competition across the single market area. What has happened to national electricity markets in Europe since then is a fascinating economic story and is a textbook case study in how the process of European market integration has worked and the difficulties to be overcome in achieving such integration. Globally electricity is not a heavily traded good. Of all gross electricity production only around 3% was exported across national borders in 2015, and most of this trade occurred in Europe (with a significant share of the rest being between the US and Canada).Footnote 2 This makes electricity much less heavily traded than oil, gas, and coal. While electricity trading across European borders is a key part of the single market in electricity story, it is by no means all of it. National electricity systems and policies have been significantly altered by the requirements of the single market; and indeed these effects have been at least as important as what has happened to cross-border trading of wholesale electricity. Here the requirement for national policies to adhere to the requirements of European directives have affected the organization of the sector and its regulation. Combined with other EU energy policies—towards carbon trading (which covers the electricity sector); 2020 renewable electricity and energy targets; and energy security and energy efficiency—national electricity sectors have gone through profound changes. The primary legislative means by which the EU has brought about this change is through three single electricity market directives in 1996 (96/92/EC), 2003 (03/54/EC) and 2009 (09/72/EC): These directives have required member states (and Norway as a non-EU member of the single electricity marketFootnote 3) to meet certain requirements in their national legislation, as well as setting out pan-European policy. The electricity sector comprises of a number of elements, each of which has been affected by the directives: generation (power plants); transmission (high voltage wires); distribution (lower voltage wires); retail suppliers (who bill final customers); customers (who might choose suppliers); the degree of unbundling (both horizontal and vertical between generation, transmission, distribution, retail); and cross-border trading over interconnectors.Footnote 4 Prior to the 1996 directive a few single market countries—such as Norway, Sweden, and the UK—had liberalized their electricity sectors to create wholesale power markets and introduced competition in the early 1990s. However, across most of the EU, generation, transmission, distribution, and retail supply were largely in the hands of incumbent domestic monopolists (such as EdF in France, or ENEL in Italy). Horizontal bundling was the norm, with no competition in each segment of the industry. Often incumbent monopolists ranged across generation, transmission, distribution, and retail; they exhibited large degrees of vertical bundling of assets. Customers of these monopolists had no choice of supplier, no matter how large the customers were. Cross-border trade was controlled by bilateral monopolists on both sides of the border, which were able to set cross-border tariffs and allocate cross-border transfer capacity. The only example of cross-border trading on a market basis was between Norway, Sweden, and later Finland, within a market arrangement called NordPool. The directives changed this radically by establishing a process of opening the market to competition across the EU. Essentially this process forced all member countries both to follow the example of the early market-reforming states nationally and to promote a genuine cross-border market. The 1996 directive envisaged that by the end of 1999 all generation would be either subject to free entry into a wholesale market arrangement or competitively procured by a single buyer under a tendering procedure; all access to the transmission and distribution system would be subject to negotiated or regulated third party (RTP) access on common terms, in the absence of a single buyer; retail suppliers could freely compete with one another to acquire customers; the largest customers—representing about 1/3 of demand—could choose their retail supplier; all remaining vertically bundled transmission and distribution businesses would have to produce separate accounts (so called ‘accounting unbundling’); and all cross-border trade would be subject to at least negotiated third party access. The 1996 directive offered a number of options that countries could take—such as the choice of negotiated or regulated third-party access—as a way of persuading initially reluctant reformers (such as France) to begin their reform process. Individual EU member states (MSs) were free to adopt the more competitive arrangements more quickly and indeed to go further than the minimum that was required by the directive: such as giving all customers free choice of retail supplier, which happened in the UK in 1999. The 2003 directive (03/54/EC) envisaged that by the end of 2007Footnote 5: all generation would be subject to free entry into a wholesale market arrangement; all access to the transmission and distribution system would be subject to regulated third-party access on common terms; retail suppliers could freely compete with one another to acquire customers; all customers, including households of any size, could choose their retail supplier; all remaining vertically bundled transmission and distribution businesses would have to be held in legally separate business units (legal unbundling); and all cross-border trade would be subject to regulated third-party access. The 2003 directive extended the scope of wholesale and retail competition and was a way of forcing slowly reforming MSs to go further in an environment where leading countries were already completing their own internal market in electricity (see Jamasb and Pollitt 2005). The 2003 directive also required MSs to have a national electricity regulator with a degree of independence from government responsible for regulating the charges of the incumbent transmission and distribution companies and ensuring non-discriminatory network access. A very visible effect of the directives (and of the Single Market more generally) was that it unleashed a wave of mergers across the EU of electricity and gas companies. EdF,  RWE, E.ON, Iberdrola, ENEL, and Vattenfall expanded substantially outside their home markets in both generation and retail. In the UK, for instance, EdF, RWE, and E.ON became the three largest generators and three of the largest retailers. By the mid-2000s many of the smaller European generators and retailers had been taken over by major pan-European companies. What followed the enforcement of the 2003 directive was a growing realization that while much progress had been made in reforming national electricity markets and the internationalization of ownership, very little progress had been made in creating a genuine single market in electricity with wholesale markets extending across borders. In 2004, the European Commission began to support what became known as the ‘target model’,Footnote 6 which envisaged the gradual integration of national electricity markets, through a system of market coupling, whereby national markets would be merged or coordinated. Prior to market coupling a trader that wished to sell electricity between two markets would need to buy the power in one market, sell the power in another, and separately procure the transfer capacity on the interconnector between them. This was a costly and inaccurate process—especially if trading periods were not coordinated across the three transactions. Under market coupling, available transfer capacity is declared to the markets, and power can be bought and sold between the two markets—subject to one market-clearing algorithm. If there is enough transfer capacity, the prices in the two markets will be the same; if there is a transmission capacity constraint, power should be seen to flow from the low-price market to high-price market. The period since 2004 has seen a large increase in the degree of coordination between day-ahead wholesale markets as a result of the extension of individual markets and the coupling between markets. Progress on market design has been assisted by pan-European competition policy in electricity. MSs have traditionally been somewhat reluctant to increase imports of electricity, so as to protect their domestic generators (from increased competition) and partly for reasons of energy security (by making it easier for national system operators to manage their system by simply adjusting national supply and demand). This has led to allegations that transfer capacity was not being allocated efficiently at the border and that available capacity was not being offered to the market. In response to this and other concerns about the slow progress in the creation of single market, the European Commission began a major energy sector competition inquiry in 2005. The inquiry reported in 2007 (European Commission 2007) and spurred competition enforcement action and the third electricity single market directive in 2009. This directive significantly strengthened the unbundling requirements on transmission businesses and created a preferred model of ownership unbundling. It also established a pan-European regulatory agency for electricity and gas (Agency for the Cooperation of Energy Regulators-ACER).Footnote 7 This agency was charged with dispute regulation between national regulators and the monitoring of cross-border competition. Since then there has been a significant move towards the unbundling of German transmission assets, which has helped to promote cross-border trading and the efficient allocation of transmission capacity in central Europe (which will be discussed in the next section). Two other sets of policies also affect the single electricity market: Several incidents have highlighted the vulnerability of interconnected national electricity markets. In 2003, a series of blackouts across the globe drew attention to the need for increased coordination between system operators across different interconnected systems. As a result, the European Commission now lists as one of its policies for energy security an increase in national electricity interconnection from its current average level of 8% of peak capacity to 15% by 2030 (having had a target of 10% by 2020).Footnote 8 To promote this policy the Commission has been actively promoting projects of common interest (PCIs) that increase transmission capacity between nations, in particular with respect to Baltic (Lithuania, Latvia, and Estonia) and Iberic (Spain—and by implication Portugal—and France) isolation.Footnote 9 In some areas, such as across the North Sea, there has been a significant increase in transmission capacity. Increased interconnection for security reasons promotes wholesale market integration and expansion. The renewables and decarbonisation agenda are having a significant impact on the electricity industry. The 2001 renewable electricity directive (2001/77/EC) and the 2009 renewable energy directive (2009/28/EC) have together massively increased the requirement for electricity generation to come from renewable electricity sources—such as bio-energy, wind, and solar. These have been heavily subsidized by national governments and have significantly reduced the amount of generation that is being competitively added on the basis of predicted future wholesale market prices. Meanwhile the introduction of the EU Emissions Trading Scheme (EU ETS) in 2005—which included electricity within a traded carbon allowance system—has seen significant incentives at different times to favour gas-fired power generation over coal fired power generation (and sometimes vice versa).Footnote 10 The overall context for current energy and climate policy to 2020 is the 20–20–20 targets for 2020 that were agreed upon in 2007 and were enacted in 2009: a 20% reduction in CO2 (from 1990 levels); 20% of gross final energy consumption to come from renewable energyFootnote 11; and a 20% increase in energy efficiency (energy demand relative to levels projected around 2005). The European Union agreed in 2014 to set a 40–27–30 set of targets for 2030 (more precisely: − 40% greenhouse gas (GHG) emissions; > 27% renewable energy; and > 30% increase in energy efficiency), with primacy given to the 40% reduction in greenhouse gas emissions.Footnote 12 The EU wide targets for CO2e reduction and renewables share are disaggregated into national-level targets (some greater or less than the aggregate target), whereas all member states are expected to meet the energy efficiency target. These targets are themselves in the process of further tightening at the beginning of 2019.Footnote 13 As noted in Pollitt (2009), much of the initial implementation of these policies to meet energy and climate targets across the EU was ‘patchy’, with big differences between the enthusiastic reformers and lagging states. A 4th Energy Package was tabled by the European Commission on 30th November 2016: ‘Clean Energy for All Europeans’. These measures are intended to lead to a new Electricity Directive and include three main goals: ‘Putting energy efficiency first; Achieving global leadership in Renewable energies; and Providing a fair deal for consumers.’Footnote 14",54
55.0,1.0,Review of Industrial Organization,01 March 2019,https://link.springer.com/article/10.1007/s11151-019-09697-3,European Natural Gas Markets: Taking Stock and Looking Forward,August 2019,Chi Kong Chyong,,,,Unknown,Unknown,Mix,,
55.0,1.0,Review of Industrial Organization,20 February 2019,https://link.springer.com/article/10.1007/s11151-019-09694-6,The Single Market in Pharmaceuticals,August 2019,Margaret K. Kyle,,,Female,Unknown,Unknown,Female,"This paper examines the state of the single market in the European Union (EU) for pharmaceuticals. As with other products, the EU has adopted a number of institutions and policies to encourage integration and the free movement of goods. Pharmaceuticals differ from most other products, however, in several important respects. First, they are highly regulated. Second, their consumption is influenced by agency problems. Doctors and pharmacists act as gatekeepers, and insurance introduces moral hazard. Third, the extent of state involvement in their purchase is significant—including influence over prices. Finally, the reliance on patents and other forms of intellectual property is greater than in most other sectors. This research draws on data of marketing authorizations, patenting, and sales to describe how the European pharmaceutical market has evolved since the establishment of the European Union. I show that over time, member states are more similar in the availability of products, as well as in the patents that protect them. New pharmaceuticals are generally available sooner. Regulatory harmonization and the centralized approval procedure appear to have played an important role. However, significant differences persist in the availability of older products and of generic versions of older drugs, which benefit less from EU institutions. Similarly, the patent landscape has become more similar across member states. European institutions such as the European Patent Office (EPO) have reduced the cost of obtaining protection in multiple countries. Greater similarity of IP contributes to the development of a single market, although the effects are more evident for recent products that still benefit from patent protection. However, pricing of pharmaceuticals remains a national competence: Member states are free to control drug prices within their borders. Price variation remains, despite the potential for arbitrage of differences through parallel trade. For example, the median German price is 43% higher than in Greece, while Bulgaria has median prices that are 67% of the German level. While the early 2000s saw some convergence in prices, the gap has not narrowed in recent years. This may be desirable from a social welfare standpoint, however, if it facilitates access to new products in poorer member states.",1
55.0,1.0,Review of Industrial Organization,27 June 2019,https://link.springer.com/article/10.1007/s11151-019-09711-8,Occupational Licensing in the EU: Protecting Consumers or Limiting Competition?,August 2019,Mario Pagliero,,,Male,Unknown,Unknown,Male,"Occupational licensing regulations require workers in many different professions to obtain a special permit to work legally in their chosen field. Examples include medical doctors, nurses, lawyers, teachers, engineers, hairdressers, and also smaller specialized professions such as skiing instructors, alpine guides, and farriers. In the EU, 22% of workers are subject to occupational licensing (Koumenta and Pagliero 2016). Although professional associations argue that the only goal of professional licensing is to protect the public, economists have long held two opposing views on the subject: The first view is in the category of public interest theory. Building on the work of Akerlof (1970), Leland (1979) showed that professional licensing might serve to remedy market failure that follows from asymmetric information. Capture theory—which was pioneered by Stigler (1971)—argues instead that “regulation is acquired by the industry and is designed and operated primarily for its benefit”. Hence, occupational regulation may reduce competition: for example, by reducing entry. Occupational licensing is particularly common in the services sector (health and social work, public administration, education, transportation and communication industries), but less so in agriculture and manufacturing (Koumenta and Pagliero 2016). Since the service sector accounts for a large share of employment in the EU, reform of professional licensing regulations could have a significant impact on economic growth in the European Union. This paper reviews the recent literature and policy developments since the last comprehensive review on the subject (Kleiner 2000), with a focus on the European Union. The paper is organized as follows: Sect. 2 describes the prevalence of licensing in the EU. Section 3 illustrates the importance of licensing for economic policy in the EU. Section 4 reviews its importance for wage determination, mobility, and the quality of services that are provided. Section 5 introduces the growing literature that investigates how licensing boards behave and interact. Finally, Sect. 6 argues that occupational regulation is important for researchers in industrial organization and discusses the applicability of competition policy to professional associations.",4
55.0,1.0,Review of Industrial Organization,09 February 2019,https://link.springer.com/article/10.1007/s11151-019-09689-3,Algorithmic Pricing What Implications for Competition Policy?,August 2019,Emilio Calvano,Giacomo Calzolari,Sergio Pastorello,Male,Male,Male,Male,"The geographical fragmentation of markets has dramatically fallen in Europe in the last decades. The European Common Market has removed artificial barriers to the free movement of goods, technological progress has significantly decreased transportation costs, and the advent of electronic commerce has greatly enlarged the set of potential suppliers to which a typical buyer has access. As a result, for many types of goods Europe is today a single geographical market. This process has brought about substantial benefits but has also created new challenges. In this paper, we focus on one side-effect of electronic commerce: the diffusion of algorithmic pricing. Firms’ pricing decisions are increasingly delegated to software programs that incorporate the latest developments of artificial intelligence. While pricing algorithms have been used by airline companies for decades,Footnote 1 only more recently have they been adopted in other sectors, such as financial markets and the hotel and insurance industries. Still more recently, the diffusion of Algorithmic Pricing (AP) has extended beyond these domains and is now much more widespread. For example, Chen et al. (2016) document that a significant fraction of sellers in a large online marketplace (Amazon US), where many different types of goods are traded, adopted algorithmic pricing in 2015.Footnote 2 AP does not seem to be a fad. As increasing numbers of transactions take place in digital environments, and the software technology further improves, it is likely that the demand for AP will keep increasing. And the supply of AP is likely to keep up with the demand. AP has become affordable even for small businesses, as off-the-shelf machine learning solutions and computing capability are now being supplied by tech giants such as Amazon, Google and Microsoft. More entry in this new industry may well occur in the future. Recent developments—such as the Distributed Digital Ledgers and the Internet of Things—may further fuel the growth in the demand for and supply of AP. The diffusion of AP raises various concerns for competition policy and regulation. One concern is that AP tremendously enlarges the scope for price discrimination. While the competitive effects of price discrimination are generally uncertain, with AP prices may be conditioned not only on relatively innocent information such as the timing of the purchase or the firm’s residual capacity, but also on the buyer’s entire past purchasing history. Such conditional pricing may lead to consumer poaching; or it could lead to the use of exclusivity or market-share discounts –both of which may have anti-competitive effects. Furthermore, the commercial exploitation of information that should arguably remain private may raise issues of privacy.Footnote 3 Another source of concern is the possibility that AP may facilitate collusion: this concern has been repeatedly voiced in recent years, both in the popular pressFootnote 4 and in the academic literature. In particular, Ezrachi and Stucke (2015) and Mehra (2016) were the first in the law literature to point explicitly to the risk that AP may inhibit competition and effectively sustain collusion with no need of human intervention. The issue is now on the radars of various antitrust agencies, such as the US Federal Trade Commission and the European Commission.Footnote 5 These concerns may seem somewhat speculative as, so far, the evidence of digital cartels seems limited. To the best of our knowledge, the only antitrust case that involved algorithmic pricing was the US’s and UK’s agencies successful challenge of a pricing software that was allegedly designed to coordinate the price of posters by multiple online sellers.Footnote 6 Commentators have also pointed to a few specific examples: such as software programs that appear to have escalated the price of a second-hand book to the millions of dollarsFootnote 7; or, more important, the use of the same pricing algorithm for car parts by several manufacturers, which allegedly resulted in billions of extra profits in the European market.Footnote 8 However, we have not seen much real action on the antitrust front so far. In the light of this evidence—or lack thereof—the optimistic view of AP is that these programs are not really more conducive to collusive outcomes than is human pricing. According to this view, the concerns mentioned above are exaggerated. The pessimistic view, in contrast, maintains that the anticompetitive potential of AP has not fully materialized yet, as AP is still in its infancy. Furthermore, pessimists argue that antitrust authorities may have refrained from intervening because they are not well equipped to cope with this new form of collusion. In this paper, we contribute to this debate, which so far has involved for the most part law scholars and, especially, computer scientists.Footnote 9 Bringing an economic perspective into the debate may be useful, as AP raises a number of important economic questions. Can “intelligent” pricing algorithms learn to collude? Is AP collusion any different from collusion among humans? Is AP conducive to collusion more often than what humans could do? If the answers to these questions are affirmative, how can we detect algorithmic collusion? What are the appropriate new standards for competition policy? In the next sections, we shall briefly address these questions. Since economic research on AP is still in its infancy, we are not in a position to provide answers. Our aim is, more modestly, to clarify the terms of the debate.",43
55.0,2.0,Review of Industrial Organization,03 September 2018,https://link.springer.com/article/10.1007/s11151-018-9659-3,Radical Innovations: The Role of Knowledge Acquisition from Abroad,September 2019,Damián Tojeiro-Rivero,Rosina Moreno,Erika Raquel Badillo,Male,Female,Female,Mix,,
55.0,2.0,Review of Industrial Organization,18 September 2018,https://link.springer.com/article/10.1007/s11151-018-9660-x,Gasoline Pricing in the Country and the City,September 2019,David P. Byrne,,,Male,Unknown,Unknown,Male,"Prices rise like rockets and fall like feathers. Bacon (1991) coined this phrase to describe his finding that retail gasoline prices quickly adjusted to rising costs, but prices sluggishly adjusted to falling costs. While many industries exhibit such pricing asymmetry or asymmetric pricing (Peltzman 2000), particular attention has been paid to gasoline by the media and policymakers. This is because gasoline prices are highly visible to consumers and have a large impact on their weekly expenditures. For instance, in 2014 pricing asymmetry was at the forefront of public debate as retail prices fell slowly despite rapidly falling crude oil prices.Footnote 1 Given this public interest, it is not surprising that there is a wealth of research on pricing asymmetry. A number of papers have documented asymmetry with the use of data on gasoline prices and costs at the national level (Borenstein et al. 1997; Bachmeier and Griffin 2003), state-level (Deltas 2008), from individual cities (Eckert 2002; Verlinda 2008; Balmaceda and Soruco 2008; Lewis 2011), and more recently with panel data from many cities (Lewis and Noel 2011). Identifying the underlying mechanism has proven elusive. However, we know that the degree of pricing asymmetry is larger in markets where firms have more market power (Deltas 2008; Verlinda 2008). To the extent that market power is linked to collusion, such findings raise antitrust concerns. Indeed, Clark and Houde (2013) present evidence from a gasoline cartel that asymmetric pricing is directly linked to collusive behavior. This paper extends the literature by providing estimates of gasoline pricing asymmetry for rural markets. My analysis uses daily station-level price data from a uniquely diverse set of markets from Ontario, Canada. The data permit a unique contrast between concentrated rural markets and less concentrated urban markets. In this way, this paper complements previous research that focuses on cities. By comparing gasoline pricing in rural and urban markets, I shed new light on the relationship between pricing asymmetry and market power. After describing the industry and dataset in Sect. 2, I develop an analysis of asymmetric pricing in Sect. 3. Rural gasoline stations exhibit substantial pricing asymmetries. While 45% of a typical positive cost shock is passed through to retail prices in the week that the shock is realized, only 21% of an equal magnitude negative shock is passed through. In contrast, I find that urban stations pass through 100% of both positive and negative cost shocks within a week. I further study the determinants of asymmetry across rural and urban gasoline stations. Various measures of local market power—including local market concentration and spatial differentiation—are associated with asymmetric pricing. Moreover, I find that vertically integrated major oil companies and independent retailers leverage their local market power in different ways to engage in asymmetric pricing. Finally, I highlight the importance of proximity to wholesale supply in explaining asymmetry and discuss the role that inventory-based pricing potentially plays in generating these patterns. Section 4 summarizes and concludes. As with previous studies, the data are insufficient for identifying the underlying mechanisms for pricing asymmetry in rural markets. However, I discuss various aspects of rural market structure that, in light of my results, make collusion a first-order concern.",7
55.0,2.0,Review of Industrial Organization,30 October 2018,https://link.springer.com/article/10.1007/s11151-018-9670-8,When Efficient Firms Flock Together: Merger Incentives Under Yardstick Competition,September 2019,Jonas Teusch,,,Male,Unknown,Unknown,Male,"Yardstick competition is a regulatory tool in which a firm’s performance is evaluated relative to similar firms—firms are benchmarked against their peers (Shleifer 1985). It is widely applied in order to regulate industries that exhibit natural monopoly characteristics, as shown in Table 1.Footnote 1 Where yardstick competition is applied, firms frequently merge (e.g., Dijkstra et al. 2017). Against this background, it is important to understand whether and when merger incentives under yardstick competition are aligned with social welfare. Even though applied researchers warn that yardstick mergers may be socially harmful (Bitran and Serra 1994; Jamasb and Pollitt 2003), the existing theoretical literature generally does not consider the possibility that firms strategically manipulate peers to their advantage—with the exception of the extreme case of a merger-to-monopoly (Auriol and Laffont 1992) and strategic behaviour that is motivated by collusive considerations (Tangerås 2002; Dijkstra et al. 2017). The theoretical model that is developed in this paper shows that even in a setting where firms are many and collusion is not an option, yardstick competition does not necessarily incentivise firms to pursue cost-reducing mergers. Specifically, peer effects can make efficiency-decreasing mergers firm-level rational. Perverse incentives are possible because mergers that involve relatively efficient peers further improve the insiders’ competitive position, since such transactions remove firms with costs that are below their peer group from the yardstick and thereby increase the applicable yardstick for the merging parties. The results suggest that regulators ought to pay more attention to mergers in industries that are subject to yardstick competition. In competitive markets, the welfare trade-offs of mergers and acquisitions are generally well understood, and transactions are routinely scrutinised by competition authorities (Motta 2004). By contrast, in industries that are regulated to yardstick competition, the implications of horizontal mergers are rarely assessed.Footnote 2 The recently proposed asset swap between the two largest German utilities—E.ON and RWE—is a case in point. Despite the fact that E.ON will control about a third of Germany’s electricity distribution business after the transaction, and the distribution system operators are regulated by yardstick competition, insiders involved in the transaction do not expect competition authorities to intervene because “the bulk of the deal affects regulated assets”.Footnote 3 Even the head of the German regulatory authority was quoted as saying that network ownership was irrelevant.Footnote 4",2
55.0,2.0,Review of Industrial Organization,16 November 2018,https://link.springer.com/article/10.1007/s11151-018-9673-5,Bank Competition and Financial Inclusion: Evidence from Mexico,September 2019,Ana Georgina Marín,Rainer Schwabe,,Female,Male,Unknown,Mix,,
55.0,2.0,Review of Industrial Organization,02 January 2019,https://link.springer.com/article/10.1007/s11151-018-09675-1,Patent Licensing and Technological Catch-Up in a Heterogeneous Duopoly,September 2019,Bruno D. Badia,,,Male,Unknown,Unknown,Male,"A large fraction of the literature on the theory of patent licensing—following the seminal contributions of Kamien and Tauman (1984, 1986), and Katz and Shapiro (1986)—focuses on the interaction between the patentee (i.e. the owner of a patent) of a cost-reducing innovation and potential licensees that are homogeneous firms in a certain industry. Evidence, however, suggests that in practice firms are often different. Scherer and Ross (1990, p. 83), for instance, reports that the market shares of leading firms in American manufacturing industries lie between 1.1 to 68.7%, which reveals a wide range of industry configurations, from more homogeneous to more heterogeneous.Footnote 1 For some applications homogeneity is therefore an unnecessary rigid assumption. This paper considers a model in which potential licensees are heterogeneous duopolists that produce with different costs. An outside patentee owns a technology that reduces the cost of an adopting firm by an idiosyncratic magnitude and seeks to maximize licensing revenues. The patentee and the firms are assumed to play the auction-licensing game that was introduced by Katz and Shapiro (1986) and described in great detail by Kamien (1992). In this game the patentee decides how many licenses to put for sale; firms bid competitively for the license(s) and, in the post-licensing stage, choose output simultaneously. The question addressed is whether an inefficient firm can, through licensing, catch up to its efficient rival. Even though the answer is affirmative, the conditions for catch-up are biased against the high-cost competitor: it is not sufficient that the technology reverses the efficiency rank of the firms. Because in the model high cost corresponds to small market share, the conclusion hints at the importance of R&D for the survival of relatively small firms and may, therefore, be part of an explanation for the phenomenon that is reported in Kamien and Schwartz (1982, p. 90) that within concentrated industries these firms engage proportionately more in R&D. The results reported here are complementary to those of Gilbert and Newbery (1982) who show that the incentives that are presented to an incumbent monopolist to invest in R&D and preemptively patent the resulting innovation are usually greater than the corresponding incentives that face a potential entrant firm. The persistence of monopoly power in their framework thus derives from the winner-takes-all character of patent races.Footnote 2 In the present paper both firms can simultaneously adopt the innovation—the “winner” does not necessarily take all. Still the ability of the leading firm to maintain its market power is, as noted above, sizable. 
Stamatopoulos and Tauman (2009) and Rtischev (2009) have also studied the problem of an outside patentee that faces heterogeneous duopolists.Footnote 3 The former paper compares the profitability of fixed fee to that of auction licensing and shows that fixed fee may be a superior licensing mechanism; with homogeneous duopolists auction is known to be superior (Kamien et al. 1992). Rtischev (2009) assumes linear downstream market demand and studies the licensing of two types of innovations: one that allows the inefficient rival to diminish the cost gap; and another that allows both firms to produce with a cost that is lower than that of the efficient duopolist. In the present paper linearity is replaced with log-concavity and more general innovations are considered. In particular, it is possible in the present model for the ex ante inefficient firm to become more efficient than its rival following adoption of the innovation by both firms. It turns out that even in this case catch-up may not occur. The next section contains the description of the model, which is then analyzed in Sect. 3. The analysis is divided into two cases, which are defined by the effect of the innovation on firms’ costs. Each case is studied in a separate subsection which also contains discussion of the respective results. Section 4 considers alternative assumptions: royalty as opposed to auction licensing; drastic as opposed to non-drastic innovations; and differentiated products and price competition as opposed to homogeneous-good Cournot competition in the downstream market. The “Appendix” section presents the proof of an important auxiliary result.",3
55.0,2.0,Review of Industrial Organization,27 August 2018,https://link.springer.com/article/10.1007/s11151-018-9656-6,Competitive Pressure and Diversification into Green R&D,September 2019,Tobias Stucki,Martin Woerter,,Male,Male,Unknown,Male,"In order to reduce greenhouse gas emissions a de-carbonization of the energy sector is required, which can only be achieved in time by developing and deploying green innovations (IPCC 2014). The available literature emphasizes the importance of policies for green innovations, but largely ignores market forces that might also drive the decision of firms to direct their technological activities to green markets. We try to fill this research gap with the investigation at hand. Controlling for policies and important firm characteristics, we identify the consequences of product market competition in the traditional market of a firm for its diversification into green R&D activities. More concretely, we identify whether competitive pressure—measured as (a) quick obsolescence of products, (b) unpredictable technological developments, and (c) easy substitution of products—drives firms to enter traditional R&D (H1), to enter green R&D (H2), and whether these effects differ between traditional and green R&D (H3; see Fig. 1). Competition and diversification into green R&D For policy-makers this is important information, since measures might be ineffective or very costly if they battle strong market forces, and we know from the literature that policy activities should focus on markets with less resistance primarily (see Popp et al. 2011). Moreover, it is of utmost importance for researchers to understand why firms diversify into green R&D even if it proves to be less profitable than traditional innovation (see Marin 2014; Soltmann et al. 2015; Van Leeuwen and Mohnen 2017). Accordingly, it is important to analyze new, untested drivers of green product innovation. Most related to our work, there are some studies that analyzed the relevance of market structure for green innovation at the aggregated level based on very general proxies for competitive pressure (Brunnermeier and Cohen 2003; Jamasb and Pollitt 2011; Nesta et al. 2014).Footnote 1 We choose a more differentiated approach: First, we use firm-level data for Austria, Germany, and Switzerland to analyze the effect of competitive pressure on green R&D activity, which allows us to capture heterogeneity across firms. In our empirical setting, green R&D refers to: (a) R&D activities for the generation of energy-saving technology for end-users in one of the following areas: production, ICT, transport, or building technology; and (b) R&D activities for the generation of technology for the use of energy from renewable sources, such as solar systems or wind or hydroelectric power plants. Second, instead of using a single competition measure, we consider different aspects of market characteristics—(1) quick obsolescence of products; (2) unpredictable technological development; and (3) easy substitution of products—which is important, as market power cannot be measured directly (Baldwin and Scott 2013; Beneito et al. 2015; Tang 2006; Vives 2008). Third, in order to better understand what we can learn from the traditional innovation literature, we directly contrast the effect of competitive pressure for green R&D and for traditional R&D.",10
55.0,3.0,Review of Industrial Organization,12 July 2019,https://link.springer.com/article/10.1007/s11151-019-09715-4,Economies as an Antitrust Defense: The Welfare Tradeoffs—Introduction to the Special Issue,November 2019,Stephen Martin,,,Male,Unknown,Unknown,Male,"The origin of the paperFootnote 1 that is the occasion for this special issue lie in Oliver Williamson’s 1-year (1966–1967) stint as Special Economic Assistant at the Antitrust Division of the U.S. Department of Justice (Shapiro 2010, p. 138). The Antitrust Division was faced with (Williamson 2003, p. 64): the proposed merger of two daily newspapers in a small community. Given the clear prospect of increased market power, this was an easy case: Disallow the merger. But there was a further complication. That was that the merger might also yield economies. The question was, how should a merger that would simultaneously yield both efficiencies and market power be evaluated? I discovered to my surprise that the allocative efficiency consequences of such a merger had never been worked out. The prevailing intuition, however, was that any increase in market power, however small, would trump the benefits of any cost saving. Was that intuition correct? Williamson posed the implied research question as follows (1968a, p. 18, footnotes omitted): Suppose that a merger ...is proposed that yields economies but at the same time increases market power. Can the courts and antitrust agencies safely rely, in these circumstances, on a literal reading of the law which prohibits mergers “where in any line of commerce or any section of the country, the effect of such acquisition may be substantially to lessen competition, or to tend to create a monopoly,” or does this run the risk of serious economic loss? Williamson’s introductory approach to the problem, which he labelled the “naive” model, is illustrated in Fig. 1a. It shows an initial partial equilibrium with price equal to constant marginal cost (\(p_{1}=c_{1}\)) and output at the perfect competition level, \(Q_{1}=Q_{C}\). In the post-merger regime, price is greater than initial marginal cost, \(p_{2}>c_{1}\), but unit cost is reduced: \(c_{2}<c_{1}\).Footnote 3 Some consumer surplus remains for the demand side of the market (the area of the triangle \(abp_{2}\)), and there is a deadweight loss, relative to \(c_{1}\): the area of the triangle bde. Post-merger profit is \(\left( p_{2}-c_{2}\right) Q_{2}\): the area of the rectangle \(p_{2}bfc_{2}\). Of this profit, \(\left( c_{1}-c_{2}\right) Q_{2}\)—the area of the rectangle \(c_{1}efc_{2}\)—is a cost saving that represents a real economy of resources that are released for other uses. Market power versus efficiency tradeoffs, \(p_{1}=c_{1}\) in (a), \(p_{1}>c_{1}\) in (b), \(p_{2}\) and \(c_{2}\) identical in (a) and (b) The deadweight loss is in general approximately proportional to the square of the reduction in output,Footnote 4 while cost savings are proportional to post-merger output. Leaving aside income effects (Williamson 1968a, p. 22, fn. 4), the net welfare effect of the price increase and the unit cost decrease is given by the difference between cost savings and deadweight loss, the difference between the areas \(c_{1}efc_{2}\) and bde in Fig. 1a. Using numerical examples to build intuition, Williamson (2003, p. 64) concluded that “over a wide range of demand elasticities, the allocative efficiency benefits of a small reduction in average costs could be offset only by a large increase in prices—easily on the order of 10:1.”Footnote 5 Williamson recognizes the practical importance of factors that are omitted by assumption from the naive model. He notes (1968a, fn. 5 and the associated text) that second-best considerations (Lipsey and Lancaster 1956) may introduce other elements in the tradeoff calculus. He also acknowledges (without accepting) the argument that rent-seeking (Posner 1975, and others) could dissipate post-merger profit (or, in a dynamic perspective, its present-discounted value) and thus that the apparent rectangle of post-merger profit could become deadweight loss as well. The administration of merger policy absorbs resources;Footnote 7 it is therefore appropriate to require that if there is a welfare tradeoff, the cost saving should exceed deadweight loss by some positive threshold amount before admitting efficiency gains as a valid defense to a merger challenge.Footnote 8 The naive model is static; reality is not. In a dynamic perspective, one must allow (and Williamson does, 1968a, pp. 25–26; 1968b; 1987, pp. 12–14; see also Ross 1968) for the possibility that if antitrust policy blocks the achievement of efficiencies by merger, they may nonetheless be realized at a later date by means of internal expansion.Footnote 9 In present-discounted value terms, the policy alternatives may be “merger with market power and cost savings now” and “no merger, no market power in the near term with cost savings somewhat down the road.”Footnote 10 U.S. merger control as amended by the Celler–Kefauver Act applies to combinations in a sequence of mergers that would, at its completion, worsen market performance.Footnote 11 Williamson acknowledges that this will influence the use that is made of a market power-efficiency evaluation for any one merger (1968a, p. 26): “[I]f economies are available by combining one pair of firms they will often be available more generally, this may frequently be an important consideration.” Williamson points out that if a merger permits the combining firms to exercise market power, it may do the same for firms outside the merger.Footnote 12 He also observes that if a merger creates market power, it may affect more than strictly static market performance. It may slow the rate of technological progress.Footnote 13 It may permit managers to pursue their own interests, at the expense of shareholders’ interests (Williamson 1964). Although Williamson assumed an absence of income effects in working out the naive model, he later recognizes that (1968a, p. 28) “For specific welfare valuations, ...we might not always wish to regard consumer and producer interests symmetrically,” and continuing “although since, arguably, antitrust is an activity better suited to promote allocative efficiency than income distribution objectives (the latter falling more clearly within the province of taxation, expenditure, and transfer payment activities), such income distribution adjustments might routinely be suppressed.” At this point in the 1968 paper, Williamson also writes “the transfer involved could be regarded unfavorably not merely because it redistributes income in an undesirable way (increases the degree of inequality in the size distribution of income), but also because it produces social discontent. This latter has serious efficiency implications that the above analysis does not take explicitly into account. ...Distinguishing social from private costs in this respect may, however, be the most fundamental reason for treating claims of private efficiency gains skeptically.” Immediately thereafter, he identifies possible political considerations in evaluating merger welfare effects (1968a, pp. 28–29):Footnote 14 Combinations which involve firms that are already very large in absolute terms might be resisted on grounds that these raise extra-economic problems of political significance. There is not, however, any obvious way in which to integrate these into the analysis. Rather, although the political implications of control over wealth are a matter for serious concern, these are separable from the economic problems posed by control over markets; a different calculus is required to deal with each. Williamson (1969b, 1972, 1987) extends the naive model to the case that there is some exercise of market power before the merger. For the case that the post-merger price is the same as in Fig. 1a, the required modifications in the elements of the welfare tradeoff are depicted in Fig. 1b. The incremental deadweight loss due to the merger (area bdhe) is less in Fig. 1b than in Fig. 1a, because of pre-merger deadweight loss (in an amount given by the area of the triangle dgh). The net welfare effect of the merger is more likely to be positive in Fig. 1b than in Fig. 1a. Market power versus efficiency tradeoffs, \(p_{1}=c_{1}\) in (a), \(p_{1}>c_{1}\) in (b), \(p_{2}-p_{1}\) and \(c_{2}\) identical in (a) and (b) Alternatively, one might consider an identical cost reduction \(c_{1}-c_{2}\) and an identical price increase \(p_{2}-p_{1}\) before and after a merger, as shown in Fig. 2. Figures 1a and 2a are the same. In Fig. 2b the post-merger price is higher, and the post-merger output lower, than in Fig. 1b. Output restriction is greater in Fig. 2b than in Fig. 1b. Thus incremental deadweight loss (again, area bdhe) is greater, and the cost reduction is applied to fewer units of output, in Fig. 2b than in Fig. 1b. The net welfare effect of the merger is less likely to be positive in Fig. 2b than in Fig. 1b. Williamson (1972, 1987) goes through numerical illustrations of the resulting tradeoff for selected parameter values. He concludes (1972, p. 119) that “the cost savings required to offset price increases are significantly greater if pre-merger market power prevails. ...Still, the existence of pre-merger market power is not enough, by itself, to upset the basic conclusions of the naive model.” Williamson (1969a, pp. 113–114; 1972) envisaged that the welfare-tradeoff approach to merger control would gradually diffuse, in four stages. In the first stage, agencies and courts would recognize cost savings, along with deadweight loss, as a consequence of a merger, without making a net welfare calculation. In the second stage, evaluating the welfare tradeoff would be part of the enforcement process, without becoming the basis for decisions. In the third stage, policy decisions for some mergers would be based on an assessment of net welfare impact. In the final stage, welfare-tradeoff evaluation of proposed mergers would be the rule rather than the exception. Viewed through the lens of this four-stage process, welfare-tradeoff analysis in U.S. merger policy remains in the second stage.Footnote 15 Discussing U.S. antitrust agency practice, Scherer writes (2012, p. 258):Footnote 16 the U.S. agencies have continued to insist that no tradeoff be accepted. Rather, in the words of the joint agency Horizontal Merger Guidelines of August 19, 2010, section 10: ... To make the requisite determination, the Agencies consider whether cognizable efficiencies likely would be sufficient to reverse the merger’s potential to harm customers in the relevant market, e.g., by preventing price increases in that market.... From this perspective, agencies called upon to permit, or not, a proposed merger evaluate prospective cost savings, with a focus on consumer welfare. If cost savings are so great that there is no loss of consumer surplus, the merger will not be condemned on the grounds that it creates market power.Footnote 17",1
55.0,3.0,Review of Industrial Organization,10 July 2019,https://link.springer.com/article/10.1007/s11151-019-09717-2,Effect of Merger on Market Price and Product Quality: American and US Airways,November 2019,Somnath Das,,,Male,Unknown,Unknown,Male,"According to the United States Department of Justice’s (DOJ) updated 2010 merger guidelines, “mergers should not be permitted to create, enhance or entrench market power or to facilitate its exercise”.Footnote 1 A merger can decrease competition by reducing the number of firms in the market. In the case of the 2013 merger between American Airlines (AA) and US Airways (US), the DOJ—along with seven states and the District of Columbia—decided to challenge the merger because of anti-competitive concerns. AA and US Airways argued that the merger would generate substantial efficiencies, in terms of cost savings and consumer network benefits. The following quote is from the chief executive officer (CEO) of US Airways defending the merger: This merger will greatly enhance competition and provide immense benefits to the traveling public. Combined, US Airways and American Airlines will offer more and better travel options for passengers through an improved domestic and international network, something that neither carrier could provide on its own. Millions more passengers each year will fly on this new network than would fly on US Airways and American, should they be forced to remain separate. Conservative estimates place the net benefits to consumers at more than $500 million annually. Simply put, from the perspective of consumers, the new American will be much greater than the sum of its parts. This merger will be pro-competitive and lawful. Plaintiffs’ request for this Court to enjoin the merger should be summarily denied.Footnote 2 Since the U.S. airline industry has only a few large competitors, this merger raises the issue of increased market power for the existing airlines. But an increase in market power may not be always welfare-reducing for society as a whole. Even though an increase in market power and the resulting increase in price is not desirable from the point of view of consumers’ welfare, Williamson (1968) shows that there is a tradeoff between efficiency gain and market power effect as is shown in Fig. 1. Cost savings versus market power According to Williamson (1968), a market power effect is necessary but not sufficient for a merger to reduce welfare. Accordingly in Fig. 1, \(AC_1\) is the average cost and \(P_1\) is the price in the pre-merger period. Average cost decreases to \(AC_2\) in the post-merger period, but price increases to \(P_2\). The area \(A_1\) represents the dead-weight loss, while the area \(A_2\) represents the cost savings. If the area of \(A_2\) is larger than the area of \(A_1\) then the merger will be welfare-improving even though there is an increase in price. Farrell and Shapiro (2001) provides more detailed discussion about a consumer-welfare standard versus a total-welfare standard for the evaluation of mergers. There is a debate about the efficiency gain and market power effects of mergers that involve airlines. The efficiency gain may be generated from cost savings in airport operations, information technology, and supply chain management. Synergy is the concept that the performance of two companies that are combined will be greater than the sum of the performances of the separate individual companies. It can occur due to cost reductions, economies of scale, combined human resources, or technology. Market power may be generated due to a reduction in the number of competitors in the market. As a result of the removal of a competitor, a firm might be able profitably to raise the market price of a good or service. There is anecdotal evidence—for example, in media reports—that service quality decreases after a merger. Similar to price, there are two opposite effects on product quality: a positive effect that is due to a larger resource poolFootnote 3 and negative effects that are due to problems of integration. Service quality can improve because of the combined resource pool of the merged airline. The merged airline can improve quality by efficiently managing a larger resource pool.Footnote 4 For example, if there is a technical problem in the aircraft, a firm with a larger number of aircrafts can deploy a substitute aircraft and reduce delays in departure. A larger airline can also internalize congestion externalities.Footnote 5 The merged airline can upgrade quality by adopting the best practices of the two airlines. Quality of service can decrease due to the problems in integrating important resources. Problems can occur in combining the labor forces and merging the reservation systems of the two airlines. Reduced competition in the post-merger period may also decrease quality. A post-merger empirical analysis can help determine whether efficiency or market power dominates by analyzing the price before and after the merger (Hosken et al. 2017). Also, a change in the quality of service can be analyzed by looking at the change in flight frequency and other observable data, such as delays and cancellation of flights. While there are many studies that analyze the effect of mergers on market price, there are only a few studies that analyze the effect on product quality. This paper analyzes the effect of the merger on product quality in addition to analyzing the effect on price. The merger between AA and US is quite special in many respects: First, these two airlines together were going to create the largest airline in the world when the merger was proposed in 2012. Second, AA was undergoing bankruptcy during that time. Last, these two airlines had 30% overlappingFootnote 6 routes among their city-pair markets. It is an important merger to study because of these three unique factors. I use difference-in-differences analysis as the main identification strategy. I find that the merger has a significant negative effect on price and that the effect is larger for bigger markets. The effect on price in smaller markets is the opposite of that in larger markets, which implies that the smaller city-pair markets have not benefited from the merger. I also find that the merger had no significant impact on the frequency of flights or on the number of seats. However, delays in departure and delays in arrival have increased in the post-merger period. But the merger has reduced the number of canceled flights. Section 2 of this paper briefly describes the related literature. Section 3 covers the history of the U.S. airline industry. Section 4 provides a brief background of the merger. Section 5 describes the data and the variables. Section 6 outlines the identification strategy. Section 7 describes the results. Section 8 concludes.",10
55.0,3.0,Review of Industrial Organization,23 August 2019,https://link.springer.com/article/10.1007/s11151-019-09723-4,Static or Dynamic Efficiency: Horizontal Merger Effects in the Wireless Telecommunications Industry,November 2019,M. Grajek,K. Gugler,I. Mişcişin,Unknown,Unknown,Unknown,Unknown,,
55.0,3.0,Review of Industrial Organization,29 July 2019,https://link.springer.com/article/10.1007/s11151-019-09719-0,"Post-merger Price Dynamics Matters, So Why Do Merger Retrospectives Ignore It?",November 2019,Franco Mariuzzo,Peter L. Ormosi,,Male,Male,Unknown,Male,"The price effect of past mergers has received increasing attention since the early 1990s. The recent upsurge in the number of such studies generated a considerable body of evidence of the price effect of mergers. Kwoka (2013, 2014) identified more than 60 US studies that looked at the price effect of mergers. Mariuzzo et al. (2016) reviewed another 20 similar European studies. Methodologically, these studies are relatively homogeneous. They use standard difference in-differences type models, and they vary mainly in the way the counterfactual is constructed. The objective of our paper is to focus on a specific empirical aspect of these studies, the handling of post-merger time-periods. The specification of the estimated model plays a cardinal role in how the results should be interpreted. Most previous studies estimate over-time average post-intervention price-effects; these studies overlook post-merger price dynamics. In general, in many causal inference studies the post-intervention dynamics of the outcome variable would not matter. However, there are equally many situations where evidence on this variation is exactly what the researcher should be aiming to get. Estimating the price effect of mergers is one of these.Footnote 1 Estimating the over-time average price effect of mergers is counter-intuitive for two main reasons. First, merger guidelines agree that no intervention is needed if the post-merger price increase disappears within a reasonable amount of time, for example because of new entry. The US Horizontal Merger Guidelines say: “The Agency will consider entry to be timely so long as it would deter or counteract the competitive effects of concern within the two year period and subsequently.”Footnote 2 Similarly, the European Commission’s guidelines on the Merger Regulation state: “The Commission examines whether entry would be sufficiently swift and sustained to deter or defeat the exercise of market power. What constitutes an appropriate time period depends on the characteristics and dynamics of the market, as well as on the specific capabilities of potential entrants. However, entry is normally only considered timely if it occurs within two years.”Footnote 3 Of course for entry to occur, a potential entrant would have to find such entry profitable, and the extent of entry would have to be such that prices would revert to (or remain at) pre-merger levels. Retrospective studies could verify whether these conditions are fulfilled after a merger. However, entry and its effects are a gradual process (prices might take some time to drop or to increase), which requires looking at the dynamics of post-merger prices in order to identify whether pre-merger expectations about entry—and the effect of entry—were correct. Second, merger retrospectives are typically conducted to inform policy-makers whether a merger decision was correct or not. For this reason the conclusion as to how prices change post-merger is crucial. The estimation of the average post-merger price-effect requires a different empirical model than estimating annual effects. Is it possible that the two empirical models return different evidence on the price effects of the merger? We show in this paper that the likelihood of making the wrong conclusion is very high if the wrong empirical model is used. The purpose of this paper is not to stipulate that longer-term studies are better suited for post-merger price evaluations, although given merger policy guidelines, it appears appropriate to include at least two post-merger years in any merger evaluation. Instead we argue that even if the available data are relatively short-spanning (two years), one should still look at the dynamics of price effects (for example the effect in the first and in the second year separately) and not only the over-time average as it is currently done in the majority of studies. The difference is easy to see. Take a merger, that increases prices by 10 percent in the year following the merger but then prices revert to the pre-merger level in the second post-merger year. Currently, only one in five merger retrospectives estimate these annual price effects and would conclude that post-merger prices reverted to pre-merger levels by the end of the second year. Four in five studies would estimate an over time average. In this case this would imply a 5 percent price increase and could lead to the conclusion that the merger was anticompetitive, and that the intervention was insufficient.Footnote 4 There is surprisingly little empirical work on the dynamics of how markets evolve post-merger, and whether the antitrust agency’s expectations at the time of the merger came true (for example, did entry happen as expected and did it reduce prices as predicted?) A notable exception is a set of annually conducted studies by the UK Competition Commission, which used to collect qualitative evidence on how market characteristics (other than just price) evolved over a longer post-merger period.Footnote 5 With regard to specific mergers, Winston et al. (2011) look at the long-run effect of two railroad mergers. They estimate how prices evolved (year-by-year) post-merger and find that despite the short-term increases in price the mergers had no effect in the long-run on prices and welfare. Looking at mergers in the US market for bank deposits Focarelli and Panetta (2003) arrive at similar conclusions: mergers create higher prices in the more immediate aftermath of the merger, but this effect later disappears.Footnote 6 We contribute to the rich body of merger retrospective studies in an important way, by pointing out how inappropriately designed empirical models, irrespective of data availability, will mask important information on the price effect of mergers. First we formalise the problem and argue that pooling together all post-merger time periods will provide price-effect estimates that are the average of the per period (annual) effects with a standard error that is lower than the standard errors of the annual price effects (at least under the assumption of non-positive correlation). This difference in standard errors has an important role to play in our main argument. We attempt to demonstrate the effect of choosing the wrong model by employing a meta-analysis of more than 600 previous market-level price-effect estimates. Where estimates were available on price dynamics—e.g. where a study estimated annual effects—we were able to show how far off the over-time average estimates would have been. On the other hand, where only over-time average estimates were reported in the studies (this is what we refer to as inappropriate model choice), we could not re-construct the per-period variation in prices, therefore we turned to a set of Monte Carlo simulations and calibrations. These simulations show that models that estimate an average post-merger price effect are more likely to lead to erroneous conclusions (e.g. concluding that the merger increased prices, even when it did not, or concluding that the merger did not increase prices even when it did). The paper is structured the following way. First, we describe how previous papers have handled post-merger price dynamics and show that this has been typically ignored. We then provide a discussion of the difference between the pooled and unpooled time period models. This is followed by a set of simulations and calibrations to demonstrate the magnitude of the problem, and we conclude with policy recommendations.",6
55.0,3.0,Review of Industrial Organization,15 June 2019,https://link.springer.com/article/10.1007/s11151-019-09709-2,Estimating Differential Dynamic Merger Effects on Market Structure and Entry in Related Markets,November 2019,Ralph B. Siebert,,,Male,Unknown,Unknown,Male,"The United States and the European Union prohibit mergers that substantially lessen competition.Footnote 1 Distinguished scholars and policy makers have a long-standing interest in mergers and attempt to understand when mergers can become harmful to consumer welfare. Most empirical merger studies devote attention to evaluating instantaneous competitive merger effects on prices (see Davis and Garces 2009). These merger effects are frequently characterized by a trade-off between two forces: the efficiency gain, and the market-power effect (see Williamson 1968; Harris and Siebert 2017; Kwoka 2015). For a merger to be permitted by competition authorities, merger-specific efficiency gains must be sufficiently large to compensate for the anticompetitive market-power effects of the merger and to cause post-merger prices to not increase significantly.Footnote 2 To date, the dynamic impact of actual mergers on market structure has not received much attention—which is surprising, since many empirical studies highlight the impact of market structure on competition and prices (see also Martin 2012, for more details). More insight on the dynamic merger effects on market structure and performance is needed. The aim of this study is to provide insights into this topic while explicitly distinguishing between different types of mergers: those that generate dominant instantaneous market-power, and those that are dominated by efficiency gains. To the best of our knowledge, this is the first empirical study that explores the differential dynamic impact of realized mergers on market structure. Our study also accounts for the fact that a merger between two competing firms in one market can exert an impact on entry in related product markets. The merger could eliminate the acquired firm as a potential entrant into a related product market and thereby “diminish the likelihood of entry” into related product markets. A large strand of literature concentrates on the relationship between market structure, competition, and prices. Standard theoretical models show that the number of firms in a market is determined by market characteristics such as entry barriers, fixed setup costs, the nature of price competition, the elasticity of demand, etc.Footnote 3 While economists put much emphasis on market structure as a determinant for competition and market performance and many studies simulate the impact of hypothetical mergers on market structure, little is known about how actual mergers impact market structure. Several economists recognize the need for insights on this important merger aspect (see, for example, Williamson 1977; Werden and Froeb 1998; Baker 2003; Carlton 2007).Footnote 4 In this context, Baker (2003) argues that pre- and post-merger market conditions can be different, such that potential entrants can have incentives to enter post-merger even though entry was unattractive pre-merger. This argument plays a central role in many merger investigations and in our study. For example, a market-power-dominated merger increases prices and opens sales opportunities for an entering firm. If a merger is counteracted by post-merger entry, the ability of the merging parties to raise prices significantly above pre-merger levels is thereby constrained. Therefore, entry can mitigate the anticompetitive market-power effect (see also Shapiro 2010). The U.S. and EU merger guidelines also explicitly refer to the “ease of entry” argument as an indication of whether entry will be likely, timely, and sufficient to prevent potential short-run anticompetitive effects of mergers (see Section  9 of the U.S. Department of Justice and U.S. Federal Trade Commission Horizontal Merger Guidelines, August 19, 2010, and Section VI of the European Commission’s Guidelines on the Assessment of Horizontal Mergers, February 5, 2004). Entry is defined as timely if it occurs within 2 years, as mentioned in Section 3.2 in the U.S. Horizontal Merger Guidelines (1992, revised 1997 and 2010) and Paragraph 74 in the European Commission’s Guidelines on the Assessment of Horizontal Mergers.Footnote 5 Interestingly, several U.S. courts have rejected merger challenges on the ground that mergers would trigger entry and prevent any post-merger anticompetitive effects.Footnote 6 For motivational purposes, we adopt a simple standard theoretical oligopoly framework with free entry to determine the number of firms; the established relationship serves as a basis for specifying our empirical model. A simple two-stage game is considered, in which profit-maximizing firms first decide to enter a market. Entry requires a fixed setup cost, which presumably represents capital costs from investments into a new fabrication plant, machinery, tools, and production technology. Regardless of the firm’s output, the fixed capital cost must be paid in each period in which the firm remains in the market. In the second stage, firms simultaneously determine their output. Prices and profits fall with the number of entering firms, and firms enter as long as positive profits are earned. The equilibrium number of firms in a market depends upon market determinants such as the fixed setup cost, efficiency levels, demand sensitivity, and market size. We take this relationship to the data and apply reduced-form regressions to test for post-merger impacts on market structure while distinguishing mergers by their dominant instantaneous impacts: efficiency- and market-power-dominated mergers. We use a comprehensive database on the dynamic random access memory (DRAM) market that contains detailed quarterly firm-level information on mergers, production, entry, exit, and innovation. The data are augmented by merger information on the flash memory market. The data on the DRAM market are particularly suited to our research for the following reasons: one main empirical challenge is that market structure studies require firm-level entry and exit information for a narrowly defined product market. This is difficult to find and frequently comes at the expense of rarely observing any merger events. We have data on the DRAM market at a level that is far more disaggregated than the common six-digit NAICS classification system for U.S. industries, and it is characterized by a relatively large number of mergers. In fact, the number of mergers in the DRAM industry is quite high for an industry that is defined at such a highly disaggregated level. Moreover, the industry is not highly concentrated, such that mergers with different short-term impacts (especially potential market-power-dominated mergers) would not have raised significant anticompetitive concerns. This ensures that mergers that are characterized by different short-term impacts (market-power- and efficiency-dominated mergers) are observed and considered in our study. The industry is also characterized by relatively unhindered entry conditions, but firms must incur fixed setup costs. This entry condition is favorable for our purposes since fixed setup costs aggravate the replacement of a consolidated firm by a potential entrant, which makes a merger study on market structure more meaningful. Moreover, the institutional characteristics of the DRAM market (such as market size, fixed costs, and efficiencies) show sufficient temporal variation, which serves our identification purpose of explaining the variation in the number of firms over time. One further distinct feature of the database is the availability of highly disaggregated firm-level shipment data, which are rarely available. This specific characteristic enables us to classify mergers into efficiency- and market-power-dominated mergers without a need to estimate unobserved marginal costs, as will be detailed later. Our main estimation results show that in the short-run (1 year after merger formation), neither efficiency- nor market-power-dominated mergers trigger instantaneous entry or exit. In the more distant future—2 and 3 years after merger formation—both types of mergers exert significantly differential impacts on market structure, and these impacts are increasing over time. Efficiency-dominated mergers cause two firms to exit the market 3 years after merger formation. Market-power-dominated mergers leave room for entrants and attract an additional 2 (3) entering firms 2 (3) years after merger. It is interesting to note that efficiency-dominated mergers have a greater effect on triggering exits than market-power mergers have on attracting new entry. Our results also support the claim that is frequently made by economists that instantaneous merger effects can have opposing dynamic competitive impacts via market structure changes. For example, while mergers that are dominated by market-power effects increase prices and harm consumer surplus in the short-run, they provide entry opportunities in the longer run, which increases competition and causes downward pressure on prices. Therefore, post-merger entry can mitigate the instantaneous anticompetitive market-power effect. In contrast, mergers that are driven by efficiency gains have a more negative long-run impact on the number of firms in the product market, which diminishes competition—and that causes upward pressure on price. In a comparison of all three merger effects, it is interesting to note that the effects of market-power- and efficiency-dominated mergers on market structure go in opposite directions and are increasing over time. The estimation results also show that mergers can reduce the number of entrants into related product markets. Hence, mergers can instantaneously “diminish the likelihood of entry” into related product markets. The reduced likelihood of entry into related product markets is a short-term phenomenon and is limited to 2 years. Our study is related to the literature on market structure and entry. Theoretical entry studies show that the equilibrium number of firms is determined by market determinants: such as fixed setup costs, efficiency levels, market size, and the price elasticity of demand, among other things. Empirical entry studies have shown that these market determinants determine entry and competition, as well as firms’ profits and margins (see also Carlton 1983; Graham et al. 1983; Geroski 1989; Reiss and Spiller 1989; Weiss 1990). Dunne et al. (1989) highlight that free and easy entry of new competitors provides the ultimate constraint on the exercise of market-power by incumbent firms. Dunne et al. (1988) examine entry and exit patterns across industries and over time.Footnote 7 In the context of mergers, theoretical studies have shown that merger-specific synergies are a critical aspect when evaluating the impact on consumer welfare. Prominent contributions in this area are Stigler (1950), Williamson (1968), Salant et al. (1983) , Davidson and Deneckere (1985), Perry and Porter (1985), and Farrell and Shapiro (1990), among others. Other theoretical studies elaborated on the fact that post-merger entry becomes more likely if mergers are dominated by instantaneous market-power effects rather than instantaneous efficiency effects; see, for instance, Werden and Froeb (1998), Cabral (2003) , Spector (2003), and Davidson and Mukherjee (2007). Most empirical merger studies concentrate on estimating instantaneous merger effects. Examples are Gugler et al. (2003) , Ivaldi and Verboven (2005), Goetz and Gugler (2006) , Gugler and Siebert (2007), Duso et al. (2007) , Clougherty and Duso (2009), Ashenfelter and Hosken (2010), Duso et al. (2011) , Duso et al. (2013), Aguzzoni et al. (2016), Gugler and Szuecs (2016) , and Allain et al. (2017). For further information see also the surveys by Geroski and Vlassopoulos (1990) and Siegfried and Evans (1994). Another strand of empirical merger studies frequently simulates the impact of one hypothetical merger on market structure using computational models. The simulation studies do not evaluate the impact of real-world mergers. They usually use firm profitability as the dependent variable, while our approach concentrates on estimating the actual merger impact on the number of firms.Footnote 8 To date, little is known about the implications of real world mergers on market structure. We are not aware of any empirical merger study that evaluates the dynamic impact of actual mergers on market structure—accounting for the impact of different actual merger types on market structure. The empirical merger study that is closest to ours is the study by Berger et al. (2004). Their study, however, is distinct from ours in several ways: while their study evaluates the impact of actual mergers and acquisitions on entry, our study concentrates on the differential impact of mergers—that is, market-power- and efficiency-dominated mergers—on market structure. This focus furthers our understanding of whether efficiency-defense and ease-of-market-entry arguments can work in opposite directions when evaluating the effects of mergers on consumer welfare. Moreover, our study concentrates on the DRAM industry, which exhibits rapid innovation. Their study focuses on the banking industry where innovation is not as highly paced. Therefore, more insight is required on the actual merger impact on the evolution of market structure. The remainder of the paper is organized as follows: Sect. 2 introduces the industry and data and provides summary statistics. In Sect. 3, the theoretical foundation and the empirical model are introduced. Section 4 presents the results, and we conclude in Sect. 5.",2
55.0,3.0,Review of Industrial Organization,17 August 2019,https://link.springer.com/article/10.1007/s11151-019-09724-3,A New Perspective on Entry in Horizontal Merger Analysis,November 2019,Charles J. Thomas,,,Male,Unknown,Unknown,Male,"A critical part of the antitrust analysis of horizontal mergers is assessing whether new entry into the market will be timely, likely, and sufficient to deter or counteract any anticompetitive harm that a merger is otherwise predicted to create. The horizontal merger guidelines in the US and EU stress the importance of such market-level entry,Footnote 1 as do the judicial opinions in merger cases that involve industries such as waste hauling, movie theaters, office superstores, and baby food.Footnote 2 In this paper I use game-theoretic tools to analyze the antitrust implications of a different entry problem that is encountered in what competition authorities call bidding markets, in which competition for each buyer’s business occurs in a separate procurement contest:Footnote 3 to compete in a contest, sellers already in the market frequently must incur entry costs: for example, to assess their product’s fit with the buyer’s preferences or purchasing requirements, formulate an initial proposal, evaluate production costs, or design prototypes. Contest-level entry costs are present in a wide variety of markets, including those for external audit services, highway construction, maintenance contracts, and hydro power equipment.Footnote 4 Similar costs are present in bidding markets in which bidders are buyers rather than sellers, such as in markets for oil or timber rights, radio spectrum, and large asset sales.Footnote 5
French and McCormick (1984), McAfee and McMillan (1987), and Levin and Smith (1994) provide early theoretical analyses of the strategic impact of contest-level entry on outcomes in bidding markets; but the role of such costs in merger analysis has not yet been formally analyzed.Footnote 6 In Sect. 2 I add contest-level entry costs to a standard procurement model that has been used in horizontal merger analysis: this is a simple and empirically relevant change that in Sect. 3 I show sharply alters merger effects: a profitable merger can increase both consumer and total surplus if it reduces the merging sellers’ contest-level entry costs, while the same merger decreases consumer surplus and leaves total surplus unchanged in the corresponding model without such costs. These differences reveal that ignoring contest-level entry can lead to recommendations to block a merger that is procompetitive under either a consumer or total welfare standard. Moreover, the mistaken recommendation from the standard model will not be corrected by considering new sellers’ market-level entry: because of the nature of price competition in the standard model, potential entrants will not anticipate higher expected profits post-merger despite the merger’s effect on the expected price. Consequently, those sellers will not enter post-merger, and hence they will not counteract the merger’s anticompetitive effects. The existence of procompetitive mergers relies on the practical consequence of contest-level entry costs that not all sellers necessarily compete for each buyer’s business, via a simple mechanism that is consistent with the claim that is frequently made by merging parties that their merger is beneficial because it creates a stronger competitor. Mergers benefit buyers in non-overlap contests in which one or both parties would not have competed pre-merger, because the now-stronger merged seller enters the contest. Mergers harm buyers in overlap contests in which both parties would have competed pre-merger, because the merger eliminates instances in which the merging sellers would have placed first and second in the contest, and hence the transaction price post-merger instead will be determined by the seller who pre-merger would have placed third. This reduction in consumer surplus is familiar from the standard analysis of horizontal mergers in bidding markets without contest-level entry costs. However, mergers increase total surplus in overlap contests by reducing the merging sellers’ contest-level entry costs: an effect that is absent in settings without such costs. Antitrust authorities are well aware that there is variation in entry across contests in a market, and to account for it they have developed approaches for assessing mergers that informally complement the stark insight that all mergers are anticompetitive, which emerges from the standard procurement model without contest-level entry. A common quantitative approach is a frequency analysis that uses historical contest-level data from industry participants to assess how often the merging parties meet, and how often they place first and second in such overlap contests, with the perceived extent of harm increasing in both frequencies. This approach is described in Section 6.2 of the US Horizontal Merger Guidelines (2010), and it has been used by the European Commission in merger investigations in a variety of industries, including the supply of industrial gases (Air Liquide/Messer), railway transportation technology (Bombardier/ADtranz), secure plastic cards (Axalto/Gemplus), and city buses (MAN/Scania).Footnote 7 A common qualitative approach is to argue that a buyer is unlikely to be harmed if not all sellers compete for its business pre-merger, because competition lost through the merger of two active sellers can be replaced by sellers who were inactive pre-merger. This approach has been used in EC merger cases in industries such as the supply of enterprise application software (Oracle/PeopleSoft), automotive components to OEMs (Magna/New Venture Gear), large turbines (Siemens/Alstom), and equipment for mobile networks (Nokia/Siemens).Footnote 8 In Sect. 4 I argue that these informal approaches do not reliably predict merger effects, when assessed with the use of my formal model that incorporates sellers’ costly entry decisions for each contest. First, although frequency analyses seem sensible because mergers diminish competition in overlap contests, I show that a merger can change sellers’ contest-level entry decisions in such a way that a merger is more harmful the less frequently the merging sellers compete pre-merger. Moreover, merger effects can differ for a given frequency of overlap, depending on the frequency of various non-overlap possibilities. Second, the existence of inactive sellers pre-merger does not prevent a merger’s anticompetitive effects in overlap contests. Those inactive sellers might not find it profitable to enter even if the merger increases the expected price, depending on the nature of post-entry price competition. Finally, both approaches ignore the procompetitive effects that arise in non-overlap contests. To my knowledge antitrust authorities normally consider mergers to be competitively neutral in non-overlap contests, and hence they do not trade off competitive benefits in such contests against whatever anticompetitive harm is expected to occur in overlap contests. In Sect. 4 I also describe extensions of the basic procurement model that reflect potentially relevant market features, which include alternative entry protocols and efficiencies that affect the merging sellers’ production costs. The extensions seem unlikely to change the central insight that procompetitive effects can arise because a merger leads to more and stronger contest-level entry by the merged seller, but they amplify the importance of assessing the suitability of the various approaches to modeling horizontal mergers in bidding markets. For example, I assume that every seller pays the same entry cost, but a higher entry cost for the merged seller decreases the likelihood of procompetitive mergers. The extensions also might be useful for conducting the sort of merger simulations that have become an oft-used tool by antitrust practitioners, as described in the context of bidding markets by Dalkir et al. (2000), Brannman and Froeb (2000), Bengtsson (2005), Budzinski and Ruhmer (2010), and Gugler et al. (2015).",3
55.0,3.0,Review of Industrial Organization,15 July 2019,https://link.springer.com/article/10.1007/s11151-019-09716-3,The Kaldor–Hicks Potential Compensation Principle and the Constant Marginal Utility of Income,November 2019,Stephen Martin,,,Male,Unknown,Unknown,Male,"Ever since economics gave up utilitarianism,Footnote 1 economists’ theoretical approach to evaluating the welfare impact of resource reallocations has been Pareto optimality: a reallocation of resources is a Pareto improvement if it makes one or more economic agents better off and no economic agents worse off. The Pareto criterion does not provide a complete ordering. It will often—indeed, most often—be the case that a reallocation of resources makes some economic agents better off and other economic agents worse off, and the Pareto standard does not rank such changes. The Kaldor–Hicks potential compensation principle aspires to deal with this kind of case (Robbins 1981, p. 6): According to this principle, we can still say that a community is better off, despite the fact of a change involving gains for one person or group and losses for others, if out of the gains it would be possible to compensate the losses and still leave a benefit for the gainer or gainers (and this without regard to whether compensation is actually made). The potential compensation principle is the basis of industrial economists’ most widely-used measure of the impact of market power on market performance: partial-equilibrium deadweight loss. Its use in this context relies on two premises: equal weighting of changes in producer and consumer surplus and the assumption that the marginal utility of income is constant. The first assumption serves to separate questions of efficiency in resource allocation from questions of income distribution. It is universally rejected by welfare economists, who deny that if a change in resource allocation leaves some groups better off and some worse off, economics teaches us what weights should be assigned to the monetary value of the respective gains and losses. The role of the second assumption is twofold: first, it permits a partial-equilibrium approach. Second, it provides a link between changes in surplus (that is, monetary values) and changes in welfare. As regards applications in industrial economics, the first assumption has received substantially more attention than the second. My focus is on the second assumption. I show by means of a simple model that if there is diminishing marginal utility of income, the partial equilibrium analysis of net changes in surplus is a misleading indicator of overall welfare changes—even if gains and losses are weighted equally. Interest in this topic is enhanced by recent economic developments where the fact that compensation is not made following resource reallocations has had important economic and political implications, as losing groups that have not been compensated in the wake of policy changes that left them worse off support populist positions at the polls. Essentially all economists support free trade as a policy that maximizes overall welfare. It is increasingly (if sometimes grudgingly) accepted that free trade can create, and has created, groups of “economic losers” (Pierce and Schott 2016). These groups are a large enough portion of the U.S. economy to raise the possibility that the U.S. will retreat from a policy of free trade. If one believes that free trade is welfare-enhancing, this is disquieting, and suggests that “compensation could be made” should not be the end of a discussion of the impact of policy changes on market performance. I begin, in Sect. 2, with a review of the origins of, and professional reception of, the potential compensation principle. In Sect. 3, I present a simple model that weights welfare changes of winners and losers identically. In the case of a price increase, the net change in aggregate welfare indicated by the potential compensation principle is shown to be ambiguous if there is decreasing marginal utility of income. Section 4 pursues the implications of diminishing marginal utility of income for the market power versus efficiency tradeoff that was identified by Williamson (1968). Section 5 examines the welfare implications of costless first-degree price discrimination if the marginal utility of income is not constant. Section 6 reviews empirical evidence on the marginal utility of income. Section 7 concludes. The following points emerge from this discussion. First, at the level of theory, the assumption that there is an outside good with constant marginal utility is as important for the validity of the potential compensation principle as the assumption that welfare changes of different individuals are weighted equally. It follows, second, that at the partial equilibrium level, deadweight loss is not in general a valid indicator of net welfare changes. Changes in consumer surplus and producer surplus should be considered separately. Third, deadweight loss may be a useful approximation to partial equilibrium welfare effects if wealth effects can be neglected—which extends back to Marshall, if consumer expenditures on a good are a small part of total expenditures. Fourth, from this it follows that one should be skeptical of estimates of the welfare cost of market power for the economy as a whole obtained by summing partial equilibrium estimates for a broad range of markets: It may be acceptable to neglect wealth effects for some goods, but not all.",3
55.0,3.0,Review of Industrial Organization,17 June 2019,https://link.springer.com/article/10.1007/s11151-019-09708-3,Williamson’s Welfare Trade-Off Around the World,November 2019,Germán Bet,Roger D. Blair,,Male,Male,Unknown,Male,"Half a century ago, Williamson (1968) explained that an efficiency-enhancing merger could have conflicting welfare effects. On the one hand, the efficiencies reduce costs and thereby improve social welfare (i.e., the sum of both consumer and producer surpluses). On the other hand, the merger may increase the degree of market power, which would lead to allocative inefficiency and thereby decrease social welfare. Consequently, an efficiency-enhancing merger may present a welfare trade-off in analyzing the net effect on social welfare. In the last 50 years, Williamson’s model has been refined in several ways (e.g., Farrell and Shapiro 1990). It has also been extended to the case of monopsony (Blair 2010) and to the case of quality-enhancing mergers (Blair and Sokol 2015). In all cases, under the explicit and implicit assumptions that were made by Williamson (1968) and absent distributional concerns, Williamson’s point is well taken: If a merger produces a net improvement in social welfare, then there is no sound economic rationale for prohibiting the merger. In spite of its economic logic, Williamson’s analysis has not been embraced by the U.S. antitrust authorities nor by the European Union (EU) authorities. The attitudes of other countries toward merger-specific efficiencies vary to some extent. In this paper, we begin by presenting Williamson’s model, along with some refinements in Sect. 2. In Sect. 3, we extend Williamson’s model to the case of monopsony and to the case of quality improvement. Section 4 provides a survey of the antitrust treatment of merger efficiencies in the U.S., Canada, China, and other countries. In Sect. 5, we explore various reasons why antitrust authorities have failed to adopt an explicit social welfare standard. We offer some concluding remarks in Sect. 6.",5
55.0,4.0,Review of Industrial Organization,16 November 2019,https://link.springer.com/article/10.1007/s11151-019-09741-2,General Editor’s Note: Antitrust and Regulatory Update,December 2019,Lawrence J. White,,,Male,Unknown,Unknown,Male,,
55.0,4.0,Review of Industrial Organization,07 September 2019,https://link.springer.com/article/10.1007/s11151-019-09726-1,"The Year in Review: Economics at the Antitrust Division, 2018–2019",December 2019,Evan Gee,Craig Peters,Jeffrey M. Wilder,Male,Male,Male,Male,"Over the past year, the Antitrust Division of the U.S. Department of Justice continued its tradition of enforcing the antitrust laws in accordance with sound economics. In this review article, we take a close look at the economic work underlying two such cases: the Antitrust Division’s challenge of AT&T’s acquisition of Time Warner and the anti-steering settlement that the Division reached with Atrium Health. Of course, these constitute just a sliver of the matters on which the Antitrust Division’s Economic Analysis Group (EAG) provided economic analysis. Other noteworthy examples include: the landmark settlement that was reached with Bayer AG to allow it to acquire the Monsanto Company; the settlement that was with CVS fashioned to preserve competition for individual prescription drug plans following CVS’s acquisition of Aetna; and the Division’s challenge to and subsequent abandonment of the merger of two rival printing companies: Quad/Graphics and LSC Communications. Although the U.S. Court of Appeals for the D.C. Circuit allowed AT&T to acquire Time Warner in early 2019, the Antitrust Division’s challenge of the transaction represented a meaningful step forward for vertical antitrust enforcement. As explored in greater detail below, the Division alleged that the merger would increase Time Warner’s bargaining leverage as it negotiated with AT&T’s rivals downstream. By incorporating bargaining theory expressly into the theory of harm, the case allowed for a much richer modeling of the impact of the vertical merger. It also called into question whether efficiencies that arise from the elimination of double marginalization were as large as is often assumed in vertical mergers. We also discuss the Division’s settlement that was reached with Atrium Health: a large hospital network that operates in Charlotte, North Carolina. Health care insurers have increasingly attempted to adopt insurance plans that promote competition among providers. For example, insurers have created plans with tiered networks in which insurers provide incentives for their members to use low-cost, high-quality providers that qualify for preferred tiers. Unsurprisingly, such plans constitute a threat to well-established providers that charge premium prices, even after controlling for quality. Based on economic work from EAG that is described below, the Division was able to reach a settlement with Atrium Health that prohibited anti-steering restrictions that undercut insurer efforts to induce competition among providers. We encourage interested readers to visit the Division’s website at www.justice.gov/atr to learn more about these and other enforcement efforts of the Division.",
55.0,4.0,Review of Industrial Organization,07 November 2019,https://link.springer.com/article/10.1007/s11151-019-09739-w,Recent Developments at DG Competition: 2018/2019,December 2019,Rossitza Kotzeva,David Kovo,Tommaso Valletti,Unknown,Male,Male,Male,"The CET is a part of DG Competition. Its staff consists of 30 economists (mostly holding PhDs) with a mix of permanent and temporary positions. The CET is headed by the Chief Competition Economist, who is an external academic who is recruited for a 3-year term. The CET has both a support role and a scrutiny role. As part of its support role, the team provides guidance on methodological issues of economics and econometrics in the application of EU competition rules. It contributes to individual competition cases—in particular, the ones that involve complex economic issues and quantitative analysis—and to the development of general policy instruments, as well as assisting with cases that are pending before the courts of the European Union. Members from the CET who are assigned to specific cases have a specific and independent status within case teams, and report directly to the Chief Competition Economist. As part of the scrutiny role, the Chief Competition Economist can report his opinion directly to the Director-General of DG Competition as well as to the Competition Commissioner, providing her with an independent opinion with respect to the economic aspects of a case before she proposes a final decision to the European Commission. The CET is active in DG Competition’s three main areas of policy: antitrust, merger control, and state aid. Between January 2018 and July 2019, the European Commission took decisions in 16 (non-cartel) antitrust cases. Four of these cases—involving Qualcomm, Gazprom, Greek lignite, and Asus/Denon&Marantz/Pioneer/Philips—are listed and briefly discussed in Amelio et al. (2018). The Google Android case is reviewed in depth in Sect. 3 of this paper. The other 11 antitrust decisions by the European Commission were: Bulgarian Energy Holdings (BEH) in December 2018Footnote 2; Guess in December 2018Footnote 3; Danish/German electricity interconnector in December 2018Footnote 4; Mastercard in January 2019Footnote 5; Google AdSense in March 2019Footnote 6; Nike in March 2019Footnote 7; Cross-border access to pay-TV in March 2019Footnote 8; Mastercard and Visa, in April 2019Footnote 9; AB InBev in May 2019Footnote 10; Character merchandise in July 2019Footnote 11; and Qualcomm predation in July 2019.Footnote 12 During the 2018–2019 period there have been also important judgments by the European Courts on past antitrust decisions adopted by the European Commission. These include the three judgments in: ServierFootnote 13; Slovak TelekomFootnote 14; and Canal+Footnote 15 (all in December 2018). In the Servier case, the General Court upheld the Commission’s findings that some of the patent settlements that involved payments from the originator (Servier) to generic producers constituted “pay-for-delay” agreements that restricted competition “by object” (under Article 101 of the European Treaty). The Court also found that for one specific settlement agreement, the Commission did not prove a restriction of competition “by effect”. Finally, the Court also annulled the Commission’s finding that Servier was dominant, and hence that it had abused its dominant position (under Article 102 of the European Treaty). In Slovak Telekom, the Court largely upheld the Commission decision that found that Slovak Telekom had abused its dominant position by refusing access to its local loop and by engaging in margin squeeze practices. In Canal+ the Court dismissed the application for annulment that was brought by Canal+ against the Commission decision that made binding the commitments that were offered by Paramount. The commitments addressed the Commission’s concerns that clauses in Paramount’s pay-tv film licensing agreement with Sky UK prevented cross-border passive sales and therefore amounted to absolute territorial protection that eliminated all cross-border competition between pay-tv broadcasters. During the period January 2018–June 2019, 569 merger investigations were concluded at DG Competition. The vast majority (438 cases) were unconditional clearances under a simplified procedure. 114 cases were concluded during a (non-simplified) phase I investigation, and 17 cases during a phase II investigation.Footnote 16 Of the (non-simplified) phase I cases,Footnote 17 85 were cleared unconditionally; 23 could be cleared in phase I subject to commitments; and six were abandoned.Footnote 18 The phase II investigations resulted in: four unconditional clearancesFootnote 19; eight clearances that were subject to commitmentsFootnote 20; three prohibitionsFootnote 21; and two abandoned transactions.Footnote 22 Therefore, around 7% of cases were not cleared unconditionally during this period. The CET was involved in all second-phase investigations as well as in many complex first-phase investigations. In terms of broader policy themes, the prohibition of the Siemens/Alstom transaction in February 2019 led some commentators to call for more flexible EU merger control to allow for the emergence of European Champions—possibly even at the expense of reduced competition in Europe.Footnote 23 At the same time, there is mounting evidence that market power in many industries has been increasing considerably in recent times.Footnote 24 Other observers have therefore argued that merger control should instead be particularly vigilant, to prevent anti-competitive concentrations.Footnote 25 In the same vein, active policy debates have continued regarding (1) mergers in the digital world (in particular with respect to platform competition) (2) mergers that eliminate potential competition (e.g. so-called “killer acquisitions”), as well as (3) transactions that may fall below EU notification thresholds. With respect to all of these themes, various commentators also seem to be suggesting that, if anything, merger control should become stricter rather than looser. In particular, several voices have advocated a closer and more thorough scrutiny of digital platforms—because of their ability and incentive to hamper competition.Footnote 26 Between January 2018 and July 2019, the Commission took almost 300 decisions in the area of state aid; most of those decisions concluded that the actions were compatible with the Commission’s criteria for justifiable actions or did not actually involve aid.Footnote 27 Positive decisions for important projects of common European interest—notably, IPCEI Microelectronics—were adopted also in the course of the last year. In the postal sector, various decisions were adopted, including: the Correos decision; the La Poste press distribution decision; and the Poste Italiane press distribution decision. These last two—which are described at more length in the remainder of this article—provided additional guidance with respect to the application of the net avoided cost methodology to the compensation of public service obligations. The Commission has also been active in the tax field: for instance, adopting decisions in the Gibraltar and UK CFC tax cases, and in banking with the HSH Nordbank decision. In the transport sector, the Athens airport decision and the Helsinki buses decision were adopted, amongst others. In the energy sector, several decisions with respect to the support for renewable energy and combined heat and power (CHP, or co-generation) systems were also adopted. This list is of course not exhaustive. The CET has been mainly involved in cases that are related to transport, energy, regional aid, and banks. In the transport sector, the CET worked with financial models and business plans to assess a wide range of issues, such as the valuation of concession extensions or assessments of the least distortive conditions for such extensions. A significant contribution took the form of applying the market-economy operator principle across various sectors—notably in the context of recapitalisation measures. The CET also contributed to the funding gap analysis—especially for “important projects of common European interest” (IPCEI). The CET also contributed to calculating proportionate amounts of investment or operating aid to regional airports. For “services of general economic interest” (SGEI)—e.g., in the postal or transport sectors—the CET continued to work on the calculation of proportionate compensation for the delivery of “universal” or “public service obligation” (PSO) contracts.",5
55.0,4.0,Review of Industrial Organization,09 October 2019,https://link.springer.com/article/10.1007/s11151-019-09730-5,Recent Developments at the CMA: 2018–2019,December 2019,San Sau Fung,Jenny Haydock,Ian Windle,,Female,Male,Mix,,
55.0,4.0,Review of Industrial Organization,23 September 2019,https://link.springer.com/article/10.1007/s11151-019-09729-y,Economics at the FTC: Quantitative Analyses of Two Chemical Manufacturing Mergers,December 2019,Daniel Greenfield,Bruce Kobayashi,Nathan Wilson,Male,Male,Male,Male,"Roughly 75 Ph.D. economists comprise the bulk of the staff of the Federal Trade Commission’s Bureau of Economics (BE). They are joined by a few financial analysts, roughly a dozen research analysts, and a handful of administrative staff. BE supports the FTC’s two primary missions: competition (antitrust), and consumer protection. The main capacity in which BE serves the Commission is the performance of economic analysis in connection with the Commission’s law enforcement activities (i.e., investigations and litigation). BE’s staff also conduct economic research aimed at refining FTC enforcement decisions and policies, as well as topics that more generally address competition or consumer protection issues. In addition, FTC economists interact with other state and federal government agencies to help provide feedback about laws and regulations that may relate to the FTC’s two missions. Merger review is the modal activity in which BE economists assist in the pursuit of the FTC’s competition mission. In 2018, the FTC entered into consent orders for ten mergers and filed suit in three; and seven transactions that were investigated by the FTC staff were abandoned. The FTC also brought actions in three non-merger antitrust matters in 2018. Consumer protection actions were taken by the Commission in 66 cases that represented a great variety of frauds, privacy violations, and false or deceptive advertising (to name a few).Footnote 1 FTC actions can have significant economic impact—especially for the consumers who have been harmed. For example, in an FTC monopolization case that alleged an abuse of government processes, a federal district court awarded $448 million in consumer monetary relief after finding that drug maker AbbVie illegally used sham litigation to maintain its Androgel monopoly.Footnote 2 And on the consumer protection side, the FTC required that refunds of over $505 million be sent to people who were deceived in the AMG Services/Tucker payday lending scam.Footnote 3 BE economists also participate in and contribute to the larger economics community by regularly publishing original research articles in academic journals, participating in and hosting conferences, and maintaining an active seminar series. In November of 2018, BE hosted the eleventh FTC Microeconomics Conference.Footnote 4 Paper sessions, panel discussions, and keynote addresses focused on topics such as the estimation of markups, strategic supply reduction, extended warranties, consumer protection via occupational licensing, and online privacy. The next FTC Microeconomics Conference will be co-sponsored by Yale University’s Tobin Center for Economic Policy and will be held on November 14–15, 2019 in Washington, DC.Footnote 5 This article discusses the analyses that were performed by BE economists in connection with two FTC merger investigations—both of which involved chemicals but presented quite different economic issues: Sect. 2 considers an FTC investigation of a merger of manufacturers of chloride process rutile titanium dioxide. This is a chemical that is used in paints, plastics, and other final goods. Two aspects of this case that required particularly detailed analysis by economists included market definition—in particular, the determination of whether a different type of titanium dioxide would be a close substitute—and the use of a Cournot oligopoly model to analyze the likely competitive effects of the transaction. Section 3 turns to an action that the Commission took to preserve competition for polyethylene terephthalate (PET) resin that is used to make plastic bottles and other products. The Commission required three PET resin producers to restructure their transaction and agree to other conditions to settle charges that their proposed $1.1 billion joint acquisition of an under-construction PET production facility would violate federal antitrust law. This section discusses the evaluation of potential price effects from a proposed acquisition of a partially constructed plastics plant. This evaluation required a comparison of the possible anticompetitive harms from alternative ownership structures, while accounting for differences in the likelihood and timeliness with which alternative purchasers might finish construction and open the plant.",7
55.0,4.0,Review of Industrial Organization,21 November 2019,https://link.springer.com/article/10.1007/s11151-019-09740-3,"Economics at the FCC 2018–2019: Competition, Broadband Deployment, and Transaction Review",December 2019,Babette Boliek,Kim Makuch,Aleks Yankelevich,Female,,Male,Mix,,
56.0,1.0,Review of Industrial Organization,08 August 2019,https://link.springer.com/article/10.1007/s11151-019-09720-7,Introduction: The Radio Act of 1927 Turns 90,February 2020,Thomas W. Hazlett,,,Male,Unknown,Unknown,Male,,1
56.0,1.0,Review of Industrial Organization,19 February 2019,https://link.springer.com/article/10.1007/s11151-019-09692-8,Populist Antitrust and the 1927 Radio Act,February 2020,Babette E. Boliek,,,Female,Unknown,Unknown,Female,"In policy circles of Washington DC, in academia, and among advocates and lobbyists, there has been growing attention to the role of antitrust enforcement in today’s economy.Footnote 1 Various populist arguments seek an expanded role for antitrust law, as proponents seek to control perceived political and free speech dangers associated with market concentration. These new antitrust populists are particularly interested in large, content-laden companies such as Google, Facebook, and broadcast and cable firms. Strong populist interest in content companies is not new. Different political, economic, and philosophical regimes are at play as some contend that social media, radio, and broadcast firms are businesses like any other and that the laws of competition (antitrust law) will protect consumer interests, and others argue that far more intrusive regulatory controls are required to do the job. Specifically, it is an argument as to whether antitrust laws are sufficient or if regulation—as is today administered by the Federal Communications Commission (FCC)—is necessary to protect consumers, democracy, and free speech. Important to this discussion is that others rely further on the fact that Congress has already designated broadcast and telecommunications as unique by virtue of the Radio Act of 1927, a fact reiterated in the Communications Act of 1934,Footnote 2 and that, therefore, antitrust has already been deemed insufficient to police such unique resources.Footnote 3 The latter contention argues for path dependency: since Congress at the dawn of radio decided to regulate the broadcast industry, it should continue to regulate the broadcast industry. That argument is unresponsive to whether antitrust is better suited than the regulator to police the broadcast industry of the 21st century. But more important for this essay, any path dependency argument must assume that Congress’ decision to regulate radio (or any broadcast or content-laden industry) was based on a conscious, consumer-welfare-driven choice between antitrust law and regulation. The history of the Radio Act reveals something different. In creating the Radio Act of 1927, antitrust was not on the mind of Congress. Indeed, the legislative story is consistent with the historic tendency for government control of content. Second, the story of antitrust versus regulation is less a sober debate between two power centers than it is the history of one man at the heart of both: Herbert Hoover. Hoover’s imprint is on both the development of antitrust law and its lenient application in his day and at the heart of the control of radio licensing. Arguably, Hoover intentionally led radio down a path where regulation and the ever-politically-tempting control of content became inevitable. In the end, the history of the Radio Act of 1927 shows less a disciplined, coherent choice between antitrust and regulation than a drive by Herbert Hoover and others to regulate the radio industry. Moreover, the ensuing tendency to first regulate content-based industries by analogy to radio—television broadcast, then cable, and yes, even Internet transmissions—demonstrates that path dependency in content regulation is powerful.Footnote 4 The regulatory lessons of yesterday, therefore, may prove to be powerful inputs for the regulatory choices of today, if we choose to learn them. The choice of antitrust over regulation at the dawn of radio may not have led to a different technological landscape than what we have today, but it might well have gotten us there faster with far more “voices” heard along the way. To examine the antitrust versus regulation choice, Part 1 of this essay describes the different motivation for both regimes. Part 2 and Part 3 examine the “Hoover Connection”: Part 2 examines the state of antitrust law in the 1920s and Herbert Hoover’s heavy imprint. Part 3 provides some historic background on the radio industry—in particular, how Herbert Hoover set the stage for regulation. I argue that antitrust was capable of protecting consumer interests but its impact had been minimized by the forceful ideology held by Herbert Hoover. Moreover, the historic preference of political elites to control new forms of content was almost impossible to resist in the licensing chaos encouraged by Hoover. One lesson to be drawn is clear: if free speech (free of government control) and consumer welfare are to be taken seriously, then modern-day choices to regulate nascent content-laden technologies should not be bound by historic choices. As set forth below, historic choices may sometimes lie more in the cult of personality and political opportunism than in balanced consideration of freedom and consumer welfare.",1
56.0,1.0,Review of Industrial Organization,10 June 2019,https://link.springer.com/article/10.1007/s11151-019-09707-4,The 1927 Radio Act as Pre-emption of Common Law Property Rights,February 2020,Thomas W. Hazlett,,,Male,Unknown,Unknown,Male,"[T]his Act is intended to regulate all forms of interstate and foreign radio transmissions and communications within the United States… and to provide for the use of such channels, but not for the ownership thereof, by individuals, firms or corporations, for limited periods of time, under licenses granted by Federal authority, and no such license shall be construed to create any right, beyond the terms, conditions, and periods of the license. So reads the first sentence of H.R. 9971 from the 69th Congress: the 1927 Radio Act. Signed into law by President Calvin Coolidge on February 23, 1927, the statute created a new governance scheme for spectrum use under a Federal Radio Commission (FRC). That agency was rolled into a newly constituted Federal Communications Commission (FCC) in 1934, with statutory language that was virtually a word-for-word copy of the 1927 Act. The FCC continues—90 years later—to determine how spectrum rights are defined and allocated; the Commission shapes wireless networks, devices, services, applications, and markets. Such supervision employs “public interest, convenience or necessity” as the legal standard for decision-making; this supervision bars the assertion of property rights in frequencies, as seen above. The policy that was adopted in 1927 has been widely described as a necessary response to the facts of nature. Framing the conventional wisdom, the U.S. Supreme Court has stated: “Before 1927, the allocation of frequencies was left entirely to the private sector, and the result was chaos. It quickly became apparent that broadcast frequencies constituted a scarce resource whose use could be regulated and rationalized only by the Government” (Supreme Court, 1969; see also Supreme Court 1943). The logic was that endemic market failure would ensue were government not to extensively manage access to airwaves. The confusion would lead to a “cacophony [sic] of competing voices.”Footnote 1 This rationale for regulation triggered important developments in spectrum law and in economic theory. The latter flowed from Coase’s (1959) response to the view that radio transmissions could be efficiently organized only by central authority. He surmised that such coordination might alternatively be provided by individual frequency rights owners, and that whether such a system would prove superior would depend on circumstances. This comparative approach, developed in thinking about spectrum allocations, was then generalized in a highly influential critique of A.C. Pigou’s theory of market failure in welfare economics (Coase 1960). This article focuses on spectrum law, however. It was argued by Coase that the 1927 Act—and the property rights regime that ensued—was simply an error. Policy makers did not understand that government regulation might not be the most productive mechanism for preventing the tragedy of open access. Policy makers of the 1920s did not, however, see any alternative to administrative allocation. This paper examines legal and marketplace events in the 1920s radio market, including retail sales data and the stock price performance of the Radio Corporation of America (RCA), the leading maker of radio receivers. We deduce evidence that wireless markets developed prior to the 1927 Radio Act. A legal framework supporting the emergence of radio broadcasting came in the form of priority-in-use spectrum rights. The “public interest” licensing law that was adopted in 1927 over-ruled this regime; this outcome was purposefully pursued by a political coalition of commercial and political interests. The cause-and-effect provides a public choice explanation of the 1927 Radio Act and the origins of U.S. radio spectrum policy.",2
56.0,1.0,Review of Industrial Organization,01 October 2018,https://link.springer.com/article/10.1007/s11151-018-9665-5,Radio “Fences” and Inventor Attention to Property Rights: Evidence from Wireless Patents,February 2020,Sarah Oh,,,Female,Unknown,Unknown,Female,"Do spectrum property rights help or hurt innovation? Scholars debate whether open commons or flexible licenses better serve ecosystem growth. In developing a theory of innovation, empirical evidence can help explain how inventors respond to property rights. The 90th anniversary of the Radio Act of 1927 seems an appropriate time to consider this interaction of innovation and policy on the radio waves.",
56.0,1.0,Review of Industrial Organization,22 February 2019,https://link.springer.com/article/10.1007/s11151-019-09695-5,Spectrum Concentration and Performance of the U.S. Wireless Industry,February 2020,Glenn A. Woroch,,,Male,Unknown,Unknown,Male,"Since the birth of the U.S. cellular industry, policy makers have allocated radio spectrum with the aim to limit concentration in the downstream mobile services market. To promote this competition, the Federal Communications Commission (FCC) has used its authority to ensure that commercial airwaves did not end up concentrated among a few owners. Similarly, antitrust authorities have been wary of threats to competition posed by aggregation of radio spectrum. The anticompetitive use of spectrum licenses was foreseen as far back as the Radio Act of 1927, which cautioned against issuing broadcast licenses that could be used “to substantially lessen competition or to restrain commerce.”Footnote 1 More recently, the Department of Justice expressed concern that incumbent wireless carriers could acquire spectrum licenses for the purpose of foreclosing new entrants or constraining smaller rivals.Footnote 2 The economic underpinnings of these spectrum policies can be traced to the conventional structure–conduct–performance paradigm of industrial organization. The Commission’s spectrum policies are consistent with the proposition that poor performance is a likely consequence of concentration in the supply of mobile services, and further, that structural concentration that is measured in terms of subscriber market shares is inherited directly from concentration in spectrum holdings.Footnote 3 This paper tests this causal chain empirically by estimating the relationship between spectrum concentration and mobile subscription penetration where subscriptions serve as the measure of consumer welfare. Using reduced-form regressions on a 2012–2013 cross-section of approximately 700 U.S. Cellular Market Areas (CMAs), an inverted-U relationship between the two variables emerges. In addition, the marginal effect of spectrum concentration is positive in the sampled markets—contrary to the conventional concentration-performance hypothesis. The vast majority of CMAs in 2012–2013 have spectrum HHIs that lie in the increasing portion of the inverted-U—which suggests that consumer benefits would be sacrificed if steps are taken to reduce spectrum concentration in those markets. Before we turn to the econometric analysis, a couple of simple scatterplots offer a preview of these results. The scatterplot in Fig. 1 shows the relationship between spectrum concentration and subscriber penetration by CMA. Spectrum concentration is measured by the Herfindahl–Hirschman Index (HHI) of operators’ shares of spectrum holdings, and subscriber penetration is given by an estimate of the percentage of adults that subscribe to a mobile wireless service. Both variables are expressed as residuals after they have been regressed on a suite of control variables that will be described below. Figure 1 shows little relationship between spectrum concentration and subscriber penetration. Additionally, a locally weighted estimation of smoothing scatterplots (LOWESS) curve suggests an inverted-U pattern between the two variables that will be explored in regression models below. Residuals for spectrum HHIs and penetration rates The same type of scatterplot was created using residuals for subscriber HHIs and spectrum HHIs by CMA. The resulting plot in Fig. 2 does not show a clear relationship between the two concentration measures—after “partialling out” the same set of control variables.Footnote 4 It suggests that attempts to deconcentrate spectrum holdings do not mechanically reduce concentration in the mobile wireless industry. Residuals for subscriber and spectrum HHIs It has often been argued that, because of attractive propagation characteristics, spectrum bands below 1 GHz convey competitive advantages on its licensees. This assumption has guided Commission policy that governs the assignment of mobile spectrum in these lower bands.Footnote 5 To examine this proposition, the concentrations of license holdings above and below 1 GHz are separately measured for each CMA market. For the most part, the same pattern appears—which casts doubt on claims that aggregation in those bands harm industry performance. Another claim that shapes federal spectrum policies is based on a belief that consumers who are located in sparsely-populated rural areas are especially vulnerable to spectrum concentration in those markets. Certainly, the higher costs of infrastructure deployment result in fewer wireless carriers that serve those markets, and a correspondingly high concentration of spectrum holdings. The FCC takes steps to counteract aggregation of spectrum in rural areas, as when it recently provided spectrum bidding credits to small businesses and rural telephone companies in the incentive auctions. The regression results will show that the urban and rural areas alike display an inverted-U relationship between spectrum concentration and subscription penetration. In the meantime, Figs. 1 and 2 suggest little or no relationship depending on whether the CMA is urban or rural. In those scatterplots, urban CMAs are indicated by circles and rural CMAs by triangles. To the naked eye, the two types of markets exhibit no clear relation between spectrum concentration and subscription penetration. Reduced-form concentration-performance regressions are well known to be infected by endogeneity, and that concern arises here. In the present case, the concentration in spectrum holdings in certain areas may be determined by unobserved factors that simultaneously affect mobile subscriptions in those same areas. Absent a valid instrument for spectrum concentration, techniques of treatment effects are applied where here different levels of spectrum concentration serve as a continuous treatment across markets. Regression-adjusted treatment regressions continue to affirm the inverted-U relationship that emerged from the reduced-form regressions. What explains the relationship between spectrum concentration and industry performance that contradicts the usual industrial organization paradigm? One potential answer follows from Demsetz’s (1973) challenge to the concentration-performance orthodoxy: He proposed that industry concentration could be a product of efficient operation and desirable products of a select few firms. This alternative explanation is tested by examining how carriers’ market penetration rates are related to various metrics of network quality and coverage. These regressions show a strong correlation between fast, reliable data transmissions as well as coverage of 4G wireless technologies, and subscription to carriers’ services. In addition, the measures of network quality and coverage are in turn directly related to local aggregation of spectrum holdings. This latter finding suggests that the spectrum held by the largest carriers was combined with complementary investments to deliver better service to consumers. The next section, Sect. 2 reviews the existing literature that explores empirically and theoretically the relationship between spectrum concentration and industry performance. This review suggests a reduced-form cross-sectional model. Section 3 describes the data that were collected to estimate this relationship. Section 4 presents the main regressions of market-wide and carrier-specific penetration rates on spectrum concentration. In this section we also explore hypotheses about concentration in low-frequency bands and in rural markets. Section 5 addresses the possibility that spectrum concentration is endogenous and concludes that the main findings are unchanged. Section 6 investigates how high-quality service rewards mobile operators with higher subscription rates relative to those with relatively poor service. Section 7 concludes by examining the merits of policies that are aimed at non-spectrum factors to foster competition and benefit consumers.",3
56.0,1.0,Review of Industrial Organization,04 January 2019,https://link.springer.com/article/10.1007/s11151-018-09676-0,Interactions Across Firms and Bid Rigging,February 2020,Mats A. Bergman,Johan Lundberg,Johan Y. Stake,Male,Male,Male,Male,"Early on October 24, 2001, the Swedish Competition Authority (SCA) conducted unannounced raids on a number of companies in the Swedish asphalt paving industry; the purpose was to find documents that could verify suspicions of illegal collusive bidding on public contracts.Footnote 1 In 2003, nine firms were convicted for collusive bidding in the Stockholm District Court. The convicted firms appealed the decision to the Market Court, which confirmed the District Court’s decision on July 10, 2007. Based on data on public procurements of asphalt paving before and after the raids in 2001, the main objective of this paper is to show how an econometric method that is influenced by the spatial econometric literature (see Anselin 1988; Anselin and Bera 1998; LeSage and Pace 2009; Gibbons et al. 2015)Footnote 2 can be used to confirm collusive bidding before the raids in 2001 and reject such behavior during a period after the first court order in 2003. Following Gibbons et al. (2015) spatial data consists of observations located in some space. In this paper the unit of observation is the bid and the space is the specific auction, which places our approach in the class of spatial models that are often applied on social networks. The access to data after the cartel members were convicted constitutes a good testing ground for the suggested method and at the same time for the efficacy of litigation in stopping the collusion. The parameter of interest in the empirical model can be interpreted as the slope of reaction curves between firms that place bids on the same contract. This follows broadly the same principle as in Bajari and Ye (2003): That in the absence of collusive bidding and after controlling for publicly available information, bids placed by one firm should be uncorrelated with bids placed by all other firms.Footnote 3 Our results indicate collusive bidding among cartel members before 2002, while the relevant parameter is insignificant, and its variance differs in magnitude after 2003—which is consistent with non-collusive bidding. This suggests a structural change in bidding behavior among cartel members between the cartel and post-cartel periods and, hence, that the litigation caused the cartel to cease its activities. We argue that our approach—given some priorFootnote 4 on where to look for suspicious behavior—can be used to corroborate cartel suspicions. The method is relatively simple; it requires only a minimal amount of data. If this method shows significant dependence of bids among a group of suspected bidders while insignificant and different dependence across the other bidders, competition authorities could decide to proceed with further investigations. To our knowledge, spatial econometrics techniques have never before been used to test for collusion in the way that is proposed in this paper. The advantage of our suggested approach is the applicability to various auction designs, the modest data requirement, and the simple estimation techniques—as compared to tests that have been used previously. This paper also serves as a complement to previous studies that, for the most part, are based on U.S. data and from the cartel period only. Two limitations—which we share with the vast majority of the existing literature on cartel detection—are that: (1) the investigator needs a relatively specific hypothesis with respect to which firms are involved in the cartel; and (2) the competition authority will need accompanying evidence for a charge to hold up in court. See Harrington (2008) and Abrantes-Metz and Bajari (2009) for surveys. The rest of this paper is organized as follows: Sect. 2 provides an overview of the existing literature; it is followed in Sect. 3 by a description of the procurements studied. Section 4 presents our data, and the econometric setup and specification are presented in Sect. 5. The results are presented and discussed in Sect. 6, with concluding remarks provided in Sect. 7.",12
56.0,1.0,Review of Industrial Organization,11 January 2019,https://link.springer.com/article/10.1007/s11151-019-09678-6,When Multiple Merged Entities Lead in Stackelberg Oligopolies,February 2020,Walter Ferrarese,,,Male,Unknown,Unknown,Male,"In homogeneous linear symmetric Cournot–Nash (CN) oligopolies, mergers are profitable only under the unrealistic condition that the firms that account for, at least, the 80% of the market participate (Salant et al. 1983, SSR henceforth). Moreover, even for profitable mergers, remaining outside—being an outsider—is more beneficial than participating—being an insider—. This result is commonly known as the free-riding effect and was also previously detected by Stigler (1950). In this paper I discuss scenarios where a single entity or multiple merged entities acquire the right to become the leader in an otherwise symmetric CN oligopoly. My model mainly refers to Liu and Wang (2015, LW henceforth), who show that a single leading entity can profitably merge with an arbitrary number of firms; but they neglect the possibility that a firm can obtain an even larger payoff by not participating. First I study the case of a unique leading entity and show that the profitability and the free-riding issues can both be solved only if the number of participants to the merger is sufficiently low; second, I step beyond LW (2015) by studying markets with multiple leading entities, which are allowed to be heterogeneous in the number of insiders. I show that the transition from a simultaneous to a sequential quantity-setting industry can often generate welfare improvement, even in absence of cost synergies. This contrasts with the main result in Farrell and Shapiro (1990), where mergers that generate no synergies unambiguously increase price and reduce consumer surplus. This is due to the fact that—despite a lower post-merger number of firms and despite the fact that a follower produces less than does a CN firm—the production of the leading entity/ies is large enough to offset both of these negative effects. The acquisition of the leadership following a merger is (as in LW 2015) taken as given. This assumption tries to accommodate some real-world features, which however are not included in my model. For instance, the leadership acquisition may occur because of large enough economies of scale or scope (Farrell and Shapiro 1990; LW 2015) or because a merger facilitates the flow of information among the merging parties (Huck et al. 2004). Finally, despite its theoretical nature, it is possible to find industries whose features are in line with those of this paper. An example—as suggested by Escrihuela-Villar and Faulí-Oller (2007) and Cunha and Vasconcelos (2015)—is the DRAM industry: where multiple mergers are widely observed and where firms are endowed with different strategic power. In particular, the leading manufacturers set their production before other manufacturers enter the market and the former adjust their production in accordance. The paper is structured as follows: in Sect. 2, I present the related literature; in Sect. 3, I analyze markets with a unique leading entity. In Sect. 4, I extend the analysis to the case of multiple heterogeneous leading entities. Section 5 provides a welfare analysis. Section 6 concludes. All proofs are in the “Appendix”.",2
56.0,1.0,Review of Industrial Organization,23 February 2019,https://link.springer.com/article/10.1007/s11151-019-09696-4,"A Comparison of Electricity-Pricing Programs: Economic Efficiency, Cost Recovery, and Income Distribution",February 2020,Ming-Feng Hung,Bin-Tzong Chie,Huei-Chu Liao,,Unknown,Unknown,Mix,,
56.0,1.0,Review of Industrial Organization,05 March 2019,https://link.springer.com/article/10.1007/s11151-019-09699-1,New Business Formation and Incumbents’ Perception of Competitive Pressure,February 2020,Javier Changoluisa,Michael Fritsch,,,Male,Unknown,Mix,,
56.0,2.0,Review of Industrial Organization,16 August 2019,https://link.springer.com/article/10.1007/s11151-019-09721-6,Introduction: Firms with Behavioral Biases,March 2020,Victor J. Tremblay,Mo Xiao,,Male,,Unknown,Mix,,
56.0,2.0,Review of Industrial Organization,31 July 2019,https://link.springer.com/article/10.1007/s11151-019-09722-5,"Firms’ Beliefs and Learning: Models, Identification, and Empirical Evidence",March 2020,Victor Aguirregabiria,Jihye Jeon,,Male,Unknown,Unknown,Male,"Firms have uncertainty about current and future realizations of demand, costs, market regulations, and/or the behavior of competitors. They may learn about these elements over time, and this learning process can have substantial implications for their profits and market efficiency. For example, firms may gather better information and use it in their pricing, entry, and investment strategies to improve their profits and the probability of survival in the market. In today’s economies, big data and learning algorithms are becoming important inputs in many industries.Footnote 1 The assumption of rational expectations has been the status quo to represent agents’ beliefs in many areas in economics, and in particular in industrial organization. Rational equilibrium models of competition incorporate two basic assumptions: Firms form beliefs about uncertain demand, costs, and the behavior of competitors, and given their beliefs the firms maximize expected profits; and firms’ beliefs coincide with the actual probability distribution of demand, costs, and competitors’ behavior, i.e., rational equilibrium beliefs. The assumption of rational expectations has the attractive feature that beliefs are endogenously determined in the equilibrium of the model. It also provides econometric identification of belief functions. Nevertheless, this assumption is frequently criticized for ignoring that information acquisition and processing is costly (e.g., Pesaran 1987; Manski 2004). In reality, firms often face significant uncertainty about their rivals’ strategies. Firms are different in their ability for collecting and processing information—for similar reasons as they are heterogeneous in their costs of producing goods. As a result, firms are also heterogeneous in their degree of uncertainty and in their speed of learning. The importance of firms’ heterogeneous expectations and the implications for firms’ performance and market outcomes have been long recognized in economics, at least since the work of Simon (1958, 1959) and his debate with Muth (1961) on the relative merits of adaptive/behavioral expectations versus rational expectations. However, it has not been until recently that this behavioral approach has received substantial attention in structural models in empirical industrial organization. Part of the reason is that the joint identification of firms’ beliefs and structural parameters in payoffs is more challenging when we relax the assumption of rational expectations. Nevertheless, the combination of better data, identification strategies, and econometric techniques has made possible the recent developments in structural models of competition with boundedly rational firms. An active research area in economics has consisted in modeling firms’ beliefs—allowing for their endogeneity but relaxing the assumption of rational expectations. A goal in this literature is to develop useful models that allow for heterogeneity in firms’ information and that incorporate the process through which firms acquire knowledge about the environment by searching and processing information and ultimately learning. In industrial organization—based on the seminal work of Jovanovic (1982)—there has been work in the development of theoretical models of industry dynamics with Bayesian learning. Macroeconomists have incorporated Bayesian learning (e.g., Evans and Ramey 1992) and adaptive learning (e.g., Sargent 1993, and Evans and Honkapohja 2001, 2012) in dynamic general equilibrium models, and have established conditions for convergence to a rational expectations equilibrium (e.g., Marcet and Sargent 1989a, b). In experimental economics, there is evidence on players’ non-equilibrium beliefs from games played in laboratory experiments (e.g., Van Huyck et al. 1990; Heinemann et al. 2009). Behavioral and experimental economists have also developed non-equilibrium models of endogenous beliefs (e.g., the Cognitive Hierarchy model by Camerer et al. 2004, and the Level-k rationality model by Costa-Gomes and Crawford 2006, and Crawford and Iriberri 2007) and learning in games (e.g., experience-weighted attraction learning by Camerer and Ho 1999), and they have estimated structurally these models using data from laboratory experiments. In microeconometrics, there is a large body of work on measuring expectations and using expectations data to relax or validate assumptions about beliefs (Guiso and Parigi 1999; Manski 2004, 2018; Pesaran and Weale 2006; Bover 2015). Building on these literatures, there has been an increasing interest in empirical industrial organization in the development and estimation of structural models of market competition where firms have non-equilibrium beliefs and try to learn over time, with potentially different degrees of success. Motivated by this interest, there has been also work in the econometrics of games and on the identification of beliefs and payoffs in non-equilibrium models. This paper reviews this recent literature. In the context of games, firms’ learning is related to the game’s information structure and how this structure evolves over time. In games with learning, biased beliefs can evolve endogenously to become equilibrium beliefs, and an incomplete information environment may converge to complete information. Learning is also related to multiplicity of equilibria in games. In a model of competition with multiple equilibria, firms are engaged in an adaptive process where they learn how to play an equilibrium of the game (Fudenberg and Levine 1998; Fershtman and Pakes 2012). The specification of a learning process can allow researchers to identify an equilibrium selection mechanism, and this can be an attractive solution to deal with the problem of multiple equilibria in comparative statics exercises using these models (Lee and Pakes 2009). In the learning literature that we review in this paper, agents (firms) know the model that describes the environment but they have uncertainty about some elements of this environment. Agents may learn over time about these elements when new information arrives. This type of model contrasts with the approach in evolutionary game theory to represent learning (Samuelson 1998). Models in evolutionary game theory do not assume that players know the nature of the game, or even that they know that they are playing a game. These models do not specify any particular element that is the object of agents’ learning. Instead, evolutionary games in economics consider that agents’ actions (strategies) are driven by imitation, either of other agents or of their own behavior in situations that they perceive as similar. Though our paper does not review this important literature, in Sect. 2.2, we discuss the relationship between reinforcement learning algorithms and the concept of learning in evolutionary games. The theoretical and empirical literature on firms’ learning is large and spreads over multiple areas in economics. In this paper, we focus on a specific part of this literature that deals with empirical applications of structural games of oligopoly competition that allow for firms’ non-equilibrium beliefs. There are several recent surveys that cover related topics but with different emphases. Heidhues and Köszegi (2018) provide an excellent survey on behavioral industrial organization with special emphasis on models of consumer demand (see their section 6 that covers supply models). Crawford et al. (2013) review the theoretical and empirical literature of structural models of non-equilibrium strategic thinking in experimental economics, with a focus on evidence from laboratory experiments, but with some discussion of the more scarce evidence from field data. Ching et al. (2017) review the marketing literature on dynamic structural models with Bayesian learning that has concentrated on consumer demand but has some applications to firms’ learning (see their Sect. 4). Goldfarb et al. (2012) provide a brief discussion of recent empirical applications of structural non-equilibrium games. Borkovsky et al. (2015) examine several methodological topics in empirical games of oligopoly competition, including firms’ biased beliefs and learning. Beyond the topic of biased beliefs and learning, there is a growing interest in empirical research on structural behavioral models. The recent survey by DellaVigna (2018) provides an excellent review of this literature that includes important methodological aspects on modelling, identification, estimation, and sensitivity analysis. The rest of the paper is organized as follows. Section 2 presents a model of competition with firms’ learning that incorporates the main features in the empirical applications that we cover in this paper. In Sect. 3, we discuss different types of data and identification strategies. Sect. 4 reviews recent empirical applications. We conclude in Sect. 5.",12
56.0,2.0,Review of Industrial Organization,26 September 2019,https://link.springer.com/article/10.1007/s11151-019-09727-0,"Almost‐Maximization as a Behavioral Theory of the Firm: Static, Dynamic and Evolutionary Perspectives",March 2020,Huw Dixon,,,Male,Unknown,Unknown,Male,"Perfect rationalityFootnote 5 has been the approach that has been adopted by most economics for over a century. A stereotypical perfectly rational agent has the ability to calculate the answer to any well‐defined problem. The agent has a well‐defined objective function that enables the best solution to be identified from a given range of possibilities. An objective function should be able to rank all possible outcomes in a way that is transitive (or at least acyclic). Choice is subject to some constraint: for example, a budget constraint or a technological constraint. Uncertainty can be introduced if there is a known probability distribution and the objective function satisfies the Von Neumann‐Morgenstern properties. In its simplest form, we can think of agent utility as defined over a vector x, \( U:\Re^{n} \to \Re \), where x is chosen from some compact convex set S. The agent then solves: The set S may itself be determined by some parameters (prices and income in the case of the budget set). The solution to the problem is a choice of action x* and resultant utility U*; both can be seen as depending on S. In the case of the consumer, the budget set is determined by prices and income: Indirect utility identifies the maximum utility given prices and income. The Marshallian demand is the optimal choice of consumption given prices and income. The supply and input‐demand functions of competitive firms are likewise determined. Now, let us see under what external circumstances this sort of behavior might arise in a firm. Perfect competition is the market structure that would lead to this sort of firm behavior. With free (zero cost) entry, (supernormal) profits will be zero in the long‐run. Firms that do not minimize costs and maximize profits will not survive against maximizers. In this textbook scenario, profit maximization is required for survival (except perhaps in the case of an owner manager who is willing to subsidise the firm out of other income). Since profit maximization is required for survival, there is no discretion for managers; and bounded rationality is not possible in the long run (unless, perhaps, in the special case where it is universal across all firms). We can think of almost-correct choices in terms of two metrics: the closeness of the payoff relative to the optimal payoff; or alternatively the closeness of the action to the optimal action. Under certain assumptions, these two metrics are equivalent; but they need not be. Consider first the case of an action: The idea here is analogous to the “trembling hand” of equilibrium refinements in game theory, which were first introduced by Selten (1975). The agent tries to implement the optimal action x* but by a mistake in execution chooses some other action. We might want to say that the mistake in action is “close” to the optimal action. That means that with an appropriate metric M, the chosen action x ‘ is within a distance \( \kappa \) of x*Footnote 6: The fact that the error might be “small” when measured in the metric M need not imply that the loss in utility is small. For example, in an Olympic final, a small error can give rise to a huge difference in utility (e.g., Bronze instead of Gold). However, a small error in action that gives rise to a big loss can occur only if there is a discontinuity in the objective function. If we make the standard assumption that the payoff function is continuously differentiable for at least the first two derivatives,Footnote 7 then we can ensure that small mistakes in the implementation of the strategy will give rise to small losses in payoff. Put simply, if U is continuously differentiable, then for any \( \varepsilon > 0 \), there exists \( \kappa > 0 \) such that: if \( \kappa > M\left( {x^{{\prime }} ,x^{*} } \right) \), then \( U\left( {x^{*} } \right) - U\left( {x^{{\prime }} } \right) < \varepsilon \) We can go further and think of this as defining the distance \( \kappa \) as an (increasing) function of \( \varepsilon :\kappa = \kappa (\varepsilon );\;{\text{d}}\kappa /{\text{d}}\varepsilon > 0 \): If we want the loss in terms of payoff to be smaller than a certain level, then we need the strategy to be sufficiently close to the optimal strategy.Footnote 8 Can we go in the other direction and claim that if the action is close in terms of payoff, then the action must be close to optimal? If the payoff is strictly concave, then the answer is yes, since there can be only one local maximum, which is the global maximum. If there is have weak concavity or even some convexity, then there can be local maxima that are close to the global maximum in terms of payoff but a long way away in terms of action. Think of two hills that are separated by a valley; hill A is slightly taller than hill B. We can be almost as high as the summit of A by being close to the summit of A or by being across the valley near the top of summit B. The valley is the convexity. If we assume strict concavity, then there is in effect only one hill and no local maxima other than the global maximum.",4
56.0,2.0,Review of Industrial Organization,18 November 2019,https://link.springer.com/article/10.1007/s11151-019-09737-y,Managerial Payoff and Gift-Exchange in the Field,March 2020,Florian Englmaier,Stephen Leider,,Male,Male,Unknown,Male,"Firms must regularly address the problem of providing incentives to employees when actions are not at all or hardly contractible. The standard approach in economics has been to focus on analyzing the optimal explicit incentive schemes: tying the level of the worker’s compensation to the amount of output produced, which serves as a (noisy) measure of employee effort.Footnote 1 However, the importance of fairness and social preferences—especially for the work relationship—has long been documented. Starting with Akerlof (1982), a literature has developed that considers gift-exchange as an alternative source of incentives in the workplace. According to this gift-exchange theory, firms can induce above-minimal effort from agents—even in the absence of explicit pay-for-performance incentives—since such-inclined agents may reciprocate generous wage payments with higher effort exertion: a positive wage-effort relationship takes effect as workers repay the initial “gift” of a generous wage with a “return gift” of above-minimum effort. Recently there have been conflicting results on the significance of gift-exchange as a motivating force outside of the lab. While some papers have found a robust pattern of gift-exchange in field settings, others have failed to find the positive relationship of initial and return gift at all or have documented only effects that persist for very short periods; cf. DellaVigna et al. (2016). The varying effectiveness of gift-exchange in different settings suggests that the efficacy of gift-exchange incentives depends on details of the environment. We add to this research by providing results that suggest an avenue to reconcile those findings: In our field experiment we do not find evidence for an overall positive effort response merely from an initial wage gift. However, the gift’s efficacy is substantially improved if the manager benefits more strongly from a worker’s high effort. That is, gift-exchange can induce effort if workers are able to repay the gift to the manager. Moreover, we document that gift-exchange works more effectively with subjects that we classify as reciprocal via a personality test,Footnote 2 and that the efficacy of gift-exchange does not dissipate over the course of the experiment. We conclude from our results that while gift-exchange may not be effective as an incentive in all settings, it can be a powerful incentive device in the proper job context: such as in our setting when managers have performance-related incentives, and when it is directed to the right employees, who are most likely to be reciprocal. For our field experiment we hired temporary workers for a data entry job.Footnote 3 The workers entered historical data from the 1849 Prussian Census. In total we had 59 workers entering data during a five hour shift in the Harvard Business School computer lab where the data entry took place. The job was advertised to the worker by a temp worker agency at the standard hourly wage of $13; however for 30 of the workers we increased the hourly wage to $18 upon their arrival. We explained to all of the workers that we were hired by two professors to organize the entry of these data. For 15 workers in each of the $13 and the $18 groups we emphasized the importance of them working hard for us by explaining that we would receive a bonus of 50% if the job was done ‘by the end of the week’ (Bonus treatment). For the ‘control’ groups in both of the $13 and the $18 conditions we did not inform the workers of this bonus (No Bonus treatment). We also asked the workers to fill out a short version of the “Big 5” personality test, to give us a measure of non-cognitive skills.Footnote 4 In line with previous field experiments, we do not find an effort increase in response to the higher wage in the No Bonus treatment. However, for the workers in the Bonus treatment, a higher wage leads to a significant increase in worker output. Hence, there is a strong complementarity between the wage gift and the resulting payoff for the manager.Footnote 5 Furthermore, when we separate workers based on their agreeableness (a personality trait associated with standard lab measures of reciprocity), we find that the positive effect of high wages on effort is driven entirely by highly agreeable (strong positive reciprocity) workers, with low reciprocity workers showing either a zero or a negative response to a higher wage. We consider the finding that the strength of gift-exchange is positively correlated with measures of reciprocal inclination as absolutely necessary to lend credibility to gift-exchange based explanations of motivation in the labor market. Though apparently obvious, to the best of our knowledge this study was, at the time of writing it in 2007/08, the first to document this fact in the field. We also examine the strength of the gift-exchange response over time. In contrast to other studies, e.g. Gneezy and List (2006), we find no weakening of positive responses to wage gifts over time. To the contrary, any negative effects of the wage gift disappear in the later stages of the task, and we find an overall strongly positive effect of our treatment manipulations in the second half of the experiment. We use two different measures of effort in our analysis: gross data entered, and an error-corrected measure of data entered. The estimates that were derived from these two measures are qualitatively and quantitatively very similar, which suggests that any effort responses work along the quantity margin only; the responses leave the quality margin of effort unaffected.Footnote 6 We can rationalize these results with an agency model that captures reciprocal preferences, where we show that there is complementarity between gift and ability to repay the gift. In the model a risk-neutral firm hires a risk-averse worker to exert non-contractible effort. The novel feature of the model is that the worker is reciprocal: the worker’s utility increases in the principal’s profit whenever the worker receives a rent in excess of his outside option. Thus, when the firm is generous to the worker by giving him additional compensation, the worker desires to provide in turn something of value to the firm. The worker’s reciprocal attitude can now be used by the firm to align the worker’s preferences with those of the firm, which thus generates intrinsic motivation. The comparative statics show that ceteris paribus the worker’s optimal effort choice increases in the initial wage gift and his ability to repay the gift. The corresponding cross derivative is also positive, which indicates the complementarity of the instruments. An extensive body of evidence has developed that demonstrates reciprocal behavior and gift-exchange in laboratory experiments. Fehr and Gächter (2000) summarize results from earlier studies and highlight several key results: (i) Average wages in the experiments are above the minimal wages and leave workers with rents; (ii) There is a positive wage-effort relationship; and (iii) These results are robust to various institutions, to competition, and to high stakes.Footnote 7 The laboratory experiment by Hennig-Schmidt et al. (2010) is closely related to our paper. Hennig-Schmidt et al. (2010) present a real-effort laboratory experiment and show that a positive wage-effort relation as implied by gift-exchange prevails only if information on the manager’s surplus is provided to the experimental workers. This indicates—as is predicted by our model—that the manager’s surplus is an important determinant of the effectiveness of gift-exchange relations. Note, however, that Hennig-Schmidt et al. (2010) do not vary the surplus accruing to the manager nor do they collect the additional information necessary to test our hypotheses. It is beyond the scope of this paper to give a comprehensive overview of the vast set of excellent papers on gift-exchange that have been written in the last decade. See DellaVigna et al. (2016) or Esteves-Sorenson (2018) for excellent overviews of this literature. These two papers also address the controversial discussion about the validity of the lab results for gift-exchange in the field. We take the mixed findings of these field studies as evidence that the efficacy of gift-exchange depends on subtle details of the field situation. While Falk (2007) finds strong evidence for gift-exchange in a field experiment with charitable donations, Gneezy and List (2006) argue that the effect of gift-exchange in the field is only minor, fast disappearing, and overall not a viable employment strategy. In Gneezy and List, students are hired for a day job in a library, and half of them get a surprise rise of their hourly pay. Gneezy and List document that, other than in our field experiment, there is only a short lived effect of this gift on the students’ effort. Overall the ‘firm’ would have fared better hiring more students for the lower wage rate. Kube et al. (2013) replicate the Gneezy and List study and also find no effect of a wage gift but document a strong negative effect in response to a wage cut. In a comparable design, Kube et al. (2012) document a strong positive effect of non-monetary gifts, such as wrapped thermos bottles, on students’ effort. Note that in neither of these cases were the subjects given any indication that the manager who provided the higher wage would benefit directly from increased productivity and the performed jobs were not ones where an employee would expect such a compensation structure. Becker et al. (2012) study a field experiment where a random sub-sample of participants in the Swiss Labor Force Survey received vouchers for training courses. The authors find evidence for long-term (six months) gift-exchange, as voucher recipients are more likely to participate in future survey waves. As the authors can track actual voucher redemption, they are able to document that this long-lasting gift-exchange relationship is most pronounced for the sub-group that had redeemed their vouchers. In light of the above studies, the current study makes two contributions: On the one hand, as we also elicit measures of ability and personality traits, we were in 2007/2008 (to the best of our knowledge) the first to document the heterogeneity of the effect of gift-exchange across different types of employees. On the other hand, we add to the two “standard” features of a gift-exchange experiment—a surprise higher wage offer and the possibility for the worker to reciprocate by exerting more effort—the information that the task matters to the researchers and that the “managers” stand to benefit from a job that is well done by receiving a bonus. Hence, we believe, the fact that gift-exchange is supposed to be at work is very salient for the workers. This, in turn, offers a good reason for why the initial wage gift is given and what the appropriate reaction to the gift is. In some of the above studies this is clear to employees due to the circumstances, but sometimes it is not [as in Gneezy and List (2006) where the wage increase comes as a surprise]; hence it is not clear why subjects should be contextually aware of the fact that they are engaged in a gift-exchange relationship and that exerting more effort is in fact appropriate. 
Bellemare and Shearer (2009) analyze gift-exchange within a real firm (where the value of output is clear to the workers). In their study, there is a surprise bonus for the workers in a tree planting firm in British Columbia. Their results indicate a 10% increase in worker productivity on average which slowly dwindles. Moreover the effect of the gift is more marked if the worker has been with the firm for longer. Hence, Bellemare and Shearer argue that spot-market field experiments only establish a lower bound of the effects of gift-exchange in real firms that are characterized by longstanding and ongoing relations that amplify the effects. Based on data from the same firm, Bellemare and Shearer (2011) develop a structural behavioral model to identify a worker’s optimal response to monetary wage gifts. They use data from two separate field experiments to estimate the model and simulate how workers would react to different wage gifts. They find that profit-maximizing gifts would increase profits under slack labor market conditions by up to 10% on average. The key innovation of the current study was to take seriously an immediate implication of reciprocity based gift-exchange models; the importance of the ability of the agent to repay the gift to the principal. According to the recent comprehensive study by DellaVigna et al. (2016), there are only three other studies, next that address this issue: Englmaier and Leider (2012b), Kessler (2013), and DellaVigna et al. (2016). Englmaier and Leider (2012b) also analyze the importance of the ability of the worker to “repay the gift” to the manager in a real-effort laboratory experiment where they vary the wage and the effect of the worker’s effort on the manager’s payoff. They report results that are consistent with the core findings of the current study plus additional predictions about which is the marginal worker (in terms of ability) affected by their experimental variation and how different types of individuals—selfish and reciprocal—react to it. Kessler (2013) uses a laboratory experiment and finds, consistent with our results, that gift-exchange is more prevalent when worker effort is more efficient. Finally, as part of a rich set of findings, DellaVigna et al. (2016) document in a large scale natural field experiment that the return of effort to the employer—as is predicted by this study or Englmaier and Leider (2012a)—positively affects the efficacy of gift-exchange. The rest of the paper is organized as follows: The next section describes the design of the field experiment. Section 3 derives the theoretical predictions and Sections 4 and 5 present and discuss the results. Section 6 concludes. Appendices 1–3 contain illustrations, derivations and additional tables.",8
56.0,2.0,Review of Industrial Organization,10 October 2019,https://link.springer.com/article/10.1007/s11151-019-09733-2,Platform Mispricing and Lender Learning in Peer-to-Peer Lending,March 2020,Xinyuan Liu,Zaiyan Wei,Mo Xiao,Unknown,Unknown,,Mix,,
56.0,2.0,Review of Industrial Organization,09 February 2019,https://link.springer.com/article/10.1007/s11151-019-09691-9,Managerial Control and Executive Compensation,March 2020,F. M. Scherer,,,Unknown,Unknown,Unknown,Unknown,,
56.0,2.0,Review of Industrial Organization,08 April 2019,https://link.springer.com/article/10.1007/s11151-019-09700-x,Sourcing Co-Created Products: Should Your Suppliers Collaborate on Cost Reductions?,March 2020,Oksana Loginova,Niladri B. Syam,,Female,Unknown,Unknown,Female,"Firms in business-to-business (B2B) markets often develop innovative products with the help of their upstream suppliers. Such co-creation of products benefits both the upstream supplier and the downstream firm. Most papers on co-creation in marketing and in user-design literature have focused on the incentives of the upstream firm to collaborate with its customers (Redström 2006; Payne et al. 2008; Syam and Pazgal 2013). The current work differs in that we adopt the perspective of the downstream firm and investigate its incentives to co-create with its upstream suppliers. Cohen-Vernik et al. (2018) also investigate the incentives of downstream firms to co-create with upstream suppliers. However, in their setup competing downstream firms decide whether and how to co-create with a monopolistic upstream supplier, and therefore they do not consider multi-sourcing or single-sourcing in the presence of co-creation, which is a key focus of the current paper. The literature on product sourcing has considered whether a downstream firm should source its products from one or multiple suppliers but has not considered product co-creation in conjunction with multi-sourcing. In actual practice, where products are sourced from suppliers, the suppliers and/or downstream firms often undertake relationship-specific investments. In fact, the knowledge-sharing and collaborative R&D across vertical levels is very common in international trade, with buyers in developed countries sharing their expertise with their suppliers in developing nations (Pack and Saggi 2001). See Spencer (2005) for a survey of the literature on outsourcing. We contribute to the outsourcing literature by incorporating endogenous R&D investment—both at the upstream and downstream levels—into the downstream firm’s decision to single-source or multi-source such co-created products. For instance, Toyota works with different suppliers in North America to design tires for each of its car models (Liker and Choi 2004). However, seats for both the Camry sedan and the Venza SUV are manufactured by Kentucky-based Johnson Controls with inputs from Toyota engineers.
 When a downstream firm works closely with different suppliers, another decision it has to make is how much R&D collaboration among the suppliers to establish. For example, Toyota started its US suppliers’ association (Bluegrass Automotive Manufacturers Association) expressly to facilitate collaboration and knowledge-sharing among its suppliers. The Big Three US automakers, on the other hand, are well known to foster rivalry among their suppliers. Such anecdotal evidence clearly suggests that downstream firms differ in how much collaboration among their upstream suppliers they would like to have. We analytically model the phenomenon of this kind of supplier collaboration in the context of co-creation. Our research questions are: (1) What is the optimal sourcing strategy for a multi-product downstream firm that can choose to (a) either co-create with or purchase the products from its upstream supplier(s), and (b) do so either from a single or multiple suppliers? (2) What are the equilibrium levels of co-creation investments of the downstream firm and its supplier(s)? (3) If the downstream firm multi-sources the co-created products, will it prefer to establish a collaborative environment for its suppliers? (4) Are the incentives to multi-source co-created products weaker or stronger compared to the downstream firm’s incentives to multi-source products that are simply purchased from the upstream market? Stated differently: How does co-creation change the incentives to multi-source? We analyze a model where a monopolistic downstream firm sells two horizontally differentiated products: For example, a car manufacturer sells both a mid-size sedan and an SUV. The downstream firm can choose to co-create its products with two different suppliers or with the same supplier. We conceptualize co-creation as investments that are made at the different hierarchical levels and that are aimed at reducing the production costs incurred by its suppliers. In the case when the downstream firm sources its co-created products from two suppliers, it can establish an environment for them to collaborate in their cost-reduction efforts. Outright purchase from the upstream market serves as a benchmark. First, we find that—counter to intuition—the downstream firm may be worse off when its upstream suppliers collaborate in their cost-reduction efforts. Intuitively, in a collaborative environment each supplier has an incentive to free-ride on the investment of the other; this free-riding decreases the ‘effective’ investment at the upstream level. When the cross-effect between the downstream and upstream investments (the second-order cross-partial derivative of the per unit production costs function) is large, the downstream firm is motivated to decrease its investment because the upstream suppliers will pick up the slack through their own increased investment. The negative free-riding effect is muted. When the cross-effect is small, the negative free-riding effect dominates, and this adversely affects the downstream firm’s profit. Second, we show that when the downstream firm sources both products from a single supplier, this single-sourcing completely destroys the downstream firm’s incentives to invest. Multi-sourcing softens the holdup problem and thus leads to a positive level of investment by the downstream firm. This is because competition among the suppliers implies that they cannot extract all of the downstream firm’s return on its co-creation investment. Importantly, we find that the downstream firm’s incentives to multi-source (versus single-source) are higher for co-created products than for non-co-created products. Third, we find that for a commonly used additively separable cost function the optimal sourcing strategy for the downstream firm is multi-source co-creation without collaboration among the suppliers. Intuitively, co-creation allows the marginal costs of production to be lower because of the cost-reducing investments by both upstream suppliers and the downstream firm, and this dominates straight purchase. Moreover, by not having the upstream suppliers collaborate the downstream firm avoids the negative free-riding effect; and finally, by multi-sourcing the downstream firm mitigates the holdup problem, which would be severe with single-sourcing. Product co-creation is an increasingly important business phenomenon (Sawhney et al. 2005; Kalaignanam and Varadarajan 2006; Jaworski and Kohli 2006; Payne et al. 2008; Moreau and Herd 2010; Moreau et al. 2011). Much of the research in the literature has adopted the point of view of the upstream supplier whose collaboration with the downstream firm enables it to develop products that truly reflect the ‘voice of the customer’ (Griffin and Hauser 1993). In the absence of such collaboration with the downstream firm, the upstream firm would not be able to effectively incorporate the voice of the customer. In B2B contexts the lead-user literature has made similar arguments (von Hippel 1986; Thomke and von Hippel 2002; von Hippel and Katz 2002; Randall et al. 2007). The outsourcing literature too has documented knowledge-sharing and collaborative R&D across vertical levels in international trade, with buyers in developed countries sharing their expertise with their suppliers in developing nations (Pack and Saggi 2001; Spencer 2005). Downstream partners also benefit from the upstream suppliers. For example, in automobile manufacturing the ‘German Model’ has OEMs (original equipment manufacturers) work very closely with their upstream suppliers; and in fact, the suppliers undertake a large part of the R&D investments that lead to innovations (Calzolari et al. 2017). Japanese automobile manufacturers also work on joint R&D with their suppliers—especially to reduce production costs and to increase organizational learning (Cohen and Levinthal 1990; Kogut and Zander 1992). As early as the 1930s Sears had a reputation for working with its suppliers to improve their products and processes. When a downstream firm decides to collaborate with upstream suppliers for co-creation, it has to decide on the number of suppliers with which to collaborate. The literature on product sourcing has investigated this issue, but unlike us, has not considered co-created products (Shy and Stenbacka 2003; Cohen and Young 2006; Burke et al. 2007; Feng 2012; Mukherjee and Tsai 2013). Since co-creation requires substantial relation-specific investments, our research also contributes to the work on the holdup problem that arises when the agents make relationship-specific investments before the prices are set (Grout 1984; Tirole 1986). The empirical evidence of the holdup problem has been much debated in the economics literature (Coase 2000; Klein 2000); but we show theoretically that the holdup problem persists even with co-created products.",
56.0,2.0,Review of Industrial Organization,19 April 2019,https://link.springer.com/article/10.1007/s11151-019-09701-w,Collaborative Networks in Oligopoly with Asymmetric Firms,March 2020,Qiang Gong,Huanxing Yang,,,Unknown,Unknown,Mix,,
56.0,2.0,Review of Industrial Organization,30 May 2019,https://link.springer.com/article/10.1007/s11151-019-09702-9,Vertical Contracts That Reference Rivals,March 2020,Fan Liu,David S. Sibley,Wei Zhao,,Male,,Mix,,
56.0,3.0,Review of Industrial Organization,20 June 2019,https://link.springer.com/article/10.1007/s11151-019-09710-9,How Valuable are Patent Blocking Strategies?,May 2020,Dirk Czarnitzki,Katrin Hussinger,Bart Leten,Male,Female,Male,Mix,,
56.0,3.0,Review of Industrial Organization,04 June 2019,https://link.springer.com/article/10.1007/s11151-019-09705-6,Endogenous Horizontal Product Differentiation in a Mixed Duopoly,May 2020,Longhua Liu,X. Henry Wang,Chenhang Zeng,Unknown,Unknown,Unknown,Unknown,,
56.0,3.0,Review of Industrial Organization,03 June 2019,https://link.springer.com/article/10.1007/s11151-019-09704-7,When Does Variety Increase with Quality?,May 2020,Suren Basov,Svetlana Danilkina,David Prentice,Male,Female,Male,Mix,,
56.0,3.0,Review of Industrial Organization,10 June 2019,https://link.springer.com/article/10.1007/s11151-019-09706-5,Movie Industry Demand and Theater Availability,May 2020,Tin Cheuk Leung,Shi Qi,Jia Yuan,,,,Mix,,
56.0,3.0,Review of Industrial Organization,17 September 2019,https://link.springer.com/article/10.1007/s11151-019-09728-z,Signaling Quality in the Presence of Observational Learning,May 2020,Nicolás Figueroa,Carla Guadalupi,,Male,Female,Unknown,Mix,,
56.0,3.0,Review of Industrial Organization,03 June 2019,https://link.springer.com/article/10.1007/s11151-019-09703-8,Market Power Absent Merger Review: Brewing in Perú,May 2020,Ariel A. Casarin,Magdalena Cornejo,María Eugenia Delfino,Male,Female,,Mix,,
56.0,4.0,Review of Industrial Organization,05 May 2020,https://link.springer.com/article/10.1007/s11151-020-09759-x,The Intellectual Property-Antitrust Interface,June 2020,Roger D. Blair,,,Male,Unknown,Unknown,Male,"An inventor engages in the search for new information. This is an extremely risky endeavor since resources—sometimes substantial resources—must be invested before any return can be realized. Moreover, the search may yield nothing of value or even nothing at all. Even when the search is productive, the inventor will not realize much, if any, return due to problems of appropriability. Arrow (1962) warned many years ago that information is intangible and, therefore, difficult to appropriate. In order to resolve, or at least mitigate this problem, intellectual property (IP) laws were enacted. The laws governing IP allow the inventor or creator to appropriate the use of what has been discovered or created. IP rights in the form of patents, trade secrets, copyrights, and trademarks accomplish this goal by enabling the inventor or creator to exclude others from using the information without permission. The IP right holder may also charge others for the use of the former’s information. This IP is often characterized—without qualification—as legal monopolies; but in most instances they do not constitute economic monopolies. The purpose of granting these property rights is to provide an incentive to invest resources in the creation of new information—even if these property rights sometimes involve the establishment of economic monopolies. Antitrust policy is aimed at promoting and protecting competition as a market structure and as a process for allocating scarce resources. It condemns collusive efforts to emulate monopoly. It also condemns competitively objectionable conduct that creates or may create a monopoly. Ultimately, the goal is to protect consumer welfare from the deleterious impact of monopoly. The system of IP rights is aimed at promoting social welfare through the production of new information. However, once discovered, the information may be under-utilized when profit maximization leads to monopoly prices and static welfare losses. There is a tension between the antitrust laws and the intellectual property (IP) laws. Both aim to promote social welfare; but their focus differs. By and large, antitrust law aims to promote competition and static welfare. In contrast, IP law permits static welfare losses in exchange for dynamic welfare gains. Thus, there is a tradeoff between static and dynamic welfare considerations. This tradeoff leads to a natural tension between IP law and antitrust policy. Implicitly, overall policy reflects the belief that the benefits of progress outweigh short-run welfare losses that are due to the misallocation of resources. This can be seen in our Special Issue.",2
56.0,4.0,Review of Industrial Organization,12 May 2020,https://link.springer.com/article/10.1007/s11151-020-09761-3,"Error Costs, Ratio Tests, and Patent Antitrust Law",June 2020,Keith N. Hylton,Wendy Xu,,Male,Female,Unknown,Mix,,
56.0,4.0,Review of Industrial Organization,11 February 2020,https://link.springer.com/article/10.1007/s11151-020-09748-0,The Welfare Effects of Spotify’s Cross-Country Price Discrimination,June 2020,Joel Waldfogel,,,Male,Unknown,Unknown,Male,"Cross-country price discrimination is a common strategy for multinational firms, and it is one of particular importance for firms with high fixed and low marginal costs, such as pharmaceuticals and media products. Price discrimination can be undermined by transferability across consumers, but access to prescription drugs is highly regulated, which makes cross-country trade difficult. Analogously, the country-specific nature of copyright law has inhibited cross-country trade in digital media products; but proposals to legalize cross-country trade in digital products are under discussion in the European Union.Footnote 1 Such changes could undermine firms’ ability to engage in differential pricing across countries. These proposals raise the question of how the well-being of sellers and buyers would be affected by such changes. It is well understood that third degree price discrimination raises overall welfare when it raises quantities sold (Varian 1985), but magnitudes—as well as the identities of winners and losers—are empirical questions. This leads us to explore how cross-country price discrimination, relative to uniform pricing, affects output, consumer surplus, and overall welfare, as well as their distribution across countries and between consumers and producers. In general this is difficult to study, as prices are in many cases shrouded. One important exception is music streaming. Monthly streaming prices are freely available online, and—translated to dollars—they vary substantially across countries, from $14.42 for an individual monthly Spotify subscription in Denmark to $2.45 in the Philippines. Within the EU, monthly subscription rates vary between Denmark’s $14.42 and about $5.39 in Poland, Bulgaria, Romania, and Hungary. The individual prices for Apple Music vary similarly across countries. How would the inability to price discriminate across countries affect producers as well as the consumers in various countries in this market? To answer this question we calibrate a simple logit model of demand for streaming to data on prices and estimates of the numbers of subscribers by country: we infer parameters under the assumption that current country-specific prices are revenue maximizing (and profit-maximizing given zero marginal costs). We then ask how profits and consumer surplus would change—country by country and overall—if Spotify could not charge different prices in different countries, separately among EU countries and among all countries. Data availability presents a significant obstacle. While prices, along with estimates of total revenue and the total numbers of world subscribers are widely available, country-specific measures of the number of subscribers are not. For Spotify we estimate the number of subscribers per country with data on the volume of streams for top 200 songs, by country. For Apple Music, we use a less direct proxy, the volume of Google searches for “Apple Music” by country. Our basic analysis takes a monopoly approach, treating Spotify as the only seller, but we also explore how results change with a duopoly alternative in which Spotify competes with Apple Music. We find that cross-country price discrimination raises quantity sold and therefore welfare. It also raises worldwide revenue by about 6%, in both the monopoly and duopoly versions of the model. Because of the greater economic similarly of countries within the EU than among countries overall, cross-country price discrimination has a smaller effect within the EU, raising revenue by 1%. A move toward uniform pricing would help consumers in high-price, high-income countries, while hurting consumers in lower-priced, lower-income countries. The paper proceeds in five sections after the introduction. Section 2 provides some background on cross-country price discrimination. Section 3 presents the monopoly model. Section 4 describes the data that are used in the study. Section 5 presents monopoly results. Section 6 presents duopoly results, and a brief conclusion follows.",4
56.0,4.0,Review of Industrial Organization,26 March 2020,https://link.springer.com/article/10.1007/s11151-020-09751-5,Antitrust Limits on Startup Acquisitions,June 2020,Kevin A. Bryan,Erik Hovenkamp,,Male,Male,Unknown,Male,"Startup acquisitions are ubiquitous—particularly in high-tech industries. Frequently the acquiring firms are established incumbents with significant market power, as illustrated by Facebook’s acquisition of WhatsApp or Google’s acquisition of Waze. Many large technology firms acquire ten or more startups per year. To be sure, startup acquisitions play an important role in facilitating entrepreneurship and innovation (e.g. Rasmusen 1988). However, over time, persistent startup acquisitions by highly dominant incumbents may provoke countervailing competition policy concerns. In the aggregate, such acquisitions may have significant adverse effects on market structure, competition, and the diffusion of innovations. Indeed, there is growing empirical evidence that decreased business dynamism and lower productivity growth may be related to the growing productivity gap between “superstar” firms and others (Autor et al. 2017; Decker et al. 2018). Nevertheless, in any particular acquisition, it is not obvious that traditional merger analysis could support a viable antitrust challenge. In most cases, the startup’s technology is currently just an input or complement to the acquirer’s product, not a full-fledged competitor—let alone a “disruptive” competitor. It may be quite plausible that the startup would eventually have entered the product market if not for the acquisition; but in practice this is rarely provable. Further, even if there is clear evidence that the merger is horizontal, the startup’s market share will typically be small or zero, and any estimates of its future market share will likely be too speculative to meet the plaintiff’s burden of proof. Despite this uncertainty, it does not follow that the best policy is to let dominant incumbents absorb all new startups as they emerge. An alternative option is to acknowledge that such cases involve significant uncertainties, but that limited intervention under certain verifiable conditions may nevertheless leave society better off in the aggregate.Footnote 1 This paper offers some preliminary arguments in support of such a policy. Our analysis considers how startup acquisitions influence both static competition and innovation incentives, with a focus on whether certain antitrust limitations might improve the balance of these effects. We consider a market with one dominant firm (the “leader”) and one less efficient rival (the “laggard”). Market shares are determined by the relative quality levels of the firms’ products, with the leader growing more dominant as its technological advantage increases. A startup is modeled as a promising new “component technology” (an upstream input technology)Footnote 2 that has resulted from some ex ante R&D investment, and that could be utilized within one or both incumbent products. There is no assumption that the startup would enter the product market absent an acquisition; the theory of harm assumes only that the relevant technology may influence competition and consumer welfare based on how its diffusion influences product quality levels.Footnote 3 In particular, we focus on technologies that could improve the quality of the laggard and potentially the leader’s product, but which are not so radical that they would permit a laggard to leapfrog a leader. One core feature of our analysis is that all relevant technology rights can be transacted endogenously, subject to any stipulated antitrust limitations, in a technology trade game. This has a major impact on private valuations for new technologies (and by extension R&D incentives) and on the extent to which new technologies are utilized. Through this model, we consider three dimensions of efficiency in startup acquisitions. First, once a technology exists, is it licensed to the set of incumbents that maximize either consumer surplus or total welfare? Second, if technology is endogenous, does the startup work on the right technology component? Third, if the startup works on the right technology, does it invest an efficient amount in total R&D? That is, we are concerned with the diffusion, the direction, and the rate of startup activity. Our results indicate that, under laissez-faire acquisition rules, startup behavior will be inefficient in all three dimensions. Why? When a laggard incumbent acquires a startup technology, its own product gets better, but the differentiation between leader and laggard declines. If the joint-profits of the leader and laggard fall following an acquisition by the laggard, the leader would have an incentive to buy the startup instead and refuse to license its invention. The leader does so even if the startup’s invention is entirely incapable of improving the quality of the leader’s own product. The outcome is that the laggard’s product is worse than it could have been, and that the leader has more market power; both are harmful to consumers. Under a laissez-faire regime, the leading incumbent continues to buy startups partially to keep the laggard from reducing differentiation. However, the acquisition price is highest for inventions that both directly improve the leader’s product as well as indirectly increase differentiation. Startups therefore produce too few inventions that help laggards catch up to leaders. Note that the harm here is not the traditional antitrust concern that future “potential competitors” are being bought, but rather that startup acquisitions affect the technological gap and thereby influence competition and market structure. What can be done to limit these harms? We do not propose that any startup be categorically denied the opportunity to be acquired. Instead, we argue in favor of intervention in situations where a highly-dominant incumbent acquires a startup whose technology could plausibly influence competition if rivals are excluded from using it. Alternatively, intervention could be predicated on a dominant firm’s pattern of acquiring promising startups and then declining to license competitors.Footnote 4 To that end, we focus mainly on intervention in the form of a compulsory licensing requirement, although we also consider a policy that would preemptively block the dominant firm from acquiring a startup. In all cases, the resulting equilibrium involves both incumbents gaining access to the startup technology, usually because the laggard acquires the startup and then strikes a licensing deal with the leader. Unsurprisingly, the impact on static consumer welfare is always positive, since there is greater diffusion. While efficient diffusion can be achieved, we also consider how such an antitrust policy would impact ex ante R&D decisions by a startup. Recall that in laissez faire, startups are biased toward inventions that help improve the leader’s product versus those that help the laggard catch up technologically. The consumer surplus maximizing invention given equilibrium price setting by the oligopolists does not involve any bias in favor of improving one product versus the other; the marginal benefit of a small quality improvement is the same for both products. Compulsory licensing or limits on exclusive licensing by leading incumbents decrease the acquisition price of startups with inventions that help the leader, and hence partially mitigate the directional distortion. Though directional distortions are improved, lower acquisition prices due to antitrust intervention will lead the innovator to invest less in R&D, provided the leader has not yet obtained a pure monopoly. The startup gets the largest payouts for inventions that widen the technology gap, while antitrust intervention prevents this by compelling licensure of the laggard. But, critically, this property vanishes as soon as the technological gap is large enough for the leader to become a pure monopolist: Its marginal willingness to pay for a technological improvement falls abruptly, becoming permanently flatter. This implies that market contestability plays a key role in shaping private valuations of new technologies.Footnote 5 This role of contestability suggests that innovation rate incentives could be bolstered over the long run by a policy that maintains at least some amount of contestability over time. Our proposed intervention strategy would accomplish this by requiring compulsory licensing when the acquiring firm is sufficiently dominant. We close this section with a discussion of related research. Section 2 then introduces the baseline model of duopoly competition with differentiated product quality and endogenous inter-firm licensing. In Sect. 3 we model startup acquisitions, both with and without antitrust restrictions. Section 4 then evaluates the impact of antitrust intervention on ex ante innovation incentives. Finally, the policy implications of our analysis are discussed in Sect. 5. There are long related literatures on the operation of markets for technology, and antitrust in innovative markets. In markets for technology, the classic results of Gilbert and Newbery (1982) and Katz and Shapiro (1985) show that, contrary to the Arrow replacement effect, if an innovation would be used by a laggard, the leader is always willing to outbid the laggard in order to obtain exclusive rights over the invention in order to limit competition. This tendency toward persistent technological leadership is a longstanding issue in the literature that has raised the question of why laggards or entrepreneurs ever do anything other than sell to a technological leader, thus allowing the leader to maintain market power. A number of authors have attempted to answer this question (e.g. Gans and Stern 2000, 2003; Arora 1995; Spulber 2012), suggesting informational frictions, missing markets for technology, tacit knowledge as a complement to technology, among other factors. Most of this literature concerns licensing from potential competitors (including those who enter solely to induce the incumbent to buy them out, as in Rasmusen (1988)). We restrict our model to an environment in which startups are not prospective competitors, but can supply useful complementary technologies. Katz and Shapiro (1985) has pure licensors that sell cost-reducing technology, rather than our startups that develop components with differential value to product market competitors. Nonetheless, their propositions 7 and 8 are closely related to our proposition 2. We further discuss how startup acquisition rules affect the direction of innovation performed by startups, in addition to affecting the rate. Three germane papers in the literature on antitrust in innovative markets are Aghion et al. (2005), Segal and Whinston (2007), and especially Cabral (2018). The first two papers discuss the tradeoff between strong product market competition and innovation. Competition today incentivizes firms to escape competition by vertically differentiating through innovation, but the benefit of that innovation depends on how long the innovator can prevent laggards from replicating or surpassing their invention. Gans (2017) expands the Segal and Whinston (2007) model to show how the acquisition of dynamic capabilities causes firms to avoid selling to incumbent leaders even when there is a static product market reason to do so. These papers generally involve “drastic” innovation where startup technology allows them to supercede the leader; this is something we assume away in our model of component improvement. Cabral (2018) models fringe and dominant firms that innovate over time with the possibility of licensing. When the fringe firm can license, its incentive to innovate increases, and strict merger policy for dominant firms can therefore lower the rate of innovation. On the empirical side, Andrews et al. (2015) and Baily and Montalbano (2016) find evidence of widening productivity gaps between market leaders and laggards. This effect plays a major role in our model, and it occurs endogenously. Wollmann (2019) shows that mergers between large and small firms became much more common when the Hart–Scott–Rodino Act was modified in 2001 to exempt mid-sized firms from per-merger notification. Mergers outside the purview of the Act resulted in a combined concentration of activity adding up to 32–44% of the total growth in 4- and 8-firm industry concentration ratio between 1994 and 2001. These “submarine” acquisitions are therefore cumulatively important for market structure. 
Cunningham et al. (2019) find that acquisitions in biotechnology often involve “killer acquisitions” of potential competitor drugs. As our results show, incumbents are incentivized to maintain vertical differentiation with “killer” acquisitions; but if startup’s choice of technology is endogenous, startups will develop innovations that will be killed in equilibrium only if it is sufficiently inexpensive to develop technologies that would improve the laggard’s quality but not the leader’s—as compared to technologies that would improve both firms’ qualities. The innovator can obtain larger rewards for the latter type of technology, as it can generate a highly profitable structural effect: an increase in quality differentiation. This increase occurs when the leader acquires exclusive rights over the technology, thereby improving its own quality while also forestalling an increase in the laggard’s quality.",30
56.0,4.0,Review of Industrial Organization,14 February 2020,https://link.springer.com/article/10.1007/s11151-020-09749-z,Trading in Information: On the Unlikely Correspondence Between Patents and Blackmail Law,June 2020,Thomas J. Miceli,,,Male,Unknown,Unknown,Male,"Information is a valuable asset, but one that is notoriously difficult to trade in. This is a consequence of its public good attributes, which impede the ability of discoverers or sellers of information to capture its full social value: the “appropriability problem.” This paper studies the problem of trading in information in two seemingly unrelated settings: inventive activity; and blackmail. In the former case, a discoverer of some new information wishes to profit from it but may be deterred from doing so because the act of disclosure effectively makes the information available to everyone. Thus, legal protection of the information in the form of a patent is usually needed to allow the inventive process to go forward.Footnote 1 Blackmail also involves trading in information; but because the transaction is between two parties who already know its content—the discoverer and someone who wishes to keep it hidden—the appropriability problem is absent. In fact, the illegality of blackmail is specifically aimed at depriving the discoverer of the legal right to profit from such a transaction. In this sense, we might characterize anti-blackmail laws as being the inverse of patents. Alternatively, the discoverer might have tried to sell the information to an uninformed party who would benefit from learning its content: perhaps a prospective business partner, or the spouse of the blackmail victim. In contrast to the blackmail transaction, such an exchange would be perfectly legal (and, as we will demonstrate, more profitable); indeed, the divergent legal treatment of these two cases has been described as the “paradox of blackmail.”Footnote 2 The analysis in this paper will show that this paradox is easily resolved by thinking about blackmail within the context of markets with asymmetric information. Specifically, promoting transactions that result in information revelation (or more accurately, discouraging those transactions that seek to conceal information) improves the efficiency of markets in the presence of information asymmetries. However, the resolution of one paradox creates another: Why do those individuals who hold compromising information not naturally try to sell it to the uninformed parties, who (as we will demonstrate) actually value it more highly than do the informed parties? The resolution of this paradox provides the link to patent policy because it hinges on the above problem of trading in information: A transaction between the discoverer of information and an uninformed party would be susceptible to the appropriability problem and hence is unlikely to take place.",1
56.0,4.0,Review of Industrial Organization,10 March 2020,https://link.springer.com/article/10.1007/s11151-020-09753-3,"Method-of-Use Patents, Appropriability, and Antitrust Policy",June 2020,Roger D. Blair,Anita N. Walsh,,Male,Female,Unknown,Mix,,
56.0,4.0,Review of Industrial Organization,21 April 2020,https://link.springer.com/article/10.1007/s11151-020-09756-0,"Patents, Litigation Strategy and Antitrust in Innovative Industries",June 2020,Steffen Juranek,Thomas Quan,John L. Turner,Male,Male,Male,Male,"This paper studies the characteristics and implications of patent invalidity and patent non-infringement. Since the early 1990s, there has been a marked increase in the importance of pretrial litigation maneuvers for outcomes in patent litigation.Footnote 1 Some of the more common maneuvers—e.g., requests for a particular claim construction in a “Markman” hearing, or a motion for summary judgment—give alleged infringers significant ability to influence the likelihood of invalidity and non-infringement rulings (Ford 2013). Firms have also asked courts to vacate rulings as part of patent litigation settlements, and courts have often granted these requests (Bock 2013).Footnote 2 Unfortunately, the incentives to alter the likelihoods of invalidity and non-infringement—and the effects on innovation of doing so—are not well understood. Many researchers have argued that the incentives to invalidate patents are too low, as alleged infringers may not pursue invalidity due to the relatively high burden of proof (Ford 2013) and may not internalize the benefits of patent invalidity that accrue to other firms and consumers (Farrell and Merges 2004). But previous consideration of these phenomena has been largely informal; and no research has used a dynamic model to study the effects on innovation of changes to expected rates of invalidity and non-infringement. We take steps to fill both gaps. We introduce a model that delineates current and future effects— on a patentee and a single alleged infringer—of replacing patent invalidity with non-infringement. The model assumes that all non-patentee firms—including a group of other competitors—may use the patented technology in current and future periods in the event of invalidity. Under non-infringement, in contrast, there are some restrictions: In the current period, the alleged infringer may continue using its own (non-infringing) technology, but other firms may not imitate the patented technology. And in the future, all non-patentee firms may not use the patented technology in pursuing innovation that determines which firm has the dominant technology at the start of a second period of competition. This model highlights when and how a patentee and alleged infringer may have different preferences over invalidity and non-infringement. The patentee clearly prefers non-infringement, which limits competition in the current period and for future innovation. But for the alleged infringer, there is a tradeoff: In the current period, it benefits more from patent non-infringement, as the patent prevents other firms from imitating the patented technology; effectively, the alleged infringer is able to “slipstream” behind its rival’s (valid) patent and face less competition. For the future, the alleged infringer benefits more from patent invalidity, as an otherwise valid patent “blocks” the infringer from using the patentee’s technology in cumulative innovation. We embed the slipstreaming and blocking effects (in reduced form) in a dynamic model and analyze the equilibrium innovation and legal strategies. In particular, we adapt the “innovative industries” model of Segal and Whinston (2007): Entrants innovate and patent in attempts to replace current (sluggish) incumbents and gain dominant market positions. The incumbent copies the entrant’s patented innovation; and the entrant sues the incumbent for infringing the entrant’s patent. Our adaptations specify current-period payoffs and the probability that the entrant replaces the incumbent as the future dominant firm as functions of the outcome of the uncertain patent litigation. We find that a change in legal regime that raises the likelihood of a legal finding of non-infringement—while reducing the likelihood of a finding of invalidity—promotes innovation. Specifically, equilibrium innovation is higher under an “infringement first” (IF) legal regime (which always considers infringement) than under a “validity first” (VF) legal regime (which always considers validity). The expected reward for an entrant innovator is higher under IF for two reasons: Expected current-period payoffs are higher for both firms, because a valid-but-not-infringed patent deters imitation from fringe firms while an invalid patent does not. And the entrant innovator is more likely to replace the incumbent as the dominant firm, because of the future blocking effect of patent validity. We then allow the legal regime (IF or VF) to be determined endogenously in the model. Consistent with the seniority of validity in patent law, we specify that VF obtains if either firm prefers it. Because the entrant patentee is better off in the current period and also in the future under non-infringement, it always prefers IF. But due to the tradeoff between the slipstreaming and blocking effects, the incumbent alleged infringer may prefer either IF or VF. The incumbent alleged infringer’s preferences are therefore decisive. In analyzing equilibrium regime choice and innovation, we identify multiple possible outcomes. But two stark cases sharply highlight the key tradeoffs. On the one hand, if there is a strictly positive slipstreaming effect but zero blocking effect, then IF and a relatively high rate of innovation obtain in equilibrium. Intuitively, this is a “live and let live” equilibrium: It will tend to obtain in an industry with two leading firms that do not compete fiercely on price and have highly differentiated technologies (so that it is not difficult to invent around patents). On the other hand, if the slipstreaming effect is zero but there is a strictly positive blocking effect, then VF and a relatively low rate of innovation obtain in equilibrium. Intuitively, this is a “scorched earth” equilibrium: It will tend to obtain in an industry where firms compete fiercely on price—e.g., à la Bertrand—and have homogeneous technologies. The latter case yields a “litigation strategy” effect: The option to choose the legal regime yields a rate of innovation that is lower than it would be under mandated IF. With strictly positive slipstreaming and blocking effects, the equilibrium depends upon the relative sizes of the effects. Interestingly, multiple equilibria—“live and let live” and “scorched earth”—are possible in the model. Intuitively, higher innovation decreases the incumbency advantage—the additional payoff from being the incumbent instead of the entrant—and this reduces the alleged infringer’s expected loss from the blocking effect, which reinforces its incentive to choose IF. Similarly, lower innovation under VF increases the future incumbency advantage, which increases the alleged infringer’s expected loss from the blocking effect and reinforces its incentive to choose VF. The model permits some analysis of comparative static effects of various parameters on the likelihood that there is an equilibrium where IF is chosen. Any increase in the expected replacement probability increases the incentive to innovate and decreases the incumbency advantage. In general, this increases the likelihood that there is an equilibrium where IF is always chosen and attenuates the litigation strategy effect. However, a caveat applies when there is an increase in the probability that the entrant replaces the incumbent after a “not infringed” decision. This decreases the incumbency advantage, but simultaneously increases the incumbent’s likelihood of retaining its incumbency under VF relative to IF. The former increases the likelihood of an IF equilibrium, while the latter decreases the likelihood of an IF equilibrium. Thus, the total effect is ambiguous. Antitrust enforcement should seek to promote innovation incentives, which, in this context, entails attenuating the litigation strategy effect. In studying policy towards unilateral actions that dominant incumbents might take, we follow Segal and Whinston (2007) in assuming that enforcement raises the expected current-period profit for the entrant. As in their model, there are clear circumstance— e.g., prohibiting predatory pricing—where antitrust enforcement raises the joint current-period profit of the firms and thereby enhances incentives to innovate, under both the IF and VF regimes. More importantly, we find that whenever the effect of antitrust enforcement is higher in magnitude for the entrant’s current-period payoff than for the incumbent’s current-period payoff, the incumbency advantage falls. This attenuates the litigation strategy effect and indirectly yields even higher innovation incentives. We also consider a policy against multilateral agreements. When multiple equilibria may obtain, firms might try to coordinate to achieve a particular equilibrium. In this case, attempts to use antitrust policy (to attenuate the litigation strategy effect) sharply highlight the tension between antitrust enforcement and intellectual property. Consider an agreement among rivals (or an industry norm) always to choose the IF regime and eliminate the possibility of a VF equilibrium. Or similarly, that two rivals agree not to file petitions for inter partes review with the Patent Trials and Appeals Board (PTAB), but otherwise compete (in product markets and in litigation), which has the same basic effect as an agreement always to choose IF. Antitrust authorities are likely to take a dim view of such agreements; but in the settings that are captured by our model this sort of shift would actually attenuate the litigation strategy effect and weakly raise innovation incentives. This paper formalizes the effects of patent non-infringement versus invalidity in a stylized model. Our slipstreaming effect encompasses ideas from Farrell and Merges (2004) and Ford (2013), who offer detailed discussions of the external effects of patent validity absent infringement (which we discuss below). Our blocking effect on future innovation captures the well-understood idea that patents may stifle future innovation by blocking access to a technology (e.g., Murray and Stern 2007; Williams 2013; Galasso and Schankerman 2015). Our analysis of the relationship between the characteristics of patent litigation and innovation builds directly off of the Segal and Whinston (2007) framework.Footnote 3 In furthering their effort to provide understanding of the effects of static market power on dynamic incentives to innovate, our paper relates to the literature on the effects of policies that alter the market power of technology leaders when the primary nexus of competition is “for the market” instead of “in the market” (Evans and Schmalensee 2002).Footnote 4 Both the slipstreaming and blocking effects are likely to be present, in some form, in industries where direct competitors also attempt to produce drastic innovations.Footnote 5 We also complement recent work by Gans (2010) and Gans and Persson (2013), who study similar issues in an environment where an innovating entrant and a (patent-holding) incumbent may cooperate in commercializing new technology. They add bargaining over a license to the basic Segal and Whinston (2007) framework and study incentives to innovate and the effect of antitrust enforcement. Cooperative bargaining alters the effects of antitrust enforcement on innovation incentives in important ways: For example, Segal and Whinston (2007) show that antitrust enforcement that raises the incumbent’s payoff under competition increases the innovation reward (by raising the value of incumbency). In contrast, Gans (2010) and Gans and Persson (2013) show that antitrust enforcement that reduces the incumbent’s payoff under competition increases the innovation reward. Intuitively, the entrant shares the bargaining surplus from cooperating instead of competing, and this is higher when the incumbent’s competitive payoff is lower. Our work also sheds light on the literature that analyzes how patent lawsuits may help to sort out bad patents. The problem of bad patents—patents that should not have been issued—stems from the inadequate resources of patent offices and the incentives that are faced by the examiners (Farrell and Merges 2004). Since patents may hinder future innovation by blocking access to patented technology (Murray and Stern 2007; Williams 2013; Galasso and Schankerman 2015), the existence of invalid patents may not only be detrimental to firm success but may also slow down technological progress and economic growth. A number of authors (e.g., Lemley 2001) have argued that the issuance of invalid patents by patent offices is not necessarily inefficient because, in reality, only a few patents really matter. Hence, it may be more cost-effective to raise the question of the validity of those patents in a courtroom rather than encumbering the application procedure for all patents.Footnote 6 However, Farrell and Merges (2004) challenge this view. They argue that besides a lack of resources faced by many alleged infringers and the risk of losing, alleged infringers do not fully internalize the benefits of challenging a potentially invalid patent. The latter argument follows from the public goods nature of invalidating a truly invalid patent that would otherwise create market power. If such a patent is invalidated, it will not only benefit the alleged infringer but also other competitors in the industry (as well as consumers). 
Ford (2013) focuses on the procedural details of an alleged infringer’s defense strategy and compares a non-infringement strategy with an invalidity strategy. He first argues that it is difficult to pursue both strategies simultaneously.Footnote 7 He also discusses the advantages and disadvantages of each strategy, which is formalized in our model by the slipstreaming and blocking effects. Ford (2013) argues that because of the high standard to prove invalidity, the non-infringement defense strategy often dominates, and litigation does not effectively sort out invalid patents. However, our results suggest that this may actually increase the incentive to innovate by increasing the expected payoff to innovation.Footnote 8",1
56.0,4.0,Review of Industrial Organization,28 February 2020,https://link.springer.com/article/10.1007/s11151-020-09750-6,Pay-for-Delay with Follow-On Products,June 2020,Jorge Lemus,Emil Temnyalov,,Male,Male,Unknown,Male,"The patent system is founded on the premise that granting an exclusion right to an inventor for a limited period encourages innovation. The right to exclude rivals creates market power, so patents trade-off consumer-welfare losses and innovation incentives. In practice, whether a patent holder can implement an exclusion right is uncertain (Lemley and Shapiro 2005). In the pharmaceutical industry, a generic firm can enter a market that is protected by a patent after demonstrating:
(a) the bio-equivalence of its product and a patented product; and (b) that either the generic product does not infringe on the original patent or that the original patent is invalid.Footnote 1 In response to an entry attempt by a generic firm, the patent holder (the brand firm) typically files a lawsuit that claims patent infringement. These lawsuits have often been resolved through “pay-for-delay” settlements, where the brand firm and the generic agree on an entry date for the generic (before the expiration of the patent) and the brand firm makes a payment to the generic: a “reverse payment.”Footnote 2 Pay-for-delay settlements have been one of the important categories of the intellectual property and antitrust debate. The anti-competitive aspect of these settlements is that they forestall competition by preserving patents that are unlikely to withstand reexamination (weak patents). Given that competition between two substitute products lowers total industry profit relative to monopoly profits, a brand firm and a generic entrant have incentives to preserve monopoly profits and share the rents.Footnote 3 This is particularly worrisome when the brand firm holds a weak patent, because pay-for-delay settlement in this case can generate large consumer-surplus losses. Ghili and Schmitt (2017) compare the consumer surplus that was generated by the pay-for-delay settlement for the drug Lamictal with the consumer surplus that was generated in two counterfactual scenarios: a settlement without direct payment (a pure-delay settlement); and litigation to final judgment. They find that a pure-delay settlement would have increased consumer surplus by $100 million, whereas litigation to final judgment would have increased consumer surplus by $1.3 billion. The FTC has challenged settlements involving reverse payments under the suspicion of anti-competitive conduct (Hemphill 2006). In FTC v. Actavis, 570 U.S. 136 (2013), the Supreme Court concluded that reverse payments are illegal if they are used to avoid competition, but they are not per-se illegal. The Supreme Court called on U.S. courts to apply the rule of reason when dealing with pay-for-delay cases. Edlin et al. (2015) interpreted this ruling by proposing the Actavis Inference: a settlement that involves a large and otherwise unexplained payment, combined with delayed entry, supports a reasonable inference of harm to consumers from lessened competition. Pay-for-delay settlements have been studied in a setting with a single product. Our contribution is to study pay-for-delay settlements in a setting with more than one product. Specifically, in our setting the brand firm can introduce a new product that can be a radical innovation or just a minor modification of an existing product. This is an important feature of the pharmaceutical industry, where brand firms routinely introduce follow-on products: This strategy has been called “product hopping” or “evergreening” when the follow-on product is a minor modification: e.g., a reformulation from a capsule to a tablet. Product hopping has recently attracted the attention of antitrust authorities. Cases that involve product hopping include: AstraZeneca’s reformulation of Prilosec into Nexium (two drugs that are used to treat severe stomach acid-related conditions);Footnote 4 Abbott’s reformulation of TriCor (a drug that is used to treat high triglyceride levels) from capsules to tablets;Footnote 5 Reckitt’s switch of its branded formulation Suboxone (a drug that treats opioid addiction) from a sublingual tablet to a sublingual film;Footnote 6 Warner Chilcott’s switch of Doryx (an acne medication) from tablets to capsules;Footnote 7 and Actavis and Forest Laboratories’ switch of Nameda (an Alzheimer’s drug) from an immediate release formulation to an extended release formulation.Footnote 8 The main economic force in our analysis is the strategic use of follow-on products to moderate the losses from patent invalidation. If the patent for the first product is invalidated, the patent holder introduces the second product earlier. This strategic effect changes the payoffs in a pay-for-delay negotiation relative to the case of no follow-on products. Consider a simplified version of our model to illustrate this economic trade-off: First, suppose that there is only one product. Under patent protection the brand firm gets a profit \(\pi \) for one period. In this case, the patent holder risks \(\pi \) by going to litigation: The patent holder loses \(\pi \) if the patent is invalidated. Next, consider a setting where there is a second product that is protected by an ironclad patent that generates a profit of \(\pi ^H\) for the patent holder. We assume that the second product completely cannibalizes the sales of the first product, and that the patent holder prefers to introduce the two products sequentially rather than simultaneously: \(\pi ^H<\pi +\beta \pi ^H\), where \(\beta \in (0,1)\) is the discount factor. In this case, if the first product’s patent is invalidated, the patent holder loses a profit of \(\pi \) from the first product and introduces the second product earlier, which creates a gain of \((1-\beta )\pi ^H\). Thus, patent invalidation changes the incumbent’s profits by \(-\pi +(1-\beta )\pi ^H\) when there is a follow-on product; without a follow-on product, patent invalidation changes the incumbent’s profits by \(-\pi \). The key insight is that the invalidation of the first patent removes the cannibalization between the first and the second product, which triggers an earlier introduction of the follow-on product. This effect implies that the invalidation of the first patent reduces the patent holder’s payoff by less when there are follow-on products, which changes the patent holder’s negotiation incentives. We study settlements that delay entry both when reverse payments are allowed and when they are not. First, when reverse payments are allowed, we show that settlements in the presence of a follow-on product involve a smaller transfer from the brand firm to the generic relative to the transfer in a model without follow-on products. Thus, an antitrust inference that is based on this payment—such as the Actavis inference—over-estimates the strength of the patent if follow-on products are not accounted for properly. Second, in pure-delay settlements, we show that follow-on products could push the parties to settle on an earlier date of entry relative to the equilibrium settlement date in a setting without follow-on products. Thus, an inference that is based on the length of the delay of entry that ignores follow-on products may under-estimate the strength of the patent. Importantly, if the introduction of a follow-on product increases the brand firm’s outside option significantly more than its settlement profits, this result reverses, and an inference that is based on the length of the delay leads to an over-estimation of the patent strength. As a consequence, welfare-loss estimates that are based on a settlement framework that ignores the endogenous introduction of a new product may lead to biased results. Finally, we show that under pure-delay settlement, litigation may arise in equilibrium. In this case a weak patent for the first product or longer development time for a follow-on product both make settlement agreement more likely. The model provides a novel explanation for equilibrium litigation even when firms hold symmetric beliefs about their litigation prospects. To the best of our knowledge, we are the first to provide a formal analysis of pay-for-delay settlements with follow-on products. Carrier (2010) was among the first to discuss pay-for-delay in conjunction with product hopping. Carrier (2011) presents the case study of Provigil, which shows the anticompetitive harm that can result from the combination of pay-for-delay and product hopping. Gallasch (2016) argues that product hopping is facilitated by pay-for-delay settlements. 
Feldman and Frondorf (2016) describe three “generations” of pay-for-delay strategies: In Generation 1.0, brand firms pay cash directly to generics to delay their entry. In Generation 2.0, the brand firm uses side deals, instead of cash, to disguise the payment to generics. In Generation 3.0, brand firms exploit regulation in combination with pay-for-delay to prevent generics from entering the market. Similarly, Kesselheim and Darrow (2015) discuss current and emerging challenges with the Hatch-Waxman Act, whereas Hovenkamp and Lemus (2018) discuss how the Patent Trial and Appeal Board (PTAB), a new venue within the U.S. Patent and Trademark Office to challenge the validity of a patent, has influenced firms’ settlement decisions. Dickey et al. (2009) show that some of the conclusions in the analysis of pay-for-delay settlements change after including real-world complexities such as litigation costs, risk aversion, asymmetric information, time discounting, and cash constraints. Our model incorporates several of these features (e.g., litigation costs and time discounting) in addition to follow-on products.",4
56.0,4.0,Review of Industrial Organization,06 May 2020,https://link.springer.com/article/10.1007/s11151-020-09760-4,A “Primarily Property” Presumption Is—Still—Really Needed for the IP/Antitrust Interface,June 2020,Lawrence J. White,,,Male,Unknown,Unknown,Male,"Antitrust discussions in the U.S. have a long tradition of describing intellectual property (IP)—especially patents and copyrights, but sometimes even trademarks—in unqualified terms of “monopoly”. Since antitrust policy is supposed to encourage competition and discourage monopoly, this tradition has meant that there was a hostile climate that automatically surrounded any antitrust discussion that involved IP. Modern antitrust discussions—for at least the past four decades—have struggled to move away from this presumptive hostility. Over two decades ago the U.S. Department of Justice (DOJ) and the Federal Trade Commission (FTC) abandoned this presumption for enforcement purposes; over a decade ago the U.S. Supreme Court followed suit. But, alas, the presumption of unqualified monopoly still appears in important legal decisions, as well as legal and social sciences discussions, that involve IP.Footnote 1 There is another place where the discussions might start: with a presumption that any IP is “primarily property”—albeit with some important distinctions that separate IP from “garden variety” tangible property (such as land and structures, vehicles, personal possessions, etc.). The discussion could then acknowledge that in some instances IP does involve market power and thus warrants antitrust considerations. Why does this matter? The monopoly presumption has clearly influenced past policy—both by antitrust enforcers and by the courts—in unfortunate directions. And it continues to get in the way of clear thinking about IP and its role in a modern economy and the relationship between antitrust and IP in such economies. This paper will expand on these themes: In Sect. 2 we provide a brief overview of the standard argument for doing something special—for establishing a property right—in a newly created idea and thus for the concept of IP. Section 3 addresses the “monopoly” presumption that has traditionally accompanied IP discussions, especially when antitrust issues are also involved. Section 4 explores the important similarities—and differences—between “garden variety” property, such as real estate, and IP; it concludes that the similarities are indeed substantial, so that the perspective that IP is “primarily property” is a reasonable starting point for antitrust/IP discussions—instead of starting with the traditional monopoly presumption. Section 5 then addresses some beneficial differences that this alternative starting point could have made and/or could still make. Section 6 concludes.",3
57.0,1.0,Review of Industrial Organization,12 July 2019,https://link.springer.com/article/10.1007/s11151-019-09712-7,"Regulatory Change, Market Structure, and Fatalities: The Case of the Gulf of Mexico Reef Fish Fishery",August 2020,Sami Dakhlia,Akbar Marvasti,,Male,Male,Unknown,Male,"The fishing industry faces at least two important challenges: the common-pool problem of stock depletion on one hand, and high occupational hazard on the other. As regulatory bodies have attempted to address these dual problems, policy failures have also arisen. In the case of the reef fish fisheries in the U.S. waters of the Gulf of Mexico (GoM): The initial policy response to the collapsed reef fish populations was to impose seasonal closures to constrain output to an annual fleet-wide total allowable catch (TAC). Unfortunately, this command-and-control approach to conservation had the unintended consequence of exacerbating the so-called derby-fishing problem: Fishermen competed even more fiercely over the short season, for instance by braving harsher weather conditions. To add insult to injury, market gluts during the short, but intensive, fishing season led to depressed prices. Individual tradable fishing quotas (ITQs) were eventually introduced for red snapper in 2007 and for a wider set of GoM reef fish species in 2010. With fishermen now competing over access in the marketplace rather than at sea, these de facto property rights put an end to derby-fishing behavior and reduced the number of fatal accidents. ITQs have a potential effect on vessel efficiency as well: Because fishing privileges are tradable, owners of less efficient vessels may prefer to transfer their rights to owners of more efficient vessels. The ensuing shift in market structure may, in turn, affect safety: On the one hand, the remaining vessels would target larger annual catches, spend more days at sea every year, and thus increase their chance of being exposed to harsh weather conditions; on the other hand, with increased efficiency, fewer labor-hours are exposed to risk. In short, because they are individual, ITQs solve the derby-fishing problem; but because they are also tradable, the fewer vessels that are still operating would increase their catch and spend more days at sea. To gauge to what extent any ITQ-induced fleet consolidation might have contributed—positively or negatively—towards a reduction in fatal work-related injuries, we decompose the effect of regime change on safety with the help of a simulated counterfactual scenario: How much risk would fishermen take if quota privileges were individual, but not tradable, and thus could not lead to fleet consolidation? Our results are threefold: (1) Fleet consolidation has so far been incomplete; (2) trips on larger vessels are inherently more dangerous; (3) nevertheless, a shift to fewer, larger, and more efficient vessels contributes positively to safety.",1
57.0,1.0,Review of Industrial Organization,30 August 2019,https://link.springer.com/article/10.1007/s11151-019-09725-2,The Role of Spatial Density and Technological Investment on Optimal Pricing Strategies in the Grain Handling Industry,August 2020,Anton Bekkerman,Mykel Taylor,,Male,Unknown,Unknown,Male,"In competitive grain commodity markets, agribusinesses are price takers of globally-determined prices. As such, improvements in profit margins are largely dependent on the technologies and management strategies that improve cost-side efficiencies of handling grain. Shuttle train-loading elevators—high capacity, high-speed grain loading facilities—are a recent example of agribusinesses responding to these incentives by adopting technologies that improve efficiency and by attempting to capture market share through cost reductions. Shuttle train-loading elevators are designed to load quickly approximately 380,000 bushels of wheat onto dedicated shuttle-unit trains in 15 hours or less (Kenkel et al. 2004; Bekkerman 2013).Footnote 1 Through these operational efficiencies, grain handling facilities are able to reduce costs with improved rail rates and guaranteed railcar availability. For example, between 2010 and 2015, rail tariffs across numerous U.S. origins and destinations for wheat that was delivered by shuttle trains were, on average, 23.3% lower than were the tariffs for delivery that used non-shuttle trains (USDA Agricultural Marketing Service 2016). These comparative advantages have spurred agribusinesses to upgrade existing elevators and build new shuttle-loading facilities across the U.S. Great Plains (Bekkerman 2013; Kowalski 2014). If shuttle-loading facilities reduce the marginal costs of handling a bushel of grain, then it is possible that some portion of those savings will be passed through to grain farmers in the form of higher cash prices that the elevators pay to the farmers. Pass-through seems especially plausible because these facilities must meet strict shuttle train capacity requirements and, therefore, have higher demand for grain than do smaller, conventional elevators. Additionally, technological advances and firms’ historical location choices can result in local monopsony power, which can also affect pass-through behaviors. This study characterizes and measures systematic differences in elevators’ pricing and pass-through behaviors and examines variation in these differences that may be associated with the spatial competitiveness of a local market for wheat. We develop a model of spatial competition among elevators to characterize optimal pricing strategies and pass-through behavior. We then empirically assess these behaviors by elevators within and between Kansas and Montana: two large wheat-producing states where historical differences in the spatial marketing competition structures provides for empirical identification. We model cross-sectional and temporal variation in local wheat prices with the use of daily cash price bids at grain elevators between January 2, 2004, and July 12, 2013. Specifically, we use a spatial basis model to estimate and test for evidence of differences between cash price bids across elevators that have different variable costs that are due to their grain handling technology. The estimation results of the spatial basis model indicate that price bids at shuttle-loading elevators are higher than at conventional elevators by $0.13 per bushel (22% higher) in Kansas and $0.04 per bushel (6.0% higher) in Montana. These results indicate that cost savings from a technology that reduces variable grain handling costs are passed through to agricultural producers, but that in less spatially competitive markets (Montana) the pass-through is lower. We also show that a greater degree of local spatial competition leads to pressure on firms that do not have the cost-saving technology to raise their price bids also (thus reducing their profit margins) in order to remain competitive with their more efficient neighbors. These results represent the first empirical estimates that quantify the observed pricing behaviors in the grain handling industry and the extent to which these are affected by the competitive structure of the industry.",
57.0,1.0,Review of Industrial Organization,30 July 2019,https://link.springer.com/article/10.1007/s11151-019-09718-1,The Welfare Implications of the Meeting Design of a Cartel,August 2020,María C. Avramovich,,,,Unknown,Unknown,Mix,,
57.0,1.0,Review of Industrial Organization,09 July 2019,https://link.springer.com/article/10.1007/s11151-019-09713-6,Input Price Discrimination and Upstream R&D Investments,August 2020,Ioannis N. Pinopoulos,,,Male,Unknown,Unknown,Male,"Price discrimination by suppliers is an important issue in competition policy. For example, legal enactments—such as the Robinson-Patman Act in the US and Article 102(c) of the Treaty on the Functioning of the European Union (TFEU) in the EU—are aimed at prohibiting manufacturers from engaging in anti-competitive input price discrimination.Footnote 1 There is by now a large theoretical literature on the welfare effects of price discrimination in input markets.Footnote 2 Acknowledging the fact that investing in research and development (R&D) is a common business practice worldwide, a number of papers within that literature consider the case where downstream firms engage in cost-reducing R&D investments (DeGraba 1990; Inderst and Valletti 2009; Herweg and Müller 2014; Dertwinkel-Kalt et al. 2016). In this paper, we consider the case of upstream cost-reducing R&D investments. We assume an upstream supplier that deals with two cost-asymmetric downstream firms. Our focus is on two-part tariff contracts that can be observable (as in Inderst and Shaffer 2009) or unobservable (as in Rey and Tirole 2007) by downstream firms. With observable two-part tariffs, a ban on input price discrimination always decreases R&D levels, and thus decreases welfare in the long run. With unobservable two-part tariffs, banning price discrimination may increase or reduce R&D levels, depending on the degree of downstream cost-asymmetry. But long-run welfare always decreases after the ban. It is a common presumption that when a ban on input price discrimination increases R&D investments it also increases long-run welfare and vice versa. The above-cited literature that focuses on downstream R&D investments indeed verifies this presumption. We show that it may not necessarily be true for the case of upstream R&D: Banning discrimination reduces welfare even when its effect on R&D investments is positive. R&D investments and welfare may move in opposite directions as a result of the ban when contracts are unobservable—but not when they are observable by downstream firms. The rest of the paper is organized as follows: in Sect. 2, we review the related literature. In Sect. 3, we consider the case of observable two-part tariff contracts, whereas in Sect. 4 we deal with unobservable two-part tariffs. In Sect. 5, we briefly discuss linear tariffs. Section 6 concludes the paper. All proofs are relegated to Appendix 1.",9
57.0,1.0,Review of Industrial Organization,10 July 2019,https://link.springer.com/article/10.1007/s11151-019-09714-5,Performance-Based Road Contracts in Zambia,August 2020,Atsushi Iimi,,,Male,Unknown,Unknown,Male,"Public infrastructure procurement is a complex process that involves substantial uncertainty. The initial engineering design may be imperfect because of unknown geological and hydrological factors. The inputs required may be over- or underestimated. Project completion is often delayed. Even after a project is completed, the delivered object may not function as expected due to a lack of maintenance and other unanticipated events, such as natural disasters. How to manage a contract under uncertain conditions is a common challenge in public procurement. In principle, there are two main regimes: fixed-price contracts; and cost-plus arrangements. In general, the former regime is better than the latter when a principal (e.g., a government) cannot observe efforts by an agent: the contractor (see, for example, Laffont and Tirole 1993). Fixed-price contracts place all of the risk on the contractors. However, there is a trade-off between providing effective incentives and reducing ex post renegotiation costs: While fixed-price contracts incentivize contractors to contain costs, a more flexible regime allowing ex post adjustments can be less costly overall (Bajari and Tadelis 2001). In practice, public authorities seem increasingly to prefer more flexible arrangements that specify only overall outcomes, rather than monitoring individual inputs or technologies. This output-based approach has the general advantage of encouraging innovative solutions while promoting efficiency. In the environmental regulation context, for instance, performance standards are preferred to design standards as they provide individuals and businesses with more opportunities to develop their own strategies (for example, Hueth and Melkonyan 2009). In the road sector, the output- and performance-based road contracts (OPRC) scheme is becoming increasingly popular around the world. Under the OPRC approach, no individual inputs or processes are predetermined by governments. Contractors are obliged to maintain the functionality of contracted roads at an agreed level for a certain period of time. They are responsible for designing, choosing technologies, and investing in and maintaining roads. Their performance is measured only by preset performance criteria, such as surface degradation and road user comfort, not by the quantities of inputs used, such as bitumen and concrete. Despite its growing use, there is little evidence to show whether the OPRC method is actually more effective at maintaining roads than are traditional input-based procurement. This paper aims to answer this question by examining the direct impact on road users—farmers—in rural Zambia, where the OPRC method was introduced in 2009. Our main hypothesis is that road rehabilitation under the OPRC approach could improve transport connectivity, thereby contributing to increasing farmers’ crop production. The sections are organized as follows: Sect. 2 provides a brief literature review of relevant topics; Sect. 3 describes the project context in Zambia; Sect. 4 develops our empirical strategy, and Sect. 5 explains our data; Sect. 6 presents the main results; Sect. 7 discusses the robustness and policy implications of the results; Sect. 8 concludes.",
57.0,1.0,Review of Industrial Organization,24 September 2019,https://link.springer.com/article/10.1007/s11151-019-09731-4,Unilateral Price Effects and Vertical Relations Between Merging and Non-merging Firms,August 2020,Harald Nygård Bergh,Arne Rogde Gramstad,Jostein Skaar,Male,Male,Male,Male,"In recent years, measures using pre-merger margins and diversion ratiosFootnote 1 have been important tools for assessing the unilateral effects of horizontal mergers. Upward Pricing Pressure (UPP) and the Gross Upward Pricing Pressure Index (GUPPI) (Salop and Moresi 2009; Farrell and Shapiro 2010), which are directional measures that are applied to each merging firm, are now standard tools that are used by competition authorities to analyze the merging parties’ incentives to raise prices. In addition, post-merger equilibrium prices can be estimated by assuming linear demand with the use of the same information as with UPP/GUPPI (Hausman et al. 2011). These measures of price effects may be incorrect if vertical relations are affected and not controlled for (Moresi and Salop 2013; Asphjell et al. 2017). This is because sales of inputs can affect the extent to which vertically integrated firms compete over their rivals’s customers. In fact, if a merger eliminates vertical relations between a merging and a non-merging firm, the response from the non-merging firm may go in the opposite direction to that of the merging firms. This paper expands the set of tools that competition authorities and others can use to screen and analyze unilateral effects from mergers. In this context, there are two main contributions: First, we integrate non-merging firms’ responses from changes in vertical relations into the Hausman et al. (2011) framework with linear demand. Second, we extend the framework of linear demand to account for price effects from vertical relations that have been previously analyzed in the literature.Footnote 2 Our contribution is of practical importance for screening mergers in markets that contain a mix of vertically integrated firms and pure downstream retailers that buy inputs from vertically integrated wholesalers with whom they also compete downstream. There are several examples of this: In telecommunications, a few firms typically own the network infrastructure or rights to spectrum, while other firms buy access to their competitors’ network infrastructure.Footnote 3 In grocery markets, smaller retail chains may have supply agreements with larger vertically integrated chains. Other examples include electronics,Footnote 4 web services,Footnote 5 and agriculture.Footnote 6 This paper builds on the literature of Upward Pricing Pressure (UPP) and the related literature on unilateral effects of mergers. 
Shapiro (1996) was the first to propose using pre-merger margins and diversion ratios to assess horizontal mergers with differentiated products. The diversion ratio—which measures the share of sales lost for one product that is recaptured by another product when the price of the former rises—interacted with profit margins gives a measure of the incentive to raise prices following a merger. 
Werden (1996) formalized and extended this framework to measure the critical value of cost reductions that are required to restore pre-merger prices. O’Brien and Salop (2000) defined the “Price Pressure Index” (PPI). This index closely relates to the Upward Pricing Pressure (UPP) and Gross Upward Pricing Pressure Index (GUPPI) that were introduced by Farrell and Shapiro (2010) and Salop and Moresi (2009), respectively. Willig (2011) generalized this framework to account for quality-adjusted prices, output effects, and firms that acquire partial stakes in other firms.Footnote 7 The UPP framework provides only a directional indication of price effects and does not capture the equilibrium effects of mergers. Assuming linear demand, Hausman et al. (2011) derived a formula that solves the post-merger equilibrium prices for the merging firms. Further generalizations on pass-through and non-Bertrand conduct are provided by Jaffe and Weyl (2013).Footnote 8 Vertical relations have been incorporated by Moresi and Salop (2013) and Asphjell et al. (2017). Moresi and Salop (2013) introduced the vGUPPI concept for vertical mergers, with three types of vGUPPIs: effects on input (wholesale) pricing incentives for the upstream merging firm vis-a-vis rivals (vGUPPIu); effects on output pricing incentives for downstream rivals that are due to increased input pricing (vGUPPIr); and effects on retail pricing incentives for the downstream merged firm due to increased input sales for the upstream firm to downstream rivals (vGUPPId).Footnote 9 
Asphjell et al. (2017) study unilateral price effects of a vertically integrated firm that merges with a downstream rival to which it sells inputs before the merger. In that case, competition is partially internalized before the merger, as diverted sales to the downstream rival are partially recaptured by increased input sales. The authors adjust Hausman et al.’s (2011) formula to account for pre-merger internalized competition from vertical relations. Our contribution to the literature is twofold: First, we incorporate price effects from non-merging firms due to changes in vertical relations. To the best of our knowledge, we are the first formally to incorporate this price effect.Footnote 10 Second, we adjust Hausman et al.’s (2011) formula to account for the unilateral effects from the vertical relations that have been previously highlighted in the literature.Footnote 11 The remainder of the paper is structured as follows: Sect. 2 sets up the model. Sect. 3 solves the model and provides the price effects formula. Examples where our framework is applied is given in Sect. 4. Section 5 concludes.",3
57.0,1.0,Review of Industrial Organization,03 October 2019,https://link.springer.com/article/10.1007/s11151-019-09732-3,Decisions of Duopoly Firms on Sharing Information on Their Delegation Contracts,August 2020,Kyung Hwan Baik,Dongryul Lee,,,Unknown,Unknown,Mix,,
57.0,1.0,Review of Industrial Organization,01 January 2020,https://link.springer.com/article/10.1007/s11151-019-09743-0,Antitrust Fines: Experiences from China,August 2020,Ran Jing,Jiong Gong,Fang Yi,,,,Mix,,
57.0,2.0,Review of Industrial Organization,19 June 2020,https://link.springer.com/article/10.1007/s11151-020-09767-x,"Global Value Chains: Inter-Industry Linkages, Trade Costs and Policies",September 2020,Bernard Hoekman,,,Male,Unknown,Unknown,Male,,
57.0,2.0,Review of Industrial Organization,14 August 2020,https://link.springer.com/article/10.1007/s11151-020-09781-z,Made in the World? Global Value Chains in the Midst of Rising Protectionism,September 2020,Sébastien Miroudot,Håkan Nordström,,Male,Male,Unknown,Male,"In the last decade, the concept of ‘global value chain’ (GVC) has become popular to describe the way that firms vertically fragment their production into different stages that are located in different economies. The concept was first introduced by Gereffi et al. (2001) to analyze governance structures in sectors that produce for global markets and is now widely used to study structural changes in the global economy (Gereffi 2019). The ‘made in the world’ narrative suggests that production today is global: with inputs that come from all parts of the world before being assembled into final products that are also shipped all over the world. However, the empirical basis of this story has been questioned. First, even before the rise of protectionism, there was a debate about whether GVCs are truly global. For example, Baldwin and Lopez-Gonzalez (2015) argued that global production networks are “marked by regional blocs, what could be called Factory Asia, Factory North America, and Factory Europe”. Second, following the recovery from the 2008 financial crisis, rising protectionism was pointed out as a determinant of the globalization slowdown (Bown 2018). This protectionism was first observed among G20 economies through a more frequent use of non-tariff measures and trade remedies (Evenett 2019) and turned into trade wars after 2018 (Crowley 2019). Falling trade barriers after the creation of the WTO and decreasing communications cost with the information technology revolution were the main drivers of the rise of GVCs in the 1990s. While new technological advances in the digital era can still reduce trade costs, protectionism can offset the gains from foreign sourcing and encourage firms to source locally or from less distant countries—and thus trigger a ‘deglobalization’ (James 2018). Whether we have entered into a new era of deglobalization and whether GVCs are becoming less global is an empirical matter. Several types of indicators that are based on international input–output tables are now available to shed light on these questions (Johnson and Noguera 2012; Koopman et al. 2014; Timmer et al. 2014; Los et al. 2015; Johnson 2018). In this paper, we offer a comprehensive review of the evidence that is based on the 2018 release of the OECD TiVA database and underlying inter-country input–output (ICIO) tables, including new indicators that count the number of domestic and foreign production stages, border crossings, and geographic length of supply chains. Moreover, in order to examine a longer time period, we add information from the previous edition of the OECD database that covered 1995 to 2011. The two sets of data are not fully comparable as national accounts moved from definitions and standards of the 1993 System of National Accounts (SNA) to the new 2008 SNA. We present data separately for 1995–2011 and 2005–2016 to make sure that the interpretation of results is not affected by this change in national accounting practices. The paper is organized as follows: Sect. 2 introduces the basic value chain tools and the OECD ICIO that is used in the empirical analysis. Section 3 explains how to measure the internationalization of supply chains in the conventional way of decomposing value added by country and industry. It provides the first evidence of a deglobalization in terms of lower levels of foreign value added in exports. Section 4 then investigates whether this decline in value added corresponds to shorter value chains in the sense of fewer production stages; we build on Fally´s (2012) measure of embodied production stages. Section 5 reviews the evidence whether supply chains are regional or global, and in Sect. 6 we examine whether there has been a decrease in the geographic length of supply chains in the recent period. Section 7 concludes.",15
57.0,2.0,Review of Industrial Organization,11 June 2020,https://link.springer.com/article/10.1007/s11151-020-09762-2,The Gravity of Intermediate Goods,September 2020,Paola Conconi,Glenn Magerman,Afrola Plaku,Female,Male,Unknown,Mix,,
57.0,2.0,Review of Industrial Organization,06 July 2020,https://link.springer.com/article/10.1007/s11151-020-09773-z,Footloose Global Value Chains: How Trade Costs Make a Difference,September 2020,Adam Jakubik,Victor Stolzenburg,,Male,Male,Unknown,Male,"International trade occurs increasingly within global value chains (GVCs), which combine raw materials, intermediate parts, and services—often in long sequences and complex production networks that span multiple countries—into final products which are exported to consumers all over the world. Over the last decades, the increased fragmentation of the production process—which has been enabled by technological innovations in manufacturing, communications, and transport—has led to increased international specialisation according to comparative advantage (Hummels et al. 1998, 2001). These developments have led to welfare gains through higher productivity and lower prices for consumers (Amiti and Konings 2007; Caliendo and Parro 2015; Kummritz 2016; Caliendo et al. 2019). Furthermore, they have allowed developing countries to participate in global production according to their capabilities, which has resulted in increased incomes and positive knowledge spillovers (Beverelli et al. 2019). These developments have also brought new prominence to trade policy. While trade costs for decades have decreased due to trade liberalisation and technological innovation such as container shipping and airfreight, recent policy decisions have resulted in increased trade costs. In particular, the trade conflict between the United States and its major trading partners has driven up tariffs on a wide range of goods (Bown 2019); and the decision of the UK to leave the European Union has raised uncertainty about future trade policy, which drives up expected future trade costs and acts as a barrier to exporter market entry (Crowley et al. 2019). The World Uncertainty Index—which uses country reports by the Economist Intelligence Unit and a methodology that was developed by Baker et al. (2016)—has reached a record high in 2018 as a result of these events (Ahir et al. 2019). Both theory and empirical evidence point to trade policy uncertainty as an important component of overall trade costs (Dixit 1989; Handley 2014). As production networks have become complex and intricate, they have become increasingly exposed to such disruptions. Furthermore, theory tells us that under certain conditions even small shocks to sectoral productivity in interlinked production networks may have large macroeconomic consequences (Acemoglu et al. 2012). Firms make decisions on sourcing inputs and locating final assembly stages according to the global trade policy landscape. In a world of GVCs trade costs have become more important than ever. With the fragmentation of production stages across borders, final goods embody the costs of tariffs that are imposed on semi-processed products several times during the production process. As a result, GVCs are associated with an accumulation of tariff-related costs that arise along the chain of production. Yi (2003) describes how this accumulation effect causes tariffs to have a nonlinear effect on trade by hampering GVCs: for instance, in the simple case where all countries impose tariffs of 5%, a traditionally (purely domestically) produced and exported final good has a total tariff incidence of 5%. A final good produced across five separate stages in five different countries, each of which add an equal amount of value, has a total tariff incidence of 16%, since a 5% tariff has to be paid each time that an intermediate input crosses a border, if the full value of the good at that stage is taxed.Footnote 1 In this context, some stages of production may be more internationally footloose than others. GVCs not only imply that tariffs are accumulated along the supply chain, which makes downstream production stages more cost sensitive, but their effect also is magnified for production stages that add relatively little value compared to other stages. Baldwin et al. (2014) and WTO et al. (2019) describe the nonlinear patterns of value added along the production process: Some stages add most of the value, and others stages add relatively little. As tariffs are applied to the full value of the good and not just to the value added at a particular stage, the tariff rate in proportion to value added at any given stage can be quite high for certain low value-added production stages: this is known as the “magnification effect” (Koopman et al. 2014; Diakantoni et al. 2017). Assume for instance that an assembly firm imports $100 of inputs, assembles them, and sells the final good for $110: it thus adds $10 of value, of which $5 go towards labour costs and $5 are profits. Then, the introduction of a tariff of 5% on the inputs completely absorbs the firms’ profits. Production stages that add relatively little value to a good—such as assembly—are as a consequence more sensitive to trade costs relative to the sensitivity of other stages. Koopman et al. (2014) find that due to the magnification effect, an additional production stage would increase the trade costs that are faced by Vietnam in merchandise trade by an equivalent of 80% of the tariffs that it currently faces since the additional production stage would raise the value of its imported inputs relative to the value that its own stages add. Koopman et al. (2014) also find that in general emerging economies are more exposed to magnification than are developed economies as the former tend to specialise in tasks that add relatively little value. In addition to being disproportionately burdened by trade costs, low value-added production stages are also relatively easy to relocate internationally. These production stages typically do not require a skilled workforce and do not rely on tacit knowledge. They tend to involve simple and routine work processes that can be easily codified. As a result, they do not give rise to large fixed costs when setting up or closing down, which makes them more responsive to changes in trade costs. In contrast, stages that add more value—such as R&D, design, or marketing—typically depend on a highly qualified and trained workforce that provides highly differentiated inputs and cannot easily be replaced by workers in a different country. The same logic applies to stages that rely on the particular comparative advantage of a country—for instance, due to the presence of natural resources. Such stages are considerably less footloose. In this paper we confirm and quantify this intuitive hypothesis and show that trade costs are relatively more consequential for stages that add little value to a good. Using industry-level data for 64 countries from 1995 to 2011 from the OECD–WTO Trade in Value Added (TiVA) database, we apply a standard gravity framework to estimate a differential impact of ratios of domestic value added to exports on trade-cost elasticities. We find that trade flows of industries that have low ratios of domestic value added to exports respond significantly more to changes in trade costs than do industries with high ratios. These results are both statistically and economically significant. Our most conservative estimates imply that while an industry at the bottom twenty-fifth percentile in terms of share of foreign value added in exports (high domestic value-added share) does not respond to an increase in trade costs, at the seventy-fifth percentile (low domestic value-added share) the trade-cost elasticity is statistically significant, such that doubling the tariffs faced by an exporting sector leads to an average reduction in bilateral annual exports of $3.14 million in that sector. This is an important result because the elasticity of trade flows with respect to trade costs is a key parameter to quantify welfare gains from trade. Arkolakis et al. (2012) show that a broad class of the most prominent trade models in the literature that assume Dixit–Stiglitz preferences, one factor of production, linear cost functions, complete specialisation, iceberg trade costs, and either perfect competition (Anderson and Van Wincoop 2003; Eaton and Kortum 2002) or monopolistic competition (Melitz 2003) share two common parameters that are sufficient for quantifying the welfare gains from trade: the import penetration ratio; and the trade elasticity with respect to variable trade costs. The policy relevance of this finding becomes apparent when viewed together with results from Jakubik and Stolzenburg (2018). The effects of import competition on labour markets differs based on the exporter’s domestic-value added share in gross export value, which reflects the exporter’s inherent comparative advantage in producing the good. Jakubik and Stolzenburg (2018) show that exposure to imports from Chinese industries with a higher share of Chinese value added causes greater local labour market adjustments in the US. Since exports from these high domestic (Chinese) value-added sectors are less sensitive to trade costs, our research suggests that raising bilateral trade barriers is unlikely to shield US labour markets effectively from import competition. Instead, it causes the low domestic (Chinese) value-added assembly stages to shift out of China, but these stages do not contribute significantly to US labour market adjustment. Our finding is also relevant from a development policy perspective. Many developing and emerging economies join GVCs by specialising in stages that add relatively little value. Since these are the most footloose stages, these countries are more exposed to the risks and uncertainties that have been created by the current trade policy environment. Much of the closely related research on this topic is recent or still unpublished, which shows that the sensitivity of GVCs to trade costs is a topical, emerging area of research. Heise et al. (2017) model the impact of trade policy changes on the formation of GVCs. They show that reductions in trade policy uncertainty will lead to the formation of Japanese-style just-in-time sourcing practices that are characterised by long-term buyer–supplier relationships that enhance operational efficiency and lead to substantial welfare gains. In the alternative, for American-style production networks the buyer typically chooses the lowest-cost option for each order via competitive bidding without investing in the buyer–supplier relationship. The focus of their paper is on the impact of trade costs—specifically expected future trade costs—on the nature of global production networks, whereas we focus on the impact of trade costs on the relative sensitivity of the location of low value-added production stages as compared to high value-added production stages. In the presence of costs from switching suppliersFootnote 2 and taking into account further linkages in the production network, Huneeus (2018) estimates that the effects on output of the international trade shocks that faced Chile due to the Great Recession were significantly amplified due to the switching costs. In the context of our finding that low value-added production stages are more footloose, further research is needed to understand how these production stages are affected by international trade shocks and switching costs: since these costs are large relative to profits they may disproportionately affect the markups or output losses in low value-added production stages. Johnson and Moxnes (2019) offer a different argument for how trade costs shape value chains, which is based on a quantitative model.Footnote 3 In their model, as the level of trade costs falls, value chains reorganise endogenously. Distance becomes a more dominant force under lower trade costs so spatial clustering increases, as does the prominence of so-called export platforms. These platforms can be viewed as final assembly stages, since these stages endogenously locate to places with relatively low iceberg trade costs. Moreover, the proportion of input trade to final goods trade increases, which could be viewed as a proliferation of GVCs, and input trade is more trade-cost elastic. Therefore, bilateral gross trade becomes overall more elastic to trade costs. Antràs and De Gortari (2020) use a general equilibrium model to study the specialisation of countries within GVCs. In addition to the marginal cost of producing a given stage in a given country, spatial proximity to upstream and downstream stages matters. An important insight from their model is that, since trade costs at each stage of production will compound along the value chain, these costs will erode more value in downstream relative to upstream stages. The upshot is that trade-cost elasticities are stage specific, and will increase further down the value chain. The authors use the WIOD and EORA datasets to provide some suggestive evidence for this observation. First they note that countries tend to rely on foreign sources more prevalently for inputs than for final goods which is consistent with the notion that trade costs are more detrimental for downstream versus upstream stages. As further evidence, they compare the trade elasticities of distance in a standard bilateral aggregate trade gravity framework and find that this is larger for final goods than for intermediate inputs. The authors conclude that trade barriers impede trade more severely for downstream stages than for upstream stages—with the caveat that their gravity specification does not take into account third-country effects in the form of multilateral resistance. These results taken together are suggestive evidence to motivate their theoretical assumptions. The authors then estimate the elasticities in their structural model with the use of WIOD data and perform counterfactual exercises to study how changes in trade costs will impact countries’ GVC participation. Rather than examine differences in intermediate and final goods trade, or upstream versus downstream stages more generally, our intention is to test the hypothesis that an industry’s ratio of domestic value added to exports determines the sensitivity of exports in that industry to trade costs, which requires a detailed country-sector value-added decomposition of bilateral trade flows. The rest of this paper is organised as follows: Sects. 2 and 3 discuss the data, followed by Sect. 4 on the empirical strategy. Section 5 presents the results, and Sect. 6 concludes.",
57.0,2.0,Review of Industrial Organization,09 July 2020,https://link.springer.com/article/10.1007/s11151-020-09774-y,Backward and Forward Integration Along Global Value Chains,September 2020,Davide Del Prete,Armando Rungi,,Male,Male,Unknown,Male,"In 1871, Continental AG was founded in Germany and started its business as a rubber manufacturer. Nowadays, it is one of the largest manufacturers of tires; but, since its foundation, it has extended its range of activities including both backward (upstream) and forward (downstream) tasks along the automotive chain. For example, Continental AG acquired the segment of brakes and chassis in 1998 from ITT Inc. It concluded a deal with Motorola in 2006 to take over the segment of automotive electronic components ant it acquired the VDO brand by Siemens for powertrain and fuel injection systems in 2007. Later, in 2015, the company moved further upstream after the acquisition of the US firm Vejance Technologies, which is a supplier of engineered rubber products. Consider also Acer: the Taiwanese company started in 1976 as an electronic components importer and became among the top producer of PCs in 2 decades. Upstream, in 1989 Acer partnered with Texas Instruments to produce semiconductors; and in 1998 it partnered with TI for additional electronic components. Downstream, Acer’s regional business units took over local assembly, and it started to develop capabilities in distribution activities (Bartlett and Ghoshal 2000). More generally, we may think of many cases in which a manufacturer extends its firm boundary to include other activities both upstream and downstream. Both backward and forward integration strategies shape the firm-level organization of global value chains (GVCs). From our data, we estimate that they represent about 45% and 35%, respectively, of all parent-subsidiary relationships. Yet, many studies make the unrealistic assumption that integration decisions are one-directional and binary: that is, companies can go either backward or forward but not in both directions and only one supplier is needed for the specific input. For example, there is the voluminous trade literature that was inspired by Antràs (2003) and followed by Antràs and Chor (2013) and Alfaro et al. (2019), who model integration as always starting from the bottom of the supply chain; consequently, the coexistence of forward and backward integration choices (from now on, VIF and VIB, respectively) is assumed away. If the two types of integration coexist and are driven by different mechanisms, any empirical exercise that is based on the one-directional assumption may well be biased. The aim of this paper is to analyze the firm-level organization of GVCs when both VIB and VIF decisions are taken into account. To this end, we adopt a framework in which production processes are sequential on an ideal supply chain. Therefore, GVCs can be organized in two organizational modes: (1) firms exchange goods at arm’s length when they sign supply contracts (outsourcing); or (2) firms integrate one or more production stages after establishing new affiliates or taking over companies that will eventually exchange intermediate goods intra-firm, within the boundary of the group that may stretch across national borders. The latter case is visualized in Fig. 1, where the principal (a parent firm) can decide to integrate an agent (a subsidiary) under a unique firm boundary. The arrows indicate the transaction direction. In the VIB case, the buyer (parent) employs the supplier (subsidiary) of an intermediate input, whereas in the VIF case the supplier (parent) of the intermediate input employs one of its buyers (subsidiaries). Backward and forward integration along GVCs For our purpose, we exploit a sample of 201,272 multinational enterprises (MNEs) that control about 1.2 million domestic or foreign subsidiaries. Then, we further identify newly established subsidiaries or takeovers that were completed in the period 2004–2012. First, we find that parent companies are more likely to integrate production stages that have a relatively low elasticity of substitution—whether as a buyer or a supplier in an input–output relationship—possibly because an underinvestment by a low substitutable firm would undermine the value that is generated at the end of the chain. In this framework, we rely partially on the intuition by Antràs and Chor (2013), although they assume that only final producers can start integration, which excludes VIF. Yet, they were the first to introduce the notion of interdependence along the GVCs, where all buyers and suppliers must rely on a partition of the final surplus. We believe that the latter is a peculiar characteristic of fragmented production processes that are oriented over a technological sequence. This is also in line with the original assumption of the contract theory of the firm that was sketched in the seminal work by Grossman and Hart (1986) and Hart and Moore (1990) whereby, in presence of incomplete contracts, vertical integration helps mitigate inefficiencies that arise from underinvestment, and the party whose marginal investment is more relevant should start integration. Second, we find that integrated activities—both VIF and VIB—tend to be proximate on a supply chain: a parent company is less likely to integrate subsidiaries if they perform activities that are technologically remote from its core activity. Such a proximity on supply chains can be explained by the existence of economies of scope across similar stages, when it is easier to coordinate activities that share some technological features (Del Prete and Rungi 2017). Finally, we provide evidence of a multiplication of subsidiaries that perform the same production stages in a given location. As far as we know, the latter is a largely unexplored fact that paves the way for an understanding of an important organizational characteristic of GVCs. We find that for 26% of cases in our sample the activity by a subsidiary is a duplicate at the industry–country level. This is consistent with Atalay et al. (2019), who provide a first rationale for the duplication of integrated stages: they found that having an additional vertically integrated establishment in a given destination ZIP code within the US has the same effect on shipment volumes as a 40% reduction in distance. To grasp the essential aspects of our main findings, let us consider three case studies of downstream, midstream, and upstream parents from our data that are reported in the upper, middle, and bottom panels, respectively, of Fig. 2. For each case, we plot the relative positions on the supply chain of both the parent company and its affiliates.Footnote 1 Cases of a downstream, b midstream, and c upstream parent companies First, we show Daimler AG—a German multinational automotive corporation that is headquartered in Stuttgart, Baden-Württemberg—which presents a downstreamness measure of 0.99, quite close to final demand. The German corporation controls 357 subsidiaries around the world; all are located relatively more upstream than the parent company: performing production processes that supply inputs that are required for the core activity of the headquarters. Hence, we consider them as choices of backward integration. Of these subsidiaries, 62% are a duplicate at the country–industry level within the firm boundary: there is more than one subsidiary in Daimler AG that performs the same production stage in a given location. Second, we report a case of a midstream parent company—Continental AG—which is a leading German automotive manufacturer specialized in tires, brake systems, and other parts for the automotive and transportation industries. It has a downstreamness of 0.69 and controls 279 affiliates, which are located both upstream and downstream along the chain: the headquarter of Continental AG receives inputs from some subsidiaries, but also delivers inputs to other subsidiaries along the automotive supply chain. In total, there is a redundancy of 59% subsidiaries within Continental AG that perform the same production stage. Finally, we report the case of ArcelorMittal: the world’s largest steel producer headquartered in Luxembourg City. This is a typical case of forward integration. Its headquarters are upstream, with a downstreamness measure of 0.3, which has integrated over time 631 downstream affiliates. In the case of ArcelorMittal, we also find a remarkable share of production stages duplicated within the firm boundary: 67%. In sum, it is common in our data to find a multiplicity of organizational modes—including both VIF and VIB and a duplication of production stages along the supply chain. From our point of view, these findings violate the main stringent assumptions of existing theoretical models of GVCs, according to which integration always starts from either the top or the bottom of the supply chain, and only one supplier of an intermediate input is needed for the technological sequence. The remainder of this paper is organized as follows. In Sect. 2, we briefly review related works. Section 3 introduces the construction of our sample and first evidence from descriptive statistics. In Sect. 4, we present empirical analyses and robustness checks. Section 5 concludes.",5
57.0,2.0,Review of Industrial Organization,29 June 2020,https://link.springer.com/article/10.1007/s11151-020-09772-0,"Policy Uncertainty, Trade and Global Value Chains: Some Facts, Many Questions",September 2020,Cristina Constantinescu,Aaditya Mattoo,Michele Ruta,Female,Unknown,Female,Female,"Global trade has grown slowly after the Great Recession, and 2019 is projected to continue the trend as one of the years with the weakest trade performance since the 2008–2009 global financial crisis. A growing body of work analyzes the determinants of the current slowdown in global trade (Constantinescu et al. 2015; Hoekman 2015; Haugh et al. 2016; IMF 2016). Recent analyses attribute the trade slowdown, in varying degrees, to such factors as: changes in the composition of economic activity away from import-intensive investment; a slowing pace of global value chain growth and trade liberalization; and an increase in trade protectionism. This paper draws upon recent pioneering work on the measurement and impact of economic policy uncertainty (Baker et al. 2016) to examine whether policy uncertainty can help explain the slowdown in world trade growth. To motivate the analysis, Fig. 1 juxtaposes the growth in the volume of world merchandise imports against an index of global economic policy uncertainty. The figure does suggest that there is a negative association between the two, and the particularly weak trade performance in 2016 has coincided with unusually high levels of economic policy uncertainty in that year. Source: CPB Netherlands Bureau of Economic Policy Analysis, www.PolicyUncertainty.com, Baker et al. (2016), and authors’ calculations World import growth and policy uncertainty, January 2012 to June 2019. Economic policy uncertainty can reduce trade growth in two ways: First, a rise in policy uncertainty reduces trade indirectly by reducing GDP growth. In a less-certain environment, firms may choose to postpone investment decisions, consumers may cut back spending, and banks may increase the cost of finance. Second, policy uncertainty, may affect trade directly, by affecting firms’ decisions to invest to serve foreign markets or to source inputs internationally. An important question is whether economic policy uncertainty affects trade that involves global value chains (GVCs) more than other trade. There are contrasting effects that play out over time because GVC trade requires larger upfront relation-specific sunk investments and is concentrated in capital intensive sectors. These investments make GVC trade flows stickier and less responsive to any change in the environment—including economic policy uncertainty. However, since economic policy uncertainty affects investment choices, it should eventually have larger effects on GVC trade as compared to other trade. These effects are confounded by the fact that consumer and producer investment goods are typically produced through longer GVCs. Trade in these investment goods is likely to be more sensitive to demand for investment that is affected by policy uncertainty. The combination of these forces determines whether economic policy uncertainty affects GVC trade differently from other trade. We conduct a panel estimation that covers 18 countries over 24 years. Our results—which are robust across a wide range of specifications—suggest a statistically significant negative impact of policy uncertainty on trade growth: A 1% increase in uncertainty is associated with a 0.02% point reduction in goods and services trade volume growth. For example, based on these estimates, the increase in economic policy uncertainty since mid-2018 may have caused a 1% point decrease in world trade growth. The finding is robust to focusing on subcategories of trade and employing different specifications. GVC trade appears to be as sensitive to uncertainty as non-GVC trade. Examining the effect on the components of trade may help illuminate the economic channels through which policy uncertainty affects trade. We find that economic policy uncertainty negatively affects imports of capital goods, imports of non-durable consumer goods, and imports that are used to produce exports (which is likely to be GVC trade). These findings are consistent with the view that economic policy uncertainty reduces trade growth by reducing foreign firms’ incentives to invest in serving the market, by inducing consumers’ precautionary saving, and by affecting firms that are part of global value chains. The implication of this result is that economic policy uncertainty has contributed to the sluggishness in world trade growth in recent years. However, its consequences for GVCs are less clear. We find that trade that is linked to GVCs responds to economic policy uncertainty in a way that is broadly similar to overall trade. As discussed above, this could be the result of opposing forces that link uncertainty to GVC trade. In the long term, we would expect the negative forces to dominate as economic policy uncertainty would induce firms to withhold investments today that would promote GVC trade tomorrow. We also examine at trade policy uncertainty, which has been an important component of economic policy uncertainty in recent times. We rely on the work of Ahir et al. (2019) that builds on the EPU index methodology to include trade-related keywords and construct a world trade uncertainty (WTU) index. The index documents the large increase in trade policy uncertainty since 2017. But when we use the WTU index in our econometric analysis, we do not find a consistent negative effect of trade policy uncertainty on overall and GVC trade. Rather, this effect varies by country and is at times negative and at times positive. This puzzling result depends on two main factors: First, the measure of trade policy uncertainty is based on the presence of the words “uncertainty” and “trade” in proximity within press articles. This approach does not allow us to distinguish between different types of uncertainty that could have different effects on trade: whether the trade policy uncertainty is “negative”—about the implementation of tariff increases—or “positive”: about the conclusion of a new trade liberalization agreement. Second, the measure fails to distinguish between whether the trade policy uncertainty measure for a specific country relates to its policies vis-à-vis all other countries or specific countries. Threats of escalating tariffs solely on trade between the US and China increase policy uncertainty worldwide. But its impact on US–China trade could be very different from the effect on trade between the US (or China) and third parties, which may benefit from uncertainty-induced trade diversion. The rest of the paper is organized as follows: Sect. 2 reviews the existing literature on policy uncertainty. Section 3 presents the empirical strategy. Section 4 discusses the key results, which use the economic policy uncertainty index, while the trade policy uncertainty index is used in Sect. 5. Concluding remarks follow.",13
57.0,2.0,Review of Industrial Organization,15 July 2020,https://link.springer.com/article/10.1007/s11151-020-09769-9,Critically Important: The Heterogeneous Effect of Diplomatic Tensions on Trade,September 2020,Julian Hinz,Elsa Leromain,,Male,Female,Unknown,Mix,,
57.0,2.0,Review of Industrial Organization,29 June 2020,https://link.springer.com/article/10.1007/s11151-020-09770-2,Services Input Intensity and US Manufacturing Employment Responses to the China Shock,September 2020,Omar Bamieh,Matteo Fiorini,Adam Jakubik,Male,Male,Male,Male,"The rapid rise in China’s share of global trade since the early 1990s has generated significant adjustment pressures in countries around the world. Recent research on the impact of the steep rise in exports of manufactures from China to the United States on US manufacturing employment has documented the regionally differentiated effects of the “China shock” (Autor et al. 2013, 2020). Of particular note is the finding that the negative effects on manufacturing employment in local labor markets (commuting zones) are substantial and that during the time period that was investigated other economic sectors within commuting zones do not provide alternative employment opportunities to affected manufacturing workers (Acemoglu et al. 2016), which implies that much of the adjustment to the shock takes the form of exit from the labor market. Aggregate employment and productivity growth in the US and other high-income advanced economies is increasingly intertwined with the performance of the service sector. The share of manufacturing in total employment has been falling since the late 1970s, with a concomitant steady increase in the services content of production, consumption and employment. At the level of the economy as a whole, competition from China and other emerging economies is just one—albeit important—factor that has induced shifts in employment away from manufacturing and towards services sectors. These shifts in US comparative advantage are driven by technical change and investment responses to policies in both the US and in the rest of the world (China). Services account for an increasing share of US exports (34 percent in 2016, up from 27 percent in 2000); in 2016 the services trade balance registered a surplus of $248 billion, compared to a merchandise trade deficit of $752 billion.Footnote 1 US comparative advantage in services reflects human capital endowments and the ability to take advantage of services agglomeration externalities (Gervais and Jensen 2019). These broader features of structural transformation of the US economy are important in assessing the determinants of the impact of the China shock. In this paper we focus on one specific dimension of the ‘servicification’ of the US economy: the role of cross-sectoral variation in services input use (arms-length purchases of services) by manufacturing sectors as a factor that influences the resilience of the latter to greater import competition from China. Given that the US has a revealed comparative advantage in services, downstream industries that are relatively intensive users of services may be better able to withstand import competition from China. We show that industries where production is relatively services intensive have fared better in terms of employment because their competitiveness has either prevented significant Chinese import penetration in their sector or secured them a distinct market segment even in the face of import penetration. Given the worldwide trend of structural transformation, we propose a sector-level measure of services input intensity (SII), which is an internationally comparable statistic that broadly captures the variety of advantages that accrue to manufacturing industries that use services inputs. We know from previous literature that relative to intermediate parts and components, services are special inputs that enhance competitiveness through complex mechanisms: e.g., they coordinate increasingly fragmented global production processes; manage within-firm processes; coordinate between upstream suppliers and downstream customers in global value chains (GVCs) (Francois 1990; Baldwin et al. 2015); and finally R&D, product development, innovation, and marketing help meet market demand and anticipate future preferences (Bloom et al. 2016). At our level of analysis we do not disentangle the relative importance of these services-dependent mechanisms, which are better studied using firm-level data. It is helpful to illustrate the role of services inputs using the case of Carhartt: an apparel manufacturer that operates in an industry where Chinese import competition has largely substituted for US manufacturing. The company has been able to continue to operate factories in the US that, employ around 2200 workers. Carhartt has used advertising services successfully to differentiate itself, emphasising the quality and durability of its products; it has used external consulting services to optimise business processes; it has promoted consumer engagement on e-commerce platforms to build its brand; and it has captured additional value-added by branching into retail. The latter elements of its strategy have been implemented through the use of cloud-based transportation management technology that has been sourced from specialized services consulting firms that led to efficiency gains through supply-chain optimization (GlobeNewswire 2016). Use of such outsourced services inputs have helped Carhartt compete with imports by reducing costs, but more important is that these services inputs have allowed the company successfully to meet market demand and respond to changing consumer tastes in a way that many other import-competing products have not been able to replicate. The literature on services inputs into manufacturing highlights their special function in coordinating and logistics that support the process of production fragmentation and specialisation, which in turn improve industry-level efficiency and competitiveness. For instance, information and communications, transport, and logistics services are needed to connect labor and capital across space; and financial and insurance services allow firms to manage the risks of routine operations as well as the risks that are inherent in innovation and experimentation (Francois 1990; Francois and Hoekman 2010). In a world of global value chains (GVCs) where production involves the coordination across space and time of intermediate inputs that are produced by firms that are located in different regions or countries, this coordination function is particularly important. Baldwin et al. (2015) note that transport, telecommunications, logistics, and distribution services account for an increasing share of total value added in manufacturing because of the increasing fragmentation of the production process and the outsourcing of non-core activities. In the increasingly complex value chains that characterise modern manufacturing, parts have to be shipped and activities coordinated in ways that minimize the need for (cost of) storage.Footnote 2 Services outsourcing as a driver of firm performance has been the subject of numerous papers, with research identifying a positive effect of services outsourcing on productivity at both the firm level (see for instance Görg et al. 2008; Hijzen et al. 2010) and at the sector level (see Amiti and Wei 2009; Winkler 2010). For example, Görg and Hanley (2011) identify a positive impact of outsourcing of services on innovation practices in a sample of Irish manufacturing firms. The use of ICT services in a broad range of industries has been a driver of US output and productivity growth since the mid-1990s (van Ark et al. 2008). Our analysis extends the literature in several respects: The main contribution is to assess the role of services input intensity as a determinant of the local manufacturing employment response to greater import penetration. We complement Acemoglu et al. (2016) by showing that labor demand effects within a commuting zone are a function of the degree of sectoral exposure to Chinese imports, but that the services intensity of production is an additional factor that should be considered. More generally, our analysis contributes to the debate on the employment effect of services outsourcing. This literature has identified different theoretical channels with a net ambiguous effect on employment.Footnote 3 To the best of our knowledge the role of services outsourcing on the response of manufacturing employment to trade shocks has not been investigated. In doing so, we contribute to the broader debate on the role of services in aggregate economic performance and structural transformation (see Schettkat and Yocarini 2006; Young 2014; De Backer et al. 2015). We analyze the heterogeneity of local manufacturing employment effects of the China shock, focusing specifically on the question of whether differences in the intensity of use of externally purchased services inputs across US manufacturing industries are associated with greater resilience of employment to import competition from China. We use the empirical approach that was developed by Autor et al. (2013) to identify the employment response of manufacturing sectors at the commuting zone level in the US. We do not take a stance on whether it is appropriate to limit analysis of Chinese competition to a relatively short-run setting in which worker mobility is assumed to be very limited. Our goal is simply to deepen the understanding of the factors that determine the cross-sectoral variation in employment effects at the level of local labor markets. We find that more intensive use of producer services appears to be positively associated with resilience to import competition. The remainder of the paper is organized as follows: Sect. 2 presents the data on services input intensity. Section 3 lays out the empirical strategy. Results are reported and discussed in Sect. 4. Section 5 concludes with some implications for further work.",4
57.0,2.0,Review of Industrial Organization,01 July 2020,https://link.springer.com/article/10.1007/s11151-020-09771-1,Make or Buy: Offshoring of Services Functions in Manufacturing,September 2020,Hildegunn Kyvik Nordås,,,Female,Unknown,Unknown,Female,"Between 25 and 60% of employment in manufacturing is in services functions such as transport, marketing, IT, R&D, management, maintenance, repair, cleaning, and training (Miroudot and Cadestin 2017). Digitisation and trade liberalisation have significantly decreased transaction costs in services, which has opened the opportunity to outsource such supporting services. Following the rise of India as a major exporter of computer services, scholars took interest in the offshoring of services, which is sometimes referred to as “trade in tasks” (Grossman and Rossi-Hansberg 2008). Trade in tasks is portrayed as the latest turn in the spiral of ever-deepening specialisation and fragmentation of production. According to business surveys in Europe and the Americas, however, firms tend to outsource services functions rather than individual tasks.Footnote 1 Furthermore, the surveys reveal that most firms outsource locally. When they buy services from abroad, the source is most often countries in the same region with similar production costs as in their own country. Multinationals are more likely to offshore than are local firms, and the former often offshore from their own subsidiaries. The story of deepening globalisation through the slicing of the value chain into ever thinner slivers seems not to tally with the insights from these surveys. This paper proposes an empirical approach to study the make-or-buy decision that is embedded in the offshoring literature in a multi-country setting. It exploits new information on employment in services within manufacturing firms and the 2016 release of the World Input Output Database (WIOD) to map the services functions that are produced inside the manufacturing sector and services that are provided by outside suppliers. I next use this mapping to create a new measure of narrow outsourcing and offshoring, which makes it possible to analyse rigorously the make-or-buy decision for services in the offshoring context in a similar manner as for goods. The empirical literature on offshoring distinguishes between narrow and broad offshoring. The former includes imported intermediate inputs from the importing industry only, while broad offshoring comprises imports of any intermediate inputs. Broad offshoring captures all imports of intermediate inputs—not only inputs that are commonly produced in-house—and empirical offshoring studies therefore prefer to analyse narrow offshoring. From this perspective, offshoring of services is excluded. Given the importance of services functions inside manufacturing firms, however, narrow offshoring should capture not only the fabrication activities in manufacturing but also the supporting services functions. Consider for example a computer engineer who is employed in the IT department of a car manufacturer. The market for her skills is IT departments in any sector, including special computer services firms. Similarly, she and her colleagues in the IT department face direct competition from computer services firms that may offer to take over the IT functions of the car manufacturer on a contractual basis rather than facing competition from car producers abroad. The main contribution of this paper is, first, to create a measure of narrow offshoring that matches the services functions inside manufacturing to services that are provided by outside suppliers. Second, it analyses the relationship between market and product characteristics as well as the policy environment on the one hand and the outcome of the make-or-buy decision on the other. The contribution in this regard is to create sector-specific policy and technology indicators and explore how the location of services functions is conditioned on the policy and technology framework. The data reveal that the aggregate share of services inputs in manufacturing has not changed much during the period 2000–2014. There is however substantial variation across manufacturing sectors and countries. Furthermore, the share that is offshored and the share that is produced inside manufacturing have both increased slightly at the expense of local services suppliers. Tentatively, our results suggest that on average offshoring does not have a large impact on in-house employment. However, the average conceals large variations across sectors and functions. Furthermore, the marginal impact of offshoring on internal manufacturing employment strongly depends on the characteristics of the sector and the policy environment. Narrow offshoring affects manufacturing employment mainly in ICT-mature sectors. Narrow offshoring tends to replace in-house functions in short and simple value chains, but narrow offshoring complements in-house functions in long and complex value chains. The function that is most affected by offshoring is R&D, which seems to be completely hived off when offshored. Finally, narrow offshoring complements internal employment when policy barriers to entry and investment are high. The rest of the study is organised as follows: The data and stylised facts are portrayed in Sect. 2. Section 3 positions the paper in the literature and describes the analytical framework. Regression results are presented and analysed in Sect. 4, while Sect. 5 concludes.",4
57.0,2.0,Review of Industrial Organization,30 July 2020,https://link.springer.com/article/10.1007/s11151-020-09780-0,Deep Trade Agreements and Global Value Chains,September 2020,Edith Laget,Alberto Osnago,Michele Ruta,Female,Male,Female,Mix,,
57.0,2.0,Review of Industrial Organization,20 June 2020,https://link.springer.com/article/10.1007/s11151-020-09765-z,Importing and Productivity: An Analysis of South African Manufacturing Firms,September 2020,Lawrence Edwards,Marco Sanfilippo,Asha Sundaram,Male,Male,Female,Mix,,
57.0,2.0,Review of Industrial Organization,03 June 2020,https://link.springer.com/article/10.1007/s11151-020-09763-1,"Technology Adoption, Vertical Coordination in Value Chains, and FDI in Developing Countries: Panel Evidence from the Dairy Sector in India (Punjab)",September 2020,Saule Burkitbayeva,Emma Janssen,Johan Swinnen,Female,Female,Male,Mix,,
57.0,2.0,Review of Industrial Organization,22 June 2020,https://link.springer.com/article/10.1007/s11151-020-09768-w,Global Value Chains and Local Business Environments: Which Factors Really Matter in Developing Countries?,September 2020,Marion Dovis,Chahir Zaki,,Female,Unknown,Unknown,Female,"Developing countries are increasingly engaged in international production networks that have increased during the past 2 decades. In 2013, 60% of the international trade was performed through global value chains (GVCs) (UNCTAD 2013). GVCs not only represent the fractionalization process that unbundles supply chains into specific stages of production but also the international scattering of these stages and tasks. In order to reduce costs, most of the required inputs are sourced from other domestic firms or are imported by the producing firm, which creates a production system outside of borders. This process can take a number of forms for firms: Firms may marginally integrate the production process for one step—or they may engage far more extensively in being vertically integrated. All participants in a GVC—whatever their characteristics—are linked to such activities through the value creation process. Thus, GVCs represent the opportunity for firms to produce and export as a part of a supply chain—depending on their comparative advantages—which is particularly important for developing countries. In this way, integrating into a GVC may facilitate the exports by firms from developing countries. As mentioned by Baldwin (2013), joining supply chains increases the likelihood of exporting. Yet we know little about the incentives and constraints that influence firms to integrate into a GVC, which makes it hard to identify policy levers to address this issue. The quality of the legal, institutional, financial, and regulatory systems plays a crucial role in the development of the performance of firms. Indeed, according to the World Bank (2017), business regulations and their enforcement still vary widely across regions and countries. The aim of this paper is therefore to highlight the crucial role of the business environment on the integration of firms into GVCs in the case of the Middle East and North African (MENA) countries. Despite heterogeneous performances, the export dynamics of the MENA’s countries have been largely unsatisfactory over the past 2 decades. As highlighted by Jaud and Freund (2015), when MENA countries are compared to East Asian and Pacific (EAP) countries, the former has export superstars: Their top firms are comparable to those of other countries. However, except for these champions, MENA countries suffer from a lack of large and productive firms at the top of the distribution. Significant efforts have been made in terms of trade openness and policy support for firms’ transitions; but MENA countries have failed to develop a group of large exporting firms that usually contribute to the success of the export dynamic of a country. Thus, expanding GVC linkages in the MENA region is crucial for two main reasons: First, MENA countries are much less integrated than are EAP countries in international trade. As integrating into GVCs may facilitate the upgrading and competitiveness of exported goods, it is important to analyze the constraints that are faced by firms in terms of their business environments. Second, the recent political events in the MENA countries highlighted the urgency of creating jobs and redistributing the benefits of growth to their populations. Hence, helping firms to integrate with GVCs may be relevant to the job challenges in MENA countries. Indeed, as highlighted by Brambilla et al. (2012) and by Frias et al. (2012), exporters create more jobs and pay higher wage. With respect to theory, several papers have showed the association between firms’ integration and their performance. Indeed, a large trade literature that has followed Melitz (2003) shows that exporting firms are larger and more productive (e.g., Bernard et al. 2003; Bernard and Jensen 2004; Eaton et al. 2004; Yeaple 2005). In this literature, trade liberalization implies a reallocation of resources among the most productive firms. In another strand of the literature, learning-by-doing and externalities, technical innovation through imports of intermediate goods, and managerial efforts are other possible sources of productivity improvements that have been evidenced by different theoretical models (e.g., Ethier 1982; Markusen 1989; Grossman and Helpman 1991; Schmidt 1997; Kasahara and Rodrigue 2008). In parallel, there is a large body of empirical evidence that suggests that more integrated firms—which are defined as firms that both export and import—are larger, more productive and pay higher wages (e.g., Muûls and Pisu 2009; Kasahara and Lapham 2013; Smeets and Warzynski 2013; De Hoyos and Iacovone 2013). Nevertheless, the first analysis that identified these firms as integrated into GVCs was Baldwin and Yan (2014). They find that Canadian firms that integrated into a GVC benefited from a rise in productivity by 5% as compared with their counterparts during the first year, and by 9% 4 years later. By contrast, firms that left a GVC experienced a decrease in their productivity of 1% in the first year and 8% 4 years later. Whereas the integration of a firm into a GVC can take a number of forms, the vast majority of the empirical literature focuses on one particular form of GVC linkage: processing trade. For Feng et al. (2016), an increased use of imported intermediate inputs helps firms develop the volume and the scope of their exports. The origin of imports plays an important role in the destination of exports. Indeed, importing intermediary inputs from high-income countries increases the probability of exporting to high-income countries. Therefore, under financial constraints, Manova and Yu (2016) find that firms are more likely to conduct more processing trade and pure assembly, whereas value added and profitability increase with ordinary trade. Dai et al. (2016) point out the fact that processing activities are linked to lower fixed costs of exporting. In Yu (2015), input and output tariff reductions in China induced an increase in firm-level productivity, but this impact decreased with the share of a firm’s processing imports. Thus, although a lower fixed cost of exporting and improved trade policy favored processing activities, this induced lower firm-level productivity. According to Manova and Yu (2016), a large part of Chinese exports comes from foreign affiliates instead of domestic firms. Among these foreign affiliates, Lu et al. (2010) show that non-exporters are more productive than are exporters. In line with the literature, they find the opposite is true for the non-foreign affiliates. Ju and Yu (2015) calculate an “upstreamness” index for all industries using the number of stages that the product will go through before reaching its final use. They find that upstream firms are more capital-intensive and that productivity and profitability are higher for these firms. For the MENA region, Del Prete et al. (2017) perform a micro firm-level analysis—based on the World Bank Enterprise Survey data for Egypt, Morocco, and Algeria—and show that the performance of firms, measured by several indicators, is positively associated with internationalization and GVC participation. On another front, there is growing evidence that an adverse business environment impedes firms’ performance (e.g., Dollar et al. 2005; Van Biesebroeck 2005; Hallward-Driemeier et al. 2006; Fernandes 2008; Goedhuys et al. 2010; Augier et al. 2012; Bah and Fang 2015) and export activity (e.g., Berman and Héricourt 2010; Commander and Svejnar 2011). In these studies, the business environment in which firms operate—access to credit; regulatory and institutional environment; and infrastructure—play a crucial role in their performance but with considerable heterogeneity. These studies mainly focused on total factor productivity, labor productivity, export status, and ownership, while a firm’s integration into a GVC was never addressed. At the trade policy level, while tariffs on manufactured products are low in industrialized countries and are decreasing in developing countries, low tariffs that are repeated along the value chain can represent a significant cost for exporting firms (OECD 2018). Moreover, as has been argued in the literature, business environment characteristics are a fixed cost that affects exporters, while tariffs are a variable cost. This is why we examine how these characteristics exert a differential effect on sectors with low versus high tariffs: We analyze the extent to which a better business environment can counter-balance the negative effect of higher tariffs or amplify the positive effect of low tariffs with respect to the likelihood of a firm’s integrating into a GVC. Hence, our study provides a bridge between two active literatures on GVCs and the business environment. Using a comprehensive firm-level dataset from the World Bank Enterprise Survey (WBES) between 2006 and 2017,Footnote 1 we use four different definitions of what constitutes a firm’s integration into a GVC to shed light on the importance of business environment in this integration process. The contribution of the paper is threefold: First, it provides a range of measures of the characteristics of firms that would identify a firm as integrated into a GVC. Second, it examines an array of business environment variables that are likely to influence the likelihood of a firm’s integration into a GVC. Third, we examine this process separately for small and large firms and for sectors with high versus low tariffs. To our knowledge this is one of the first studies to examine the impact of the business environment on a firm’s integration into a GVC, with a special focus on the MENA and EAP countries. Nevertheless, instead of establishing a causal link between the business environment and firms’ integration into a GVC, we test more precisely the correlates between GVC linkages and a range of business environment measures. Our main findings show that, in general, the number of days that are required to pay taxes, the number of procedures that are necessary to register property, and the time to export and to import have a significantly negative association with a firm’s integration into a GVC. More heterogeneity is observed at the regional level and at the firm-size level and for sectors with high versus low tariffs. Indeed, while small firms in the MENA region suffer more from access to finance, tax procedures, obtaining electricity, and trade procedures, those of the EAP region do not. When trade policy is taken into consideration, firms that operate in high-tariff sectors are likely to benefit more from a better business environment and hence be able to integrate into a GVC. The remainder of the paper is organized as follows: Sect. 2 presents some descriptive statistics on GVCs and the business environment. Section 3 describes the methodology. Section 4 presents our empirical findings; and Sect. 5 concludes.",13
57.0,3.0,Review of Industrial Organization,18 July 2020,https://link.springer.com/article/10.1007/s11151-020-09778-8,Introduction: Entrepreneurship and Industrial Organization,November 2020,David B. Audretsch,Albert N. Link,Erik E. Lehmann,Male,Male,Male,Male,"At first glance it would seem that the literatures of industrial organization and entrepreneurship are not only distinct but have very little overlap or even relevance to each other. The purpose of this special issue is to argue that this is not the case and that, in fact, the literatures of industrial organization and entrepreneurship are highly intertwined. In the second section of this paper, three main themes that link the literatures of industrial organization and entrepreneurship are explicitly identified and explained. In particular, these themes involve entry, innovation, and competition. In the third section of the paper, how each of the individual contributions to the special issue are related to at least one of these themes is explicitly identified and explained. Finally, in the last section of the paper, a summary and conclusion are provided. In particular, this paper finds that because of the central role that is played by the themes of entry, innovation, and competition, the fields of industrial organization and entrepreneurship are not just interrelated but are also highly complementary.",2
57.0,3.0,Review of Industrial Organization,25 July 2020,https://link.springer.com/article/10.1007/s11151-020-09777-9,The Economic Contribution of a Cohort of New Firms Over Time,November 2020,Alex Coad,Julian S. Frankish,Albert N. Link,Male,Male,Male,Male,"Economic development owes much to the unrelenting waves of entrepreneurial entrants who perceive business opportunities, and act upon these perceptions to provide novel goods and services. The contribution of entrepreneurship to the economy is not only a topic of considerable economic and political interest but also one of controversy. An area of controversy—albeit one that is not studied in detail—is the economic contribution of new entrants and how their contribution evolves in the years after entry. The economic contribution of a cohort of new firms is the result of two countervailing forces.Footnote 1 On the negative side, life is short for many entrants (Audretsch et al. 2000): Most new firms die within a few years after entry—about 50% will die within the first 3 years. On the positive side, firms that do survive will grow and make an economic contribution (Fariñas and Moreno 2000; Cabral and Mata 2003; Angelini and Generale 2008; Meisenzahl 2016). New firms have a spurt of relatively rapid post-entry growth, which is particularly pronounced in the years after entry (Haltiwanger et al. 2013; Coad et al. 2018). We therefore investigate the total outcome—at the cohort-level—of these two countervailing forces. We analyze a cohort of over 6000 new ventures in the UK, with the use of rich data that capture their economic contribution (in terms of their total sales) immediately after they start to trade. Our review of the related literature (which is summarized in Table 1) highlights the prevailing gaps in knowledge about new ventures and our contribution to the literature. While previous studies have measured the economic contribution of a cohort in terms of jobs created—total number of employees—or market share, we are the first to measure the economic contribution of a cohort in terms of total sales. We achieve this by analyzing a novel data source—entrepreneurs’ bank account records that were collected by a major bank—in order to complement previous studies by showing an alternative perspective on the evolving economic contribution of entrants. Furthermore, given that previous studies have investigated different countries during different time periods, and have obtained conflicting results, our results can be useful for assembling a more robust body of evidence on the matter. In Sect. 2, we present the previous literature on the economic contribution of a cohort of new firms, and we describe the contribution of this paper. In Sect. 3, we discuss the dataset, and in Sect. 4 we present the descriptive empirical analysis. Section 5 concludes the paper with summary remarks and offers a roadmap for future research.",
57.0,3.0,Review of Industrial Organization,26 September 2020,https://link.springer.com/article/10.1007/s11151-020-09787-7,Entry Regulation and Persistence of Profits in Incumbent Firms,November 2020,Sameeksha Desai,Johan E. Eklund,Emma Lappi,Unknown,Male,Female,Mix,,
57.0,3.0,Review of Industrial Organization,04 August 2020,https://link.springer.com/article/10.1007/s11151-020-09782-y,"Entrepreneurial Firms: With Whom Do They Compete, and Where?",November 2020,Marc Cowling,Simon Peter Nadeem,,Male,Male,Unknown,Male,"The study of entrepreneurship and entrepreneurial behaviours over the last 40 years has provided some important insights: What entrepreneurial firms do when faced with competition (Dodge et al. 1994; Lechner and Gudmundsson 2014; Covin and Slevin 1989); how their agility can be an asset in times of economic crisis (Bradburd and Ross 1989); how they can find and defend strategic niches (Papadogonas and Droucopoulos 2015; Bradburd and Ross 1989); and the decision to internationalise (Brush et al. 2015; Cowling 2003).
 But this literature has been strangely silent about formally establishing precisely the markets in which these firms operate (other than international or domestic) and the exact nature of the competition and the prices that they face in these output markets. Economics, by contrast, has well established definitions and theories about markets and competition. For example, Robinson (1934) and Stigler (1957) describe the conditions under which perfect competition would exist. Stigler (1964) and Sweezy (1939) define oligopoly. Machlup (1952) describes imperfect competition, and Bain (1956) sets out a context in which barriers to new firm entry exist and hence prevent competition. Chamberlin (1937) describes the theory of monopolistic competition, whilst Baran (1966) sets out the theory of monopoly, and Baumol et al. (1977) consider the special case of a natural monopoly. But, since the development of the production function to a large degree excluded a role for the entrepreneur (Cowling 2003; Niman 1991), mainstream economics has largely ignored smaller, entrepreneurial businesses from empirical investigation despite a voluminous body of literature that is concerned with the effects of imperfect competition, barriers to entry, and market concentration on the profitability of large incumbent firms (Bain 1951; Cowling and Waterson 1976; Conyon and Machin 1991; Acs and Audretsch 1987). In this paper we will empirically quantify just how many entrepreneurial firms operate in competitive markets, how many can compete against large firms, and how many are able to create a genuine market niche through being innovative. In doing so we will adopt the definitions of markets and competition from standard economic theory to give us a well-grounded theoretical basis and point of reference. We hope that our findings will clarify just how many entrepreneurial firms are involved when we discuss different ‘types’ of business and entrepreneurs. Further, we hope that our results may challenge prevailing orthodoxy in economics, and also mainstream management, which has tended to be in thrall to the study of very large, household-name, industrial conglomerates (Pelham and Wilson 1995).",7
57.0,3.0,Review of Industrial Organization,25 July 2020,https://link.springer.com/article/10.1007/s11151-020-09779-7,"Knowledge Transfer, Transitional Dynamics and Optimal Research & Development Policy in a Dynamic Monopoly Setting",November 2020,Jürgen Antony,Torben Klarl,,Male,Male,Unknown,Male,"Knowledge and its management are of crucial importance for a firm’s inventiveness and, hence, is essential for its sustainable competitive advantage. In general, knowledge itself has an internal as well as an external dimension. For instance, firms can increase their own knowledge stock by either investing in product R&D or process R&D, or both. However, theoretically, a firm can also exploit external knowledge that is produced by its competitors. Ironically, new knowledge—accessed externally or internally—also generates types of knowledge barriers, which may hinder the firm’s ability to exploit the accumulated and existing stock of knowledge (Caldwell 1967). The knowledge barrier is also a subject of research in knowledge management.Footnote 1 In general and applied to an economic setting, the knowledge barrier refers to any impediment that prevents existing knowledge from being used elsewhere. This interpretation is consistent with Attewell’s (1992) view of knowledge barriers as the absence of ability to access existing knowledge. Knowledge barriers are relevant within the firm as well as with respect to knowledge that is external to the firm. The former is also known as internal stickiness (Szulanski 1996, 2003).Footnote 2 Consistent with this somewhat vague concept of knowledge barriers, we consider anything that prevents existing knowledge from being applied, transferred, shared or diffused. We take account of these barriers in our theoretical approach at several instances whenever existing knowledge affects the economic environment of the firm. We distinguish explicitly between barriers to accessing internal knowledge and to accessing external existing knowledge. Following the knowledge management literature, the reduction of knowledge barriers goes hand in hand with improving knowledge transfer and knowledge sharing. While the latter is usually focused on what is happening inside the firm, the former is often applied to knowledge at a higher aggregated level that includes also inter-business relations (Choo and Alvarenga Neto 2010). To reduce knowledge barriers, the relevant economic literature suggests fostering the firm-specific, underlying learning process and, thereby to increase the firms’ absorption capacities (Cohen and Levinthal 1990). Lichtenthaler (2009) considers a firm’s absorption capacity as important to transform knowledge into innovations for improved products and production processes. Consistent with the concept of “a learning economy” that was proposed by Lundvall and Johnson (1994), we argue that a conditio sine qua non to reduce the firm’s knowledge barriers is learning. As a link to the knowledge management literature, learning includes sharing and transferring knowledge from where it originates towards where it can contribute to productivity. This interpretation is consistent with Demircioglu and Audretsch (2017), who point out that learning can be seen as a critical dimension reducing the knowledge barrier. However, the authors also highlight that more research is needed to explore the link between knowledge barriers and innovation. Our paper not only addresses this issue specifically, but goes a step further by asking whether or not a reduction of the knowledge barrier is beneficial for welfare. In our setting, we focus on an abstract form of learning without specifying the learning process itself. For instance, a direct effect of learning is reflected in a reduction of innovation costs. This might happen if a firm successfully makes use of its own accumulated knowledge through sharing it within the firm. As a second effect, learning also increases the accumulation of knowledge within the firm which is again related to knowledge sharing. Further, learning makes it easier to benefit from external knowledge spillovers which would typically be seen as a knowledge transfer. Strategic investment decisions (in knowledge) always have a dynamic dimension as today’s decisions in most cases affect the conditions for future investments.Footnote 3 In recent years, some efforts have been made to discuss the inherently dynamic nature of product and process improvement, ranging from the specific patterns of R&D races, to the timing of innovative ventures, to spillover effects. For example, Lambertini and Mantovani (2009) focused on the dynamic behavior of a multiproduct monopolist that invests in process and product innovation, whereas Lambertini and Orsini (2015), Li and Ni (2016), or more recently, Zhong and Zhang (2018) consider a monopolist that invests in cost-reducing and quality-enhancing endeavors. Common to this last mentioned strand of literature is the result that due to the monopoly power with respect to product quality, the firm distorts product quality downwards compared to what is optimal from a social point of view. However, none of these articles has analyzed the dynamic adjustment of welfare that is due to a potential unforeseen shock in the knowledge barrier sphere: unforeseen changes where knowledge is shared or transferred. Consequently, none of the articles have discussed the optimal policy design when external and internal knowledge transfers and sharing are present. Process and product innovations differ. We distinguish them by introducing a product innovation with a specific cost component to the monopolist. Additionally, a product innovation represents an increase in the consumer’s marginal utility. Consistent with the literature, we refer to this as an improvement in the monopolist’s product quality. Such innovations are subject to a scale-independent production cost component. This will give rise to a scale effect in product quality that is exploited by the monopolists market power. Since the existing literature almost entirely focuses on the role of scale in process innovations (see, e.g., Cohen and Klepper 1996a, b), little attention has been paid to the role of scale in product innovations. This paper fills these gaps. First, we combine the dynamic models that were introduced by Lambertini and Orsini (2015), Li and Ni (2016), and Zhong and Zhang (2018) and, inter alia, solve the control problem for the monopolist’s equilibrium product quality. We show that this hyperbolic equilibrium is a degenerate saddle, which implies that there exists a path to which the economy converges in the long-run. We find that product quality increases with a decreasing knowledge barrier. Next, we compute the socially optimal solution. We find that the socially optimal level of product quality is higher due to under-investments in product quality in the decentralized setting. However, the level of process R&D is socially optimal, which is consistent with the literature.Footnote 4 Hence, in order to establish the first-best solution, we propose a policy that imposes a product R&D subsidy scheme that is completely lump-sum financed by consumers. The paper makes the following important points: (1) we find that the higher is the optimal, long-run subsidy-rate, the lower is the knowledge barrier. For instance, a lower knowledge barrier allows for better accessing existing knowledge. This increases product quality today but—and this is important—for a given depreciation rate, product quality decreases in the future since private R&D efforts decrease. A higher subsidy then counteracts the lower private incentive to invest in own product R&D due to a low knowledge barrier. Further, only in the long-run where product quality is constant, the optimal subsidy-rate is constant as well. During the transitional phase towards the steady-state, the optimal subsidy is time-varying. (2) Performing a numerical simulation study, we show that welfare may considerably differ in the short-run from its long-run level. This finding has important policy implications: if policy makers focus on the short-run welfare effects of reducing the knowledge barrier, the policy recommendation that may be optimal in the long-run can be biased in the short-run. Hence, welfare effects in the short-run may differ considerably from those in the long-run as speculated by Audretsch (1995). To clarify this last issue, we run several numerical simulations of our model over its transition towards the long-run equilibrium. We find heterogeneity with respect to the effects of knowledge barrier reductions across different types of barriers as well as during the short- and long-run. Additionally, we find R&D policy to generate different welfare outcomes in the short- and long-run as well. As will be seen, market size plays an important role in all of the mentioned effects. The plan of the paper is as follows: Sect. 2 introduces the model and solves for the monopolist’s long-run equilibrium. The stability properties of this equilibrium are developed in Sect. 3. Section 4 provides our welfare analysis, and Sect. 5 establishes the welfare optimal R&D policy. Section 6 focuses on the transitional dynamics of welfare effects that are due to knowledge barrier shocks and R&D subsidies. Section 7 concludes.",2
57.0,3.0,Review of Industrial Organization,09 September 2020,https://link.springer.com/article/10.1007/s11151-020-09786-8,Does a Guaranteed Basic Income Encourage Entrepreneurship? Evidence from Alaska,November 2020,Robert M. Feinberg,Daniel Kuehn,,Male,Male,Unknown,Male,"While the concept has been around for years, recently the policy notion of a “guaranteed basic income” (GBI) or “universal basic income” has had a resurgence of interest.Footnote 1 In addition to rationales for a GBI that relates to fairness and as a response to structural employment shifts that are due to automation and globalization, another motivation sometimes put forward for these plans is to encourage risk-taking by providing a safety net. Higher risk-taking could imply greater entrepreneurial activity if an unsuccessful entrepreneur had the GBI to fall back on. In this paper we investigate the entrepreneurial effects of a long-standing example of a GBI in the US, the Alaska Permanent Fund (APF) Dividend program.Footnote 2 The APF program is not generally thought of as a GBI, and the annual amount is too small to allow an individual fully to rely on these funds; but for a moderate-to-large family the APF can replace a large share of a poverty-level income. For example, in 2000 a family of six would have received a Permanent Fund Dividend (PFD) payment worth more than 40% of the federal poverty threshold that is calculated for Alaska by the US Department of Health and Human Services. Receipt of the PFD does not preclude a family from receiving other safety-net benefits—e.g., food stamps, housing vouchers, unemployment compensation—which suggests that the downside risk for a potential entrepreneur may be lower than in other US states where transfers are means-tested. In this paper we examine trends in small-firm births in Alaska over time from the Census Bureau’s Business Dynamics Statistics 1977–2014—before and after the institution of the PFD program (the first payment was in 1982)—relative to other US states to investigate a possible impact on entrepreneurship. We then turn to individual-level data from the Current Population Survey’s Annual Social and Economic Supplement (ASEC) to examine more disaggregate influences on movements towards self-employment.",3
57.0,3.0,Review of Industrial Organization,06 November 2019,https://link.springer.com/article/10.1007/s11151-019-09738-x,Penalising on the Basis of the Severity of the Offence: A Sophisticated Revenue-Based Cartel Penalty,November 2020,Yannis Katsoulacos,Evgenia Motchenkova,David Ulph,Male,Female,Male,Mix,,
57.0,3.0,Review of Industrial Organization,10 October 2019,https://link.springer.com/article/10.1007/s11151-019-09734-1,Competition Between Offline and Online Retailers with Heterogeneous Customers,November 2020,Stefano Colombo,Noriaki Matsushima,,Male,Male,Unknown,Male,"While online retailers have strongly developed their presence in retail markets, offline retailers continue to play an important role (Choi et al. 2012) for the following three reasons. First, some customers lack the ability to use the Internet, such as not knowing how to find the most suitable website for their needs. Second, purchasing from online retailers incurs several costs, including those that relate to the waiting time for delivery or the limited information available on products.Footnote 1 Last, some customers may prefer offline retailers because they prefer the feeling of shopping in physical places or they wish to share time shopping with family and friends. The quality of service is a crucial element in the marketing mix of online retailers. Therefore, some e-retailers will attempt to improve the quality of their services, such as the quality of their website and the options that are available for consumers when browsing the website.Footnote 2 It seems intuitive that online retailers will want to improve the quality of their online services as much as possible, thus minimizing the disutility of consumers when making online purchases. However, we also observe that at least in some cases, online retailers will not minimize the disutility costs of consumers purchasing from them, even if doing so would be without apparent excessive costs. For example, Dell’s online retailers use highly technical language when describing product characteristics; the language is easily understood by expert users, but not by computer novices. Similarly, ArredoDesign Online—an online retailer that specializes in home furnishings and interior design—offers a choice of different product colors. However, it depicts only one of the colors that are available for each product on its website. A natural question is then why do some online retailers not appear to attempt to minimize consumer disutility costs, even when doing so does not apparently entail significant costs, as shown by the previous examples. To answer this question, we examine how an improvement in the usefulness of online retailers affects retailer profitability. We consider an oligopoly competition model in which two offline retailers compete with an online retailer that has some cost/quality (dis)advantage. In our model, consumers are heterogeneous across two dimensions: (1) the costs of traveling to either of the offline retailers as in standard Hotelling models; and (2) the costs of purchasing from the online retailer. The latter contrasts with the typical assumption that consumers are homogeneous in their disutility costs of using the Internet (see Balasubramanian 1998), and reflects that consumers are heterogeneous in their Internet skills, in finding information on the web, etc. We show that—depending on the competitive position of the online retailer with respect to the offline retailers—the consumer-specific disutility of online purchases provides quite different effects on the online and offline retailers. In particular, the online retailer’s profit changes nonmonotonically with an increase in the degree of consumer disutility for online purchases if the competitive position of the online retailer is sufficiently weak. This implies that an increase in the consumer disutility of online purchase can benefit the online retailer if its competitive position is sufficiently weak, but always harms the online retailer if its competitive position is strong. In addition, this nonmonotonic relationship emerges only if the offline retailers compete directly with each other: The online retailer serves only consumers with a high degree of familiarity with the Internet. Several existing studies consider the competition between online and offline retailers, of which Balasubramanian (1998) was the first to introduce competition between online retailers and offline retailers in a circular setup (see also Bouckaert 2000). Subsequently, Nakayama (2009) analyzes the situation where some consumers are constrained to purchase only from offline retailers in a linear city model,Footnote 3 while Guo and Lai (2014, 2017) consider the spatial positioning of offline retailers when facing competition with an online retailer. All of these studies, however, assume that consumers are homogeneous with respect to the disutility of online purchases. The remainder of the paper proceeds as follows: Sect. 2 introduces the model. Section 3 derives the equilibrium prices and profits. Section 4 discusses the effect of changes in the model parameters on equilibrium profits. Section 5 concludes.",8
57.0,3.0,Review of Industrial Organization,16 October 2019,https://link.springer.com/article/10.1007/s11151-019-09735-0,Competitive Intelligence and Disclosure of Cost Information in Duopoly,November 2020,Tao Wang,,,,Unknown,Unknown,Mix,,
57.0,3.0,Review of Industrial Organization,26 October 2019,https://link.springer.com/article/10.1007/s11151-019-09736-z,Product Repositioning in a Horizontally Differentiated Market,November 2020,Hiroki Kishihara,Nobuo Matsubayashi,,Male,Male,Unknown,Male,"When incumbent firms offer new products for a new segment in the market, it is important for them to consider the difference in market conditions between their current and new markets carefully.Footnote 1 However, it is not easy for established firms with existing core products to offer new products with different market positions successfully—even if their existing and new products do not directly cannibalize each other. A famous example is that in the 1980s, to grab market share from PepsiCo, Coca-Cola changed the taste of its traditional Coca-Cola and launched a new product that was named “New Coke” (Project Kansas). However, many Coca-Cola drinkers complained about this change. The company changed its mind and returned to the old Coca-Cola formula.Footnote 2 In this example Coca-Cola’s repositioning was likely expensive. In fact, regardless of whether a firm stops producing an old product and keeps the same product name as an old product, various costs seem relevant in repositioning activities in horizontally differentiated markets, such as introducing new facilities, changing a flavor, and advertising to raise awareness among consumers of the new position. For example, General Motors (GM) offered a new plug-in-hybrid (PHV) car under the Chevrolet brand, accompanied with a repositioning from a traditional gasoline-powered vehicle to an environmentally-friendly car. For this repositioning, the company invested 336 million USD to establish a new plant in Detroit (see GM 2009). In considering these types of costs that are associated with repositioning to introduce new products, which we refer to as “repositioning cost” here, our interest is in how the presence of repositioning costs might alter competition between firms. More specifically, owing to repositioning cost, firms are restricted in their optimal adjustments to their positions in a new market. Thus, a strategic effect and equilibrium outcomes in a repositioning competition might be significantly different from those in a typical positioning competition case as explored in the literature. Based on this motivation, this study explores product repositioning in a duopoly framework of Hotelling’s linear city. Specifically, we incorporate the positions of firms’ existing products given exogenously as a parameter, which we refer to as “base positions,” and their repositioning costs, which are quadratically proportional to the difference between their base and actual product positions and where we allow asymmetric unit cost of repositioning between both firms. By analyzing the equilibrium outcomes of the location-then-price game in this model, we attempt to see how the presence of repositioning cost changes the resulting positioning and the relative profitability between the firms, as well as social welfare. We show that neither the base product nor the new product in an attractive position in the market necessarily implies a competitive advantage. In particular, in the presence of asymmetric unit repositioning costs, the potentially cost-inefficient firm can earn higher profits than does its rival in equilibrium—despite the rival’s more attractive position in the market. We also have a welfare implication in terms of whether a social planner should regulate or encourage firms’ repositioning activities, which is sensitive to and depends on the base positions and cost structures of both firms. Most of these results contrast sharply with the results that are based on the standard Hotelling model.",5
57.0,4.0,Review of Industrial Organization,07 November 2020,https://link.springer.com/article/10.1007/s11151-020-09794-8,General Editor’s Note: Antitrust and Regulatory Update,December 2020,Lawrence J. White,,,Male,Unknown,Unknown,Male,,
57.0,4.0,Review of Industrial Organization,06 October 2020,https://link.springer.com/article/10.1007/s11151-020-09790-y,Recent Developments at the CMA: 2019–2020,December 2020,Richard Havell,Chris Jenkins,Mike Walker,Male,,Male,Mix,,
57.0,4.0,Review of Industrial Organization,05 November 2020,https://link.springer.com/article/10.1007/s11151-020-09792-w,"Economics at the FTC: Fertilizer, Consumer Complaints, and Private Label Cereal",December 2020,Andrew Sweeting,David J. Balan,Devesh Raval,Male,Male,Male,Male,"The staff of the Federal Trade Commission’s Bureau of Economics (BE) is made up of just over 100 full-time employees. It is currently composed of 83 Ph.D. economists, with 7 new hires joining in 2020, 13 research analysts and statisticians, 6 administrative professionals, and 4 financial analysts. While this article focuses on the output of economists within BE, that work benefits from contributions of the entire BE staff, as well as the cooperation of many attorneys and paralegals in the FTC’s Bureau of Competition and Bureau of Consumer Protection. BE economists provide economic analysis in support of the FTC’s dual competition and consumer protection missions. Most of the staff’s time is spent on casework for particular matters that may come before the Commission. On the competition side, most matters involve proposed horizontal or vertical mergers, where BE’s analysis can be critical in determining whether the proposed merger is likely to harm consumers. FTC merger enforcement is particularly active in healthcare (hospital, pharmaceutical and medical devices), and in the oil and gas, chemical, manufacturing and retail sectors. In 2019, the FTC entered into consent orders for eight mergers and filed suit in four, while merging parties abandoned eight proposed transactions that were investigated by the FTC staff. This article discusses some of the models that BE used to assess the proposed merger between private-label (PL) ready-to-eat (RTE) cereal manufacturers—Post and TreeHouse—which was one of the deals that was abandoned when challenged by the Commission. Consumer protection matters cover a wide-range of cases where firms may be engaging in unfair or deceptive—and sometimes simply fraudulent—practices that harm consumers. These range from cases of identity theft and imposter scams, to deceptive advertising and unfair data-security practices. BE economists provide independent analyses of virtually all consumer protection matters before the Commission; work side-by-side with legal staff on investigations, reports, and workshops; serve as expert witnesses, and conduct original economic research on a range of consumer protection questions, including development of original theoretical economic models to improve understanding of consumer protection problems, applications of existing economic and marketing literature to policy questions, and original empirical analysis. The Commission filed actions in 76 consumer protection matters and obtained orders in 126 cases in 2019; and, amongst many other matters, the Commission is currently engaged in protecting consumers from COVID-related scams.Footnote 1 BE also helps to shape Commission enforcement actions by conducting theoretical and empirical economic research projects on topics that are connected to policy. This article discusses two examples: The first is a retrospective analysis of a fertilizer manufacturer merger that the Commission investigated in 2016 and 2017. Since Barton and Sherman’s (1984) study of two consummated mergers in the U.S. microfilm industry, BE staff have published over 30 retrospectives on consummated mergers. These studies provide insights into whether the tools that enforcement agencies worldwide use to evaluate mergers—including the type of tools used in the RTE cereals case—are effective. The second project consists of a set of studies (Raval 2020a, b, c) that link the ZIP codes reported in the government’s customer complaints databases, and datasets on victims from several fraud cases that were prosecuted by the Commission, to local demographics. This work shows that residents of areas with higher numbers of Black and Latino residents are much less likely to report being victims of fraud even though they may be just as likely or more likely to be victims. This difference matters, because BE staff frequently use the complaints database as a source of information that can guide assessments of likely consumer harm. Additionally, BE economists interact with broader policy and academic research communities by participating in and hosting conferences and workshops. For instance, FTC economists recently participated in a Consumer Financial Protection Bureau (CFPB) workshop on behavioral economicsFootnote 2 and organized an FTC hearing on merger retrospectives.Footnote 3 In November 2019, BE welcomed a new co-host for the twelfth FTC Microeconomics Conference: the Tobin Center for Economic Policy at Yale.Footnote 4 A wide range of topics—including deception and collusion—were discussed in paper sessions, panel discussions, and keynote addresses. The next FTC Microeconomics Conference, again co-sponsored by the Tobin Center, is to be held online on November 5–6, 2020.Footnote 5 Section 2 describes a retrospective analysis of the $36 billion merger of Agrium and PotashCorp, which formed the world’s largest crop nutrient company. The study uses publicly available data to examine what happened to the price of potash, a vital source of potassium for farmers, in the U.S. Corn Belt—compared to potash prices in other countries and domestic prices of other fertilizers. Section 3 describes the consumer complaints research that was discussed above—one of the products of which is an approach to weighting complaint data so that it is likely to reflect more accurately victimization rates. Section 4 discusses the economic analysis of the PL RTE cereal manufacturers, and, in particular, describes how staff used a range of alternative models to calculate estimates of the effects of eliminating competition between the two companies in order to understand the range of possible outcomes that could be compared to creditable efficiencies.",5
57.0,4.0,Review of Industrial Organization,12 November 2020,https://link.springer.com/article/10.1007/s11151-020-09796-6,Recent Developments at DG Competition: 2019/2020,December 2020,Liliane Karlinger,Dimitrios Magos,Hans Zenger,Female,Male,Male,Mix,,
57.0,4.0,Review of Industrial Organization,03 November 2020,https://link.springer.com/article/10.1007/s11151-020-09793-9,The Year in Review: Economics at the Antitrust Division 2019–2020,December 2020,Ronald Drennan,Helen C. Knudsen,Jeffrey M. Wilder,Male,Female,Male,Mix,,
57.0,4.0,Review of Industrial Organization,23 October 2020,https://link.springer.com/article/10.1007/s11151-020-09791-x,"Economics at the FCC 2019–2020: Spectrum Policy, Universal Service, Inmate Calling Services, and Telehealth",December 2020,Allison Baker,Patrick Brogan,Emily Talaga,Female,Male,Female,Mix,,
57.0,4.0,Review of Industrial Organization,19 December 2019,https://link.springer.com/article/10.1007/s11151-019-09744-z,Strategic Obfuscation and Retail Pricing,December 2020,Timothy J. Richards,Gordon J. Klein,Zohra Bouamra-Mechemache,Male,Male,Female,Mix,,
57.0,4.0,Review of Industrial Organization,23 January 2020,https://link.springer.com/article/10.1007/s11151-019-09745-y,Pricing and Industry Structure when Demand Elasticity Changes,December 2020,Jean-Paul Chavas,Guanming Shi,Kyle Stiegert,Male,Unknown,,Mix,,
57.0,4.0,Review of Industrial Organization,26 November 2019,https://link.springer.com/article/10.1007/s11151-019-09742-1,Advance-Purchase Financing of Projects with Few Buyers,December 2020,Marco Sahm,,,Male,Unknown,Unknown,Male,"One proposal in the debate about how R&D of new drugs can be incentivized and how they can be made available in low-income countries is the use of advance-purchase arrangements:Footnote 1 Negotiating with the producer, some (supra-) national health authorities may pre-order a drug and pay in advance (or promise to pay the prespecified price on delivery). With reduced uncertainty about how countries value the drug, the firm can then use these (promises of) advance payments to finance its R&D investments. Moreover, poorer countries might benefit from lower prices once the development of the drug has been financed by pre-orders from richer countries. Despite being intuitively appealing, the proposal has not yet undergone a rigorous analysis that is based on a theoretical economic model. My article fills this gap by addressing the more general questions that underlie the above example: Is it possible to finance more (costly) projects through the use of advance-purchase contracts instead of relying on traditional funding such as debt or equity? Are there circumstances under which advance-purchase financing (APF) Pareto-dominates traditional funding (TF)? To examine these questions, I consider a monopolistic entrepreneur who must meet a commonly known capital requirement in order to start production. The entrepreneur then offers the related product to a limited number of potential buyers who are privately informed about their willingness to pay. Under TF, the entrepreneur relies on standard uniform pricing and realizes the project if and only if it is ex-ante profitable. In contrast, APF is modeled as a two-stage game: First, the entrepreneur offers to pre-order the good at a certain advance-purchase price. Second, if pre-orders cover the capital requirement, the good is produced, delivered to advance-purchasers, and offered to residual customers at a (possibly different) regular price. Two results are striking:Footnote 2 First, APF enables the entrepreneur to practise second-degree price-discrimination and set an advance-purchase price above the regular price: Agents with a high willingness to pay prefer to pre-order the good at the advance-purchase price because they fear the non-availability of the product most and consider that their pre-order could be pivotal for its realization. Second, APF enables the entrepreneur to screen demand and to undertake only projects that are ex post profitable. The probability of realization is thus positive even for projects that are too costly to be financed traditionally because they are not profitable ex ante. APF will, therefore, Pareto-dominate TF if fixed costs are sufficiently large.Footnote 3 In addition to the introductory example from health economics, the model captures a series of stylized facts that characterize highly concentrated markets in which a seller with increasing returns to scale deals with a limited number of potential buyers or, alternatively, with some large potential buyers and a fringe of small ones. Examples include the international defense industry, where an arms manufacturer such as Heckler and Koch collects more than 80% of its revenue from the governments of four large countries (the US, Germany, France, and the UK).Footnote 4 The model may also be understood as a simple reward-based crowdfunding mechanism for which the financing threshold equals the (residual) capital requirement (cf. Belleflamme et al. 2014).",2
58.0,1.0,Review of Industrial Organization,07 January 2021,https://link.springer.com/article/10.1007/s11151-020-09807-6,The 2010 Horizontal Merger Guidelines After 10 Years,February 2021,Joseph Farrell,Carl Shapiro,,Male,Male,Unknown,Male,"The proper treatment of horizontal mergers has always been a central public policy question for industrial organization economists. The Clayton Act prohibits acquisitions where “in any line of commerce or in any activity affecting commerce in any section of the country, the effect of such acquisition may be substantially to lessen competition, or to tend to create a monopoly.” (emphasis added) Major mergers are reviewed prospectively by the DOJ or the FTC, so it is not possible to assess their impact on competition directly. Because merger review is a predictive exercise, economic analysis has come to play a central role in merger enforcement. Faced with a proposed merger, the analysis seeks to predict whether that merger “may substantially lessen competition.” In evaluating mergers, antitrust law has typically equated a substantial lessening of competition with substantial harm to customers based on diminished competition.Footnote 1 This is a leading example of how antitrust law has embraced the “consumer welfare standard” in recent decades.Footnote 2 A given horizontal merger thus presents a well-defined economic question: Will this merger likely harm customers rather than benefit them? Viewed this way, every horizontal merger involves a fundamental tradeoff: On the one hand, it will eliminate competition between the merging firms and lead to a more concentrated market, so it poses a risk of diminished competition. On the other hand, it may enable efficiencies that could make the merged entity a stronger rival for other firms. Williamson identified this fundamental tradeoff over 50 years ago.Footnote 3 Since 1968, the merger guidelines have explained how antitrust enforcers in the United States evaluate mergers and thus—implicitly or explicitly—make this tradeoff.Footnote 4 The 1968 Merger Guidelines placed great emphasis on market concentration, establishing strong presumptions against mergers that raised concentration even modestly. Those Guidelines were fundamentally changed in 1982, making merger enforcement far more lenient. After a minor update in 1984, the next major revision came in 1992, at which time they became a joint product of the DOJ and the FTC. The 1992 Guidelines greatly advanced theories of harm that were based on “unilateral effects”: the elimination of competition specifically between the two merging firms. The 1982 guidelines had focused almost entirely on “coordinated effects”: the danger that the merger would enhance anti-competitive coordination between the merged firm and its remaining rivals. The treatment of efficiencies was updated in 1997. By and large, the 2010 Horizontal Merger Guidelines updated guidance going back to 1992. During those intervening 18 years, both economic learning and agency enforcement practice had significantly evolved. The 2010 Guidelines sought to communicate more accurately how the DOJ and the FTC actually analyze horizontal mergers, which centers on the “well-defined economic question” described above. By doing so, it also sought to reinvigorate merger enforcement, within the contours of established case law, both where economic analysis had improved and also where accumulated interpretations of earlier Guidelines had made enforcement more difficult without sound reason. At a high level, as one of us explained at the time,Footnote 5 it was time for the Guidelines to stress the agencies’ increasingly substantive focus (will the merger harm customers?—how do we know?…) rather than a process focus (first define markets and calculate concentration; then consider effects, then entry…) that the 1992 Guidelines (section 0.2) had suggested. The substantive focus in turn affects the kinds of evidence that is considered (2010 Guidelines, section 2) and how that evidence is evaluated and used. This did not mean abandoning traditional processes or technique; rather, it gave them a more flexible role in the service of the fundamental substantive question, and supplemented them with other techniques and evidence, as appropriate. This can be seen in many places; for instance: The greater emphasis on a variety of evidence that indicates that a merger may lessen competition; The greater openness to identifying harm to certain targeted customers even if other customers are not harmed; The explicit statement that “the measurement of market shares and market concentration is not an end in itself, but is useful to the extent it illuminates the merger’s likely competitive effects;” The clarification that relevant markets that are defined with the use of the hypothetical monopolist test (HMT) can be quite narrow, excluding a number of substitutes to the products and services that are sold by the merging firms (e.g., Guidelines Example 5), and a discussion of techniques for applying the HMT, such as critical loss analysis; The retention of the “structural presumption” that certain mergers that increase market concentration are likely to harm competition, based on updated HHI thresholds that more accurately reflect actual enforcement practice; A greatly expanded treatment of unilateral effects that identify diversion ratios and margins, and their combination in the form of upward pricing pressure, as the key metrics to diagnose unilateral price effectsFootnote 6; The inclusion of theories of harm in markets where prices are set by auctions or by bargaining; The inclusion of theories of harm based on diminished innovation; A more expansive treatment of coordinated effects, including not just explicit and tacit collusion but also “parallel accommodating conduct;” A more skeptical treatment of the entry defense, with a call for evidence of actual, recent, successful entry, and with a preference for the identification of specific potential entrantsFootnote 7; The inclusion of a section that addresses mergers between competing buyers; and The inclusion of a section that addresses partial acquisitions. The 2010 Guidelines also modified the “narrowest market principle.” The 1992 Guidelines (Section 1.11) stated that the Agency “generally will consider the relevant product market to be the smallest group of products that satisfies [the hypothetical monopolist] test.” This unexplained announcement risked committing to a methodology that would ignore important competition. Consider a market with three differentiated products: A, B, and C. Evidence shows that all three are significant substitutes for one another, but B is slightly closer to each of A and C than A and C are to one another. Depending upon the diversion ratios and gross margins, it can easily be the case that, starting with product A, one finds that {A, B} is a relevant market using the hypothetical monopolist test, and likewise that {B, C} is a relevant market if one starts with C. Now A and C propose to merge. Under the “narrowest market principle,” the HMT would generate relevant markets {A, B} and {B, C}, but not {A, B, C}, notwithstanding that a hypothetical monopolist over {A, B, C} would have an even greater incentive to raise prices than would a hypothetical monopolist over {A, B} or {B, C}. The 1992 Guidelines therefore would hinder if not block the Agency from challenging the merger between A and C as a three-to-two merger in the {A, B, C} market. The Agency would thus be hindered or blocked from establishing its prima facie case based on the increase in the HHI in the {A, B, C} market from 3333 to 5555. Indeed, advocates for the merger would emphasize that “B is the closest substitute to A” (and likewise to C) and stress that “A and C are not even in the same relevant market!” To avoid that kind of error, Section 4.1 in 2010 Guidelines gives the agencies the flexibility to define the market in this example as {A, B, C}. The key passage states: “The hypothetical monopolist test ensures that markets are not defined too narrowly, but it does not lead to a single relevant market. The Agencies may evaluate a merger in any relevant market satisfying the test, guided by the overarching principle that the purpose of defining the market and measuring market shares is to illuminate the evaluation of competitive effects.”Footnote 8 (emphasis added) However, defining markets too broadly can also lead to errors. Because “the relative significance of more distant substitutes is apt to be overstated by their share of sales,” the inclusion of distant substitutes can bias inferences from market shares. In evaluating a merger between two motorcycle producers (Guidelines Examples 4 and 7), if one includes “cars” in the market, the resulting market shares would greatly overstate the competitive significance of car manufacturers relative to that of other motorcycle manufacturers (a bias that could incorrectly make the merger look either more troubling or less so, depending on whether a merging motorcycle manufacturer also makes many cars). Thus the 2010 Guidelines retain the principle that “when the Agencies rely on market shares and concentration, they usually do so in the smallest relevant market satisfying the hypothetical monopolist test.” (emphasis added) The papers in this special issue address many of these specific topics, based on 10 years of experience with the 2010 Merger Guidelines.",1
58.0,1.0,Review of Industrial Organization,03 January 2021,https://link.springer.com/article/10.1007/s11151-020-09799-3,Ten Years of the 2010 HMG: A Perspective from the Department of Justice,February 2021,Craig T. Peters,Jeffrey M. Wilder,,Male,Male,Unknown,Male,"In 2010, the U.S. Department of Justice and the Federal Trade Commission (“the Agencies”) revised the Horizontal Merger Guidelines (HMG) to reflect more accurately how the Agencies review horizontal mergers. The revision marked the culmination of a long-standing effort to increase the transparency of the Agencies’ decision-making framework for horizontal mergers.Footnote 1 Ten years later, it is natural to reflect on the current state of horizontal merger enforcement and, in particular, whether the 2010 HMG still provide businesses, courts, and antitrust practitioners with a reliable compass for Agency enforcement of horizontal mergers. In our view, the 2010 HMG have aged well. They continue to describe accurately Agency practice and reflect current legal and economic principles of antitrust. Over the past 10 years, the 2010 HMG have only grown in force, as a number of courts have issued opinions that endorse the Agencies’ analytical approach to horizontal merger enforcement as is outlined in the 2010 HMG.",3
58.0,1.0,Review of Industrial Organization,04 January 2021,https://link.springer.com/article/10.1007/s11151-020-09800-z,The 2010 Horizontal Merger Guidelines at Ten: A View from the FTC’s Bureau of Economics,February 2021,Alison Oldale,Joel Schrag,Christopher Taylor,Female,Male,Male,Mix,,
58.0,1.0,Review of Industrial Organization,24 January 2021,https://link.springer.com/article/10.1007/s11151-020-09802-x,Judicial Response to the 2010 Horizontal Merger Guidelines,February 2021,Carl Shapiro,Howard Shelanski,,Male,Male,Unknown,Male,"In this article, we study how the courts have responded to the 2010 Horizontal Merger Guidelines (2010 Guidelines, or Guidelines, or 2010 HMGs) that were issued by the U.S. Department of Justice (DOJ) and the Federal Trade Commission (“FTC”). This allows us to assess whether the Guidelines have achieved one of their explicit goals: to “assist the courts in developing an appropriate framework for interpreting and applying the antitrust laws in the horizontal merger context.”Footnote 1 Our method for evaluating the judicial response to the 2010 Guidelines is straightforward, albeit qualitative in nature. We have carefully reviewed all judicial decisions in horizontal merger cases since 2000, roughly 10 years before and 10 years after the agencies issued the Guidelines. We look especially for passages where courts cite the Guidelines and where courts address substantive issues that the Guidelines cover. We pay special attention to topics for which the 2010 HMGs made significant changes compared with their predecessor, the 1997 HMGs.Footnote 2 The 2010 HMGs retained the overall framework for analyzing horizontal mergers that has been in place since the 1982 Merger Guidelines. Notably, they retained the “hypothetical monopolist test” (HMT) as the method of defining relevant markets. They also retained the use of the Herfindahl–Hirschman Index (HHI) for screening mergers and for triggering structural presumptions about likely merger effects, while raising the HHI thresholds to reflect agency practice more accurately. We examine how courts have responded to these new thresholds. The 2010 HMGs also brought changes of various magnitudes to several important aspects of merger analysis, including: the assessment of unilateral and coordinated competitive effects; the impact of mergers on innovation; the treatment of entry; the evaluation of efficiencies; and the significance of powerful buyers. Perhaps the most important of those changes relates to the role of market definition in merger analysis, with the 2010 Guidelines putting increased focus on direct evidence of competitive effects—especially for unilateral competitive effects. Herbert Hovenkamp described these changes as making the Guidelines “less technocratic, accommodating a greater and more realistic variety of theories about why mergers of competitors can be anticompetitive and, accordingly, a greater variety of methodologies for assessing them.”Footnote 3 While Hovenkamp found the 2010 Guidelines to be “a striking improvement” over the previous version, others predicted that the revisions—and particularly their focus on unilateral effects and openness to new methodologies—would create problems for the agencies and the courts. Malcolm Coate and Joseph Simons criticized the empirical reliability of unilateral effects models such as those incorporating the upward pricing pressure (UPP) analysis that is embraced by the 2010 Guidelines.Footnote 4 Former senior DOJ official Deborah Garza read the then-new Guidelines to “abandon the analytical framework of prior guidelines in favor of describing principal analytical techniques and types of evidence used to assess a merger.”Footnote 5 She interpreted the new Guidelines as “throwing out the structural screens of the older guidelines,” despite the fact that Section 5.3 of the 2010 HMGs embraces the structural presumption. She predicted that “the very efforts the agencies have made to diminish the significance of market shares and concentration should make it more difficult to rely on them in court.” These fears have not been borne out over the past decade. To the contrary, the 2010 Guidelines have continued to be well accepted by the courts and to assist the case law’s (slow) incorporation of new economic learning and agency experience in analyzing the impact of mergers on competition. In particular, we find that the richer explanation of how the Agencies use qualitative and quantitative evidence to assess competitive effects has favorably influenced the case law and strengthened merger enforcement. The most significant impact of the 2010 HMGs on the courts has been in the area of unilateral effects. Not coincidentally, the assessment of unilateral effects is the area within merger analysis that has seen the most activity and the most progress among economists in recent years. Increasingly over the past 30 years, spurred by the 1992 Guidelines, the DOJ and FTC have used modern economic tools to assess unilateral effects. These tools focus on direct competition between the products that are sold by the merging firms (diversion ratios) and the impact of internalizing that competition (price/cost margins) and can involve full-blown merger simulation. Judicial acceptance of these methods was in doubt in 2010 when the FTC and DOJ updated the Guidelines to address and explain assessment of unilateral effects more directly. Those tools have now become well established in the case law. More generally, we have found numerous examples where the courts embraced the analytical framework provided in the 2010 Guidelines—including especially the guidance that the 2010 HMGs give with regard to the assessment of competitive effects. The process has been similar to past judicial responses to changes in the Guidelines: Courts generally accept the analytical methods that the Guidelines describe; show respect to the experience of the DOJ and the FTC that lies behind the Guidelines changes; but still ground their decisions in principles established by judicial precedent. This is how the Guidelines gradually influence the evolution of the case law. Critically for effective merger enforcement, we find that the 2010 Guidelines not only preserved the agencies’ ability to invoke structural presumptions but strengthened their hand in demonstrating competitive effects. They also appear to have made it harder for merging firms to mount an entry defense in the absence of actual, recent, and successful instances of entry.",7
58.0,1.0,Review of Industrial Organization,09 January 2021,https://link.springer.com/article/10.1007/s11151-020-09809-4,The 2010 HMGs Ten Years Later: Where Do We Go From Here?,February 2021,Steven C. Salop,Fiona Scott Morton,,Male,Female,Unknown,Mix,,
58.0,1.0,Review of Industrial Organization,09 February 2021,https://link.springer.com/article/10.1007/s11151-020-09806-7,"Natural Oligopoly Responses, Repeated Games, and Coordinated Effects in Merger Analysis: A Perspective and Research Agenda",February 2021,Joseph Farrell,Jonathan B. Baker,,Male,Male,Unknown,Male,"The first merger guidelines—which were issued by the U.S. Department of Justice in 1968—did not mention collusion or coordinated effects. They simply observed that “a concentrated market structure, where a few firms account for a large share of the sales, tends to discourage vigorous price competition by the firms in the market.” That understanding was consistent with the industrial organization economics learning of the day (e.g., Chamberlin 1962). The economic model that underlay the literature and the Guidelines viewed supracompetitive prices as the likely outcome of oligopoly interactions with non-zero conjectural variationsFootnote 1: Competition would typically be softened when oligopolists recognize their interdependence and anticipate the natural and predictable reactions of their rivals to their price changes. That view was endorsed in prior academic writing by Donald Turner, the then-head of the Antitrust Division (Turner 1962). Turner explained that a rational oligopolist understands that its rivals will “inevitably react” when it cuts price “because otherwise the price cut will make a substantial inroad on their sales.” As such “inevitable” responses undermine the price-cutter’s reward of a gain in market share, each seller will rationally refrain from price competition.Footnote 2 Some economic models incorporated conjectural variations to capture natural and predictable reactions, and empirical economists sought to estimate conjectural variations.Footnote 3 The next Merger Guidelines—which were issued in 1982 and were modified slightly in 1984—brought a different economic model to understanding the competitive effects of mergers in oligopoly markets. Outside of markets with dominant firms, those Guidelines were concerned about the threat of collusion (in the sense of consciously coordinated behavior). The Guidelines discussed concentration measures and the significance of various aspects of market structure, conduct, and performance in terms of their ability to facilitate “cartels,” “collusion,” and “collusive agreements.” That meant evaluating the effect of those factors on whether firms could reach consensus and deter cheating—consistent with the economic approach that was suggested by Stigler (1964).Footnote 4 That framework drew attention away from the softening of competition and the coordinated outcomes that Turner saw as arising simply from natural and predictable reactions of rivals. As we have discussed elsewhere (Baker and Farrell 2020), this collusion-centered perspective characterized antitrust commentators of that era associated with the Chicago school. By 1992, with the game theory revolution in microeconomics well underway, the new Horizontal Merger Guidelines famously introduced a distinction between coordinated and unilateral conduct, and linked each to a branch of economic theory: Coordinated effects were associated with oligopoly supergames, while unilateral effects were tied primarily to static Nash oligopoly models (Bertrand or Cournot) (Willig 1991).Footnote 5 Building on the 1982 Guidelines, this approach recognized that a tacit but purposive “anticompetitive minuet” (to quote the 1993 Supreme Court in Brooke Group) could lead to a coordinated outcome in an oligopoly supergame without express collusion. But it did not broaden its understanding of coordination so far as to re-incorporate oligopoly conduct predicated on natural and predictable rival reactions, which had been central in 1968. That type of conduct fell between the modeling cracks.Footnote 6 It does not occur in static Nash equilibrium (where by definition conjectural variations are zero). And although it, like a wide range of other conduct, can in principle be brought into the oligopoly supergame framework, that framework directs attention to the purposively collusive (express or tacit) possibilities.Footnote 7 The 2010 Horizontal Merger Guidelines reincorporate the dormant but still vital idea that a softening of competition—yielding supracompetitive oligopoly prices—can result from the natural and predictable reactions of rivals.Footnote 8 These Guidelines describe “coordinated effects” as adverse competitive effects arising from “coordinated, accommodating, or interdependent behavior among rivals,” which can involve “parallel accommodating conduct” that is not pursuant to a prior understanding and does not involve reactions intended to punish cheating, but that “nevertheless emboldens price increases and weakens competitive incentives to reduce prices or offer customers better terms.” Thus, they bring back a recognition that coordination can emerge from non-purposive “interdependent behavior.” While this older idea was once central to both industrial organization economics and antitrust, it has been marginalized by both disciplines. We aim to show why the 2010 Merger Guidelines were right to reincorporate this older idea, and to suggest a corresponding research agenda for antitrust economists and lawyers. The Guidelines do not provide much guidance on evaluating whether a merger creates parallel accommodating conduct—nor could they be expected to do so given the way that earlier Guidelines and the economic literature has developed. Our goal in this paper is to begin the work of rehabilitating the significance for antitrust enforcement—particularly horizontal merger analysis—of coordinated conduct in the gap between static Nash equilibrium models and oligopoly supergame models. We explain the strengths and limitations of the oligopoly supergame framework for horizontal merger enforcement. We also take steps toward explaining, in terms of modern economic theory, how to reincorporate the missing role of natural and predictable reactions of oligopolists. While “coordinated” effects have long been a central concept in the Merger Guidelines, the meaning of the term has varied over time as the focus of economic theory has changed.Footnote 9 For that reason, we begin by explaining how we use the term; we highlight the distinction between coordinated and unilateral competitive effects. It is linguistically natural to describe explicit collusion as involving “coordination” on an anticompetitive scheme and on plans to respond or “punish” a participant that “defects” from the scheme—thereby “deterring” such defections. The same language readily extends to incorporate “tacit… collusion [that] may or may not be lawful in and of itself” (1992 Guidelines § 2.1), and the 2010 Guidelines (§ 7) similarly include “a similar common understanding that is not explicitly negotiated but would be enforced by the detection and punishment of deviations that would undermine the coordinated interaction.” From an economic point of view, the key issue is rivals’ responses to a firm’s competitive moves—most saliently, whether those responses discourage price cuts (and other pro-consumer changes). But the 1984 and 1992 Guidelines described “coordination” only in terms suggesting what we call “purposive coordination” (Baker and Farrell 2020). In purposive coordination, responses are understood as the carrying out of what Schelling (1960) called “threats”: responses that would not naturally be in the threatener’s interest to carry out, had it not made the threat.Footnote 10 The firms’ goal—itself a purposive word—is to establish incentives to support as an equilibrium a pre-defined desired (anticompetitively profitable) equilibrium path. As the folk theorems in repeated games make clear, it is often possible for collusive pricing or output to be a subgame-perfect equilibrium if “supported by” sufficiently vigorous responses that deter more-competitive market choices. These responses are usually thought of as: (a) based on history (in particular, whether anyone has “cheated” and if so, perhaps who); and (b) discontinuous (any defection “triggers” strong retaliation). Such reactions require some sort of mutual understanding and detection and punishment of deviations. We discuss the workhorse model of purposive coordination—repeated games with Nash reversion—in Sect. 2. As the game theory revolution taught us—and as Harrington (2014) has ably exposited in the coordinated effect context—all oligopoly dynamics presumably must be consistent with subgame-perfect equilibria, and “natural” dynamics are not an exception. One might naturally have hoped that characterizing the set of subgame-perfect equilibria is a good way to understand such dynamics. That hope has turned out to be largely unfulfilled: There are too many subgame-perfect equilibria for that characterization to be useful. The folk theorems undertake that characterization and conclude that threats can “support” a wide range of behavior. With standard oligopoly stage-games and plausible discount factors, that wide range often includes fully collusive (shared monopoly) behavior even in unconcentrated industries (Shapiro 1989). Moreover, as a matter of game theory this is the case even if we limit attention to threats that are credible in the sense of subgame perfection. Consequently, a focus on “what’s the worst that can credibly happen?” —interpreting credibility in that sense—would suggest pervasive pessimism about oligopoly performance: One would expect most oligopolies to perform almost monopolistically. Moreover, since that pessimism applies pre- as well as post-merger, it militates toward fatalism about the competitive effects of a merger: If full collusion were very much in the cards with or without the merger, it’s not clear that one should worry about mergers. And the theory offers no answers as to what degree of collusion is “very much in the cards” versus only a little so, or how a merger might affect that. Finally, in light of those (well-known) facts, antitrust economists customarily pull back from attempts to apply the theory quantitatively, and that in turn weakens the impact of concerns about coordinated effects in a policy and litigation world that has (rightly or wrongly) become quantification-hungry. Thus, at a high level, we propose stepping back and, while continuing to use insights from the folk theorems and the repeated game approach, refocusing attention away from “what’s the worst that could happen (or the range of everything that could happen) consistent with subgame-perfect equilibrium?” and toward “what’s natural and apt to happen?”. That broadly was the goal of the conjectural variations approach, and it is our goal here. It is an ambitious goal, and we do not claim to accomplish it: We aim mostly to reinvigorate the question, and to suggest a navigable way forward. While the analysis of “coordinated effects” has suffered from the problems just described, antitrust economics in practice has come to define the “unilateral effects” of a merger as changes in how each firm behaves if it maximizes profits on the assumption that its choices (of price, quantity, capacity, quality, etc.) do not affect its rivals’ choices. In modern economic terms this typically means analyzing the static Nash equilibria of the oligopoly game: assuming zero conjectural variations. These usages, taken together, on their face describe only some oligopoly conduct. They omit—or at least direct attention away from—conduct that is significantly driven by (a firm’s expectations of) how rivals will respond, but that is “individually rational, and not motivated by retaliation or deterrence nor intended to sustain an agreed-upon market outcome” (2010 Guidelines § 7). We have in mind natural and predictable business responses of firms to their rivals’ price changes (or other competitive conduct). When competition is softened as a result, we term those oligopoly outcomes “non-purposive” coordination. Non-purposive coordination may be contrasted with the outcomes of static Nash equilibrium models in which firms are assumed not to respond to their rivals. A more subtle contrast is with the purposive coordination that arises when firm responses are part of a scheme or attempt to develop a consensus or deter price-cutting. To clarify the distinction we make between non-purposive and purposive conduct, consider the different ways thinking that would be involvedFootnote 11: Suppose that a firm’s executives say that if they lower price, they expect their rivals to lower prices in response—and that this expectation discourages them from cutting price. If the executives expect rivals to match because they are trying to make price-cutting less profitable for the first firm, they are thinking in terms of purposive conduct: about deterrence of cheating. If the executives expect rivals to match simply because the rivals would lose too many customers if they kept their prices high, they are thinking in terms of non-purposive conduct: about natural and predicable reactions. Or suppose a firm’s executives routinely match when rival firms cut prices. If the executives say “we want to send a signal that we would like to avoid a price war,” or “our policy is to always match rivals’ prices, even if it might not always seem to make business sense, so that rivals will know they can’t profit from price-cutting”, they are thinking in terms of purposive conduct. If they say “we see that the overall industry price level has declined, and will lose many customers unless we reduce price in response”, they are thinking in terms of natural or non-purposive reactions. We do not grapple with the empirical challenges that arise in identifying the natural and predictable reactions of firms to changes in the decision variables of rivals. Such reactions must be distinguished from the consequences of common shocks (observed by multiple rivals but not by the econometrician) or of rivals’ learning about industry costs and demand by observing changing market prices. Empirical identification problems are compounded because the number of potentially distinct interfirm reactions grows much more rapidly than the number of firms that interact. We also do not grapple with the problem of mapping responses that are observed in data to an underlying theoretical model (Corts 1999).Footnote 12 As we explore in Sects. 3 and 4 below, non-purposive coordination includes cases in which a “leader” sets a price and one or more rivals then respond based on short-run incentives given the leader’s choice.Footnote 13 This in turn would include the Stackelberg model of duopoly or oligopoly, and also the dominant firm/competitive fringe model. The same spirit infuses longer-run incentives that flow from Stackelberg-type Markov reactions in Cyert and DeGroot (1970) and Maskin and Tirole (1987), which are not leader–follower models. In Schelling’s terminology, firms’ responses in such models correspond to “warnings,” not “threats,” because they reflect the responding parties’ underlying natural incentives—not a bootstrapped equilibrium. While oligopolists sometimes collude or perform an “anticompetitive minuet” to train one another not to cut prices, such purposive dynamics are surely by no means the only kind of reactions observed among oligopolists. Often firm A will change its price or output decisions simply because a rival firm B has done so, which alters the market environment that faces A. After all, a change in B’s price shifts A’s residual demand curve, which would be expected to make a different choice optimal for A even if A is in no way trying to reach and support a favored equilibrium or to “deter” B from changing its price or “retaliate” for its having done so. This is the essence of Turner’s observation that firms will “inevitably react” to their rivals’ price cuts, and it is analyzed in Sects. 3 and 4 below. Indeed, firms’ tracking and responding to rivals’ moves is often seen as a hallmark of who significantly competes with whom: responding to rivals’ moves and taking account of rivals’ likely responses is ubiquitous in oligopoly. Not all such oligopolies are attempting to collude. We seek to avoid turning this discussion into one about terminology or classification. One could classify oligopoly outcomes that arise from natural and predictable responses under either the “unilateral” or the “coordinated” heading. The 2010 Guidelines place “parallel accommodating conduct” under the “coordinated” heading because it centers on rivals’ responses, and we follow that choice here and in our earlier (Baker and Farrell 2020) work. Even if one might defensibly classify this conduct under the “unilateral” framework, in practice the modern antitrust economics of “unilateral effects” overwhelmingly assumes simultaneous-move Nash equilibrium in actions such as prices or quantities, and leaves out conduct that is predicated on non-zero conjectural variations. But we stress that our point is to prevent economically significant effects from falling through modeling or classification cracks—not to quarrel about classification decisions.Footnote 14 In Sect. 2 below, we discuss the repeated game approach to coordinated effects, which has dominated the economics discussion of the topic in recent decades. We stress that it is best understood as identifying outer bounds on coordinated effects—what is the worst that might happen?—rather than predicting what is apt to happen. We offer some suggestions for how the theory might be made more helpful for analyzing mergers and quantifying their adverse effects by relaxing some extreme assumptions. We then consider ways to broaden the understanding of coordination by discussing the economics of “parallel accommodating conduct,” which we identify with “natural” (“warning”-like or “non-purposive”) oligopoly responses—in contrast to those that are often studied in the repeated game framework, which have a constructed and purposive (“threat”-like) flavor.Footnote 15 This arguably takes us into modeling conjectural variations, which was once an important topic in industrial economics but has languished. The conjectural variations approach to oligopoly analysis focuses on how the strength of responses affects conduct and performance—though the strength of those responses were often left un-modeled, which made that approach incomplete. One reason, we suspect, that the work on oligopoly behavior in Markov equilibrium models by Nobel laureates Maskin and Tirole has not generated more of an economics literature is that it is technically difficult even in the simplest cases. Maskin and Tirole (1987) themselves solve only a symmetric linear duopoly case, and even then a quartic equation is required. Below, we propose a way to make some more tractable progress. Specifically, in Sect. 3 we propose that studying Stackelberg responses—which are the epitome of “natural” in their very simple dynamic context, and the starting point of the Cyert-DeGroot and Maskin-Tirole models—may offer a path to sensible calibration of natural and predictable responses in a more complex dynamic environment. For that reason, in Sects. 3 and 4 we consider models with Stackelberg reactions, and in particular compare those to Nash equilibrium models. In Sect. 3, we link the incentive effects of Stackelberg responses to the familiar antitrust concept of diversion ratios: We find, in a simple case, that the effect on firm 1′s pricing incentives of anticipating a Stackelberg response by firm 2 can be quantified as half the product of the diversion ratios between the two. In some variants of the Stackelberg framework we calculate the price effects of simple three-to-two mergers and compare those effects to those calculated in the standard unilateral Nash-Bertrand framework. In those calculations, which will be set forth in Sect. 4, prices are higher than in the conventional unilateral effect analysis—both pre- and post-merger—and the competitive effects of mergers are also larger. While the latter results in particular may well not be general, they point to the potential for significant errors if the Nash-Bertrand model is used to estimate merger price effects when parallel accommodating conduct is present. The “Appendix” presents numerical simulations of a simple behavioral model in which firms take turns setting price to match the average of other firms’ prices. While we do not derive that behavior from an optimizing model, similar responses could be natural and predictable under some circumstances. For instance, in the optimizing model of Sect. 4, each Stackelberg follower goes part-way toward matching its rivals’ average price. Starting from a uniform (and therefore steady-state) market price, the model that is set forth in the “Appendix” envisions firm 1 perturbing that steady state by raising its price on day 1, thereafter reverting to turn-by-turn matching. We numerically calculate the new (higher) steady-state price to which the dynamic system converges, and quantify the tradeoff for firm 1 between raising the steady-state price on the one hand, and avoiding losing customers to an interim pricing disadvantage on the other hand. We illustratively study how that tradeoff is affected by the number of (symmetric) firms and by a merger between two such firms. As with the Stackelberg models that we explore in the text, this model displays how horizontal mergers can raise price through effects on rivals’ reactions, in ways that are assumed away in Nash models and are not salient (even if technically present, at least potentially) in standard models of oligopoly supergames. Our modeling here is exploratory and aims at setting forth a research agenda to reanimate analysis of the coordinated effects analysis of mergers: the topic of Sect. 7 in the 2010 Guidelines. We first suggest some directions in which the repeated games approach to coordinated effects can be made more realistic: a precondition for useful quantification. We then begin the work of reincorporating into competitive effects analysis important ideas that have fallen dormant in antitrust economics about the role of natural and predictable reactions of oligopolists, which is our interpretation of the Guidelines’ discussion of parallel accommodating conduct. Throughout, we identify a number of open questions.",1
58.0,1.0,Review of Industrial Organization,09 February 2021,https://link.springer.com/article/10.1007/s11151-020-09805-8,Quantitative Methods for Evaluating the Unilateral Effects of Mergers,February 2021,Nathan H. Miller,Gloria Sheu,,Male,Female,Unknown,Mix,,
58.0,1.0,Review of Industrial Organization,09 February 2021,https://link.springer.com/article/10.1007/s11151-021-09810-5,Mergers with Differentiated Products: Where Do We Stand?,February 2021,Tommaso Valletti,Hans Zenger,,Male,Male,Unknown,Male,"When the revised U.S. Horizontal Merger Guidelines were issued a decade ago, they provided a concise summary of the main economic principles and approaches for assessing the competitive effects of horizontal mergers.Footnote 1 Rereading them today, it is remarkable how well they have aged. As was the case then, this is an instructive document for competition practitioners that distills the most important methods for assessing horizontal transactions. Many aspects of the Guidelines that may have seemed controversial at the time are common ground in competition analysis today. E.g., the initially heated debate about diversion-based tools such as upward pricing pressure has largely subsided. In other areas, the Guidelines promoted analytical principles that anticipated what researchers would confirm in more formal analyses in the decade that followed. E.g., in the case of innovation competition, the Guidelines put an early focus on contestability and innovation diversion. The main strength of the Guidelines, however, was not that they endorsed radically new concepts at the time. Many of the methods that they propose had existed for some time and had previously been applied in individual cases. For instance, the origins of upward pricing pressure can be traced back at least as far as Shapiro (1996), which had already contained the basic idea for what would later be termed “gross upward pricing pressure index” (GUPPI). Since around 2005, the UK authorities had started implementing Shapiro’s early formulas for illustrative price rises in UK merger cases.Footnote 2 And also the European Commission’s 2004 Guidelines had emphasized the central importance of high diversion ratios and margins (the two main ingredients of upward pricing pressure) for assessing competitive effects.Footnote 3 The main virtue of the 2010 Guidelines was instead to bring together a disparate panoply of approaches that had been used in isolated cases to create a unifying framework for implementation. As Shapiro (2010) put it, the Guidelines reflect the transition of merger analysis “from hedgehog to fox.” Whereas the hedgehog knows one big idea (market shares), the fox knows many different ideas: the variety of economic tools that are tailored to different market environments as described in the Guidelines. In Europe, the publication of the U.S. Guidelines coincided with an ongoing shift of EU merger control towards a more economic approach. That shift had been initiated several years earlier following a number of court defeats in which the Court of First Instance had criticized the Commission’s (lack of) economic analysis.Footnote 4 These judgments had led to the creation of a Chief Economist Team (in 2003), the adoption of a new Merger Regulation, and the publication of Horizontal Merger Guidelines (both in 2004).Footnote 5 When the U.S. Guidelines were issued in 2010, this transition of EU merger control towards effects-based analysis was already well underway. Arguably, the publication of the U.S. Guidelines with their focus on economic methods facilitated that process. Perhaps this can be felt most noticeably in two areas: First, the Guidelines supported the calibration of competitive effects through their endorsement of price pressure tools. In the decade that followed, the Commission employed such quantifications in a significant number of cases, in particular in consumer goods and mobile telephony markets.Footnote 6 Second, the Guidelines supported enforcement in the area of R&D competition, where they endorsed investigating innovation theories of harm. In recent years, the Commission has brought several such cases on the basis of economic mechanisms that were also described in the Guidelines.Footnote 7 On the occasion of the 10th anniversary of the revised Horizontal Merger Guidelines, this article provides an overview of the state of economic analysis of unilateral effects in mergers with differentiated products. We discuss both static and dynamic competition, with a special emphasis on the calibration of competitive effects. Besides providing a comparative treatment of different economic methods, we also describe the practical enforcement experience with different approaches in EU merger control from our personal perspective.Footnote 8\(^{\text {,}}\)Footnote 9 The remainder of the article is organized as follows: Section 2 focuses on price competition and discusses the calibration of unilateral effects using diversion-based tools such as upward pricing pressure. Section 3 goes on to assess innovation competition. Section 4 discusses the role of market shares and structural presumptions in differentiated product markets. Section 5 concludes with an outlook.",6
58.0,1.0,Review of Industrial Organization,10 November 2020,https://link.springer.com/article/10.1007/s11151-020-09798-4,Effects of the 2010 Horizontal Merger Guidelines on Merger Review: Based on Ten Years of Practical Experience,February 2021,Dennis W. Carlton,Mark A. Israel,,Male,Male,Unknown,Male,"The 2010 Horizontal Merger Guidelines (hereinafter “2010 Guidelines”) describe the government agencies’ then-current practices for analyzing horizontal mergers. That description, though valuable, was not particularly novel to antitrust practitioners. The Guidelines do contain some novel features, however, and we focus mainly on those features in this article. In particular, we focus on the effects those features have had on the practice of merger review as we have experienced it in the subsequent 10 years. In comparison to the prior Guidelines, the 2010 Guidelines: (1) deemphasized market definition; (2) introduced the concept of upward price pressure (UPP) explicitly into the text of the Guidelines; (3) maintained a focus on potential harm from “coordinated effects” despite what appeared to be its diminishing role in merger analyses (but failed to connect the economics of unilateral behavior to the economics of coordinated behavior, even though both are variations on non-cooperative game theoretic analysis of oligopoly competition); (4) discussed entry and the implications of profit margins; and (5) discussed auctions and bargaining. In this article we address the following questions: How have these more novel features worked out in practice? How does what happened compare to what we thought would happen, based on our views then as reflected in our articles evaluating the Guidelines when they were issued? (Carlton 2010; Carlton and Israel 2010a, b). And what lessons can be learned from 10 years of merger review under the 2010 Guidelines? A short summary of key points, which we elaborate on in the remainder of this article is as follows: The deemphasis of market definition and the elevation of factual analysis that can establish the existence of market power has generally been helpful in focusing the economic analysis of mergers. Nevertheless, the retention of market definition as one step in an analysis of mergers is generally desirable—especially as a means to prevent courts from abandoning any principles to find market power. In particular, it is generally highly useful to employ market definition to identify the relevant set of similarly situated competitors and not to challenge mergers in which that set is large, since competition is likely to remain strong post-merger in such cases. It is also important to stress that the use of market definition and market shares to draw inferences about market power is, at best, only a first step in merger analysis: Market definition, with the associated market shares, is just a crude, imprecise predictor of a merger’s effects (Carlton 2007). Combined with the previous point, this leads us to conclude that a finding that a market has a large number of significant competitors should be a safe harbor for a merger; but finding high market shares for the merging parties should, at most, point to the need for further analysis and should create, at most, a weak presumption in favor of finding harm from the merger. The fear that we had previously raised—that the 2010 Guidelines could lead courts to ignore market definition and be unconstrained in their decision making as to whether there is market power—did not materialize. In fact, if anything, the reverse happened. In complicated situations, courts have sometimes ignored empirical evidence with regard to the presence or absence of market power in favor of using only market definition and share-based presumptions of harm. The problem of over-reliance on market definition—even where it gets in the way of direct evidence on competitive effects—may grow in importance with the increase in litigation that involves two-sided “markets,” where market definition remains a murky and confused exercise for courts. The HHI thresholds in the Guidelines remain basically a reflection of agency practice rather than being based on any rigorous economic research. The introduction of UPP has yielded useful intuition about merger effects—and the connection between them and marginal cost changes—but we believe that UPP has been overused, which has led the agencies to focus scarce investigative time and resources on UPP even when more direct evidence from natural experiments is available. UPP is a great concept for creating intuition for why harm can occur from a merger; but it is a poor one for deciding when to challenge a merger. UPP analysis is a type of (incomplete) structural approach. A superior structural approach is merger simulation, in which one estimates merger effects that are based on underlying demand and cost parameters, in addition to other assumptions. The argument that UPP analysis can be conducted with fewer assumptions than merger simulation is, in our view, greatly overstated. Even more important, the attention that UPP has garnered detracts from the use of “natural experiments,” which are much less structural and instead look at what happened to price after some event. While natural experiments must be interpreted with care, we believe that they have the greatest potential to measure merger effects in particular industries (or groups of industries)—particularly in ways that courts have some chance to understand and evaluate. Unfortunately, we have found that the agencies divert significant attention to UPP (or similar) metrics—even where good natural experiments can be developed; and in some cases the agencies have even discounted the results of natural experiments if they do not align with UPP-based predictions. Although it is good that the Guidelines maintained a focus on coordinated effects, the failure to emphasize the connection between unilateral and coordinated effects has limited these benefits substantially. The introduction of profit measures and linking them to entry is a good idea that could be pursued more, if attention is paid not only to the margins that are relevant but also to how to judge whether accounting data are sufficient to answer the relevant questions. The 2010 Guidelines’ discussion of auctions and bargaining was overdue and has had desirable effects. We would encourage the agencies to continue to rely on auction or bargaining models where appropriate and to avoid reliance on metrics that come out of other models—such as UPP metrics that derive from Bertrand pricing models—in such cases. Finally, although the Guidelines promote the use of certain tools or analyses to evaluate merger effects, the lack of merger retrospective studies that test the predictive accuracy of these tools and analyses continues to be a problem. Rigorous merger retrospective studies could yield insights about the predictive accuracy of the various tools in different settings, which would improve the decision making of the antitrust agencies and the courts.",5
58.0,2.0,Review of Industrial Organization,06 February 2020,https://link.springer.com/article/10.1007/s11151-020-09747-1,Is the Whole Greater than the Sum of Its Parts? Pricing Pressure Indices for Mergers of Vertically Integrated Firms,March 2021,Michael Trost,,,Male,Unknown,Unknown,Male,"Over the last decade, upward pricing pressure indices have been used by several competition authorities—such as the Federal Trade Commission and the EU Commission—as an additional tool for screening mergers. These indices have been strongly advocated by Salop and Moresi (2009) as well as by Farrell and Shapiro (2010). They regard them as an easily manageable tool that accurately indicates the potential anti-competitive price effects of mergers: in particular, in markets for differentiated products for which traditional screening tools that are based on market definition often fail. Upward pricing pressure indices directly focus on the incentive of a merging firm to raise the prices of its products post-merger due to the recapture of lost sales by the other merging partner. The construction of these indices is based on an idea of Werden (1996). They measure the intensity of this incentive by the amount of the reduction in the marginal costs that are required to cause the merged firm to refrain from raising the prices of its products post-merger. The first type of gross upward pricing pressure index—\(\texttt {GUPPI}\)—was introduced by Salop and Moresi (2009) and is applicable for horizontal mergers in markets with differentiated products.Footnote 1 Meanwhile, there exist several variants of this index that take account of alternative market conditions or types of mergers.Footnote 2 However, to the best of our knowledge, there is one type of merger that has not yet been covered in the upward pricing pressure literature although several of such mergers have been extensively scrutinized by competition authorities in recent years. In this paper, we aim to fill this gap. Our objective is to derive gross upward pricing pressure indices—\(\texttt {iGUPPI}\)—for mergers of vertically integrated firms. Recently, this type of merger occurred in several national mobile telecommunication markets where two mobile network operators (MNO) merged. Such operators have their own network infrastructure and are active at two stages of the supply chain: the provisions of network services upstream, and telecommunication services downstream. In the upstream stage, they offer network access to independent mobile virtual network operators (MVNOs), which have no network infrastructure of their own and are thus dependent on network access to supply telecommunication services. Moreover, MVNOs compete with the MNOs, which also offer retail services. Prominent cases of mergers of MNOs in Europe are: Hutchison 3G Austria/Orange Austria in 2012; Hutchsion 3G UK/Telefónica Ireland in 2014; Telefónica Deutschland/E-Plus in 2014; and Hutchison 3G UK/Telefónica UK in 2016.Footnote 3 Interestingly, the European Commission applied the \(\texttt {GUPPI}\) concept of Salop and Moresi (2009) to gauge the price effects of these merger in the retail market.Footnote 4 The question arises whether the \(\texttt {GUPPI}\) concept is still an appropriate measure of the pricing pressure when both merging firms operate at both stages of the supply chain. This paper provides an answer to this question: Such an approach might lead to an (possibly substantial) underestimation of the actual pricing pressure. This underestimation is attributed to the fact that there are additional pricing pressure effects that are not captured by the standard \(\texttt {GUPPI}\) for this kind of merger. The paper is organized as follows: In the next section, we provide a brief summary of our model-based approach to measuring the pricing pressure that is induced by a merger of two vertically integrated firms. The game-theoretic setting of our pricing pressure analysis is detailed in Sect. 3. In the fourth section, the situation pre-merger is characterized. The upward pricing pressure methodology and the data requirements for our indices are discussed in Sect. 5. Sections 6 and 7 are the core part of the paper. The \(\mathtt{iGUPPI}\)s for the products that are offered by the merging firms and by their downstream rivals are specified here. Section 8 concludes.",1
58.0,2.0,Review of Industrial Organization,13 August 2020,https://link.springer.com/article/10.1007/s11151-020-09783-x,Behavior-Based Price Discrimination and Product Choice,March 2021,Chongwoo Choe,Noriaki Matsushima,,Unknown,Male,Unknown,Male,"Behavior-base price discrimination (BBPD) refers to the practice whereby firms condition their price offers on customers’ purchase histories. Advances in technologies have reduced the costs of firms’ investment in customer information, which has led to a proliferation of various types of BBPD.Footnote 1 In the simplest two-period model of BBPD, firms segment a market into two separate markets on the basis of the first-period purchase—existing customers and new customers—and exercise third-degree price discrimination in the second period. Existing studies on BBPD typically focus only on the pricing game with the assumption that product differentiation is exogenously fixed. For example, Fudenberg and Tirole (2000) and many subsequent studies consider a two-period Hotelling model and take maximal differentiation as given. While maximal differentiation is an equilibrium outcome in the static Hotelling model with quadratic transportation cost, it is not obvious whether it continues to be so in the dynamic context: Suppose that a firm chooses an interior location in the first period, while its rival chooses the opposite end. In the second period, the first firm is in a more strategic position than is its rival, which may allow it to poach the rival’s customers more effectively. This line of argument suggests that maximal differentiation may not be an equilibrium outcome when locations are chosen in the first period. Indeed this is shown by Choe et al. (2018): When firms choose locations in the first period and compete in personalized pricing in the second period, BBPD results in an equilibrium where one firm initially chooses an interior location. But we are not aware of any study that endogenizes location choice when the second-period competition is in third-degree price discrimination. The purpose of our study is to fill this gap. Our main result is that—unlike Choe et al. (2018)—maximal differentiation is the only possible equilibrium outcome. The intuition is as follows: When the second-period competition is in third-degree price discrimination, the firm with a larger market share loses more customers to its rival. The reason is that, with third-degree price discrimination, a firm has to charge the same price to all of its loyal customers, some of which are inevitably closer to the rival when the firm has a larger market share. Thus the second period does not matter much to the firm’s decision in the first period. As a result, firms choose maximal differentiation to soften competition in the first period. Given that the result in Choe et al. (2018) is based on competition in personalized pricing, our result is driven mainly by third-degree price discrimination. This highlights an important interplay between the type of price competition and product choice. We proceed below by providing a brief literature review, followed by the model and analysis, and some discussion and the conclusion.",2
58.0,2.0,Review of Industrial Organization,24 January 2020,https://link.springer.com/article/10.1007/s11151-020-09746-2,The “Italian Football Federation Auction” for Co-ownership Resolution,March 2021,Nicola Dimitri,,,Female,Unknown,Unknown,Female,"Since the seminal paper by Cramton et al. (1987), the issue of joint ownership resolution of an asset (Cai 2003), the dissolution of marriages, and in general the dissolution of partnerships has attracted much attention. This paper takes inspiration from the auction mechanism that was used by the Italian Football Federation (FIGC) from the 1950s until June 2015. The FIGC Auction was used to dissolve a 50% joint-ownership with respect to a footballer’s performance rights between two teams. Despite having been used by FIGC for many years, and its similarity with other joint ownership resolution mechanisms, until now a game theoretic analysis of the FIGC Auction with complete information has been missing. This paper is a contribution towards filling this gap, as well as considering alternatives: the Extended Italian Football Federation Auction (EA), and the Second Price Extended Italian Football Federation Auction (SEA). The EA extends the FIGC Auction to owners with any share of the asset, while the SEA further extends EA to a second-price award criteria rather than a first-price auction. The two extended auctions exhibit some interesting and non-standard features. In particular—somewhat surprisingly—we find that truthful bidding is not a weakly dominating strategy in the SEA. Moreover, unlike what happens in standard first- and second-price sealed-bid auctions, the set of pure strategy Nash Equilibria in EA and SEA coincide. This suggests that the FIGC would have obtained the same set of possible outcomes by using a second-price, rather than a first-price, mechanism. The paper is structured as follows. In Sect. 2 we present a brief review of the literature. In Sect. 3 we provide an extensive characterization of the EA and SEA Nash Equilibria with two agents under complete information. Section 4 briefly discusses co-ownership of football players’ performance, while Sect. 5 concludes the paper.",
58.0,2.0,Review of Industrial Organization,27 February 2020,https://link.springer.com/article/10.1007/s11151-020-09752-4,Endogenous Price Leadership and Product Positioning,March 2021,Scott M. Gilpatric,Youping Li,,Male,Unknown,Unknown,Male,"Being the first to enter a market can benefit a firm—if there is a first-mover advantage in establishing product position. The value of a favorable product position depends on the nature of competition. Standard models of differentiated-product competition assume that firms set prices simultaneously; but recent work has shown that—with endogenous timing of pricing decisions—firms may choose to move sequentially. Does the endogenous timing of price competition affect the value of being first to establish product position? Price competition games typically exhibit second-mover advantage. Is the value of superior product position undermined by having it convey undesirable leadership in price-setting? In this paper we model competition between two firms in a differentiated (Hotelling) product space. We focus on a setting with sequential choice of product position, followed by endogenous timing of price-setting.Footnote 1 We find that advantageous product position does confer unwanted leadership in the price-setting timing game. However, the sequential setting of prices benefits both firms relative to simultaneous price-setting. Moreover, because the second entrant chooses to locate farther away when prices are set sequentially rather than simultaneously, obtaining superior product position by entering the market first is nevertheless more valuable (as compared to entering second) given endogenous price leadership. In consumer product and retail markets, key strategic choices are likely to be the initial choice of product location—representing product characteristics or geography—followed by price competition. Of course, it has long been recognized that the timing of these decisions can have important strategic consequences; but modeling the timing of these decisions as strategic choices unto themselves is a relatively recent development. We show that if firms that enter and compete in markets such as these not only choose prices strategically, but also strategically choose when to set prices, this has implications for margins and profits in equilibrium and for the value of being first to enter the market. Since pricing games usually exhibit second-mover advantage, intuition suggests that endogenous timing in price competition might undermine the advantage of being first to locate in a product space if the first entrant is also the price leader in equilibrium. Perhaps surprisingly, we find that while the first entrant does become the price leader, the value of being first to market is not undermined because the price follower chooses to differentiate more from the leader than the differentiation that would occur with simultaneous pricing. From a market efficiency perspective there is a negative impact because endogenous timing leads to increased prices and higher transportation cost, and thus reduces both consumer and social welfare. The remainder of the paper is organized as follows: In Sect. 2, we review the related literature and discuss the differences of our model with that literature. In Sect. 3, we analyze the firms’ timing choices in an extended price game, with their locations taken as given. In Sect. 4, we study the initial positioning strategies of the firms and the resulting market outcomes. Section 5 concludes the paper. Proofs of the propositions are presented in the “Appendix”.",2
58.0,2.0,Review of Industrial Organization,23 March 2020,https://link.springer.com/article/10.1007/s11151-020-09754-2,Cheating in Ranking Systems,March 2021,Lihi Dery,Dror Hermel,Artyom Jelnov,Female,Male,Male,Mix,,
58.0,2.0,Review of Industrial Organization,16 April 2020,https://link.springer.com/article/10.1007/s11151-020-09755-1,Bargaining in Patent Licensing with Inefficient Outcomes,March 2021,Yair Tauman,Yoram Weiss,Chang Zhao,Male,Male,,Mix,,
58.0,3.0,Review of Industrial Organization,15 January 2021,https://link.springer.com/article/10.1007/s11151-020-09803-w,Consumer Use of Multiple Payment Methods,May 2021,Oz Shy,,,Male,Unknown,Unknown,Male,"Data on consumer payment choice show that more than 70 percent of U.S. consumers carry the following payment instruments: cash, credit cards, debit cards, and paper checks; and over 50 percent own a prepaid card: see Greene and Stavins (2018, Fig. 2). Moreover, consumers tend to own duplicates of the same payment instrument. For example the same authors report that in 2017, three-quarters of consumers owned two or more credit cards, and one-fifth owned six or more (the median was three cards). However, owning a particular payment instrument does not imply that consumers actually use it to pay for their in-person purchases. As this article shows, most consumers restrict their use of payment methods to a smaller subset of the payment instruments that they own. In fact, this research shows that 13.1 percent of consumers use only one payment method, which constitutes the highest payment concentration level. These findings apply to consumers who own credit and debit cards and make in-person purchases from seven major merchant categories that are most likely to accept cash, checks, credit, debit cards, and prepaid cards, so the decision which payment instrument to use lies on the consumer side. This article has two goals: first, to conduct an empirical investigation of consumers’ multiple use of payment instruments; second, to demonstrate how the widely-used measures of concentration and inequality can be applied to capture the degree of concentration or diversification of the use of payment instruments for in-person purchases. This investigation is important because, in an era when new payment methods are introduced, policymakers and innovators need to know to what degree a newly-introduced payment method will increase the variety of payment methods that are actually used for in-person purchases, or, whether it will it simply replace existing payment methods. The research that is described in this article introduces a novel approach to measuring payment concentration, which is sometimes (in the literature on payment cards) referred to as the degree of “homing”. Instead of just counting the number of payment instruments that are used by each consumer, this research applies widely-used measures of concentration and inequality in order to generate indices of payment concentrations. These indices reflect better consumers’ choice of whether to concentrate their payments on one or several payment instruments. The derived payment concentration indices are needed for addressing policy questions that are related to the effect of introducing new payment methods on consumer use and adoption of new payment methods. The data that are analyzed in this article reveal diverse consumer preference for the use of multiple payment methods. This raises the following question: Why do some consumers concentrate all of their payments for in-person purchases on a single instrument, whereas others use multiple payment methods for their in-person purchases? The main advantages of concentrating all payments on a single payment instrument are that it simplifies record keeping, facilitates tracking expenses and spending, limits the need for multiple funding sources, and also generates one bill (immediate settlement in the case of cash). The main advantages of using multiple payment instruments to pay for in-person purchases are that they allow for selecting different payment instruments according payment dollar amount, type of good/service, and merchant type. In addition, using multiple methods allows for diversification of the source of funding among different payments and the timing of funding: Cash is immediate; debit is same day; and credit is delayed to the end of the billing or borrowing cycle. This article is organized as follows. Section 2 provides a short review of the literature on homing. Section 3 briefly describes the overall patterns of consumer use of payment instruments for in-person purchases. Section 4 describes the data. Section 5 tests “inertia” effects in consumer payment choice. Section 6 defines measurements of concentration and inequality in the use of payment instruments and applies them to respondents who recorded their payment choice for in-person purchases. Section 7 presents payment concentration regression results. Section 8 concludes.",1
58.0,3.0,Review of Industrial Organization,06 July 2020,https://link.springer.com/article/10.1007/s11151-020-09764-0,"Product Market Competition, Executive Compensation, and CEO Family Ties",May 2021,Clara Graziano,Laura Rondi,,Female,Female,Unknown,Female,"A powerful force that mitigates managerial slack is the market mechanism (Hart 1983). On the one hand, product market competition is itself a source of discipline that prompts managers to exert effort. On the other hand, by increasing the value of effort, competition may make it optimal to offer the manager a performance-related payment contract. Whether competition is a substitute or a complement for monetary incentives is still an open question (Raith 2003; Vives 2008). Although a growing empirical literature has examined the relationship between product market competition and various aspects of corporate governance in managerial firms,Footnote 1 few articles focus on executive compensation, and even fewer examine this issue within family firms. This is probably due to the view that closely-held firms need not provide incentive contracts to their managers because large inside ownership eliminates the agency costs that arise from separation between ownership and control. Recent corporate governance contributions, however, have suggested that there are agency problems also within family firms (Mazur and Wu 2016; Burkart et al. 2003; Schulze et al. 2001). Conflicts typically arise between minority and majority shareholders who pursue non-monetary objectives and let family members run the company even when those family members do not maximize its value. This paper investigates whether the structure of managerial compensation differs between family and non-family CEOs who operate in markets that are subject to different sources of competitive pressure. To test our conceptual framework, we implement different aspects of competition: foreign, and domestic; and we focus on market characteristics that are related to the intensive use of sunk intangible assets to increase product differentiation. We use a panel dataset of publicly listed family companies from 2000 to 2017 in Italy: where many quoted firms are owned by an individual or a family, and are run by a member of the controlling family group. Our findings can be summarized as follows: First, in industries where import penetration is high, products are differentiated, or domestic concentration is high, the variable share of total pay of family CEOs is lower than for external CEOs. Although this result may suggest weaker incentives for family CEOs, we also find that in these industries the variable share of family CEOs’ pay is significantly more related to firm performance than is true for professional CEOs. This suggests that family CEOs are provided stronger incentives than are non-family CEOs. Second, where foreign competitive pressure is weak, the product is homogeneous, or domestic concentration is low, the structure of family and non-family CEOs is similar. Third, the above results are robust to endogeneity concerns about the direction of the relationship between CEO pay and performance, and these results hold when we account for the equity-based component (stock distributions and options) of the compensation. The remainder of the paper is organized as follows: Sect. 2 illustrates the theoretical framework. Section 3 briefly describes the Italian institutional context. Section 4 presents the empirical model and the dataset. In Sect. 5, we describe the main results. Section 6 reports the robustness analyses that focus on: “pay for luck”; alternative definitions of family firms; and the reverse causality in the relationship between CEO pay, firm performance, and other potentially endogenous variables. Section 7 concludes.",2
58.0,3.0,Review of Industrial Organization,01 July 2020,https://link.springer.com/article/10.1007/s11151-020-09766-y,Upstream Competition with Complex and Unobservable Contracts,May 2021,Izak Atiyas,Toker Doganoglu,Firat Inceoglu,Male,Unknown,Unknown,Male,"A lack of upstream competition may arise in a variety of contexts. For example, in several of the European mobile telecommunications markets the mobile network operators (MNOs) refused to supply wholesale airtime to rival mobile virtual network operators (MVNOs). In the allocation of spectrum, the possibility that firms acquire and hoard excess spectrum to prevent access by competitors raised concerns of a collective refusal to supply.Footnote 1 While regulatory and competition policy approaches have implicitly assumed that this situation is likely to emerge as a result of coordination, recent research has established that a lack of upstream competition may arise as the equilibrium of a static oligopoly game. This literature, which is discussed at length in Sect. 1, investigates the incentives of vertically integrated firms (VIFs) to provide access to independent downstream competitors and mainly assumes that contracts are observable to all parties.Footnote 2 Additionally, they focus on a given restricted contractual form: e.g. a linear wholesale price. However, the degree of sophistication of contracts and their observability have significant empirical and practical relevance.Footnote 3 In line with these facts, we consider contracts which are: (i) private; and (ii) are “complex” or “sophisticated” in that they allow the contracting parties to maximize their joint profits. Our model consists of two VIFs that compete to supply an input to an independent competitor in the downstream market, where products are differentiated. We show that the unobservability of contracts makes it more likely that the independent competitor is foreclosed. Furthermore, upstream competition emerges—or, equivalently in our context, the downstream firm gets supplied—for a larger region of parameters, when more sophisticated contracts are allowed. We also provide practically relevant and permissible examples of such contracts. Our results imply interesting complications for competition policy. Some examples of sufficiently sophisticated contracts envisage a high degree of coordination among contracting parties. Hence they may raise competition concerns and may be frowned upon by anti-trust authorities. However, we show that there are situations where anti-trust oriented restrictions on contract complexity may actually make upstream competition less likely to emerge, and therby result in lower welfare. In the next section, we discuss related literature. The basic model is introduced in Sect. 3. In Sect. 4, we describe the set of equilibria that obtain with linear unobservable wholesale contracts. In Sect. 5, we relax this restriction and characterize equilibria when joint profit maximizing contracts are available and present the welfare implications of permitting more complex contractual forms. Sect. 6 concludes.",1
58.0,3.0,Review of Industrial Organization,09 May 2020,https://link.springer.com/article/10.1007/s11151-020-09758-y,Non-Controlling Minority Shareholdings and Collusion,May 2021,Samuel de Haas,Johannes Paha,,Male,Male,Unknown,Male,"Corporations sometimes acquire a minority (less than 50%) equity stake in a rival firm that allows them to share in the profitability of the rival without obtaining control: The buyer acquires a passive interest; see Salop and O’Brien (2000), Tzanaki (2015), and Nain and Wang (2018) for evidence of such acquisitions. Similarly, the majority shareholder of a firm may decide to acquire a non-controlling share in a rival firm (common ownership). Competition authorities have shown an interest in the economic effects of the acquisition of non-controlling minority shareholdings (NCMS) of both types. For example, in July 2014 the EU issued a White Paper that discusses an amendment of the current EU Merger Regulation towards assessing NCMS. Since then, especially common ownership has received increasing attention. Theoretical literature such as Reynolds and Snapp (1986), Flath (1991), Flath (1992), Malueg (1992), and Gilo et al. (2006) has studied the effects of NCMS on firms’ profits and the sustainability of collusion under a variety of assumptions with respect to a number of key parameters such as firms’ profit function, their strategic variables (prices versus quantity), and the degree of product differentiation. This diversity of assumptions constitutes an impediment to the comparability of different articles’ results. Our article integrates these earlier models into a more comprehensive one, which fills a gap in the literature because we analyze several combinations of assumptions that have not been studied jointly by prior literature. We also provide analytic proofs for effects that have been established only numerically by prior literature. The model confirms two insights: First, NCMS of firm i in firm j raise firms’ profits in competition. These are the profits that are made when every firm plays its best response to the other firm’s choice of its strategic variable. But this increase in competitive profits also increases the incentive to deviate from collusion. This is because the deviator i’s profits in the punishment phase will be higher because of the reduced intensity of competition. Second, NCMS decrease firm i’s incentive to deviate because firm i (or its majority shareholder) would then receive lower dividends from the cheated firm j. Hence, minority shareholdings increase the deviation incentive if the first effect prevails over the second; as has been shown by Malueg (1992) for convex demand. We advance the literature in two directions. First, our model is the first to study analytically how a competition authority influences the effect of minority shareholdings on the sustainability of collusion. We find that the collusion-destabilizing effect of NCMS is particularly strong in the presence of an effective competition authority. This effect can be observed even when demand is non-convex. Second, prior literature has typically concentrated on the question of how firm i’s shares in firm j affect i’s decision whether to deviate from collusion. In addition, we show that firm j’s shareholdings in firm i destabilize collusion by raising firm i’s critical discount factor whenever the cross shareholdings raise the firms’ profits in competition. This indicates that minority shareholdings destabilize collusion under a wider set of assumption than was suggested by earlier literature. The article is structured as follows. Section 2 shows how the present study contributes to the existing literature. Section 3 provides the model and studies the effects of NCMS on firms’ stage game profits. Section 4 analyzes the effects of NCMS on the sustainability of collusion. Section 5 adds the competition authority. Our results are robust to changes in the assumptions about firms’ profit functions, which might either model cross ownership or common ownership, as is demonstrated in Sect. 6. Section 7 concludes the article. Proofs are provided in the “Appendix”.",9
58.0,3.0,Review of Industrial Organization,05 May 2020,https://link.springer.com/article/10.1007/s11151-020-09757-z,Payoff-Improving Competition: Games with Negative Externalities,May 2021,Petros G. Sekeris,Kevin Siqueira,,Male,Male,Unknown,Male,"Competition in games with negative externalities is typically thought to reduce the payoffs of incumbents. In Cournot competition models, for instance, entry of new competitors increases aggregate production, which thereby pushes market prices and incumbents’ profits downwards. The same holds true in Common Pool Resource (CPR) problems and in rent-seeking games, where free entry carries negative consequences and is thus detrimental to overall efficiency (e.g. Hardin 1968; Tullock 1980). Increasing competition in such games—by either adding players or improving the efficiency of some incumbents—has typically two effects on the payoffs of the other incumbents. First, the extra production effort of the entrant/competitor has a detrimental direct effect on the well-being of the remaining incumbents as it reduces the marginal benefit of effort. Second, with respect to the strategic effect, if the incumbents’ best-response functions are downward sloping, as is usually the case, this leads to an aggregate increase of effort and a decrease in individual payoffs. Yet, with upward sloping response curves, as we show to be the case with sufficiently convex outcome functions—e.g., the demand function in a Cournot setting—the new equilibrium can involve lower aggregate effort and higher individual payoffs.Footnote 1 We show that entry in such instances can also be desirable from the entrant’s viewpoint, and thereby produce Pareto-superior outcomes for both incumbents and entrants: Incumbents that face a Prisoner’s Dilemma and fail to commit to low efforts may welcome the increased competition that incentivizes all other players to constrain their effort level, and reduce the negative externality, and thereby increase the welfare of all individuals. To further fix ideas, consider a Cournot duopoly with 2 symmetric firms that simultaneously decide their output \(q_i\), \(i\in \{1,2\}\). Moreover, consider a decreasing and convex demand function \(P(Q)=\frac{1}{Q}+\frac{1}{Q^4}\), where \(Q=\sum _{j=1}^nq_j\), and assume that production is costless. Accordingly, each firm i maximizes its profit function by optimizing \(\max _{q_i}\left[ \frac{1}{Q}+\frac{1}{Q^4}\right] q_i\). Thence at optimality, we obtain \(P(Q)+P'(Q)q_i=0 \Leftrightarrow \frac{1}{Q}+\frac{1}{Q^4}-\left( \frac{1}{Q^2}+\frac{4}{Q^5}\right) q_i=0\). To decide the optimal output, a firm then weighs the marginal benefit of selling an additional unit at the market price, against the negative effect of dropping prices on total revenue: \(P'(Q)q_i\). Solving this problem and imposing symmetry allows us to deduce the equilibrium production levels of any duopolist i: \(q_i^*=\frac{1}{2^{2/3}}.\) We next deduce that the equilibrium prices \(P(q_1^*+q_2^*)\) equal \(\frac{3}{2^{4/3}}\), and profits thus equal 3/4. Consider next the same setting featuring 3 firms instead. One can derive \(q_i^*=\frac{1}{3\times 2^{1/3}}\), \(P(Q^*)=3\times 2^{1/3}\), and \(\pi _i^*=1\). As one can easily see, individual output and total output are lower, and prices and profits are higher with the addition of the third firm.Footnote 2 In this example, since demand is sufficiently convex, the players’ best-response functions are upward slopping and therefore the firms’ outputs are strategic complements of another. In addition, since demand is highly convex, the added production of an extra competitor results in a potentially higher marginal benefit of production because of the cost of dropping prices \(P'(Q)q_i\) shrinks faster than prices P(Q). However, increased output by incumbents would leave all players worse off since the demand is downward sloping. Increased output by each firm cannot be a profitable equilibrium response to entry. On the other hand, a possible reduction in output in order to accommodate entry may be profitable since the interpretation of the two terms in the above paragraph is then reversed. Indeed in equilibrium, firms “over-accommodate” entry and reduce their output (to offset the entrant’s) such that total output falls and price rises with entry. Since the demand is steeper for lower aggregate production, the negative effect of dropping prices on total revenue will then be sufficiently high to disincentive firms from deviating. The empirical IO literature has identified a situation that corroborates our findings in the U.S. market for solar photovoltaic systems. Nemet et al. (2017) and Pless et al. (2017) show that higher market concentration amongst installers/suppliers is associated with lower prices and that ‘residential solar PV prices are higher in more competitive markets’ (Pless et al. 2017, p. 24). Thomadsen (2007) reaches comparable conclusions when showing that McDonalds and Burger King tend to charge higher prices when they are more closely in competition with each other: when located geographically closer to one another in U.S. markets. In the specific context of CPRs, Johnson and Libecap (1982) wondered why the implementation of entry barriers was not put in place in the Texas shrimp industry. The authors found it remarkable that not only did the shrimp fishery have no formal, limited-entry program, it did not even have a pre-existing informal program to limit entry as well. At the time of their writing, this seems in accordance with our assumptions since fishing activities often exhibit falling average product, as in Johnson and Libecap (1982), and may take place where production is convex in aggregate effort, as in Kotchen and Salant (2011). In the next section we briefly review the related literature, before presenting the theoretical contribution in Sect. 3. Section 4 concludes.",
58.0,3.0,Review of Industrial Organization,16 July 2020,https://link.springer.com/article/10.1007/s11151-020-09775-x,Comparing Cournot and Bertrand Equilibria in the Presence of Spatial Barriers and R&D,May 2021,Kuang-Cheng Andy Wang,Yi-Jie Wang,Wen-Jung Liang,Unknown,,Unknown,Mix,,
58.0,4.0,Review of Industrial Organization,26 October 2020,https://link.springer.com/article/10.1007/s11151-020-09795-7,Vertical Mergers: A Survey of Ex Post Evidence and Ex Ante Evaluation Methods,June 2021,Margaret E. Slade,,,Female,Unknown,Unknown,Female,"Over time, mergers have grown in size and become more international. Moreover, the developed countries have moved from industrial economies — with giant firms such as Standard Oil, US Steel, and American Tobacco that produce physical products — to knowledge economies — with giant firms such as Amazon, Microsoft, Facebook, and Google that perform computer-based services. Furthermore, whereas competitive concerns that involved the former industries were most often horizontal, some of the most publicized concerns that involve the latter industries are vertical. High profile vertical mergers — such as AT&T/Time Warner, Nielsen/Arbitron, Comcast/NBCU, Ticketmaster/Live Nation and Broadcom/Brocade — have focused attention on the possibility of harmful vertical mergers. Since the technology, media, and telecom sectors dominate the list of today’s largest companies, it is not surprising that those firms also dominate the list of today’s largest and most controversial vertical mergers. Relationships between upstream and downstream firms have been hotly contested. Indeed, opinions range from the position that all vertical mergers and restraints are efficient and should therefore be per se legal to a much more skeptical view that foreclosure, entry deterrence, and other anticompetitive motives lie behind most of those arrangements. Furthermore, policy makers are hampered by the fact that the findings from both theoretical models and empirical assessments of those models are most often ambiguous and, even when conclusions are reached, they are apt to be weak. In order to assess the tradeoff between vertical efficiencies and competitive harm, this article first examines recent empirical research that attempts to evaluate vertical mergers and integration. That evidence is retrospective in the sense that it relies on post–merger data. When a merger is proposed, however, competition authorities must have screening and evaluation techniques that rely only on premerger data. There are several such techniques that are routinely used in the context of horizontal mergers and it is tempting to modify them to fit the vertical context. Unfortunately, there are many pitfalls that are encountered when attempting to do this. This article also compares and contrasts horizontal and vertical screening and evaluation techniques and reports evidence with respect to their performance. The organization of the paper is as follows: Sect. 2 contains a discussion of vertical mergers in general as well as in the telecom, media, and technology sectors. In particular, it examines vertical merger actions in the US over the last 25 years. Sect. 3 assesses vertical merger efficiencies in theory and practice with emphasis on the technology, media, and telecom sectors. A similar exercise is performed for competitive harm. Sect. 4 discusses quantitative techniques for vertical merger assessment and contrasts them with those used to evaluate horizontal mergers. Specifically, upward pricing pressure calculations and merger simulations are considered. In the last section, some conclusions are drawn.",11
58.0,4.0,Review of Industrial Organization,24 August 2020,https://link.springer.com/article/10.1007/s11151-020-09784-w,Jointly Held Investment Options and Vertical Relationships,June 2021,Dimitrios Zormpas,,,Male,Unknown,Unknown,Male,"Innovation is an important factor for a company’s success and a crucial explanation for observed differentials in performance (McGrath and Nerkar 2004). Consequently, a fundamental problem that a firm faces has to do with the decision to invest in a new product or technology. These managerial decisions are characterized by risky, irreversible and lumpy investments that are often beyond the resources of a single firm (Chesbrough and Schwartz 2007). As a result, an investment partner is frequently sought (Kogut 1991; Scott 1996). According to Quinn (2000), using partnerships “companies have lowered innovation costs and risks by 60% to 90%, while similarly decreasing cycle time and leveraging their internal investments by tens to hundreds of times”. Investment partnerships might take the form of joint ventures, venture capital investments, strategic alliances, or mergers. Irrespective of the exact nature of the partnership, the reasons that motivate it are common: When joining forces with another firm, a potential investor anticipates financial returns and/or future growth opportunities.Footnote 1 The real options approach is a standard framework for the analysis of such opportunities. It builds on the idea that the option to undertake an investment that is characterized by uncertainty and irreversibility is analogous to an American call option on a real asset. Hence, the potential investor needs to factor in that, at the time of the investment, he forgoes the option to reconsider the investment decision at some future time point when the uncertainty will be, naturally, partly resolved.Footnote 2 This means that apart from the investment cost, there is also an opportunity cost that the investment needs to pay for. The standard real options model does not account for investment partnerships. However, there is a growing body of papers that analyze investments that involve two or more parties that can generate a surplus by jointly exercising an investment option. In spite of the differences in their analyses, what these papers share is the assumption that the inputs that are required for the investment to take place are competitively priced. The key originality of our work is as follows: We discuss the optimal exercise of a jointly held investment option and explicitly assume that the input supplier has market power. Our analysis evolves as follows: We first present the case where the input market is competitive and the investment option is held by a single party. This constitutes our standard of comparison. Then, we discuss an investment option that is jointly held by two parties. We assume that the two option holders first agree on how to share the surplus that is generated by the project and then one of them chooses the timing of the investment. The sharing rule is chosen, either cooperatively, using a Nash bargaining solution, or non-cooperatively. In line with the extant literature we show that when the input market is competitive the investment can take place before, after, or exactly when the optimal investment threshold is reached. This depends on the way the two parties interact cooperatively or non-cooperatively and on the bargaining power distribution. When instead the input market is non-competitive, we show that, irrespective of the game theoretic framework downstream, the investment takes place inefficiently late. The main message that the paper conveys is that, as soon as the completion of the investment depends on the provision of an input by an upstream firm with market power, the way that the two option holders interact (non-cooperatively versus Nash bargaining) is of secondary importance since the investment timing is always dictated by the presence of the input supplier. This result highlights the importance of the nature of the input market (competitive or non-competitive) when considering jointly held investment options. The remainder of the paper is organized as follows. In Sect. 2 we present an overview of the related literature. In Sect. 3 we present the model set-up and demonstrate the connections with previous work. In Sect. 4 we introduce an input supplier with market power, and Sect. 5 concludes.",1
58.0,4.0,Review of Industrial Organization,01 October 2020,https://link.springer.com/article/10.1007/s11151-020-09788-6,Signaling in Technology Licensing with a Downstream Oligopoly,June 2021,Cheng-Tai Wu,Cheng-Hau Peng,Tsung-Sheng Tsai,Unknown,Unknown,Unknown,Unknown,,
58.0,4.0,Review of Industrial Organization,27 August 2020,https://link.springer.com/article/10.1007/s11151-020-09785-9,On Bundling and Entry Deterrence,June 2021,Andrea Greppi,Domenico Menicucci,,Female,Male,Unknown,Mix,,
58.0,4.0,Review of Industrial Organization,03 January 2021,https://link.springer.com/article/10.1007/s11151-020-09801-y,A Kantian Analysis of Pricing and R & D,June 2021,Murat Donduran,Burak Ünveren,,Male,Male,Unknown,Male,"This study revisits the cooperation versus competition debate in the context of pricing and R&D investments by oligopolistic firms. A recent and empirically relevant development in the theory of cooperation motivates our analysis. Firm cooperation is typically modeled as cartel behavior: maximizing the sum of profits. But this type of cooperation stipulates that a central authority knows all firms’ profit functions to control their decisions. So the cartel formulation is a form of “selfless” or “centralized” cooperation. The general theory of Kantian cooperation – which was developed by Roemer (2010) – offers a general alternative to maximizing the sum of profits. To be specific: A Kantian firm would increase its effort if and only if its own profit would increase when all firms exert higher efforts. Hence, a Kantian firm would care solely about its own profit, rendering Kantian decision-making a self-regarding and decentralized form of cooperation. Kantian cooperation among firms is also an empirically relevant concept that we shall discuss later. In this study, we develop a two-stage pricing R&D investment game, where firms are either Kantian cooperators, cartel cooperators, or competitors a la Bertrand. In the first stage, firms decide how much to invest in R&D. This investment decision increases the probability of improving technology that will reduce marginal cost. So, the outcome of R&D investments is uncertain.Footnote 1 This is in stark contrast to the current literature where deterministic R&D models are the norm. As we shall see, uncertainty is crucial for our results. In the second stage, firms observe their technology and then choose their prices according to their behavioral types. The Cartesian space of different behavioral assumptions in two stages of the game is fully analyzed. For example, an admissible scenario is Kantian cooperation in R&D decisions despite non-cooperative behavior in pricing decisions. So, in general, there are nine (3 × 3) possible scenarios. We find that Kantian cooperation in prices induces weakly higher (lower) R&D investment than does cartel cooperation in prices without (with) perfect research externalities. We also compare all outcomes to the social optimum. Among all nine cases considered, only Kantian cooperation in prices and non-cooperation in R&D can exceed, or be equal to, the socially optimal R&D. These results have important implications for policy design and market regulation that intend to boost innovation, as we show that cooperation in pricing strongly affects firms’ R&D incentives. Interestingly, this link between cooperation in pricing and R&D has hitherto been overlooked in the literature. Moreover, our results also imply that decentralized (Kantian) cooperation in pricing can induce more R&D investment than does both centralized (cartel) cooperation and decentralized competition. The next section explains the preliminaries of the Kantian optimization. In Sect. 3, we present a short literature survey. The model is explained in Sect. 4 and is solved in Sect. 5. Those solutions are ranked according to their levels of R&D in Sect. 6, followed by the analysis of first best in Sect. 7. We discuss further extensions of our model is Sect. 8. The conclusion is in Sect. 9.",4
59.0,1.0,Review of Industrial Organization,10 March 2021,https://link.springer.com/article/10.1007/s11151-021-09813-2,Evidence Production in Merger Control: The Role of Remedies,August 2021,Markus Dertwinkel-Kalt,Christian Wey,,Male,Male,Unknown,Male,"In a landmark decision in May 2020, the General Court of the European Union annulled the decision of the European Commission to block the acquisition of Telefonica UK by Hutchison 3G UK: The Court stated that the Commission failed to prove that this acquisition would have harmed competition.Footnote 1 This case highlights the policy relevance of the question how antitrust agencies produce evidence, and how the incentives to produce evidence in merger control can be enhanced. We analyze evidence production in merger control as a delegation problem in an inquisitorial competition system. Depending on its ex-ante uncertain efficiency type, a merger proposal can be anti- or pro-competitive: consumer welfare reducing or increasing. A principal-agent problem between the legislator—whose objective is to maximize consumer welfare—and the antitrust agency—whose objective is consumer surplus minus effort costs—arises from the fact that the agency’s investigative effort in a merger case is non-contractible. We investigate how different action sets of the agency affect its incentives to exert effort and acquire information on the efficiency type of a proposed merger. We compare the case (1) in which the agency can either approve or prohibit the merger altogether with the case (2) where a merger can also be cleared conditionally on the basis of a remedy solution. Throughout our analysis we take the remedy solution as a compromising choice that is optimal from an ex ante perspective: whenever only the a priori information on the merger’s efficiency type is available. Our main contribution is to show that allowing for remedial solutions deteriorates incentives for the agency. As the remedy solution represents a compromising choice and thereby the negative effect of a false extreme decision, allowing for it reduces the agency’s incentives to obtain information on the merger’s efficiency type. Altogether, the availability of the remedy solution reduces the agency’s effort provision when compared to a no-remedy regime that forces the agency to either to approve or to prohibit the merger. In contrast, in a scenario in which only extreme options are implementable, a false decision bears the risk of making a wrong decision with strong negative consequences. Therefore, in the absence of the remedy solution, the agency acquires more information in order to avoid such negative consequences. Thus, it can be desirable overall for the legislator to remove the remedy solution from the agency’s choice set.Footnote 2 Finally, we analyze “evidence-based remedies” whereby a remedy solution can be implemented only if the agency has gathered and evaluated information that supports the ex-post optimality of the remedy decision. This leads to higher information (and higher consumer welfare) levels than in the case where remedies cannot be implemented. As a consequence, requiring evidence for the remedial solution is always weakly preferred over a no-remedy regime.",2
59.0,1.0,Review of Industrial Organization,27 October 2020,https://link.springer.com/article/10.1007/s11151-020-09789-5,Leniency Programs and the Design of Antitrust: Experimental Evidence with Free-Form Communication,August 2021,Peter T. Dijkstra,Marco A. Haan,Lambert Schoonbeek,Male,Male,Male,Male,"One of the main tasks of antitrust authorities is to fight cartels. Leniency programs can help. In such programs, an Antitrust Authority (AA henceforth) offers a fine reduction to firms that report a cartel. Since the introduction of leniency programs, the number of cartels prosecuted has increased in both the United States and European Union (Motta 2004; Spagnolo 2008). Whether this is due to the success of leniency programs or merely reflects an increase in cartel activity is unclear. Since cartels are secretive, it is hard to assess this empirically.Footnote 1 Experimental methods may shed some light. In most leniency experiments in the literature, subjects can communicate in a restricted manner, essentially by sending signals. Yet, studies without leniency have shown that lessons drawn from cartel experiments with restricted communication may not translate to environments with free-form communication: Where natural conversation is possible. Free-form communication may be important in building trust, resolving conflicts, and coordinating collusive strategies. If free-form communication allows firms to build trust, the question becomes whether leniency programs can break that trust. We therefore study a leniency experiment that allows for free-form communication. We let subjects play a repeated game and allow them to discuss anything via a computer chat. To the best of our knowledge, we are the first to do so.Footnote 2 However, once subjects decide to communicate, they are technically in a cartel and hence may be prosecuted. One other important innovation is that we allow subjects to report after they have learned that an AA has started an investigation. This also gives subjects the option to discuss their reporting strategy, should there be an investigation. For robustness, we consider two leniency regimes that differ in the probability that the AA starts an investigation, and in the probability that it finds evidence of the existence of a cartel. We do not explicitly compare free-form communication with restricted communication. Nor do we study the effect of the number of oligopolists. That would exponentially increase our number of treatments. Rather, we compare our results to those in the literature with restricted communication. Different from experiments with restricted communication, we do not find much of an effect of leniency programs. Leniency does not deter cartels. It only delays them. Free-form communication allows subjects to build trust and resolve conflicts. Subjects achieve remarkable sophistication in the agreements they make. Reporting and defection rates are low, especially when compared to experiments with restricted communication. Indeed, communication is so effective that, with leniency in place, prices are not affected if cartels are fined and cease to exist. Inevitably, any experiment only partly reflects real-world collusion. We cannot impose reputational consequences of being in, or reporting a cartel. We cannot have criminal penalties as in the United States or the United Kingdom. In our experiment the likelihood of investigation is exogenous, and the extent of penalties does not depend on the amount of communication. There are no additional penalties for recidivism. The AA does not learn, and penalties do not depend on how long a cartel has been active. Still, despite these shortcomings, we believe that our experiment can shed some light on real-world collusion. The remainder of this paper is structured as follows: In Sect. 2 we discuss related literature. Section 3 presents our experimental design, while results are reported in Sect. 4. Section 5 concludes.",8
59.0,1.0,Review of Industrial Organization,01 March 2021,https://link.springer.com/article/10.1007/s11151-021-09811-4,Recall and Vehicle Characteristics Associated with Vehicle Repair Rates,August 2021,Andrew M. Malec,Patricia K. Smith,Anson E. Smuts,Male,Female,Male,Mix,,
59.0,1.0,Review of Industrial Organization,15 January 2021,https://link.springer.com/article/10.1007/s11151-020-09804-9,Partial Privatization Upstream with Spatial Price Discrimination Downstream,August 2021,John S. Heywood,Shiqiang Wang,Guangliang Ye,Male,Unknown,Unknown,Male,"We examine the optimal privatization of a public firm that competes against a private firm upstream and that sells to spatial price competitors downstream. The extent of privatization is less—and often substantially less—than would be implied without the double marginalization that is introduced by the vertical chain. We identify a trade-off between the ability of the public firm to eliminate double marginalization and the potential for the mixed upstream market to produce more cheaply because of the presence of the private firm. We demonstrate that the critical determinant of this trade-off is the extent of horizontal differentiation downstream. We combine two strands of imperfect competition literature: First, we study the extent to which partially privatizing a public firm improves welfare. Matsumura (1998) demonstrates that partial privatization restrains an otherwise welfare maximizing public firm from producing too much and shifts enough production to a lower-cost private rival to improve welfare. Second, we recognize that imperfect markets at multiple production stages typically have lower welfare than do imperfect markets at one stage (Spengler 1950; Cournot 1838). Adding this vertical chain changes the balance of what the partially privatized firm can accomplish. Increased privatization reduces the cost as before, but the reduced output makes double marginalization worse—which leaves welfare in doubt. We examine two private firms that compete downstream as spatial price discriminators with transport cost representing product differentiation. When downstream transport cost equals zero, the market is perfectly competitive. With sufficiently high transport cost the downstream market becomes two separate monopolies. Intermediate cases present realistic circumstances in which some customers are sufficiently “close” to one brand that they are not influenced by the price of the other brand, while other customers remain in play in a pricing game between imperfect substitutes. This setting differs from typical differentiated product models in which all customers share identical relative evaluations of the two products (starting with Bowley 1924). Thus, we uniquely characterize the optimal degree of privatization and show how it varies with the extent of the downstream (retail) differentiation. We isolate that this variation depends critically on the extent to which consumers are in play between the retailers versus the extent to which they are sufficiently close to one firm as to face no competition. Finally, we compare this market with one in which the upstream market is simply a public monopoly and identify the conditions under which this is welfare-superior to the mixed duopoly upstream.",1
59.0,1.0,Review of Industrial Organization,06 November 2020,https://link.springer.com/article/10.1007/s11151-020-09797-5,Licensing of a New Product Innovation with Risk Averse Agents,August 2021,Siyu Ma,Yair Tauman,,Unknown,Male,Unknown,Male,"Patent licensing schemes have been extensively studied. The past literature focuses more on a per-unit royalty, an up-front fee, and their combination and less on an ad valorem royalty (a percentage of dollar sale)—even though the latter is far more popular in practice.Footnote 1 A central part of this paper deals with ad valorem royalty licensing (used alone or combined with an up-front fee) and provides analytical justifications for its prevalence. The paper studies patent licensing of a new product innovation whose viability is uncertain: The demand is either zero (non-viable product) or a specific downward sloping function in price. An example is the Tata Nano launched in 2008 by Tata Motors. Nano was a mini city car with an extremely inexpensive manufacturing cost (less than $ Í2500), which was intended to appeal to riders of motorcycles and scooters for personal transportation. However, the numerous cost-cutting features led to serious safety flaws. Reports of Nanos bursting into flames after rear collisions were common in the months after the vehicle’s debut. Tata ultimately sold fewer than 8,000 Nanos before pulling the vehicle from the market entirely. Another example is the Samsung Note 7 that launched in 2017: It lasted less than a year in the market after Samsung had to recall it due to complaints of overheating and exploding batteries.Footnote 2 Studying the licensing policies for such products, our main contributions are: (i) The innovator and licensees can be risk averse. (ii) A general set of licensing schemes is analyzed. It includes: a pure up-front fee; a pure per-unit royalty; a pure ad valorem revenue royalty; and two-part tariffs with any type of royalty. (iii) The number of licensees is a choice variable of the innovator, which allows the examination of the diffusion of the innovation for each scheme. (iv) The paper compares these schemes in terms of: the incentive to innovate; industry payoff (the sum of the innovator’s revenue and licensees’ profit); and market structures. (v) The innovator can be either an outsider or a producing firm. A pure up-front fee eliminates uncertainty for the innovator while licensees bear the entire risk of the product being non-viable. However, in the model, by charging pure royalties the innovator takes all of the risk, since payments are collected only after demand is realized. A two-part tariff scheme provides risk-sharing between the innovator and the licensees. The paper shows that for a non-producing innovator (e.g., a lab), ad valorem royalties favor the innovator whereas per-unit royalties tend to benefit licensees. The use of ad valorem royalty, compared to per-unit royalty (with or without up-front fee), leads to: a lower market price; higher consumer surplus; higher innovator’s revenue; higher aggregate industry payoff; but lower profit for licensees. Since a per-unit royalty directly raises marginal cost while an ad valorem royalty only indirectly affects marginal cost, the double-marginalization effect is stronger with a per-unit royalty, which implies lower quantity and higher price. Consequently, for the innovator and consumers, schemes with a per unit royalty yield a worse equilibrium outcome than do schemes with an ad valorem royalty. A pure up-front fee scheme, on the other hand, avoids double marginalization and results in a lower market price, higher consumer surplus and higher industry payoff than schemes with a royalty component, even though the innovator optimally sells only one license and creates a monopoly. A pure up-front fee, however, yields the innovator higher revenue only if the licensees’ risk aversion is below a certain threshold. Otherwise, they are willing to pay less up front, which induces the innovator to charge a two-part tariff with a lower fee and with an ad valorem royalty. This may explain why a pure up-front fee is less common, especially with licensees who tend to be risk averse. Unlike the pure up-front fee scheme, the innovator sells licenses to all potential producers when using schemes with a royalty component.Footnote 3 Hence risk aversion contributes to greater diffusion of a new product innovation. The above results do not change qualitatively if the innovator is also risk averse. To summarize: The optimal scheme for a non-producing innovator is a combination of positive up-front fee and positive ad valorem royalty if either the number of potential producers is sufficiently large or producers’ risk aversion magnitude is above a certain threshold. Otherwise, the optimal two-part tariff for the innovator collapses to a pure up-front fee. Our result confirms Llobet and Padilla (2016) that value-based royalties provide a greater incentive to innovate than do volume-based royalties. Moreover, we provide additional policy implications: The best scheme for licensees is a pure per-unit royalty, and schemes that maximize technology diffusion are those that include either type of royalty. The results are quite different if the innovator is himself a producer, since licensing hurts his own operating profit. A mildly risk-averse producing innovator is best off selling no licenses and producing the entire demand himself, regardless of how risk averse are the other potential producers/licensees. A highly risk-averse producing innovator is best off selling one license only and creating a duopoly. Finally, the paper is closely related to franchising.Footnote 4 The innovator plays the role of franchisor, and the licensees play the role of franchisees. Like licensing contracts, a franchise agreement is a contractual arrangement between a franchisor and a franchisee. As of 2001, 93.5\(\%\) of all franchisors charged franchisees an ad valorem revenue royalty, and most of them charged in addition some up-front fees. This is consistent with our result with regard to non-producing innovators, which accounts for 28\(\%\) of all franchisors that own and operate no units (see Blair and Lafontaine 2005). As for producing innovators (which corresponds to franchisors that own and operate units), our model suggests that they are best off either acting as local monopolists or licensing their technology to one licensee only. Indeed, many franchisors own and operate only very few units in each of their geographic locations, supplying different local demands.",1
59.0,1.0,Review of Industrial Organization,08 March 2021,https://link.springer.com/article/10.1007/s11151-021-09812-3,An Econometric Analysis of the Brazilian Merger Policy,August 2021,Diego S. Cardoso,Mariusa M. Pitelli,Adelson M. Figueiredo,Male,Unknown,Unknown,Male,"Competition authorities play a central role in maintaining well-functioning markets. When necessary, these authorities can intervene in markets by blocking mergersFootnote 1 and by repressing anticompetitive practices, such as cartels and predatory pricing. The decision to block a merger is usually preceded by economic analysis. In many countries, these analyses follow publicly available rules, which are also known as guidelines. A consistent application of the guidelines aligns agents’ expectations, reduces uncertainty, and speeds the evaluation process (Bergman et al., 2005). The consistency of decisions also reinforces the preventive effect of antitrust policies: For instance, firms might choose to refrain from attempting a merger when consistently applied rules allow them to predict that the merger would be blocked. This paper studies the application of guidelines by the Brazilian competition authority on mergers. Using discrete choice methods, we examine which factors consistently affect the authority’s decisions and whether the authority follows the guidelines. In doing so, we also check whether factors that are not included in the guidelines play a role in these decisions. Our analysis is based on an original dataset that encompasses mergers in 334 relevant markets from 2004 to 2012. The results show that two factors that are included in the merger policy guidelines play a significant role in the authority’s decisions: post-merger market share, and adverse entry conditions. In addition, we find that market regulation—a factor that is not included in the guidelines—consistently affects these decisions. These findings are robust to alternative model specifications, to potential omitted variable bias from factors with low availability in the data, and to endogeneity concerns that are due to commissioners’ ad hoc choices of relevant market definition. Firm nationality, vertical integration between merging firms, and geographic size of the relevant market appear to play a role in some models, but their significance is not robust to alternative specifications. Quantitative analyses of merger policies can be traced back at least as far as Posner (1970). In his seminal paper, which was later updated and expanded by Gallo et al. (1985, 2000), Posner brought attention to the statistical analysis of antitrust enforcement as a tool for improving and increasing the efficiency of antitrust policy. Since then, several studies have analyzed the decisions of antitrust commissions: primarily through econometric methods. In general, researchers seek to identify the relevant variables in the decision process, as well as their relative weight and whether their observed effects align with the economic theory of antitrust policy. Table 1 summarizes the main covariates and models that are used in a collection of related papers. As the outcome of a merger appraisal is qualitative, the econometric models applied in these studies are predominantly discrete choice models. For binary outcomes—allowing or blocking a merger—the most used models were the binomial probit and the binomial logit. When the decision-making process was more complex, and the available data permitted, the response was also modeled using multinomial and ordered versions of the probit and logit. Most models in the literature included market share and indexes of market concentration. Along with the factors that are specified in each country’s legislation, studies frequently tested other variables that could influence policy decisions. Though most papers have focused on high-income countries, a more recent strand of the literature has shed light on the merger policy of emerging economies: Mexico (Avalos & De Hoyos, 2008); South Africa (Grimbeek et al., 2013); and China (Tan et al., 2014). For Brazil, in particular, Gama and Ruiz (2007) discussed the analytical methods that are used by the commissioners; the authors’ findings suggested that the lack of appropriate data management could lead to heterogeneous and lax enforcement of antitrust law. However, to our knowledge, there are no studies about the factors that statistically influence the merger policy decisions in Brazil. This paper contributes to the literature on the statistical analysis of merger policies by adding Brazil to the currently small set of emerging economies studied. Moreover, we document robust evidence of the interaction between merger and regulatory policies; this is a relationship that has been rarely analyzed in this literature so far.",1
59.0,2.0,Review of Industrial Organization,25 July 2021,https://link.springer.com/article/10.1007/s11151-021-09828-9,The 2020 Vertical Merger Guidelines,September 2021,Roger D. Blair,,,Male,Unknown,Unknown,Male,"On June 30, 2020, the Department of Justice (DOJ) and the Federal Trade Commission (FTC) replaced the 1984 Non-Horizontal Merger GuidelinesFootnote 1 with the 2020 Vertical Merger Guidelines (VMG).Footnote 2 In the years between these two enforcement policy statements, there has been an avalanche of academic literature that addressed the antitrust law and economics of vertical integration, vertical mergers, and economically equivalent vertical contracts. To one extent or another, this burgeoning literature has informed the 2020 VMG. But have the new VMG gotten it right? This Special Issue will go a long way in answering that question. Some of the contributions offer an assessment of the 2020 VMG, while others contain analyses of economic issues that were prompted by the publication of the VMG. Analyzing the competitive consequences of a vertical merger is complicated. There appears to be no change in the structure of either the upstream market or the downstream market. But a vertical merger may significantly reduce transaction costs and, ceteris paribus, thereby improve consumer welfare. A vertical merger might eliminate double marginalization, which leads to lower prices for consumers and an increase in consumer welfare. But a vertical merger may permit the newly merged firm to raise its rivals’ costs. It could also result in rivals’ being foreclosed from the market. In either event, consumers are bound to pay higher prices and experience reductions in consumer welfare. To make matters worse, there could be conflicting effects. For example, a merger that eliminates double marginalization could also result in market foreclosure. Balancing the procompetitive benefits and the anticompetitive harms may not be too difficult in theory, but may be quite elusive in practice. The articles in this Special Issue have been organized into four categories: 1. Vertical Merger Policy; 2. Empirical Insights; 3. Issues in Implementation; and 4. Remedies. This organization is a bit arbitrary, but the content of each article, rather than its location, is what really matters.",
59.0,2.0,Review of Industrial Organization,06 July 2021,https://link.springer.com/article/10.1007/s11151-021-09821-2,Competitive Harm from Vertical Mergers,September 2021,Herbert Hovenkamp,,,Male,Unknown,Unknown,Male,"The long-needed revision of the U.S. antitrust Agencies’ Vertical Merger Guidelines (VMGs) is an important achievement.Footnote 1 This essay examines them in light of the standards articulated in §7 of the Clayton Act. As enacted in 1914, §7 did not apply to vertical mergers. The statute referred to mergers that lessened competition “between” the merging firms.Footnote 2 That is the anticipated competitive threat from a horizontal merger, as well as most potential competition mergers.Footnote 3 The lessening of competition that occurs in a vertical merger is generally not between the merging firms, however, but between the post-merger firm and other firms who were not parties to the merger. In the simple vertical merger case, there was no competition between the merging firms prior to the merger. A few cases, such as Columbia Steel and Brown Shoe, were simultaneously vertical and horizontal because the parties operated in both the upstream and downstream markets.Footnote 4 An important purpose of the 1950 Clayton Act amendments was to add vertical mergers to the practices that fell within the statute. A principal motivator of the 1950 amendments was the Supreme Court’s 1948 Columbia Steel decision. That decision had refused to condemn a vertical asset acquisition under the Sherman Act, largely because of ambiguities about market definition and market shares that the Court found to be too small. The purpose of the 1950 §7 Amendments was threefold: First, it was drafted to expand the reach of the statute to vertical mergers. Second, the statute was amended so as to include both stock and asset acquisitions. Third, the new provision applied the Clayton Act’s broader “may substantially lessen competition” standard to both vertical mergers and mergers by asset acquisition.Footnote 5 The amendments were presumably intended to establish that the market share standards applied in the Columbia Steel case were too narrow. Prior to the amendments, the Supreme Court had also addressed the difference between the Sherman and Clayton Act standards of legality in another vertical case, although one that involved a contract practice rather than a merger: In Standard Stations (1949) the Court condemned exclusive dealing under §3 of the Clayton Act, which uses the same “may … substantially lessen competition” language. The Court observed that the statute was “directed to prohibiting specific practices even though not covered by the broad terms of the Sherman Act….”Footnote 6 The Court also declined to hold that the Sherman Act would condemn the restraint.Footnote 7 The clear message was that the Clayton Act’s injury language reached more broadly than the Sherman Act language in vertical cases. The sharp expansion in merger enforcement that occurred under the 1950 Amendments was actually driven less by technical changes in the language of the revised statute than by the legislative history. That became clear in the Brown Shoe decision, which examined the legislative history at some length. Brown Shoe was both horizontal and vertical. Further, it was a stock acquisition, so the horizontal portion of the merger was already covered by the original Clayton Act. Relying on Reports from both the House and the Senate, however, Brown Shoe concluded that the amendments fundamentally changed the standard of legality. The Clayton Act revisions were “intended to reach incipient monopolies and trade restraints outside the Sherman Act.”Footnote 8 The Court concluded that the “dominant theme pervading congressional consideration of the 1950 amendments was a fear of what was considered to be a rising tide of economic concentration in the American economy.”Footnote 9 The Court also noted a 1947 FTC study citing “the danger to the American economy in unchecked corporate expansions through mergers.” In addition, Brown Shoe observed, the legislative history reflected Congress’ belief in the “desirability of retaining ‘local control’ over industry and the protection of small businesses,“Footnote 10 as well as “other values” that a “trend toward concentration” threatened. Those other values were described as something other than “accelerated concentration of economic power on economic grounds.”Footnote 11 Finally, the Court observed that repeated acquisitions in an industry could have a “cumulative effect,” and that “control of the market * * * may be achieved not in a single acquisition but as the result of a series of acquisitions.”Footnote 12 One prominent antitrust economist from the period hailed that Report as representing the FTC’s increased use of economics in merger cases.Footnote 13 Then Harvard Law Professor Derek Bok gave the statute more qualified praise, but he criticized the legislative history for “the paucity of remarks having to do with the effects of concentration on prices, innovation, distribution, and efficiency.”Footnote 14 To be sure, he observed, Congress expressed a concern about the “need for preserving competition.” However, “competition appeared to possess a strong socio-political connotation which centered on the virtues of the small entrepreneur to an extent seldom duplicated in economic literature.”Footnote 15 With Brown Shoe the Supreme Court embarked on a substantial expansion of merger law—often employing rationales that did more harm than good to competition. Among these were exaggerated theories of harm as well as the perverse idea that mergers should be condemned because of efficiencies that served to harm rivals. It is important not to cast too much blame for these developments on the Supreme Court, however. First, the legislative history supported them. Second, all of the Supreme Court’s expansive decisions during this period were brought by either the Antitrust Division or the Federal Trade Commission.Footnote 16 The Court merely did what the enforcement agencies requested: condemning mergers on small markets shares that would never be challenged today, and on rationales, including the creation of efficiencies that harmed competing business or higher concentration for its own sake.Footnote 17 The Supreme Court was no more to blame than Congress and the enforcement agencies. Indeed, in cases of statutory interpretation it had a duty to follow the statute—not to make its own economic policy. Subsequently, both Harvard and Chicago School thinking pushed back at the aggressive attitudes about industrial concentration, as well as the idea that merger-induced efficiency was an affirmative harm.Footnote 18 But the Chicago School went much further. Particularly in the writings of Robert Bork, vertical practices including mergers came to be viewed as virtually always harmless.Footnote 19 These positions were heavily reflected in the 1984 Merger Guidelines, which were written during the high point of Chicago School influence on government policy. These were the most recent Guidelines to address vertical mergers prior to the 2020 Guidelines.Footnote 20 The economics writing since the 1980s has largely repudiated both the Brown Shoe view and the Bork view of vertical mergers. Today vertical mergers are regarded with less suspicion overall than are horizontal mergers. Nevertheless, they still pose competitive threats in some cases, with harm measured by realistic threats of reduced output, higher prices, or harms to innovation—precisely the things that Derek Bok had mentioned. The 2020 VMGs are a first public attempt to capture these concerns in a way that is capable of being implemented in enforcement policy. They need not be the final word. Just as the Horizontal Merger Guidelines, they will very likely go through periodic revisions as enforcers acquire greater experience. Nevertheless, they must be regarded as a very considerable improvement over any Agency or judicial policy statement in the past. The balance of this paper attempts to place some perspective on the most important features of the Guidelines’ approach to vertical mergers.",2
59.0,2.0,Review of Industrial Organization,10 August 2021,https://link.springer.com/article/10.1007/s11151-021-09824-z,The New Vertical Merger Guidelines: Muddying the Waters,September 2021,Michael A. Salinger,,,Male,Unknown,Unknown,Male,"The new United States Vertical Merger GuidelinesFootnote 1 (VMG) supersede the section on non-horizontal mergers in the U.S. Department of Justice (“DOJ”) 1984 Merger Guidelines,Footnote 2 the last merger guidelines that were issued by one of the U.S. antitrust agencies that addressed non-horizontal mergers.Footnote 3 When the DOJ issued those earlier guidelines, the dominant economic theories about vertical mergers were the single monopoly profit theoremFootnote 4 and the Cournot/Spengler models of complementary and successive monopoly.Footnote 5 The former laid out conditions under which vertical mergers are competitively neutral. In the latter, a complementary products/vertical merger results in the reduction of prices to consumers through the elimination of double marginalization (EDM).Footnote 6 A universally-acknowledged exception to the single monopoly profit theorem is the avoidance of rate regulation, and that theory was the basis for the Reagan-era DOJ decision to force the break-up of AT&T. A major deficiency in the economic theory of vertical mergers as of 1984 was that it ignored a primary reason to be concerned that vertical mergers might be anticompetitive. Steven Salop and David Scheffman provided the key insight. They coined the term and provided a model that captured the incentive to “raise rivals’ costs” (“RRC”).Footnote 7 The successive monopoly cannot capture that phenomenon because, with monopoly at both stages, there are no rivals whose costs might be raised. The so-called “post-Chicago” literature on vertical mergers that arose starting in the late 1980s demonstrated the theoretical possibility of anticompetitive vertical mergers based on static pricing incentives.Footnote 8 In those models, RRC is the mechanism that creates the potential for anticompetitive harm. In 2007, the European Commission issued non-horizontal merger guidelines.Footnote 9 As input into those guidelines, it commissioned a working paper by Jeffrey Church to review the literature on the economic theory of the competitive effects of vertical mergers.Footnote 10 The Church working paper contained an extensive review of the post-Chicago literature on vertical mergers and suggested policy implications. The EC Guidelines clearly reflect the influence of the Church Report. Until 2020, the US Agencies had not seen fit to issue new non-horizontal merger guidelines. Their failure to do so did not reflect ignorance of the post-Chicago literature on vertical mergers. A more likely explanation is that Agency officials and staff were not convinced that the post-Chicago literature provided a basis for practical policy guidance.Footnote 11 Given that the 1984 Merger Guidelines preceded the post-Chicago literature, a new set of vertical merger guidelines might seem long overdue. Before jumping to that conclusion, however, it is worth considering what the section on non-horizontal mergers in the 1984 Merger Guidelines stated. Reflecting the Chicago school influence, they did state that non-horizontal mergers are “less likely than horizontal mergers to create competitive problems,” but added “they are not invariably innocuous.”Footnote 12 They then laid out the principal theories that the DOJ might use to support a challenge to a vertical merger. Avoidance of rate regulation was one of those theories, but it was not the only one or even the one given the most prominence. Instead, most of the section is devoted to concerns about entry. First, they point out that large firms at one stage may be likely entrants—and act as a competitive constraint as long as they are perceived to be likely entrants—into an adjacent stage. They stated that a vertical merger might raise entry barriers by foreclosing entry at a single stage. They also raise the possibility that vertical integration might facilitate collusion—based on the theory that detecting deviations from collusive agreements is easier with respect to final goods than with respect to intermediate goods.Footnote 13 The biggest difference between the VMG and the section on non-horizontal mergers in the 1984 Merger Guidelines is the emphasis that the VMG place on how the static pricing incentives that are created by a vertical merger can be to raise rivals’ costs and, in turn, prices to consumers. The VMG stress that the Agencies’ review of vertical mergers resembles in important respects their review of horizontal mergers. The Horizontal Merger GuidelinesFootnote 14 focus primarily on how a horizontal merger is likely to affect static pricing incentives. The key question to ask in assessing whether the VMG signal an improvement in policy is whether the analysis of static pricing incentives should be as central to vertical merger enforcement as it is to horizontal merger enforcement. Echoing the 1984 merger guidelines, the VMG state, “While the agencies more often encounter problematic horizontal mergers than problematic vertical mergers, vertical mergers are not invariably innocuous.”Footnote 15 A natural question to ask about this statement is, “What distinguishes the relatively small number of vertical mergers that the Agencies believe pose a threat to competition from those that do not?” A clear answer to this question is necessary for the VMG to accomplish the stated goal of “assist[ing] the business community and antitrust practitioners by increasing the transparency of the analytic process underlying the Agencies’ enforcement decisions.”Footnote 16 Horizontal merger enforcement rests on what Sutton (1991) termed “robust theory.” In analyzing horizontal mergers and making their cases in court, the Agencies use a variety of models tailored to the specifics of a case. While the details of the models affect the quantitative predictions, the element that is common to all the models is the prisoner’s dilemma nature of decisions about what price to charge and how much to produce in oligopolistic markets. The standard oligopoly models taught in any undergraduate industrial economics course (and, for that matter, intermediate and even introductory microeconomics courses) capture the logic underlying horizontal merger enforcement. The same is not true of vertical mergers. To understand this point, it is useful—indeed crucial – to consider the simplest possible models in which RRC and EDM can both occur. Since the Bertrand model with differentiated products has emerged as the primary theoretical underpinning for horizontal merger enforcement, the natural extension to evaluate vertical mergers is to allow for Bertrand competition with differentiated products at one stage and some form of market power – perhaps monopoly – at the adjacent stage.Footnote 17 If one is to assume duopoly at one stage and monopoly at the other, the monopoly stage can be “upstream,” “downstream,” or complementary. The difference in the models concerns the timing of decisions.Footnote 18 In a model of an upstream monopolist selling a necessary input to two competing downstream firms, the monopolist selects its price first in the pricing game, and the duopolists simultaneously set their prices second. In a model of competing manufacturers or service providers (such as a video programming service) that sell through a monopoly multi-product distributor, the duopolists move first in the pricing game. If the stages are modeled as complementary, then all the firms choose the price(s) of their respective stage simultaneously.Footnote 19 In this article, I focus on the second of these cases.Footnote 20 As I show in a companion paper,Footnote 21 the results from the first and the third are similar.Footnote 22",3
59.0,2.0,Review of Industrial Organization,23 July 2021,https://link.springer.com/article/10.1007/s11151-021-09827-w,When Vertical is Horizontal: How Vertical Mergers Lead to Increases in “Effective Concentration”,September 2021,Serge Moresi,Steven C. Salop,,Male,Male,Unknown,Male,"It is sometimes claimed that vertical mergers are inherently different from horizontal mergers because there is no elimination of a competitor (Hoffman, 2018). It similarly is said that there is no increase in market concentration, unlike a horizontal merger.Footnote 1 In this article, we explain why both of these claims are incorrect. We show that there in an inherent loss of an indirect competitor that supported the non-merging competitors in the pre-merger world, which leads to reduced competition when there is an input foreclosure concern. We also show that it is possible to calculate an effective increase in the Herfindahl–Hirschman Index (HHI) measure of concentration for the downstream market, when the competitive concern is input foreclosure. We refer to this “proxy” measure as the “dHHI.” This increase in effective concentration is separate from any increase in post-merger concentration that might occur in the downstream market if there is foreclosure that actually reduces the market shares of foreclosed rivals and increases the market share of the merged firm. This dHHI analysis has two main uses. First, the dHHI addresses the claim sometimes made that vertical mergers are inherently different from horizontal mergers because there is no change in the market shares or concentration. The dHHI analysis conceptually demonstrates the inherent horizontal effects from a vertical merger that raises input foreclosure concerns. The impact of input foreclosure has the same effect as a partial horizontal merger (i.e., acquisition of a partial ownership interest) in the downstream market. Second, the magnitude of the calculated dHHI might be used as a rough gauge of the level of competitive concerns, much in the way that the conventional delta HHI is used in horizontal merger analysis. A higher dHHI might suggest greater competitive concerns, ceteris paribus. In these two ways, the dHHI (and associated post-merger HHI) can be used as potentially probative evidence in vertical merger matters that raise input foreclosure concerns. The focus on indirect competition and the possible role for the dHHI proxy can be illustrated by the litigation that involved the proposed acquisition of Farelogix by Sabre.Footnote 2 Sabre is a Global Distribution System (GDS) that provides a platform for travel agencies to search for and book airline flights. Farelogix provides a technology that is used by airlines to bypass a GDS and interact directly with the travel agencies. As such, Sabre and the airlines are competing for the travel agencies’ booking business, and the acquisition of Farelogix by Sabre was formally a vertical merger. However, the U.S. Department of Justice (DOJ) characterized the acquisition as a horizontal merger. In doing so, it emphasized statements by Sabre that it competes with Farelogix for providing airlines with access to travel agencies. While accepting this competition, the court rejected the DOJ’s complaint because it concluded that Sabre competes on both sides of a two-sided market—airlines and travel agencies—whereas Farelogix competes only on one side: airlines. Armed with our analysis, the DOJ alternatively could have framed the proposed acquisition as a vertical merger, but explained to the court that the merger had indirect horizontal effects because Farelogix supported competition between Sabre and the airlines in the market for booking services to travel agencies. The DOJ might have gone further and illustrated the magnitude of the effective reduction in horizontal competition by calculating dHHIs that would have been based on Farelogix’s current sales and also on estimates of its future sales to airlines absent the merger. The dHHI proxy also might be useful in the formation of safe harbors or anticompetitive presumptions for vertical mergers that raise input foreclosure or downstream output reduction concerns—perhaps in conjunction with other evidence. The Vertical Merger Guidelines (VMGs) do not suggest any safe harbor or anticompetitive presumption that is based on either shares or concentration.Footnote 3 We previously showed that the first-round incentives to engage in input foreclosure after a vertical merger by raising input prices—which we denote as the upward pricing pressure (UPP)—can be related to the analogous UPP that results from a horizontal merger. In this article, we show how the increase in the effective horizontal concentration (dHHI) from a vertical merger also can be related to these UPP measures (Moresi & Salop, 2013). We specifically derive the dHHI measure by comparing the pricing incentives and associated UPPs that are involved in two alternative types of acquisitions: (1) vertical mergers that raise unilateral input foreclosure or output reduction concerns—and the associated vertical gross upward pricing pressure index (vertical GUPPI or vGUPPI) measures; and (2) horizontal acquisitions of partial ownership interests among competitors that raise unilateral effects concerns—and the associated modified GUPPI and modified HHI measures (Asoni & Sarafidis, 2017; HMGs 2010; O’Brien & Salop, 2000). This connection between the vGUPPIs for vertical mergers and the modified HHIs (mHHIs) for horizontal partial ownership transactions demonstrates the horizontal nature of the concern that is raised by potential input foreclosure in vertical mergers and how this horizontal concern is connected to the unilateral effects concern from horizontal mergers or horizontal partial ownership transactions. The connection demonstrates that there is not an “inherent” difference in the competitive concerns—as is sometimes claimed. The impact on pricing incentives and effective concentration from input foreclosure concerns is the same as the impact of an identifiable hypothetical horizontal consolidation that involves partial ownership interests between the downstream merging firm and its potentially foreclosed rivals. The dHHI is based on the way in which the pricing incentives that arise in vertical mergers that involve unilateral input foreclosure or output reduction concerns are similar to the pricing incentives that arise from partial ownership interests among competing firms. It is derived analytically from consideration of two UPP measures—the vGUPPIs that areused to gauge unilateral input foreclosure effects, and the “modified GUPPIs” (“mGUPPIs”) that are used to gauge unilateral price effects from partial ownership interests among horizontal competitors—and the associated mHHI concentration measure. The dHHI analysis also has some intuitive properties that can make it a useful addition to the antitrust toolkit. We frame our formal analysis of input foreclosure and downstream output reduction incentives in the context of a standard vertical industry model in which the upstream firms are Bertrand competitors that sell differentiated inputs to downstream firms, and the downstream firms are Bertrand competitors that sell differentiated substitute products to consumers.Footnote 4 The vertically merged firm may have the incentive to engage in an input foreclosure strategy by raising the price of the input that is charged to one or several targeted downstream rivals. In extreme cases, the merged firm may have the incentive to raise the input price to a prohibitively high level that totally forecloses the (targeted) downstream rivals from access to its input. Such partial or total input foreclosure can be profitable to the merged firm because it can raise the costs that are faced by the downstream rivals, and hence can lead to diversion of sales from the downstream rivals to the downstream merging firm. It simultaneously can lead the downstream rivals to raise prices to consumers, which then can allow the downstream merging firm to increase its price, its market share, or some combination of the two.Footnote 5 At the outset, we want to emphasize several features of the dHHI and vGUPPI measures as well as some associated caveats and limitations: First, it is important to recognize that the dHHI measures only the increase in effective concentration in the downstream market. We do not derive a measure of the increase in effective concentration in the upstream market. Second, our formal model focuses on the effects of a vertical merger on unilateral incentives to raise downstream prices and engage in input foreclosure. It also examines only “first-round” effects. Output reduction and input foreclosure conduct by the merged firm likely also would lead to pricing effects by rival firms at either level of the vertical supply chain. Total foreclosure or price increases by the upstream merging firm may lead its competitors to respond with accommodating input price increases of their own. These price increases might be unilateral (or more strictly, multilateral) or they may be coordinated.Footnote 6 At the downstream level, price increases by the merged firm likely would induce other downstream firms to raise their own prices unilaterally even in the absence of input foreclosure. In addition, input foreclosure may raise the costs of a maverick competitor, which could facilitate downstream coordination.Footnote 7 While coordination can play a role in input foreclosure, we are not explicitly taking account of “coordinated effects” theories of harm in the formal model. The dHHI—like the vGUPPIs—does not take any of these possibilities into account. However, we will discuss the role of coordinated conduct outside the formal model. Third, we are focusing on input foreclosure—not customer foreclosure. While the analysis of customer foreclosure is analogous, it also differs in some ways. It typically involves reducing rivals’ revenues instead of or in addition to increasing rivals’ costs. The dHHI—like the vGUPPIs—is not derived here with an eye towards customer foreclosure.Footnote 8 Fourth, because we are focusing on concentration—and its possible use as a safe harbor screen or anticompetitive presumption—the dHHI does not take into account any merger-specific elimination of double marginalization (“EDM”) or other cognizable efficiencies. This is the same approach that is taken for horizontal mergers, where the delta HHI is based on pre-merger market shares and only captures the change in post-merger incentives in a very limited and imperfect way.Footnote 9 Of course, any cognizable EDM or other efficiencies would be analyzed if the merger is investigated further. The remainder of this paper is organized as follows: in Sect. 2, we show how the vertically merging firms are “indirect competitors” in the pre-merger world and how the merger similar to like a horizontal consolidation that eliminates this indirect competition. The indirect competition that we study is not the possibility that an input producer might enter the downstream market in competition with its future downstream merger partner absent the merger. Instead, we mean that the input producer supports the downstream competitors of the future downstream merger partner by selling inputs to them. In Sect. 3, we derive the dHHI to proxy for the increase in effective concentration in the downstream market and explain how it can be measured in practice. The dHHI is based on vGUPPIs, the relationship between vertical and horizontal GUPPIs, and the mHHI for horizontal acquisitions of partial ownership interests. In Sect. 4, we discuss how the dHHI can be used in practice to form a general indicator (like the delta HHI in horizontal mergers), a safe harbor, or an anticompetitive presumption. In Sect. 5, we briefly explain that the vGUPPIs themselves could be used instead of the dHHI, address some criticisms that have been made of the vGUPPI methodology in two recent papers, and derive simultaneous vGUPPIs in response. Section 6 concludes.",5
59.0,2.0,Review of Industrial Organization,26 August 2021,https://link.springer.com/article/10.1007/s11151-021-09837-8,"The Upstream Pass-Through Rate, Bargaining Power and the Magnitude of the Raising Rivals’ Costs (RRC) Effect",September 2021,William P. Rogerson,,,Male,Unknown,Unknown,Male,"The raising rivals’ costs (RRC) theory—which was originally proposed by Salop and Scheffman (1983)Footnote 1—has been one of the most significant and influential contributions of modern industrial organization theory to the analysis of the competitive effects of vertical mergers. This theory provides a simple, logically consistent economic model of pricing equilibrium in vertically related markets. It explains why a vertical merger might result in the vertically integrated firm increasing input prices to downstream rivals, or perhaps even foreclosing them completely, which may in turn harm consumers in the downstream market.Footnote 2 Reflecting the technical tools in common use at the time, the original RRC model assumed that upstream firms have all of the bargaining power in the sense that they can make take-it-or-leave-it (TIOLI) offers to downstream firms. This limited the applicability of the model, because in upstream markets it is often the case that both sides of the market are highly concentrated. It is reasonable to expect that bargaining power will be split between both sides of the market in such circumstances. In recent decades, there has been an explosion of research in bargaining models and their application to industrial organization problems.Footnote 3 These new modeling techniques can be used to create a generalized RRC theory that allows for bargaining power to be split between upstream and downstream firms. The assumption that the upstream firm can announce a TIOLI input price is replaced by the assumption that the input price is determined by the Nash Bargaining Solution (NBS) given the division of bargaining power. The case where the upstream firm has all of the bargaining power is simply a special case of the more general model. This generalized RRC theory has recently begun to be used by antitrust authorities and other government agencies in both the United States and abroad to analyze vertical mergers in cases where both sides of the upstream market are highly concentrated.Footnote 4 A straightforward intuition explains why a vertical merger may result in downstream rivals paying higher input prices in the generalized RRC model. This effect occurs because, after the merger, the vertically integrated firm now views the lost profit of its own downstream partner as an extra opportunity cost of providing the input to rival downstream firms. This opportunity cost is just as real as any production cost, and an increase in the opportunity cost has exactly the same role in affecting the vertically integrated firm’s incentives and behavior as would a similar increase in production cost. In particular, when the vertically integrated firm negotiates the input price with a downstream rival, a share of this cost increase is passed through to the downstream firm in the form of an increase in the negotiated input price. A simple formula for estimating the magnitude of the input price increase has played an important role in the two most important cases in the United States where government agencies have relied on the generalized RRC theory to guide their analysis of a vertical merger. The formula was first suggested by Murphy (2010a, 2010b) and Rogerson (2010a, 2010b, 2010c) in independent filings made to the Federal Communications Commission (FCC) when it considered the Comcast/NBCU merger. The FCC adopted the generalized RRC theory as its central theory of harm in this case and used the Murphy/Rogerson formula to provide an estimate of the harm that the merger would create. Although the FCC did not block the merger, it placed significant restrictions on the merged firm that were intended to limit Comcast/NBCU’s ability to increase the programming prices that it charged to rival distributors.Footnote 5 Subsequently, this theory became the primary theory of harm that was adopted by the U.S. Department of Justice (DOJ) and its economic expert, Carl Shapiro, when the DOJ attempted to block the AT&T/Time Warner merger; and, once again, the very simple Murphy/Rogerson formula played a central role in the case.Footnote 6 It seems very likely that some version of this formula will continue to play an important role in the regulatory evaluation of future vertical mergers.Footnote 7 As was explained above, the basic intuition for the RRC effect is that a vertical merger creates a new opportunity cost for the vertically integrated firm of providing the input to a rival downstream firm, and a share of this cost increase is passed through to the downstream firm as an increase in the negotiated input price. The formula for estimating the input price increase that results from a vertical merger reflects this basic intuition. The formula includes two sub-formulas: one for estimating the cost increase of serving rivals that is induced by a vertical merger; and one for estimating the upstream pass-through rate, which is the share of the cost increase that is passed through to the negotiated input price.Footnote 8 The estimated increase in the input price is simply equal to the product of the cost increase and the upstream pass-through rate. The division of bargaining power does not enter into the calculation of the cost increase. However, it does enter into the calculation of the upstream pass-through rate. While there is a solid foundation for the sub-formula that is used to estimate the cost increase, there is a problem with the sub-formula that is used to estimate the upstream pass-through rate. In particular, the intuition for this latter sub-formula is derived from considering a bargaining model where the buyer requires only one unit of the product and the buyer and seller bargain over the price of this single unit. In the real bargaining problem between the upstream firm and downstream firm, the downstream firm purchases multiple units of the input, and the number of units that it purchases depends on the negotiated price. The nature of the Nash Bargaining Solution (NBS) is more complex in this case, and the sub-formula for calculating the upstream pass-through rate does not reflect this extra complexity. Related to this, the Murphy/Rogerson sub-formula for estimating the upstream pass-through rate is incorrect for the special case that is considered by the original RRC theory where the upstream firm has all of the bargaining power and upstream prices are set before downstream prices. While the Murphy/Rogerson sub-formula has generally been used in situations where bargaining power appears to be somewhat evenly split between upstream and downstream firms, the fact that the formula produces an incorrect answer for the extreme case where the upstream firm has all of the bargaining power is still troubling. Rogerson (2020) has argued that the existing sub-formula for estimating the upstream pass-through rate is correct even for the case of downward sloping demand—so long as it is assumed that upstream and downstream prices are determined simultaneously; or, equivalently, that upstream prices are determined before downstream prices but that firms ignore the effect of changes in the upstream price on the downstream price when they negotiate the upstream price. However, this is not necessarily an appealing assumption, and at a minimum, is a non-standard assumption in this type of economic model.Footnote 9 The standard assumption is that the upstream price is determined before the downstream price and that parties that negotiate the upstream price take into account the effect that changes in the upstream price will have on the downstream price.Footnote 10 This paper examines more closely the underlying factors that determine the upstream pass-through rate when the NBS determines the negotiated input price—both for the case where upstream and downstream prices are set sequentially and for the case where they are set simultaneously. When prices are set sequentially, this paper proposes a new simple and intuitive sub-formula for approximating the upstream pass-through rate that is very intuitive. The new sub-formula produces a higher estimated upstream pass-through rate than does the existing sub-formula. The intuition for this result is straightforward. The negotiated input price is affected both by the value of the lowest input price that the upstream firm would be willing to accept and the value of the input price that would maximize the upstream firm’s profit. An increase in the upstream firm’s cost causes both of these values to increase, and both changes generate upward pressure on the negotiated input price. The existing formula only takes account of the impact of a cost increase on the minimum price that the upstream firm would be willing to accept and thus underestimates the total effect.Footnote 11 When prices are set simultaneously, this paper provides a qualification to Rogerson’s (2020) earlier result that the existing sub-formula is correct for this case. The qualification is that the existing sub-formula provides a partial-equilibrium calculation of the upstream pass-through rate for this case. However, it ignores the equilibrium feedback effect from the change in downstream price that is caused by the change in the negotiated input price. This equilibrium feedback effect amplifies the partial equilibrium effect. The correct sub-formula for calculating the upstream pass-through rate that takes this equilibrium feedback effect into account is also provided. Both new sub-formulas for estimating the upstream pass-through rate generate larger estimates than does the existing sub-formula. The difference can be significant. Furthermore, since the estimated magnitude of the input price increase is proportional to the estimated upstream pass-through rate, significant percentage changes in the estimated upstream pass-through rate result in equally significant percentage changes in the estimated input price increase. In cases where the generalized RRC theory has played a major role in the evaluation of a vertical merger, government agencies have generally determined that bargaining power is relatively evenly split between upstream and downstream firms.Footnote 12 For the case when bargaining power is evenly split and downstream demand is linear, the existing sub-formula yields an estimated upstream pass-through rate of ½. The new sub-formula for estimating the upstream pass-through rate when prices are sequential yields an upstream pass-through rate of 3/4. The new formula for estimating the upstream pass-through rate when prices are simultaneous, but that takes equilibrium feedback effects into account, yields an upstream pass-through rate of 2/3. Papers in the relevant literature have been discussed above, with the exception of Moresi and Salop (2013).Footnote 13 Moresi and Salop (2013) provides a formula for estimating the magnitude of the increase in the input price that is charged to rival downstream firms that follows the same basic approach that was originally suggested by Murphy (2010a, 2010b) and Rogerson (2010a, 2010b, 2010c): It provides two sub-formulas: one for estimating the cost increase of serving rivals induced by the vertical merger and one for estimating the upstream pass-through rate. Its estimate of the input price increase is the product of these two terms. However, Moresi and Salop (2013) restricts itself to considering the case that is considered in the original RRC model, where the upstream firm has all of the bargaining power and is able to make TIOLI offers to downstream firms. It also assumes that prices are set sequentially. The sub-formula it uses to estimate the cost increase is the same as the Murphy/Rogerson sub-formula. Bargaining theory is not needed to calculate the upstream pass-through rate when the upstream firm is able to make TIOLI offers to downstream firms. The upstream pass-through rate is simply equal to the pass-through rate of the downstream firm’s derived demand curve for the input. Moresi and Salop (2013) refers to its estimates as vertical GUPPIs or vGUPPIs. The estimated cost increase is referred to as the “vGUPPI for the upstream merging partner’s price” and is denoted by vGUPPIu. The estimated input price increase—which is obtained by multiplying the estimated cost increase by the estimated upstream pass-through rate—is referred to as the “implied vGUPPI for the foreclosed rival’s price” and is denoted by vGUPPIr. It was noted above that the Murphy/Rogerson sub-formula for estimating the upstream pass-through rate is not correct for the case where prices are set sequentially. The fact that the formula is not correct when prices are set sequentially is most apparent for the case when the upstream firm has all of the bargaining power. In this case, the correct upstream pass-through rate is the pass-through rate of the derived demand curve as noted by Moresi and Salop (2013). The Murphy/Rogerson formula yields an upstream pass-through rate of zero for this case.Footnote 14 The new formula that is suggested by this paper for estimating the upstream pass-through rate when prices are set sequentially agrees with the Moresi/Salop sub-formula for the case when the upstream firm has all of the bargaining power. Thus the new formula for estimating the magnitude of the RRC effect for the case where prices are set sequentially suggested by this paper is a generalization of the Moresi/Salop formula. The paper is organized as follows: Sect. 2 briefly describes the existing Murphy/Rogerson formula for estimating the increase in the input price that is charged to rivals induced by a vertical merger. It describes the sub-formulas for estimating both the cost increase and the upstream pass-through rate, and also explains the intuition that underlies each sub-formula. Section 3 presents the model where prices are set sequentially. Section 4 analyzes the determinants of the upstream pass-through rate in this model and presents the suggested new sub-formula for calculating the upstream pass-through rate for this case. Section 5 presents the alternate model where prices are set simultaneously. Section 6 analyzes the determinants of the upstream pass-through rate in this model. It shows that the Murphy/Rogerson sub-formula is correct subject to the qualification that it ignores equilibrium feedback effects, and provides the fully correct sub-formula that takes equilibrium feedback effects into account. Section 7 draws a brief conclusion.",1
59.0,2.0,Review of Industrial Organization,17 June 2021,https://link.springer.com/article/10.1007/s11151-021-09816-z,A Canadian Perspective on Vertical Merger Policy and Guidelines,September 2021,Thomas W. Ross,Ralph A. Winter,,Male,Male,Unknown,Male,"This paper offers a Canadian perspective on vertical merger law and guidelines, and on developments in the economic foundations that underlie the recent U.S. vertical merger guidelines.Footnote 1 The issuance of new U.S. guidelines for vertical mergers offers an opportunity to review the state of guidance in Canada in the same area of competition policy. It also offers a chance for a comparative review of policy in the United States from the perspective of a competition law that has very different foundations. In comparing Canadian and U.S. guidelines and policy we focus on a particular area—the theories of harm—since this area has changed the most from the previous guidelines on vertical mergers. The theories in the new guidelines include “raising rivals’ costs”, and foreclosure in particular, as well as a general reduction in emphasis on the presumption that vertical mergers are procompetitive. We discuss the extent to which the same theories have influenced Canadian competition policy. Canadian law on mergers in general differs sharply from U.S. law. U.S. antitrust law has essentially a consumer focus. In the case of a potentially anticompetitive merger, efficiencies must be strong enough to offset any anticompetitive impact of a merger on consumers. The criterion for mergers in Canada on the other hand balances consumer surplus and producer surplus, and in many circumstances the criterion is simply total surplus. In a case concluded in 2003—Superior PropaneFootnote 2—the Canadian Competition Tribunal accepted evidence that a merger would increase prices by 8 percent yet allowed the merger to proceed because the reduction in consumer surplus was not enough to offset the gain in profits resulting from increased efficiencies. The Canadian law differs as well in the allocation of the burden of proof between the plaintiff and the defendant in a merger case. While the plaintiff (the government) bears the initial burden of providing evidence of a lessening or prevention of competition as in the U.S., the government’s burden in Canada is stronger. The Canadian Supreme Court, in Tervita—one of only two merger cases to have reached the Supreme Court—ruled that the government has the burden of providing quantitative evidence of a lessening of competition whenever quantification is possible. Both of these differences bring Canadian merger law, in principle, close to a model in which a merger is assessed on the basis of quantitative estimates of total surplus. The common law, specifically the common law interpretation of the Canadian statute on competition policy, has developed in cases involving horizontal mergers. But the statute (sections 92 to 94 of the Canadian Competition Act) applies to vertical as well as horizontal mergers. The formal law has not been applied to vertical merger cases in Canada because no vertical merger case has been litigated; the Commissioner of Competition and prospective merger parties negotiate settlements in potentially anticompetitive mergers in the shadow of the law. As in the U.S., which has litigated only one vertical merger in the last 50 years (AT&T-Time Warner), guidelines as to the competition policy agencies’ approach are essential in understanding negotiations or rulings from authorities even for mergers that are not expected to reach the court. While we can take the new U.S. guidelines on vertical mergers as an outline of U.S. policy in the area, no guidelines dedicated to vertical mergers have been issued in Canada. Nor, as noted, has a vertical merger case been brought before the Canadian Competition Tribunal. Brief sections of the Merger Enforcement Guidelines have been dedicated to non-horizontal mergers. We take these parts of the Canadian Guidelines as well as consent agreements and other opinions that have been communicated by the Competition Bureau as conveying the Canadian policy on vertical mergers. These—plus aspects of cases on horizontal mergers that interpret the general merger sections of the Canadian competition law statutes—form the basis for our outline of the Canadian policy. We begin with a brief outline of the changes that have been integrated in the new U.S. Vertical Merger Guidelines; we then turn to the Canadian guidelines and vertical merger policy.",2
59.0,2.0,Review of Industrial Organization,19 August 2021,https://link.springer.com/article/10.1007/s11151-021-09831-0,Presumptions in Vertical Mergers: The Role of Evidence,September 2021,Francine Lafontaine,Margaret E. Slade,,Female,Female,Unknown,Female,"High-profile vertical mergers such as the acquisition of Ticketmaster by LiveNation, the CVS/Aetna merger, and the merger of AT&T and Time Warner—as well as the growth of large technology companies—have generated renewed interest in vertical merger issues. Moreover, the appropriate treatment of such mergers has generated heated debates in academic and policy circles. With horizontal mergers, which involve substitute products, economic theory is relatively unambiguous in predicting that, in oligopolistic markets and in the absence of offsetting efficiencies, due to unilateral (or possibly coordinated) effects, higher prices are likely to result from a reduction in the number of competitors. In contrast, vertical mergers, which involve complements, are often thought to be benign. From a theoretical perspective, there is not a direct expectation that vertical mergers will lead to higher prices for consumers. Nevertheless, vertical mergers in imperfectly competitive industries almost always involve a tradeoff between potential efficiencies—which include the lower transaction costs and better aligned incentives that are emphasized in the organizational economics literature as well as the elimination of double marginalization—and potential competitive harm—which can be due to, for example, foreclosure or the elimination of potential entrants. The antitrust treatment of vertical mergers in the U.S. has changed considerably over time. In 1962, the Supreme Court prohibited a vertical merger between Brown Shoe (the fourth largest shoe manufacturer with a 4% share, and third largest in retail sales of shoes) and Kinney (the largest retailer, with a 1 to 2 percent share, and the twelfth largest manufacturer).Footnote 1 The argument that was used by the Court was mostly about rival access: “The primary vice of a vertical merger or other arrangement tying a customer to a supplier is that, by foreclosing the competitors of either party from a segment of the market otherwise open to them, the arrangement may act as a “clog on competition,” which “deprive(s) ...rivals of a fair opportunity to compete.”Footnote 2 This view was reflected in the Department of Justice (DOJ) 1968 Merger Guidelines, which specified that a vertical merger could be challenged if the supplier had a 10 percent market share and the buyer accounted for 6 percent of upstream demand. In contrast, in the late 1970s and through the 1980s, U.S. courts moved towards more of a consumer welfare focus and began to consider the potential efficiencies associated with vertical arrangements and mergers. Compared to the 1960s, U.S. antitrust enforcement was much more limited through the 1980s and policy towards vertical mergers—as reflected in the 1982 and then 1984 merger guidelines—moved away from explicit concerns of access and foreclosure.Footnote 3 Starting with the development of theoretical models of exclusion, entry deterrence, foreclosure, and raising rivals’ costs in the late 1980s and early 1990s, antitrust practitioners began to question again the proper treatment of vertical mergers and restraints. Moreover, after some years, the new theories of vertical mergers became embedded in new guidelines. In particular, the EU issued its 2008 Non–Horizontal Merger Guidelines. And last year, more than 25 years after the DOJ put forward the 1984 Non–Horizontal Guidelines, the DOJ and Federal Trade Commission (FTC) produced Vertical Merger Guidelines (VMG) that supersede those of 1984.Footnote 4 These new Guidelines were the result of increased questioning with regard to the more lenient treatment of vertical mergers, and have themselves led to further heated discussions about the consequences of such mergers among academics, regulators, and consultants. In this paper, we focus on the role of presumptions and likelihoods in vertical merger analysis and guidelines. In particular, we discuss the role that statistical evidence should play in establishing presumptions. However, our analysis is more general and includes a discussion of the sort of evidence that can guide conclusions with respect to the consequences of vertical mergers.",6
59.0,2.0,Review of Industrial Organization,11 August 2021,https://link.springer.com/article/10.1007/s11151-021-09832-z,Evaluating the Evidence on Vertical Mergers,September 2021,Marissa Beck,Fiona Scott Morton,,Female,Female,Unknown,Female,"The recent update by the U.S. Department of Justice and Federal Trade Commission to the Vertical Merger Guidelines has intensified the debate with respect to vertical merger enforcement,Footnote 1 with some commenters asserting that vertical mergers are relatively harmless. These arguments often rely heavily on surveys of the empirical economic literature as justification for a procompetitive presumption for vertical mergers (e.g., Lipsky et al., 2020; Wong-Ervin, 2019). For example, Wong-Ervin (2019, p. 1) states: “The generally accepted belief underlying modern antitrust analysis of vertical mergers … has been that they are generally procompetitive or neutral. This belief is supported by a significant body of empirical evidence.” Similarly, Wright et al. (2020) conclude: “Thus, the modern antitrust approach to vertical mergers, as reflected in the antitrust literature, should reflect the empirical reality that vertical relationships are generally procompetitive or neutral.” O’Brien (2008, p. 76) says: “With few exceptions, the literature does not support the view that [vertical] practices are used for anticompetitive reasons.” Even if in practice we observe many benign and procompetitive vertical mergers, the claims of supporting empirical evidence in these quotations are simply incorrect. We demonstrate below that the empirical evidence that is evaluated in these articles does not show that vertical mergers are generally procompetitive—or generally anticompetitive. In our view the economic literature demonstrates a variety of effects of vertical integration—including foreclosure and efficiencies—that justify examining vertical transactions on their merits rather than making general assumptions about their competitive effects. First, the assertion that vertical mergers are “generally” benign requires some notion of a population: Which group of mergers do the authors consider, and what proportion of that group is benign? There is substantial heterogeneity in structure and competitive effects across transactions and a lack of empirical information on the prevalence of each type. These issues are not addressed, as far as we know, by commenters who make the claim that vertical mergers are “generally procompetitive.” We readily agree that many vertical mergers are harmless or procompetitive, but that is a far weaker statement than presuming that all or even most vertical mergers benefit competition regardless of market structure. Second, the quotations above give the impression that there are many academic studies that have evaluated the welfare effects of vertical mergers and that the vast majority find that mergers increase social welfare. This is not the case, as we discuss below. In this paper, we review two frequently cited surveys of empirical evidence on vertical integration (Cooper et al., 2005; Lafontaine & Slade, 2007), as well as more recent studies that are not included in those surveys, to determine the extent to which they find that the vertical integration they study is procompetitive or anticompetitive. Upon careful inspection, the evidence that they provide as to the change in welfare that is due to vertical mergers is decidedly mixed. Perhaps more importantly, taken as a whole, these studies do not provide evidence for the proposition that all or most vertical mergers are good for consumers. In our review of the literature, we find that—due to the questions that are posed by the authors or the tools that are used to address the authors’ hypotheses—many studies cannot determine the net effect of the vertical integration on welfare. Even if we set aside these methodological issues, the findings are mixed: For example, of the 29 more recent studies that we review, 14 find some evidence of harm to consumers or competition from vertical integration; and 14 find some evidence of benefits from vertical integration. We do not view these results as providing any support for the proposition that vertical mergers are usually procompetitive, nor that they are usually anticompetitive. Instead, the effects of a vertical merger will depend on the specifics of the transaction and markets at issue; and the effects are worth carefully investigating when the transaction and market characteristics indicate a potential for harms to outweigh benefits. Before we discuss the literature, it is important to make clear that a survey of the empirical studies on vertical integration does not provide an unbiased assessment for determining, as a matter of policy, whether vertical mergers in general should be presumed to be procompetitive or anticompetitive: First, the ability to conduct an empirical study depends critically on the availability of data, so the literature tends to be concentrated on studying a few industries where good data are available. These industries are often ones that are relatively competitive—e.g., fast food—which may make the findings hard to apply in more concentrated markets; or these industries have complex structures and regulations that may make generalizations to other industries difficult: e.g., cable television or healthcare. Second, each study attempts to test a particular hypothesis or factor of interest to its author(s), and often that hypothesis is not whether social welfare increased or decreased. So, while these studies shed light on particular incentives or effects of vertical integration, and in fact do provide evidence that both harms and efficiencies are occurring, they do not provide an unbiased sample of welfare effects that can be used in policy discussions. Finally, the extent of vertical integration in particular industries and the mergers that have occurred—and are therefore available to be studied—are not exogenous. The transactions (or business forms) that are included in an empirical study are influenced by the enforcement policy at the time that they were undertaken (or created). We would expect a different enforcement regime to generate a different set of vertical transactions. For example, suppose that current antitrust enforcement policy deters the worst cases of anticompetitive conduct, so that consummated mergers are comprised of slightly anticompetitive as well as procompetitive transactions. An empirical study of actual mergers would tend to find benefits from vertical integration. But this finding would significantly underestimate the harm that would occur if more lenient antitrust rules permitted the more anticompetitive transactions to be carried out (see, e.g., Baker, 2015, pp. 19–22). Retrospective studies without a model of the choice to merge cannot be used to justify a change in enforcement that would be expected to alter the number and type of vertical mergers. The general lack of attention to the endogeneity of transactions when applying the results of the empirical literature on vertical mergers to proposed policy is regrettable.Footnote 2 While the notion of equilibrium is sophisticated to be sure, it is a fundamental concept in the field of economics, and therefore should be incorporated into the analysis of economist authors who contribute to policy in the antitrust area.",7
59.0,2.0,Review of Industrial Organization,19 July 2021,https://link.springer.com/article/10.1007/s11151-021-09826-x,Vertical Mergers and Input Foreclosure Lessons from the AT&T/Time Warner Case,September 2021,Carl Shapiro,,,Male,Unknown,Unknown,Male,"The 2020 Vertical Merger Guidelines (“2020 Guidelines” or VMGs) are a major improvement over the 1984 Non-Horizontal Merger Guidelines that they replaced, which had become a “dead letter.” The topic that forms the centerpiece of the 2020 Guidelines—“Foreclosure and Raising Rivals’ Costs” (Section 4a), which is the most common theory of harm that has been explored by the U.S. Department of Justice (DOJ) and the Federal Trade Commission (FTC) in recent years in vertical merger cases—was entirely absent from the 1984 Guidelines. A large majority of the enforcement actions that are highlighted in the FTC’s Commentary on Vertical Merger Enforcement involve foreclosure and raising rivals’ costs. See Federal Trade Commission (2020). This article offers a practical guide to analyzing vertical mergers that is based on the approach to input foreclosure and raising rivals’ costs that is described in the 2020 Vertical Merger Guidelines.Footnote 1 The step-by-step analysis that is described here draws lessons from how that theory of harm played out in the lone vertical merger case that has been litigated by the antitrust agencies in recent decades: the DOJ’s unsuccessful challenge to the merger between AT&T and Time Warner.Footnote 2 I testified as the DOJ’s economic expert in that case.Footnote 3 The approach taken to input foreclosure in the 2020 Guidelines shares much in common with the approach that I took in the AT&T/Time Warner case. Inasmuch as that approach was roundly rejected by Senior Judge Leon, and his decision was upheld on appeal, that experience must serve as a warning about the difficulties that the antitrust agencies will face in future challenges to vertical mergers that are based on this core theory of harm. Of course, the analysis that was presented in the AT&T/Time Warner case was highly fact-specific, and the evidence in another case may prove to be much more favorable to the government. Still, the AT&T/Time Warner case can teach us a great deal about how to structure an input foreclosure inquiry to obtain the most accurate results and how best to present those results in court when necessary. The AT&T/Time Warner case also reveals a number of shortcomings of the 2020 Vertical Merger Guidelines.",5
59.0,2.0,Review of Industrial Organization,19 July 2021,https://link.springer.com/article/10.1007/s11151-021-09825-y,"Successive Monopoly, Bilateral Monopoly and Vertical Mergers",September 2021,Tirza J. Angerhofer,Roger D. Blair,,Female,Male,Unknown,Mix,,
59.0,2.0,Review of Industrial Organization,12 August 2021,https://link.springer.com/article/10.1007/s11151-021-09833-y,Vertical Mergers in a Model of Upstream Monopoly and Incomplete Information,September 2021,Serge Moresi,David Reitman,Yianis Sarafidis,Male,Male,Unknown,Male,"The analysis of a vertical merger by an upstream monopolist has a long history and a prominent role in antitrust analysis. Some important themes and developments include: The seminal tying model of Burstein (1960)—which was motivated by Bowman (1957)—showed that a requirement by a monopolist in one product that buyers also purchase a second product that is currently produced by the monopolist and other (perfectly competitive) firms that sell perfect substitute products with constant marginal cost would have no effect on prices, output, or profits. This result became the famous “single monopoly profit” theorem, as first noted by Bowman (1957) and then popularized by Robert Bork (1978) as a reason to have very permissive antitrust policy towards vertical mergers and other vertical restraints. Cournot (1838) showed that the merger of two complementary products monopolists would lead to lower prices—a result that was applied to vertical mergers by Spengler (1950). This result became the famous “elimination of double marginalization” efficiency benefit of vertical mergers that involve markets where prices exceed marginal costs at both levels. When an upstream monopolist that uses linear prices for the input that it supplies to a downstream oligopoly merges with one of the downstream firms, the merged firm benefits from the elimination of double marginalization but may foreclose downstream rivals, completely or partially, from access to the input. Lu et al. (2007) showed that foreclosure does not occur and the merger is procompetitive if downstream firms face linear demand functions that satisfy Slutsky symmetry. More recently, Das Varma and De Stefano (2020) and Domnenko and Sibley (2020) have studied how partial foreclosure (or raising rivals’ costs) can occur if downstream firms face logit demand. They showed that the unintegrated firm often increases its price, which leads to harm to its pre-merger customers who do not switch to the merged firm, and to some that do switch. Das Varma and De Stefano (2020) and Moresi (2020) showed that a vertical merger can reduce consumer surplus and thus be anticompetitive if downstream firms have some bargaining power. In a model with non-linear pricing, Hart and Tirole (1990) showed how a vertical merger could solve the upstream monopolist’s “commitment” or “opportunism” problem, and lead to lower output and higher prices. Moresi and Schwartz (2021) showed that complete or partial foreclosure can occur and the merger can be anticompetitive, if downstream firms can substitute (imperfectly) the input of the monopolist with an input that is supplied by a fringe of competitive producers. When there is not an upstream monopolist, vertical mergers may lead to higher profits and higher prices. Ordover et al. (1990) showed that a vertical merger by one upstream duopolist can lead to higher downstream prices by leading the other input duopolist to respond by raising its (linear) input price. Chen (2001) showed that the competitive effects of a vertical merger depend on the cost of switching suppliers and the degree of downstream product differentiation. Rey and Vergé (2020) considered a model with endogenous supply relationships, nonlinear pricing, and secret contracts, and showed that a vertical merger reduces consumer welfare in most cases. All these models assume that firms have complete information about the production costs of other firms. There is no private information. In this paper, we examine the role of private information on the effect of vertical mergers when there is an upstream monopolist. We show that a vertical merger can improve the information that is available to an upstream monopolist because, after the merger, the monopolist can observe the cost of its downstream merger partner. In our model, downstream costs are independent, and thus the merger does not reveal any information about the cost of the downstream rival. Because the input monopolist does not have complete information, it cannot implement the monopoly outcome: The expected pre-merger equilibrium price of the downstream product is lower than the monopoly price. After a vertical merger, the equilibrium price increases to the monopoly price, and thus the merger leads to consumer harm. However, the merged firm cannot extract all of the potential profit: The merger causes production inefficiency when the downstream rival has a small cost advantage, and the downstream rival earns an information rent when it has a large cost advantage. To demonstrate these results most simply, we analyze a model in which a buyer—who buys from one of two downstream perfect competitors—purchases one unit if the price does not exceed the buyer’s willingness-to-pay, which we refer to as the buyer’s “budget”. Thus, demand is perfectly inelastic. The output of the upstream monopolist is an input for the downstream firms, which use that input with other inputs in 1-to-1 fixed proportions to produce the two downstream products. These downstream products are perfect substitutes for one another. Except for private information, these are the standard assumptions that are used to establish the single monopoly profit result. We assume that the downstream firms purchase the input from the upstream monopolist at prices that are set by the monopolist; the downstream firms then compete for the sale to the buyer through an open-bid descending-price auction.Footnote 1 We model the incomplete information by assuming that the downstream firms each draw their costs independently from a common distribution, and their draws are private information. For simplicity, we assume that the buyer does not use a reserve price and thus starts the descending-price auction with an initial price equal to her budget, and that the input monopolist knows her budget when it sets the input price.Footnote 2 In this structure, if the downstream firms’ costs were public information, the single-monopoly-profit result would hold. Absent vertical integration, the upstream monopolist would set an input price such that the total cost of the most efficient of the two downstream firms would equal the buyer’s budget. The downstream firms would earn zero profits; all the profits would accrue to the monopolist. The buyer would have zero surplus. Thus, a vertical merger would have no impact on the market prices and welfare. The vertically integrated monopolist would not foreclose the downstream rival: When the rival has lower costs, it is more efficient; the monopolist makes more profit by selling to the rival, letting the rival win the auction, and capturing all rents through the input price. However, the results change dramatically when the downstream firms’ costs are private information. In the pre-merger world, the upstream monopolist is not able to set perfectly discriminating input prices. In this structure, the upstream firm sets an input price to maximize its expected profits. If the downstream firms both draw high costs, then once the input price is included, neither will be able to bid a price at or below the buyer’s budget, and so no transaction will occur. If instead both downstream firms draw low costs, they both will bid below the buyer’s budget, and the buyer will obtain some surplus. The vertical merger changes the structure by providing the upstream monopolist with knowledge of the costs of its merger partner. This allows the monopolist to raise the input price to the downstream rival when the monopolist knows that the merger partner has a low cost, and conversely to reduce the input price when the merger partner has a high cost. As it turns out, the buyer always pays the monopoly price whenever the auction generates a sale. However, the merged firm does not obtain all the monopoly profit because the downstream rival still wins the auction and earns some profits when it has a relatively large cost advantage. The remainder of this paper is organized as follows: Sect. 2 describes the model, and Sect. 3 analyzes the pre-merger equilibrium. Section 4 analyzes the post-merger equilibrium, and Sect. 5 discusses some possible extensions of the model. Section 6 concludes with some implications for vertical merger policy. The “Appendix” contains the proofs of Propositions 2 and 3.",2
59.0,2.0,Review of Industrial Organization,23 July 2021,https://link.springer.com/article/10.1007/s11151-021-09823-0,Diagnosing Anticompetitive Effects of Vertical Integration by Multiproduct Firms,September 2021,Fernando Luco,Guillermo Marshall,,Male,Male,Unknown,Male,"The 2020 Vertical Merger Guidelines characterize vertical mergers as transactions that “often benefit consumers through the elimination of double marginalization, which tends to lessen the risks of competitive harm”.Footnote 1 While this assumption seems intuitive, a small body of research suggests that it may fail to hold when the integrated firm is a multiproduct firm (Salinger,, 1991; Luco & Marshall, 2020). Given that vertical mergers in multiproduct industries are common, we complement existing work and investigate when such an assumption can be made in vertical transactions that involve multiproduct firms.Footnote 2 Why can we not generally assume an elimination of double margins to be procompetitive in multiproduct industries? Consider the case when a subset of the products that are sold by a firm is exposed to an elimination of double margins. This has two effects on pricing incentives (Salinger, 1991): First, it reduces the downstream firm’s perceived cost of selling the products with eliminated double margins (integrated products, henceforth), which thereby induces the firm to set lower prices for these goods (efficiency effect). Second, it makes integrated products more profitable to sell, which creates an incentive to increase the prices of unintegrated substitute products so as to sell more units of the integrated ones (anticompetitive effect). Salinger (1991) shows examples where the anticompetitive effect may dominate the efficiency effect and lead to a loss in consumer welfare caused by vertical integration. Empirical evidence in Luco & Marshall (2020) from vertical transactions in the US carbonated-beverage industry suggest that the anticompetitive effect can be as large as the efficiency effect (in absolute value). Combined, these works suggest that the elimination of double margins that can accompany vertical integration cannot be blindly assumed to be procompetitive in multiproduct industries. Our contributions are twofold: First, we provide a detailed discussion of the effect of an elimination of double margins on pricing incentives in multiproduct industries. Second, we present a model of a vertical supply chain to analyze equilibrium effects of vertical integration. We use our analysis to shed light on when the anticompetitive effects that are caused by an elimination of double margins are more likely to arise. In particular, we discuss how diversion ratios—a tool that is commonly used in merger evaluation—can be used to diagnose whether vertical integration will cause an increase in the prices of unintegrated products.Footnote 3 Because computing diversion ratios requires only demand estimates (though other data such as customer surveys could be used), this approach to screening proposed transactions is particularly useful as it saves the researcher and relevant antitrust agencies from having to model the entire vertical chain to predict price changes that are caused by a vertical merger.Footnote 4 The paper is organized as follows: Sect. 2 presents an economic discussion of the impact of vertical integration on the pricing incentives of a multiproduct firm. We introduce our model in Sects. 3, and 4 presents the equilibrium analysis of vertical integration as well as our discussion of diversion rates as a diagnostic tool. Section 5 concludes,",1
59.0,2.0,Review of Industrial Organization,12 August 2021,https://link.springer.com/article/10.1007/s11151-021-09835-w,Vertical Merger Policy: Special Considerations in Regulated Industries,September 2021,David E. M. Sappington,Dennis L. Weisman,,Male,Male,Unknown,Male,"The Vertical Merger Guidelines (VMGs) “outline the principal analytical techniques, practices and enforcement policy” of the U.S. antitrust agenciesFootnote 1 “with respect to vertical mergers and acquisitions” (U.S. DOJ & FTC, 2020, p. \(1\)). By design, the VMGs provide generic guidance and describe central considerations that are relevant across a broad array of settings. The purpose of this article is to analyze special considerations that can arise when vertical mergers take place in industries that are subject to economic regulation (hereafter, “regulated industries”). We focus on four distinct types of such special considerations: First, regulation can affect the distribution of the benefits of a vertical merger, and thereby affect the merits of the merger. Second, regulation can affect the type of vertical mergers that arise. In particular, regulation can discourage welfare-enhancing mergers or encourage mergers that reduce welfare. Third, regulation can affect the nature and extent of post-merger industry oversight. Depending upon the prevailing circumstances, regulation can enhance, diminish, or bias post-merger oversight. Fourth, regulation can affect the post-merger incentives of the merged entities. Regulation can either encourage or discourage undesirable post-merger incentives, and thereby affect the merits of a proposed vertical merger. These special considerations imply that when an antitrust agency assesses the merits of a proposed vertical merger in a regulated industry, the agency must carefully consider the resources and incentives of regulators. When regulators have substantial ability and incentive to deter post-merger anticompetitive behavior, vertical mergers that typically would be judged to reduce welfare in unregulated settings might conceivably enhance welfare in regulated settings. Conversely, when regulators have limited ability or incentive to preclude anticompetitive behavior, vertical mergers that normally would be expected to enhance welfare in unregulated industries might reduce welfare in regulated industries. Our discussion of these issues proceeds as follows: Sect. 2 explains how regulation can affect the merits of a merger by affecting the distribution of merger-induced benefits. Section 3 notes how regulation can affect the type of vertical mergers that arise and discusses the implications for merger policy. Section 4 reviews how regulation can affect the nature and extent of post-merger industry oversight and thereby affect the welfare-maximizing merger policy. Section 5 explains how regulation can affect the post-merger incentives of the merging entities and can thereby affect both the merits of a proposed vertical merger and the appropriate focus of post-merger oversight. Section 6 concludes, in part by emphasizing the need to consider carefully the resources and incentives of regulators when assessing the merits of a vertical merger in a regulated industry.",2
59.0,2.0,Review of Industrial Organization,04 August 2021,https://link.springer.com/article/10.1007/s11151-021-09829-8,The Welfare Effects of Vertical Mergers and their Remedies,September 2021,John W. Mayo,Mark Whitener,,Male,Male,Unknown,Male,"Recently, antitrust policy has emerged from a quiet and cloistered discussion—one largely confined to economists and antitrust lawyers—to a more visible and lively conversation that has extended well beyond its historical participants. Topics of discussion range from the merits of specific enforcement policies and statutory language to foundational questions with regard to the objectives of antitrust itself. Among the many threads of discussion to have emerged is the issue of vertical merger policy, owing in part, perhaps, to: the ongoing prevalence of vertical mergers in the economy; the fact that such mergers have typically attracted fewer antitrust concerns than horizontal mergers; and the generally less settled state of economic theories of harm for vertical mergers. The most visible manifestation of this emerging focus on vertical mergers is the publication in June 2020 of a set of Vertical Merger Guidelines (VMGs) by the U.S. Department of Justice (DOJ) and the Federal Trade commission (FTC) (collectively, “the Agencies”).Footnote 1 These Guidelines—which are akin to the Horizontal Merger Guidelines—provide guidance on the analytical framework that the Agencies use to evaluate vertical mergers for potential enforcement action. The VMGs lean heavily on the principles, methods and processes that are found in the more battle-tested Horizontal Merger Guidelines. The VMGs also, however, introduce several methods and processes for evaluating vertical mergers that the Agencies have employed in practice but have not previously described in enforcement guidelines. Of particular note, the VMGs: (1) identify theories of harm that arise in vertical mergers that are not typically present in horizontal merger cases; and (2) recognize efficiencies such as the elimination of double marginalization that are absent in the consideration of horizontal mergers. The articulation of these differences provides important input for firms as they consider how antitrust enforcement will be conducted as the Agencies evaluate proposed vertical mergers. The specification of these differences also naturally provokes a renewed focus on another key element of antitrust enforcement that is directed toward vertical mergers: the remedies that might be appropriate in the event that an as-proposed vertical merger is judged by the Agencies to violate Sect. 7 of the Clayton Act. This latter issue is especially salient as it is well known that the vast majority of mergers that are subject to an Agency enforcement action are resolved through negotiated remedies rather than through a fully-litigated trial. For vertical merger cases, this tendency is particularly pronounced. Remedies that are agreed to by the Agencies and the merging parties are likely to continue to be the primary “landing spot” for most mergers that are covered by the VMGs.Footnote 2 Despite the importance of remedies in vertical merger cases, the VMGs are silent on the issue of remedies. While the FTC has not issued merger remedies guidance since the VMGs were issued, the DOJ released a new merger remedies manual, which states that structural remedies are “strongly preferred” in merger cases, including vertical mergers, and describes a number of concerns with conduct remedies. As with previous DOJ merger policy statements, however, the Manual acknowledges that conduct relief may be appropriate when it is necessary to preserve significant efficiencies that a structural remedy would sacrifice.Footnote 3.
 In this paper, we seek to shed light on the economic welfare effects of vertical mergers and remedies that are directed to these mergers, in light of economic theory and the Agencies’ policies and practice. The paper is organized as follows. In Sect. 2, we provide a conceptual foundation for assessing the welfare effects of vertical mergers and of the remedies that are applicable in vertical merger cases. In Sect. 3, we describe the Agencies’ merger remedy policies—as articulated and as revealed in practice—and find that these policies are broadly consistent with the goal of maximizing welfare.Footnote 4 Section 4 then examines remedies policy in the context of the substantive analysis of vertical mergers in the VMGs, and suggests some ways that the welfare effects framework could more clearly inform Agency policy on vertical merger remedies. Section 5 offers some conclusions.",1
59.0,3.0,Review of Industrial Organization,06 July 2021,https://link.springer.com/article/10.1007/s11151-021-09818-x,Targeted Value-Enhancing Advertising and Price Competition,November 2021,Lynne Pepall,Daniel Richards,,Female,Male,Unknown,Mix,,
59.0,3.0,Review of Industrial Organization,02 July 2021,https://link.springer.com/article/10.1007/s11151-021-09819-w,Renegotiations and Renewals of Public Contracts,November 2021,Jean Beuve,Stéphane Saussier,,Male,,Unknown,Mix,,
59.0,3.0,Review of Industrial Organization,04 May 2021,https://link.springer.com/article/10.1007/s11151-021-09814-1,Location-Price Equilibria when Traditional Retailers Compete Against an Online Retailer,November 2021,Stefano Colombo,Zemin Hou,,Male,Unknown,Unknown,Male,"Online retailers represent a major challenge for traditional (offline) retailers. One crucial difference between online retailers and traditional retailers is that the former are location-irrelevant, whereas the latter are physically located in a specific place. Several empirical studies have shown how the structure of the traditional retailing industries has been re-shaped since the appearance of online competitors (see, for instance, Brynjolfsson and Smith, 2000; Brown and Goolsbee, 2002; Chevalier and Goolsbee, 2003).Footnote 1 Furthermore, the current COVID-19 crisis has also increased the importance of online shopping, given the need to reduce direct contact among consumers (see, for example, Chang and Meyerhoefer, 2020; Pantano et al., 2020). It is expected that this change of habits will last even when the health crisis has subsided (Sheth, 2020). The existence of online competitors affects the way that traditional retailers compete against each other. The choice of location is a crucial strategic variable for traditional retailers (Aguirregabiria and Vicentini, 2016; Krider and Putler, 2013). Therefore, it is expected that online competition alters the incentives that underlie the location choices of the traditional retailers. However, the theoretical analysis of the location choices of traditional retailers that compete with online retailers is still scant. In this paper we analyze location-then-price equilibria in a spatial model a lá Hotelling (1929), where two traditional retailers compete against an online retailer. The aim of this work is to highlight and describe which forces drive the location choices of traditional retailers when facing the competition of online retailing. Specifically, we address the following question: Does the existence of an online competitor induce the traditional retailers to agglomerate or separate in the space? We show that only locational equilibria where there is direct competition between the traditional retailers could emerge in equilibrium. Even if both symmetric and asymmetric equilibria are possible, all of them have the following characteristic: the traditional retailers locate in such a way that their equilibrium distance is neither maximal nor minimal. Therefore, traditional retailers position themselves to compete for the middle of the market and the online retailer competes for the extreme ends of the market (sometimes both ends, sometimes only one end). This paper is rooted in two strands of literature: First, it is rooted in the so-called “spatial competition” literature that investigates the location choices of firms that compete in a spatial dimension (D’Aspremont et al., 1979; Hotelling, 1929).Footnote 2 Second, the present paper is rooted in the literature that investigates the competition between a location-irrelevant retailer and traditional retailers (Balasubramanian, 1998; Bouckaert, 2000; Nakayama, 2009; Colombo and Matsushima, 2020). However, no paper considers the endogenous location of traditional retailers when they compete against an online retailer. This paper aims to fill this gap.Footnote 3 The remainder of the paper proceeds as follows: In Sect. 2 we introduce the model. In Sect. 3 and 4 we derive the equilibria. In Sect. 5 we discuss welfare. In Sect. 6 we consider the case of a multi-channel retailer. Section. 7 concludes.",1
59.0,3.0,Review of Industrial Organization,09 May 2021,https://link.springer.com/article/10.1007/s11151-021-09815-0,Optimal Incentives for Patent Challenges in the Pharmaceutical Industry,November 2021,Enrico Böhme,Jonas Severin Frank,Wolfgang Kerber,Male,Male,Male,Male,"It is a well-established empirical insight that patent offices grant many patents that are later found invalid when challenged in court (Allison & Lemley, 1998; Lemley, 2001; Lemley & Shapiro, 2005). Patents that are granted erroneously might lead to unjustified market power that harms consumers through higher prices. Invalidating patents through patent litigation is an important instrument for solving this problem (Ayres & Klemperer, 1999; Lemley & Shapiro, 2005; Shapiro, 2003); but this raises the question of whether firms have socially optimal incentives to challenge potentially invalid (‘weak’) patents. Since challenging a patent is costly (with costs of, e.g., searching for prior art, attorneys, courts or patent office fees, lengthy proceedings), this creates an underlying externality that results in fewer patent challenges: Potential challengers are not fully internalizing the positive effects of their patent challenge for society—in particular, in terms of the additional consumer surplus that is generated from market entry.Footnote 1 The literature has discussed instruments to address this issue such as: the subsidization of patent challenges; the creation of cash-bounty programmes to encourage private patent examinations; or the reduction of costs for patent revocation (Farrell & Merges, 2004; Miller, 2004; Thomas, 2001). In addition to this general problem, a pattern has emerged in the pharmaceutical industry whereby patent holders pay firms (usually generics) not to challenge their weak patents (‘reverse payments’) through patent settlements. These ‘pay-for-delay’ agreements have the consequence of delaying market entry and price competition. Patent settlements can therefore be an instrument for undermining the usefulness of patent litigation as a tool to solve the weak patent problem. Competition authorities in the U.S. and the E.U. have challenged a number of patent settlements with reverse payments in the pharmaceutical industry for violating antitrust rules. The objective of this paper is to analyse whether the incentives to challenge weak patents should be considered in the antitrust assessment of patent settlements with reverse payments. Beyond all controversial discussions of the details, the basic arguments on the potentially anticompetitive effects of patent settlements with high reverse payments are widely accepted in the economic and legal discussion (Elhauge & Krüger, 2012; Shapiro, 2003; Willig & Bigelow, 2004; Woodcock, 2016) and were accepted by the Supreme Court in its 2013 Actavis decision (FTC v. Actavis 2013). According to this view, patent settlements do not violate antitrust laws if they do not lead to lower consumer welfare (through later market entry of generics) than the level that could be achieved through patent litigation. The basic idea of the model that we are presenting in this paper is to analyse the trade-off between allowing later market entry in patent settlements (with higher profits for the originator and the generic firm) and the positive effects on consumer welfare from the greater incentives for generics to challenge a larger number of weak patents. We can show that incorporating consideration of patent-challenge incentives into the antitrust assessment under certain conditions increases consumer welfare by allowing an additional period of collusion – which is stipulated by a newly introduced policy parameter. The paper is structured as follows: In Sect. 2, we present a brief overview of the legal and economic discussion of the antitrust assessment of patent settlements and explain our basic approach. The model is presented in Sects. 3–5 (model framework, equilibrium analysis, and welfare analysis). Section 6 provides our analyses of comparative statics, while Sect. 7 addresses the policy parameter’s impact on innovation incentives. In Sect. 8, we briefly discuss the results and some conclusions.",
59.0,3.0,Review of Industrial Organization,13 July 2021,https://link.springer.com/article/10.1007/s11151-021-09820-3,Loving What You Get: The Price Effects of Consumer Self-Persuasion,November 2021,Matthew G. Nagler,,,Male,Unknown,Unknown,Male,,1
59.0,3.0,Review of Industrial Organization,25 July 2020,https://link.springer.com/article/10.1007/s11151-020-09776-w,Correction to: Global Value Chains and Local Business Environments: Which Factors Really Matter in Developing Countries?,November 2021,Marion Dovis,Chahir Zaki,,Female,Unknown,Unknown,Female,"In the original publication of the article, the research grant information was inadvertently missed in the acknowledgement section. The correct acknowledgment section should read as given below: This work was supported by French National Research Agency Grants ANR-17-EURE-0020 and a research Grant financed by the Economic Research Forum (Cairo, Egypt). We are grateful to Bernard Hoekman (European University Institute) and David C. Francis (World Bank) for their constructive comments. Also, the affiliation of the first author was published with an error. The correct affiliation should read as given below: Aix-Marseille Univ., CNRS, EHESS, Centrale Marseille, IRD, AMSE, Marseille, France.",1
59.0,3.0,Review of Industrial Organization,09 July 2021,https://link.springer.com/article/10.1007/s11151-021-09817-y,Correction to: Is the Whole Greater than the Sum of Its Parts? Pricing Pressure Indices for Mergers of Vertically Integrated Firms,November 2021,Michael Trost,,,Male,Unknown,Unknown,Male,"The article “Is the Whole Greater than the Sum of Its Parts? Pricing Pressure Indices for Mergers of Vertically Integrated Firms”, written by Michael Trost, was originally published Online First without Open Access. After publication in volume 58, issue 2, pages 235–262, the author decided to opt for Open Choice and to make the article an Open Access publication. Therefore, the copyright of the article has been changed to ©The Author(s) 2021, and the article is forthwith distributed under the terms of the Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article is included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0. Open access funding enabled and organized by Projekt DEAL. The original article has been corrected.",
59.0,4.0,Review of Industrial Organization,28 October 2021,https://link.springer.com/article/10.1007/s11151-021-09849-4,General Editor’s Note: Antitrust and Regulatory Update,December 2021,Lawrence J. White,,,Male,Unknown,Unknown,Male,,
59.0,4.0,Review of Industrial Organization,21 November 2021,https://link.springer.com/article/10.1007/s11151-021-09847-6,Recent Developments at DG Competition: 2020/2021,December 2021,Apostolos Baltzopoulos,Liliane Karlinger,João Vareda,Male,Female,,Mix,,
59.0,4.0,Review of Industrial Organization,14 November 2021,https://link.springer.com/article/10.1007/s11151-021-09846-7,"Economics at the FCC 2020–21: Closing the Connectivity Gap, COVID-19 and Telehealth, Spectrum Auctions, Communications Marketplace Report, and Economic Research",December 2021,Allison Baker,Patrick Brogan,Glenn Woroch,Female,Male,Male,Mix,,
59.0,4.0,Review of Industrial Organization,02 November 2021,https://link.springer.com/article/10.1007/s11151-021-09845-8,Economics at the FTC: Multi-level Marketing and a Coal Joint Venture,December 2021,Marta Wosińska,David Givens,Benjamin Wallace,Female,Male,Male,Mix,,
59.0,4.0,Review of Industrial Organization,19 October 2021,https://link.springer.com/article/10.1007/s11151-021-09842-x,"The Year in Review: Economics at the Antitrust Division, 2020–2021",December 2021,Brian Clark,Jeffrey S. Lien,Jeffrey M. Wilder,Male,Male,Male,Male,"The past year has seen a flurry of activity at the Antitrust Division of the U.S. Department of Justice. Among the Division’s most high-profile enforcement actions was its October 2020 suit, joint with 11 state Attorneys General, that alleged monopoly maintenance against Google in search and search-advertising markets. The Division also reached a settlement with rival hospital systems Geisinger Health and Evangelical Community Hospital in central Pennsylvania. A partial-acquisition agreement that would have given Geisinger a 30% stake in its rival—in addition to introducing significant entanglements between the two hospital systems—was reduced to a 7.5% passive interest. Division economists played a critical role in each of these and many other enforcement efforts. In this review article, we report on two enforcement matters that share a common theme: nascent competition. In traditional horizontal merger challenges, the Division often benefits from a structural presumption of harm that arises when mergers sufficiently increase concentration. Such presumptions are articulated in the 2010 Horizontal Merger Guidelines issued by the U.S. Department of Justice and the Federal Trade Commission.Footnote 1 Over time, U.S. courts have increasingly embraced and applied these structural presumptions in evaluating horizontal mergers.Footnote 2 Of course, nascent competition cases are defined by their lack of significant overlap, or at the very least the observation that the nascent competitor’s share today understates its future competitive impact. While the Horizontal Merger Guidelines prescribe the use of market shares “based on the best available indicator of firms’ future competitive significance in the relevant market,”Footnote 3 it may be difficult to project such shares reliably for nascent competitors. As a result, legal challenges to acquisitions of nascent competitors may not always benefit from the structural presumptions outlined in the Horizontal Merger Guidelines. This is unfortunate because the stakes could not be higher: Such transactions often occur in markets that are characterized by pronounced scale economies and barriers to entry, and the strategic acquisition of one or a handful of potential competitors can effectively insulate the incumbent from competition. The first attempted acquisition that we discuss is that by Visa of technology firm Plaid. As will be described in detail below, Plaid aspired to leverage its position as a financial aggregator with access to hundreds of millions of consumer bank accounts to facilitate debit transactions in direct competition with Visa and other debit card networks. The Division challenged the acquisition in November 2020. The Division alleged that Visa has monopoly powerFootnote 4 in online debit. Two months later, with the trial pending, the parties terminated their merger agreement. The second attempted acquisition was in the travel industry, which has long been characterized by dominant global distribution systems that facilitate the sale of airline tickets through travel agencies. The Division filed suit to block the acquisition of Farelogix by Sabre, the nation’s leading global distribution system, in August 2019. Unlike Plaid, Farelogix had begun to make its presence felt in the market well before the challenged transaction. Farelogix offered airlines the ability to connect directly to travel agencies and thereby disintermediated global distribution systems such as Sabre. Despite acknowledging that the threat of deploying Farelogix’s technology allowed airlines to negotiate lower fees, the court ultimately declined to enjoin the transaction. The court cited legal precedent that was established in Ohio v. American Express Co., 138 S. Ct. 2274 (2018). The acquisition was later provisionally blocked by the U.K.’s Competition and Markets Authority and never consummated. Because the parties decided to abandon their transaction, the Third Circuit vacated the district court decision (which had concluded that the merger would have been lawful).",
59.0,4.0,Review of Industrial Organization,23 November 2021,https://link.springer.com/article/10.1007/s11151-021-09848-5,Recent Developments at the CMA: 2020–2021,December 2021,Julie Bon,San Sau Fung,Mike Walker,Female,,Male,Mix,,
60.0,1.0,Review of Industrial Organization,13 July 2021,https://link.springer.com/article/10.1007/s11151-021-09822-1,Differentiated Entry or “Me-Too” Entry in Bertrand and Cournot Oligopoly,February 2022,James A. Brander,Barbara J. Spencer,,Male,Female,Unknown,Mix,,
60.0,1.0,Review of Industrial Organization,04 September 2021,https://link.springer.com/article/10.1007/s11151-021-09839-6,Two-Period Duopolies with Forward Markets,February 2022,Caleb Cox,Arzé Karam,Matthias Pelster,Male,Unknown,Male,Male,"Corporate hedging is of great interest to both practitioners and academics (e.g., Graham and Rogers 2002; Haushalter 2000; Mello and Parsons 2000; Tufano 1996; Smith and Stulz 1985). Managing risks can reduce firms’ expected bankruptcy costs, agency costs, information asymmetries, or expected taxes, and thus increase shareholder value (e.g., Bolton et al. 2011; Campello et al. 2011; Froot et al. 1993; Mackay and Moeller 2007).Footnote 1 While several optimal strategies developed theoretically propose a full hedge by firms in forward markets (e.g., Broll and Wong 2013; Holthausen 1979), several empirical studies find underhedging: hedge ratios that are less than one (e.g., Adam et al. 2015; Brown et al. 2006; Carter et al. 2006; Haushalter 2000; Tufano 1996). A “sequential” setting where firms first decide on their hedging and then set their production quantity provides a theoretical rationale for underhedging in imperfectly competitive markets (Broll et al. 2009). In such cases, firms account for the effect that their hedging decision may have on the market ( Brandts et al. 2008; van Eijkel and Moraga-Gonzalez 2010; Leautier and Rochet 2014; Le Coq and Orzen 2006). Ceteris paribus, a larger hedging position of one firm increases the optimal output of this firm and decreases the competitors’ optimal output (Allaz 1992; Allaz and Vila 1993; Broll et al. 2011). In equilibrium, however, this increases competition: Output increases, and prices decrease. Thus, firms may decide to hedge less to avoid reducing their profits. It is clear that firms face a strategic dilemma: They must weigh the benefits of hedging their risk against the adverse effects of an increase in market competition. However, Broll et al. (2011) theoretically show that this strategic dilemma is non-existent in a simultaneous one-shot output market interaction setting where firms decide on their production and hedging decision at the same time. In this paper, our main objective is to examine experimentally the extent to which strategic considerations explain underhedging behavior in a simultaneous hedging setting in a multi-period framework in imperfectly competitive markets. We use a simple Cournot duopoly model with a simultaneous hedging setting and repeated interaction to examine how hedging affects market equilibrium. Ex ante, we first allow firms to hedge their risk exposure toward demand uncertainty on a forward market. Second, we provide firms with the real option for storage that allows them to react to low demand realizations ex post. This latter feature introduces real dynamics into the multi-period model and ensures that our setting is not simply a repetition of the single-shot game. In our experimental study, we conduct two treatments: one treatment with an additional production opportunity after the initial demand state is realized (Double Production), and one treatment without (Single Production). Subjects play repeatedly for 20 rounds to allow them to learn about the strategic setting, but they are randomly re-matched in each round to minimize any potential repeated game effects. Our experimental results provide supportive evidence that subjects tend to account for the adverse effects of their own financial decisions on the market equilibrium. However, we do not find any evidence that the experimental decision makers consider the hedging decisions of their competitors—which are common knowledge—in subsequent decisions. As the game is closer to a simple repetition of the single-shot game in our second setting, subjects’ level of supply prevents duopoly profits, on average. Our results underline that hedging creates a strategic dilemma for producing firms and significantly increases competition—even in a simultaneous setting.",
60.0,1.0,Review of Industrial Organization,12 August 2021,https://link.springer.com/article/10.1007/s11151-021-09834-x,The Price Effects of Competition from Parallel Imports and Therapeutic Alternatives: Using Dynamic Models to Estimate the Causal Effect on the Extensive and Intensive Margins,February 2022,David Granlund,,,Male,Unknown,Unknown,Male,"This paper studies how the prices of on-patent pharmaceuticals react to competition from parallel imports and therapeutic alternatives. Because on-patent pharmaceuticals account for about three-quarters of costs for prescription pharmaceuticals, it is important to study the competition that affects these prices. Parallel imports are products that are sold by the producer at low prices in some countries and that are imported by “parallel traders” without the producer’s permission. Therapeutic alternatives are other pharmaceutical substances that are intended for the same or similar medical diagnoses. The analyses are done using monthly data on prices for 1586 on-patent locally sourced productsFootnote 1 that were sold in Sweden from October 2002 through October 2007. I find that facing competition from one parallel trader that sells products with the same substance, but, for example, with a different strength, reduces prices by 3% in the long term. If the parallel trader instead sells a product with the same strength, form of administration, and nearly the same package size, the price reduction amounts to 7%. However, in most cases, competition from additional parallel traders causes no significant additional price reductions. I estimate that the long-term effect for an average product that faces competition from at least one parallel trader that sells an exchangeable product is a 9% price reduction. The results also show that the first therapeutic competitor does not affect the price. On the other hand, the presence of four, or five or more, competitors that sell patent-protected substances are predicted to reduce prices in the long term by 9 and 10%, respectively. However, firms do not reduce prices in response to competition from therapeutic alternatives for which generics exist. The paper contributes to the existing literature in four main ways: First, to my knowledge this paper is the first that estimates the causal price effects of the number of parallel traders. I am able to this by using reduced-form dynamic models that allow lags of the numbers of competitors to serve as valid instruments for their current values. This provides enough instruments to study also the causal effects on the intensive margins. Therefore, the paper presents estimates of how the number of parallel traders—as well as the number of therapeutic competitors—affects prices. Second, the detailed data allow me to study how the effects of competition from parallel imports depend on the similarities across several variables between the locally sourced products and the parallel imports. Third, the paper is to my knowledge also the first that distinguishes between short- and long-term effects and estimates the speed of adjustment for on-patent drugs. I find that prices react slowly to changes in competition: Fifteen months are required before half of the long-term effect is realized. A fourth contribution is that the paper provides robust estimates of the effects of competition from parallel imports without making the assumptions that were made in previous studies in this field: for example, that exchange rates are valid instruments or that firms take competitors' prices as exogenous. As I describe in the following section, previous studies have either used potentially endogenous instruments or assumed that firms take competitors' prices as exogenous.",4
60.0,1.0,Review of Industrial Organization,05 August 2021,https://link.springer.com/article/10.1007/s11151-021-09830-1,Input Price Discrimination and Allocation Efficiency,February 2022,Chin-Sheng Chen,,,Unknown,Unknown,Unknown,Unknown,,
60.0,1.0,Review of Industrial Organization,28 August 2021,https://link.springer.com/article/10.1007/s11151-021-09836-9,Supply Chain Innovations and Partial Ownership,February 2022,Matthias Hunold,Shiva Shekhar,,Male,Female,Unknown,Mix,,
60.0,2.0,Review of Industrial Organization,21 September 2021,https://link.springer.com/article/10.1007/s11151-021-09838-7,Has Anheuser-Busch Let the Steam Out of Craft Beer? The Economics of Acquiring Craft Brewers,March 2022,Kenneth G. Elzinga,Alexander J. McGlothlin,,Male,Male,Unknown,Male,,1
60.0,2.0,Review of Industrial Organization,04 September 2021,https://link.springer.com/article/10.1007/s11151-021-09840-z,Price Regulation and Fraud—with Special Emphasis on Gasoline Retailing,March 2022,Julio César Arteaga,Daniel Flores,,Male,Male,Unknown,Male,"Retail gasoline stations often have a bad reputation for cheating. This occurs around the world both in places with and without price regulation. For instance, a report of the consumer protection agency (PROFECO) in Mexico—at a time when gasoline prices were fixed by the government—found that more than 60% of consumers believed that retail stations do not dispense the correct amount of gasoline (PROFECO, 2005): They believed that stations delivered less gasoline than the amount that consumers paid for. Similarly, Keteyian (2008) claims that about 2,000 pumps in the state of Texas—a place in which retailers can set prices freely—cheat drivers.Footnote 1 Darby and Karni (1973) recognize that fraud is essentially a result of information problems. Fraud arises when consumers are unable to realize that they are victims of the fraud—or they do so with some delay. This is likely to occur in the consumption of experience goodsFootnote 2: Customers’ inability to observe if the pump dispenses the exact amount of gasoline that they are paying for, provides stations with an incentive to commit fraud. Our study links early theoretical work on experience goods with recent literature on gasoline retailing. This paper is close to the works of Shapiro (1982) and Riordan (1986) on the provision of quality in the context of experience goods. In a sense, short liters constitute a low-quality product. The paper is also related to relatively recent models about pricing in gasoline retailing, such as: Iyer and Seetharaman (2008), Obradovits (2014), and Carranza et al. (2015). Nevertheless, none of these articles addresses the effects of price-cap regulation on fraud. Finally, the paper can also be related to the experimental work of Huck et al. (2016), who compare quality under fixed and flexible prices. In this article, we study the incentives of gasoline stations to commit fraud dispensing short liters both with and without price cap regulation. In particular, we extend the model of spatial competition that was developed by Salop (1979) to consider: (i) the information dynamics of experience goods in the context of fraud; and (ii) the effects of price-cap regulation on fraud, firms’ profits, consumers’ surplus, and welfare. Although this work is motivated by documented evidence of fraud and recent regulatory changes—price liberalization—in the Mexican gasoline retail market,Footnote 3 the theory on fraud and price regulation that we propose may apply to other places and goods as well. Among other things, we find that gas stations—with or without a price cap—have more incentives to commit fraud—to sell shorter liters—as: competition becomes less intense; the unit cost of gasoline increases; and cheating fines or law enforcement efforts decrease. Interestingly, we also find that price-cap regulation itself generates an additional incentive to commit fraud and, consequently, reduces social welfare. Nevertheless, its effect on consumers’ surplus is ambiguous.",2
60.0,2.0,Review of Industrial Organization,14 January 2022,https://link.springer.com/article/10.1007/s11151-021-09851-w,"Cheap Talk, Monitoring and Collusion",March 2022,David Spector,,,Male,Unknown,Unknown,Male,"This paper shows that in a market where demand is uncertain and data on other firms’ sales become available with a delay, the early exchange of sales reports between firms can make collusion more efficient even if such communication is cheap talk. Our main finding is that—for some parameter values—collusion with near-monopoly pricing in all periods along the equilibrium path can occur only if communication is possible, even though such communication does not make sales data verifiable sooner. The novel theoretical mechanism that is identified in this paper can contribute to the ongoing debate on the proper antitrust treatment of information exchanges between firms. The assumptions of our model and also the collusive equilibrium with communication that we derive exhibit features that are similar to those that are observed in many recent cartels:Footnote 1 Firms compete in prices; self-reported sales volumes are not instantaneously verifiable, but they can be compared to reliable data that become public with a lag;Footnote 2 the collusive scheme is based on a target market share allocation; firms exchange detailed sales reports before these data becomes verifiable; and when these reports point to a discrepancy between actual and target market shares, companies that sold above their quotas take steps to decrease their sales for a while: compensation takes the form of a temporary reallocation of market shares rather than inter-firm payments. According to Harrington (2006), whereas in some recent cartels participants compensated market share swings by making payments to each other—often under the guise of interfirm sales; in other cases the compensation was through market share reallocations of the kind that is highlighted in this paper, as the continuous monitoring of sales volumes afforded colluding firms “the opportunity to adjust their sales”.
 The equilibrium we derive is symmetric, which limits the need for pre-play coordination. It involves pure strategies along the equilibrium path, with no need for coordination on a public randomization device. The possibility for firms to collude more efficiently by exchanging reports on their own sales arises from the following difference between undercutting competitors and misreporting sales: Past misreporting can be spotted with certainty once verifiable sales information becomes public, whereas, if demand is noisy enough, undercutting cannot be distinguished from demand shocks. In a collusive equilibrium with near-monopoly profits, price wars should be present (almost) only as an off-equilibrium threat. Since lying-unlike price undercutting-can be inferred with certainty once verifiable sales data become available, the threat of a price war can be used to deter lying at no cost to total profits, but not to deter undercutting. The expectation that being caught lying will cause a price war induces firms to report their sales truthfully; in turn, their accurate reports allow firms to correct market share imbalances sooner, without waiting until verifiable data become available. This quicker reallocation of market shares implies that firms have less to gain by secretly cutting their prices and pretending they were just lucky. This in turn facilitates the enforcement of collusive discipline through market share reallocations—without a need for costly price wars to take place along the equilibrium path. After a review of the related literature (Sect. 2), we present the model (Sect. 3) and derive a necessary condition for a pure-strategy symmetric equilibrium without communication to yield profits that are bounded away from some near-monopoly level (Sect. 4). We then characterize a sufficient condition for such near-monopoly profits to be attainable with communication, by constructing a specific equilibrium (Sect. 5). These results jointly yield a sufficient condition for communication to expand the set of attainable profit levels (Sect. 6). The conclusion discusses the implications of these results for antitrust policy.",1
60.0,2.0,Review of Industrial Organization,27 October 2021,https://link.springer.com/article/10.1007/s11151-021-09843-w,Reverse Privatization as a Reaction to the Competitive Environment: Evidence from Solid Waste Collection in Germany,March 2022,Juri Demuth,Hans W. Friederiszick,Steffen Reinhold,Male,Male,Male,Male,"There is a continuing discussion about the relative merits of public versus private provision of services and the potential competitive distortions that arise from the role of public providers. This discussion has heated up again, as in recent years municipalities across the globe have taken back control of service provision from the private sector in the areas of energy, water, and waste collection, and have started providing these services themselves. The process toward insourcing (“reverse privatization”)Footnote 1 has reversed earlier waves of privatization during the 1980s. In this paper, we use the example of solid waste collection service to show that this trend also exists in Germany. More importantly, we analyze municipalities’ motives for reverse privatization; we focus on motives that are related to the competitive interaction of private and public providers. Our analysis relies on a panel dataset that provides the status (in-house versus private provision) for all of the German municipalities (more than 11,000) for the years 2003, 2009, and 2015.Footnote 2 Bel and Fageda (2007, pp. 528–529) point out that only studies that are based on changes in the status, instead of levels, allow a proper analysis of the motivations for (reverse) privatization.Footnote 3 Accordingly, we built an indicator variable of changes in status between observable time periods. This allows us to analyze two episodes of switching: Episode 1 reflects the changes in status between 2003 and 2009; episode 2 reflects the changes in the time period between 2009 and 2015. The year of the switchover is known for a subsample of the dataset (albeit with some measurement error), which allows us to analyze annual data as well. Given economies of scale across municipal borders—cost advantages for a provider that is active in neighboring municipalities—markets are local. Exploring cross-market variation, we estimate the probability that a municipality reverts to privatization as a function of: (i) local concentration (measured by the CR3 of private service providers in local markets); (ii) local experience in in-house provision (measured by the share of in-house provision for neighboring municipalities); (iii) vertically related local public service (measured by the proximity of state-owned incinerators); and (iv) the existence of local incumbents (measured by the residents that are served locally by a company relative to its nationwide coverage). We find a statistically significant effect on reverse privatization in at least one of the episodes for all four factors. The results are also economically significant. We show that variations in those four factors are capable of moving predicted probabilities of switching by considerable amounts compared to the baseline probability. If those factors are changed from their median values to their 99% percentile, the switching probability increases substantially: In the first episode it increases from 12.1 to 36.5%, and in the second episode from 4.6 to 14.9%. The estimated coefficients for additional explanatory variables are in line with the results from earlier studies. In Sect. 2, we describe the institutional background of the service industry for solid waste collection in Germany. In Sect. 3 we summarize the related literature. Section 4 introduces the data, the variables that we use, and the descriptive statistics. Section 5 delivers our empirical assessment, and Sect. 6 offers policy conclusions.",
60.0,2.0,Review of Industrial Organization,02 November 2021,https://link.springer.com/article/10.1007/s11151-021-09844-9,The Handmade Effect: A Model of Conscious Shopping in an Industrialised Economy,March 2022,Jasmin Droege,,,Female,Unknown,Unknown,Female,"
We believe that human connection is central to buyer engagement. On Etsy, we emphasize that the items listed for sale are brought to life by real people.
 -Etsy, Inc., 2018 Annual Report. The e-commerce website Etsy was founded in 2005 as a marketplace for handmade products. In an era of technological advancement, Etsy’s business model is notable: Everything that is listed in the marketplace must be “handmade or unique and assembled with production partners, vintage or craft supplies” (Etsy, Inc, 2019a, p. 11). In a wide range of categories—including jewelry, clothing, toys and furniture—the sellers’ production processes could readily be automated, which could potentially result in improved quality and fewer defective products. Nevertheless, the number of buyers and sellers on Etsy has been rising with gross merchandise sales (GMS) surpassing 2.5 billion U.S. dollars in the second quarter of 2020 (Fig. 1). It is, therefore, worth understanding why this sector of the economy can persist in the twenty-first century. Business activity on Etsy since 2014 (data source: Etsy, Inc) In this paper, I offer an explanation for the observed puzzle. I argue that a handmade effect on the consumer side (Fuchs et al., 2015) can explain why some firms—like those selling on Etsy—do not adopt superior production processes and instead choose to produce and advertise their products as handmade. I present a model that features a unit mass of shoppers. They come in two types: quality shoppers, and conscious shoppers. In this setting, product differentiation has two dimensions (e.g., Economides, 1989): All shoppers value product quality equally, but they differ in the weight that they give to the production process. From a firm’s perspective, there are nontrivial interactions: Hand production comes at a higher effort cost, and may be inferior at translating any given effort into quality. I show that when a fraction of shoppers is sufficiently concerned about the conditions under which the product is manufactured and, therefore, is willing to pay a handmade premium, the firm adopts a handmade strategy. A minimum quality standard, however, can alter the firm’s behaviour and induce switching to machine production. When hand production is associated with increasing marginal cost, I show that a niche handmade product can be perceived to be of higher quality than a mass market machine-made product. I extend the model to settings in which two ex-ante identical firms decide simultaneously on the production process, pricing strategy, and per-unit effort. I show that the existence of sufficiently conscious shoppers can explain the specialisation of firms and, thus, the observed co-existence of handmade and machine-made products in the economy. I show that such specialisation is efficient, and robust to collusion if the proportion of conscious shoppers in the market is not too large and their concern about the conditions under which the product is manufactured is not too high. I then introduce conformist shoppers who behave exactly like conscious or quality shoppers depending on their beliefs. In this setting, a monopolist may be able to use a handmade strategy to signal a social norm of conscious consumption. When credible, this strategy generates a crowding-in effect and explains sales growth even in markets where conscious shoppers are believed to be in the minority. Finally, I show that my model can shape intuitions also on ethical production, and can explain the mainstreaming of Fair Trade in Europe in the late 1990s (Renard, 2003) through such a crowding-in effect. My paper relates to the growing economic literature on ethical consumption (e.g., Stiefenhofer, 2019). The empirical literature has focused on estimating consumers’ willingness to pay a premium for ethical products (e.g., Galarraga & Markandya, 2004; Loureiro & Lotade, 2005; Arnot et al., 2006). For example, when buying more expensive Fair-Trade products, consumers reveal their preferences for ethical products. They are inferred to obtain additional utility from the product’s Fair-Trade label. My model builds on these insights: conscious shoppers gain utility from buying a handmade product whereas quality shoppers care only about product quality. My extension to two firms relates to how product differentiation can relax price competition. In his classical work on monopolistic competition, Chamberlin (1933) notes that product differentiation leads buyers to pair with sellers according to their preferences. Firms evade price competition by focusing buyers’ attention towards a trade-mark, or by competing on the basis of quality. In my model, attention is focused on the production process: A handmade strategy relaxes price competition. Champsaur and Rochet (1989) obtain a similar result by allowing firms to choose non-overlapping qualities followed by prices. Sebald and Vikander (2019) consider a related signaling game in which a monopolist faces a fraction of consumers who care about what other consumers believe. The rest of the paper is organised as follows: Sect. 2 introduces the model. I discuss my main results when the firm acts as a monopolist in Sect. 3, and when the firm is part of a duopoly in Sect. 4. In Sect. 5, I explain how a monopolist may use a handmade strategy to signal a social norm of conscious consumption. Section 6 concludes with an application to Fair Trade, and avenues for future research.",2
60.0,3.0,Review of Industrial Organization,02 February 2022,https://link.springer.com/article/10.1007/s11151-022-09857-y,Competition Policy in Africa,May 2022,Liberty Mncube,Thomas W. Ross,,Female,Male,Unknown,Mix,,
60.0,3.0,Review of Industrial Organization,01 March 2022,https://link.springer.com/article/10.1007/s11151-022-09863-0,Some Opening Words for The Special Issue,May 2022,Tembinkosi Bonakele,Francis Kariuki,,Unknown,Male,Unknown,Male,"
We all originate from Africa. It is our great pleasure to welcome home readers, competition family, editors and the rest of the Review of Industrial Organization team. We are honoured to pen the opening words of this African edition. 
The fact that there is an issue that is dedicated to African competition policy is in itself a testament to the firm presence and growing influence of African competition policy in the world and hopefully a sign that more attention will turn to African competition policy in the future. It has been our long-held wish that the growth of competition policy in Africa warrants academic attention in the form of a publication of this nature. Our wish is that this publication will inspire the establishment of an internationally recognised permanent dedicated journal on African competition policy. We purposefully say African competition policy—rather than competition policy in Africa—because competition policy on the African continent has taken on a distinctly African flavour since its inception. Rather than securing market efficiencies alone, it has become clear that African competition policy seeks to address a range of socio-economic ills—such as inequality, unemployment and poverty—as well. There is, in our view, solid justification for this: All competition laws are underpinned by a political economy context. Let us recall a few features of the African economic profile: Africa has more than a billion in population and has the youngest population of all the continents of the world. It has the largest and most diverse mineral resources, and has the greatest agricultural potential of any continent. Most of Africa has adopted a free-market economy model—at least notionally. But most citizens are engaged in subsistence farming and informal markets. Much of the large industry is directed at the extraction of natural resources for exports to Europe and Asia, which retains largely the same features of the colonial economy. It imports most processed goods and services from multinationals. Huge portions of the population live in poverty; many are unemployed; and in South Africa—where there are relatively well-developed markets—inequality is the highest in the world, and the economy is highly concentrated. Studies that have been conducted by competition agencies indicate that restrictions in competition is paid for by the poor consumers. According to Fox and Bakhoum (2019), Africa needs markets; but competition policy must ensure that markets work for the marginalised. This naturally is preceded by a review that demonstrates-although there are encouraging notable exceptions-that markets have not worked for the greater good of the population on the continent. African markets are bound to grow. The establishment of the African Continental Free Trade Area (ACFTA), various industrialisation projects that are especially focused on infrastructure, and the likely demographic dividend in a continent coming from a low base, all point to Africa’s being the next frontier of economic growth. What then should the competition policy underpinning this growth be? To put it bluntly: Africa is jaded about the ability and incentive of unfettered market competition to equalise societies and so is seeking more direct measures—within competition policy—to achieve these outcomes. Fox (1987), for one, predicted the coming of a new age of thinking about distribution economics 1987—more than 10 years before South Africa’s modern competition regime came into existence. In it she distinguished between the traditional Chicago school of thought and a new coalition that was arising at the time. She described members of the Chicago school as those who commonly asserted their preference for freedom from government interference in the economy. “They assume” she wrote “that competition in markets untouched by positive law is robust, that the natural tendency of firms is to be efficient and that the progressive, industrious entrepreneur is likely to succeed. On the other hand, “members of the New Coalition … worry about private as well as government power, the coercion and exclusion of the weak by the powerful and the distribution of power and opportunity. They take seriously the imperfections of free market competition.” Eleanor ended her piece with a strong endorsement for the new coalition’s way of thinking and a prediction that their approach would more likely be the blueprint for the second century of antitrust that was to come. The second century of antitrust has come, and Africa is the new coalition that Fox predicted. However, the call for competition issues to respond to its context is receiving attention beyond our own continent. Many are looking at competition law to address the continuing concentration of wealth and widening inequality within and between countries, and the challenges that emanate from digital markets and sustainability issues. Competition authorities no longer have the luxury of a neat platform for application of competition policy, and these challenges are, of course, greater in developing countries that face numerous social and economic challenges. In South Africa, the context is that of a highly unequal society in the world, with unemployment above 30%, and conditions further worsened by Covid-19. The profile of the South African economy was by design, and there is a determination to use all available instruments to turn it around. The vision of an economy that is owned and shared by her people in South Africa is at least as old as the anti-apartheid struggle. Kenya’s market-based economy is one of the largest and most developed in eastern and central Africa with a GDP of $95 Billion. Kenya is a lower middle-income country, and is characterised by a diverse and dynamic economy and a growing middle class that is entrepreneurial in nature. Whereas economic inequality still exists in Kenya, like other African countries, the Government’s interventions and initiatives—which are guided by progressive development blueprints such as the Vision 2030 and the Economic Recovery Strategy (which was developed to counter the impact of Covid-19)—has the purpose to foster an inclusive society and create competitive and functional markets for Kenyans. It is noteworthy that African governments have substantially invested in business drivers and enablers such as improving road networks, ports, and energy and telecommunication infrastructure, among others. Additionally, there has been significant progress in terms of removing regulatory barriers nationally and regionally, and the solidification of constitutionalism and democracy. These developments have improved the investment climate across Africa. To supplement and complement these efforts, and address the aforementioned desire for a more inclusive society, there has been great effort at elevating competition law enforcement: as a critical catalyst for sustainable economic development. This is the desire of most African countries. Competition laws reflect this desire. There have been notable achievements in the development of competition law on the continent: In our own countries—Kenya and South Africa—competition law is enjoying unprecedented success. Owing to the vision of our African forefathers, the intellectual contributions of our cherished colleagues in foreign jurisdictions, and the tireless efforts of local stakeholders in the government, the private sector and civil society, today South Africa and Kenya have established competition laws that are administered by autonomous and respected agencies. Our enforcement of competition law has become a source of refuge for consumers and small firms, and our cases have become a matter of public debate in the media and a subject of interest to the judiciary and other branches of government. Africa as a whole has seen enormous growth in the development of competition policy and the establishment of competition regulators in recent years. According to the African Competition Forum (ACF)-a grouping of competition agencies that exists to support agencies and promote competition as a whole-in 2000 there were just 13 African jurisdictions with competition laws. ACF was launched in Nairobi in 2011 with Kenya as the first Chair, South Africa as Vice Chair and Senegal as Secretary. Today, in 2020, the ACF has 47 members. This growth in the number of national competition authorities over the last 20 years reflects the increasing influence of competition policy on the development agenda. The deepening of competition law through progressive enactment and application of laws has occasioned better functioning markets that have yielded competitively priced and innovative services and products. Over and above national regulators, Africa has a number of regional competition regulators, including the West African Economic Monetary Union (WAEMU), the East African Community (EAC), the Common Market for Eastern and Southern Africa (COMESA), the Economic Community of West African States (ECOWAS) and the Economic and Monetary Community of Central Africa (CEMAC). The biggest economies in Africa all have a competition statute: The latest to join has been Nigeria. The Federal Competition and Consumer Protection Bill was passed by the Nigerian parliament in December 2017, and the President assented to it in February 2019. The new law established a Commission and Tribunal and covered cartels, dominance, anti-competitive practices, and mergers—as well as consumer protection. The Nigerian Federal Competition and Consumer Protection Commission—which administers the new law—has since become fully operational. Nigeria joins many other African countries in achieving this milestone. A further indicator of the growing influence of competition policy on the African continent can be seen in the proposed competition policy protocol of the African Continental Free Trade Area (ACFTA) agreement. The ACFTA agreement was signed on 21 March 2018, and this event signaled the commitment of policy makers and African leaders to regional integration. As part of the ACFTA Phase II negotiations, signatories to the ACFTA agreement are currently in discussions about the most appropriate competition policy protocol to adopt in support of the ACFTA’s goals. Incorporating competition policy in the ACFTA agreement is necessary to mitigate cross-border harms to competition and also to promote competition as a means of achieving Africa’s development goals. Competition agencies must now—preferably under the mantle of the ACF—apply themselves to the various options of implementing the agreement, including critically considering the option of installing a supranational competition agency. Whichever prescription is eventually adopted needs to be singularly focused on fast-tracking integration efforts and boosting intra-Africa trade. This opportunity should not heighten barriers to trade, but dismantle them for the collective advancement of our economies. Although the number of agencies that have been established over time is worth celebrating, the greater accomplishment—to which we now turn—is what the effective implementation of competition law has been able to achieve on the continent. First among these is the overall approach that African agencies have taken to crafting their respective competition laws. Each country has determined the unique purpose for which competition law is required in its jurisdiction and has, thereafter, drafted laws that are suited to achieve the intended outcomes. In South Africa, for instance, we had a need to correct the economic imbalances of our racially segregated past and to promote economic inclusion. For this reason, South Africa’s competition laws include provisions that allow firms that are owned by historically disadvantaged persons to be exempted from competition in defined circumstances. Merger regulation and other instruments are used to promote public interests such as employment and small and medium enterprises. This approach to implementation has translated to a focused prioritisation: concrete actions that are targeted at achieving equity and uplifting the marginalised. In this regard, a World Bank (2016) study concluded that by tackling four cartels—in wheat, maize, poultry and pharmaceuticals (these are goods that amount to just over 15% of the consumption basket of the poorest 10% in South Africa)—the reduction in the overcharge in prices was estimated to have reduced overall poverty by at least 0.40% points. Some 202,000 individuals were made better off and lifted above the poverty line through the lower prices that followed the actions that were taken by the South African competition authorities against these four cartels. The savings put an additional 1.6% back into the pockets of the poorest 10% by raising their disposable income—as the World Bank’s (2016) report demonstrated. In Kenya, ours was largely a command economy before and immediately after we gained independence in 1963. The economy was characterised by institutionalised price fixing of key commodities by the Government; this was a policy that was meant to spur the agriculture sector: a key GDP contributor. However, we gradually pivoted toward a free market in the 1980 s, with the setting up and operationalisation of laws, policies and institutions supportive of a liberalised economy. The Government progressively tapped competition law and policy enforcement as a driver of economic growth and inclusivity, with the aim of addressing restrictive trade practices that were throttling economic growth by increasing the cost of doing business for incumbents and erecting barriers to entry for both local and international investors. Kenya’s competition law was developed with the overarching objective of enhancing the welfare of Kenyans, through addressing anti-competitive businesses practices but also, uniquely, protecting consumer rights. Today, the Kenyan economy is largely service-sector driven: It is powered by an educated and enterprising human capital component that is mostly young. Additionally, Kenya’s vibrant Micro, Small, & Medium Enterprises (MSMEs) contribute about 40% to the GDP; the majority of these enterprises are in the informal sector. The drafters of our competition law attended to our unique socio-economic circumstances in various ways: With regard to mergers and acquisition transactions, our two-pronged analysis approach—impact on competition, and public interest concerns—seeks to secure employment opportunities for Kenyans. Additionally, our purpose is to ensure that approved mergers do not negatively impact SMEs, but instead support them to gain access to and compete in international markets. This is enforced through conditions that are precedent to approval. Similarly, transactions that enhance the ability of our national industries to compete more favourably in international markets are welcomed. In order to reduce Kenya’s trade deficit—which stood at $9.1 billion in 2020—Kenya also allows exemptions that permit businesses to engage in conduct that would otherwise be considered anti-competitive—but for a specific period of time. In Kenya, one notable intervention was in the telecommunication sector: The country’s leading Mobile Network Operator (MNO) unjustifiably ring-fenced its mobile money agents in exclusivity contracts, which prohibited them from doing business with competitor firms. This impeded competition, handicapped the agents from expanding, and—more importantly—limited customers’ choices. We (the Competition Authority) ordered the telecommunications firm to expunge the clauses, which permitted the agents—who are usually small business persons—freely to engage other MNOs and grow their businesses. Today, 223,000 agents are serving an ever-increasing client base of over 66 million registered mobile money users. Additionally, we ordered a reduction of Unstructured Supplementary Service Data (USSD) costs from Kshs. 10.00 to Kshs.1.00. The country’s 57 million registered phone users heavily rely on USSD to access various services on their mobile phones and, therefore, the price reduction had a direct and positive impact on their transaction costs. In the agriculture sector, Kenya dismantled barriers to entry that restricted competition in the production and export of purple tea. Rules in the sector—which is dominated by black tea producers—blocked competitors from joining the market. Our intervention created over 2,000 jobs through the entry of five factories that produce purple tea. Additionally, farmers have diversified their black tea-dominated enterprises so as also to grow the specialty tea—which fetches over 70% more per kilo in the market. A more recent and notable development is Kenya’s move to enforce the law against undertakings that abuse their Buyer Power—or, as it is commonly described, Superior Bargaining Position. This was made possible through amendments to our competition laws to address emerging issues in the retail sector, which had come under strain; this negatively affected big retail entities and their SME suppliers. Today, Kenya is investigating Abuse of Buyer Power cases in many sectors, including insurance, to ensure that strong buyers do not take advantage of their position to disadvantage their suppliers. Kenya has also relied on these provisions to monitor and address challenges in the retail sector with the objective of ensuring unfettered supply of essential goods to our population during the Covid-19 pandemic. Last, in September 2020, the Kenya Competition Authority moved to automate fully all of its technical processes, which include the filing of mergers and exemption applications as well as registering restrictive trade practices and consumer complaints. The permanent operational switch has resulted in significant savings for our stakeholders and ourselves—especially with regard to printing costs since we no longer accept manual filings of cases. We have also recorded an 80% reduction in printer maintenance and stationery costs by a similar percentage-a testament to our contribution to sustainable consumption. Most international mergers now require notification in one or more jurisdictions in Africa. We also have regional collaboration in enforcement against cartels and have made strides in getting our agencies to continue normal operations through use of technology where necessary. For all of our accomplishments—which are rightly highlighted in the pages of this Review—our work as competition agencies in developing countries is not done. If we are to see the day when our people are lifted from the scourge of poverty, unemployment, and inequality, African competition agencies must: (1) advocate for competition across the continent; (2) assist in developing the capacity of new and established agencies to carry out their respective mandates; and (3) contribute to the growing body of knowledge and academic research in this area. Although the growth of competition policy on the continent has had great momentum in recent years, there are still African countries without competition laws or an active competition agency. Therefore, there is a greater scope for adoption of competition laws on our continent. Additionally, as new agencies emerge, there is the need to equip them with the skills and tools to carry out their work effectively. Finally, there is a strong need for African competition practitioners to contribute to the growing body of knowledge and academic research in competition policy. Competition policy in Africa can only be seen as credible if it addresses the concerns that plague African markets. If it doesn’t, it will soon become irrelevant in the eyes of the public—which will leave other policy instruments to achieve desired outcomes. There is currently a dearth of literature and academic resources that target competition policy in Africa in a comprehensive way. Improving on this would spread learning across the continent and embolden African competition practitioners to develop jurisprudence that is uniquely suited to African market conditions. In addition, a growing body of literature on African competition policy could bear influence on more established foreign jurisdictions and possibly encourage a new approach to old persistent market failures in more mature markets. The future of African competition policy has never looked brighter. But competition policy—no matter how well it is crafted—is not an end in itself. It must be judged on its objectives, unique to its environment. As just two of the many competition agencies that are working towards these outcomes in Africa, we are encouraged by the enormous development that has already taken place in this area and remain confident that Africa is equal to the task of delivering equity and shared prosperity to all of its people.",
60.0,3.0,Review of Industrial Organization,02 March 2022,https://link.springer.com/article/10.1007/s11151-022-09854-1,Integrating Africa by Competition and Market Policy,May 2022,Eleanor M. Fox,,,Female,Unknown,Unknown,Female,"Africa has a rare opportunity: It has adopted a continental free trade agreement: the AfCFTA.Footnote 1 The Competition Protocol is due to be negotiated. Two alternative models are commonly suggested for the Competition Protocol: (1) a full continental antitrust law similar to the antitrust laws of most nations; or (2) intergovernmental cooperation with enhanced regionalism, which could possibly lead to a continental competition law. This essay takes a different cut: Africa should create a bespoke architecture with few but critical functions at the center. It should also serve a coordinating role for the continent. Regionalism should proceed, but enforcement at the center cannot wait. This essay offers a mode for considering what the center must do and ought not do, and then offers guidance on application of the principle. It addresses why the tasks at the center should be few and practicably achievable, and must be something more than and different from inter-governmental or regional cooperation. I telescope here, at the outset, three major insights that argue for the “center core” model, and then proceed with a fuller argument on constructing the core: 1) A critical mass of the most egregious restraints on trade, competition and entrepreneurial creativity in Africa are hybrid; public and private conduct are intertwined. Many acts involve corruption by complicit officials and other abuses; these acts obstruct trade/competition at member state borders, and prevent Africa from functioning as an internal market.Footnote 2 Africa has the opportunity to pioneer an integral trade/competition regime that addresses the core of this central obstacle to the one-Africa vision.Footnote 3 2) Competition within Africa is increasingly regional or continental—not just national. African firms that were national champions—mostly owned by a few African political and business elites—are expanding across African state borders and competing with global firms in Africa.Footnote 4 An effective competition law needs to have a geographical reach as wide as the competition that it is meant to address. 3) Africa needs a competition voice at the center, just as the European Union and the US each has a competition voice at the center. The central voice should speak to both internal-market (continent-wide) problems and global problems. Absent that voice, Africa will remain uncoordinated at home and a price-taker in the world. The developed world will continue to go first, setting the rules and foreseeing the outcomes with respect to all of the megamergers, world cartels, big tech abuses, and other global restraints that significantly impact Africa. 
Background. Most of the member nations of AfCFTA and some of the many regional economic communities (RECs) have adopted modern competition laws—although many are not in force.Footnote 5 The competition laws that are in place and their execution are far from perfect, but a number of the nations and some RECs are developing their own competition ecosystems, which help to build capacity of the younger competition agencies and help align the national and regional systems.Footnote 6 Crafting a coherent and effective continental competition law out of the current “spaghetti bowl” of national and regional authorities is a huge task. It would be hard for so many asymmetric nations to reach agreement on the terms—let alone to enforce the law in a meaningful way. Setting up a system of voluntary coordination among the nations is not so hard; it is feasible. Substantial work is already being done in the Africa Competition Forum (which is like an African ICN).Footnote 7 But the potential of nation-to-nation cooperation is limited and leaves critical tasks undone. Inter-governmental cooperation can do neither of the two most critical tasks that were identified above: drilling down on the business/state border restraints; and providing the platform at “the top” that is necessary for an economically unified Africa. Africa needs a more finely honed model. In the search for this model, Europe offers a helpful principle: subsidiarity:Footnote 8 What can be done as well or better at a lower level—national or regional—should be done at the lower level. The flip side is: Issues of essentially community level (here, the African continental community), which cannot be done as well at a lower level, should be done at the community level. I call this the “center core principle,” which is the other side of the subsidiarity coin. Africa should sort out those issues that can be solved at a lower levelFootnote 9 and leave them at a lower level. It needs to identify those competition/market issues that cannot be solved well at a lower level, and weave them holistically into the central tasks of the AfCFTA. This approach will go the longest, fastest way to creating a true African economic union. Failure to address the uniquely central issues will defeat the promise of Africa. Thus, this essay asks: What important competition tasks can the lower level (national or regional) not do well or soon, or would probably not do at all? It looks in the space between the single-discipline silos (trade, competition, consumer protection), and it imagines a unifying notional “dome” at the top of the continent.Footnote 10 Given its very particular focus, this essay does not dwell on important tasks at national and regional levels, which could start with enhanced intergovernmental cooperation and intensified capacity building within the RECs. It is expected that these projects would proceed side-by-side. The essay proceeds as follows: Part I provides background on the AfCFTA and briefly describes proposals tabled for the Competition Protocol. Part II asks why the tasks at the top must be streamlined, and what are the competition/trade tasks that cannot be handled well at the lower level and must be addressed at the continental level. Part III provides examples of the issues that are identified in Part II. Part IV addresses the implications and applications of the suggested competences for AfCFTA. Part V concludes.",2
60.0,3.0,Review of Industrial Organization,16 February 2022,https://link.springer.com/article/10.1007/s11151-022-09862-1,Characteristics of Prosecuted Cartels and Cartel Enforcement in South Africa,May 2022,Wawa W. Nkosi,Willem H. Boshoff,,Unknown,Male,Unknown,Male,"Cartel conduct is widely regarded as the most egregious of competition law infringements. Competition authorities around the globe have over the past two decades introduced policy reforms with the goals of better detecting, prosecuting, and deterring cartel behaviour—and South Africa has been no exception. South African competition authorities have expanded the scope of anti-cartel policy over the past 20 years. Policy changes have included: the introduction of a corporate leniency policy (CLP); administrative guidelines for the consistent and systematic penalization of cartels; personal criminal liability for cartel conduct; and amendments to the statutory maximum penalty for repeat offenders.  These policy changes and the accumulated data on detected cartels that have been published by the South African Competition Tribunal (Tribunal) and the Commission raise the ideal opportunity to contribute to the discussion on detected cartels in South Africa. In recent years, policymakers, practitioners, firms, and the public engaged in extensive consultation and debate on the Competition Act of 1998 (Competition Act) and its ability to deliver the desired economic and competition outcomes. This process culminated in substantial amendments to South African competition legislation in 2018. Unfortunately, much of this process was not guided by a systematic analysis of past cases. This paper investigates the number and features of detected cartels and cartel policy in South Africa, how cartel enforcement has changed, and the relationship between the features of cartels and cartel enforcement. The analysis presented here is of broader importance to the international antitrust community. South Africa has been a particularly ardent enforcer of anti-cartel policies; it has often emulated policies that have been introduced by other competition authorities. In particular, our analysis provides a developing-country comparator for recent work that has focused on European cartel enforcement. To this end, the paper introduces a new cartel dataset and employs descriptive and econometric analysis to study the variables of interest in a systematic fashion. The remainder of the paper is organised as follows: First we provide an overview of the South African cartel and cartel enforcement landscape and a brief review of the relevant literature. Section three provides a brief description of the dataset. Section four begins by describing the number of detected cartels and the duration of these cartels over the sample period. The section then characterises detected cartels by selected features: number of cartel members; type of cartel infringement; affected industries; and involvement of an industry association. Section five provides a characterization of cartel enforcement by investigating dimensions of cartel enforcement, such as: the cause of cartel breakdown; the corporate leniency policy; cartel penalties; and the length of the cartel enforcement process over the period under observation. Section six presents an empirical study of the relationship between cartel duration on the one hand and several features of cartels and cartel enforcement in South Africa. Section seven concludes.",1
60.0,3.0,Review of Industrial Organization,07 February 2022,https://link.springer.com/article/10.1007/s11151-022-09856-z,Non-competition Goals and Their Impact on South African Merger Control: An Empirical Analysis,May 2022,Prince M. Changole,Willem H. Boshoff,,Male,Male,Unknown,Male,"The inclusion of non-competition—or “public interest”—goals in merger control has gained traction in several competition jurisdictions. Such goals are particularly popular in developing countries—several of which have introduced antitrust legislation over the past 20 years. Yet non-competition objectives in merger control raise concerns, inter alia, about the predictability of merger adjudication. This paper evaluates these concerns in the context of South African merger control: a jurisdiction that assigns a particularly salient role to public interest considerations in merger review. Following the end of Apartheid, public interest considerations were embedded in the new South African merger control regime. The aim was to use competition policy—and merger control in particular—to help ad- dress deep social concerns that surround unemployment and inequality. Opponents have argued that including public interest considerations in South African competition policy may deter efficiency-enhancing mergers, economic growth, and employment creation. Furthermore, and of concern for this study, opponents have argued that public interest considerations in merger control may increase substantive and procedural uncertainty (OECD, 2016). The critics argue that the broad nature of public interest concerns may both increase the costs of merger assessment and create room for shifting interpretation (and possibly undue interference) over time. This paper aims to assess South African merger control by first studying the duration of merger adjudication for cases that involve public interest concerns. The duration of merger adjudication is of critical concern to investors and merging parties, and we show that the presence of public interest concerns in a merger case may double the duration of adjudication. Second, the paper investigates the probability of a merger’s receiving only conditional approval if it involves public interest concerns. As will be shown below, South African competition authorities appear to have turned increasingly to merger conditions specifically to address public interest concerns. We study changes in this probability of conditional merger approval over time and find not only that the probability is higher for public interest cases, but also that it has risen substantially in recent years. This suggests more aggressive merger control in South Africa over the sample period. The study relies on a newly compiled database of South African largeFootnote 1 merger decisions. As will be explained below, the compilation involved extracting information on merger and adjudication characteristics from publicly available records of the South African Competition Tribunal and Competition Commission. The compiled database covers the years 2006 to 2018. The paper is structured as follows: Sect. 2 provides a cursory review of public interest objectives in merger control in several jurisdictions, with an emphasis on Africa and South Africa in particular. Section 3 considers the limited extant research that involves systematic studies of merger control, with an emphasis on public interest concerns. Section 4 discusses the methodology, including: the data collection methods; sampling; and data analysis. Section 5 provides a descriptive analysis that highlights key features of the data, while Sect. 6 presents an econometric assessment of the link between duration, conditional approval, and public interest concerns. Section 7 concludes the paper.",
60.0,3.0,Review of Industrial Organization,05 November 2021,https://link.springer.com/article/10.1007/s11151-021-09841-y,The Assessment of Exclusive Contracts: The Competition Case Against Computicket in South Africa,May 2022,Liberty Mncube,Giulio Federico,Massimo Motta,Female,Male,Male,Mix,,
60.0,3.0,Review of Industrial Organization,18 November 2021,https://link.springer.com/article/10.1007/s11151-021-09850-x,Kenyan Competition Policy After Ten Years of the Competition Act: A Progress Report,May 2022,Robert Mudida,Thomas W. Ross,,Male,Male,Unknown,Male,"With the passage of the Competition Act in 2010, Kenya entered a new era in its evolution toward a more market-oriented economy. A modern competition law, an ambitious and resourced competition authority, and support from its government have made Kenya a leader in competition policy in Africa. It is clear to all in the field that the passage of a new competition law—in any country—is just the first step toward creating a new competition policy regime. There will inevitably need to be a great deal of education, advocacy, skills development, statutory amendments, guidance document development and, of course, enforcement actions including judicial decisions. With the passing of 10 years under the Act, we believe that this is an appropriate time for a review and stock-taking. These last 10 years have been a remarkable period for Kenya, and it is fair to say that the Kenya of 2020 is different from that of 2010. The country is absorbing enormous governance changes after the introduction of a new Constitution in 2010, which will devolve significant powers to county governments—a process that began in 2013. Expanded demand for government spending has increased the public debt to GDP ratio from 41% in 2013 to 62.4% by December 2019.Footnote 1 At the same time, the economy has continued to grow and achieved “low middle income status” (up from “low income”) in 2014. The average growth rate from 2010 to 2019 was approximately 5.8%; the gross domestic product (GDP) in 2019 was approximately US$95.5 billion.Footnote 2 The country also benefits from a relatively young population: 70% of Kenya’s population of approximately 47.5 million is under the age of 30.Footnote 3 Despite substantial overall growth, however, income inequality remains very high.Footnote 4 We make two additional observations that have relevance for the design and implementation of a competition law: First is the importance of agriculture and informal work in Kenya. In 2018 56% of employment was in agriculture.Footnote 5 The World Bank (2019a) also reports that 84% of workers are employed in the informal sector. These are areas with large numbers of small enterprises and from which data can be extremely difficult to secure—yet they represent large fractions of the Kenyan economy. Second, on the positive side, there is evidence that the Kenyan business environment has improved in important respects since 2010. In the “Ease of Doing Business” rankings of the World Bank (2020a), Kenya’s position has improved from 106th in 2010 to 56th in 2020. The key factors that contributed to the higher ranking included improvements in the ease of: getting construction permits; securing electricity; accessing credit; paying taxes; and resolving insolvency; and improved protections for minority investors. All represent promising developments toward providing the structural conditions that are needed to support competitive markets. Significantly, Kenya is currently negotiating a Free Trade Agreement with the United States. The Kenya-US Free Trade Agreement is expected to be based on the text of the United States-Mexico-Canada Agreement (USMCA) of 2018 and is expected to include an important chapter that is related to competition policy.Footnote 6 This illustrates the increasing status of Kenya in Africa and the perception of Kenya as a gateway to Africa in the global context. Deeper preferential trade agreements recognize the need to account for competition promotion as a fundamental tool to achieve the benefits of market access through trade. Our purpose in this paper is to evaluate the progress that has been made in Kenya with respect to its competition policy regime and to assess some of the challenges that lie ahead. We do this from the perspective of competition economists, and we readily admit that legal issues—for example, with regard to legal processes and constitutional alignment—will get little attention in this essay. We will describe the successes that we have observed and offer suggestions for improvements in legislation and enforcement that would further strengthen and modernize Kenya’s new approach. We believe that there are important insights to be derived from the Kenyan experience that can inform our understanding of how competition policy might need to function differently in a developing country context. As such there are lessons here for other countries in earlier stages of this process.Footnote 7 While our ambitions and approach here are related to those of the “peer review” studies that have been conducted by, most famously, the Organization for Economic Cooperation and Development (OECD) and the United Nations Conference on Trade and Development (UNCTAD), they differ in a number of ways:Footnote 8 Principally, we believe our perspectives as outside academic researchers provides a somewhat different lens through which we evaluate the success and challenges of Kenyan competition policy; this is less of an insider’s or practitioner’s view perhaps but one that is possibly more wedded to current research and thinking about the appropriate design and enforcement of competition policy.Footnote 9 We are also much more focused on economic aspects of competition policy here and less on legal and procedural elements.Footnote 10 We will not review the history that led to the 2010 Act, or provide a great deal of detail about its original contents. This has been covered in earlier work.Footnote 11 We will also not consider in any detail the consumer protection elements of the Competition Act—they deserve their own treatment. The next section will focus on the evolution of the Act from its beginnings to the present day—including amendments made as recently as 2019. Many of the early amendments were made to correct what were likely typographical errors or drafting oversights, while others have introduced important new elements: for example, new powers for the Competition Authority of Kenya (CAK) and new provisions on the abuse of buyer power. Section 3 examines the key competition policy intuitions that were created by the Act: the CAK and the Competition Tribunal. As the Tribunal has only very recently issued its first decisions, most of the attention here is on the CAK: We study changes in its size and budgets, and examine the activities it has undertaken. Chief among these activities are the cases that it has pursued; and, while space does not permit a detailed review of many cases, we discuss some important themes that have emerged. We review the evolution of the law and institutions in Kenya—not merely to record these histories but also to suggest directions for future progress, which will involve new methods of enforcement and possibly further legislative changes. In making such recommendations, however, we realize that we must always be aware of the different contexts in which competition policy works in different countries. Kenya’s experience suggests a number of ways in which competition policy might be called upon to be different in a developing country than in a developed one. Section 4 examines some of these differences. As will be clear from these earlier sections, there are a number of ways in which Kenya’s competition policy regime might be strengthened and brought into closer alignment with what competition economists might see as best-practices. Section 5 offers our suggestions. They do not generally represent criticisms of the current activities of the CAK; indeed, addressing most could require further legislative amendments. Section 6 offers a few concluding remarks.",
60.0,3.0,Review of Industrial Organization,22 January 2022,https://link.springer.com/article/10.1007/s11151-022-09858-x,Competition and Regulation of Mobile Money Platforms in Africa: A Comparative Analysis of Kenya and Uganda,May 2022,Anthea Paelo,Simon Roberts,,Female,Male,Unknown,Mix,,
60.0,4.0,Review of Industrial Organization,08 February 2022,https://link.springer.com/article/10.1007/s11151-022-09855-0,The Welfare Effects of Licensing Product-Differentiating Technology in a Commodity Market,June 2022,H. Phoebe Chan,,,Unknown,Unknown,Unknown,Unknown,,
60.0,4.0,Review of Industrial Organization,26 January 2022,https://link.springer.com/article/10.1007/s11151-021-09852-9,Environmental Policy as a De Facto Industrial Policy: Evidence from the Japanese Car Market,June 2022,Taiju Kitano,,,Unknown,Unknown,Unknown,Unknown,,
60.0,4.0,Review of Industrial Organization,21 April 2022,https://link.springer.com/article/10.1007/s11151-022-09869-8,"Vertical Opportunism, Bargaining, and Share-Based Agreements",June 2022,Emmanuel Petrakis,Panagiotis Skartados,,Male,Male,Unknown,Male,"The anti-competitive effects of vertical common ownership have recently raised a vivid discussion (Azar et al., 2018), and have puzzled the competition authorities in both sides of the Atlantic (Council of Economic Advisers, 2016; OECD, 2017).Footnote 1 It is a fact that the implied common ownership of the S&P500 index firms has more than tripled from 1980 to 2017 (Backus et al., 2021). Besides its traditional form, vertical common ownership may evolve as a result of share-based agreements (SBAs) among firms along the supply chain. An SBA is a payment in a firm’s shares to its supplier for purchased goods or services. In practice, SBAs appear in numerous variations and are influenced by taxation and the firms’ internal organizations (KPMG, 2018).Footnote 2 The scope of our research is twofold: The first is to study the effects of SBAs in contrast to other common non-linear vertical contracts, such as two-part tariffs (TPTs), under alternative supply-chain structures; and through this, to underline the importance of the supply-chain ownership structure for market outcomes and welfare. The second is to highlight potential policy implications. In our base model, we consider an upstream monopolist that supplies an essential input to downstream horizontally differentiated Cournot duopolists. The firms play a two-stage game with secret actions. In stage 1, the vertical contract terms are subject to simultaneous and separate negotiations between each downstream firm and the upstream supplier. Negotiations take place either over a TPT (which is composed of a wholesale price plus a fixed fee), or an SBA (which is composed of a wholesale price plus a share of the downstream profits that is designated for the upstream supplier).Footnote 3 In stage 2, the downstream firms compete à la Cournot. We show that in our setup with no uncertainties, though both SBAs and TPTs are intended to address potential double-marginalization problems, the two vertical contracting arrangements are non-equivalent.Footnote 4 The driving mechanism is that SBAs mitigate the well-known upstream monopolist’s commitment problem (Hart & Tirole, 1990): They enable the upstream supplier partially to restore its monopoly power and set wholesale prices above marginal cost. Intuitively, a downstream firm anticipates a less opportunistic behavior from the monopolist supplier, because the downstream firm knows that the supplier cares about that firm’s gross profits—part of which will be transferred upstream via their SBA. This creates a contractual externality that leads to higher retail prices, and lower aggregate output, consumer surplus, and total welfare.Footnote 5 Moreover, we show that the upstream supplier prefers SBAs since the latter alleviate its commitment problem, and thus it enjoys higher profits than under TPTs. Downstream firms prefer TPTs because they induce higher profits for the downstream firms. Even though competition authorities usually avoid micro-regulations, it might be useful to consider the welfare implications of the wide usage of SBAs in vertically related markets. The SBAs may lead to an indirect increase in common ownership and eventually to welfare losses. To check the robustness of our main findings, we extend our analysis to price competition in the downstream market, as well as to vertical contracts with interim observable terms. We show that our non-equivalence result remains robust so long as there is a bottleneck in the upstream market. However, under exclusive dealing between multiple upstream suppliers and downstream firms, TPTs and SBAs turn out to be equivalent in all respects. The remainder of the paper proceeds as follows: Sect. 2 provides a literature review. Section 3 describes our base model. Section 4 establishes the non-equivalence result. Section 5 extends our analysis in a few dimensions. Section 6 offers concluding remarks.",
60.0,4.0,Review of Industrial Organization,13 February 2022,https://link.springer.com/article/10.1007/s11151-022-09853-2,On the Effects of Raised Rival’s Costs,June 2022,Sreya Kolay,Rajeev K. Tyagi,,Unknown,Male,Unknown,Male,"It is commonly believed that a firm gains a strategic advantage and improves its profitability from an increase in its rival’s costs: that an increase in the rival’s costs forces the rival firm to raise its price or reduce its output, which yields a competitive advantage to the competing firm. Such an increase in the rival’s costs could arise from exogenous reasons, or from firm strategies that aim to increase profits through raising rivals’ costs (Salop & Scheffman, 1983; Salop, 2006). Some examples of such raising rivals’ cost strategy include: firms’ influencing industry standards so as to disadvantage rivals that have different technological strengths (Anton & Yao, 1995); a downstream firm’s backward or forward integrating to force its rivals to switch to a more costly source of input or of distribution (DeSanti, 2000); using patents to force rivals to use more expensive technology (Rubinfeld & Maness, 2005); and firms’ hiding information from competitors (Mandy et al., 2016). A few papers also show circumstances where an increase in a rival’s costs can hurt a firm. Sibley and Weisman (1998) demonstrate that a vertically integrated firm that competes downstream with other firms may lose from an increase in its downstream rivals’ costs. The rationale is that the cost increase reduces the downstream rivals’ demand for the essential input that they buy from the integrated firm. Pawlina and Kort (2006) show that an increase in the investment cost of a rival firm can hurt the focal firm by making it switch from a later investment to a preemptive investment. We add to this literature by studying the effects of a rival firm’s cost increase on a firm’s profitability in a vertically differentiated market with endogenous product qualities. Here an increase in a rival’s cost may make it optimal for the rival to decrease its product quality and bring it closer to the focal firm’s product quality. This then creates two opposing forces for the focal firm in the ensuing price competition: While the firm benefits from a reduction in its rival’s price competitiveness as a consequence of the rival’s cost increase, the focal firm is disadvantaged from the reduction in the gap in product qualities that is caused by the rival’s cost increase. Our contribution is in showing the conditions under which these opposing forces net out such that the focal firm gains/loses. Our main results are as follows: In duopoly markets where producing a higher-quality product requires a higher fixed cost (e.g., pharmaceuticals, software products), an increase in a high-quality firm’s cost may decrease the (rival) low-quality firm’s profit or leave the latter firm’s profit unchanged. This result depends on whether there is an outside option for consumers (i.e., whether the market is fully covered). In markets where the production of a higher-quality product requires a higher variable cost (e.g., automobiles, computers), an increase in the higher-quality firm’s cost may increase or decrease the lower-quality firm’s profit. The decrease happens when: (i) the high-quality firm is sufficiently relatively more efficient in quality production; and (ii) consumers are sufficiently heterogeneous in their marginal valuations of product quality. Finally, we show when consumer surplus may increase from a firm’s cost increase.",
60.0,4.0,Review of Industrial Organization,17 February 2022,https://link.springer.com/article/10.1007/s11151-022-09859-w,Unilateral Effects of Mergers that Enhance Product Quality,June 2022,Bertram Neurohr,,,Male,Unknown,Unknown,Male,"The topic of ‘mergers and innovation’ has received significant attention following the European Commission’s investigation of the 2017 Dow/DuPont merger.Footnote 1 At the centre of that debate is the question whether a merger is likely to increase or decrease incentives to invest in cost-reducing or quality-enhancing R&D. Starting with Federico et al. (2017, 2018) and Motta and Tarantino (2018), a number of academic articles have focused on this topic.Footnote 2 In addition to this ‘mergers and innovation’ literature there is the ‘merger efficiencies’ literature, to which the present paper belongs. Rather than looking at the impact of a merger on incentives in relation to endogenous cost- or quality-related R&D expenditures, the ‘merger efficiencies’ literature looks at merger-specific marginal cost reductions or quality enhancements and the extent to which these counteract the competition-reducing effects of a merger. In the merger efficiencies literature the efficiencies are taken to be exogenous—except for their merger-specificity. On the cost side of merger efficiencies a particularly important contribution is due to Werden (1996), who showed that the critical efficiency levels or ‘compensating marginal cost reductions’ (CMCRs) that are required to offset the competition-reducing effect of a merger can be calculated as a function of margins and diversion ratios. The result does not require particular demand or cost functions. Neurohr (2019) showed that CMCRs can be interpreted as gross upward pricing pressure with feedback effects,Footnote 3 and that linear merger simulations are simply the application of post-merger pass-through rates to CMCRs.Footnote 4 The earlier linear merger simulation by Hausman et al. (2011) did not make this connection to Werden, although it can be seen directly upon inspection of their result. On the quality side of merger efficiencies, Willig (2011) used a hedonic price model to derive a quality-adjusted GUPPI. This paper exploits the fact that quality improvements in Willig’s hedonic model have the same effect as marginal cost reductions.Footnote 5 This means that in the hedonic model the above results from the cost side of the merger efficiencies literature carry over one-to-one to the quality side. In particular, CMCRs do not apply merely to actual marginal cost reductions but to the sum of actual marginal cost reductions and the implied marginal cost reductions that result from the quality improvements.Footnote 6 Similarly, as the cost pass-through rates apply to quality, quality efficiencies can also be readily incorporated into linear merger simulation. This results in surprisingly simple formulas for nominal and hedonic merger-specific price changes. Thus, in addition to incorporating quality and hence extending the previous work by Hausman et al. (2011) and Neurohr (2019), owing to relatively small differences in the setup the results presented here are also more concise and intuitive than the results that were presented in these earlier papers. Willig notes that his analysis—and thus, by implication, the present analysis—applies in differentiated product markets that feature fixed R&D and design costs, and his model has been applied in empirical investigations of airline mergers.Footnote 7 Logistics and transport in general, telecoms, and financial markets are all candidate areas of application of the present analysis—given the potential for quality enhancements as a result of merger-specific increases in fleet sizes, infrastructure networks, and liquidity, respectively.",
61.0,1.0,Review of Industrial Organization,25 May 2022,https://link.springer.com/article/10.1007/s11151-022-09872-z,Doubling Back on Double Marginalization,August 2022,Laurent Linnemer,,,Male,Unknown,Unknown,Male,"Nowadays, the catch-phrase “double marginalization” (DM) is used widely by IO economists and antitrust scholars. For example, in the recent revision of the U.S. Vertical Merger Guidelines,Footnote 1 which is only 12 pages long, it is mentioned 19 times. Indeed, the question of the “elimination of double marginalization” (EDM) is central to these guidelines.Footnote 2 Yet, it seems impossible to find the DM or EDM expressions in the economic literature before the early 1980s, and the first papers in which it appears in print are Mathewson and Winter (1983a, 1983b), Mathewson (1984). All three articles were written at about the same time, between 1980 and 1983. In Mathewson and Winter (1983a) which was presented at the Western Economic Association Meetings in San Francisco in 1981, the authors refer to “the classic ‘double mark-up’.”Footnote 3 In Mathewson and Winter (1983b), they definitely use the DM expression, as they also do in Mathewson (1984).Footnote 4 Mathewson and Winter write: “The first explanation of this over-pricing effect is attributed to Spengler (1950).” In Spring 2021, Ralph Winter wrote to me: I am sure that the term double marginalization was first uttered in the halls of the Chicago econ department. Frank and I certainly did not originate the term. We had a lot of Chicago colleagues, and maybe heard it from them. But I think that by the 70s the term was in common use. People referred to the ‘oral tradition’ at Chicago (Aaron Director, for example), so this seems to be the origin.Footnote 5 After Mathewson and Winter, the association of DM/EDM with Spengler is found in Rey and Tirole (1986), Bolton and Bonanno (1988), and Tirole (1988).Footnote 6 From then on, these expressions became increasingly popular. Most of the time, they remained linked to Spengler.Footnote 7 I take a fresh look at the origin of DM and EDM, and thereby challenge the emphasis on the role of Spengler. First, DM is not confined to vertical relationships. In Sect. 2, I recall its link to complementary goods or services. Since such goods and services abound in the economy, the DM phenomenon turns out to be much broader.Footnote 8 Next, in Sect. 3.1, the results of Cournot (1838) on the simultaneous pricing of complementary goods are presented, and in Sect. 3.2 the sequential version—first exposed by Edgeworth (1897)—is detailed. Sequential timing is usually retained in the modelling of a vertical structure. Simultaneous timing has been used to analyze compatibility by Economides (1989) or to analyze a patent pool, see Shapiro (2000) and Lerner and Tirole (2004). Section 3.3 compares equilibrium prices under both timings. Through an example, I show that when demand is convex enough, prices can be larger for the simultaneous timing. Otherwise, and in particular, for a linear or concave demand, prices are higher when timing is sequential. Section 4 gives a historical perspective and underlines that Cournot’s chapter IX was confined to the bilateral monopoly strand of the literature in the mid 20th century when Spengler wrote his article.",1
61.0,1.0,Review of Industrial Organization,10 February 2022,https://link.springer.com/article/10.1007/s11151-022-09860-3,Competition and Fan Substitution Between Professional Sports Leagues,August 2022,Tim Wallrafen,Georgios Nalbantis,Tim Pawlowski,Male,Male,Male,Male,"Competitor identification is an important task for any company with competitive threats that arise from substitutability either on the supply or the demand side. Moreover, it is important for clearly defining markets—which, in turn, is crucial for developing antitrust and regulatory policies in any industry (Bergen & Peteraf, 2002). Accordingly, the analysis of substitutability has already some tradition in empirical economic research (e.g., Kalnins, 2003; Stigler & Sherwin, 1985). A peculiar case in this regard is professional sports. On the one hand, leagues regularly hold monopoly power within their sports (for a discussion see Vrooman, 2009). On the other hand, they may well compete for broadcasting revenues, sports ownership, or fan interest with leagues in other sports. In fact, already in 1982, the U.S. Circuit Court of Appeals (670 F.2d 1249) found the National Football League (NFL) ban on cross-ownerships to be anticompetitive. This was based on the argument that the ban restricts teams in other sports—in this case North American Soccer League (NASL) teams—from sports ownership capital.Footnote 1 However, whether and to what extent leagues indeed compete across sports, is relatively unexplored. The few existing studies that previously looked at competition and fan substitution across sports exclusively focused on the North American market where selection issues are present. Most notably, the franchise system enables leagues to limit or even avoid any competition across sports within the same region. Moreover, most of these studies only offer limited evidence given the rough substitution measures that were employed. By using game-level attendance data for the top-tier German leagues in handball, basketball, and ice hockey, we analyze the effect on these leagues of top-tier football (soccer) games that are played concurrently in Germany. We contribute to the literature in two ways: First, we analyze competition and fan substitution in a European setting, where the implemented promotion-and-relegation system makes it impossible for leagues to take full control over the team-league-allocation in a given league. Moreover, professional football dominates by far all other sports (see Buzzacchi et al., 2010) and thereby constitutes a practically highly relevant case to explore. This dominant position has raised serious concerns among league officials and managers in other sports, who have recently claimed that their teams suffer from an intensified competition for fan interests – particularly in Germany.Footnote 2Second, we depart from previously implemented substitution measures and explicitly test whether substitution can be observed even for games that are not played concurrently but are played a few days before or after. Overall, our findings suggest that scheduling overlaps with nonlocal and local football games have a sizeable negative impact on the demand for games in other sports leagues. Moreover, we provide some evidence for the relevance of intertemporal time and budget constraints since substitution effects are also evident within a few days before or after football games take place. The remainder of the paper is as follows: The following section provides the theoretical background and discusses the related literature. The third section presents some relevant background information on the organizational and financial structures of the professional sports leagues and outlines the empirical strategy that we employ. The fourth section presents the findings of this study. The fifth section concludes.",2
61.0,1.0,Review of Industrial Organization,10 April 2022,https://link.springer.com/article/10.1007/s11151-022-09864-z,Competition Makes Inspectors More Lenient: Evidence from the Motor Vehicle Inspection Market,August 2022,Osmis Areda Habte,Håkan J. Holm,,Unknown,Male,Unknown,Male,"Under intense competition, firms’ risk of losing customers to rivals will increase. When car owners have greater choice among inspection stations for state-mandated inspections, the car owners may prefer the station that provides the most leniency. Due to the potential to steal market share from rivals, a competitive inspection service provider has stronger incentives to provide leniency to attract customers than would a monopoly provider. Increased competition thus incentivizes an inspection station to deviate from what is socially desirable. In this paper, we examine the impact of competition among inspection providers on the incidence of leniency toward customers in the Swedish car inspection market. The Swedish car inspection market is particularly interesting to analyze since it has intentionally been designed with concern about the distorted incentives that competition could create. For instance, if the inspecting firm sells other services (such as car repairs), it can “trade” a passing result (regardless of actual car condition) for the side payment of a valuable future stream of other services (e.g., repairs). To remove such obvious distorting incentives, Swedish car inspection firms are not permitted to engage in other businesses. Firms are also free to set their own prices based on market conditions. The Swedish car inspection market is also interesting since Sweden belongs to the set of countries with the strongest adherence to the rule of law.Footnote 1 Hence, it may be that in countries where laws and regulations are expected to be followed, the implementation of regulations can avoid side-effects that are present in countries where the adherence to the rule of law is lower. This also means that if side-effects are present in countries where the institutional structure that surrounds the inspections are designed to remove distorting incentives, then it is an indication that more regulatory efforts are required to avoid the side-effects. The car inspection market in Sweden also provides us with a unique and high-quality panel dataset at the station level, which allows us to study carefully the effect of competition on inspection pass rates. The data represent all car inspections (22.5 million) that were conducted in Sweden from July 2010 to August 2015. Furthermore, we use individual-level data that contain the addresses of car owners and the respective station that each owner chose, so as to measure travel distances, which are used to approximate geographic markets and, thus, the number of competitors of each station. To examine the connection between competition and inspection pass rates, we start with a simple correlation analysis and find a positive association between local competition and pass rate. To address the possibility that this positive correlation is confounded by omitted factors, we first control for station-specific factors that affect both competition and pass rate. After controlling for station fixed effects, we find that competition has a positive and significant effect on the probability for a given car to pass mandatory inspection. We also use instrumental variables regressions with population size at a municipality level as the instrument for competition. Our results show that local competition has a significant positive effect on the inspection pass rate and is robust to different specifications. The rest of the paper is organized as follows: Section 2 presents a literature review of the research area. We then (in Sect. 3) introduce a simple theoretical model to illustrate the mechanism through which competition affects pass rates. Section 4 describes the data; it defines geographic markets; and it also provides an overview of the car inspection market in Sweden. Section 5 presents the specification of the model and estimation strategies. Section 6 shows our main results. Section 7 provides a sensitivity analysis. Section 8 presents the conclusion.",2
61.0,1.0,Review of Industrial Organization,28 March 2022,https://link.springer.com/article/10.1007/s11151-022-09866-x,Copyright Protection in the Digital Single Market: Potential Consequences for Content Platform Competition,August 2022,Frank Stähler,Leander Stähler,,Male,Male,Unknown,Male,"In this paper, we scrutinize the new role of collective management organizations (CMOs) as a result of the new Directive on Copyright in the Digital Single Market (CDSM).Footnote 1 The EU Collective Management Directive (CMD) defines CMOs as organizations that manage the intellectual property rights of rightholdersFootnote 2. Importantly, they are representative for all rightholders of a domestic industry as long as an individual rightholder does not opt out. Under the CDSM, Online Content-Sharing Service Providers (OCSSPs) are required to have the consent from rightholders of protected content or should have an agreement with CMOs. OCSSPs are content platforms that are a “...provider of an information society service whose main or one of the main purposes is to store and give the public access to a large amount of copyright protected works or other protected subject-matter uploaded by its users ...” (Art. 2, Sect. 5). This affects not only Facebook, YouTube and Instagram but any forum that is financed by advertisements, and includes any content upload. We will scrutinize the potentially anti-competitive effects of the CDSM Directive. While it can be expected to increase the share of the surplus that accrues to the CMOs, we show that the CDSM Directive may increase the market power of a strong content platform, even if the CMO does not in principle refuse to license to other content platforms. If a license agreement is profitable only for a large platform, small-scale content platforms may have to make provisions so that copyright-protected content is not uploaded, which will reduce their platform benefit. We show in particular that a most-favored-customer (MFC) provision – which is part of the CDSM Directive – may make an alliance of a CMO with a single, large content platform stronger, while also reducing aggregate welfare. Our results will not depend on the specific type of contracts that are offered by the CMO, as long as the MFC provision guarantees that both platforms are offered the same menu of contracts. Our analysis contributes to the literature on platform competition in media markets, and many papers have investigated their performance in two-sided markets.Footnote 3 We focus on the network externality of media markets, and we do so to be able to investigate the role of the CMO as a monopolist that controls an intangible asset that contributes to the quality of the platform. In this respect, our analysis is close to papers that consider the role of quality in media markets.Footnote 4 However, in these papers, quality provision is an endogenous choice of a platform; in our case, it is the CMO that either has a contractual arrangement with a platform or not. At least in the short run, the size and quality of these assets are given.Footnote 5 Our paper also contributes to the literature on exclusion, and part of this literature deals with licensing in vertical product markets and considers the trade-off between exclusion and non-exclusion (see Li and Wang 2010). While potential exclusion has been extensively discussed in the literature in different contexts (see, for example, Motta 2015 Chapter 7), there is no analysis yet on the role of CMOs as representatives of rightholders vis-à-vis content platforms. This paper fills this gap. There is also a substantial literature on the role of intellectual property rights in digital markets due to the non-rival nature of digital information – in particular on the music industry (see, for example, Section 4.3 in Goldfarb and Tucker (2019), and the cited literature). An older literature has scrutinized the role of CMOs. This literature regards CMOs as natural monopolies due to decreasing average costs of managing content.Footnote 6 In our context, CMOs are de facto monopolists. There is also a similarity of our analysis with the analysis of media platforms that hold exclusive broadcasting rights – for example, for sport events (see Gratton and Solberg 2007). Copyright protection is not an issue in this case as the platform has acquired the broadcasting rights. The difference for our paper is that the CDSM Directive deals with content platforms that allow users to upload potentially copyright-protected content. We now present the key features of the CDSM Directive that are relevant for our analysis. Arguably, no other intellectual property right (IPR) discussion has stirred the EU as much as the CDSM. Critics accuse it of threatening internet freedom, or even imposing a form of censorship (see Stolton 2019), whilst proponents see it as an important step in ensuring the protection of IPR in the digital world (see European Commission 2019). Central to this discussion has been the so-called “upload filter” that content platforms may use to control online content. These upload filters are seen as a restriction of internet freedom because their algorithm may also block content that is not violating IPRs. More importantly for our analysis, the CDSM Directive imposes a burden of proof on a content platform that it has sought an agreement with rightholders for any kind of content that may be uploaded by the platform’s users. Under Art. 12 of the DSM Directive,Footnote 7 Member States may grant CMOs a presumed mandate as rightholders; this effectively elevates them to a one-stop-shop for certain authorizations and makes them de facto monopolists in certain European markets. Subject to this legislative option, content platforms of all sizes will need to seek authorization from CMOs for communications to the public.Footnote 8 The difficulty to monitor the detailed content that is uploaded by users implies so-called blanket licenses such that any agreement will allow users of the platform to use all content managed by the CMO, and not only part of it. Blanket licenses are universal in these markets, also because it is impossible or at least very costly to control for content selection in digital markets.Footnote 9 Furthermore, the CMD Directive imposes a most-favored-customer (MFC) provision:Footnote 10 Any offer, or any set of offers, must be made to all platforms. This MFC rule is very similar to a ban on price discrimination as it does not allow platforms to charge different blanket license fees to different platforms. Usually, these bans are introduced as a measure to guarantee “fairness”, and the CMD Directive is no exception. While the CDSM Directive is one of the first legal frameworks in this context, the political debate has gained momentum in other countries – in particular in Australia and the US.Footnote 11 Australia has introduced legislation under which Facebook and Google have to compensate media outlets for news content that they use. Also in the US, there is a growing concern that these platforms do not compensate media outlets properly. In response to a study by the News Media Alliance that claims that Google made USD 4.7 billion by using news content of media outlets for free,Footnote 12 the US Congress has introduced a bill that would grant news publishers an antitrust exemption for four years. They would be allowed to negotiate collectively with content platforms about models of compensation and revenue sharing which would put them in a similar position as the CMOs in Europe.Footnote 13 Google and Facebook have responded to this bill that they are merely redirecting to media outlets, and that those media outlets actually benefit from this. Taken together, an analysis is required that scrutinizes the role of CMOs as monopolists that potentially sell blanket licenses to content platforms under an MFC provision. Consequently, the remainder of this paper is organized as follows: Section 2 develops a Hotelling model of content platform competition that is extended to include network externalities and the benefits for users if they have access to licensed content that is controlled by a CMO. Section 3 shows how the CDSM Directive may lead to substantial industry concentration, and section 4 scrutinizes the effect on aggregate welfare. Section 5 concludes.",
61.0,1.0,Review of Industrial Organization,16 February 2022,https://link.springer.com/article/10.1007/s11151-022-09861-2,Effects of Policy Reforms on Firm Innovation,August 2022,Murat Şeker,Mehmet Fatih Ulu,,Male,Male,Unknown,Male,"The regulatory environment in a country plays an important role in the success of technology adoption strategies and innovative efforts. This paper studies the effects of India’s delicensing reform in the 1980s and 1990s on firms’ innovation performances.Footnote 1 Before the reform, firms were required to obtain a license to establish a new factory, significantly expand capacity, start a new product line, or change location. Delicensing reform led to freedom from constraints on the choice of output, use of inputs and technology, and facilitated location choice. The reform allowed firms to take advantage of economies of scale, allocate inputs more efficiently, and use newer technologies. This study shows that the delicensing reform in India increased the product innovation rate by eight percentage points within the first two years following the reform. In our analysis, we use a novel firm-level panel dataset that allows us to observe product-level information for each firm. We measure innovation through the introduction of new product varieties. We also use real sales as an alternative proxy for firms’ innovative output. Our empirical analysis yields a strong, positive impact of delicensing reform on innovation and sales growth. In the empirical framework, we compare the product growth of firms that were in recently delicensed industries with those firms that were delicensed earlier. Using the panel nature of our data, we introduce firm-level fixed effects and compare the innovation performance of the two groups using the difference-in-difference methodology. We also introduce several industry-level control variables such as input tariffs, output tariffs, and foreign direct investment exposure to control for other potential factors that could affect the innovation performance of firms. These additional variables also help control for other policy reforms that took place during the time of our analysis. We further investigate whether any particular subgroup of firms in the dataset such as export-oriented firms could drive the results. Our estimation results are also robust to using alternative specifications and different estimation methods. The product growth rates of firms in recently delicensed industries reach growth rates that are observed in the control group in about two years after reform. Although the theoretical and empirical literature on innovation is rich, it is a demanding task to measure innovation empirically. Most of the existing studies on innovation proxy it with patenting activity, the number of patent citations received, labor productivity, total factor productivity (TFP), or data from innovation surveys.Footnote 2 The innovation measure that we use is the introduction of a new product variety by a firm. The use of such a direct measure of innovation differentiates this study from most of the existing work in this field with firm-level datasets. Although patent data could provide a good measure of innovation as compared to innovation survey data or TFP estimates, patent data are usually available for a small set of firms. Moreover, in developing countries, the patent recording mechanism might not work efficiently. Thus, such data allows a limited analysis of innovation performance. An alternative proxy for the innovative outcome—TFP—measures firm performance as a residual of production function estimations. Although TFP or labor productivity are commonly used measures of firm performance, they can reflect innovation output only indirectly. Moreover, the assumptions as to the shape of the production function, the prices of outputs, and the use of inputs make it difficult to estimate TFP. The remainder of this paper is organized in the following sections: In Sect. 2 we provide a brief review of the literature. Section 3 outlines the relevant reforms in India that affect the results of this study. Section 4 describes our estimation methodology. Section 5 discusses the data, while Sect. 6 presents the main results. In Sect. 7, we provide a set of robustness tests. In Sect. 8, we provide concluding remarks.",
61.0,2.0,Review of Industrial Organization,27 April 2022,https://link.springer.com/article/10.1007/s11151-022-09868-9,The Pricing Structure of Legal Services: Do Lawyers Offer What Clients Want?,September 2022,Flóra Felső,Sander Onderstal,Jo Seldeslachts,Female,Male,,Mix,,
61.0,2.0,Review of Industrial Organization,27 April 2022,https://link.springer.com/article/10.1007/s11151-022-09870-1,Product Liability and Strategic Delegation: Endogenous Manager Incentives Promote Strict Liability,September 2022,Tim Friehe,Cat Lam Pham,Thomas J. Miceli,Male,,Male,Mix,,
61.0,2.0,Review of Industrial Organization,09 April 2022,https://link.springer.com/article/10.1007/s11151-022-09867-w,"Deregulation, Entry, and Competition in Local Banking Markets",September 2022,Paolo Coccorese,Alfonso Pellecchia,,Male,Male,Unknown,Male,"The relationship between banking market structure and competitive forces has been an intriguing and persistent topic in the economic literature—especially with respect to highly concentrated markets (for example, local areas). In contestable markets, entry and exit are costless because of low or absent barriers; hence, there are no sunk entry costs, and potential competition may make the market perfectly competitive regardless of its concentration. More often, concentration results from the presence of entry barriers for new banks, with important implications in terms of antitrust and policy debates on the need and importance of competition among banks. In this study, we apply the empirical entry threshold model of Bresnahan and Reiss (1991) to the Italian banking sector in four different years—1981, 1991, 2001, 2011—that cover a wide period of noteworthy structural and regulatory changes. This model is a consolidated tool for analyzing industries with several geographically independent local markets, so we employ it for analyzing the behavior of all categories of Italian banks, which normally compete at the local level across Italy. The model allows the estimation of entry thresholds—the minimum number of customers that are needed to open a new bank or branch—without needing any information about banks’ prices and costs. We regard our investigation as a valuable contribution for assessing the impact of deregulation on banks’ behavior in Italy. We provide evidence on the changes in their conduct in a long-run perspective—30 years—through the use of a different econometric technique than those that have been employed in the existing studies. Moreover, we focus on the lowest possible level of geographic aggregation—municipalities (which are the smallest administrative division in Italy with own government), that represent our unit of observation—so as to capture meaningful specific—and otherwise neglected—characteristics of local markets. As background, in Italy local banking markets are mostly monopolies or oligopolies: In 2011, 33.6% of banked municipalities had just one bank (53.4% in 1981), and 22.2% of them had just two banks (20.3% in 1981).Footnote 1 Focusing on the Italian case is also important because we can obtain evidence on how the changes in regulation—which occurred in the past few decades—have affected the competitive forces and behavior in local banking markets; we thus shed light on banks’ reactions to changing environments. The determinants of the number of banks that operate in local markets—as well as the relationship between the number and conduct of banks in a market—are crucial questions also for other European countries that share with Italy the structural transformations that followed the European Directives for the creation of a single European banking market. Hence, our approach might be applied to those countries’ banking industries as well. The estimation results reject any evidence of collusive behavior among banks for all years, since the per bank entry thresholds gradually increase with the number of operating banks. This means that an additional bank needs a larger clientele in order to achieve long-run profitability. However, such thresholds fall with time, which implies that deregulation has made entry in local markets easier. Besides, banks’ variable profits are higher in monopolistic markets, decreasing in the number of banks but increasing with time, while fixed costs rise with the number of competitors. The latter trends are compatible with the presence of endogenous sunk costs (Sutton, 1991): Banks raise their provision of quality in order to increase consumers’ willingness to purchase, despite the banks’ higher fixed costs. The analysis is structured as follows: Sect. 2 sketches the evolution of the Italian banking sector, while Sect. 3 illustrates the Bresnahan-Reiss approach to the analysis of entry and competition in local concentrated markets; we also review some empirical studies that have made use of this methodology. Section 4 describes our empirical model; the data and estimation technique are presented in Sect. 5. Section 6 discusses the econometric results, and Sect. 7 provides some conclusions and policy recommendations.",
61.0,2.0,Review of Industrial Organization,30 March 2022,https://link.springer.com/article/10.1007/s11151-022-09865-y,"Entry Deterrence, Concentration, and Merger Policy",September 2022,Gopal Das Varma,Martino De Stefano,,Male,Male,Unknown,Male,"Entry plays an exculpatory role in horizontal merger investigations. It is considered to be a factor that potentially can discipline otherwise anti-competitive incentives that are created by a merger. Accordingly, in mergers that are considered to pose competitive concerns, the U.S. antitrust agencies evaluate whether entry will be likely, timely, and of sufficient magnitude as to discipline post-merger exercise of market power.Footnote 1 Several factors are analyzed to determine the incentives and ability of potential entrants to enter the market, including—importantly—whether there historically has been entry at times of elevated industry profits.Footnote 2,Footnote 3,Footnote 4 Missing from merger reviews is the notion that the likelihood of entry depends not only on whether a market is profitable enough to attract entry but also on the extent to which incumbent firms can proactively create entry barriers. In this article, we explore the effect of mergers on incumbent incentives to create entry barriers. Our main result is that a merger can increase the strategic investments that are made by incumbents towards entry deterrence and thus potentially reduce the likelihood of entry relative to pre-merger. The intuition for the result is straightforward: Except for the case in which the incumbent is a monopolist, entry deterrence is a public good amongst incumbents. (See the discussion of the literature with regard to non-cooperative entry deterrence in the following sub-section). As a result, incumbents have the incentive to free-ride on each other’s efforts to deter entry. A merger between two incumbents increases the merged entity’s contribution to the public good of entry deterrence in two ways: First, it eliminates free-riding between the merging firms. Second, a profitable merger—one in which the merged entity’s profit exceeds the combined pre-merger profits of the merging firms—further increases the merged entity’s private benefit from deterring entry. Both effects lead to an increase in post-merger investment in entry deterrence. The increased profitability of non-merging firms following a merger also serves to increase their private benefit from entry deterrence, which leads them to increase their entry deterrence investments as well. Our results have at least two important implications: First, a merger can reduce the likelihood of future entry even if it is not assessed to create traditional competitive concerns such as a price increase or quality reduction. As such, the likelihood of entry should not just be a mitigating factor for mergers that pose competitive risks. The effect of a merger to reduce the likelihood of future entry—entry that would have made the market more competitive relative to status quo—may be considered as a theory of harm in its own right. Second, a merger can, by itself, heighten entry barriers, which makes historical evidence of entry to be a questionable predictor of the likelihood of post-merger entry. There is a well-developed literature in economics—both theoretical and empirical—that examines non-cooperative incentives of incumbent firms to deter entry proactively.Footnote 5 Although individual firms can choose how much to invest in entry deterrence, the benefit from successful entry deterrence is enjoyed by all incumbents regardless of the level of their individual investments. Non-cooperative entry deterrence is thus a public good that can lead to under-investment relative to the industry profit-maximizing level (“optimal level”). The level of investment in entry deterrence is optimal (from the point of view of the incumbents) if the market is a monopoly in which case successful entry deterrence is not a public good but a private benefit to the monopolist. For purposes of this paper, an important distinction in the theoretical literature is related to whether the total investment that is required to deter entry is deterministic or uncertain. Bernheim (1984) and Gilbert and Vives (1986) consider environments with complete information and show that the free-rider problem does not cause incumbents to underinvest in entry deterrence. In contrast, Waldman (1987) shows that if the result of entry deterrence is uncertain, then, for certain investment technologies, incumbents may underinvest. There are a variety of strategies that incumbent firms can use to discourage entry. Such strategies can include: lobbying the industry regulator or legislators to enact rules that hinder entry (Stigler, 1971); limit pricing to signal lack of profitability to potential entrants (Sweeting et al., 2020); introducing additional varieties of product with the goal of crowding up the product space and denying entrants a foothold in the market (Berry & Waldfogel, 2001; Scherer, 1979; and Schmalensee, 1978); and spurious innovations to leave potential entrants seemingly behind in the race to develop newer technologies (Gilbert & Newberry, 1982).Footnote 6,Footnote 7 Each of these deterrence strategies involves costly (sunk) investments by incumbents. For example, lobbying an industry regulator entails lobbying expenditures; limit pricing involves setting a price that is below the profit-maximizing price level without the prospect of entry; cluttering the product space requires investments to introduce additional varieties that a profit maximizing incumbent may not have incurred except to deter entry; etc.Footnote 8 Since writing the first version of our paper, we have become aware of a working paper by Cowgill et al., titled “Political Power and Market Power” (2021), which explores the relationship between industry concentration and political lobbying. There are similarities and differences between our paper and Cowgill et al.: An important contribution of the latter is that it establishes empirically that an increase in industry concentration leads to greater political lobbying effort by incumbents, by employing mergers as shocks to industry concentration. Their paper further shows that this is consistent with a theoretical model in which the public good nature of political lobbying causes mergers to reduce the extent of free-riding between incumbents. Our paper focuses more closely on the entry deterrence effect of mergers with regards to its policy implications for merger enforcement. Among other things, we show that mergers which are not anti-competitive by traditional measures may, under certain circumstances, reduce the likelihood of future entry. We also derive sufficient conditions under which a merger between two competing firms increases total investment towards entry deterrence and demonstrate that the conditions are satisfied by commonly used oligopoly models such as Cournot and Bertrand. Further, we show that the increased deterrence effort after a merger can actually make the post-merger likelihood of entry lower than that pre-merger. Our paper indicates that merger investigations should incorporate the effect of mergers on the incentives of incumbents to proactively deter entry. We view Cowgill et al. and our inquiries to be complementary in their approach and focus. The remainder of the paper is organized as follows. Section 2 presents a simple model of a merger between two firms that do not compete with each other but that face a common entrant into their markets. (The simple model is motivated by a recent merger that was investigated by the Antitrust Division of the U.S. Department of Justice.) Analysis of the simple model helps to illustrate the basic idea of the alleviation of free-riding incentives between the merging firms. It also helps to establish the first of the policy implications: that a merger may not pose a direct risk of anti-competitive price increase or quality reduction but may still serve to reduce the likelihood of future competition-enhancing entry and thereby warrants attention. Section 3 introduces a model in which the merging incumbents compete with one another prior to the merger. In addition to eliminating free-riding between the merging firms, the merger engenders two additional effects: First, the elimination of competition between the merging firms increases the amount of profits that the merged firm stands to lose from entry. This further increases its optimal investment towards entry deterrence. Second, the elimination of competition between the merging firms also increases the profitability of entry relative to pre-merger. The net effect of the three forces determines the likelihood of entry. The “elimination of free-riding between the merging firms” effect and the “increase in profit at stake” effect tend to reduce the likelihood of entry by raising incumbent incentives to deter entry. The third effect—“increased profitability of entry”—tends to increase the likelihood of entry. The current framework for entry analysis in merger investigations—which does not analyze strategic entry deterrence by incumbents—captures only this third effect. Thus, merger analysis tends to over-estimate the likelihood of entry as a mitigating factor and places undue weight on the incidence of historical entry as evidence of ease of post-merger entry. Section 4 re-iterates policy implications and offers practical guidance to enforcers.",
61.0,2.0,Review of Industrial Organization,07 June 2022,https://link.springer.com/article/10.1007/s11151-022-09873-y,A Note on Input Price Discrimination Under Bertrand Competition: Simultaneous vs. Sequential Contracting,September 2022,Kangsik Choi,DongJoon Lee,Seonyoung Lim,Unknown,Male,Unknown,Male,"A large volume of the literature on input price discrimination (hereafter, price discrimination) in upstream firm-retailer relationships focuses on the profit and welfare effects. For instance, Katz (1987) and DeGraba (1990) found that a higher input price is charged to a downstream firm with lower marginal cost under price discrimination than under uniform pricing, which reduces social welfare.Footnote 1 Recently, Kim and Sim (2015) examined a case of sequential contracting with input buyers. They showed that: (i) under Cournot competition, allowing price discrimination improves welfare in sequential contracting; and (ii) with an efficient retailer who acts as a leader, the supplier prefers sequential contracting in input markets, whether price discrimination is banned or not. This study develops a model of a monopoly supplier that sells an identical input to two differentiated downstream retailers that also differ in their efficiency and that compete under Bertrand competition.Footnote 2 Similar to Kim and Sim (2015), this study restricts the supplier to using linear prices when trading with retailers. Thus, this study conducts robustness checks under Bertrand competition as with Kim and Sim (2015), where the main intuition may or may not carry over from the viewpoint of antitrust implications. Comparing sequential with simultaneous contracting under Bertrand competition, this study finds that: (i) under sequential contracting, the monopolistic supplier prefers to contract with an inefficient retailer first and an efficient retailer later, whether price discrimination is banned or not; (ii) with uniform pricing (resp. price discrimination), consumer surplus and total welfare are greater under simultaneous (resp. sequential) contracting than under sequential (resp. simultaneous) contracting; (iii) in contrast to the results of Kim and Sim (2015), the supplier prefers simultaneous contracting over sequential contracting because a supplier makes higher profits from simultaneous offers; and (iv) sequential contracting does not occur. In the context of simultaneous contracting, the supplier prefers price discrimination over uniform pricing. This study finds that consumer surplus and total welfare are higher under uniform pricing than under price discrimination in the context of simultaneous contracting. Section 2 reviews the literature. Section 3 describes the basic model structure, and Sects.  4 and 5 analyze sequential and simultaneous contracting with both pricing rules under Bertrand competition, respectively. Section 6 provides comparative results, and Sect. 7 contains concluding remarks.",1
61.0,3.0,Review of Industrial Organization,24 August 2022,https://link.springer.com/article/10.1007/s11151-022-09880-z,Protecting Sticky Consumers in Essential Markets,November 2022,Walter Beckert,Paolo Siciliani,,Male,Male,Unknown,Male,"The presence of sticky consumers who fail to switch to cheaper tariffs is arguably one of the most intractable issues that are faced by competition and consumer protection authorities in many market economies.Footnote 1 Such customer inertia has been observed in markets that involve utilities, including: retail energy; basic telecom services; and retail financial services such as current accounts or credit card accounts. These utilities provide essential services that every consumer must purchase to satisfy basic needs and to participate actively in economic and social life.Footnote 2 Consumers often show little preference for variety, so that competing offers are perceived as closely substitutable, as long as a minimum level of service quality and reliability is guaranteed. Therefore, the potential lock-in of consumers and the risk of their being taken advantage of are significant policy concerns. Many of these markets have experienced entry by so-called “challenger” firms. Yet challenger firms typically face barriers to entry and expansion because of high customer acquisition costs that are due to customer inertia. And they risk that the make-up of their customer base is overexposed towards active customers who regularly shop around in their search for a better deal.Footnote 3 This gives rise to asymmetric market structures, in terms of market shares and switching costs—at least initially. This configuration, therefore, provides the typical background for regulatory intervention to reduce demand side frictions, with the dual objectives of protecting sticky consumers and promoting competition from “challengers”. In this paper, we study regulatory policy interventions that are aimed at protecting sticky consumers who are vulnerable to exploitation. We consider a setting in which two homogeneous-good producers with asymmetric market shares - a dominant firm and a challenger - compete for customers whose switching costs are heterogeneous, to the disadvantage of the challenger.Footnote 4 Heterogeneous switching costs allow us to distinguish between the firms’ “front-book”—new, switching customers—and “back-book”—inert, locked-in customers. We investigate how the distribution of demand-side frictions and market shares interact under various discriminatory pricing regimes that reflect recent regulatory proposals. We show that in our setting, while price discrimination benefits consumers by making an oligopoly more competitive, regulatory remedies that promote disclosure and limit price dispersion dissipate much of these benefits. We also show that asymmetric regulatory interventions that are aimed at the dominant firm would tend to favour the challenger firm. And we argue that the dominant firm may use price discrimination as a means to deter entry by a challenger that lacks the ability to discriminate.Footnote 5 The paper proceeds as follows: Sect. 2 lays out the policy background of our study and motivates the setup that we consider for our model. It also provides details on the pricing regimes that we consider in this paper. Section 3 connects our study to the large existing literature on price discrimination. Section 4 formalises our modelling framework and its underlying technical assumptions. Within the framework of a model with given asymmetric market shares and heterogeneous switching cost distributions, Sect. 5 presents results on the four pricing regimes that are central to this paper. Section 6 extends the framework to a dynamic model that endogenises the asymmetric market structure and the heterogeneous switching cost distributions. Section 7 concludes.",1
61.0,3.0,Review of Industrial Organization,07 July 2022,https://link.springer.com/article/10.1007/s11151-022-09874-x,The Effects of Vertical Integration in the Korea Movie Industry: Efficiency Versus Exclusion,November 2022,Seulgi Yoo,Seonghoon Jeon,,Unknown,Unknown,Unknown,Unknown,,
61.0,3.0,Review of Industrial Organization,07 July 2022,https://link.springer.com/article/10.1007/s11151-022-09875-w,Ringleader Discrimination in Leniency Policies,November 2022,Konstantinos Charistos,,,Male,Unknown,Unknown,Male,"Most jurisdictions have adopted “leniency programs” (LPs) in an attempt to destabilize existing cartels and discourage the formation of new ones. LPs offer the possibility for cartel members to report the existence of the infringement and to cooperate with competition authorities by offering evidence and/or information that can be used as proof of the illegal conduct in the prosecution phase. In exchange, any fines that are related to that firm’s cartel participation are partially or completely waived.Footnote 1 LPs may recognize and reward two distinct types of cooperation. Pre-investigation leniency encourages reporting to the antitrust authority (AA) by one or more members of a cartel that has not yet been detected. Post-investigation leniency rewards the voluntary provision of evidence that helps the AA to confirm whether an investigated market has been cartelized, and eventually provide legal proof of its accusations towards cartel participants in order to be able to administer penalties.Footnote 2 The present paper investigates the impact of introducing discrimination in the treatment of cartel instigators or ringleaders on the sustainability of collusive agreements. There exist jurisdictions that exclude ringleaders from the possibility of receiving fine reductions: the United States (US) corporate leniency policy – which excludes firms that coerce others to participate or that were the leader in (originator of) the anticompetitive activity – is a prominent example.Footnote 3 On the other hand, the European LP does not include provisions for cartel instigators.Footnote 4 Jurisdictions that deny leniency to ringleaders count on the fact that such a practice discourages cartel formation by making potential instigators less willing to engage in collusive arrangements, due to their eventually harsher treatment in case of conviction. However, the exclusion of the ringleader may increase trust among cartel participants by offering a credible commitment never to report the cartel to the AA. The final effect of excluding the ringleader from the LP is uncertain: It depends on the balance of these two effects. The LP-related literature highlights possible adverse effects of LPs and proposes their optimal design.Footnote 5 Harrington (2008) identifies the effects of leniency on cartel deterrence: He notes that LPs: i) destabilize collusion by increasing the (private) appeal of deviation (the deviator’s effect); and ii) favor collusion through the implicit reduction of expected fines (the cartel amnesty effect). In addition, a sufficiently generous LP that offers leniency only to the first informant increases the expected penalties by inducing the “race to the court”. This effect works against cartel stability. A well-designed policy must rely on a balanced tradeoff of these effects. Blatter et al. (2018) examine the impact of LP features on cartel deterrence under the assumptions that: a) a single firm’s cartel reporting is not sufficient to secure conviction; and b) firms may possess asymmetric evidence. It is shown that ringleader discrimination (RD henceforth) can be beneficial since the ringleader is less willing to set up a cartel in the absence of leniency. Chen et al. (2015) study the implications of denying leniency to cartel ringleaders under the assumption that firms have the opportunity to report after an investigation has been launched. It identifies the impact of such exclusion on the sustainability of the collusive agreement and concludes that, while the anticipated harsher treatment may reduce the ringleader’s incentive to instigate a cartel, the incentive of other firms to come forward is also mitigated. Under RD cartel formation may be less frequent; but once a cartel is created, whistle blowing and evidence provision become less likely. Clemens and Rau (2019) experimentally find that RD enhances trust among infringers. Cartels emerge less frequently under a non-discriminatory LP; this is a result that points against the use of RD. Our contribution to the theoretical literature is twofold: First, we examine the impact of the discriminatory LP considering that firms can report not only while an investigation is underway, but also before any investigation has been launched. This highlights two countervailing effects of discriminatory policies: Excluding the ringleader from any leniency provision: a) creates an asymmetry that is destabilizing for the cartel; and b) reduces the ringleader’s payoff from deviation. Second, we propose an alternative leniency scheme: The ringleader’s eligibility for leniency depends on whether the cartel is already under investigation: Leniency is available for the ringleader only in the event of pre-investigation reporting. Allowing the ringleader to benefit from pre-investigation leniency restores its payoff from deviation at the non-RD level, while excluding the ringleader from leniency when the AA already possesses incriminating evidence weakens the ringleader’s incentive to adhere to collusion. We show that a partially discriminatory LP undermines collusion more efficiently compared to either a fully exclusionary LP, or a non-discriminatory LP. The paper proceeds as follows: Sect. 2 contains the model specifications. Section 3 presents the analysis of the model. Section 4 includes an extension; and Sect. 5 concludes.",2
61.0,3.0,Review of Industrial Organization,24 August 2022,https://link.springer.com/article/10.1007/s11151-022-09881-y,Correction to: Ringleader Discrimination in Leniency Policies,November 2022,Konstantinos Charistos,,,Male,Unknown,Unknown,Male,"In the original publication of the article, the appearance of \(\widetilde{\mu }\) and the inequalities \(\mu \ge \widetilde{\mu }\) and \(\mu <\widetilde{\mu }\) throughout the paper are disorderly presented. In Tables 1 and 2, the payoff combination “\(B, B\)” is placed without space. The text between Lemma 2 and Lemma 3, Lemma 4 and Lemma 5, Lemma 6 and Lemma 7, Lemma 7 and Proposition 2 and incorrectly provided in italics. The mathematical expressions in the paragraph below Lemma 8 “(\({\delta }_{pd}^{^{\prime}}\left({\sigma }_{1}\right)\) and \({V}_{pd}^{^{\prime}}\left({\sigma }_{1}\right)\))” are placed very closely that may cause confusion. In the Appendix, the Proof of Lemma 8 and Proposition 3 (especially the first lines) on p. 18 is not properly presented. I quote the correct form of this proof right below: Recall that the critical discount factors for the ringleader and the follower are respectively when both report under non-discrimination. Observe that \( \frac{{\partial \delta _{n}^{\prime } }}{{\partial \sigma }} < 0 \) and \( \frac{{\partial \delta _{n}^{{\prime \prime }} }}{{\partial \sigma }} > 0 \); the ringleader’s (follower’s) ICC loosens (tightens) with \(\sigma \). For \(\sigma =\frac{1}{2}\), \( \delta _{n}^{\prime } \left( {\frac{1}{2}} \right) = \delta _{n}^{{\prime \prime }} \left( {\frac{{\text{1}}}{{\text{2}}}} \right) = \delta _{{{n}}} = \frac{{{\text{2 + a}}\mu }}{{{\text{4}}\left( {{\text{1}} - a} \right)}};\quad max \{ \delta _{n}^{\prime } ,\delta _{n}^{{\prime \prime }} \} \);  is minimized; and the firms’ expected collusive payoffs are also equal: \( V_{n}^{\prime } \left( {\frac{1}{2}} \right) = V_{n}^{{\prime \prime }} \left( {\frac{{\text{1}}}{{\text{2}}}} \right){\text{ = }}\frac{{\pi \left( {{\text{2}} - a\mu } \right)}}{{{\text{2}}\left[ {{\text{1}} - \delta \left( {{\text{1}} - a} \right)} \right]}} \). The critical discount factors for the ringleader and the follower are \( \delta _{{pd}}^{\prime } (\sigma ) = \frac{{1 - \sigma + a\sigma \mu }}{{1 - a}}\quad {\text{and}}\quad \delta _{{pd}}^{{\prime \prime }} (\sigma ) = \frac{\sigma }{{{\text{1}} - a^{\prime } }} \), respectively, given that the investigated follower reports under partial discrimination. Observe that \(\frac{\partial {\delta }_{pd}^{^{\prime}}}{\partial \sigma }<0\) and \(\frac{\partial {\delta }_{pd}^{{^{\prime}}{^{\prime}}}}{\partial \sigma }>0\); the ringleader’s (follower’s) ICC loosens (tightens) with \(\sigma \). For \(\sigma ={\sigma }_{1}\equiv \frac{1}{2-a\mu }\), \({\delta }_{pd}^{^{\prime}}\left({\sigma }_{1}\right)={\delta }_{pd}^{{^{\prime}}{^{\prime}}}\left({\sigma }_{1}\right)=\frac{1}{\left(1-a\right)\left(2-a\mu \right)}\). For \(\sigma ={\sigma }_{1}\) the firms’ expected collusive payoffs are also equal: \({V}_{pd}^{^{\prime}}\left({\sigma }_{1}\right)={V}_{pd}^{{^{\prime}}{^{\prime}}}\left({\sigma }_{1}\right)\). It is easy to verify that",
61.0,3.0,Review of Industrial Organization,25 July 2022,https://link.springer.com/article/10.1007/s11151-022-09876-9,Measuring the Effects of Bid-Rigging on Prices with Binary Misclassification,November 2022,Seoyun Hong,Chang Sik Kim,Hyunchul Kim,Unknown,,Unknown,Mix,,
61.0,3.0,Review of Industrial Organization,06 August 2022,https://link.springer.com/article/10.1007/s11151-022-09877-8,Cartel Penalties Under Endogenous Detection,November 2022,Berkay Akyapi,Douglas C. Turner,,Male,Male,Unknown,Male,"The recent discovery of a number of large and harmful cartels demonstrates that illegal price fixing remains a significant concern for antitrust authorities.Footnote 1 To deter cartels, antitrust authorities penalize firms that are proven guilty of illegal collusion. The structure of the penalties that are imposed by an antitrust authority affects both cartel formation and pricing.Footnote 2 Revenue-based and aggregate overcharge-based penalties are two often-proposed types of cartel penalties. A revenue-based penalty is a multiple of cartel revenue. An aggregate overcharge-based penalty is a multiple of the difference between the collusive price and the competitive price (the overcharge) multiplied by some base volume of sales. Revenue-based penalties are the current practice in all major jurisdictions.Footnote 3 Recent research (Bageri et al., 2013; Katsoulacos et al., 2015) suggests that cartel penalties that are based on revenue generate a lower level of social surplus than do penalties that are based on the cartel aggregate overcharge.Footnote 4 This is the case because revenue-based penalties induce cartels to price above the monopoly level in order to reduce revenue and thereby reduce the potential penalty. Intuitively, because a cartel that is maximizing profits already prices on the elastic part of its demand curve, the cartel increases its price so as to reduce revenue. Conversely, aggregate overcharge-based penalties induce cartels to price below the monopoly level so as to reduce the measured overcharge. These studies assume a constant and exogenous probability of cartel detection. In this study, we compare revenue-based and overcharge-based cartel penalties while allowing the probability of detection to depend on the cartel price.Footnote 5 We consider two specifications for the probability of detecting a cartel: In the first specification, the probability of detection is increasing in the cartel (per-unit) overcharge.Footnote 6 In the second, the probability of detection is increasing in the rate at which the cartel price increases, as in Harrington (2004, 2005). Intuitively, relatively high prices or large price increases are more likely to attract the attention of an antitrust authority and lead to the cartel’s detection. For each specification, we analyze and compare cartel pricing, deterrence, total surplus and consumer surplus under revenue-based and overcharge-based penalties. We find that cartel penalties that are based on revenue generate a higher level of total and consumer surplus when the probability of detection is sufficiently sensitive to price under both specifications. Cartels do not charge prices above the monopoly price because such a high price is likely to raise suspicions of collusion and may cause the cartel’s detection. Thus, the pricing result of Katsoulacos et al. (2015) does not occur. Instead, cartels set low prices to avoid detection. However, a revenue-based penalty is larger than an aggregate overcharge-based penalty for low cartel prices. As a result, collusion is more difficult to sustain under revenue-based penalties. In addition, cartels that face revenue-based penalties have a stronger incentive to reduce price further so as to avoid detection and the payment of larger revenue-based penalties. The rest of the article is organized as follows: Sect. 2 presents the model. Section 3 compares the two types of penalties when the probability of detection depends on the cartel overcharge. Section 4 compares the two types of penalties when the probability of detection depends on the rate at which the cartel price increases. Section 5 concludes. All proofs can be found in “Appendix 1”.",
61.0,3.0,Review of Industrial Organization,01 June 2022,https://link.springer.com/article/10.1007/s11151-022-09871-0,Comment on “A Comparison of the Wholesale Model and the Agency Model in Differentiated Markets”,November 2022,Kangsik Choi,Seonyoung Lim,,Unknown,Unknown,Unknown,Unknown,,
61.0,4.0,Review of Industrial Organization,28 November 2022,https://link.springer.com/article/10.1007/s11151-022-09889-4,General Editor’s Note: Antitrust and Regulatory Update,December 2022,Lawrence J White,,,Male,Unknown,Unknown,Male,,
61.0,4.0,Review of Industrial Organization,25 August 2022,https://link.springer.com/article/10.1007/s11151-022-09882-x,Recent Developments at the CMA: 2021–22,December 2022,Adam Cellan-Jones,Hussein Farook,Mike Walker,Male,Male,Male,Male,"The Competition and Markets Authority (CMA) is the UK’s leading competition and consumer authority, and its primary duty is to promote competition, both within and outside the UK, for the benefit of consumers. The CMA has a wide range of tools to use in addressing competition and consumer problems including carrying out investigations into mergers and markets, enforcing competition and consumer law, and working with sector regulators. In this article, we provide a brief overview of three projects which the CMA completed in the past year.
",1
61.0,4.0,Review of Industrial Organization,03 November 2022,https://link.springer.com/article/10.1007/s11151-022-09883-w,Economics at the FTC: Estimating Harm from Deception and Analyzing Mergers,December 2022,Michael Vita,Keith Brand,Daniel H. Wood,Male,Male,Male,Male,"This article summarizes work done by economists in the Federal Trade Commission’s (FTC’s) Bureau of Economics (BE) in support of the commission’s consumer protection and antitrust missions. In particular, it highlights the analyses that were performed by consumer protection economists to assess the harm to consumers who were provided bad information in two different settings: In the first, consumers were misled about the true terms of rent-to-own payment plans; and in the second, consumers were shown only a censored set of consumer reviews of apparel products. On the competition side, we first discuss the analysis of a proposed semiconductor merger that raised vertical concerns, and then we explore how the evaluation of hospital mergers can assess and account for complementarity between hospitals. The staff of the Federal Trade Commission’s Bureau of Economics is composed of about 74 Ph.D. economists, nine research assistants/statisticians, eight financial analysts, and five administrative professionals. BE mainly contributes to the FTC’s missions by performing economic analysis in extensive law enforcement investigations and rulemakings that are conducted along with teams of FTC attorneys from the Bureau of Competition and the Bureau of Consumer Protection. The information that is generated by the economists and attorneys serves as an important input into the decisions that are made by the FTC Commissioners. When the Commission pursues a legal challenge in court, BE economists help to develop economic evidence and, in some cases, may testify in court. BE economists also conduct economic research to address topics of economic importance outside the context of law enforcement investigations. Our economists write working papers and journal articles that are based on original research that they conduct in addition to their other professional duties. BE economists also conduct commission-wide studies and reports, often in collaboration with FTC attorneys.Footnote 1 BE also participates in the larger economics community via participation in seminars and conferences. Notably, on November 4 and 5, 2021, BE–along with co-sponsor, the Tobin Center for Economic Policy at Yale–held the fourteenth FTC Microeconomics Conference.Footnote 2 The topics that were covered in keynote addresses and paper presentations included: gig work and digital platforms; data governance; pharmaceutical rebates; misinformation in advertising; product market concentration; and online privacy. On November 3–4, 2022, BE and the Tobin Center will again hold the FTC Microeconomics Conference in Washington, DC.Footnote 3 Section 2 of this article describes the economic analysis of harm to consumers from allegedly misleading information about rent-to-own leasing terms that involved the firm Progressive Leasing. Section 3 presents a methodology for exploring the consumer harm from the censorship of negative reviews by Fashion Nova, a marketer of apparel. Section 4 presents some of the economic issues that were considered by BE in the NVIDIA/Arm semiconductor merger investigation. Finally, Sect. 5 explores the conditions that may lead payers to view merging hospitals as complements and how that complementarity would affect the analysis of the merger’s effects.",1
61.0,4.0,Review of Industrial Organization,01 November 2022,https://link.springer.com/article/10.1007/s11151-022-09884-9,The Year in Review: Economics at the Antitrust Division 2021–2022,December 2022,Susan  Athey,Russell Pittman,Fan Zhang,Female,Male,,Mix,,
61.0,4.0,Review of Industrial Organization,30 November 2022,https://link.springer.com/article/10.1007/s11151-022-09890-x,Recent Developments at DG Competition: 2021/2022,December 2022,Thomas Buettner,Daniel Coublucq,Pierre Régibeau,Male,Male,Male,Male,"The Chief Competition Economist’s team (CET) is a group of about 30 economists who provide advice to the Commissioner (Executive Vice-President Margrethe Vestager) and to the Director General (Olivier Guersent) of DG Competition. This advice concerns ongoing cases, revisions of practices and guidelines, as well as broader policy issues (e.g., green policies, industrial policies, digital sector regulation). The CET does not just express an opinion on cases. Often some of its members are embedded in the case teams. This is generally the rule for mergers and has become much more common in antitrust and State aid—especially on the most relevant and complex cases. In addition, given the sheer number of State aid cases, the CET’s involvement in some of these cases is limited to performing specialised tasks and to vouching for the economic coherence of the analysis. The Fig. 1 below describes the allocation of resources across tasks over the last few years. Workload across antitrust, merger and State aid (percentage of working hours) Overall, while merger control used to account for a large part of our time, the dedication of resources has been increasingly more balanced. Recently, a similar amount of resources have been devoted to antitrust, merger control, and State aid control. In the following sections, we summarize some of the main developments in our work over the last year: In antitrust, we outline the main changes in the new version of the Vertical Block Exemption Regulation (VBER) and the corresponding Vertical Guidelines. (Sect. 2). While it was a very busy year for State aid, we feel that the regulation of State aid that aims at achieving environmental objectives is worth special attention. Accordingly, with respect to the “Green Deal”, we discuss the new “Guidelines on State aid for climate, environmental protection, and energy” (CEEAG) (Sect. 3). Finally, Sect. 4 is devoted to a merger review—the Veolia/Suez case—where a catchment area analysis contributed to the assessment of the impact of the merger on local markets and bidding data were used to assess the closeness of competition between the merging parties and other suppliers.",
61.0,4.0,Review of Industrial Organization,16 November 2022,https://link.springer.com/article/10.1007/s11151-022-09887-6,"Economics at the FCC 2021–22: 5G Spectrum Auctions, Affordable Connectivity, Broadband Data Collection, and Merger Review",December 2022,Joanna Fister,Catherine Matraves,Aleksandr Yankelevich,Female,Female,Male,Mix,,
62.0,1.0,Review of Industrial Organization,14 November 2022,https://link.springer.com/article/10.1007/s11151-022-09888-5,Is Divestiture Effective as a Merger Remedy in the U.S. Beer Industry?,February 2023,Xiangrui Wang,Ron C. Mittelhammer,Jill J. McCluskey,Unknown,Male,Female,Mix,,
62.0,1.0,Review of Industrial Organization,02 September 2022,https://link.springer.com/article/10.1007/s11151-022-09879-6,Measuring the Power of Regulatory Regimes,February 2023,Dennis L. Weisman,,,Male,Unknown,Unknown,Male,"It is generally recognized that the objective of economic regulation is to emulate a competitive market outcome (Bonbright, 1961, p. 107; Kahn, 1970, p. 17). The literature is largely silent, however, on the specific form of competition that should be emulated.Footnote 1 The power of a regulatory regime (PRR) measures the strength of the incentives for cost-reducing innovation. In a dynamic setting, the PRR depends on the length of time that the regulated firm is permitted to retain the gains from its cost-reducing innovation before those gains are appropriated by the regulator (acting as a surrogate for the competitive process) and reflected in downward price adjustments. The regulated firm is the “residual claimant” when it retains a full dollar of each additional dollar in efficiency gains.Footnote 2,Footnote 3 This is the defining property of pure price-cap regulation (PCR) in which there is no ex post sharing of earnings (Braeutigam & Panzar, 1989; Cabral & Riordan, 1989; Weisman, 1993). In theory, the price cap that is faced by the regulated firm under pure PCR is invariant (exogenous) to the regulated firm’s behavior (Bernstein & Sappington, 1999; Brennan, 1989; Shleifer, 1985). This “invariance property” engenders superior incentives for efficiency and explains why pure PCR is considered a “high-powered” regulatory regime.Footnote 4 In contrast, in the textbook model of rate-of-return regulation (RRR), efficiency gains are fully and instantaneously appropriated. This property discourages regulated firms from incurring the effort costs that are associated with innovation and explains why RRR (at least in its stylized form with perfect regulatory oversight and no regulatory lag) is considered a “low-powered” regulatory regime.Footnote 5,Footnote 6 As Sappington (1994, pp. 262–263) observes, “Absent credible rewards for superior performance and/or credible penalties for poor performance, the regulated firm will have little incentive to incur the effort costs that increase the likelihood of good performance.” Nonetheless, the differences between PCR and RRR may be more stark in theory than they are in practice. As Laffont and Tirole (1993, p. 19) observe, “overall COS (cost-of-service) and PC (price cap) regulations have a lot in common... the contrast between the two modes is mostly one of emphasis.”Footnote 7 The primary objective of this paper is to derive a general static measure of the PRR and then explore its dynamic properties. The PRR metric depends on: (1) the share of the efficiency gains that the regulated firm is permitted to retain; and (2) the length of time that the regulated firm is permitted to retain them. The thought experiment that is contemplated here assumes that the regulated firm realizes a dollar of cost savings in each period of the regulatory regime and then computes the discounted stream of cost savings that is retained by the regulated firm relative to that of a benchmark competitive firm. The analysis reveals that the literature may significantly overstate the power of regulatory regimes. This may help explain why the empirical findings with regard to the efficiency gains from PCR do not offer unequivocal validation of the prevailing theory. The format for the remainder of this article is as follows: Sect. 2 provides the definitions and notation that are used in the analysis. The static PRR metric is derived formally in Sect. 3. Section 4 explores the PRR in a dynamic setting. The implications of uncertain regulatory commitment for the PRR are explored in Sect. 5. Section 6 concludes. The “Appendix” contains the formal proofs of select propositions.",1
62.0,1.0,Review of Industrial Organization,07 November 2022,https://link.springer.com/article/10.1007/s11151-022-09885-8,"Experience Goods, Umbrella Branding, and Reputation",February 2023,J.-P. Niinimäki,,,Unknown,Unknown,Unknown,Unknown,,
62.0,1.0,Review of Industrial Organization,17 November 2022,https://link.springer.com/article/10.1007/s11151-022-09886-7,Patent Licensing and Capacity in a Cournot Model,February 2023,Stefano Colombo,Luigi Filippini,Debapriya Sen,Male,Male,Unknown,Male,"We consider the problem of patent licensing in a Cournot duopoly in which the innovator (the patentee) is one of the competing firms and it is capacity constrained. When the capacity constraint is maximum (that is, the innovator cannot produce), the model coincides with the case of an outside patentee; when the capacity constraint is not binding, the model coincides with the case of an unconstrained inside patentee. Therefore, our model provides a bridge between the two cases usually considered in the literature: outside innovator and unconstrained inside innovator. A capacity constraint is often relevant for the innovator. Pavitt et al. (1987), Acs and Audretsch (1990), OECD (2004), Marx et al. (2014), and Scholz (2017) provide evidence of the importance of small firms in generating technological innovations that are diffused by means of licenses. For example, Marx et al. (2014) explore the commercialization strategy in which a start-up temporarily enters the product market in order to establish the value of its innovation; ultimately, the entrant may switch to a strategy of cooperating with incumbents. Scholz (2017) emphasizes that—due to the increasing scarcity of raw materials that posit severe capacity constraints, especially for small firms—licensing agreements that delegate production (or part of production) to other firms are becoming widespread.Footnote 1 In many cases the innovator is a small firm with limited production possibilities, which licenses its innovation to other firms. The theoretical literature has rarely considered the role of a capacity constraint in determining the licensing choice of the patentee. Scholz (2017) analyses a vertical model where the upstream firms are capacity constrained, while the patentee is an outside innovator. Alderighi (2008) proposes a licensing method that involves a maximum authorized production for the licensee. However, to the best of our knowledge, the case of a capacity-constrained patentee has not been considered yet. In a different context, Mukherjee (2001) examines the possibility of technology transfer when firms have pre-commitment strategies such as a capacity commitment or an incentive delegation under the assumption of fixed-fee licensing. Filippini (2005) suggests that restrictions on licensing contracts reduce the viability of technology transfers. Bagchi and Mukherjee (2011) show that an incumbent firm may hold excess capacity: not to deter entry but to extract a larger licensing fee.Footnote 2 While the literature has shown that in the case of an outside (inside) innovator the fixed fee (unit royalty) is preferred by the patentee (Kamien & Tauman, 1986; Sen & Tauman, 2007; Wang, 1998), we show that a fixed fee is preferred by the patentee even if the patentee competes with the licensee—provided that the patentee is able to produce only a relatively small quantity. Therefore, a fixed fee might be preferred to a unit royalty even if the patentee is an insider. This happens both in the case of drastic and non-drastic innovation. We show that the results are driven by two parameters: k, the maximum quantity that can be produced by the capacity-constrained firm; and c, the cost reduction after the innovation (which is a measure of the innovation size). Furthermore, we show that when the patentee can set two-part tariffs in the form of combinations of fixed fees and unit royalties, it charges a positive fixed fee if and only if the patentee can produce only a relatively small quantity due to the capacity constraint. We also show that with combinations of fixed fees and royalties, the royalty rate is lower than is true for the standard case. The reason is the following: When the quantity that can be produced by the patentee is relatively small, it is better for the patentee to let the licensee expand its production, and then extract the extra profit of the licensee by means of a fixed fee. By contrast, when the patentee can produce a relatively large quantity, it benefits from expanding production and earns additional revenues from the royalties that it charges on the licensee’s output. Therefore, the patentee chooses a per-unit royalty. The rest of the paper proceeds as follows: In Sect. 2 we introduce the model. In Sect. 3 we derive some preliminary results with regard to a constrained Cournot duopoly with asymmetric firms. In Sect. 4 we derive the equilibrium profits under licensing. In Sect. 5 we compare different licensing mechanisms. Section 6 discusses several extensions. Section 7 concludes.",2
62.0,1.0,Review of Industrial Organization,20 August 2022,https://link.springer.com/article/10.1007/s11151-022-09878-7,What can be Expected from Mergers After Deregulation? The Case of the Long-Distance Bus Industry in France,February 2023,Thierry Blayac,Patrice Bougette,,Male,Male,Unknown,Male,"France’s long-distance bus industry is a dynamic sector in which consolidation has played an important role since it was liberalized with the enactment of the Macron Law in the summer of 2015.Footnote 1 Indeed, four mergers have occurred since its opening to competition in 2015: FlixBus/Megabus and Ouibus/Starshipper in 2016; Blablacar/Ouibus in 2018; and FlixBus/Isilines-Eurolines in 2019. These mergers have strongly affected the structure of this new market, in which new hopes for mobility have emerged. This study analyzes the competitive effects of the 2016 acquisitions on three strategic variables—prices, load factors, and frequencies—for which sufficient hindsight and data are available. This exercise is important because French railways will be fully open to competition by 2023, and the Italian experience suggests that this will increase intermodal competition (Gremm, 2018). The economics literature identifies two main types of impacts resulting from horizontal mergers: On the one hand, a merger can lead to a rationalization of the production system through efficiency gains or cost synergies. These are the pro-competitive effects of mergers. On the other hand, a merger may increase market power, leading to higher prices, less choice, or reduced innovation and quality: the anticompetitive effects on consumers. This tradeoff was analyzed from a theoretical perspective in the pioneering work of Williamson (1968) and within the oligopoly framework by Deneckere and Davidson (1985), who focused on price competition, and by Farrell and Shapiro (1990), who focused on quantity competition.Footnote 2 We address this tradeoff from an empirical perspective: We focus on how mergers affect prices, load factors, and scheduling frequencies in a new industry: France’s intercity bus industry. As was pointed out by Crozet and Guihéry (2018), load factors are a key variable for bus operators. One strategy is to increase load factors. Mergers can achieve this objective more readily. By rationalizing frequencies, mergers can lead to synergies that make it possible to offer fewer scheduled trips but with a larger number of passengers per bus. These two non-price variables—load factors and frequencies—are specific to mergers in transport markets and fully exploring the effect of the French intercity bus mergers on these variables is worthwhile. We examine the 2016 mergers that have created changes in market concentration.Footnote 3 We use original data that have been provided by the French transport regulator Autorité de régulation des transports (ART)Footnote 4 to show that these two acquisitions affected the competitive dynamics of the French intercity bus industry. A difference-in-differences (DiD) analysis shows that the Megabus and Starshipper acquisitions resulted in more concentrated links (routes), which allowed operators to raise their prices and reduce their frequencies, although entry barriers appear to be low. In the first quarter after the acquisition, prices increased by 13.5%; but these increases diminished over time, reaching 5.3%. Frequency decreases started one quarter later and ranged from − 21.5 to − 25.7%, while there were no effects on load factors. Thus, we show that these mergers may have had raised anticompetitive effects. However, they were not scrutinized by the French competition agency (because the mergers were below the notification thresholds). The remainder of this paper is organized as follows. Section 2 briefly reviews the relevant empirical literature. Section 3 provides a background on France’s long-distance intercity bus market. Section 4 describes our estimation strategy and data sources, as well as the methodology that we used to construct the merger and comparison markets. Section 5 presents the study’s empirical findings. Section 6 concludes the paper.",
62.0,2.0,Review of Industrial Organization,13 February 2023,https://link.springer.com/article/10.1007/s11151-023-09896-z,Simulating Vertical Mergers,March 2023,Gleb B. Domnenko,David S. Sibley,,Male,Male,Unknown,Male,"Traditionally, vertical mergers have not been scrutinized frequently due to the widespread view that they are benign, because they solve a double-markup problem, which was originally posited by Cournot (1838). Early analyses of the problem in the context of vertical integration are Spengler (1950) and Warren-Boulton (1974). This view has not been unanimous, however.Footnote 1 Most vertical mergers involve a downstream firm that has competitors downstream, so the possibility of foreclosure exists. Salinger (1988) showed that it is possible that a vertical merger will cause the merged firm’s upstream price to rise, even if its downstream price falls. Chen (2001) makes the same point, adding that part of the motivation of a vertical merger may be to soften competition in the downstream market. That is, even the solving of a double-markup problem by the merged firm is consistent with foreclosure.Footnote 2 Concerns such as this were part of the litigation between the Department of Justice (“DOJ”) and AT&T over the latter’s acquisition of Time Warner.Footnote 3 They were also a part, though a minor one, of the FCC’s analysis of the proposed merger between T-Mobile and Sprint.Footnote 4 Other vertical mergers which have led to serious vertical concerns are: Nielsen–Arbitron, Comcast–NBC, and Ticketmaster–Live Nation.Footnote 5 Previous papersFootnote 6 on vertical mergers and foreclosure are primarily concerned with demonstrating that certain effects can occur in a properly specified vertical model. They are not concerned with trying to analyze the competitive impact of vertical mergers in general. Nor do they tell us what circumstances are likely to lead to foreclosure. There are no broadly applicable theoretical results on the upstream and downstream price effects of a vertical merger. There are recent insightful analyses of numerical examples, such as that of Das Varma and De Stefano (2020). These are devoted to examining the variety of special cases that can emerge in a vertical merger. In an effort to search for somewhat more general results, we take the approach of Monte Carlo simulations. As do Das Varma and De Stefano, we assume an upstream monopoly and two downstream firms. The two downstream firms each purchase a critical input from the monopolist. One unit of the input is needed for each unit of downstream output. Then we allow the upstream firm to merge with one of the two downstream firms. We simulate a large number of cases so as to determine whether a merger between an upstream monopolist and one downstream producer makes upstream and downstream prices rise or fall after the merger. We also examine whether there are intuitive explanations of the pattern of results that we obtain. We assume two types of downstream demand curves, linear and logit. Apart from the general goal of better understanding the qualitative price effects of vertical mergers, we are also interested in assessing the accuracy of a tool that is used increasingly in merger analysis with vertical components: the vertical GUPPI approach, which is due to Moresi and Salop (2013).Footnote 7 This approach involves three different test expressions. All are evaluated at the pre-merger prices; one is designed to predict the direction of the upstream price effects of a vertical merger; the others predict the direction of change of the downstream prices of the merged firm and the unintegrated downstream rival, due to the merger. This approach has recently been extended in an interesting way by Rogerson (2020), who modified the Nash bargaining approach to include the setting of upstream and downstream prices. Our results are as follows: We find that a vertical merger confers a strategic timing advantage on the merged firm. In equilibrium, the merged firm can choose whether it wants to be a first or a second mover in the downstream pricing subgame with the unintegrated rival. In most, but not all, simulations, the downstream price of the merged firm falls, relative to its pre-merger level. The price of the unintegrated downstream firm can increase or decrease due to the merger. In our simulations, when demand curves are linear, the merged firm always chooses to be a first mover. For the most part, all downstream prices fall, but the unintegrated firm is caught in a vertical price squeeze. When downstream demands are logit, and when the merged firm chooses to be a first mover, its downstream price always falls. When it chooses to be a second mover, prices frequently increase. The remaining downstream rival suffers a decline in market share and profit due to the merger. If the acquired downstream firm is large enough, the remaining downstream firm is the victim of a price squeeze. That firm is caught between a reduced downstream price by the merged firm and an upstream price for the critical input that either rises or does not fall as much as does the downstream price of the merged firm. Based on our results, the use of the vGUPPI approach should be tempered with caution. It has no predictive power with regard to the post-merger upstream price or the price of the unintegrated downstream firm. Our results highlight a significant policy issue that arose in the FTC–DOJ Vertical Merger Guidelines that were promulgated in 2020. The initial version of these Guidelines stresses the importance of the pre-merger market share of the acquired downstream firm. The final version of these Guidelines does not do so. Our results imply that the pre-merger share of the downstream firm is very important as a predictor of the price effects of the merger. From this standpoint, removing the original emphasis on market shares was an error.",
62.0,2.0,Review of Industrial Organization,29 December 2022,https://link.springer.com/article/10.1007/s11151-022-09893-8,Hybrid Marketplaces with Free Entry of Sellers,March 2023,Federico Etro,,,Male,Unknown,Unknown,Male,"A hybrid marketplace is monetized through percentage commissions on third-party sales and through direct sales of its own products and services. In the case of Amazon, as well as other prominent platforms, this double role as “umpire and player” has been at the center of a lively debate. The common presumption is that a hybrid marketplace would systematically promote its own products or increase commissions on third-party products so as to favor its own sales, and this may harm consumers in the long run (according to the New Brandeisian view of Khan (2016)). In this work we ask whether this is consistent with the endogenous market structure emerging on a hybrid marketplace open to third-party sellers.Footnote 1 Contrary to the common presumption, we show that the introduction of own products can actually increase both consumer welfare and total welfare through a reduction of commissions on sellers which reduces all prices and expands gains from variety.Footnote 2 Recent important works by Anderson and Bedre-Defolie (2021) and Zennyo (2022) have introduced tractable frameworks that are based on a logit model of product differentiation to address these issues. In both these works, a hybrid marketplace acts as a Stackelberg leader in selecting commissions and prices, and faces endogenous entry of third-party sellers that are engaged in imperfect competition. Zennyo (2022) adopts a commission on units sold and shows that a hybrid marketplace is neutral on commissions and consumer welfare, while AB (2021) adopt a percentage commission on revenues (the empirically relevant case) and argue that a hybrid marketplace sets excessive commission rates to shift demand toward its own products, which reduces consumer welfare. We unveil the nature of this apparent contradiction by developing a microfoundation of demand systems which nests the logit case and an entire class of alternative ones, and we derive conditions under which a hybrid marketplace can either increase or decrease welfare as compared to a pure marketplace. More formally, we adopt a representative agent framework that is based on a quasi-linear indirect utility that depends on additive aggregators of the prices of all of the products that are sold on the marketplace. The sellers are engaged in monopolistic competition with free entry.Footnote 3 For a given commission rate, the entry and pricing strategies of the marketplace are neutral on consumer welfare; this is a consequence of a result that applies to aggregative games with free entry (Etro, 2008; Anderson et al., 2020). The only impact of the introduction of products by the marketplace on consumer welfare occurs through a change in the commission set on sellers. When this is increased, consumers are harmed through higher prices and lower gains from variety, while a reduction of the commission reduces prices and expands the gains from variety, increasing consumer welfare as well as total welfare. This result is powerful because independent from details on the demand conditions (the welfare impact depends on an observable feature as the change in commissions). In general - and this is our novel result - either outcome is possible because the introduction of products by the marketplace exerts two effects: on one side, there is an incentive for the marketplace to increase the commission and shift demand toward its own products; but, on the other side, there is an incentive to reduce the commission to attract new sellers and collect more commission revenues on the extensive margin and to expand purchases by customers on the marketplace. One can regard the former as a demand substitution effect - which harms consumers and biases their purchases toward the marketplace’s own products - and the latter as an extensive margin effect - which benefits consumers and expands their purchases of all products. Under additional restrictions on the microfoundation we can obtain more precise results on the conditions under which each effect is dominant. In the prominent case of demands with a constant elasticity, if the marketplace faces the same elasticity as the third-party sellers, its products are introduced at the same price and the commission rate is left unchanged. However, when the marketplace faces a less elastic demand than the sellers (for instance due to a reputational advantage of Amazon on its platform), the extensive margin effect is dominant: the marketplace sets higher markups on its own products but reduces the commission on third-party sales so as to attract more purchases (without diverting too much demand from its own products). Instead, under a logit demand system, the demand substitution effect is dominant and the commission is increased, which is consistent with findings by AB (2021). We explore extensions to: specific commissions, where the neutrality applies in the logit case (which is consistent with findings by Zennyo (2022)); strategic interactions between sellers; alternative timing without price leadership by the marketplace; endogenous product selection by the marketplace; and advertising for product discovery. Our findings suggest that the presumption that a hybrid marketplace tends to favour its own products through worse conditions or higher commissions for third-party sellers lacks a solid foundation. For instance Amazon sets different commission rates across wide product categories, and these rates have been quite stable over time and - more important for the implications of our model - not correlated with the introduction of products by Amazon. Public data from Amazon in the US reveal that the commission rates between 2017 and 2021 have been constant at 8% for consumer electronics, cameras, cell phone devices and video game consoles; 12% for industrial & scientific products; 15% for books, home & garden, office products, music, sports, toys and much more; and 45% for Amazon device accessories. Changes in commissions during the last five years have been reductions (below a price threshold) from 15% to 8% for baby products, beauty and health & personal care; from 20% to 15% for sports collectibles; and (above a price threshold) from 15% to 10% for the category furniture & décor; and from 20% to 5% for jewelry. The only increases have been from 15% to 17% for clothes and from 6% to 8% for personal computers.Footnote 4 Remarkably, private label products had been introduced for product categories with unchanged commissions, as well as for product categories with a reduction of the commissions and for clothes, but not for personal computers. Such a state of affairs - which is broadly confirmed for other countries - suggests that there is not a significant correlation between changes in commission rates and market shares of Amazon by product category. The work is organized as follows. Section 2 reviews the related literature. Section 3 presents the structure of the model. Section 4 derives the key results. Section 5 discusses extensions. Section 6 concludes.",2
62.0,2.0,Review of Industrial Organization,15 December 2022,https://link.springer.com/article/10.1007/s11151-022-09892-9,When Do Firms Offer Higher Product Quality? Evidence from the Allocation of Inflight Amenities,March 2023,Myongjin Kim,Qihong Liu,Nicholas G. Rupp,Unknown,Unknown,Male,Male,"When firms compete for consumers in competitive markets, the firms make choices about both price and product quality. While economists agree that competition reduces prices, less well understood is the influence of competition on product quality. Theoretically it is ambiguous how market competition may affect product quality. Therefore, we need to study this question empirically using US airline data. Moreover, the empirical results may differ from one context to another, as the existing airline literature already shows when on-time performance is used to measure quality.Footnote 1 When we are confronted with a new context, such as in-flight amenities, we cannot directly draw on results from past findings, since they may not translate to the new context. Hence, this study employs self-collected product quality data on in-flight amenities to investigate empirically the link between competition and product quality in the airline industry. More broadly, the issues of quality and amenities - which to offer and which to include in a base offering - is confronted across many industries including car/truck sales, hotels, and car rental agencies, etc. In this paper, our measure of product quality includes four separate inflight amenities that are provided by airlines: Wi-Fi; seat size; entertainment; and at-the-seat electrical power outlets. Airlines must make decisions about quality and amenities, as well as which amenities to include in the base price and for which amenities to charge an additional fee. For example, on domestic flights coach class fares typically include a snack and complimentary non-alcoholic beverage service for flights over 500 miles (Delta) or exceeding 2 hours and 20 minutes (United), while alcohol is available for an additional fee. In our setting, two of the four quality measures are option goods - Wi-Fi and entertainment - since once quality is enhanced in the aircraft, travelers have the option of using the good for an additional price. These option goods generate non-taxable ancillary revenue for the airline. Alternatively, an airline can provide these option goods for free, and the U.S. airlines commonly do so for their elite frequent fliers. Using a unique data set of slightly more than 1 million flights for over 800 routes and spanning nine weeks in the third quarter of 2015, we observe conflicting effects of competition on the provision of product quality. When network carriers compete with Southwest Airlines on a route, we find that they provide significantly lower product quality in the form of fewer inflight amenities. We also find, however, that routes with higher market concentration are significantly less likely to provide inflight amenities. Jointly this suggests that the composition of the competition matters when carriers are deciding whether or not to increase product quality. This paper makes two contributions to the existing literature. First, given that previous research has found both a positive and negative relationship between product quality and competition, our empirical findings will shed more light on this relationship. We find that the composition of competition within the route matters: heightened competition in a market generally increases product quality. On the other hand, the presence of Southwest Airlines on the route reduces product quality offerings. Network carriers appear to be more focused on price and willing to forgo product quality in Southwest markets. We also find that airlines are more likely to introduce inflight amenity options on routes with more passengers and to tourist destinations. Second, we explore the relationship between inflight amenities and ticket prices. Our results suggest that carriers are moving to a la carte pricing. They reduce base ticket prices on routes with Wi-Fi and entertainment and then charge passengers to use these amenities. This is similar to Brueckner et al. (2015) and He et al. (2022), who both show that airlines reduce base fares while imposing checked and carry-on bag fees. Intuitively, with additional revenue sources from add-ons, airlines have an incentive to reduce base fares, with the goal of attracting more passengers while also increasing ancillary revenue. This positive externality of lower base fare on ancillary revenue is also in the same spirit as pricing by a single firm that makes complementary goods and hence chooses to reduce the prices of both goods. These pricing changes could be welfare-enhancing for passengers since they pay lower base ticket prices while having an additional option to purchase the amenity. These Wi-Fi fees are part of the ever-growing ancillary revenue for airlines, which is estimated at $66 billion worldwide for airlines in 2021, an increase of 13 percent from 2020.Footnote 2 In sum, we believe that inflight amenities improve passenger welfare and conjecture that airlines use inflight amenities as a tool to attract and retain passengers.",
62.0,2.0,Review of Industrial Organization,07 December 2022,https://link.springer.com/article/10.1007/s11151-022-09891-w,Research Diversity and Invention,March 2023,John T. Scott,,,Male,Unknown,Unknown,Male,"This paper explains why having numerous diverse research organizations greatly increases the likelihood of invention. An open question is discussed: Does the invention-increasing effect of research diversity justify adjusting competition (antitrust) merger policy by encouraging greater stringency in merger approvals so as to protect the diversity that numerous research rivals in a market would provide? The importance of diversity for successful research is a theme that is found in the literature about invention and innovation. That literature defines an invention as a new combination of essential elements of knowledge—envisaged together in their working configuration for a new product or service—and defines an innovation as the commercialization of an invention. The key reason for the beneficial effects of diversity on invention is that an invention combines existing ideas in new ways, and the ideas that are combined in a successful invention are often diverse, coming from very different sources of knowledge and experience. Because diversity within an organization expands the set of ideas that the organization has available for invention, diversity fosters the inventions that become innovations.Footnote 1 This paper adds an explanation for why a diverse collection of research organizations further stimulates invention. In terms of the set of knowledge elements from which elements combined in an invention are chosen, Sect. 2 defines uncertainty for an invention and establishes that, given such uncertainty, numerous diverse research organizations make invention more likely.Footnote 2 Section 3 discusses the possibility that the pace of invention could be increased if competition (antitrust) merger policy placed more emphasis on preserving numerous diverse research organizations. Section 4 concludes by emphasizing that the proposed change in merger policy is efficiency-based and is important because of its potential for increasing the pace of discovery of new ideas and increasing socially beneficial economic growth.",
62.0,2.0,Review of Industrial Organization,24 January 2023,https://link.springer.com/article/10.1007/s11151-023-09894-1,Before Privatization There was Its Impact: Sugar Factories in Turkey,March 2023,Alper Demirdogen,,,Male,Unknown,Unknown,Male,"Privatization policies involve the transfer of state institutions to the private sector. These policies have generated more than US $3.6 trillion in revenue for governments worldwide between 1988 and 2016 (Privatization Barometer, 2017). Economists regularly evaluate the impact of privatization policies on efficiency, productivity, profitability, earnings, and employment (Djankov & Murrell, 2002; Estrin & Pelletier, 2018; Estrin et al., 2009; Iwasaki & Mizobata, 2018; Megginson & Netter, 2001; Roland & Stiglitz, 2008). In addition to the direct changes in institutional properties, privatization policies may influence prices and consumer and producer behaviors (Birdsall & Nellis, 2003; Hailu et al., 2012; La Porta & Lopez-de-Silanes, 1999). For example, the privatization of tobacco factories directly affects the farmers who sell their products to these factories. Accordingly, the implication of privatization on the agriculture sector has been an active area of research that covers a wide geographical focus, including China, Central and Eastern Europe, and Russia (Ghazalian & Fakih, 2017; Stupak, 2016; Wang et al., 2019). Privatization policies may create uncertainty in the markets, because of the uncertainty as to how institutions will change after the process is completed (Dewatripont & Roland, 1995; Fernandez & Rodrik, 1991; Potter, 2018). However, few papers focus on the uncertainty that is created by privatization policies. Instead, most of the literature focuses on the “before and after” approach, which compares institutions and their related individuals before and after privatization. However, privatization takes time; and generally, there is a delay between the announcement of privatization and the transfer of the institutions (Martin & Parker, 1995). Because of this delay, there is also an additional period called “pre-privatization” that creates an “anticipation effect” (Dewenter & Malatesta, 2001; Megginson & Netter, 2001). In February 2018, the Government of Turkey announced that it would privatize 14 of 25 state-owned sugar factories. Although the government announced the privatization policy at the beginning of 2018, the actual transfer of these factories to the private sector stretched until the end of the year. This announcement caused significant concerns among the farmers under contract with these factories. As farmers had to plant their sugar beets around April, they were not able to see the transfer of the factories before signing contracts with them. In this paper, we estimate the effect of this privatization policy on farmers’ land allocation decisions with a difference-in-differences approach. We use a village-level micro dataset for 2015–2020. We find that sugar beet acreages decreased by more than 15% due to the 2018 privatization policy that was applied in Turkey. The effect of the policy emerged even before the actual transfer of the sugar factories to the private sector. Farmers decreased their contracted sugar beet acreages in the middle of 2018: after the announcement but before the transfer of the institutions. Production continued to decrease in the following years in the actually-privatized group. However, for the factories for which privatization was subsequently canceled, the negative effects of the announcement on sugar beet acreages vanished, and farmers began to negotiate contracts with these to-be-privatized factories that remained under state control. The findings in this paper emphasize the importance of future uncertainty in formulating economic reform policies. Policymakers could minimize the unexpected results of transitioning state institutions to the private sector by considering the anticipation effect of privatization policies. Additionally, this paper could contribute to the topic of contract farming by showing how farmers might behave according to the institutional changes that are related to their contracting partner (Bellemare & Bloem, 2018; Ton et al., 2018). Finally, policies that are related to sugar and its production are heavily discussed in the policy arena (European Commission, 2017; OECD & FAO, 2019). The recent abolition of sugar production quotas in EU countries and the decreasing role of the state in Turkey will both significantly affect sugar markets. This paper proceeds as follows: Sect. 2 summarizes Turkey’s sugar market and the privatization of sugar factories. Section 3 discusses the village-level micro dataset. Section 4 presents the empirical strategy. Section 5 shows the results of our study on the impact of privatization. Section 6 provides additional evidence, discussion, and policy implications. Finally, Sect. 7 concludes.",
62.0,3.0,Review of Industrial Organization,03 February 2023,https://link.springer.com/article/10.1007/s11151-023-09895-0,Price Competition in a Vertizontally Differentiated Duopoly,May 2023,Iwan Bos,Ronald Peeters,,Male,Male,Unknown,Male,"In the period mid 2017 until mid 2018, U.S. citizens spent over $5 billion on dry dog food.Footnote 1 The table below lists the four leading dry dog food brands in the period mid 2017 until mid 2018.Footnote 2 These four brands are produced by the two major firms in the dog food market: Nestlé (39% market share) and Mars (24% market share). The last column of the table presents the price per pound at Walmart for a large-sized bag.Footnote 3 Notice that both manufacturers offer a ‘standard’ and a ‘premium’ brand and that segment prices are (approximately) the same.  Rank Brand Dollar sales (million) Manufacturer $/lb 1 Pedigree $603 Mars, Inc. 0.52 2 Purina dog chow $457 Nestlé Purina Petcare Co. 0.45 3 Purina one smartblend $346 Nestlé Purina Petcare Co. 1.08 4 Iams proactive health $265 Mars, Inc. 1.08 There are many industries that consist of a few firms that compete in multiple market segments that are characterized by product quality.Footnote 4 A critical feature of such quality-segmented markets is that competition has both a horizontal and a vertical dimension. For instance, if a firm raises the price of its premium product, then it is likely to ‘lose’ customers to rival brands as well as to its own lower quality division(s). Likewise, if a firm cuts its premium product price, then ceteris paribus it steals customers from comparable quality competitors while cannibalizing the sales of its other items. The fact that multi-product firms are partly in competition with themselves makes the design of an optimal pricing policy far from trivial. The purpose of this paper is to study strategic pricing by sellers that are competing ‘head-to-head’ in several quality segments simultaneously. Toward that end, we develop a price-setting duopoly model of vertizontal product differentiation in which firms offer both a standard and a premium product. Demand for these product types comes from two different sorts of customers: those who are brand-anchored; and those who are quality-anchored. Brand-anchored buyers choose only between the standard and premium product of their preferred supplier; by contrast, quality-anchored buyers have a preference for a particular quality level and choose between brands only.Footnote 5 The model contains no less than nine distinct demand- and supply-side parameters, which enables us to study separately the impact of these ‘horizontal’ and ‘vertical’ forces on firms’ pricing decisions. To summarize some of our main findings: We establish the existence of a unique (and symmetric) competitive pricing equilibrium and perform a series of comparative statics exercises on this equilibrium outcome. With regard to the ‘horizontal forces’, we find that equilibrium prices are increasing in the extent of brand differentiation and decreasing in the number of quality-anchored buyers. With regard to the ‘vertical forces’, we establish that equilibrium prices are increasing in the number of brand-anchored buyers and show that the price of the standard (premium) product is decreasing (increasing) in the quality difference. Interestingly, we find that equilibrium profits may rise when there is a segment-wide increase in production costs. We then use these results as a basis of comparison to explore the effect of decentralized pricing. If pricing decisions are taken at the product (division) level, then there is again a unique (and symmetric) competitive pricing equilibrium. The equilibrium outcome is such that both prices and profits are lower than in the centralized case. If the quality difference between the standard and premium product is substantial and the costs of producing additional quality are sufficiently small, then a switch from centralized to decentralized pricing leads to an increase of the standard good’s sales. By contrast, the premium product’s market share increases when the quality difference is limited and the marginal costs of producing extra quality are high enough. Last, we find that societal welfare is unambiguously lower with decentralized pricing. The next section provides a brief literature review. Section 3 introduces the vertizontal differentiation model. The symmetric version of this model is analyzed in Sect. 4. Sections 5 and 6 consider the impact of asymmetry in consumer preferences, unit costs and organizational structure. Section 7 concludes. All proofs are relegated to the Appendix.",
62.0,3.0,Review of Industrial Organization,20 February 2023,https://link.springer.com/article/10.1007/s11151-023-09898-x,Competition and Specialization in the VC Market: A Non-monotonic Relationship,May 2023,Christos Cabolis,Mian Dai,Konstantinos Serfes,Male,,Male,Mix,,
62.0,3.0,Review of Industrial Organization,16 February 2023,https://link.springer.com/article/10.1007/s11151-023-09899-w,Uncertainty of Outcome Hypothesis: Theoretical Development and Empirical Evaluation,May 2023,Hayley Jang,Doyoung Kim,Young Hoon Lee,Female,Unknown,,Mix,,
62.0,3.0,Review of Industrial Organization,13 February 2023,https://link.springer.com/article/10.1007/s11151-023-09897-y,Pricing Strategies and Partial Privatization Policy,May 2023,Akio Kawasaki,,,Male,Unknown,Unknown,Male,"Privatization of previously government-owned firms has been in progress worldwide for decades. Consequently, many network industries–e.g., power, gas, water, telecommunications, and transportation–are witnessing increased competition between private firms and public (or semi-public) firms. Under these circumstances, many researchers have examined whether partial privatization–where a firm has a mixture of public and private ownership–or full privatization improves social welfare, and have emphasized the necessity of the partial or full privatization of public firms (e.g., De Fraja and Delbono, 1989; Matsumura, 1998). In the aforementioned network industries, a public firm provides goods or services to multiple regions. In some regions, both the incumbent public firm and private entrant firms provide goods or services, whereas in other regions, only the public firm provides goods or services. In other words, asymmetric multi-market competition is sometimes observed. When a public firm provides essential services to multiple regions, it often sets identical prices for all regions: It offers uniform pricing. Although many studies have examined whether uniform or discriminatory pricing increases social welfare (e.g., Schmalensee, 1981; Varian, 1985; Holmes, 1989; Dastidar, 2006), no study has hitherto examined this problem in the context of a privatization policy. However, both pricing strategies–discriminatory and uniform pricing–exist in network industries; moreover, (partial) privatization can exist for each pricing strategy. This study first considers the optimal privatization policy in relation to each pricing strategy. With regard to the privatization policy, there are three choices: full privatization; partial privatization; and full government ownership. At the same time, this study examines how the differences in production technology affects the privatization policy.Footnote 1 Finally, using these results, this study examines the optimal pricing strategy and attempts to show the condition where uniform pricing is socially preferable. This study’s contribution is in showing results for the aforementioned important issues. The remainder of this paper is organized as follows: The following section reviews the literature on privatization and price discrimination. The model is presented in Sect. 3. Additionally, we summarize our results at the end of Sect. 3 in a comprehensive table. Sections 4 and 5 analyze the optimal degree of privatization under discriminatory and uniform pricing, respectively. Section 6 compares the equilibrium prices for each pricing type and examines whether uniform pricing increases social welfare. Section 7 offers concluding remarks and suggestions for future research.",
62.0,4.0,Review of Industrial Organization,08 April 2023,https://link.springer.com/article/10.1007/s11151-023-09900-6,Slot Divestitures and Price Competition at Reagan National and LaGuardia,June 2023,Huubinh B. Le,Jules O. Yimga,,Unknown,Male,Unknown,Male,"Airports in the US are classified depending on the level of congestion. At the highest level, Level 3Footnote 1 airports have flight demand during peak hours that greatly exceed their runway capacity and without control would result in excessive congestion. To manage this congestion, these airports limit the number of flights with the use of time slots during these hours: Airlines must have a specific time slot for each departure and landing. Although slots help manage congestion, they have implications for market competition. Since the number of slots is capped, competitive pressure is also reduced if slots are not distributed among competitors. How is price competition affected if the existing holders are required to divest some of their slots to other competitors? This question is relevant because the merger between American Airlines (AA) and US Airways (US) in 2013 was initially blocked by the US Department of Justice (DOJ)Footnote 2–in part because the two airlines had dominant slot positions at Reagan National (DCA) in Washington, DC, and to lesser extent at LaGuardia (LGA) in New York: two of the most capacity-constrained airports in the US. Consequently, a major requirement for the DOJ to approve their merger was the divestiture of some of their slots at these two airports to low-cost competitors (LCCs).Footnote 3 Although these divestitures had the potential to preserve price competition at these airports, it is unclear whether this potential was realized–particularly in merger-related markets (overlap markets): While these divestitures reduced the slot concentration of the merging airlines and gave these LCCs greater access to these airports, the divestitures did not ensure that the competition that was lost in overlap city-pair route markets would be replaced or maintained. This paper considers how these divestitures affected price competition in city-pair markets at DCA and LGA–particularly in overlap markets. We use a difference-in-differences approach to isolate these price effects. While several factors affect the magnitude of these estimates–including the direction of the routes, nonstop versus connecting routes, and the extent of overlap–on balance these divestitures have not preserved price competition in overlap markets at DCA, but they have done so at LGA: The largest increases in price at DCA have been on those nonstop one-way routes for which DCA is the departing airport. Much of the procompetitive effect at DCA came instead from markets in which the merging airlines did not directly compete (nonoverlap markets): particularly those markets where US provided service prior to the divestitures. In the case of LGA, even though price competition in overlap markets has essentially been preserved, there is evidence of higher prices in nonoverlap markets: particularly for round-trip nonstop routes where US provided service. These findings suggest that the effectiveness of these divestitures in preserving price competition in these markets was limited. In particular, price competition in overlap markets that were connected to DCA was not preserved even though the size of the divestitures at DCA was three times larger than at LGA. This finding raises the question of the appropriate size of the divestitures and the effectiveness of using LCCs alone to discipline these markets. The next section summarizes the regulatory framework of airport slots and slot distribution before and after the divestitures. A brief literature review follows in Sect. 3. Section 4 describes the data and specifies the empirical model. Results are presented in Sect. 5. Section 6 concludes.",
62.0,4.0,Review of Industrial Organization,16 May 2023,https://link.springer.com/article/10.1007/s11151-023-09901-5,Product-Line Decisions and Rapid Turnover in Movie Markets,June 2023,Yu-Hsi Liu,Darlene C. Chisholm,George Norman,Unknown,Female,Male,Mix,,
62.0,4.0,Review of Industrial Organization,13 May 2023,https://link.springer.com/article/10.1007/s11151-023-09902-4,The Timing of Technology Adoption in Network Industries,June 2023,Leonard F. S. Wang,Domenico Buccella,,Male,Male,Unknown,Male,"There is a general consensus among academics and policymakers about the relationship between innovation and economic development. In particular, technological innovation contributes to the productivity of labour and capital, and this in turn has a positive effect on long-run economic growth. New technology adoptions have a flywheel effect for technological progress. In recent years, an increasing focus is on digital innovations such as 3-D printing, robotic automation, artificial intelligence, the industrial internet of things, and big data analysis (Forbes, 2018), whose effect is to reduce operating (production) costs and improve processes, as consulting groups report (Deloitte, 2018; McKinsey & Company, 2018). However, it has been widely observed that both the adoption and diffusion rates of new technologies are considerably different across industries. Remarkably, in the European Union (EU), network industries – such as telecommunications and computer programming – and ICT manufacturing are top-ranked sectors with regard to the percentage of firms (above 50%) that have a high “digital intensity index” (a measure of the degree of enterprises’ new technology adoption) – in contrast to, for example, construction and food manufacturing (below 10%) (see, e.g., European Commission, 2004, 2005, 2006, 2018). Similar findings have been found for the average adoption rates of core digital technologies in the period 2010–2016 for the OECD countries. For example, with regard to cloud computing, adoption rates range from 16.56% in food and beverage service to 55.51% in computer programming; with regard to enterprise resource planning, adoption rates range from 11.19% in food and beverage service to 55.61% in computer, electronic and optical products manufacturing; and adoption rates of customer relation management range from 16.21% in food and beverage services to 65.95% in telecommunications (Nicoletti et al., 2020). Network industries are expanding in advanced contemporary economics. In general, network industries produce goods whose utility for a consumer/user increases with the number of other consumers/users of those goods: Network goods generate positive consumption externalities, and the total sales of the goods improve the welfare of each consumer (Amir & Lazzati, 2011; Katz & Shapiro, 1985). To implement a new technology successfully might usually require time. When consumers adopt a new technology, the network externalities can be considered to be one of the reasons for consumers to wait for or for firms to accelerate the introduction of the technology. From this standpoint, introducing the network effects into the timing of the technology adoption is a timely investigation. The present paper focuses on this subject. The remainder of the paper is organized as follows: Sect. 2 surveys the related literature and briefly describes the key findings. Section 3 describes the model and extensively discusses the results. Section 4 briefly discusses two extensions of the basic model to check its robustness. Section 5 presents some concluding remarks and outlines future lines of research.",
62.0,4.0,Review of Industrial Organization,21 June 2023,https://link.springer.com/article/10.1007/s11151-023-09903-3,Public–Private Collusion,June 2023,Filipa Mota,João Correia-da-Silva,Joana Pinho,Female,,Female,Mix,,
